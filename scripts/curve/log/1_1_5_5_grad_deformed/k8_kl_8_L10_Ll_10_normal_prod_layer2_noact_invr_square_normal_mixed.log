use normalized raw measures
Preprocessing data : computing close_node_pairs
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:15<00:00, 62.85it/s]
maximum number of close node pairs is  10000
Casting to tensor
x train:torch.Size([900, 1000, 8]), y train:torch.Size([900, 1000, 1]), x test:torch.Size([100, 1000, 8]), y test:torch.Size([100, 1000, 1])
length of each dim:  tensor([6.5573987960815430, 6.1420288085937500])
kmax = 8, kmax_local = 8
L =  10  L_local =  10
In PCNO_train, ndims =  2
Epoch :  0  Time:  3.515  Rel. Train L2 Loss :  0.5117532222800785  Rel. Test L2 Loss :  0.36364480495452883  Test L2 Loss :  0.523368148803711  inv_L_scale:  [1.0, 1.0]
Epoch :  1  Time:  2.914  Rel. Train L2 Loss :  0.2983650824758742  Rel. Test L2 Loss :  0.2547044563293457  Test L2 Loss :  0.36321896195411685  inv_L_scale:  [1.0, 1.0]
Epoch :  2  Time:  3.041  Rel. Train L2 Loss :  0.21829406665431128  Rel. Test L2 Loss :  0.19483703911304473  Test L2 Loss :  0.28007997751235963  inv_L_scale:  [1.0, 1.0]
Epoch :  3  Time:  2.952  Rel. Train L2 Loss :  0.18594789889123706  Rel. Test L2 Loss :  0.17693531155586242  Test L2 Loss :  0.253701878786087  inv_L_scale:  [1.0, 1.0]
Epoch :  4  Time:  2.963  Rel. Train L2 Loss :  0.17300927016470166  Rel. Test L2 Loss :  0.16073898792266847  Test L2 Loss :  0.23152112007141112  inv_L_scale:  [1.0, 1.0]
Epoch :  5  Time:  2.924  Rel. Train L2 Loss :  0.16329942517810397  Rel. Test L2 Loss :  0.15942334055900573  Test L2 Loss :  0.2291711950302124  inv_L_scale:  [1.0, 1.0]
Epoch :  6  Time:  2.832  Rel. Train L2 Loss :  0.15735050625271269  Rel. Test L2 Loss :  0.16250515520572661  Test L2 Loss :  0.23377105951309204  inv_L_scale:  [1.0, 1.0]
Epoch :  7  Time:  2.941  Rel. Train L2 Loss :  0.15814721167087556  Rel. Test L2 Loss :  0.15353558242321014  Test L2 Loss :  0.22074774265289307  inv_L_scale:  [1.0, 1.0]
Epoch :  8  Time:  2.938  Rel. Train L2 Loss :  0.15130830685297647  Rel. Test L2 Loss :  0.14664947867393494  Test L2 Loss :  0.21189538836479188  inv_L_scale:  [1.0, 1.0]
Epoch :  9  Time:  2.908  Rel. Train L2 Loss :  0.14982820279068418  Rel. Test L2 Loss :  0.14564075708389282  Test L2 Loss :  0.2102336949110031  inv_L_scale:  [1.0, 1.0]
Epoch :  10  Time:  2.996  Rel. Train L2 Loss :  0.14746874060895707  Rel. Test L2 Loss :  0.1498420763015747  Test L2 Loss :  0.21522595643997192  inv_L_scale:  [1.0, 1.0]
Epoch :  11  Time:  2.979  Rel. Train L2 Loss :  0.14665684858957925  Rel. Test L2 Loss :  0.14396577060222626  Test L2 Loss :  0.20789556801319123  inv_L_scale:  [1.0, 1.0]
Epoch :  12  Time:  2.916  Rel. Train L2 Loss :  0.1480292722913954  Rel. Test L2 Loss :  0.1492994600534439  Test L2 Loss :  0.2160245269536972  inv_L_scale:  [1.0, 1.0]
Epoch :  13  Time:  3.002  Rel. Train L2 Loss :  0.1442129905356301  Rel. Test L2 Loss :  0.1414720606803894  Test L2 Loss :  0.20380232512950897  inv_L_scale:  [1.0, 1.0]
Epoch :  14  Time:  2.934  Rel. Train L2 Loss :  0.14365061865912543  Rel. Test L2 Loss :  0.1417924189567566  Test L2 Loss :  0.20512391567230226  inv_L_scale:  [1.0, 1.0]
Epoch :  15  Time:  2.938  Rel. Train L2 Loss :  0.142703508204884  Rel. Test L2 Loss :  0.1422437024116516  Test L2 Loss :  0.20450155675411225  inv_L_scale:  [1.0, 1.0]
Epoch :  16  Time:  2.94  Rel. Train L2 Loss :  0.14170408758852218  Rel. Test L2 Loss :  0.14017276108264923  Test L2 Loss :  0.202625350356102  inv_L_scale:  [1.0, 1.0]
Epoch :  17  Time:  2.992  Rel. Train L2 Loss :  0.14110934886667464  Rel. Test L2 Loss :  0.13780536949634553  Test L2 Loss :  0.1999731934070587  inv_L_scale:  [1.0, 1.0]
Epoch :  18  Time:  3.068  Rel. Train L2 Loss :  0.14145408127042983  Rel. Test L2 Loss :  0.1370811504125595  Test L2 Loss :  0.19805317640304565  inv_L_scale:  [1.0, 1.0]
Epoch :  19  Time:  2.963  Rel. Train L2 Loss :  0.1380368141995536  Rel. Test L2 Loss :  0.13788651645183564  Test L2 Loss :  0.19997963905334473  inv_L_scale:  [1.0, 1.0]
Epoch :  20  Time:  2.998  Rel. Train L2 Loss :  0.1397025261984931  Rel. Test L2 Loss :  0.13820855736732482  Test L2 Loss :  0.19969124913215638  inv_L_scale:  [1.0, 1.0]
Epoch :  21  Time:  3.069  Rel. Train L2 Loss :  0.13856024748749204  Rel. Test L2 Loss :  0.1387581342458725  Test L2 Loss :  0.20082060158252715  inv_L_scale:  [1.0, 1.0]
Epoch :  22  Time:  2.952  Rel. Train L2 Loss :  0.13906398912270865  Rel. Test L2 Loss :  0.1403406071662903  Test L2 Loss :  0.20325840294361114  inv_L_scale:  [1.0, 1.0]
Epoch :  23  Time:  3.07  Rel. Train L2 Loss :  0.1388145946794086  Rel. Test L2 Loss :  0.14788002729415894  Test L2 Loss :  0.21378095626831053  inv_L_scale:  [1.0, 1.0]
Epoch :  24  Time:  2.94  Rel. Train L2 Loss :  0.13887486179669697  Rel. Test L2 Loss :  0.1384642565250397  Test L2 Loss :  0.20085914969444274  inv_L_scale:  [1.0, 1.0]
Epoch :  25  Time:  2.911  Rel. Train L2 Loss :  0.13787933038340675  Rel. Test L2 Loss :  0.13505305528640746  Test L2 Loss :  0.19583068132400513  inv_L_scale:  [1.0, 1.0]
Epoch :  26  Time:  2.922  Rel. Train L2 Loss :  0.13696760707431369  Rel. Test L2 Loss :  0.1338925039768219  Test L2 Loss :  0.19374487817287445  inv_L_scale:  [1.0, 1.0]
Epoch :  27  Time:  2.912  Rel. Train L2 Loss :  0.13623551242881352  Rel. Test L2 Loss :  0.13836560308933257  Test L2 Loss :  0.2001040458679199  inv_L_scale:  [1.0, 1.0]
Epoch :  28  Time:  2.908  Rel. Train L2 Loss :  0.1372814279794693  Rel. Test L2 Loss :  0.135461146235466  Test L2 Loss :  0.19687787652015687  inv_L_scale:  [1.0, 1.0]
Epoch :  29  Time:  2.944  Rel. Train L2 Loss :  0.137264214820332  Rel. Test L2 Loss :  0.1373937326669693  Test L2 Loss :  0.19852061927318573  inv_L_scale:  [1.0, 1.0]
Epoch :  30  Time:  2.93  Rel. Train L2 Loss :  0.13660749428802066  Rel. Test L2 Loss :  0.13294459402561187  Test L2 Loss :  0.192960045337677  inv_L_scale:  [1.0, 1.0]
Epoch :  31  Time:  2.929  Rel. Train L2 Loss :  0.13595005803638036  Rel. Test L2 Loss :  0.13396758913993836  Test L2 Loss :  0.19514986395835876  inv_L_scale:  [1.0, 1.0]
Epoch :  32  Time:  3.06  Rel. Train L2 Loss :  0.13859689679410722  Rel. Test L2 Loss :  0.1342829519510269  Test L2 Loss :  0.19479165732860565  inv_L_scale:  [1.0, 1.0]
Epoch :  33  Time:  3.079  Rel. Train L2 Loss :  0.13602283305592008  Rel. Test L2 Loss :  0.13517029762268065  Test L2 Loss :  0.1955706548690796  inv_L_scale:  [1.0, 1.0]
Epoch :  34  Time:  2.946  Rel. Train L2 Loss :  0.1360909159315957  Rel. Test L2 Loss :  0.13644660234451295  Test L2 Loss :  0.19907251477241517  inv_L_scale:  [1.0, 1.0]
Epoch :  35  Time:  2.938  Rel. Train L2 Loss :  0.13568459477689532  Rel. Test L2 Loss :  0.13449146151542662  Test L2 Loss :  0.19530601024627686  inv_L_scale:  [1.0, 1.0]
Epoch :  36  Time:  2.92  Rel. Train L2 Loss :  0.1352166924873988  Rel. Test L2 Loss :  0.1331617259979248  Test L2 Loss :  0.19337878584861756  inv_L_scale:  [1.0, 1.0]
Epoch :  37  Time:  3.014  Rel. Train L2 Loss :  0.1346317332320743  Rel. Test L2 Loss :  0.13670046091079713  Test L2 Loss :  0.1979583740234375  inv_L_scale:  [1.0, 1.0]
Epoch :  38  Time:  2.935  Rel. Train L2 Loss :  0.13517265415853924  Rel. Test L2 Loss :  0.1355430465936661  Test L2 Loss :  0.19630060970783234  inv_L_scale:  [1.0, 1.0]
Epoch :  39  Time:  2.964  Rel. Train L2 Loss :  0.13491243263085684  Rel. Test L2 Loss :  0.13231031000614166  Test L2 Loss :  0.19215880274772645  inv_L_scale:  [1.0, 1.0]
Epoch :  40  Time:  2.938  Rel. Train L2 Loss :  0.13433993074629041  Rel. Test L2 Loss :  0.13190558016300202  Test L2 Loss :  0.19161803603172303  inv_L_scale:  [1.0, 1.0]
Epoch :  41  Time:  2.917  Rel. Train L2 Loss :  0.13370843847592673  Rel. Test L2 Loss :  0.1372288078069687  Test L2 Loss :  0.1983249479532242  inv_L_scale:  [1.0, 1.0]
Epoch :  42  Time:  3.01  Rel. Train L2 Loss :  0.13380599909358554  Rel. Test L2 Loss :  0.13295602977275847  Test L2 Loss :  0.1928196966648102  inv_L_scale:  [1.0, 1.0]
Epoch :  43  Time:  2.842  Rel. Train L2 Loss :  0.13370597687032487  Rel. Test L2 Loss :  0.1315536892414093  Test L2 Loss :  0.19103191018104554  inv_L_scale:  [1.0, 1.0]
Epoch :  44  Time:  2.832  Rel. Train L2 Loss :  0.1345903268787596  Rel. Test L2 Loss :  0.13280688285827635  Test L2 Loss :  0.19262685298919677  inv_L_scale:  [1.0, 1.0]
Epoch :  45  Time:  2.851  Rel. Train L2 Loss :  0.13410644286208684  Rel. Test L2 Loss :  0.12965691447257996  Test L2 Loss :  0.18853350579738617  inv_L_scale:  [1.0, 1.0]
Epoch :  46  Time:  2.908  Rel. Train L2 Loss :  0.13409401800897386  Rel. Test L2 Loss :  0.1359102940559387  Test L2 Loss :  0.19710859894752503  inv_L_scale:  [1.0, 1.0]
Epoch :  47  Time:  2.891  Rel. Train L2 Loss :  0.13431856605741713  Rel. Test L2 Loss :  0.13052647531032563  Test L2 Loss :  0.19027120530605315  inv_L_scale:  [1.0, 1.0]
Epoch :  48  Time:  2.928  Rel. Train L2 Loss :  0.1331983587808079  Rel. Test L2 Loss :  0.13283707678318024  Test L2 Loss :  0.19296371400356294  inv_L_scale:  [1.0, 1.0]
Epoch :  49  Time:  2.832  Rel. Train L2 Loss :  0.13395938512351777  Rel. Test L2 Loss :  0.12964542865753173  Test L2 Loss :  0.1888915181159973  inv_L_scale:  [1.0, 1.0]
Epoch :  50  Time:  2.892  Rel. Train L2 Loss :  0.13313883913887872  Rel. Test L2 Loss :  0.13054758846759795  Test L2 Loss :  0.1901586365699768  inv_L_scale:  [1.0, 1.0]
Epoch :  51  Time:  2.839  Rel. Train L2 Loss :  0.13376287016603683  Rel. Test L2 Loss :  0.1370658141374588  Test L2 Loss :  0.19887595653533935  inv_L_scale:  [1.0, 1.0]
Epoch :  52  Time:  2.939  Rel. Train L2 Loss :  0.13361635188261667  Rel. Test L2 Loss :  0.13184098541736602  Test L2 Loss :  0.1919046974182129  inv_L_scale:  [1.0, 1.0]
Epoch :  53  Time:  3.032  Rel. Train L2 Loss :  0.13279625366131464  Rel. Test L2 Loss :  0.13473161697387695  Test L2 Loss :  0.19700731575489044  inv_L_scale:  [1.0, 1.0]
Epoch :  54  Time:  3.035  Rel. Train L2 Loss :  0.1337164444062445  Rel. Test L2 Loss :  0.1343261057138443  Test L2 Loss :  0.19507113039493562  inv_L_scale:  [1.0, 1.0]
Epoch :  55  Time:  2.883  Rel. Train L2 Loss :  0.13244802769687442  Rel. Test L2 Loss :  0.1316005790233612  Test L2 Loss :  0.19124310731887817  inv_L_scale:  [1.0, 1.0]
Epoch :  56  Time:  2.845  Rel. Train L2 Loss :  0.13313048710425696  Rel. Test L2 Loss :  0.13359474301338195  Test L2 Loss :  0.19412119805812836  inv_L_scale:  [1.0, 1.0]
Epoch :  57  Time:  2.904  Rel. Train L2 Loss :  0.13289329833454555  Rel. Test L2 Loss :  0.12896990776062012  Test L2 Loss :  0.18751802921295166  inv_L_scale:  [1.0, 1.0]
Epoch :  58  Time:  2.898  Rel. Train L2 Loss :  0.1322333359056049  Rel. Test L2 Loss :  0.13101732730865479  Test L2 Loss :  0.190306853055954  inv_L_scale:  [1.0, 1.0]
Epoch :  59  Time:  2.967  Rel. Train L2 Loss :  0.1321664043267568  Rel. Test L2 Loss :  0.13003296077251433  Test L2 Loss :  0.18844268679618836  inv_L_scale:  [1.0, 1.0]
Epoch :  60  Time:  2.821  Rel. Train L2 Loss :  0.13280706697040134  Rel. Test L2 Loss :  0.13533470749855042  Test L2 Loss :  0.19597629725933075  inv_L_scale:  [1.0, 1.0]
Epoch :  61  Time:  2.883  Rel. Train L2 Loss :  0.13264991776810753  Rel. Test L2 Loss :  0.13053822427988052  Test L2 Loss :  0.18983810901641845  inv_L_scale:  [1.0, 1.0]
Epoch :  62  Time:  3.036  Rel. Train L2 Loss :  0.13325972821977403  Rel. Test L2 Loss :  0.1323276913166046  Test L2 Loss :  0.19252027273178102  inv_L_scale:  [1.0, 1.0]
Epoch :  63  Time:  3.041  Rel. Train L2 Loss :  0.13186727864874734  Rel. Test L2 Loss :  0.13409483850002288  Test L2 Loss :  0.1944495052099228  inv_L_scale:  [1.0, 1.0]
Epoch :  64  Time:  3.051  Rel. Train L2 Loss :  0.13224453859859042  Rel. Test L2 Loss :  0.12840452432632446  Test L2 Loss :  0.18663568615913392  inv_L_scale:  [1.0, 1.0]
Epoch :  65  Time:  3.069  Rel. Train L2 Loss :  0.13049739533000523  Rel. Test L2 Loss :  0.13037323951721191  Test L2 Loss :  0.1891745537519455  inv_L_scale:  [1.0, 1.0]
Epoch :  66  Time:  3.097  Rel. Train L2 Loss :  0.13095360587040583  Rel. Test L2 Loss :  0.1305049854516983  Test L2 Loss :  0.1904448139667511  inv_L_scale:  [1.0, 1.0]
Epoch :  67  Time:  3.077  Rel. Train L2 Loss :  0.13132640361785888  Rel. Test L2 Loss :  0.12971768915653228  Test L2 Loss :  0.1889605063199997  inv_L_scale:  [1.0, 1.0]
Epoch :  68  Time:  3.096  Rel. Train L2 Loss :  0.13085597005155353  Rel. Test L2 Loss :  0.1307288372516632  Test L2 Loss :  0.18991854906082153  inv_L_scale:  [1.0, 1.0]