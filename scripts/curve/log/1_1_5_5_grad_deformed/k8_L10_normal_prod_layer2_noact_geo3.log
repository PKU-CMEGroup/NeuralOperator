(1000,) (1000, 1000, 1) (1000, 1000, 2)
use normalized raw measures
Casting to tensor
x_train shape torch.Size([900, 1000, 8]), y_train shape torch.Size([900, 1000, 1])
length of each dim:  tensor([6.5573987960815430, 6.1420288085937500])
kmax = 8
L = 10
use cube modes, scale = 0 (144, 2, 1)
geo_dims = [1, 2, 3, 4]
In PCNO_train, ndims =  2
Epoch :  0  Time:  1.133  Rel. Train L2 Loss :  0.5041917351881663  Rel. Test L2 Loss :  0.37096590518951417  Test L2 Loss :  0.5367271423339843  inv_L_scale:  [1.0, 1.0]
Epoch :  1  Time:  0.769  Rel. Train L2 Loss :  0.2924229449696011  Rel. Test L2 Loss :  0.24692318081855774  Test L2 Loss :  0.3515454244613647  inv_L_scale:  [1.0, 1.0]
Epoch :  2  Time:  0.77  Rel. Train L2 Loss :  0.21382504529423185  Rel. Test L2 Loss :  0.1876366037130356  Test L2 Loss :  0.26756944954395295  inv_L_scale:  [1.0, 1.0]
Epoch :  3  Time:  0.773  Rel. Train L2 Loss :  0.17878883086972766  Rel. Test L2 Loss :  0.16646647751331328  Test L2 Loss :  0.23778061747550963  inv_L_scale:  [1.0, 1.0]
Epoch :  4  Time:  0.777  Rel. Train L2 Loss :  0.1653763363758723  Rel. Test L2 Loss :  0.16477056920528413  Test L2 Loss :  0.2345095866918564  inv_L_scale:  [1.0, 1.0]
Epoch :  5  Time:  0.769  Rel. Train L2 Loss :  0.15729058186213177  Rel. Test L2 Loss :  0.15294272422790528  Test L2 Loss :  0.2181938821077347  inv_L_scale:  [1.0, 1.0]
Epoch :  6  Time:  0.765  Rel. Train L2 Loss :  0.14964701698886024  Rel. Test L2 Loss :  0.1444118869304657  Test L2 Loss :  0.20838978588581086  inv_L_scale:  [1.0, 1.0]
Epoch :  7  Time:  0.766  Rel. Train L2 Loss :  0.14709000868929756  Rel. Test L2 Loss :  0.14566157519817352  Test L2 Loss :  0.208669296503067  inv_L_scale:  [1.0, 1.0]
Epoch :  8  Time:  0.771  Rel. Train L2 Loss :  0.1460015709532632  Rel. Test L2 Loss :  0.14508137106895447  Test L2 Loss :  0.20781647384166718  inv_L_scale:  [1.0, 1.0]
Epoch :  9  Time:  0.766  Rel. Train L2 Loss :  0.14416210876570806  Rel. Test L2 Loss :  0.14650000929832457  Test L2 Loss :  0.21030348062515258  inv_L_scale:  [1.0, 1.0]
Epoch :  10  Time:  0.767  Rel. Train L2 Loss :  0.13878754913806915  Rel. Test L2 Loss :  0.1406876665353775  Test L2 Loss :  0.20130636692047119  inv_L_scale:  [1.0, 1.0]
Epoch :  11  Time:  0.768  Rel. Train L2 Loss :  0.13877849873569276  Rel. Test L2 Loss :  0.1372596216201782  Test L2 Loss :  0.1975988280773163  inv_L_scale:  [1.0, 1.0]
Epoch :  12  Time:  0.77  Rel. Train L2 Loss :  0.13712631596459282  Rel. Test L2 Loss :  0.13949216783046722  Test L2 Loss :  0.20073100090026855  inv_L_scale:  [1.0, 1.0]
Epoch :  13  Time:  0.77  Rel. Train L2 Loss :  0.13616744577884674  Rel. Test L2 Loss :  0.1356595128774643  Test L2 Loss :  0.19507821798324584  inv_L_scale:  [1.0, 1.0]
Epoch :  14  Time:  0.783  Rel. Train L2 Loss :  0.13705426414807637  Rel. Test L2 Loss :  0.13512331366539002  Test L2 Loss :  0.19575563073158264  inv_L_scale:  [1.0, 1.0]
Epoch :  15  Time:  0.767  Rel. Train L2 Loss :  0.1347234507401784  Rel. Test L2 Loss :  0.13755864202976226  Test L2 Loss :  0.19717377841472625  inv_L_scale:  [1.0, 1.0]
Epoch :  16  Time:  0.77  Rel. Train L2 Loss :  0.13059203942616782  Rel. Test L2 Loss :  0.13185198307037355  Test L2 Loss :  0.18929710268974304  inv_L_scale:  [1.0, 1.0]
Epoch :  17  Time:  0.854  Rel. Train L2 Loss :  0.13002086169189878  Rel. Test L2 Loss :  0.1305500102043152  Test L2 Loss :  0.18806331992149353  inv_L_scale:  [1.0, 1.0]
Epoch :  18  Time:  0.776  Rel. Train L2 Loss :  0.13002169880602094  Rel. Test L2 Loss :  0.13241404235363008  Test L2 Loss :  0.19179412484169006  inv_L_scale:  [1.0, 1.0]
Epoch :  19  Time:  0.812  Rel. Train L2 Loss :  0.12842752754688264  Rel. Test L2 Loss :  0.13105533838272096  Test L2 Loss :  0.18765242099761964  inv_L_scale:  [1.0, 1.0]
Epoch :  20  Time:  0.87  Rel. Train L2 Loss :  0.12857202880912358  Rel. Test L2 Loss :  0.1282871913909912  Test L2 Loss :  0.18485510647296904  inv_L_scale:  [1.0, 1.0]
Epoch :  21  Time:  0.817  Rel. Train L2 Loss :  0.13070440974500444  Rel. Test L2 Loss :  0.1279262787103653  Test L2 Loss :  0.18483137369155883  inv_L_scale:  [1.0, 1.0]
Epoch :  22  Time:  0.775  Rel. Train L2 Loss :  0.128035149441825  Rel. Test L2 Loss :  0.1262921941280365  Test L2 Loss :  0.18312502205371856  inv_L_scale:  [1.0, 1.0]
Epoch :  23  Time:  0.767  Rel. Train L2 Loss :  0.12692511982387966  Rel. Test L2 Loss :  0.12817901790142058  Test L2 Loss :  0.1845920842885971  inv_L_scale:  [1.0, 1.0]
Epoch :  24  Time:  0.779  Rel. Train L2 Loss :  0.12595607174767387  Rel. Test L2 Loss :  0.12818363070487976  Test L2 Loss :  0.18495844721794127  inv_L_scale:  [1.0, 1.0]
Epoch :  25  Time:  0.776  Rel. Train L2 Loss :  0.1253772321012285  Rel. Test L2 Loss :  0.12681863635778426  Test L2 Loss :  0.1830303543806076  inv_L_scale:  [1.0, 1.0]
Epoch :  26  Time:  0.767  Rel. Train L2 Loss :  0.12665439003043705  Rel. Test L2 Loss :  0.12382948935031891  Test L2 Loss :  0.17916946411132811  inv_L_scale:  [1.0, 1.0]
Epoch :  27  Time:  0.766  Rel. Train L2 Loss :  0.12459579825401307  Rel. Test L2 Loss :  0.12500039994716644  Test L2 Loss :  0.18042007923126221  inv_L_scale:  [1.0, 1.0]
Epoch :  28  Time:  0.767  Rel. Train L2 Loss :  0.12485077559947967  Rel. Test L2 Loss :  0.1237656569480896  Test L2 Loss :  0.17847898840904236  inv_L_scale:  [1.0, 1.0]
Epoch :  29  Time:  0.78  Rel. Train L2 Loss :  0.12449438598420885  Rel. Test L2 Loss :  0.12168471813201905  Test L2 Loss :  0.17613741934299468  inv_L_scale:  [1.0, 1.0]
Epoch :  30  Time:  0.773  Rel. Train L2 Loss :  0.12272991773155001  Rel. Test L2 Loss :  0.12328857243061066  Test L2 Loss :  0.17752720475196837  inv_L_scale:  [1.0, 1.0]
Epoch :  31  Time:  0.765  Rel. Train L2 Loss :  0.12500411073366802  Rel. Test L2 Loss :  0.12479346036911011  Test L2 Loss :  0.18047100484371184  inv_L_scale:  [1.0, 1.0]
Epoch :  32  Time:  0.769  Rel. Train L2 Loss :  0.12439873847696516  Rel. Test L2 Loss :  0.12316757917404175  Test L2 Loss :  0.17872032403945923  inv_L_scale:  [1.0, 1.0]
Epoch :  33  Time:  0.782  Rel. Train L2 Loss :  0.12131264024310642  Rel. Test L2 Loss :  0.12727216124534607  Test L2 Loss :  0.1830574119091034  inv_L_scale:  [1.0, 1.0]
Epoch :  34  Time:  0.772  Rel. Train L2 Loss :  0.12204408946964476  Rel. Test L2 Loss :  0.12036771953105926  Test L2 Loss :  0.17415413856506348  inv_L_scale:  [1.0, 1.0]
Epoch :  35  Time:  0.767  Rel. Train L2 Loss :  0.12221736288732953  Rel. Test L2 Loss :  0.12268734157085419  Test L2 Loss :  0.17801389336586  inv_L_scale:  [1.0, 1.0]
Epoch :  36  Time:  0.765  Rel. Train L2 Loss :  0.12150149563948313  Rel. Test L2 Loss :  0.1250224444270134  Test L2 Loss :  0.18117427110671996  inv_L_scale:  [1.0, 1.0]
Epoch :  37  Time:  0.799  Rel. Train L2 Loss :  0.12208860089381536  Rel. Test L2 Loss :  0.11955811321735382  Test L2 Loss :  0.17351197838783264  inv_L_scale:  [1.0, 1.0]
Epoch :  38  Time:  0.808  Rel. Train L2 Loss :  0.11951162457466126  Rel. Test L2 Loss :  0.11993648201227187  Test L2 Loss :  0.17344242036342622  inv_L_scale:  [1.0, 1.0]
Epoch :  39  Time:  0.791  Rel. Train L2 Loss :  0.12003846055931515  Rel. Test L2 Loss :  0.12039541691541672  Test L2 Loss :  0.17393133282661438  inv_L_scale:  [1.0, 1.0]
Epoch :  40  Time:  0.876  Rel. Train L2 Loss :  0.12034000443087683  Rel. Test L2 Loss :  0.123397017121315  Test L2 Loss :  0.17808334171772003  inv_L_scale:  [1.0, 1.0]
Epoch :  41  Time:  0.787  Rel. Train L2 Loss :  0.12007779479026795  Rel. Test L2 Loss :  0.12038310408592225  Test L2 Loss :  0.17484830617904662  inv_L_scale:  [1.0, 1.0]
Epoch :  42  Time:  0.778  Rel. Train L2 Loss :  0.11997217105494605  Rel. Test L2 Loss :  0.12210351705551148  Test L2 Loss :  0.17576233744621278  inv_L_scale:  [1.0, 1.0]
Epoch :  43  Time:  0.781  Rel. Train L2 Loss :  0.1205847856733534  Rel. Test L2 Loss :  0.12275707095861435  Test L2 Loss :  0.17725401639938354  inv_L_scale:  [1.0, 1.0]
Epoch :  44  Time:  0.82  Rel. Train L2 Loss :  0.11899548295471403  Rel. Test L2 Loss :  0.1261710637807846  Test L2 Loss :  0.1830862444639206  inv_L_scale:  [1.0, 1.0]
Epoch :  45  Time:  0.795  Rel. Train L2 Loss :  0.12023457600010766  Rel. Test L2 Loss :  0.11921149641275405  Test L2 Loss :  0.17226408421993256  inv_L_scale:  [1.0, 1.0]
Epoch :  46  Time:  0.796  Rel. Train L2 Loss :  0.12038712736633089  Rel. Test L2 Loss :  0.11960066854953766  Test L2 Loss :  0.17293254971504213  inv_L_scale:  [1.0, 1.0]
Epoch :  47  Time:  0.857  Rel. Train L2 Loss :  0.11785503506660461  Rel. Test L2 Loss :  0.12411796808242798  Test L2 Loss :  0.18122673213481902  inv_L_scale:  [1.0, 1.0]
Epoch :  48  Time:  0.789  Rel. Train L2 Loss :  0.11874473386340671  Rel. Test L2 Loss :  0.12491866588592529  Test L2 Loss :  0.1805685865879059  inv_L_scale:  [1.0, 1.0]
Epoch :  49  Time:  0.831  Rel. Train L2 Loss :  0.11870648463567098  Rel. Test L2 Loss :  0.11660611301660538  Test L2 Loss :  0.1687371563911438  inv_L_scale:  [1.0, 1.0]
Epoch :  50  Time:  0.781  Rel. Train L2 Loss :  0.11829257256454892  Rel. Test L2 Loss :  0.12449787974357605  Test L2 Loss :  0.1808268117904663  inv_L_scale:  [1.0, 1.0]
Epoch :  51  Time:  0.809  Rel. Train L2 Loss :  0.11812876641750336  Rel. Test L2 Loss :  0.12069875061511993  Test L2 Loss :  0.17502260863780975  inv_L_scale:  [1.0, 1.0]
Epoch :  52  Time:  0.827  Rel. Train L2 Loss :  0.11813147498501672  Rel. Test L2 Loss :  0.12089429378509521  Test L2 Loss :  0.1752556699514389  inv_L_scale:  [1.0, 1.0]
Epoch :  53  Time:  0.778  Rel. Train L2 Loss :  0.11813450581497616  Rel. Test L2 Loss :  0.13008322536945344  Test L2 Loss :  0.18794308423995973  inv_L_scale:  [1.0, 1.0]
Epoch :  54  Time:  0.77  Rel. Train L2 Loss :  0.11923055973317888  Rel. Test L2 Loss :  0.12039205819368362  Test L2 Loss :  0.17347519993782043  inv_L_scale:  [1.0, 1.0]
Epoch :  55  Time:  0.825  Rel. Train L2 Loss :  0.11739946868684557  Rel. Test L2 Loss :  0.12287109971046448  Test L2 Loss :  0.1779152661561966  inv_L_scale:  [1.0, 1.0]
Epoch :  56  Time:  0.799  Rel. Train L2 Loss :  0.11713543554147085  Rel. Test L2 Loss :  0.11876808345317841  Test L2 Loss :  0.17177753508090973  inv_L_scale:  [1.0, 1.0]
Epoch :  57  Time:  0.799  Rel. Train L2 Loss :  0.11721728920936585  Rel. Test L2 Loss :  0.12000288903713226  Test L2 Loss :  0.17294372677803038  inv_L_scale:  [1.0, 1.0]
Epoch :  58  Time:  0.777  Rel. Train L2 Loss :  0.11694574561383989  Rel. Test L2 Loss :  0.12042938828468323  Test L2 Loss :  0.17400298953056337  inv_L_scale:  [1.0, 1.0]
Epoch :  59  Time:  0.768  Rel. Train L2 Loss :  0.11754989326000213  Rel. Test L2 Loss :  0.11894577234983444  Test L2 Loss :  0.17213219583034514  inv_L_scale:  [1.0, 1.0]
Epoch :  60  Time:  0.764  Rel. Train L2 Loss :  0.11603683445188734  Rel. Test L2 Loss :  0.11695368230342865  Test L2 Loss :  0.16966451525688173  inv_L_scale:  [1.0, 1.0]
Epoch :  61  Time:  0.763  Rel. Train L2 Loss :  0.11676385137769911  Rel. Test L2 Loss :  0.11392629951238632  Test L2 Loss :  0.16525545120239257  inv_L_scale:  [1.0, 1.0]
Epoch :  62  Time:  0.764  Rel. Train L2 Loss :  0.11911178522639805  Rel. Test L2 Loss :  0.1156901204586029  Test L2 Loss :  0.16811624884605408  inv_L_scale:  [1.0, 1.0]
Epoch :  63  Time:  0.765  Rel. Train L2 Loss :  0.1169662371608946  Rel. Test L2 Loss :  0.11577706098556519  Test L2 Loss :  0.16738978505134583  inv_L_scale:  [1.0, 1.0]
Epoch :  64  Time:  0.768  Rel. Train L2 Loss :  0.11654068013032277  Rel. Test L2 Loss :  0.11816827416419982  Test L2 Loss :  0.17073875427246094  inv_L_scale:  [1.0, 1.0]
Epoch :  65  Time:  0.763  Rel. Train L2 Loss :  0.11528569748004278  Rel. Test L2 Loss :  0.11538977295160294  Test L2 Loss :  0.16769710779190064  inv_L_scale:  [1.0, 1.0]
Epoch :  66  Time:  0.762  Rel. Train L2 Loss :  0.11719056063228184  Rel. Test L2 Loss :  0.11963567197322846  Test L2 Loss :  0.17253814160823822  inv_L_scale:  [1.0, 1.0]