Loading data from  ../../data/curve//pcno_curve_data_1_1_5_5_stokes.npz
(1000,) (1000, 1000, 1) (1000, 1000, 2)
use normalized raw measures
Casting to tensor
x_train shape torch.Size([900, 1000, 6]), y_train shape torch.Size([900, 1000, 1])
length of each dim:  tensor([6.6455335617065430, 6.6654777526855469])
kmax = 16
L = 14
geo_dims = [1, 2, 3, 4], num_grad = 3
In PCNO_train, ndims =  2
Epoch :  0  Time:  8.573  Rel. Train L2 Loss :  0.40766467048062216  Rel. Test L2 Loss :  0.23698784410953522  Test L2 Loss :  0.45002628803253175  inv_L_scale:  [1.0, 1.0]
Epoch :  1  Time:  0.901  Rel. Train L2 Loss :  0.1936886434753736  Rel. Test L2 Loss :  0.15162580847740173  Test L2 Loss :  0.28218623757362366  inv_L_scale:  [1.0, 1.0]
Epoch :  2  Time:  0.9  Rel. Train L2 Loss :  0.13782935718695322  Rel. Test L2 Loss :  0.12564933717250823  Test L2 Loss :  0.23258566617965698  inv_L_scale:  [1.0, 1.0]
Epoch :  3  Time:  0.899  Rel. Train L2 Loss :  0.11589758041832182  Rel. Test L2 Loss :  0.11254346579313278  Test L2 Loss :  0.21081603884696962  inv_L_scale:  [1.0, 1.0]
Epoch :  4  Time:  0.9  Rel. Train L2 Loss :  0.10310086601310306  Rel. Test L2 Loss :  0.09637015044689179  Test L2 Loss :  0.17567620396614075  inv_L_scale:  [1.0, 1.0]
Epoch :  5  Time:  0.899  Rel. Train L2 Loss :  0.0882833296722836  Rel. Test L2 Loss :  0.09485614389181136  Test L2 Loss :  0.1713167917728424  inv_L_scale:  [1.0, 1.0]
Epoch :  6  Time:  0.898  Rel. Train L2 Loss :  0.08351891590489281  Rel. Test L2 Loss :  0.083730309009552  Test L2 Loss :  0.15192365884780884  inv_L_scale:  [1.0, 1.0]
Epoch :  7  Time:  0.901  Rel. Train L2 Loss :  0.07777933458487193  Rel. Test L2 Loss :  0.08382016956806183  Test L2 Loss :  0.1511618834733963  inv_L_scale:  [1.0, 1.0]
Epoch :  8  Time:  0.898  Rel. Train L2 Loss :  0.0733756666051017  Rel. Test L2 Loss :  0.07968168795108795  Test L2 Loss :  0.14343134939670563  inv_L_scale:  [1.0, 1.0]
Epoch :  9  Time:  0.899  Rel. Train L2 Loss :  0.07004214826557371  Rel. Test L2 Loss :  0.07330317944288253  Test L2 Loss :  0.13243432402610777  inv_L_scale:  [1.0, 1.0]
Epoch :  10  Time:  0.902  Rel. Train L2 Loss :  0.06518532799349891  Rel. Test L2 Loss :  0.07265122264623641  Test L2 Loss :  0.1303132152557373  inv_L_scale:  [1.0, 1.0]
Epoch :  11  Time:  0.901  Rel. Train L2 Loss :  0.06479650060335795  Rel. Test L2 Loss :  0.06402340918779373  Test L2 Loss :  0.11689773768186569  inv_L_scale:  [1.0, 1.0]
Epoch :  12  Time:  0.899  Rel. Train L2 Loss :  0.06439253191153209  Rel. Test L2 Loss :  0.06555405393242836  Test L2 Loss :  0.11874102115631104  inv_L_scale:  [1.0, 1.0]
Epoch :  13  Time:  0.906  Rel. Train L2 Loss :  0.06163803178403113  Rel. Test L2 Loss :  0.057254340946674344  Test L2 Loss :  0.10451401591300964  inv_L_scale:  [1.0, 1.0]
Epoch :  14  Time:  0.899  Rel. Train L2 Loss :  0.05643520800603761  Rel. Test L2 Loss :  0.05950695499777794  Test L2 Loss :  0.1054772013425827  inv_L_scale:  [1.0, 1.0]
Epoch :  15  Time:  0.899  Rel. Train L2 Loss :  0.055341527693801455  Rel. Test L2 Loss :  0.058566330075263975  Test L2 Loss :  0.10522322595119477  inv_L_scale:  [1.0, 1.0]
Epoch :  16  Time:  0.904  Rel. Train L2 Loss :  0.05201127929819955  Rel. Test L2 Loss :  0.06225701078772545  Test L2 Loss :  0.1117072907090187  inv_L_scale:  [1.0, 1.0]
Epoch :  17  Time:  0.907  Rel. Train L2 Loss :  0.05524430212047365  Rel. Test L2 Loss :  0.05689755067229271  Test L2 Loss :  0.10158426612615586  inv_L_scale:  [1.0, 1.0]
Epoch :  18  Time:  0.906  Rel. Train L2 Loss :  0.0506076521674792  Rel. Test L2 Loss :  0.05169713824987412  Test L2 Loss :  0.09450070202350616  inv_L_scale:  [1.0, 1.0]
Epoch :  19  Time:  0.908  Rel. Train L2 Loss :  0.05109631761908531  Rel. Test L2 Loss :  0.05702650919556618  Test L2 Loss :  0.1051326858997345  inv_L_scale:  [1.0, 1.0]
Epoch :  20  Time:  0.907  Rel. Train L2 Loss :  0.04857913606696659  Rel. Test L2 Loss :  0.055774037837982175  Test L2 Loss :  0.09962321281433105  inv_L_scale:  [1.0, 1.0]
Epoch :  21  Time:  0.907  Rel. Train L2 Loss :  0.04845979806449678  Rel. Test L2 Loss :  0.05856752023100853  Test L2 Loss :  0.10422758042812347  inv_L_scale:  [1.0, 1.0]
Epoch :  22  Time:  0.908  Rel. Train L2 Loss :  0.04786426150136524  Rel. Test L2 Loss :  0.04832653403282165  Test L2 Loss :  0.08724758803844451  inv_L_scale:  [1.0, 1.0]
Epoch :  23  Time:  0.908  Rel. Train L2 Loss :  0.046380776315927505  Rel. Test L2 Loss :  0.05563823431730271  Test L2 Loss :  0.09967307925224304  inv_L_scale:  [1.0, 1.0]
Epoch :  24  Time:  0.906  Rel. Train L2 Loss :  0.04576048908962144  Rel. Test L2 Loss :  0.05031165197491646  Test L2 Loss :  0.08989089012145995  inv_L_scale:  [1.0, 1.0]
Epoch :  25  Time:  0.907  Rel. Train L2 Loss :  0.046335027979479894  Rel. Test L2 Loss :  0.05002985864877701  Test L2 Loss :  0.08861489236354828  inv_L_scale:  [1.0, 1.0]
Epoch :  26  Time:  0.906  Rel. Train L2 Loss :  0.04615345969796181  Rel. Test L2 Loss :  0.04660655796527863  Test L2 Loss :  0.08459386229515076  inv_L_scale:  [1.0, 1.0]
Epoch :  27  Time:  0.906  Rel. Train L2 Loss :  0.04497894974218475  Rel. Test L2 Loss :  0.04973840177059174  Test L2 Loss :  0.08874407202005387  inv_L_scale:  [1.0, 1.0]
Epoch :  28  Time:  0.907  Rel. Train L2 Loss :  0.04418120957083172  Rel. Test L2 Loss :  0.046991399675607684  Test L2 Loss :  0.08459403872489929  inv_L_scale:  [1.0, 1.0]
Epoch :  29  Time:  0.907  Rel. Train L2 Loss :  0.04311230128010114  Rel. Test L2 Loss :  0.044769892543554304  Test L2 Loss :  0.07949052095413207  inv_L_scale:  [1.0, 1.0]
Epoch :  30  Time:  0.907  Rel. Train L2 Loss :  0.046404518667194576  Rel. Test L2 Loss :  0.05055491253733635  Test L2 Loss :  0.09038128197193146  inv_L_scale:  [1.0, 1.0]
Epoch :  31  Time:  0.906  Rel. Train L2 Loss :  0.044280069727036686  Rel. Test L2 Loss :  0.0454178050160408  Test L2 Loss :  0.07974818050861358  inv_L_scale:  [1.0, 1.0]
Epoch :  32  Time:  0.908  Rel. Train L2 Loss :  0.0435651275018851  Rel. Test L2 Loss :  0.042699435502290724  Test L2 Loss :  0.07675605237483979  inv_L_scale:  [1.0, 1.0]
Epoch :  33  Time:  0.907  Rel. Train L2 Loss :  0.04276536552442445  Rel. Test L2 Loss :  0.051531142592430114  Test L2 Loss :  0.0922983631491661  inv_L_scale:  [1.0, 1.0]
Epoch :  34  Time:  0.907  Rel. Train L2 Loss :  0.04407986720403036  Rel. Test L2 Loss :  0.050240894705057146  Test L2 Loss :  0.09192773103713989  inv_L_scale:  [1.0, 1.0]
Epoch :  35  Time:  0.907  Rel. Train L2 Loss :  0.042154238439268535  Rel. Test L2 Loss :  0.051659244149923324  Test L2 Loss :  0.09218252807855606  inv_L_scale:  [1.0, 1.0]
Epoch :  36  Time:  0.907  Rel. Train L2 Loss :  0.043061083008845646  Rel. Test L2 Loss :  0.041100150048732756  Test L2 Loss :  0.07350081652402878  inv_L_scale:  [1.0, 1.0]
Epoch :  37  Time:  0.909  Rel. Train L2 Loss :  0.03989818516704771  Rel. Test L2 Loss :  0.04421805575489998  Test L2 Loss :  0.0791304075717926  inv_L_scale:  [1.0, 1.0]
Epoch :  38  Time:  0.908  Rel. Train L2 Loss :  0.04226631707615323  Rel. Test L2 Loss :  0.049246071428060534  Test L2 Loss :  0.0882276377081871  inv_L_scale:  [1.0, 1.0]
Epoch :  39  Time:  0.907  Rel. Train L2 Loss :  0.039868414998054505  Rel. Test L2 Loss :  0.05379722952842712  Test L2 Loss :  0.1016607928276062  inv_L_scale:  [1.0, 1.0]
Epoch :  40  Time:  0.907  Rel. Train L2 Loss :  0.04108633562922478  Rel. Test L2 Loss :  0.04296486794948578  Test L2 Loss :  0.0770272397994995  inv_L_scale:  [1.0, 1.0]
Epoch :  41  Time:  0.907  Rel. Train L2 Loss :  0.039814035362667505  Rel. Test L2 Loss :  0.0439057195186615  Test L2 Loss :  0.07771349400281906  inv_L_scale:  [1.0, 1.0]
Epoch :  42  Time:  0.906  Rel. Train L2 Loss :  0.03962736477454503  Rel. Test L2 Loss :  0.04290287286043167  Test L2 Loss :  0.0757401517033577  inv_L_scale:  [1.0, 1.0]
Epoch :  43  Time:  0.907  Rel. Train L2 Loss :  0.041238777024878395  Rel. Test L2 Loss :  0.04187301084399223  Test L2 Loss :  0.07494793713092804  inv_L_scale:  [1.0, 1.0]
Epoch :  44  Time:  0.906  Rel. Train L2 Loss :  0.04012659817934036  Rel. Test L2 Loss :  0.044385134130716326  Test L2 Loss :  0.07896059095859527  inv_L_scale:  [1.0, 1.0]
Epoch :  45  Time:  0.907  Rel. Train L2 Loss :  0.03932792103952832  Rel. Test L2 Loss :  0.04580936908721924  Test L2 Loss :  0.08324247181415557  inv_L_scale:  [1.0, 1.0]
Epoch :  46  Time:  0.907  Rel. Train L2 Loss :  0.039211126483149  Rel. Test L2 Loss :  0.04419286698102951  Test L2 Loss :  0.08062049508094787  inv_L_scale:  [1.0, 1.0]
Epoch :  47  Time:  0.907  Rel. Train L2 Loss :  0.038448933843109344  Rel. Test L2 Loss :  0.04595326706767082  Test L2 Loss :  0.08222867250442505  inv_L_scale:  [1.0, 1.0]
Epoch :  48  Time:  0.906  Rel. Train L2 Loss :  0.03819444098406368  Rel. Test L2 Loss :  0.03811708360910416  Test L2 Loss :  0.06841185808181763  inv_L_scale:  [1.0, 1.0]
Epoch :  49  Time:  0.907  Rel. Train L2 Loss :  0.037038873665862615  Rel. Test L2 Loss :  0.04503951177001  Test L2 Loss :  0.08304538011550903  inv_L_scale:  [1.0, 1.0]
Epoch :  50  Time:  0.907  Rel. Train L2 Loss :  0.039973562442594104  Rel. Test L2 Loss :  0.040335765033960344  Test L2 Loss :  0.07233701407909393  inv_L_scale:  [1.0, 1.0]
Epoch :  51  Time:  0.906  Rel. Train L2 Loss :  0.03794455097781287  Rel. Test L2 Loss :  0.04188280194997787  Test L2 Loss :  0.07504661500453949  inv_L_scale:  [1.0, 1.0]
Epoch :  52  Time:  0.906  Rel. Train L2 Loss :  0.036168873376316496  Rel. Test L2 Loss :  0.03626367151737213  Test L2 Loss :  0.06411738067865372  inv_L_scale:  [1.0, 1.0]
Epoch :  53  Time:  0.909  Rel. Train L2 Loss :  0.035240162875917226  Rel. Test L2 Loss :  0.04211031123995781  Test L2 Loss :  0.07545865714550018  inv_L_scale:  [1.0, 1.0]
Epoch :  54  Time:  0.906  Rel. Train L2 Loss :  0.03778585101167361  Rel. Test L2 Loss :  0.052694956064224245  Test L2 Loss :  0.09867482274770736  inv_L_scale:  [1.0, 1.0]
Epoch :  55  Time:  0.907  Rel. Train L2 Loss :  0.03697380801869763  Rel. Test L2 Loss :  0.039288710653781894  Test L2 Loss :  0.07058705568313599  inv_L_scale:  [1.0, 1.0]
Epoch :  56  Time:  0.905  Rel. Train L2 Loss :  0.03510159437855085  Rel. Test L2 Loss :  0.03817552193999291  Test L2 Loss :  0.06847451239824295  inv_L_scale:  [1.0, 1.0]
Epoch :  57  Time:  0.906  Rel. Train L2 Loss :  0.03625579718914297  Rel. Test L2 Loss :  0.043251537680625916  Test L2 Loss :  0.07681840181350708  inv_L_scale:  [1.0, 1.0]
Epoch :  58  Time:  0.906  Rel. Train L2 Loss :  0.036740222076574965  Rel. Test L2 Loss :  0.04329907983541489  Test L2 Loss :  0.07795853435993194  inv_L_scale:  [1.0, 1.0]
Epoch :  59  Time:  0.907  Rel. Train L2 Loss :  0.0359559123383628  Rel. Test L2 Loss :  0.03735885471105575  Test L2 Loss :  0.06683008283376694  inv_L_scale:  [1.0, 1.0]
Epoch :  60  Time:  0.906  Rel. Train L2 Loss :  0.034502115233076946  Rel. Test L2 Loss :  0.038969734609127046  Test L2 Loss :  0.0698041957616806  inv_L_scale:  [1.0, 1.0]
Epoch :  61  Time:  0.906  Rel. Train L2 Loss :  0.03592046704557207  Rel. Test L2 Loss :  0.03971936166286469  Test L2 Loss :  0.07118347942829133  inv_L_scale:  [1.0, 1.0]
Epoch :  62  Time:  0.906  Rel. Train L2 Loss :  0.036668439226018056  Rel. Test L2 Loss :  0.03999304324388504  Test L2 Loss :  0.07214262694120407  inv_L_scale:  [1.0, 1.0]
Epoch :  63  Time:  0.906  Rel. Train L2 Loss :  0.03531771587000953  Rel. Test L2 Loss :  0.04105776816606522  Test L2 Loss :  0.07463563174009323  inv_L_scale:  [1.0, 1.0]
Epoch :  64  Time:  0.907  Rel. Train L2 Loss :  0.03598205493556129  Rel. Test L2 Loss :  0.04032001584768295  Test L2 Loss :  0.07214820921421052  inv_L_scale:  [1.0, 1.0]
Epoch :  65  Time:  0.906  Rel. Train L2 Loss :  0.03479228029648463  Rel. Test L2 Loss :  0.03851457804441452  Test L2 Loss :  0.06880295127630234  inv_L_scale:  [1.0, 1.0]
Epoch :  66  Time:  0.906  Rel. Train L2 Loss :  0.034855108890268535  Rel. Test L2 Loss :  0.042693100720644  Test L2 Loss :  0.07756892055273056  inv_L_scale:  [1.0, 1.0]
Epoch :  67  Time:  0.906  Rel. Train L2 Loss :  0.03560923147532675  Rel. Test L2 Loss :  0.038668734282255174  Test L2 Loss :  0.06956882327795029  inv_L_scale:  [1.0, 1.0]
Epoch :  68  Time:  0.906  Rel. Train L2 Loss :  0.035453395065334105  Rel. Test L2 Loss :  0.03659962445497513  Test L2 Loss :  0.06476358413696288  inv_L_scale:  [1.0, 1.0]
Epoch :  69  Time:  0.908  Rel. Train L2 Loss :  0.03331911770833863  Rel. Test L2 Loss :  0.035997026711702344  Test L2 Loss :  0.06525270253419876  inv_L_scale:  [1.0, 1.0]
Epoch :  70  Time:  0.907  Rel. Train L2 Loss :  0.03365463454690244  Rel. Test L2 Loss :  0.03467815227806568  Test L2 Loss :  0.06185576409101486  inv_L_scale:  [1.0, 1.0]
Epoch :  71  Time:  0.906  Rel. Train L2 Loss :  0.03346920995248689  Rel. Test L2 Loss :  0.0313508702814579  Test L2 Loss :  0.055974520444869995  inv_L_scale:  [1.0, 1.0]
Epoch :  72  Time:  0.906  Rel. Train L2 Loss :  0.03358387478523784  Rel. Test L2 Loss :  0.036188082695007326  Test L2 Loss :  0.06455082446336746  inv_L_scale:  [1.0, 1.0]
Epoch :  73  Time:  0.906  Rel. Train L2 Loss :  0.033873012802667087  Rel. Test L2 Loss :  0.03727227449417114  Test L2 Loss :  0.06582711040973663  inv_L_scale:  [1.0, 1.0]
Epoch :  74  Time:  0.906  Rel. Train L2 Loss :  0.03346114754676819  Rel. Test L2 Loss :  0.034404625445604325  Test L2 Loss :  0.061293698251247405  inv_L_scale:  [1.0, 1.0]
Epoch :  75  Time:  0.909  Rel. Train L2 Loss :  0.03261511216560999  Rel. Test L2 Loss :  0.034483449757099154  Test L2 Loss :  0.061584266722202304  inv_L_scale:  [1.0, 1.0]
Epoch :  76  Time:  0.907  Rel. Train L2 Loss :  0.03280700250632233  Rel. Test L2 Loss :  0.03577162876725197  Test L2 Loss :  0.06382375836372375  inv_L_scale:  [1.0, 1.0]
Epoch :  77  Time:  0.906  Rel. Train L2 Loss :  0.031709239234526954  Rel. Test L2 Loss :  0.031061678379774093  Test L2 Loss :  0.055355294495821  inv_L_scale:  [1.0, 1.0]
Epoch :  78  Time:  0.906  Rel. Train L2 Loss :  0.03170200965470738  Rel. Test L2 Loss :  0.03785345524549484  Test L2 Loss :  0.06832278609275817  inv_L_scale:  [1.0, 1.0]
Epoch :  79  Time:  0.906  Rel. Train L2 Loss :  0.03186304041081005  Rel. Test L2 Loss :  0.03384680055081844  Test L2 Loss :  0.060402173399925235  inv_L_scale:  [1.0, 1.0]
Epoch :  80  Time:  0.906  Rel. Train L2 Loss :  0.03224983753429519  Rel. Test L2 Loss :  0.031664905920624736  Test L2 Loss :  0.05647258073091507  inv_L_scale:  [1.0, 1.0]
Epoch :  81  Time:  0.907  Rel. Train L2 Loss :  0.03148669284251001  Rel. Test L2 Loss :  0.03835176900029182  Test L2 Loss :  0.06831187665462495  inv_L_scale:  [1.0, 1.0]
Epoch :  82  Time:  0.907  Rel. Train L2 Loss :  0.03206434489952193  Rel. Test L2 Loss :  0.031292745918035506  Test L2 Loss :  0.05553228437900543  inv_L_scale:  [1.0, 1.0]
Epoch :  83  Time:  0.906  Rel. Train L2 Loss :  0.03069198171297709  Rel. Test L2 Loss :  0.03006989397108555  Test L2 Loss :  0.05348199635744095  inv_L_scale:  [1.0, 1.0]
Epoch :  84  Time:  0.906  Rel. Train L2 Loss :  0.030943204760551454  Rel. Test L2 Loss :  0.03241769894957543  Test L2 Loss :  0.058022972643375394  inv_L_scale:  [1.0, 1.0]
Epoch :  85  Time:  0.906  Rel. Train L2 Loss :  0.03186040707760387  Rel. Test L2 Loss :  0.032394368350505826  Test L2 Loss :  0.05763739079236984  inv_L_scale:  [1.0, 1.0]
Epoch :  86  Time:  0.907  Rel. Train L2 Loss :  0.03101313480072551  Rel. Test L2 Loss :  0.032019814774394036  Test L2 Loss :  0.05673867389559746  inv_L_scale:  [1.0, 1.0]
Epoch :  87  Time:  0.907  Rel. Train L2 Loss :  0.03034313165479236  Rel. Test L2 Loss :  0.032166363447904585  Test L2 Loss :  0.05722981154918671  inv_L_scale:  [1.0, 1.0]
Epoch :  88  Time:  0.906  Rel. Train L2 Loss :  0.030626687515113087  Rel. Test L2 Loss :  0.03134297743439674  Test L2 Loss :  0.05545433506369591  inv_L_scale:  [1.0, 1.0]
Epoch :  89  Time:  0.906  Rel. Train L2 Loss :  0.02931245904829767  Rel. Test L2 Loss :  0.034495800137519836  Test L2 Loss :  0.060975682139396664  inv_L_scale:  [1.0, 1.0]
Epoch :  90  Time:  0.907  Rel. Train L2 Loss :  0.029991110348039203  Rel. Test L2 Loss :  0.03144720681011677  Test L2 Loss :  0.0561046239733696  inv_L_scale:  [1.0, 1.0]
Epoch :  91  Time:  0.906  Rel. Train L2 Loss :  0.02988772105011675  Rel. Test L2 Loss :  0.03484787352383137  Test L2 Loss :  0.06211287349462509  inv_L_scale:  [1.0, 1.0]
Epoch :  92  Time:  0.906  Rel. Train L2 Loss :  0.03018634494807985  Rel. Test L2 Loss :  0.03090869337320328  Test L2 Loss :  0.05502084046602249  inv_L_scale:  [1.0, 1.0]
Epoch :  93  Time:  0.908  Rel. Train L2 Loss :  0.029797423912419213  Rel. Test L2 Loss :  0.029699650257825852  Test L2 Loss :  0.05277029499411583  inv_L_scale:  [1.0, 1.0]
Epoch :  94  Time:  0.907  Rel. Train L2 Loss :  0.027648292846149867  Rel. Test L2 Loss :  0.03330044507980347  Test L2 Loss :  0.060293152928352356  inv_L_scale:  [1.0, 1.0]
Epoch :  95  Time:  0.907  Rel. Train L2 Loss :  0.029145638636416858  Rel. Test L2 Loss :  0.03136963531374931  Test L2 Loss :  0.05534491032361984  inv_L_scale:  [1.0, 1.0]
Epoch :  96  Time:  0.906  Rel. Train L2 Loss :  0.029219882637262343  Rel. Test L2 Loss :  0.030834472328424452  Test L2 Loss :  0.05485511392354965  inv_L_scale:  [1.0, 1.0]
Epoch :  97  Time:  0.906  Rel. Train L2 Loss :  0.02863790451652474  Rel. Test L2 Loss :  0.030033760294318198  Test L2 Loss :  0.053419051319360734  inv_L_scale:  [1.0, 1.0]
Epoch :  98  Time:  0.909  Rel. Train L2 Loss :  0.028682369200719728  Rel. Test L2 Loss :  0.034291976541280744  Test L2 Loss :  0.06061554983258247  inv_L_scale:  [1.0, 1.0]
Epoch :  99  Time:  0.908  Rel. Train L2 Loss :  0.03024215680029657  Rel. Test L2 Loss :  0.02853995084762573  Test L2 Loss :  0.05093342125415802  inv_L_scale:  [1.0, 1.0]
Epoch :  100  Time:  0.906  Rel. Train L2 Loss :  0.027617103556791943  Rel. Test L2 Loss :  0.028218923434615135  Test L2 Loss :  0.05032754451036453  inv_L_scale:  [1.0, 1.0]
Epoch :  101  Time:  0.906  Rel. Train L2 Loss :  0.028309024622042975  Rel. Test L2 Loss :  0.04170980393886566  Test L2 Loss :  0.07806825160980224  inv_L_scale:  [1.0, 1.0]
Epoch :  102  Time:  0.906  Rel. Train L2 Loss :  0.02913035508659151  Rel. Test L2 Loss :  0.039052014499902726  Test L2 Loss :  0.0715386700630188  inv_L_scale:  [1.0, 1.0]
Epoch :  103  Time:  0.905  Rel. Train L2 Loss :  0.02888283019264539  Rel. Test L2 Loss :  0.03408833235502243  Test L2 Loss :  0.060939607620239256  inv_L_scale:  [1.0, 1.0]
Epoch :  104  Time:  0.906  Rel. Train L2 Loss :  0.028154788464307787  Rel. Test L2 Loss :  0.03084545835852623  Test L2 Loss :  0.055245384424924854  inv_L_scale:  [1.0, 1.0]
Epoch :  105  Time:  0.905  Rel. Train L2 Loss :  0.027056946903467178  Rel. Test L2 Loss :  0.02920796535909176  Test L2 Loss :  0.05225203543901444  inv_L_scale:  [1.0, 1.0]
Epoch :  106  Time:  0.906  Rel. Train L2 Loss :  0.02715158525440428  Rel. Test L2 Loss :  0.028576456606388093  Test L2 Loss :  0.05100487947463989  inv_L_scale:  [1.0, 1.0]
Epoch :  107  Time:  0.906  Rel. Train L2 Loss :  0.027157934092813068  Rel. Test L2 Loss :  0.03212250590324402  Test L2 Loss :  0.05771999657154083  inv_L_scale:  [1.0, 1.0]
Epoch :  108  Time:  0.905  Rel. Train L2 Loss :  0.02769574887222714  Rel. Test L2 Loss :  0.029628908187150957  Test L2 Loss :  0.05291244611144066  inv_L_scale:  [1.0, 1.0]
Epoch :  109  Time:  0.906  Rel. Train L2 Loss :  0.027206312716007233  Rel. Test L2 Loss :  0.029035148322582246  Test L2 Loss :  0.051326328814029695  inv_L_scale:  [1.0, 1.0]
Epoch :  110  Time:  0.905  Rel. Train L2 Loss :  0.028120791531271404  Rel. Test L2 Loss :  0.02907197743654251  Test L2 Loss :  0.05165034607052803  inv_L_scale:  [1.0, 1.0]
Epoch :  111  Time:  0.906  Rel. Train L2 Loss :  0.026650177356269626  Rel. Test L2 Loss :  0.03166273854672909  Test L2 Loss :  0.05579061135649681  inv_L_scale:  [1.0, 1.0]
Epoch :  112  Time:  0.906  Rel. Train L2 Loss :  0.02866011670894093  Rel. Test L2 Loss :  0.026445185169577598  Test L2 Loss :  0.047307896465063094  inv_L_scale:  [1.0, 1.0]
Epoch :  113  Time:  0.905  Rel. Train L2 Loss :  0.02644108100897736  Rel. Test L2 Loss :  0.030976300910115242  Test L2 Loss :  0.054324376285076144  inv_L_scale:  [1.0, 1.0]
Epoch :  114  Time:  0.906  Rel. Train L2 Loss :  0.02617877263161871  Rel. Test L2 Loss :  0.0278593809902668  Test L2 Loss :  0.049653981328010556  inv_L_scale:  [1.0, 1.0]
Epoch :  115  Time:  0.906  Rel. Train L2 Loss :  0.026600418637196224  Rel. Test L2 Loss :  0.02888435646891594  Test L2 Loss :  0.05100624352693558  inv_L_scale:  [1.0, 1.0]
Epoch :  116  Time:  0.906  Rel. Train L2 Loss :  0.026530439390076533  Rel. Test L2 Loss :  0.026455104425549505  Test L2 Loss :  0.046904800832271575  inv_L_scale:  [1.0, 1.0]
Epoch :  117  Time:  0.905  Rel. Train L2 Loss :  0.026564821385675008  Rel. Test L2 Loss :  0.033985197618603705  Test L2 Loss :  0.06216882318258286  inv_L_scale:  [1.0, 1.0]
Epoch :  118  Time:  0.905  Rel. Train L2 Loss :  0.027248404936658012  Rel. Test L2 Loss :  0.027704989016056062  Test L2 Loss :  0.04993913680315018  inv_L_scale:  [1.0, 1.0]
Epoch :  119  Time:  0.908  Rel. Train L2 Loss :  0.026756180889076657  Rel. Test L2 Loss :  0.028364486172795297  Test L2 Loss :  0.05000658512115479  inv_L_scale:  [1.0, 1.0]
Epoch :  120  Time:  0.906  Rel. Train L2 Loss :  0.02677080690032906  Rel. Test L2 Loss :  0.028225895315408707  Test L2 Loss :  0.05057060569524765  inv_L_scale:  [1.0, 1.0]
Epoch :  121  Time:  0.906  Rel. Train L2 Loss :  0.026841863832539982  Rel. Test L2 Loss :  0.026573069021105768  Test L2 Loss :  0.046954024434089664  inv_L_scale:  [1.0, 1.0]
Epoch :  122  Time:  0.906  Rel. Train L2 Loss :  0.025527848336431715  Rel. Test L2 Loss :  0.0290118607878685  Test L2 Loss :  0.05129749566316605  inv_L_scale:  [1.0, 1.0]
Epoch :  123  Time:  0.906  Rel. Train L2 Loss :  0.025486831275953185  Rel. Test L2 Loss :  0.027025964856147767  Test L2 Loss :  0.04805138379335403  inv_L_scale:  [1.0, 1.0]
Epoch :  124  Time:  0.906  Rel. Train L2 Loss :  0.02557187491820918  Rel. Test L2 Loss :  0.02605677880346775  Test L2 Loss :  0.04621854394674301  inv_L_scale:  [1.0, 1.0]
Epoch :  125  Time:  0.906  Rel. Train L2 Loss :  0.02521694030198786  Rel. Test L2 Loss :  0.02714553028345108  Test L2 Loss :  0.04825355052947998  inv_L_scale:  [1.0, 1.0]
Epoch :  126  Time:  0.906  Rel. Train L2 Loss :  0.02534720268514421  Rel. Test L2 Loss :  0.028359054923057556  Test L2 Loss :  0.050052206814289096  inv_L_scale:  [1.0, 1.0]
Epoch :  127  Time:  0.91  Rel. Train L2 Loss :  0.026391166829400594  Rel. Test L2 Loss :  0.026752076223492623  Test L2 Loss :  0.04710248798131943  inv_L_scale:  [1.0, 1.0]
Epoch :  128  Time:  0.906  Rel. Train L2 Loss :  0.02593704417347908  Rel. Test L2 Loss :  0.025579060316085814  Test L2 Loss :  0.045341459065675736  inv_L_scale:  [1.0, 1.0]
Epoch :  129  Time:  0.906  Rel. Train L2 Loss :  0.025870118356413313  Rel. Test L2 Loss :  0.026296701207756998  Test L2 Loss :  0.04637330770492554  inv_L_scale:  [1.0, 1.0]
Epoch :  130  Time:  0.906  Rel. Train L2 Loss :  0.025150602319174344  Rel. Test L2 Loss :  0.0296307235956192  Test L2 Loss :  0.05276412695646286  inv_L_scale:  [1.0, 1.0]
Epoch :  131  Time:  0.906  Rel. Train L2 Loss :  0.024947685897350313  Rel. Test L2 Loss :  0.02738147020339966  Test L2 Loss :  0.049043953716754914  inv_L_scale:  [1.0, 1.0]
Epoch :  132  Time:  0.906  Rel. Train L2 Loss :  0.024857136540942723  Rel. Test L2 Loss :  0.031700109988451006  Test L2 Loss :  0.05747491776943207  inv_L_scale:  [1.0, 1.0]
Epoch :  133  Time:  0.906  Rel. Train L2 Loss :  0.02517294001248148  Rel. Test L2 Loss :  0.027806274145841598  Test L2 Loss :  0.05001122742891312  inv_L_scale:  [1.0, 1.0]
Epoch :  134  Time:  0.907  Rel. Train L2 Loss :  0.024308217697673374  Rel. Test L2 Loss :  0.02581044226884842  Test L2 Loss :  0.04565981686115265  inv_L_scale:  [1.0, 1.0]
Epoch :  135  Time:  0.906  Rel. Train L2 Loss :  0.02480171642369694  Rel. Test L2 Loss :  0.026097917556762697  Test L2 Loss :  0.04644757583737373  inv_L_scale:  [1.0, 1.0]
Epoch :  136  Time:  0.906  Rel. Train L2 Loss :  0.024486949576271906  Rel. Test L2 Loss :  0.024362548738718032  Test L2 Loss :  0.043324940055608746  inv_L_scale:  [1.0, 1.0]
Epoch :  137  Time:  0.903  Rel. Train L2 Loss :  0.02440777092344231  Rel. Test L2 Loss :  0.023659679889678955  Test L2 Loss :  0.041904641687870024  inv_L_scale:  [1.0, 1.0]
Epoch :  138  Time:  0.898  Rel. Train L2 Loss :  0.024362707419527903  Rel. Test L2 Loss :  0.03051444694399834  Test L2 Loss :  0.05516967967152595  inv_L_scale:  [1.0, 1.0]
Epoch :  139  Time:  0.899  Rel. Train L2 Loss :  0.024537176357375252  Rel. Test L2 Loss :  0.025967147424817084  Test L2 Loss :  0.046071737110614776  inv_L_scale:  [1.0, 1.0]
Epoch :  140  Time:  0.899  Rel. Train L2 Loss :  0.02459260112709469  Rel. Test L2 Loss :  0.026776715964078903  Test L2 Loss :  0.04753755047917366  inv_L_scale:  [1.0, 1.0]
Epoch :  141  Time:  0.898  Rel. Train L2 Loss :  0.02455541431903839  Rel. Test L2 Loss :  0.029312781468033792  Test L2 Loss :  0.05160000741481781  inv_L_scale:  [1.0, 1.0]
Epoch :  142  Time:  0.9  Rel. Train L2 Loss :  0.02515630313091808  Rel. Test L2 Loss :  0.028043408989906312  Test L2 Loss :  0.0495229272544384  inv_L_scale:  [1.0, 1.0]
Epoch :  143  Time:  0.899  Rel. Train L2 Loss :  0.02428682146800889  Rel. Test L2 Loss :  0.025161067098379133  Test L2 Loss :  0.044568265825510024  inv_L_scale:  [1.0, 1.0]
Epoch :  144  Time:  0.899  Rel. Train L2 Loss :  0.024647450066275067  Rel. Test L2 Loss :  0.025029779374599458  Test L2 Loss :  0.04390580102801323  inv_L_scale:  [1.0, 1.0]
Epoch :  145  Time:  0.898  Rel. Train L2 Loss :  0.024622809638579688  Rel. Test L2 Loss :  0.02628785640001297  Test L2 Loss :  0.0461510169506073  inv_L_scale:  [1.0, 1.0]
Epoch :  146  Time:  0.898  Rel. Train L2 Loss :  0.024392311606142254  Rel. Test L2 Loss :  0.02877780705690384  Test L2 Loss :  0.05147811144590378  inv_L_scale:  [1.0, 1.0]
Epoch :  147  Time:  0.899  Rel. Train L2 Loss :  0.02457326556245486  Rel. Test L2 Loss :  0.026144286841154097  Test L2 Loss :  0.04690310001373291  inv_L_scale:  [1.0, 1.0]
Epoch :  148  Time:  0.898  Rel. Train L2 Loss :  0.023939225955141915  Rel. Test L2 Loss :  0.024481303244829177  Test L2 Loss :  0.043195631504058835  inv_L_scale:  [1.0, 1.0]
Epoch :  149  Time:  0.899  Rel. Train L2 Loss :  0.02460209720664554  Rel. Test L2 Loss :  0.02458176389336586  Test L2 Loss :  0.04353037357330322  inv_L_scale:  [1.0, 1.0]
Epoch :  150  Time:  0.9  Rel. Train L2 Loss :  0.02392438606255584  Rel. Test L2 Loss :  0.030469352453947066  Test L2 Loss :  0.05375491932034492  inv_L_scale:  [1.0, 1.0]
Epoch :  151  Time:  0.9  Rel. Train L2 Loss :  0.02415336770315965  Rel. Test L2 Loss :  0.02651398316025734  Test L2 Loss :  0.04598674491047859  inv_L_scale:  [1.0, 1.0]
Epoch :  152  Time:  0.899  Rel. Train L2 Loss :  0.024724967992968028  Rel. Test L2 Loss :  0.024618966430425646  Test L2 Loss :  0.043271770626306535  inv_L_scale:  [1.0, 1.0]
Epoch :  153  Time:  0.898  Rel. Train L2 Loss :  0.024109761863946914  Rel. Test L2 Loss :  0.025979501456022264  Test L2 Loss :  0.045749502331018446  inv_L_scale:  [1.0, 1.0]
Epoch :  154  Time:  0.898  Rel. Train L2 Loss :  0.023565614455276065  Rel. Test L2 Loss :  0.02756498761475086  Test L2 Loss :  0.049149971604347226  inv_L_scale:  [1.0, 1.0]
Epoch :  155  Time:  0.899  Rel. Train L2 Loss :  0.023774631495277088  Rel. Test L2 Loss :  0.024556419998407363  Test L2 Loss :  0.04352440699934959  inv_L_scale:  [1.0, 1.0]
Epoch :  156  Time:  0.898  Rel. Train L2 Loss :  0.022831077559126747  Rel. Test L2 Loss :  0.023268369808793068  Test L2 Loss :  0.04084135100245476  inv_L_scale:  [1.0, 1.0]
Epoch :  157  Time:  0.899  Rel. Train L2 Loss :  0.022966854265994496  Rel. Test L2 Loss :  0.024316339045763014  Test L2 Loss :  0.04263804748654366  inv_L_scale:  [1.0, 1.0]
Epoch :  158  Time:  0.898  Rel. Train L2 Loss :  0.022977391481399535  Rel. Test L2 Loss :  0.024559924900531768  Test L2 Loss :  0.04352509111166  inv_L_scale:  [1.0, 1.0]
Epoch :  159  Time:  0.901  Rel. Train L2 Loss :  0.02301129659016927  Rel. Test L2 Loss :  0.02313455954194069  Test L2 Loss :  0.0403961718082428  inv_L_scale:  [1.0, 1.0]
Epoch :  160  Time:  0.9  Rel. Train L2 Loss :  0.023038735356595782  Rel. Test L2 Loss :  0.02615132346749306  Test L2 Loss :  0.046037576496601104  inv_L_scale:  [1.0, 1.0]
Epoch :  161  Time:  0.899  Rel. Train L2 Loss :  0.023230098717742495  Rel. Test L2 Loss :  0.02714941293001175  Test L2 Loss :  0.04812790781259537  inv_L_scale:  [1.0, 1.0]
Epoch :  162  Time:  0.898  Rel. Train L2 Loss :  0.023795248924030198  Rel. Test L2 Loss :  0.028213040456175804  Test L2 Loss :  0.05000900804996491  inv_L_scale:  [1.0, 1.0]
Epoch :  163  Time:  0.899  Rel. Train L2 Loss :  0.02370025500655174  Rel. Test L2 Loss :  0.024658801555633544  Test L2 Loss :  0.043554390966892245  inv_L_scale:  [1.0, 1.0]
Epoch :  164  Time:  0.899  Rel. Train L2 Loss :  0.024082223574320476  Rel. Test L2 Loss :  0.025255895555019378  Test L2 Loss :  0.04477425664663315  inv_L_scale:  [1.0, 1.0]
Epoch :  165  Time:  0.899  Rel. Train L2 Loss :  0.023316290693150627  Rel. Test L2 Loss :  0.0246235890686512  Test L2 Loss :  0.04337018966674805  inv_L_scale:  [1.0, 1.0]
Epoch :  166  Time:  0.898  Rel. Train L2 Loss :  0.02350777707166142  Rel. Test L2 Loss :  0.024387440979480743  Test L2 Loss :  0.04300779432058335  inv_L_scale:  [1.0, 1.0]
Epoch :  167  Time:  0.898  Rel. Train L2 Loss :  0.02307009374101957  Rel. Test L2 Loss :  0.02386098638176918  Test L2 Loss :  0.04181460440158844  inv_L_scale:  [1.0, 1.0]
Epoch :  168  Time:  0.899  Rel. Train L2 Loss :  0.022567457126246557  Rel. Test L2 Loss :  0.02344501659274101  Test L2 Loss :  0.04149824231863022  inv_L_scale:  [1.0, 1.0]
Epoch :  169  Time:  0.899  Rel. Train L2 Loss :  0.02282948239809937  Rel. Test L2 Loss :  0.024670171067118645  Test L2 Loss :  0.043609794974327085  inv_L_scale:  [1.0, 1.0]
Epoch :  170  Time:  0.899  Rel. Train L2 Loss :  0.023759858533740044  Rel. Test L2 Loss :  0.023111810684204103  Test L2 Loss :  0.040802500545978546  inv_L_scale:  [1.0, 1.0]
Epoch :  171  Time:  0.898  Rel. Train L2 Loss :  0.02330739218327734  Rel. Test L2 Loss :  0.02510194107890129  Test L2 Loss :  0.044647061824798585  inv_L_scale:  [1.0, 1.0]
Epoch :  172  Time:  0.899  Rel. Train L2 Loss :  0.02279845195511977  Rel. Test L2 Loss :  0.024101120010018347  Test L2 Loss :  0.042706279903650286  inv_L_scale:  [1.0, 1.0]
Epoch :  173  Time:  0.898  Rel. Train L2 Loss :  0.0226466815918684  Rel. Test L2 Loss :  0.023435998558998108  Test L2 Loss :  0.041579352617263796  inv_L_scale:  [1.0, 1.0]
Epoch :  174  Time:  0.898  Rel. Train L2 Loss :  0.022725421339273452  Rel. Test L2 Loss :  0.0242289911955595  Test L2 Loss :  0.042554244101047516  inv_L_scale:  [1.0, 1.0]
Epoch :  175  Time:  0.899  Rel. Train L2 Loss :  0.022278854722778  Rel. Test L2 Loss :  0.023781030625104903  Test L2 Loss :  0.04269364655017853  inv_L_scale:  [1.0, 1.0]
Epoch :  176  Time:  0.899  Rel. Train L2 Loss :  0.021745743523869248  Rel. Test L2 Loss :  0.023245352506637573  Test L2 Loss :  0.04113991945981979  inv_L_scale:  [1.0, 1.0]
Epoch :  177  Time:  0.898  Rel. Train L2 Loss :  0.022018511204255953  Rel. Test L2 Loss :  0.022310698628425597  Test L2 Loss :  0.03897353008389473  inv_L_scale:  [1.0, 1.0]
Epoch :  178  Time:  0.898  Rel. Train L2 Loss :  0.022244845661852093  Rel. Test L2 Loss :  0.023548507317900657  Test L2 Loss :  0.041770095378160475  inv_L_scale:  [1.0, 1.0]
Epoch :  179  Time:  0.899  Rel. Train L2 Loss :  0.02226494157479869  Rel. Test L2 Loss :  0.023486445024609566  Test L2 Loss :  0.04125612139701843  inv_L_scale:  [1.0, 1.0]
Epoch :  180  Time:  0.898  Rel. Train L2 Loss :  0.021900395279129348  Rel. Test L2 Loss :  0.030039267987012862  Test L2 Loss :  0.054012575149536134  inv_L_scale:  [1.0, 1.0]
Epoch :  181  Time:  0.898  Rel. Train L2 Loss :  0.022414480083518557  Rel. Test L2 Loss :  0.024497667104005815  Test L2 Loss :  0.04301395416259766  inv_L_scale:  [1.0, 1.0]
Epoch :  182  Time:  0.9  Rel. Train L2 Loss :  0.022250212439232402  Rel. Test L2 Loss :  0.02438066616654396  Test L2 Loss :  0.04342975169420242  inv_L_scale:  [1.0, 1.0]
Epoch :  183  Time:  0.898  Rel. Train L2 Loss :  0.022363668088283804  Rel. Test L2 Loss :  0.023345732912421226  Test L2 Loss :  0.040802910327911376  inv_L_scale:  [1.0, 1.0]
Epoch :  184  Time:  0.899  Rel. Train L2 Loss :  0.022643698536687427  Rel. Test L2 Loss :  0.021932164579629897  Test L2 Loss :  0.03866303637623787  inv_L_scale:  [1.0, 1.0]
Epoch :  185  Time:  0.901  Rel. Train L2 Loss :  0.021855663996603755  Rel. Test L2 Loss :  0.022774377092719077  Test L2 Loss :  0.04025179296731949  inv_L_scale:  [1.0, 1.0]
Epoch :  186  Time:  0.899  Rel. Train L2 Loss :  0.021604767590761183  Rel. Test L2 Loss :  0.022868037521839142  Test L2 Loss :  0.039937474727630616  inv_L_scale:  [1.0, 1.0]
Epoch :  187  Time:  0.899  Rel. Train L2 Loss :  0.02202282910545667  Rel. Test L2 Loss :  0.027515677735209465  Test L2 Loss :  0.049666999876499175  inv_L_scale:  [1.0, 1.0]
Epoch :  188  Time:  0.899  Rel. Train L2 Loss :  0.02201193986667527  Rel. Test L2 Loss :  0.02295407831668854  Test L2 Loss :  0.04002881318330765  inv_L_scale:  [1.0, 1.0]
Epoch :  189  Time:  0.899  Rel. Train L2 Loss :  0.021590605589250723  Rel. Test L2 Loss :  0.022121764644980432  Test L2 Loss :  0.03885728731751442  inv_L_scale:  [1.0, 1.0]
Epoch :  190  Time:  0.899  Rel. Train L2 Loss :  0.021804517921474247  Rel. Test L2 Loss :  0.022488640397787096  Test L2 Loss :  0.039814076125621795  inv_L_scale:  [1.0, 1.0]
Epoch :  191  Time:  0.898  Rel. Train L2 Loss :  0.021605781556831467  Rel. Test L2 Loss :  0.024161702618002892  Test L2 Loss :  0.043080836981534955  inv_L_scale:  [1.0, 1.0]
Epoch :  192  Time:  0.898  Rel. Train L2 Loss :  0.021827817286054294  Rel. Test L2 Loss :  0.023589350134134292  Test L2 Loss :  0.04121443957090378  inv_L_scale:  [1.0, 1.0]
Epoch :  193  Time:  0.899  Rel. Train L2 Loss :  0.021988490199049315  Rel. Test L2 Loss :  0.024126707911491393  Test L2 Loss :  0.042683397084474564  inv_L_scale:  [1.0, 1.0]
Epoch :  194  Time:  0.899  Rel. Train L2 Loss :  0.02172536397145854  Rel. Test L2 Loss :  0.02233549565076828  Test L2 Loss :  0.039091834276914594  inv_L_scale:  [1.0, 1.0]
Epoch :  195  Time:  0.9  Rel. Train L2 Loss :  0.021980377609531084  Rel. Test L2 Loss :  0.023078268468379973  Test L2 Loss :  0.04100409269332886  inv_L_scale:  [1.0, 1.0]
Epoch :  196  Time:  0.902  Rel. Train L2 Loss :  0.021921850906478035  Rel. Test L2 Loss :  0.02482048571109772  Test L2 Loss :  0.044182147979736325  inv_L_scale:  [1.0, 1.0]
Epoch :  197  Time:  0.899  Rel. Train L2 Loss :  0.02277770241101583  Rel. Test L2 Loss :  0.024293892830610276  Test L2 Loss :  0.04350362688302994  inv_L_scale:  [1.0, 1.0]
Epoch :  198  Time:  0.899  Rel. Train L2 Loss :  0.021984450096885363  Rel. Test L2 Loss :  0.024057685136795043  Test L2 Loss :  0.04301768720149994  inv_L_scale:  [1.0, 1.0]
Epoch :  199  Time:  0.899  Rel. Train L2 Loss :  0.021259593359298175  Rel. Test L2 Loss :  0.02335981361567974  Test L2 Loss :  0.041647791713476184  inv_L_scale:  [1.0, 1.0]
Epoch :  200  Time:  0.899  Rel. Train L2 Loss :  0.021239915995134247  Rel. Test L2 Loss :  0.022008632123470307  Test L2 Loss :  0.038711958527565  inv_L_scale:  [1.0, 1.0]
Epoch :  201  Time:  0.898  Rel. Train L2 Loss :  0.02094558416141404  Rel. Test L2 Loss :  0.022365722730755808  Test L2 Loss :  0.03886838972568512  inv_L_scale:  [1.0, 1.0]
Epoch :  202  Time:  0.899  Rel. Train L2 Loss :  0.021055893078446387  Rel. Test L2 Loss :  0.022674859166145325  Test L2 Loss :  0.03975522041320801  inv_L_scale:  [1.0, 1.0]
Epoch :  203  Time:  0.899  Rel. Train L2 Loss :  0.021123197567131786  Rel. Test L2 Loss :  0.022392996102571488  Test L2 Loss :  0.0388982991874218  inv_L_scale:  [1.0, 1.0]
Epoch :  204  Time:  0.899  Rel. Train L2 Loss :  0.021605132064885565  Rel. Test L2 Loss :  0.02382392331957817  Test L2 Loss :  0.04178060382604599  inv_L_scale:  [1.0, 1.0]
Epoch :  205  Time:  0.899  Rel. Train L2 Loss :  0.0213900439772341  Rel. Test L2 Loss :  0.02324272833764553  Test L2 Loss :  0.041310290396213534  inv_L_scale:  [1.0, 1.0]
Epoch :  206  Time:  0.899  Rel. Train L2 Loss :  0.021897286226352057  Rel. Test L2 Loss :  0.022891871109604837  Test L2 Loss :  0.03986538603901863  inv_L_scale:  [1.0, 1.0]
Epoch :  207  Time:  0.899  Rel. Train L2 Loss :  0.02127217176059882  Rel. Test L2 Loss :  0.02216475911438465  Test L2 Loss :  0.0388412806391716  inv_L_scale:  [1.0, 1.0]
Epoch :  208  Time:  0.898  Rel. Train L2 Loss :  0.020924683031108643  Rel. Test L2 Loss :  0.02205016016960144  Test L2 Loss :  0.03887845724821091  inv_L_scale:  [1.0, 1.0]
Epoch :  209  Time:  0.899  Rel. Train L2 Loss :  0.021383611576424703  Rel. Test L2 Loss :  0.027213405966758728  Test L2 Loss :  0.04770946085453034  inv_L_scale:  [1.0, 1.0]
Epoch :  210  Time:  0.898  Rel. Train L2 Loss :  0.021815067206819853  Rel. Test L2 Loss :  0.021337649673223495  Test L2 Loss :  0.03707985505461693  inv_L_scale:  [1.0, 1.0]
Epoch :  211  Time:  0.898  Rel. Train L2 Loss :  0.021531704093019167  Rel. Test L2 Loss :  0.02422286882996559  Test L2 Loss :  0.04311498776078224  inv_L_scale:  [1.0, 1.0]
Epoch :  212  Time:  0.899  Rel. Train L2 Loss :  0.02139107438425223  Rel. Test L2 Loss :  0.02490223936736584  Test L2 Loss :  0.04394139215350151  inv_L_scale:  [1.0, 1.0]
Epoch :  213  Time:  0.899  Rel. Train L2 Loss :  0.020996435797876783  Rel. Test L2 Loss :  0.023281822204589842  Test L2 Loss :  0.04142698377370834  inv_L_scale:  [1.0, 1.0]
Epoch :  214  Time:  0.898  Rel. Train L2 Loss :  0.020936971422698764  Rel. Test L2 Loss :  0.02269945964217186  Test L2 Loss :  0.0400164070725441  inv_L_scale:  [1.0, 1.0]
Epoch :  215  Time:  0.899  Rel. Train L2 Loss :  0.02114440845946471  Rel. Test L2 Loss :  0.022862323597073554  Test L2 Loss :  0.040304893255233766  inv_L_scale:  [1.0, 1.0]
Epoch :  216  Time:  0.899  Rel. Train L2 Loss :  0.020926088814934095  Rel. Test L2 Loss :  0.021163216903805734  Test L2 Loss :  0.03700922802090645  inv_L_scale:  [1.0, 1.0]
Epoch :  217  Time:  0.899  Rel. Train L2 Loss :  0.021051060896780757  Rel. Test L2 Loss :  0.022854637280106546  Test L2 Loss :  0.04080667823553085  inv_L_scale:  [1.0, 1.0]
Epoch :  218  Time:  0.898  Rel. Train L2 Loss :  0.020905664240320525  Rel. Test L2 Loss :  0.024014666900038718  Test L2 Loss :  0.04247412517666817  inv_L_scale:  [1.0, 1.0]
Epoch :  219  Time:  0.899  Rel. Train L2 Loss :  0.021386939903928173  Rel. Test L2 Loss :  0.02406176634132862  Test L2 Loss :  0.042754163444042204  inv_L_scale:  [1.0, 1.0]
Epoch :  220  Time:  0.898  Rel. Train L2 Loss :  0.02066286948819955  Rel. Test L2 Loss :  0.02159659266471863  Test L2 Loss :  0.03787559896707535  inv_L_scale:  [1.0, 1.0]
Epoch :  221  Time:  0.898  Rel. Train L2 Loss :  0.02078302588727739  Rel. Test L2 Loss :  0.022475783228874207  Test L2 Loss :  0.03941482231020928  inv_L_scale:  [1.0, 1.0]
Epoch :  222  Time:  0.899  Rel. Train L2 Loss :  0.02078476495212979  Rel. Test L2 Loss :  0.022291875556111337  Test L2 Loss :  0.03916590690612793  inv_L_scale:  [1.0, 1.0]
Epoch :  223  Time:  0.898  Rel. Train L2 Loss :  0.020737722996208404  Rel. Test L2 Loss :  0.023965187296271326  Test L2 Loss :  0.04257875517010689  inv_L_scale:  [1.0, 1.0]
Epoch :  224  Time:  0.898  Rel. Train L2 Loss :  0.020919768686095873  Rel. Test L2 Loss :  0.02057124152779579  Test L2 Loss :  0.03590037852525711  inv_L_scale:  [1.0, 1.0]
Epoch :  225  Time:  0.899  Rel. Train L2 Loss :  0.020180007542173067  Rel. Test L2 Loss :  0.02139659434556961  Test L2 Loss :  0.0375823238492012  inv_L_scale:  [1.0, 1.0]
Epoch :  226  Time:  0.898  Rel. Train L2 Loss :  0.020789422649476263  Rel. Test L2 Loss :  0.020660110265016556  Test L2 Loss :  0.03646839708089829  inv_L_scale:  [1.0, 1.0]
Epoch :  227  Time:  0.9  Rel. Train L2 Loss :  0.020442996703916125  Rel. Test L2 Loss :  0.020448713675141336  Test L2 Loss :  0.03570372521877289  inv_L_scale:  [1.0, 1.0]
Epoch :  228  Time:  0.898  Rel. Train L2 Loss :  0.020342544813950855  Rel. Test L2 Loss :  0.022051668614149093  Test L2 Loss :  0.0385840767621994  inv_L_scale:  [1.0, 1.0]
Epoch :  229  Time:  0.9  Rel. Train L2 Loss :  0.020431358201636208  Rel. Test L2 Loss :  0.021653972566127777  Test L2 Loss :  0.03838719561696052  inv_L_scale:  [1.0, 1.0]
Epoch :  230  Time:  0.899  Rel. Train L2 Loss :  0.020228313965102038  Rel. Test L2 Loss :  0.02036109060049057  Test L2 Loss :  0.03554746925830841  inv_L_scale:  [1.0, 1.0]
Epoch :  231  Time:  0.899  Rel. Train L2 Loss :  0.02027639685405625  Rel. Test L2 Loss :  0.02045840285718441  Test L2 Loss :  0.03561785653233528  inv_L_scale:  [1.0, 1.0]
Epoch :  232  Time:  0.898  Rel. Train L2 Loss :  0.020021647098991607  Rel. Test L2 Loss :  0.02148575261235237  Test L2 Loss :  0.03774183630943298  inv_L_scale:  [1.0, 1.0]
Epoch :  233  Time:  0.898  Rel. Train L2 Loss :  0.02022878417538272  Rel. Test L2 Loss :  0.02120787024497986  Test L2 Loss :  0.03705775052309036  inv_L_scale:  [1.0, 1.0]
Epoch :  234  Time:  0.898  Rel. Train L2 Loss :  0.020056767248445087  Rel. Test L2 Loss :  0.020886088386178017  Test L2 Loss :  0.03677869603037834  inv_L_scale:  [1.0, 1.0]
Epoch :  235  Time:  0.898  Rel. Train L2 Loss :  0.021297118614117306  Rel. Test L2 Loss :  0.02165380895137787  Test L2 Loss :  0.03803053930401802  inv_L_scale:  [1.0, 1.0]
Epoch :  236  Time:  0.897  Rel. Train L2 Loss :  0.02136711941411098  Rel. Test L2 Loss :  0.022813887298107148  Test L2 Loss :  0.040165210962295535  inv_L_scale:  [1.0, 1.0]
Epoch :  237  Time:  0.897  Rel. Train L2 Loss :  0.021006713178422717  Rel. Test L2 Loss :  0.02380515359342098  Test L2 Loss :  0.04228094279766083  inv_L_scale:  [1.0, 1.0]
Epoch :  238  Time:  0.898  Rel. Train L2 Loss :  0.020301482785079213  Rel. Test L2 Loss :  0.020790871530771256  Test L2 Loss :  0.03650607541203499  inv_L_scale:  [1.0, 1.0]
Epoch :  239  Time:  0.9  Rel. Train L2 Loss :  0.02002506581445535  Rel. Test L2 Loss :  0.020352312102913855  Test L2 Loss :  0.03586066260933876  inv_L_scale:  [1.0, 1.0]
Epoch :  240  Time:  0.9  Rel. Train L2 Loss :  0.020087006563941637  Rel. Test L2 Loss :  0.021279637515544892  Test L2 Loss :  0.03740185037255287  inv_L_scale:  [1.0, 1.0]
Epoch :  241  Time:  0.897  Rel. Train L2 Loss :  0.020417557722992367  Rel. Test L2 Loss :  0.023543749526143073  Test L2 Loss :  0.041810305416584016  inv_L_scale:  [1.0, 1.0]
Epoch :  242  Time:  0.897  Rel. Train L2 Loss :  0.02023409008151955  Rel. Test L2 Loss :  0.020532685816287994  Test L2 Loss :  0.03594652637839317  inv_L_scale:  [1.0, 1.0]
Epoch :  243  Time:  0.897  Rel. Train L2 Loss :  0.02028774467607339  Rel. Test L2 Loss :  0.021442703306674957  Test L2 Loss :  0.0373381707072258  inv_L_scale:  [1.0, 1.0]
Epoch :  244  Time:  0.898  Rel. Train L2 Loss :  0.0203087932533688  Rel. Test L2 Loss :  0.019876556396484377  Test L2 Loss :  0.034754287898540494  inv_L_scale:  [1.0, 1.0]
Epoch :  245  Time:  0.898  Rel. Train L2 Loss :  0.020301019185119205  Rel. Test L2 Loss :  0.021654701977968215  Test L2 Loss :  0.037999075949192045  inv_L_scale:  [1.0, 1.0]
Epoch :  246  Time:  0.898  Rel. Train L2 Loss :  0.020561135336756707  Rel. Test L2 Loss :  0.021600943803787232  Test L2 Loss :  0.03785234615206719  inv_L_scale:  [1.0, 1.0]
Epoch :  247  Time:  0.898  Rel. Train L2 Loss :  0.01995457525882456  Rel. Test L2 Loss :  0.021295724809169768  Test L2 Loss :  0.03754635855555535  inv_L_scale:  [1.0, 1.0]
Epoch :  248  Time:  0.897  Rel. Train L2 Loss :  0.020442597195506097  Rel. Test L2 Loss :  0.02124676987528801  Test L2 Loss :  0.03692785263061524  inv_L_scale:  [1.0, 1.0]
Epoch :  249  Time:  0.897  Rel. Train L2 Loss :  0.019775589857664373  Rel. Test L2 Loss :  0.020755805745720862  Test L2 Loss :  0.036109005510807035  inv_L_scale:  [1.0, 1.0]
Epoch :  250  Time:  0.897  Rel. Train L2 Loss :  0.01976736605167389  Rel. Test L2 Loss :  0.022934435307979582  Test L2 Loss :  0.04062834680080414  inv_L_scale:  [1.0, 1.0]
Epoch :  251  Time:  0.898  Rel. Train L2 Loss :  0.020325554857651393  Rel. Test L2 Loss :  0.021581444814801218  Test L2 Loss :  0.03785063311457634  inv_L_scale:  [1.0, 1.0]
Epoch :  252  Time:  0.898  Rel. Train L2 Loss :  0.02080174996621079  Rel. Test L2 Loss :  0.021288377940654756  Test L2 Loss :  0.0370949587225914  inv_L_scale:  [1.0, 1.0]
Epoch :  253  Time:  0.897  Rel. Train L2 Loss :  0.020416034642193052  Rel. Test L2 Loss :  0.02241604372859001  Test L2 Loss :  0.03938373386859894  inv_L_scale:  [1.0, 1.0]
Epoch :  254  Time:  0.898  Rel. Train L2 Loss :  0.02055390104651451  Rel. Test L2 Loss :  0.020721026957035066  Test L2 Loss :  0.03603518784046173  inv_L_scale:  [1.0, 1.0]
Epoch :  255  Time:  0.898  Rel. Train L2 Loss :  0.02031518386469947  Rel. Test L2 Loss :  0.022902505174279213  Test L2 Loss :  0.04073754966259003  inv_L_scale:  [1.0, 1.0]
Epoch :  256  Time:  0.898  Rel. Train L2 Loss :  0.02014444012608793  Rel. Test L2 Loss :  0.022803074568510055  Test L2 Loss :  0.03994689404964447  inv_L_scale:  [1.0, 1.0]
Epoch :  257  Time:  0.898  Rel. Train L2 Loss :  0.02010053686797619  Rel. Test L2 Loss :  0.022889204770326615  Test L2 Loss :  0.040902043581008914  inv_L_scale:  [1.0, 1.0]
Epoch :  258  Time:  0.897  Rel. Train L2 Loss :  0.020295539283090167  Rel. Test L2 Loss :  0.0209109927713871  Test L2 Loss :  0.036967258453369144  inv_L_scale:  [1.0, 1.0]
Epoch :  259  Time:  0.898  Rel. Train L2 Loss :  0.019830538067552778  Rel. Test L2 Loss :  0.020746545270085334  Test L2 Loss :  0.03624473422765732  inv_L_scale:  [1.0, 1.0]
Epoch :  260  Time:  0.898  Rel. Train L2 Loss :  0.01996424410906103  Rel. Test L2 Loss :  0.022324984520673753  Test L2 Loss :  0.03964768797159195  inv_L_scale:  [1.0, 1.0]
Epoch :  261  Time:  0.898  Rel. Train L2 Loss :  0.019770937917961015  Rel. Test L2 Loss :  0.02065570093691349  Test L2 Loss :  0.036049921959638596  inv_L_scale:  [1.0, 1.0]
Epoch :  262  Time:  0.897  Rel. Train L2 Loss :  0.01934889706472556  Rel. Test L2 Loss :  0.019832977503538133  Test L2 Loss :  0.034707712084054945  inv_L_scale:  [1.0, 1.0]
Epoch :  263  Time:  0.898  Rel. Train L2 Loss :  0.020064864150351948  Rel. Test L2 Loss :  0.020153672471642493  Test L2 Loss :  0.0352732452750206  inv_L_scale:  [1.0, 1.0]
Epoch :  264  Time:  0.899  Rel. Train L2 Loss :  0.02013425757487615  Rel. Test L2 Loss :  0.020425874143838882  Test L2 Loss :  0.03606373146176338  inv_L_scale:  [1.0, 1.0]
Epoch :  265  Time:  0.899  Rel. Train L2 Loss :  0.019775072890851234  Rel. Test L2 Loss :  0.02028385877609253  Test L2 Loss :  0.03554475098848343  inv_L_scale:  [1.0, 1.0]
Epoch :  266  Time:  0.898  Rel. Train L2 Loss :  0.020012512654066086  Rel. Test L2 Loss :  0.02113325610756874  Test L2 Loss :  0.0368509379029274  inv_L_scale:  [1.0, 1.0]
Epoch :  267  Time:  0.898  Rel. Train L2 Loss :  0.019589609230558077  Rel. Test L2 Loss :  0.021517108529806137  Test L2 Loss :  0.03769322589039802  inv_L_scale:  [1.0, 1.0]
Epoch :  268  Time:  0.898  Rel. Train L2 Loss :  0.0199978901570042  Rel. Test L2 Loss :  0.020199673920869826  Test L2 Loss :  0.03513422504067421  inv_L_scale:  [1.0, 1.0]
Epoch :  269  Time:  0.898  Rel. Train L2 Loss :  0.01941261092821757  Rel. Test L2 Loss :  0.021085152179002763  Test L2 Loss :  0.03699877455830574  inv_L_scale:  [1.0, 1.0]
Epoch :  270  Time:  0.896  Rel. Train L2 Loss :  0.019665340863996083  Rel. Test L2 Loss :  0.020032525062561035  Test L2 Loss :  0.035007149279117585  inv_L_scale:  [1.0, 1.0]
Epoch :  271  Time:  0.897  Rel. Train L2 Loss :  0.01975598051316208  Rel. Test L2 Loss :  0.021299696788191796  Test L2 Loss :  0.03732145667076111  inv_L_scale:  [1.0, 1.0]
Epoch :  272  Time:  0.898  Rel. Train L2 Loss :  0.0194121565669775  Rel. Test L2 Loss :  0.019291409775614738  Test L2 Loss :  0.03367806807160378  inv_L_scale:  [1.0, 1.0]
Epoch :  273  Time:  0.897  Rel. Train L2 Loss :  0.019182199413577714  Rel. Test L2 Loss :  0.019922579079866408  Test L2 Loss :  0.034880214780569074  inv_L_scale:  [1.0, 1.0]
Epoch :  274  Time:  0.897  Rel. Train L2 Loss :  0.01944152341120773  Rel. Test L2 Loss :  0.020715704560279845  Test L2 Loss :  0.036160385012626646  inv_L_scale:  [1.0, 1.0]
Epoch :  275  Time:  0.898  Rel. Train L2 Loss :  0.019567175789011848  Rel. Test L2 Loss :  0.020468457788228988  Test L2 Loss :  0.03584740191698074  inv_L_scale:  [1.0, 1.0]
Epoch :  276  Time:  0.898  Rel. Train L2 Loss :  0.01929017278883192  Rel. Test L2 Loss :  0.020050687119364738  Test L2 Loss :  0.03510105907917023  inv_L_scale:  [1.0, 1.0]
Epoch :  277  Time:  0.899  Rel. Train L2 Loss :  0.019754728335473273  Rel. Test L2 Loss :  0.019967190623283386  Test L2 Loss :  0.03471815779805183  inv_L_scale:  [1.0, 1.0]
Epoch :  278  Time:  0.898  Rel. Train L2 Loss :  0.019297542572021483  Rel. Test L2 Loss :  0.02057971179485321  Test L2 Loss :  0.03609194204211235  inv_L_scale:  [1.0, 1.0]
Epoch :  279  Time:  0.898  Rel. Train L2 Loss :  0.019743569501572186  Rel. Test L2 Loss :  0.02049570597708225  Test L2 Loss :  0.0360705891251564  inv_L_scale:  [1.0, 1.0]
Epoch :  280  Time:  0.898  Rel. Train L2 Loss :  0.019247172334127954  Rel. Test L2 Loss :  0.020261951237916947  Test L2 Loss :  0.03539592370390892  inv_L_scale:  [1.0, 1.0]
Epoch :  281  Time:  0.898  Rel. Train L2 Loss :  0.019032076944907505  Rel. Test L2 Loss :  0.020088285356760025  Test L2 Loss :  0.03553504467010498  inv_L_scale:  [1.0, 1.0]
Epoch :  282  Time:  0.897  Rel. Train L2 Loss :  0.01912972574432691  Rel. Test L2 Loss :  0.02172527089715004  Test L2 Loss :  0.03891410380601883  inv_L_scale:  [1.0, 1.0]
Epoch :  283  Time:  0.898  Rel. Train L2 Loss :  0.01908477085332076  Rel. Test L2 Loss :  0.019735548943281174  Test L2 Loss :  0.034619565457105636  inv_L_scale:  [1.0, 1.0]
Epoch :  284  Time:  0.898  Rel. Train L2 Loss :  0.018742496718962987  Rel. Test L2 Loss :  0.020046089440584183  Test L2 Loss :  0.03508711099624634  inv_L_scale:  [1.0, 1.0]
Epoch :  285  Time:  0.898  Rel. Train L2 Loss :  0.01900752984815174  Rel. Test L2 Loss :  0.019589994847774506  Test L2 Loss :  0.03406271994113922  inv_L_scale:  [1.0, 1.0]
Epoch :  286  Time:  0.898  Rel. Train L2 Loss :  0.019149331318007574  Rel. Test L2 Loss :  0.019750523418188094  Test L2 Loss :  0.0347709196805954  inv_L_scale:  [1.0, 1.0]
Epoch :  287  Time:  0.898  Rel. Train L2 Loss :  0.019226297496093645  Rel. Test L2 Loss :  0.019210115745663642  Test L2 Loss :  0.03358505770564079  inv_L_scale:  [1.0, 1.0]
Epoch :  288  Time:  0.899  Rel. Train L2 Loss :  0.01884584476136499  Rel. Test L2 Loss :  0.019586114808917046  Test L2 Loss :  0.034208884835243224  inv_L_scale:  [1.0, 1.0]
Epoch :  289  Time:  0.899  Rel. Train L2 Loss :  0.018813760230938593  Rel. Test L2 Loss :  0.020076723173260688  Test L2 Loss :  0.03523317202925682  inv_L_scale:  [1.0, 1.0]
Epoch :  290  Time:  0.899  Rel. Train L2 Loss :  0.019189353204435773  Rel. Test L2 Loss :  0.019540758952498436  Test L2 Loss :  0.034139445275068285  inv_L_scale:  [1.0, 1.0]
Epoch :  291  Time:  0.898  Rel. Train L2 Loss :  0.01873035372959243  Rel. Test L2 Loss :  0.02039065048098564  Test L2 Loss :  0.03585553601384163  inv_L_scale:  [1.0, 1.0]
Epoch :  292  Time:  0.901  Rel. Train L2 Loss :  0.01881545241508219  Rel. Test L2 Loss :  0.0198739118874073  Test L2 Loss :  0.03472818478941917  inv_L_scale:  [1.0, 1.0]
Epoch :  293  Time:  0.9  Rel. Train L2 Loss :  0.01896838568150997  Rel. Test L2 Loss :  0.01904215432703495  Test L2 Loss :  0.03307476609945297  inv_L_scale:  [1.0, 1.0]
Epoch :  294  Time:  0.899  Rel. Train L2 Loss :  0.01863351319399145  Rel. Test L2 Loss :  0.01932004190981388  Test L2 Loss :  0.03342714354395866  inv_L_scale:  [1.0, 1.0]
Epoch :  295  Time:  0.899  Rel. Train L2 Loss :  0.01871907140645716  Rel. Test L2 Loss :  0.02004958875477314  Test L2 Loss :  0.035009085834026336  inv_L_scale:  [1.0, 1.0]
Epoch :  296  Time:  0.898  Rel. Train L2 Loss :  0.018558118757274415  Rel. Test L2 Loss :  0.01911635547876358  Test L2 Loss :  0.03325749978423118  inv_L_scale:  [1.0, 1.0]
Epoch :  297  Time:  0.899  Rel. Train L2 Loss :  0.018646320216357707  Rel. Test L2 Loss :  0.01955373406410217  Test L2 Loss :  0.03410517230629921  inv_L_scale:  [1.0, 1.0]
Epoch :  298  Time:  0.898  Rel. Train L2 Loss :  0.018758597473303478  Rel. Test L2 Loss :  0.019668550044298173  Test L2 Loss :  0.03423690840601921  inv_L_scale:  [1.0, 1.0]
Epoch :  299  Time:  0.898  Rel. Train L2 Loss :  0.018718301819430457  Rel. Test L2 Loss :  0.019538639783859252  Test L2 Loss :  0.03407629787921906  inv_L_scale:  [1.0, 1.0]
Epoch :  300  Time:  0.899  Rel. Train L2 Loss :  0.01880042497896486  Rel. Test L2 Loss :  0.019065724685788155  Test L2 Loss :  0.033265033662319185  inv_L_scale:  [1.0, 1.0]
Epoch :  301  Time:  0.899  Rel. Train L2 Loss :  0.018962159719732072  Rel. Test L2 Loss :  0.022413410246372223  Test L2 Loss :  0.04011373490095139  inv_L_scale:  [1.0, 1.0]
Epoch :  302  Time:  0.898  Rel. Train L2 Loss :  0.01892442856811815  Rel. Test L2 Loss :  0.01912761464715004  Test L2 Loss :  0.033319914638996126  inv_L_scale:  [1.0, 1.0]
Epoch :  303  Time:  0.898  Rel. Train L2 Loss :  0.018593504238459797  Rel. Test L2 Loss :  0.019759268835186958  Test L2 Loss :  0.034853957295417785  inv_L_scale:  [1.0, 1.0]
Epoch :  304  Time:  0.898  Rel. Train L2 Loss :  0.018785779318875737  Rel. Test L2 Loss :  0.01966762565076351  Test L2 Loss :  0.034182291477918625  inv_L_scale:  [1.0, 1.0]
Epoch :  305  Time:  0.898  Rel. Train L2 Loss :  0.018631561141875055  Rel. Test L2 Loss :  0.020084394514560698  Test L2 Loss :  0.03496339365839958  inv_L_scale:  [1.0, 1.0]
Epoch :  306  Time:  0.898  Rel. Train L2 Loss :  0.018629549576176536  Rel. Test L2 Loss :  0.01930971972644329  Test L2 Loss :  0.033650219589471814  inv_L_scale:  [1.0, 1.0]
Epoch :  307  Time:  0.898  Rel. Train L2 Loss :  0.018757207410203085  Rel. Test L2 Loss :  0.019292722344398498  Test L2 Loss :  0.03348957285284996  inv_L_scale:  [1.0, 1.0]
Epoch :  308  Time:  0.898  Rel. Train L2 Loss :  0.018451359131269985  Rel. Test L2 Loss :  0.018652974143624306  Test L2 Loss :  0.03245438084006309  inv_L_scale:  [1.0, 1.0]
Epoch :  309  Time:  0.898  Rel. Train L2 Loss :  0.018591891965932316  Rel. Test L2 Loss :  0.020203924179077147  Test L2 Loss :  0.03528911650180817  inv_L_scale:  [1.0, 1.0]
Epoch :  310  Time:  0.898  Rel. Train L2 Loss :  0.01864726217670573  Rel. Test L2 Loss :  0.019618183821439743  Test L2 Loss :  0.034296797066926954  inv_L_scale:  [1.0, 1.0]
Epoch :  311  Time:  0.899  Rel. Train L2 Loss :  0.018587865158915518  Rel. Test L2 Loss :  0.019044214338064195  Test L2 Loss :  0.03333472415804863  inv_L_scale:  [1.0, 1.0]
Epoch :  312  Time:  0.898  Rel. Train L2 Loss :  0.018453146587643358  Rel. Test L2 Loss :  0.01857514098286629  Test L2 Loss :  0.03232636258006096  inv_L_scale:  [1.0, 1.0]
Epoch :  313  Time:  0.898  Rel. Train L2 Loss :  0.01802758773167928  Rel. Test L2 Loss :  0.01867737717926502  Test L2 Loss :  0.032472672760486605  inv_L_scale:  [1.0, 1.0]
Epoch :  314  Time:  0.898  Rel. Train L2 Loss :  0.01794045744670762  Rel. Test L2 Loss :  0.019028411582112312  Test L2 Loss :  0.03312724977731705  inv_L_scale:  [1.0, 1.0]
Epoch :  315  Time:  0.899  Rel. Train L2 Loss :  0.018095011367566055  Rel. Test L2 Loss :  0.019371253550052644  Test L2 Loss :  0.033868168294429776  inv_L_scale:  [1.0, 1.0]
Epoch :  316  Time:  0.899  Rel. Train L2 Loss :  0.018320825919508933  Rel. Test L2 Loss :  0.019162778556346894  Test L2 Loss :  0.03334987834095955  inv_L_scale:  [1.0, 1.0]
Epoch :  317  Time:  0.898  Rel. Train L2 Loss :  0.01813401084807184  Rel. Test L2 Loss :  0.019028250351548193  Test L2 Loss :  0.03337700396776199  inv_L_scale:  [1.0, 1.0]
Epoch :  318  Time:  0.898  Rel. Train L2 Loss :  0.01798360933860143  Rel. Test L2 Loss :  0.019161063805222513  Test L2 Loss :  0.03332494527101517  inv_L_scale:  [1.0, 1.0]
Epoch :  319  Time:  0.898  Rel. Train L2 Loss :  0.018079746464888254  Rel. Test L2 Loss :  0.019479632303118707  Test L2 Loss :  0.03385690808296204  inv_L_scale:  [1.0, 1.0]
Epoch :  320  Time:  0.898  Rel. Train L2 Loss :  0.018110023422373667  Rel. Test L2 Loss :  0.019446889832615853  Test L2 Loss :  0.03391609504818916  inv_L_scale:  [1.0, 1.0]
Epoch :  321  Time:  0.899  Rel. Train L2 Loss :  0.018311498736341796  Rel. Test L2 Loss :  0.01923658512532711  Test L2 Loss :  0.03349011018872261  inv_L_scale:  [1.0, 1.0]
Epoch :  322  Time:  0.899  Rel. Train L2 Loss :  0.018104858125249545  Rel. Test L2 Loss :  0.018484491929411886  Test L2 Loss :  0.03207456916570663  inv_L_scale:  [1.0, 1.0]
Epoch :  323  Time:  0.898  Rel. Train L2 Loss :  0.01797213043603632  Rel. Test L2 Loss :  0.01863891862332821  Test L2 Loss :  0.03260247975587845  inv_L_scale:  [1.0, 1.0]
Epoch :  324  Time:  0.898  Rel. Train L2 Loss :  0.017966483467155032  Rel. Test L2 Loss :  0.018876367583870887  Test L2 Loss :  0.032938698679208754  inv_L_scale:  [1.0, 1.0]
Epoch :  325  Time:  0.898  Rel. Train L2 Loss :  0.017843684314025773  Rel. Test L2 Loss :  0.018252379447221755  Test L2 Loss :  0.03164311245083809  inv_L_scale:  [1.0, 1.0]
Epoch :  326  Time:  0.898  Rel. Train L2 Loss :  0.017800280497305924  Rel. Test L2 Loss :  0.01857564628124237  Test L2 Loss :  0.03228120192885399  inv_L_scale:  [1.0, 1.0]
Epoch :  327  Time:  0.898  Rel. Train L2 Loss :  0.017790849349564975  Rel. Test L2 Loss :  0.018890315517783165  Test L2 Loss :  0.03302652418613434  inv_L_scale:  [1.0, 1.0]
Epoch :  328  Time:  0.898  Rel. Train L2 Loss :  0.01773906912240717  Rel. Test L2 Loss :  0.019644756838679313  Test L2 Loss :  0.03465480923652649  inv_L_scale:  [1.0, 1.0]
Epoch :  329  Time:  0.898  Rel. Train L2 Loss :  0.01788041083349122  Rel. Test L2 Loss :  0.018670395389199256  Test L2 Loss :  0.03249516665935517  inv_L_scale:  [1.0, 1.0]
Epoch :  330  Time:  0.898  Rel. Train L2 Loss :  0.0179713313240144  Rel. Test L2 Loss :  0.01871506333351135  Test L2 Loss :  0.03267554476857185  inv_L_scale:  [1.0, 1.0]
Epoch :  331  Time:  0.898  Rel. Train L2 Loss :  0.01764308518005742  Rel. Test L2 Loss :  0.018834019154310225  Test L2 Loss :  0.03272489219903946  inv_L_scale:  [1.0, 1.0]
Epoch :  332  Time:  0.898  Rel. Train L2 Loss :  0.017756699232591523  Rel. Test L2 Loss :  0.018372757211327553  Test L2 Loss :  0.03195945143699646  inv_L_scale:  [1.0, 1.0]
Epoch :  333  Time:  0.898  Rel. Train L2 Loss :  0.01764791919125451  Rel. Test L2 Loss :  0.019200911521911623  Test L2 Loss :  0.03382005676627159  inv_L_scale:  [1.0, 1.0]
Epoch :  334  Time:  0.898  Rel. Train L2 Loss :  0.017642854270007877  Rel. Test L2 Loss :  0.019331844672560692  Test L2 Loss :  0.03402799069881439  inv_L_scale:  [1.0, 1.0]
Epoch :  335  Time:  0.898  Rel. Train L2 Loss :  0.017755539077851507  Rel. Test L2 Loss :  0.01828127257525921  Test L2 Loss :  0.03179542988538742  inv_L_scale:  [1.0, 1.0]
Epoch :  336  Time:  0.898  Rel. Train L2 Loss :  0.017548892945051194  Rel. Test L2 Loss :  0.01817196823656559  Test L2 Loss :  0.03162561222910881  inv_L_scale:  [1.0, 1.0]
Epoch :  337  Time:  0.9  Rel. Train L2 Loss :  0.017405710683928596  Rel. Test L2 Loss :  0.018051822632551194  Test L2 Loss :  0.03132664829492569  inv_L_scale:  [1.0, 1.0]
Epoch :  338  Time:  0.899  Rel. Train L2 Loss :  0.01764195029106405  Rel. Test L2 Loss :  0.018658653572201728  Test L2 Loss :  0.03230633094906807  inv_L_scale:  [1.0, 1.0]
Epoch :  339  Time:  0.899  Rel. Train L2 Loss :  0.01793651684290833  Rel. Test L2 Loss :  0.01868650197982788  Test L2 Loss :  0.03246123194694519  inv_L_scale:  [1.0, 1.0]
Epoch :  340  Time:  0.899  Rel. Train L2 Loss :  0.017683622423145508  Rel. Test L2 Loss :  0.018436261117458344  Test L2 Loss :  0.0320247446000576  inv_L_scale:  [1.0, 1.0]
Epoch :  341  Time:  0.898  Rel. Train L2 Loss :  0.017491075156463518  Rel. Test L2 Loss :  0.018921266943216324  Test L2 Loss :  0.03324038043618202  inv_L_scale:  [1.0, 1.0]
Epoch :  342  Time:  0.898  Rel. Train L2 Loss :  0.017752953295906385  Rel. Test L2 Loss :  0.018611319065093994  Test L2 Loss :  0.03242434978485107  inv_L_scale:  [1.0, 1.0]
Epoch :  343  Time:  0.899  Rel. Train L2 Loss :  0.01752735745575693  Rel. Test L2 Loss :  0.01842179723083973  Test L2 Loss :  0.0320698107779026  inv_L_scale:  [1.0, 1.0]
Epoch :  344  Time:  0.898  Rel. Train L2 Loss :  0.01753392323023743  Rel. Test L2 Loss :  0.018803517669439315  Test L2 Loss :  0.032894641757011414  inv_L_scale:  [1.0, 1.0]
Epoch :  345  Time:  0.898  Rel. Train L2 Loss :  0.017408950585458015  Rel. Test L2 Loss :  0.018542020618915557  Test L2 Loss :  0.03235100954771042  inv_L_scale:  [1.0, 1.0]
Epoch :  346  Time:  0.898  Rel. Train L2 Loss :  0.01742777148054706  Rel. Test L2 Loss :  0.018383886218070983  Test L2 Loss :  0.03207731306552887  inv_L_scale:  [1.0, 1.0]
Epoch :  347  Time:  0.899  Rel. Train L2 Loss :  0.017623396640022597  Rel. Test L2 Loss :  0.017929697260260582  Test L2 Loss :  0.031074333190917968  inv_L_scale:  [1.0, 1.0]
Epoch :  348  Time:  0.898  Rel. Train L2 Loss :  0.01720286281572448  Rel. Test L2 Loss :  0.017846712172031404  Test L2 Loss :  0.031074218600988388  inv_L_scale:  [1.0, 1.0]
Epoch :  349  Time:  0.899  Rel. Train L2 Loss :  0.017311057696739834  Rel. Test L2 Loss :  0.017992685437202453  Test L2 Loss :  0.0311395289003849  inv_L_scale:  [1.0, 1.0]
Epoch :  350  Time:  0.899  Rel. Train L2 Loss :  0.017269991719060473  Rel. Test L2 Loss :  0.018071185722947122  Test L2 Loss :  0.03150483965873718  inv_L_scale:  [1.0, 1.0]
Epoch :  351  Time:  0.898  Rel. Train L2 Loss :  0.017054732309447394  Rel. Test L2 Loss :  0.01790396258234978  Test L2 Loss :  0.031179504841566084  inv_L_scale:  [1.0, 1.0]
Epoch :  352  Time:  0.898  Rel. Train L2 Loss :  0.01730078746047285  Rel. Test L2 Loss :  0.01802634373307228  Test L2 Loss :  0.03127767615020275  inv_L_scale:  [1.0, 1.0]
Epoch :  353  Time:  0.897  Rel. Train L2 Loss :  0.01712338264617655  Rel. Test L2 Loss :  0.018066283389925955  Test L2 Loss :  0.031277936100959775  inv_L_scale:  [1.0, 1.0]
Epoch :  354  Time:  0.899  Rel. Train L2 Loss :  0.01721194754872057  Rel. Test L2 Loss :  0.017816165685653685  Test L2 Loss :  0.030858791470527648  inv_L_scale:  [1.0, 1.0]
Epoch :  355  Time:  0.9  Rel. Train L2 Loss :  0.01716516192588541  Rel. Test L2 Loss :  0.018579564765095712  Test L2 Loss :  0.032414198219776154  inv_L_scale:  [1.0, 1.0]
Epoch :  356  Time:  0.898  Rel. Train L2 Loss :  0.01719229846364922  Rel. Test L2 Loss :  0.018439796566963196  Test L2 Loss :  0.032083116620779034  inv_L_scale:  [1.0, 1.0]
Epoch :  357  Time:  0.899  Rel. Train L2 Loss :  0.01709753259188599  Rel. Test L2 Loss :  0.017876853346824647  Test L2 Loss :  0.03112523540854454  inv_L_scale:  [1.0, 1.0]
Epoch :  358  Time:  0.898  Rel. Train L2 Loss :  0.017023324221372604  Rel. Test L2 Loss :  0.018409287333488466  Test L2 Loss :  0.03190656214952469  inv_L_scale:  [1.0, 1.0]
Epoch :  359  Time:  0.899  Rel. Train L2 Loss :  0.017103617307212618  Rel. Test L2 Loss :  0.01775596186518669  Test L2 Loss :  0.030796127915382384  inv_L_scale:  [1.0, 1.0]
Epoch :  360  Time:  0.898  Rel. Train L2 Loss :  0.01711637097928259  Rel. Test L2 Loss :  0.01790804900228977  Test L2 Loss :  0.031237058341503143  inv_L_scale:  [1.0, 1.0]
Epoch :  361  Time:  0.899  Rel. Train L2 Loss :  0.016992617547512055  Rel. Test L2 Loss :  0.017958827540278433  Test L2 Loss :  0.031101017743349075  inv_L_scale:  [1.0, 1.0]
Epoch :  362  Time:  0.903  Rel. Train L2 Loss :  0.016814868218368955  Rel. Test L2 Loss :  0.017467803582549096  Test L2 Loss :  0.030270036160945892  inv_L_scale:  [1.0, 1.0]
Epoch :  363  Time:  0.907  Rel. Train L2 Loss :  0.01693636092874739  Rel. Test L2 Loss :  0.017648512721061705  Test L2 Loss :  0.030557160302996635  inv_L_scale:  [1.0, 1.0]
Epoch :  364  Time:  0.907  Rel. Train L2 Loss :  0.016933417543768883  Rel. Test L2 Loss :  0.017538957819342612  Test L2 Loss :  0.030350910276174547  inv_L_scale:  [1.0, 1.0]
Epoch :  365  Time:  0.907  Rel. Train L2 Loss :  0.01698168156461583  Rel. Test L2 Loss :  0.017699731737375258  Test L2 Loss :  0.03073744975030422  inv_L_scale:  [1.0, 1.0]
Epoch :  366  Time:  0.906  Rel. Train L2 Loss :  0.016941750132375293  Rel. Test L2 Loss :  0.017714210450649262  Test L2 Loss :  0.030801146775484085  inv_L_scale:  [1.0, 1.0]
Epoch :  367  Time:  0.905  Rel. Train L2 Loss :  0.016863996899790235  Rel. Test L2 Loss :  0.017386699840426446  Test L2 Loss :  0.030237633883953095  inv_L_scale:  [1.0, 1.0]
Epoch :  368  Time:  0.906  Rel. Train L2 Loss :  0.017005022491017978  Rel. Test L2 Loss :  0.018187562450766564  Test L2 Loss :  0.03163205176591873  inv_L_scale:  [1.0, 1.0]
Epoch :  369  Time:  0.906  Rel. Train L2 Loss :  0.017065267405576175  Rel. Test L2 Loss :  0.01785472795367241  Test L2 Loss :  0.030969503223896026  inv_L_scale:  [1.0, 1.0]
Epoch :  370  Time:  0.906  Rel. Train L2 Loss :  0.016938961495955786  Rel. Test L2 Loss :  0.01795113109052181  Test L2 Loss :  0.031209726184606552  inv_L_scale:  [1.0, 1.0]
Epoch :  371  Time:  0.906  Rel. Train L2 Loss :  0.016923940608070957  Rel. Test L2 Loss :  0.01799485206604004  Test L2 Loss :  0.0312940688431263  inv_L_scale:  [1.0, 1.0]
Epoch :  372  Time:  0.905  Rel. Train L2 Loss :  0.016911214705970554  Rel. Test L2 Loss :  0.01772108405828476  Test L2 Loss :  0.030728945061564445  inv_L_scale:  [1.0, 1.0]
Epoch :  373  Time:  0.905  Rel. Train L2 Loss :  0.016770657383733324  Rel. Test L2 Loss :  0.01754744417965412  Test L2 Loss :  0.03047447606921196  inv_L_scale:  [1.0, 1.0]
Epoch :  374  Time:  0.905  Rel. Train L2 Loss :  0.016888411732183563  Rel. Test L2 Loss :  0.017595917880535127  Test L2 Loss :  0.030573338866233826  inv_L_scale:  [1.0, 1.0]
Epoch :  375  Time:  0.905  Rel. Train L2 Loss :  0.01685640229947037  Rel. Test L2 Loss :  0.01766788125038147  Test L2 Loss :  0.03080095797777176  inv_L_scale:  [1.0, 1.0]
Epoch :  376  Time:  0.905  Rel. Train L2 Loss :  0.01669446693526374  Rel. Test L2 Loss :  0.01748203717172146  Test L2 Loss :  0.030217262506484984  inv_L_scale:  [1.0, 1.0]
Epoch :  377  Time:  0.905  Rel. Train L2 Loss :  0.016774671090145906  Rel. Test L2 Loss :  0.017211714014410972  Test L2 Loss :  0.029857838973402977  inv_L_scale:  [1.0, 1.0]
Epoch :  378  Time:  0.904  Rel. Train L2 Loss :  0.016697162555323705  Rel. Test L2 Loss :  0.017465719655156135  Test L2 Loss :  0.030239389315247535  inv_L_scale:  [1.0, 1.0]
Epoch :  379  Time:  0.905  Rel. Train L2 Loss :  0.01675971206277609  Rel. Test L2 Loss :  0.017276126965880392  Test L2 Loss :  0.029912400394678115  inv_L_scale:  [1.0, 1.0]
Epoch :  380  Time:  0.905  Rel. Train L2 Loss :  0.016551928280128372  Rel. Test L2 Loss :  0.017654983177781105  Test L2 Loss :  0.03060236558318138  inv_L_scale:  [1.0, 1.0]
Epoch :  381  Time:  0.905  Rel. Train L2 Loss :  0.01656009583837456  Rel. Test L2 Loss :  0.017678423076868056  Test L2 Loss :  0.03066308319568634  inv_L_scale:  [1.0, 1.0]
Epoch :  382  Time:  0.905  Rel. Train L2 Loss :  0.016564694705108803  Rel. Test L2 Loss :  0.01728052444756031  Test L2 Loss :  0.029966231808066367  inv_L_scale:  [1.0, 1.0]
Epoch :  383  Time:  0.905  Rel. Train L2 Loss :  0.016495211372772853  Rel. Test L2 Loss :  0.01725517973303795  Test L2 Loss :  0.029906231462955474  inv_L_scale:  [1.0, 1.0]
Epoch :  384  Time:  0.905  Rel. Train L2 Loss :  0.016428531060616175  Rel. Test L2 Loss :  0.017171486765146255  Test L2 Loss :  0.029742753878235818  inv_L_scale:  [1.0, 1.0]
Epoch :  385  Time:  0.905  Rel. Train L2 Loss :  0.01658123785008987  Rel. Test L2 Loss :  0.01742629274725914  Test L2 Loss :  0.030194970667362212  inv_L_scale:  [1.0, 1.0]
Epoch :  386  Time:  0.905  Rel. Train L2 Loss :  0.016693297798434894  Rel. Test L2 Loss :  0.017599157467484475  Test L2 Loss :  0.030581467598676682  inv_L_scale:  [1.0, 1.0]
Epoch :  387  Time:  0.905  Rel. Train L2 Loss :  0.016517689617143737  Rel. Test L2 Loss :  0.017337479442358018  Test L2 Loss :  0.03012280136346817  inv_L_scale:  [1.0, 1.0]
Epoch :  388  Time:  0.906  Rel. Train L2 Loss :  0.016404213363097775  Rel. Test L2 Loss :  0.017685448080301286  Test L2 Loss :  0.030893447399139403  inv_L_scale:  [1.0, 1.0]
Epoch :  389  Time:  0.907  Rel. Train L2 Loss :  0.016506214944852722  Rel. Test L2 Loss :  0.017277984470129012  Test L2 Loss :  0.029952403753995896  inv_L_scale:  [1.0, 1.0]
Epoch :  390  Time:  0.907  Rel. Train L2 Loss :  0.016389127332303258  Rel. Test L2 Loss :  0.01735154166817665  Test L2 Loss :  0.029983225166797637  inv_L_scale:  [1.0, 1.0]
Epoch :  391  Time:  0.905  Rel. Train L2 Loss :  0.016413996583885617  Rel. Test L2 Loss :  0.017040501832962036  Test L2 Loss :  0.02943729445338249  inv_L_scale:  [1.0, 1.0]
Epoch :  392  Time:  0.905  Rel. Train L2 Loss :  0.016322196738587487  Rel. Test L2 Loss :  0.017222706079483032  Test L2 Loss :  0.02975283555686474  inv_L_scale:  [1.0, 1.0]
Epoch :  393  Time:  0.905  Rel. Train L2 Loss :  0.016368774515059258  Rel. Test L2 Loss :  0.01711087837815285  Test L2 Loss :  0.029713147059082984  inv_L_scale:  [1.0, 1.0]
Epoch :  394  Time:  0.906  Rel. Train L2 Loss :  0.01628458134002156  Rel. Test L2 Loss :  0.017539294511079787  Test L2 Loss :  0.030529315918684005  inv_L_scale:  [1.0, 1.0]
Epoch :  395  Time:  0.906  Rel. Train L2 Loss :  0.01635377941860093  Rel. Test L2 Loss :  0.017209266796708107  Test L2 Loss :  0.029771604984998704  inv_L_scale:  [1.0, 1.0]
Epoch :  396  Time:  0.905  Rel. Train L2 Loss :  0.0162605240692695  Rel. Test L2 Loss :  0.01699518248438835  Test L2 Loss :  0.029460585713386535  inv_L_scale:  [1.0, 1.0]
Epoch :  397  Time:  0.903  Rel. Train L2 Loss :  0.016250443044635986  Rel. Test L2 Loss :  0.017284832894802094  Test L2 Loss :  0.030008571669459343  inv_L_scale:  [1.0, 1.0]
Epoch :  398  Time:  0.904  Rel. Train L2 Loss :  0.016204567270146474  Rel. Test L2 Loss :  0.01694279573857784  Test L2 Loss :  0.029284618943929672  inv_L_scale:  [1.0, 1.0]
Epoch :  399  Time:  0.905  Rel. Train L2 Loss :  0.01619877458446556  Rel. Test L2 Loss :  0.017170556485652924  Test L2 Loss :  0.029731299355626108  inv_L_scale:  [1.0, 1.0]
Epoch :  400  Time:  0.905  Rel. Train L2 Loss :  0.01628352728154924  Rel. Test L2 Loss :  0.01734711669385433  Test L2 Loss :  0.030087372809648513  inv_L_scale:  [1.0, 1.0]
Epoch :  401  Time:  0.906  Rel. Train L2 Loss :  0.016211130370696384  Rel. Test L2 Loss :  0.016969338580965995  Test L2 Loss :  0.02933670371770859  inv_L_scale:  [1.0, 1.0]
Epoch :  402  Time:  0.905  Rel. Train L2 Loss :  0.016211754298872418  Rel. Test L2 Loss :  0.016942297741770744  Test L2 Loss :  0.029284982234239577  inv_L_scale:  [1.0, 1.0]
Epoch :  403  Time:  0.905  Rel. Train L2 Loss :  0.016134947256909477  Rel. Test L2 Loss :  0.016830705851316453  Test L2 Loss :  0.029096361473202704  inv_L_scale:  [1.0, 1.0]
Epoch :  404  Time:  0.906  Rel. Train L2 Loss :  0.016079639821416802  Rel. Test L2 Loss :  0.016927050948143004  Test L2 Loss :  0.029226027578115463  inv_L_scale:  [1.0, 1.0]
Epoch :  405  Time:  0.907  Rel. Train L2 Loss :  0.01616300381720066  Rel. Test L2 Loss :  0.016750736609101296  Test L2 Loss :  0.02893815830349922  inv_L_scale:  [1.0, 1.0]
Epoch :  406  Time:  0.906  Rel. Train L2 Loss :  0.016147528356975978  Rel. Test L2 Loss :  0.016938296779990196  Test L2 Loss :  0.029341006353497505  inv_L_scale:  [1.0, 1.0]
Epoch :  407  Time:  0.906  Rel. Train L2 Loss :  0.016113395914435388  Rel. Test L2 Loss :  0.017114886119961738  Test L2 Loss :  0.0296246962249279  inv_L_scale:  [1.0, 1.0]
Epoch :  408  Time:  0.906  Rel. Train L2 Loss :  0.01609884479807483  Rel. Test L2 Loss :  0.01689013436436653  Test L2 Loss :  0.02918186992406845  inv_L_scale:  [1.0, 1.0]
Epoch :  409  Time:  0.906  Rel. Train L2 Loss :  0.01611321391330825  Rel. Test L2 Loss :  0.01736642524600029  Test L2 Loss :  0.030167065262794494  inv_L_scale:  [1.0, 1.0]
Epoch :  410  Time:  0.906  Rel. Train L2 Loss :  0.016084595951769087  Rel. Test L2 Loss :  0.016861597448587416  Test L2 Loss :  0.029113577380776405  inv_L_scale:  [1.0, 1.0]
Epoch :  411  Time:  0.906  Rel. Train L2 Loss :  0.016009600717160438  Rel. Test L2 Loss :  0.016837940141558646  Test L2 Loss :  0.029199282824993133  inv_L_scale:  [1.0, 1.0]
Epoch :  412  Time:  0.905  Rel. Train L2 Loss :  0.015996438446972107  Rel. Test L2 Loss :  0.016835447773337363  Test L2 Loss :  0.029164449125528336  inv_L_scale:  [1.0, 1.0]
Epoch :  413  Time:  0.907  Rel. Train L2 Loss :  0.01611489813360903  Rel. Test L2 Loss :  0.01731458753347397  Test L2 Loss :  0.030064996555447577  inv_L_scale:  [1.0, 1.0]
Epoch :  414  Time:  0.906  Rel. Train L2 Loss :  0.016076973386936717  Rel. Test L2 Loss :  0.01699709624052048  Test L2 Loss :  0.02939675286412239  inv_L_scale:  [1.0, 1.0]
Epoch :  415  Time:  0.906  Rel. Train L2 Loss :  0.016004558801651  Rel. Test L2 Loss :  0.0168494937941432  Test L2 Loss :  0.02913666844367981  inv_L_scale:  [1.0, 1.0]
Epoch :  416  Time:  0.905  Rel. Train L2 Loss :  0.01599464349448681  Rel. Test L2 Loss :  0.016724267154932023  Test L2 Loss :  0.028977118209004404  inv_L_scale:  [1.0, 1.0]
Epoch :  417  Time:  0.905  Rel. Train L2 Loss :  0.01595719365610017  Rel. Test L2 Loss :  0.0166550076007843  Test L2 Loss :  0.02882783889770508  inv_L_scale:  [1.0, 1.0]
Epoch :  418  Time:  0.906  Rel. Train L2 Loss :  0.015925723786155383  Rel. Test L2 Loss :  0.016771031320095064  Test L2 Loss :  0.02900765709578991  inv_L_scale:  [1.0, 1.0]
Epoch :  419  Time:  0.906  Rel. Train L2 Loss :  0.0159136005739371  Rel. Test L2 Loss :  0.016640656031668186  Test L2 Loss :  0.028761164247989655  inv_L_scale:  [1.0, 1.0]
Epoch :  420  Time:  0.906  Rel. Train L2 Loss :  0.015934008521338305  Rel. Test L2 Loss :  0.016684200242161752  Test L2 Loss :  0.028859332129359247  inv_L_scale:  [1.0, 1.0]
Epoch :  421  Time:  0.906  Rel. Train L2 Loss :  0.01586486034095287  Rel. Test L2 Loss :  0.01678515747189522  Test L2 Loss :  0.02900032192468643  inv_L_scale:  [1.0, 1.0]
Epoch :  422  Time:  0.91  Rel. Train L2 Loss :  0.01592641073796484  Rel. Test L2 Loss :  0.016860221922397615  Test L2 Loss :  0.029102473109960555  inv_L_scale:  [1.0, 1.0]
Epoch :  423  Time:  0.907  Rel. Train L2 Loss :  0.01594249478644795  Rel. Test L2 Loss :  0.016856211200356484  Test L2 Loss :  0.029148701280355453  inv_L_scale:  [1.0, 1.0]
Epoch :  424  Time:  0.906  Rel. Train L2 Loss :  0.015861018213133016  Rel. Test L2 Loss :  0.016812814846634865  Test L2 Loss :  0.029002324789762498  inv_L_scale:  [1.0, 1.0]
Epoch :  425  Time:  0.906  Rel. Train L2 Loss :  0.015948947916428247  Rel. Test L2 Loss :  0.01682540789246559  Test L2 Loss :  0.029023608192801476  inv_L_scale:  [1.0, 1.0]
Epoch :  426  Time:  0.906  Rel. Train L2 Loss :  0.015904742781486778  Rel. Test L2 Loss :  0.016704853810369968  Test L2 Loss :  0.028893449306488038  inv_L_scale:  [1.0, 1.0]
Epoch :  427  Time:  0.906  Rel. Train L2 Loss :  0.015841480038232273  Rel. Test L2 Loss :  0.01668453425168991  Test L2 Loss :  0.028788975924253463  inv_L_scale:  [1.0, 1.0]
Epoch :  428  Time:  0.906  Rel. Train L2 Loss :  0.015847292211320665  Rel. Test L2 Loss :  0.01682483986020088  Test L2 Loss :  0.02902464635670185  inv_L_scale:  [1.0, 1.0]
Epoch :  429  Time:  0.906  Rel. Train L2 Loss :  0.015789818813403446  Rel. Test L2 Loss :  0.016674680337309837  Test L2 Loss :  0.028787299692630768  inv_L_scale:  [1.0, 1.0]
Epoch :  430  Time:  0.906  Rel. Train L2 Loss :  0.01577559645805094  Rel. Test L2 Loss :  0.016604637801647185  Test L2 Loss :  0.02871198743581772  inv_L_scale:  [1.0, 1.0]
Epoch :  431  Time:  0.908  Rel. Train L2 Loss :  0.01576754286057419  Rel. Test L2 Loss :  0.01666503004729748  Test L2 Loss :  0.02877159580588341  inv_L_scale:  [1.0, 1.0]
Epoch :  432  Time:  0.906  Rel. Train L2 Loss :  0.015759627289242215  Rel. Test L2 Loss :  0.016652776673436166  Test L2 Loss :  0.028789222463965414  inv_L_scale:  [1.0, 1.0]
Epoch :  433  Time:  0.906  Rel. Train L2 Loss :  0.015797339636418554  Rel. Test L2 Loss :  0.016567684710025787  Test L2 Loss :  0.028627679198980332  inv_L_scale:  [1.0, 1.0]
Epoch :  434  Time:  0.907  Rel. Train L2 Loss :  0.01572290031446351  Rel. Test L2 Loss :  0.016598403453826904  Test L2 Loss :  0.028647841513156892  inv_L_scale:  [1.0, 1.0]
Epoch :  435  Time:  0.906  Rel. Train L2 Loss :  0.015704331919550896  Rel. Test L2 Loss :  0.016803229153156282  Test L2 Loss :  0.029015683680772782  inv_L_scale:  [1.0, 1.0]
Epoch :  436  Time:  0.906  Rel. Train L2 Loss :  0.015708111085825496  Rel. Test L2 Loss :  0.016531423553824424  Test L2 Loss :  0.028497777804732324  inv_L_scale:  [1.0, 1.0]
Epoch :  437  Time:  0.905  Rel. Train L2 Loss :  0.015702783821357622  Rel. Test L2 Loss :  0.016694885194301606  Test L2 Loss :  0.028768459111452104  inv_L_scale:  [1.0, 1.0]
Epoch :  438  Time:  0.906  Rel. Train L2 Loss :  0.01570306730767091  Rel. Test L2 Loss :  0.016611487865448  Test L2 Loss :  0.028701560646295546  inv_L_scale:  [1.0, 1.0]
Epoch :  439  Time:  0.906  Rel. Train L2 Loss :  0.015712081202202372  Rel. Test L2 Loss :  0.01660900443792343  Test L2 Loss :  0.028760228902101517  inv_L_scale:  [1.0, 1.0]
Epoch :  440  Time:  0.906  Rel. Train L2 Loss :  0.015686355489823552  Rel. Test L2 Loss :  0.016564452052116395  Test L2 Loss :  0.028594806864857672  inv_L_scale:  [1.0, 1.0]
Epoch :  441  Time:  0.905  Rel. Train L2 Loss :  0.01564947520279222  Rel. Test L2 Loss :  0.016609933599829672  Test L2 Loss :  0.02868693634867668  inv_L_scale:  [1.0, 1.0]
Epoch :  442  Time:  0.906  Rel. Train L2 Loss :  0.015667453250951237  Rel. Test L2 Loss :  0.01667835433036089  Test L2 Loss :  0.028852114379405977  inv_L_scale:  [1.0, 1.0]
Epoch :  443  Time:  0.906  Rel. Train L2 Loss :  0.01565057638618681  Rel. Test L2 Loss :  0.016683135628700257  Test L2 Loss :  0.028798023760318755  inv_L_scale:  [1.0, 1.0]
Epoch :  444  Time:  0.906  Rel. Train L2 Loss :  0.01563655527929465  Rel. Test L2 Loss :  0.016573909148573877  Test L2 Loss :  0.02858886830508709  inv_L_scale:  [1.0, 1.0]
Epoch :  445  Time:  0.906  Rel. Train L2 Loss :  0.015632069243325126  Rel. Test L2 Loss :  0.01650919169187546  Test L2 Loss :  0.028490977957844735  inv_L_scale:  [1.0, 1.0]
Epoch :  446  Time:  0.906  Rel. Train L2 Loss :  0.015596505887806415  Rel. Test L2 Loss :  0.01646507266908884  Test L2 Loss :  0.028396890088915824  inv_L_scale:  [1.0, 1.0]
Epoch :  447  Time:  0.906  Rel. Train L2 Loss :  0.01560828510671854  Rel. Test L2 Loss :  0.01651334062218666  Test L2 Loss :  0.0284714824706316  inv_L_scale:  [1.0, 1.0]
Epoch :  448  Time:  0.906  Rel. Train L2 Loss :  0.015622673618296782  Rel. Test L2 Loss :  0.016572665870189667  Test L2 Loss :  0.028646309822797776  inv_L_scale:  [1.0, 1.0]
Epoch :  449  Time:  0.906  Rel. Train L2 Loss :  0.015629186059037844  Rel. Test L2 Loss :  0.01657198093831539  Test L2 Loss :  0.02860931009054184  inv_L_scale:  [1.0, 1.0]
Epoch :  450  Time:  0.906  Rel. Train L2 Loss :  0.015628431493209468  Rel. Test L2 Loss :  0.01651818610727787  Test L2 Loss :  0.02846194215118885  inv_L_scale:  [1.0, 1.0]
Epoch :  451  Time:  0.906  Rel. Train L2 Loss :  0.015573188443150785  Rel. Test L2 Loss :  0.016522797085344793  Test L2 Loss :  0.028526111766695977  inv_L_scale:  [1.0, 1.0]
Epoch :  452  Time:  0.906  Rel. Train L2 Loss :  0.015561621603038575  Rel. Test L2 Loss :  0.01653576847165823  Test L2 Loss :  0.02854707174003124  inv_L_scale:  [1.0, 1.0]
Epoch :  453  Time:  0.906  Rel. Train L2 Loss :  0.015552514998449219  Rel. Test L2 Loss :  0.01648414261639118  Test L2 Loss :  0.028441353887319564  inv_L_scale:  [1.0, 1.0]
Epoch :  454  Time:  0.906  Rel. Train L2 Loss :  0.015546572282910348  Rel. Test L2 Loss :  0.016467757374048233  Test L2 Loss :  0.02843043617904186  inv_L_scale:  [1.0, 1.0]
Epoch :  455  Time:  0.907  Rel. Train L2 Loss :  0.015550683538118998  Rel. Test L2 Loss :  0.016509503535926343  Test L2 Loss :  0.028488063961267473  inv_L_scale:  [1.0, 1.0]
Epoch :  456  Time:  0.905  Rel. Train L2 Loss :  0.015536518359763754  Rel. Test L2 Loss :  0.01658055130392313  Test L2 Loss :  0.028646515235304832  inv_L_scale:  [1.0, 1.0]
Epoch :  457  Time:  0.906  Rel. Train L2 Loss :  0.015556526275144682  Rel. Test L2 Loss :  0.016474290639162063  Test L2 Loss :  0.02841329909861088  inv_L_scale:  [1.0, 1.0]
Epoch :  458  Time:  0.905  Rel. Train L2 Loss :  0.015530171634422408  Rel. Test L2 Loss :  0.01651344794780016  Test L2 Loss :  0.028495100066065787  inv_L_scale:  [1.0, 1.0]
Epoch :  459  Time:  0.906  Rel. Train L2 Loss :  0.01549917155669795  Rel. Test L2 Loss :  0.016426442489027977  Test L2 Loss :  0.028339756280183794  inv_L_scale:  [1.0, 1.0]
Epoch :  460  Time:  0.905  Rel. Train L2 Loss :  0.015515872115890185  Rel. Test L2 Loss :  0.016424840204417705  Test L2 Loss :  0.028319135457277298  inv_L_scale:  [1.0, 1.0]
Epoch :  461  Time:  0.906  Rel. Train L2 Loss :  0.015529817322062121  Rel. Test L2 Loss :  0.0165200225263834  Test L2 Loss :  0.02853308543562889  inv_L_scale:  [1.0, 1.0]
Epoch :  462  Time:  0.905  Rel. Train L2 Loss :  0.015492972218328053  Rel. Test L2 Loss :  0.01642646547406912  Test L2 Loss :  0.028326492607593536  inv_L_scale:  [1.0, 1.0]
Epoch :  463  Time:  0.906  Rel. Train L2 Loss :  0.01548571472366651  Rel. Test L2 Loss :  0.016467025876045226  Test L2 Loss :  0.02841789446771145  inv_L_scale:  [1.0, 1.0]
Epoch :  464  Time:  0.905  Rel. Train L2 Loss :  0.015485146724515491  Rel. Test L2 Loss :  0.016458107605576516  Test L2 Loss :  0.028375071585178376  inv_L_scale:  [1.0, 1.0]
Epoch :  465  Time:  0.905  Rel. Train L2 Loss :  0.015466228077809016  Rel. Test L2 Loss :  0.016475804671645163  Test L2 Loss :  0.028428804054856302  inv_L_scale:  [1.0, 1.0]
Epoch :  466  Time:  0.904  Rel. Train L2 Loss :  0.01546119886967871  Rel. Test L2 Loss :  0.01639168705791235  Test L2 Loss :  0.028261772245168685  inv_L_scale:  [1.0, 1.0]
Epoch :  467  Time:  0.905  Rel. Train L2 Loss :  0.01544373129804929  Rel. Test L2 Loss :  0.016436099261045455  Test L2 Loss :  0.028338455632328986  inv_L_scale:  [1.0, 1.0]
Epoch :  468  Time:  0.906  Rel. Train L2 Loss :  0.015450331146518389  Rel. Test L2 Loss :  0.016434001550078393  Test L2 Loss :  0.028344901204109194  inv_L_scale:  [1.0, 1.0]
Epoch :  469  Time:  0.906  Rel. Train L2 Loss :  0.015444048009812831  Rel. Test L2 Loss :  0.016397916749119758  Test L2 Loss :  0.028272838443517686  inv_L_scale:  [1.0, 1.0]
Epoch :  470  Time:  0.906  Rel. Train L2 Loss :  0.01543730762683683  Rel. Test L2 Loss :  0.016428387388587  Test L2 Loss :  0.02833956018090248  inv_L_scale:  [1.0, 1.0]
Epoch :  471  Time:  0.905  Rel. Train L2 Loss :  0.015430684487024943  Rel. Test L2 Loss :  0.016443137526512146  Test L2 Loss :  0.028364198952913283  inv_L_scale:  [1.0, 1.0]
Epoch :  472  Time:  0.907  Rel. Train L2 Loss :  0.015431603930062718  Rel. Test L2 Loss :  0.016419938802719115  Test L2 Loss :  0.028318984657526015  inv_L_scale:  [1.0, 1.0]
Epoch :  473  Time:  0.907  Rel. Train L2 Loss :  0.01542680650535557  Rel. Test L2 Loss :  0.01639849953353405  Test L2 Loss :  0.02826048269867897  inv_L_scale:  [1.0, 1.0]
Epoch :  474  Time:  0.906  Rel. Train L2 Loss :  0.015421153091722064  Rel. Test L2 Loss :  0.016401094794273378  Test L2 Loss :  0.028282748907804488  inv_L_scale:  [1.0, 1.0]
Epoch :  475  Time:  0.906  Rel. Train L2 Loss :  0.01541374732222822  Rel. Test L2 Loss :  0.016438424959778784  Test L2 Loss :  0.028340203613042833  inv_L_scale:  [1.0, 1.0]
Epoch :  476  Time:  0.906  Rel. Train L2 Loss :  0.01540419388976362  Rel. Test L2 Loss :  0.01639808028936386  Test L2 Loss :  0.028271147310733796  inv_L_scale:  [1.0, 1.0]
Epoch :  477  Time:  0.905  Rel. Train L2 Loss :  0.015399400211042828  Rel. Test L2 Loss :  0.01640482235699892  Test L2 Loss :  0.028285908326506615  inv_L_scale:  [1.0, 1.0]
Epoch :  478  Time:  0.905  Rel. Train L2 Loss :  0.015396358221769333  Rel. Test L2 Loss :  0.016393397711217405  Test L2 Loss :  0.028264774084091185  inv_L_scale:  [1.0, 1.0]
Epoch :  479  Time:  0.906  Rel. Train L2 Loss :  0.015395396699508032  Rel. Test L2 Loss :  0.016411533877253533  Test L2 Loss :  0.028285012543201447  inv_L_scale:  [1.0, 1.0]
Epoch :  480  Time:  0.906  Rel. Train L2 Loss :  0.015391430838240518  Rel. Test L2 Loss :  0.016412905156612395  Test L2 Loss :  0.028309311494231226  inv_L_scale:  [1.0, 1.0]
Epoch :  481  Time:  0.906  Rel. Train L2 Loss :  0.015382984533078141  Rel. Test L2 Loss :  0.016390163116157055  Test L2 Loss :  0.028238362818956374  inv_L_scale:  [1.0, 1.0]
Epoch :  482  Time:  0.905  Rel. Train L2 Loss :  0.015383592078255282  Rel. Test L2 Loss :  0.016401748545467852  Test L2 Loss :  0.028275158554315567  inv_L_scale:  [1.0, 1.0]
Epoch :  483  Time:  0.904  Rel. Train L2 Loss :  0.015375586702591842  Rel. Test L2 Loss :  0.016401586681604387  Test L2 Loss :  0.02827485591173172  inv_L_scale:  [1.0, 1.0]
Epoch :  484  Time:  0.905  Rel. Train L2 Loss :  0.015369165937105815  Rel. Test L2 Loss :  0.016389050409197806  Test L2 Loss :  0.028266341984272005  inv_L_scale:  [1.0, 1.0]
Epoch :  485  Time:  0.904  Rel. Train L2 Loss :  0.01537069386906094  Rel. Test L2 Loss :  0.016407907158136368  Test L2 Loss :  0.028305709958076478  inv_L_scale:  [1.0, 1.0]
Epoch :  486  Time:  0.905  Rel. Train L2 Loss :  0.015368566682769192  Rel. Test L2 Loss :  0.016416698358953  Test L2 Loss :  0.02830710418522358  inv_L_scale:  [1.0, 1.0]
Epoch :  487  Time:  0.904  Rel. Train L2 Loss :  0.015370239093899727  Rel. Test L2 Loss :  0.016395169571042062  Test L2 Loss :  0.028272660970687865  inv_L_scale:  [1.0, 1.0]
Epoch :  488  Time:  0.908  Rel. Train L2 Loss :  0.015362100423210198  Rel. Test L2 Loss :  0.016399645246565342  Test L2 Loss :  0.028281070441007614  inv_L_scale:  [1.0, 1.0]
Epoch :  489  Time:  0.905  Rel. Train L2 Loss :  0.01536061273680793  Rel. Test L2 Loss :  0.016401518844068052  Test L2 Loss :  0.02828249156475067  inv_L_scale:  [1.0, 1.0]
Epoch :  490  Time:  0.906  Rel. Train L2 Loss :  0.015360376561681429  Rel. Test L2 Loss :  0.016397019997239113  Test L2 Loss :  0.02826909303665161  inv_L_scale:  [1.0, 1.0]
Epoch :  491  Time:  0.905  Rel. Train L2 Loss :  0.01535162966284487  Rel. Test L2 Loss :  0.01640830360352993  Test L2 Loss :  0.028284204229712485  inv_L_scale:  [1.0, 1.0]
Epoch :  492  Time:  0.905  Rel. Train L2 Loss :  0.015354820299479696  Rel. Test L2 Loss :  0.016401041857898237  Test L2 Loss :  0.02827686533331871  inv_L_scale:  [1.0, 1.0]
Epoch :  493  Time:  0.905  Rel. Train L2 Loss :  0.015352217600577407  Rel. Test L2 Loss :  0.016396935880184173  Test L2 Loss :  0.028268775939941405  inv_L_scale:  [1.0, 1.0]
Epoch :  494  Time:  0.905  Rel. Train L2 Loss :  0.015345589046676954  Rel. Test L2 Loss :  0.01639267984777689  Test L2 Loss :  0.028267357125878335  inv_L_scale:  [1.0, 1.0]
Epoch :  495  Time:  0.905  Rel. Train L2 Loss :  0.01534838978615072  Rel. Test L2 Loss :  0.01638258818536997  Test L2 Loss :  0.028240324780344963  inv_L_scale:  [1.0, 1.0]
Epoch :  496  Time:  0.905  Rel. Train L2 Loss :  0.015344500897659196  Rel. Test L2 Loss :  0.016394924968481064  Test L2 Loss :  0.028260134607553482  inv_L_scale:  [1.0, 1.0]
Epoch :  497  Time:  0.906  Rel. Train L2 Loss :  0.015347187568744024  Rel. Test L2 Loss :  0.01637184537947178  Test L2 Loss :  0.028223331943154337  inv_L_scale:  [1.0, 1.0]
Epoch :  498  Time:  0.905  Rel. Train L2 Loss :  0.015343214290009604  Rel. Test L2 Loss :  0.01638425961136818  Test L2 Loss :  0.02824536882340908  inv_L_scale:  [1.0, 1.0]
Epoch :  499  Time:  0.906  Rel. Train L2 Loss :  0.015342797690795527  Rel. Test L2 Loss :  0.016389179192483425  Test L2 Loss :  0.028248733505606652  inv_L_scale:  [1.0, 1.0]
