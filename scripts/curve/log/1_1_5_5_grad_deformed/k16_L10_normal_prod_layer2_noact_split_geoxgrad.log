x1 = speconv(fn, bases_c, bases_s, bases_0, wbases_c, wbases_s, wbases_0)
x2 = w(f)

geo_weight1 = self.softsign(geow1(geo))
x3 = gw(self.softsign(compute_gradient(geo_weight1*f, directed_edges, edge_gradient_weights)))

x = x1 + x2 + x3


(1000,) (1000, 1000, 1) (1000, 1000, 2)
use normalized raw measures
Casting to tensor
x_train shape torch.Size([900, 1000, 8]), y_train shape torch.Size([900, 1000, 1])
length of each dim:  tensor([6.5573987960815430, 6.1420288085937500])
kmax = 16
L = 10
geo_dims = [1, 2, 5, 6]
In PCNO_train, ndims =  2
Epoch :  0  Time:  1.665  Rel. Train L2 Loss :  0.5137702253129747  Rel. Test L2 Loss :  0.3158868145942688  Test L2 Loss :  0.4515330982208252  inv_L_scale:  [1.0, 1.0]
Epoch :  1  Time:  1.304  Rel. Train L2 Loss :  0.2592119670576519  Rel. Test L2 Loss :  0.21957918763160705  Test L2 Loss :  0.31813395738601685  inv_L_scale:  [1.0, 1.0]
Epoch :  2  Time:  1.309  Rel. Train L2 Loss :  0.2126010361644957  Rel. Test L2 Loss :  0.19194069802761077  Test L2 Loss :  0.27350990772247313  inv_L_scale:  [1.0, 1.0]
Epoch :  3  Time:  1.343  Rel. Train L2 Loss :  0.18954030831654867  Rel. Test L2 Loss :  0.1885428810119629  Test L2 Loss :  0.2738278126716614  inv_L_scale:  [1.0, 1.0]
Epoch :  4  Time:  1.31  Rel. Train L2 Loss :  0.1827316102716658  Rel. Test L2 Loss :  0.17812236070632934  Test L2 Loss :  0.2561753332614899  inv_L_scale:  [1.0, 1.0]
Epoch :  5  Time:  1.312  Rel. Train L2 Loss :  0.17616984950171577  Rel. Test L2 Loss :  0.17215708136558533  Test L2 Loss :  0.24917954564094544  inv_L_scale:  [1.0, 1.0]
Epoch :  6  Time:  1.302  Rel. Train L2 Loss :  0.17198856691519418  Rel. Test L2 Loss :  0.16838199138641358  Test L2 Loss :  0.2416914212703705  inv_L_scale:  [1.0, 1.0]
Epoch :  7  Time:  1.34  Rel. Train L2 Loss :  0.16805225054423015  Rel. Test L2 Loss :  0.16447538554668426  Test L2 Loss :  0.235983904004097  inv_L_scale:  [1.0, 1.0]
Epoch :  8  Time:  1.353  Rel. Train L2 Loss :  0.1667679856220881  Rel. Test L2 Loss :  0.16461519300937652  Test L2 Loss :  0.23627174377441407  inv_L_scale:  [1.0, 1.0]
Epoch :  9  Time:  1.312  Rel. Train L2 Loss :  0.16551413224803077  Rel. Test L2 Loss :  0.16970483005046844  Test L2 Loss :  0.24344408094882966  inv_L_scale:  [1.0, 1.0]
Epoch :  10  Time:  1.301  Rel. Train L2 Loss :  0.16057089858584933  Rel. Test L2 Loss :  0.15734935700893402  Test L2 Loss :  0.2274488765001297  inv_L_scale:  [1.0, 1.0]
Epoch :  11  Time:  1.314  Rel. Train L2 Loss :  0.1580317097240024  Rel. Test L2 Loss :  0.15707796752452852  Test L2 Loss :  0.22588782668113708  inv_L_scale:  [1.0, 1.0]
Epoch :  12  Time:  1.357  Rel. Train L2 Loss :  0.15646389298968844  Rel. Test L2 Loss :  0.1628747206926346  Test L2 Loss :  0.23321110188961028  inv_L_scale:  [1.0, 1.0]
Epoch :  13  Time:  1.318  Rel. Train L2 Loss :  0.15730319751633537  Rel. Test L2 Loss :  0.15593075513839721  Test L2 Loss :  0.22430926322937011  inv_L_scale:  [1.0, 1.0]
Epoch :  14  Time:  1.31  Rel. Train L2 Loss :  0.15497607635127172  Rel. Test L2 Loss :  0.15723946809768677  Test L2 Loss :  0.22611021399497985  inv_L_scale:  [1.0, 1.0]
Epoch :  15  Time:  1.326  Rel. Train L2 Loss :  0.153112363020579  Rel. Test L2 Loss :  0.152443265914917  Test L2 Loss :  0.2187102973461151  inv_L_scale:  [1.0, 1.0]
Epoch :  16  Time:  1.358  Rel. Train L2 Loss :  0.15353182938363816  Rel. Test L2 Loss :  0.1500583744049072  Test L2 Loss :  0.21636659741401673  inv_L_scale:  [1.0, 1.0]
Epoch :  17  Time:  1.333  Rel. Train L2 Loss :  0.14815461430284713  Rel. Test L2 Loss :  0.15027881562709808  Test L2 Loss :  0.2172885626554489  inv_L_scale:  [1.0, 1.0]
Epoch :  18  Time:  1.316  Rel. Train L2 Loss :  0.1481579335530599  Rel. Test L2 Loss :  0.14975725829601289  Test L2 Loss :  0.21659396350383758  inv_L_scale:  [1.0, 1.0]
Epoch :  19  Time:  1.354  Rel. Train L2 Loss :  0.14655174487166933  Rel. Test L2 Loss :  0.1502033305168152  Test L2 Loss :  0.21574681878089905  inv_L_scale:  [1.0, 1.0]
Epoch :  20  Time:  1.306  Rel. Train L2 Loss :  0.14648224466376836  Rel. Test L2 Loss :  0.15055740773677825  Test L2 Loss :  0.21726191341876983  inv_L_scale:  [1.0, 1.0]
Epoch :  21  Time:  1.299  Rel. Train L2 Loss :  0.14513053390714858  Rel. Test L2 Loss :  0.14594270765781403  Test L2 Loss :  0.211349818110466  inv_L_scale:  [1.0, 1.0]
Epoch :  22  Time:  1.328  Rel. Train L2 Loss :  0.14441377699375152  Rel. Test L2 Loss :  0.14223532140254974  Test L2 Loss :  0.2046832835674286  inv_L_scale:  [1.0, 1.0]
Epoch :  23  Time:  1.35  Rel. Train L2 Loss :  0.14229350202613406  Rel. Test L2 Loss :  0.14387754797935487  Test L2 Loss :  0.20763930797576904  inv_L_scale:  [1.0, 1.0]
Epoch :  24  Time:  1.314  Rel. Train L2 Loss :  0.14230412635538314  Rel. Test L2 Loss :  0.14643449664115907  Test L2 Loss :  0.21019473791122437  inv_L_scale:  [1.0, 1.0]
Epoch :  25  Time:  1.352  Rel. Train L2 Loss :  0.14151520752244526  Rel. Test L2 Loss :  0.14186604380607604  Test L2 Loss :  0.20336651504039766  inv_L_scale:  [1.0, 1.0]
Epoch :  26  Time:  1.305  Rel. Train L2 Loss :  0.13964054710335203  Rel. Test L2 Loss :  0.1440254831314087  Test L2 Loss :  0.20683180689811706  inv_L_scale:  [1.0, 1.0]
Epoch :  27  Time:  1.331  Rel. Train L2 Loss :  0.13885167360305786  Rel. Test L2 Loss :  0.14082543075084686  Test L2 Loss :  0.2021308320760727  inv_L_scale:  [1.0, 1.0]
Epoch :  28  Time:  1.365  Rel. Train L2 Loss :  0.1384950829545657  Rel. Test L2 Loss :  0.14069806337356566  Test L2 Loss :  0.20275012969970704  inv_L_scale:  [1.0, 1.0]
Epoch :  29  Time:  1.323  Rel. Train L2 Loss :  0.138609699010849  Rel. Test L2 Loss :  0.13982325851917266  Test L2 Loss :  0.20072700917720795  inv_L_scale:  [1.0, 1.0]
Epoch :  30  Time:  1.316  Rel. Train L2 Loss :  0.13699056423372694  Rel. Test L2 Loss :  0.13893712759017945  Test L2 Loss :  0.1997790539264679  inv_L_scale:  [1.0, 1.0]
Epoch :  31  Time:  1.349  Rel. Train L2 Loss :  0.13689953843752542  Rel. Test L2 Loss :  0.14359405815601348  Test L2 Loss :  0.2069242751598358  inv_L_scale:  [1.0, 1.0]
Epoch :  32  Time:  1.301  Rel. Train L2 Loss :  0.136637997660372  Rel. Test L2 Loss :  0.1392015027999878  Test L2 Loss :  0.1993439483642578  inv_L_scale:  [1.0, 1.0]
Epoch :  33  Time:  1.307  Rel. Train L2 Loss :  0.13600295974148643  Rel. Test L2 Loss :  0.1391652935743332  Test L2 Loss :  0.1997997748851776  inv_L_scale:  [1.0, 1.0]
Epoch :  34  Time:  1.337  Rel. Train L2 Loss :  0.1340636118253072  Rel. Test L2 Loss :  0.13507122933864593  Test L2 Loss :  0.1946081918478012  inv_L_scale:  [1.0, 1.0]
Epoch :  35  Time:  1.302  Rel. Train L2 Loss :  0.13213492453098297  Rel. Test L2 Loss :  0.13915269315242768  Test L2 Loss :  0.19954099535942077  inv_L_scale:  [1.0, 1.0]
Epoch :  36  Time:  1.326  Rel. Train L2 Loss :  0.13400243474377527  Rel. Test L2 Loss :  0.13729640781879426  Test L2 Loss :  0.19702444612979889  inv_L_scale:  [1.0, 1.0]
Epoch :  37  Time:  1.308  Rel. Train L2 Loss :  0.13163839171330133  Rel. Test L2 Loss :  0.13906031966209412  Test L2 Loss :  0.1995857572555542  inv_L_scale:  [1.0, 1.0]
Epoch :  38  Time:  1.311  Rel. Train L2 Loss :  0.1322457089026769  Rel. Test L2 Loss :  0.13592320799827576  Test L2 Loss :  0.1953580379486084  inv_L_scale:  [1.0, 1.0]
Epoch :  39  Time:  1.303  Rel. Train L2 Loss :  0.13143810017241372  Rel. Test L2 Loss :  0.13431985080242156  Test L2 Loss :  0.19340372681617737  inv_L_scale:  [1.0, 1.0]
Epoch :  40  Time:  1.359  Rel. Train L2 Loss :  0.13103274544080099  Rel. Test L2 Loss :  0.13452081143856048  Test L2 Loss :  0.193825603723526  inv_L_scale:  [1.0, 1.0]
Epoch :  41  Time:  1.304  Rel. Train L2 Loss :  0.13115514990356233  Rel. Test L2 Loss :  0.12948788106441497  Test L2 Loss :  0.18599953174591063  inv_L_scale:  [1.0, 1.0]
Epoch :  42  Time:  1.3  Rel. Train L2 Loss :  0.1293541086382336  Rel. Test L2 Loss :  0.13117493212223053  Test L2 Loss :  0.1890495240688324  inv_L_scale:  [1.0, 1.0]
Epoch :  43  Time:  1.296  Rel. Train L2 Loss :  0.13070908231867684  Rel. Test L2 Loss :  0.13075790524482728  Test L2 Loss :  0.18858740746974945  inv_L_scale:  [1.0, 1.0]
Epoch :  44  Time:  1.296  Rel. Train L2 Loss :  0.1276958939101961  Rel. Test L2 Loss :  0.13235187649726868  Test L2 Loss :  0.1903011357784271  inv_L_scale:  [1.0, 1.0]
Epoch :  45  Time:  1.297  Rel. Train L2 Loss :  0.1286137808031506  Rel. Test L2 Loss :  0.1356767952442169  Test L2 Loss :  0.1950292992591858  inv_L_scale:  [1.0, 1.0]
Epoch :  46  Time:  1.299  Rel. Train L2 Loss :  0.1277027827501297  Rel. Test L2 Loss :  0.12763093233108522  Test L2 Loss :  0.184166818857193  inv_L_scale:  [1.0, 1.0]
Epoch :  47  Time:  1.34  Rel. Train L2 Loss :  0.126383974717723  Rel. Test L2 Loss :  0.12645962357521057  Test L2 Loss :  0.18301362097263335  inv_L_scale:  [1.0, 1.0]
Epoch :  48  Time:  1.301  Rel. Train L2 Loss :  0.1252041671011183  Rel. Test L2 Loss :  0.12708099961280822  Test L2 Loss :  0.18253231883049012  inv_L_scale:  [1.0, 1.0]
Epoch :  49  Time:  1.303  Rel. Train L2 Loss :  0.12417982372972701  Rel. Test L2 Loss :  0.13075286865234376  Test L2 Loss :  0.18829061448574066  inv_L_scale:  [1.0, 1.0]
Epoch :  50  Time:  1.3  Rel. Train L2 Loss :  0.12406171798706055  Rel. Test L2 Loss :  0.1283752852678299  Test L2 Loss :  0.18497411370277406  inv_L_scale:  [1.0, 1.0]
Epoch :  51  Time:  1.301  Rel. Train L2 Loss :  0.12368897159894307  Rel. Test L2 Loss :  0.12649153053760528  Test L2 Loss :  0.18185768127441407  inv_L_scale:  [1.0, 1.0]
Epoch :  52  Time:  1.299  Rel. Train L2 Loss :  0.1228098706404368  Rel. Test L2 Loss :  0.1268220692873001  Test L2 Loss :  0.1829614198207855  inv_L_scale:  [1.0, 1.0]
Epoch :  53  Time:  1.3  Rel. Train L2 Loss :  0.12242096510198382  Rel. Test L2 Loss :  0.12539757370948793  Test L2 Loss :  0.1801789492368698  inv_L_scale:  [1.0, 1.0]
Epoch :  54  Time:  1.321  Rel. Train L2 Loss :  0.12298886954784394  Rel. Test L2 Loss :  0.13027145028114318  Test L2 Loss :  0.18884943008422853  inv_L_scale:  [1.0, 1.0]
Epoch :  55  Time:  1.305  Rel. Train L2 Loss :  0.12288563072681427  Rel. Test L2 Loss :  0.12637341320514678  Test L2 Loss :  0.18164295375347136  inv_L_scale:  [1.0, 1.0]
Epoch :  56  Time:  1.301  Rel. Train L2 Loss :  0.12130881551239225  Rel. Test L2 Loss :  0.12433978378772735  Test L2 Loss :  0.17848618924617768  inv_L_scale:  [1.0, 1.0]






如果geo只用[geo, geo_grad]:


(1000,) (1000, 1000, 1) (1000, 1000, 2)
use normalized raw measures
Casting to tensor
x_train shape torch.Size([900, 1000, 8]), y_train shape torch.Size([900, 1000, 1])
length of each dim:  tensor([6.5573987960815430, 6.1420288085937500])
kmax = 16
L = 10
geo_dims = [1, 2, 5, 6]
In PCNO_train, ndims =  2
Epoch :  0  Time:  1.659  Rel. Train L2 Loss :  0.5044414520263671  Rel. Test L2 Loss :  0.2959932327270508  Test L2 Loss :  0.4223591589927673  inv_L_scale:  [1.0, 1.0]
Epoch :  1  Time:  1.284  Rel. Train L2 Loss :  0.23633675257364908  Rel. Test L2 Loss :  0.19877463936805725  Test L2 Loss :  0.2815581440925598  inv_L_scale:  [1.0, 1.0]
Epoch :  2  Time:  1.299  Rel. Train L2 Loss :  0.18005225585566625  Rel. Test L2 Loss :  0.16462939262390136  Test L2 Loss :  0.2353955924510956  inv_L_scale:  [1.0, 1.0]
Epoch :  3  Time:  1.271  Rel. Train L2 Loss :  0.1561285400390625  Rel. Test L2 Loss :  0.1491651004552841  Test L2 Loss :  0.21287506580352783  inv_L_scale:  [1.0, 1.0]
Epoch :  4  Time:  1.258  Rel. Train L2 Loss :  0.1397452257739173  Rel. Test L2 Loss :  0.1319044905900955  Test L2 Loss :  0.189316349029541  inv_L_scale:  [1.0, 1.0]
Epoch :  5  Time:  1.262  Rel. Train L2 Loss :  0.1220960396528244  Rel. Test L2 Loss :  0.12768906712532044  Test L2 Loss :  0.18194339871406556  inv_L_scale:  [1.0, 1.0]
Epoch :  6  Time:  1.256  Rel. Train L2 Loss :  0.11667449050479466  Rel. Test L2 Loss :  0.11816465854644775  Test L2 Loss :  0.16932278275489807  inv_L_scale:  [1.0, 1.0]
Epoch :  7  Time:  1.26  Rel. Train L2 Loss :  0.11040919641653697  Rel. Test L2 Loss :  0.10470365405082703  Test L2 Loss :  0.15027131021022797  inv_L_scale:  [1.0, 1.0]
Epoch :  8  Time:  1.26  Rel. Train L2 Loss :  0.10453548977772395  Rel. Test L2 Loss :  0.10085232436656952  Test L2 Loss :  0.1445164692401886  inv_L_scale:  [1.0, 1.0]
Epoch :  9  Time:  1.302  Rel. Train L2 Loss :  0.10332754108640883  Rel. Test L2 Loss :  0.09825528591871262  Test L2 Loss :  0.1400415086746216  inv_L_scale:  [1.0, 1.0]
Epoch :  10  Time:  1.263  Rel. Train L2 Loss :  0.09747053951025009  Rel. Test L2 Loss :  0.1033478656411171  Test L2 Loss :  0.14702875137329102  inv_L_scale:  [1.0, 1.0]
Epoch :  11  Time:  1.264  Rel. Train L2 Loss :  0.09869353436761433  Rel. Test L2 Loss :  0.0962807783484459  Test L2 Loss :  0.1378427755832672  inv_L_scale:  [1.0, 1.0]
Epoch :  12  Time:  1.261  Rel. Train L2 Loss :  0.09478068610032399  Rel. Test L2 Loss :  0.09465010702610016  Test L2 Loss :  0.1354573255777359  inv_L_scale:  [1.0, 1.0]
Epoch :  13  Time:  1.262  Rel. Train L2 Loss :  0.09511678669187758  Rel. Test L2 Loss :  0.09324475288391114  Test L2 Loss :  0.13362342089414597  inv_L_scale:  [1.0, 1.0]
Epoch :  14  Time:  1.264  Rel. Train L2 Loss :  0.094137005938424  Rel. Test L2 Loss :  0.0935460239648819  Test L2 Loss :  0.13355494141578675  inv_L_scale:  [1.0, 1.0]
Epoch :  15  Time:  1.257  Rel. Train L2 Loss :  0.0910003721051746  Rel. Test L2 Loss :  0.09638991177082062  Test L2 Loss :  0.1367822527885437  inv_L_scale:  [1.0, 1.0]
Epoch :  16  Time:  1.261  Rel. Train L2 Loss :  0.09657450715700786  Rel. Test L2 Loss :  0.09323146253824234  Test L2 Loss :  0.1338470447063446  inv_L_scale:  [1.0, 1.0]
Epoch :  17  Time:  1.323  Rel. Train L2 Loss :  0.08935197744104598  Rel. Test L2 Loss :  0.08761580765247345  Test L2 Loss :  0.12534599840641023  inv_L_scale:  [1.0, 1.0]
Epoch :  18  Time:  1.266  Rel. Train L2 Loss :  0.08721812400552961  Rel. Test L2 Loss :  0.08689895182847977  Test L2 Loss :  0.1245347285270691  inv_L_scale:  [1.0, 1.0]
Epoch :  19  Time:  1.26  Rel. Train L2 Loss :  0.08706134223275715  Rel. Test L2 Loss :  0.0850643664598465  Test L2 Loss :  0.12132732152938842  inv_L_scale:  [1.0, 1.0]
Epoch :  20  Time:  1.268  Rel. Train L2 Loss :  0.08630270537402895  Rel. Test L2 Loss :  0.08781272977590561  Test L2 Loss :  0.12528483033180238  inv_L_scale:  [1.0, 1.0]
Epoch :  21  Time:  1.261  Rel. Train L2 Loss :  0.08569765167103874  Rel. Test L2 Loss :  0.0851450565457344  Test L2 Loss :  0.12184430480003357  inv_L_scale:  [1.0, 1.0]
Epoch :  22  Time:  1.267  Rel. Train L2 Loss :  0.08547929733991623  Rel. Test L2 Loss :  0.08749200135469437  Test L2 Loss :  0.12651482164859773  inv_L_scale:  [1.0, 1.0]
Epoch :  23  Time:  1.265  Rel. Train L2 Loss :  0.08530817512008879  Rel. Test L2 Loss :  0.08675924956798553  Test L2 Loss :  0.12366104155778884  inv_L_scale:  [1.0, 1.0]
Epoch :  24  Time:  1.265  Rel. Train L2 Loss :  0.08295466721057893  Rel. Test L2 Loss :  0.08937576115131378  Test L2 Loss :  0.1289135420322418  inv_L_scale:  [1.0, 1.0]
Epoch :  25  Time:  1.263  Rel. Train L2 Loss :  0.0843693451417817  Rel. Test L2 Loss :  0.08363090932369233  Test L2 Loss :  0.11989428341388703  inv_L_scale:  [1.0, 1.0]
Epoch :  26  Time:  1.265  Rel. Train L2 Loss :  0.08582167867157195  Rel. Test L2 Loss :  0.08435687243938446  Test L2 Loss :  0.1203817880153656  inv_L_scale:  [1.0, 1.0]
Epoch :  27  Time:  1.268  Rel. Train L2 Loss :  0.08249612622790867  Rel. Test L2 Loss :  0.08372339189052581  Test L2 Loss :  0.11981220126152038  inv_L_scale:  [1.0, 1.0]
Epoch :  28  Time:  1.27  Rel. Train L2 Loss :  0.08239774955643547  Rel. Test L2 Loss :  0.08856969147920608  Test L2 Loss :  0.1271175453066826  inv_L_scale:  [1.0, 1.0]
Epoch :  29  Time:  1.27  Rel. Train L2 Loss :  0.08433836238251792  Rel. Test L2 Loss :  0.08273797482252121  Test L2 Loss :  0.11882014095783233  inv_L_scale:  [1.0, 1.0]
Epoch :  30  Time:  1.269  Rel. Train L2 Loss :  0.08225842194424735  Rel. Test L2 Loss :  0.08409485638141632  Test L2 Loss :  0.1206428775191307  inv_L_scale:  [1.0, 1.0]
Epoch :  31  Time:  1.269  Rel. Train L2 Loss :  0.08414004564285278  Rel. Test L2 Loss :  0.08246929436922074  Test L2 Loss :  0.11828904062509536  inv_L_scale:  [1.0, 1.0]
Epoch :  32  Time:  1.264  Rel. Train L2 Loss :  0.08181009941630893  Rel. Test L2 Loss :  0.0830873391032219  Test L2 Loss :  0.11826888322830201  inv_L_scale:  [1.0, 1.0]
Epoch :  33  Time:  1.265  Rel. Train L2 Loss :  0.0815888097219997  Rel. Test L2 Loss :  0.08004256159067154  Test L2 Loss :  0.11475655317306518  inv_L_scale:  [1.0, 1.0]
Epoch :  34  Time:  1.261  Rel. Train L2 Loss :  0.07949053893486659  Rel. Test L2 Loss :  0.08097181409597397  Test L2 Loss :  0.11574540197849274  inv_L_scale:  [1.0, 1.0]
Epoch :  35  Time:  1.262  Rel. Train L2 Loss :  0.08251537832948896  Rel. Test L2 Loss :  0.08711599051952362  Test L2 Loss :  0.12434369206428528  inv_L_scale:  [1.0, 1.0]
Epoch :  36  Time:  1.267  Rel. Train L2 Loss :  0.08197477668523788  Rel. Test L2 Loss :  0.08131149023771286  Test L2 Loss :  0.11586316794157028  inv_L_scale:  [1.0, 1.0]
Epoch :  37  Time:  1.286  Rel. Train L2 Loss :  0.0802250539097521  Rel. Test L2 Loss :  0.08310221016407013  Test L2 Loss :  0.11898012757301331  inv_L_scale:  [1.0, 1.0]
Epoch :  38  Time:  1.311  Rel. Train L2 Loss :  0.08280495209826363  Rel. Test L2 Loss :  0.0814766377210617  Test L2 Loss :  0.11614583492279053  inv_L_scale:  [1.0, 1.0]
Epoch :  39  Time:  1.271  Rel. Train L2 Loss :  0.07934632766577933  Rel. Test L2 Loss :  0.0840089151263237  Test L2 Loss :  0.11947833150625228  inv_L_scale:  [1.0, 1.0]
Epoch :  40  Time:  1.269  Rel. Train L2 Loss :  0.07981217192278968  Rel. Test L2 Loss :  0.08030060231685639  Test L2 Loss :  0.11493495672941208  inv_L_scale:  [1.0, 1.0]
Epoch :  41  Time:  1.269  Rel. Train L2 Loss :  0.0790499288505978  Rel. Test L2 Loss :  0.08019326031208038  Test L2 Loss :  0.11474016904830933  inv_L_scale:  [1.0, 1.0]
Epoch :  42  Time:  1.265  Rel. Train L2 Loss :  0.0797306121720208  Rel. Test L2 Loss :  0.07901059180498123  Test L2 Loss :  0.1124949562549591  inv_L_scale:  [1.0, 1.0]
Epoch :  43  Time:  1.289  Rel. Train L2 Loss :  0.0791970803671413  Rel. Test L2 Loss :  0.07834081649780274  Test L2 Loss :  0.11235061079263688  inv_L_scale:  [1.0, 1.0]
Epoch :  44  Time:  1.264  Rel. Train L2 Loss :  0.07886505424976349  Rel. Test L2 Loss :  0.0788021668791771  Test L2 Loss :  0.11330253660678863  inv_L_scale:  [1.0, 1.0]
Epoch :  45  Time:  1.264  Rel. Train L2 Loss :  0.07853848417599996  Rel. Test L2 Loss :  0.07980546355247498  Test L2 Loss :  0.11408499121665955  inv_L_scale:  [1.0, 1.0]
Epoch :  46  Time:  1.262  Rel. Train L2 Loss :  0.07835437297821045  Rel. Test L2 Loss :  0.07797039717435837  Test L2 Loss :  0.11138133823871613  inv_L_scale:  [1.0, 1.0]
Epoch :  47  Time:  1.261  Rel. Train L2 Loss :  0.07762030767069923  Rel. Test L2 Loss :  0.07699736714363098  Test L2 Loss :  0.11051896393299103  inv_L_scale:  [1.0, 1.0]
Epoch :  48  Time:  1.26  Rel. Train L2 Loss :  0.07689633346266217  Rel. Test L2 Loss :  0.07935953319072724  Test L2 Loss :  0.11383237540721894  inv_L_scale:  [1.0, 1.0]
Epoch :  49  Time:  1.264  Rel. Train L2 Loss :  0.07782729201846653  Rel. Test L2 Loss :  0.07672183334827423  Test L2 Loss :  0.1098725762963295  inv_L_scale:  [1.0, 1.0]
Epoch :  50  Time:  1.264  Rel. Train L2 Loss :  0.07695249908500247  Rel. Test L2 Loss :  0.07930060684680938  Test L2 Loss :  0.11326092809438705  inv_L_scale:  [1.0, 1.0]
Epoch :  51  Time:  1.305  Rel. Train L2 Loss :  0.07709783903426594  Rel. Test L2 Loss :  0.07799407452344895  Test L2 Loss :  0.1117302331328392  inv_L_scale:  [1.0, 1.0]
Epoch :  52  Time:  1.286  Rel. Train L2 Loss :  0.07857554624478022  Rel. Test L2 Loss :  0.07898015230894088  Test L2 Loss :  0.1135012149810791  inv_L_scale:  [1.0, 1.0]
Epoch :  53  Time:  1.311  Rel. Train L2 Loss :  0.07658824013339148  Rel. Test L2 Loss :  0.07828035175800324  Test L2 Loss :  0.11190444201231003  inv_L_scale:  [1.0, 1.0]
Epoch :  54  Time:  1.273  Rel. Train L2 Loss :  0.07735542118549348  Rel. Test L2 Loss :  0.080084787607193  Test L2 Loss :  0.11567611753940582  inv_L_scale:  [1.0, 1.0]
Epoch :  55  Time:  1.281  Rel. Train L2 Loss :  0.07660733262697855  Rel. Test L2 Loss :  0.07951087206602096  Test L2 Loss :  0.11339419513940811  inv_L_scale:  [1.0, 1.0]
Epoch :  56  Time:  1.306  Rel. Train L2 Loss :  0.07703050308757359  Rel. Test L2 Loss :  0.07885403007268905  Test L2 Loss :  0.11268785327672959  inv_L_scale:  [1.0, 1.0]
Epoch :  57  Time:  1.288  Rel. Train L2 Loss :  0.07761375056372749  Rel. Test L2 Loss :  0.07718931823968887  Test L2 Loss :  0.11018484026193619  inv_L_scale:  [1.0, 1.0]
Epoch :  58  Time:  1.299  Rel. Train L2 Loss :  0.0759478066696061  Rel. Test L2 Loss :  0.07653736919164658  Test L2 Loss :  0.10926442623138427  inv_L_scale:  [1.0, 1.0]
Epoch :  59  Time:  1.323  Rel. Train L2 Loss :  0.07584146387047237  Rel. Test L2 Loss :  0.07749901503324509  Test L2 Loss :  0.11157465994358062  inv_L_scale:  [1.0, 1.0]
Epoch :  60  Time:  1.296  Rel. Train L2 Loss :  0.07627963324387868  Rel. Test L2 Loss :  0.07845972537994385  Test L2 Loss :  0.11190703451633453  inv_L_scale:  [1.0, 1.0]
Epoch :  61  Time:  1.27  Rel. Train L2 Loss :  0.0753857159614563  Rel. Test L2 Loss :  0.07422091007232666  Test L2 Loss :  0.10606599032878876  inv_L_scale:  [1.0, 1.0]
Epoch :  62  Time:  1.294  Rel. Train L2 Loss :  0.0753018926911884  Rel. Test L2 Loss :  0.07715637058019638  Test L2 Loss :  0.11038403689861298  inv_L_scale:  [1.0, 1.0]
Epoch :  63  Time:  1.272  Rel. Train L2 Loss :  0.07582741194301182  Rel. Test L2 Loss :  0.07839761674404144  Test L2 Loss :  0.11208890616893769  inv_L_scale:  [1.0, 1.0]
Epoch :  64  Time:  1.261  Rel. Train L2 Loss :  0.07528888195753097  Rel. Test L2 Loss :  0.07405614584684372  Test L2 Loss :  0.10595534443855285  inv_L_scale:  [1.0, 1.0]
Epoch :  65  Time:  1.257  Rel. Train L2 Loss :  0.07453306002749337  Rel. Test L2 Loss :  0.08153288394212722  Test L2 Loss :  0.11549440443515778  inv_L_scale:  [1.0, 1.0]
Epoch :  66  Time:  1.263  Rel. Train L2 Loss :  0.07515604767534467  Rel. Test L2 Loss :  0.07629766523838043  Test L2 Loss :  0.10901978552341461  inv_L_scale:  [1.0, 1.0]
Epoch :  67  Time:  1.266  Rel. Train L2 Loss :  0.07514813370174832  Rel. Test L2 Loss :  0.07795990347862243  Test L2 Loss :  0.1118335908651352  inv_L_scale:  [1.0, 1.0]
Epoch :  68  Time:  1.265  Rel. Train L2 Loss :  0.07366412136289809  Rel. Test L2 Loss :  0.07701247841119767  Test L2 Loss :  0.11051715165376663  inv_L_scale:  [1.0, 1.0]
Epoch :  69  Time:  1.261  Rel. Train L2 Loss :  0.0749325587352117  Rel. Test L2 Loss :  0.07582437008619308  Test L2 Loss :  0.10805570393800736  inv_L_scale:  [1.0, 1.0]
Epoch :  70  Time:  1.266  Rel. Train L2 Loss :  0.07339069972435633  Rel. Test L2 Loss :  0.07815145432949067  Test L2 Loss :  0.11156295120716095  inv_L_scale:  [1.0, 1.0]
Epoch :  71  Time:  1.27  Rel. Train L2 Loss :  0.07404938111702601  Rel. Test L2 Loss :  0.07512990862131119  Test L2 Loss :  0.10737122684717178  inv_L_scale:  [1.0, 1.0]
Epoch :  72  Time:  1.261  Rel. Train L2 Loss :  0.07385148614645004  Rel. Test L2 Loss :  0.07394584447145462  Test L2 Loss :  0.10566356837749481  inv_L_scale:  [1.0, 1.0]
Epoch :  73  Time:  1.266  Rel. Train L2 Loss :  0.07303251789675819  Rel. Test L2 Loss :  0.07647143185138702  Test L2 Loss :  0.10886397302150726  inv_L_scale:  [1.0, 1.0]
Epoch :  74  Time:  1.259  Rel. Train L2 Loss :  0.07339125944508447  Rel. Test L2 Loss :  0.0765757405757904  Test L2 Loss :  0.10945266276597977  inv_L_scale:  [1.0, 1.0]
Epoch :  75  Time:  1.262  Rel. Train L2 Loss :  0.07390860312514835  Rel. Test L2 Loss :  0.07358345806598664  Test L2 Loss :  0.10501207530498505  inv_L_scale:  [1.0, 1.0]
Epoch :  76  Time:  1.27  Rel. Train L2 Loss :  0.0727519275744756  Rel. Test L2 Loss :  0.08041136413812637  Test L2 Loss :  0.11483483731746674  inv_L_scale:  [1.0, 1.0]
Epoch :  77  Time:  1.265  Rel. Train L2 Loss :  0.07314007610082626  Rel. Test L2 Loss :  0.07414605677127838  Test L2 Loss :  0.10596526950597764  inv_L_scale:  [1.0, 1.0]
Epoch :  78  Time:  1.263  Rel. Train L2 Loss :  0.07228964989384015  Rel. Test L2 Loss :  0.07616782873868942  Test L2 Loss :  0.10861434161663056  inv_L_scale:  [1.0, 1.0]
Epoch :  79  Time:  1.261  Rel. Train L2 Loss :  0.0729858132534557  Rel. Test L2 Loss :  0.07513791173696518  Test L2 Loss :  0.10758685648441314  inv_L_scale:  [1.0, 1.0]
Epoch :  80  Time:  1.261  Rel. Train L2 Loss :  0.07231221493747499  Rel. Test L2 Loss :  0.07532928854227067  Test L2 Loss :  0.10803652316331863  inv_L_scale:  [1.0, 1.0]
Epoch :  81  Time:  1.256  Rel. Train L2 Loss :  0.07175082531240251  Rel. Test L2 Loss :  0.07518528044223785  Test L2 Loss :  0.10740860462188721  inv_L_scale:  [1.0, 1.0]
Epoch :  82  Time:  1.259  Rel. Train L2 Loss :  0.07260577195220523  Rel. Test L2 Loss :  0.07356457114219665  Test L2 Loss :  0.10486431777477265  inv_L_scale:  [1.0, 1.0]
Epoch :  83  Time:  1.262  Rel. Train L2 Loss :  0.0722729683915774  Rel. Test L2 Loss :  0.07545110285282135  Test L2 Loss :  0.10778443038463592  inv_L_scale:  [1.0, 1.0]
Epoch :  84  Time:  1.261  Rel. Train L2 Loss :  0.0721900201174948  Rel. Test L2 Loss :  0.0731879335641861  Test L2 Loss :  0.10460391968488693  inv_L_scale:  [1.0, 1.0]
Epoch :  85  Time:  1.259  Rel. Train L2 Loss :  0.07105223745107651  Rel. Test L2 Loss :  0.07291449785232544  Test L2 Loss :  0.10459754467010499  inv_L_scale:  [1.0, 1.0]
Epoch :  86  Time:  1.259  Rel. Train L2 Loss :  0.07162358406517241  Rel. Test L2 Loss :  0.07335066288709641  Test L2 Loss :  0.10500817060470581  inv_L_scale:  [1.0, 1.0]
Epoch :  87  Time:  1.261  Rel. Train L2 Loss :  0.07131082369221581  Rel. Test L2 Loss :  0.07135229587554931  Test L2 Loss :  0.10249077081680298  inv_L_scale:  [1.0, 1.0]
Epoch :  88  Time:  1.26  Rel. Train L2 Loss :  0.07038796037435531  Rel. Test L2 Loss :  0.074332095682621  Test L2 Loss :  0.1063999217748642  inv_L_scale:  [1.0, 1.0]
Epoch :  89  Time:  1.26  Rel. Train L2 Loss :  0.07090453075038063  Rel. Test L2 Loss :  0.07260100126266479  Test L2 Loss :  0.10415836274623871  inv_L_scale:  [1.0, 1.0]
Epoch :  90  Time:  1.26  Rel. Train L2 Loss :  0.07020385821660359  Rel. Test L2 Loss :  0.07424290984869003  Test L2 Loss :  0.10621057868003846  inv_L_scale:  [1.0, 1.0]
Epoch :  91  Time:  1.262  Rel. Train L2 Loss :  0.07099434650606579  Rel. Test L2 Loss :  0.07495036363601684  Test L2 Loss :  0.10722691625356674  inv_L_scale:  [1.0, 1.0]
Epoch :  92  Time:  1.26  Rel. Train L2 Loss :  0.0709925862815645  Rel. Test L2 Loss :  0.07140494883060455  Test L2 Loss :  0.10251026570796967  inv_L_scale:  [1.0, 1.0]
Epoch :  93  Time:  1.263  Rel. Train L2 Loss :  0.06970973935392168  Rel. Test L2 Loss :  0.07400733560323715  Test L2 Loss :  0.10580220222473144  inv_L_scale:  [1.0, 1.0]
Epoch :  94  Time:  1.26  Rel. Train L2 Loss :  0.06982556367913882  Rel. Test L2 Loss :  0.0701955422759056  Test L2 Loss :  0.10044956266880035  inv_L_scale:  [1.0, 1.0]
Epoch :  95  Time:  1.26  Rel. Train L2 Loss :  0.06968922413057752  Rel. Test L2 Loss :  0.07455534219741822  Test L2 Loss :  0.10670582592487335  inv_L_scale:  [1.0, 1.0]
Epoch :  96  Time:  1.265  Rel. Train L2 Loss :  0.06984402414825228  Rel. Test L2 Loss :  0.06878344088792801  Test L2 Loss :  0.09852270007133485  inv_L_scale:  [1.0, 1.0]
Epoch :  97  Time:  1.26  Rel. Train L2 Loss :  0.0693265900346968  Rel. Test L2 Loss :  0.07304122686386108  Test L2 Loss :  0.10464909315109253  inv_L_scale:  [1.0, 1.0]
Epoch :  98  Time:  1.26  Rel. Train L2 Loss :  0.06985617385970222  Rel. Test L2 Loss :  0.07231696546077729  Test L2 Loss :  0.1034560602903366  inv_L_scale:  [1.0, 1.0]
Epoch :  99  Time:  1.267  Rel. Train L2 Loss :  0.06960958550373714  Rel. Test L2 Loss :  0.07377570331096649  Test L2 Loss :  0.10534281313419341  inv_L_scale:  [1.0, 1.0]
Epoch :  100  Time:  1.268  Rel. Train L2 Loss :  0.06932853509982427  Rel. Test L2 Loss :  0.07186194449663162  Test L2 Loss :  0.10288957417011262  inv_L_scale:  [1.0, 1.0]
Epoch :  101  Time:  1.266  Rel. Train L2 Loss :  0.06887527777089013  Rel. Test L2 Loss :  0.07254937052726745  Test L2 Loss :  0.10353492736816407  inv_L_scale:  [1.0, 1.0]
Epoch :  102  Time:  1.267  Rel. Train L2 Loss :  0.06941235336992475  Rel. Test L2 Loss :  0.07295855522155761  Test L2 Loss :  0.10456511825323105  inv_L_scale:  [1.0, 1.0]
Epoch :  103  Time:  1.263  Rel. Train L2 Loss :  0.06917869842714734  Rel. Test L2 Loss :  0.0702639102935791  Test L2 Loss :  0.10108815670013428  inv_L_scale:  [1.0, 1.0]
Epoch :  104  Time:  1.267  Rel. Train L2 Loss :  0.06874702466858758  Rel. Test L2 Loss :  0.06982795149087906  Test L2 Loss :  0.0998747181892395  inv_L_scale:  [1.0, 1.0]
Epoch :  105  Time:  1.265  Rel. Train L2 Loss :  0.0680724576777882  Rel. Test L2 Loss :  0.07072754263877869  Test L2 Loss :  0.10070399433374405  inv_L_scale:  [1.0, 1.0]
Epoch :  106  Time:  1.261  Rel. Train L2 Loss :  0.06869160728322135  Rel. Test L2 Loss :  0.06984293520450592  Test L2 Loss :  0.10014295816421509  inv_L_scale:  [1.0, 1.0]
Epoch :  107  Time:  1.262  Rel. Train L2 Loss :  0.06789988434977001  Rel. Test L2 Loss :  0.07199611604213714  Test L2 Loss :  0.10294072091579437  inv_L_scale:  [1.0, 1.0]
Epoch :  108  Time:  1.264  Rel. Train L2 Loss :  0.0684601225455602  Rel. Test L2 Loss :  0.06928931653499604  Test L2 Loss :  0.09894345700740814  inv_L_scale:  [1.0, 1.0]
Epoch :  109  Time:  1.264  Rel. Train L2 Loss :  0.06835898594723808  Rel. Test L2 Loss :  0.06904771268367767  Test L2 Loss :  0.0989932495355606  inv_L_scale:  [1.0, 1.0]
Epoch :  110  Time:  1.264  Rel. Train L2 Loss :  0.06782173544168472  Rel. Test L2 Loss :  0.07124479442834854  Test L2 Loss :  0.10165845096111298  inv_L_scale:  [1.0, 1.0]
Epoch :  111  Time:  1.272  Rel. Train L2 Loss :  0.06745000956787003  Rel. Test L2 Loss :  0.06875081270933152  Test L2 Loss :  0.09842828691005706  inv_L_scale:  [1.0, 1.0]
Epoch :  112  Time:  1.27  Rel. Train L2 Loss :  0.0674703116218249  Rel. Test L2 Loss :  0.06773539960384369  Test L2 Loss :  0.09689309239387513  inv_L_scale:  [1.0, 1.0]
Epoch :  113  Time:  1.263  Rel. Train L2 Loss :  0.06754891882340114  Rel. Test L2 Loss :  0.06933291584253311  Test L2 Loss :  0.09920972853899002  inv_L_scale:  [1.0, 1.0]
Epoch :  114  Time:  1.263  Rel. Train L2 Loss :  0.06698551462756262  Rel. Test L2 Loss :  0.07033264309167862  Test L2 Loss :  0.1000808209180832  inv_L_scale:  [1.0, 1.0]
Epoch :  115  Time:  1.268  Rel. Train L2 Loss :  0.06733212947845459  Rel. Test L2 Loss :  0.06815598428249359  Test L2 Loss :  0.0975305125117302  inv_L_scale:  [1.0, 1.0]
Epoch :  116  Time:  1.264  Rel. Train L2 Loss :  0.06712771339548959  Rel. Test L2 Loss :  0.06918969184160233  Test L2 Loss :  0.09883093684911728  inv_L_scale:  [1.0, 1.0]
Epoch :  117  Time:  1.264  Rel. Train L2 Loss :  0.06710200273328357  Rel. Test L2 Loss :  0.06895744919776917  Test L2 Loss :  0.09862392455339432  inv_L_scale:  [1.0, 1.0]
Epoch :  118  Time:  1.266  Rel. Train L2 Loss :  0.06670044047964943  Rel. Test L2 Loss :  0.06993910044431687  Test L2 Loss :  0.09986404299736024  inv_L_scale:  [1.0, 1.0]
Epoch :  119  Time:  1.279  Rel. Train L2 Loss :  0.0670035105281406  Rel. Test L2 Loss :  0.06967847228050232  Test L2 Loss :  0.1000166916847229  inv_L_scale:  [1.0, 1.0]
Epoch :  120  Time:  1.267  Rel. Train L2 Loss :  0.06638654695616827  Rel. Test L2 Loss :  0.06824039310216903  Test L2 Loss :  0.09785968959331512  inv_L_scale:  [1.0, 1.0]
Epoch :  121  Time:  1.299  Rel. Train L2 Loss :  0.06668027667535675  Rel. Test L2 Loss :  0.06789463460445404  Test L2 Loss :  0.09731506884098053  inv_L_scale:  [1.0, 1.0]
Epoch :  122  Time:  1.29  Rel. Train L2 Loss :  0.06613702714443206  Rel. Test L2 Loss :  0.07406442761421203  Test L2 Loss :  0.10567061185836792  inv_L_scale:  [1.0, 1.0]
Epoch :  123  Time:  1.265  Rel. Train L2 Loss :  0.06624668508768082  Rel. Test L2 Loss :  0.06901839554309845  Test L2 Loss :  0.0982067620754242  inv_L_scale:  [1.0, 1.0]
Epoch :  124  Time:  1.278  Rel. Train L2 Loss :  0.06661422034104665  Rel. Test L2 Loss :  0.07035299003124237  Test L2 Loss :  0.1004021543264389  inv_L_scale:  [1.0, 1.0]
Epoch :  125  Time:  1.273  Rel. Train L2 Loss :  0.06643909475869603  Rel. Test L2 Loss :  0.07073931783437729  Test L2 Loss :  0.10117880016565323  inv_L_scale:  [1.0, 1.0]
Epoch :  126  Time:  1.27  Rel. Train L2 Loss :  0.06564528869258032  Rel. Test L2 Loss :  0.06726734101772308  Test L2 Loss :  0.09641328632831574  inv_L_scale:  [1.0, 1.0]
Epoch :  127  Time:  1.27  Rel. Train L2 Loss :  0.06526490734683142  Rel. Test L2 Loss :  0.0685914471745491  Test L2 Loss :  0.09810937583446502  inv_L_scale:  [1.0, 1.0]
Epoch :  128  Time:  1.271  Rel. Train L2 Loss :  0.06635349561770756  Rel. Test L2 Loss :  0.07027513802051544  Test L2 Loss :  0.10083903133869171  inv_L_scale:  [1.0, 1.0]
Epoch :  129  Time:  1.269  Rel. Train L2 Loss :  0.06591643853320016  Rel. Test L2 Loss :  0.06859919100999833  Test L2 Loss :  0.09854225039482117  inv_L_scale:  [1.0, 1.0]
Epoch :  130  Time:  1.265  Rel. Train L2 Loss :  0.06623000964522362  Rel. Test L2 Loss :  0.06830986320972443  Test L2 Loss :  0.09757818222045898  inv_L_scale:  [1.0, 1.0]
Epoch :  131  Time:  1.272  Rel. Train L2 Loss :  0.06606540464692645  Rel. Test L2 Loss :  0.06812070161104203  Test L2 Loss :  0.0974648779630661  inv_L_scale:  [1.0, 1.0]
Epoch :  132  Time:  1.265  Rel. Train L2 Loss :  0.06576283325751622  Rel. Test L2 Loss :  0.06963832288980484  Test L2 Loss :  0.09965324759483338  inv_L_scale:  [1.0, 1.0]
Epoch :  133  Time:  1.297  Rel. Train L2 Loss :  0.0648915394478374  Rel. Test L2 Loss :  0.06730625092983246  Test L2 Loss :  0.09632649809122086  inv_L_scale:  [1.0, 1.0]
Epoch :  134  Time:  1.308  Rel. Train L2 Loss :  0.06524289541774327  Rel. Test L2 Loss :  0.06888723134994507  Test L2 Loss :  0.09882912695407868  inv_L_scale:  [1.0, 1.0]
Epoch :  135  Time:  1.355  Rel. Train L2 Loss :  0.06547194384866291  Rel. Test L2 Loss :  0.06728577643632888  Test L2 Loss :  0.09660321384668351  inv_L_scale:  [1.0, 1.0]
Epoch :  136  Time:  1.324  Rel. Train L2 Loss :  0.06523153086503347  Rel. Test L2 Loss :  0.06947356700897217  Test L2 Loss :  0.09908859014511108  inv_L_scale:  [1.0, 1.0]
Epoch :  137  Time:  1.284  Rel. Train L2 Loss :  0.06479819572634167  Rel. Test L2 Loss :  0.06988810986280442  Test L2 Loss :  0.09973011791706085  inv_L_scale:  [1.0, 1.0]
Epoch :  138  Time:  1.309  Rel. Train L2 Loss :  0.06536465558740828  Rel. Test L2 Loss :  0.06831609398126602  Test L2 Loss :  0.09758845806121826  inv_L_scale:  [1.0, 1.0]
Epoch :  139  Time:  1.267  Rel. Train L2 Loss :  0.06508034729295306  Rel. Test L2 Loss :  0.06805798470973969  Test L2 Loss :  0.09775563925504685  inv_L_scale:  [1.0, 1.0]
Epoch :  140  Time:  1.272  Rel. Train L2 Loss :  0.06564248894651731  Rel. Test L2 Loss :  0.06892947316169738  Test L2 Loss :  0.09853608816862107  inv_L_scale:  [1.0, 1.0]
Epoch :  141  Time:  1.265  Rel. Train L2 Loss :  0.06560089502069685  Rel. Test L2 Loss :  0.06779214173555374  Test L2 Loss :  0.09686365514993668  inv_L_scale:  [1.0, 1.0]
Epoch :  142  Time:  1.279  Rel. Train L2 Loss :  0.06480347471104728  Rel. Test L2 Loss :  0.06781191259622574  Test L2 Loss :  0.09734685957431793  inv_L_scale:  [1.0, 1.0]
Epoch :  143  Time:  1.308  Rel. Train L2 Loss :  0.06439841647942861  Rel. Test L2 Loss :  0.06543009102344513  Test L2 Loss :  0.09350092679262162  inv_L_scale:  [1.0, 1.0]
Epoch :  144  Time:  1.269  Rel. Train L2 Loss :  0.06437221982412868  Rel. Test L2 Loss :  0.0674783256649971  Test L2 Loss :  0.09630039781332016  inv_L_scale:  [1.0, 1.0]
Epoch :  145  Time:  1.276  Rel. Train L2 Loss :  0.06479309575425254  Rel. Test L2 Loss :  0.06687594592571258  Test L2 Loss :  0.09587885916233063  inv_L_scale:  [1.0, 1.0]
Epoch :  146  Time:  1.348  Rel. Train L2 Loss :  0.06476775977346633  Rel. Test L2 Loss :  0.06693582653999329  Test L2 Loss :  0.0959827333688736  inv_L_scale:  [1.0, 1.0]
Epoch :  147  Time:  1.325  Rel. Train L2 Loss :  0.0640504198273023  Rel. Test L2 Loss :  0.06680419355630875  Test L2 Loss :  0.0954883199930191  inv_L_scale:  [1.0, 1.0]
Epoch :  148  Time:  1.29  Rel. Train L2 Loss :  0.06424745466974047  Rel. Test L2 Loss :  0.06675374269485473  Test L2 Loss :  0.09535232216119766  inv_L_scale:  [1.0, 1.0]
Epoch :  149  Time:  1.284  Rel. Train L2 Loss :  0.0644132560160425  Rel. Test L2 Loss :  0.06733537763357163  Test L2 Loss :  0.09651677787303925  inv_L_scale:  [1.0, 1.0]
Epoch :  150  Time:  1.332  Rel. Train L2 Loss :  0.0641147937377294  Rel. Test L2 Loss :  0.06789228647947311  Test L2 Loss :  0.0968379756808281  inv_L_scale:  [1.0, 1.0]
Epoch :  151  Time:  1.274  Rel. Train L2 Loss :  0.06404366006453832  Rel. Test L2 Loss :  0.06901190191507339  Test L2 Loss :  0.09899611413478851  inv_L_scale:  [1.0, 1.0]
Epoch :  152  Time:  1.326  Rel. Train L2 Loss :  0.06376563214593463  Rel. Test L2 Loss :  0.06664357781410217  Test L2 Loss :  0.09576164186000824  inv_L_scale:  [1.0, 1.0]
Epoch :  153  Time:  1.3  Rel. Train L2 Loss :  0.06377261257833905  Rel. Test L2 Loss :  0.0679122856259346  Test L2 Loss :  0.09714083790779114  inv_L_scale:  [1.0, 1.0]
Epoch :  154  Time:  1.309  Rel. Train L2 Loss :  0.06399636156029172  Rel. Test L2 Loss :  0.06652483642101288  Test L2 Loss :  0.09542477101087571  inv_L_scale:  [1.0, 1.0]
Epoch :  155  Time:  1.316  Rel. Train L2 Loss :  0.06365650347537465  Rel. Test L2 Loss :  0.06653747767210007  Test L2 Loss :  0.09502019941806793  inv_L_scale:  [1.0, 1.0]
Epoch :  156  Time:  1.288  Rel. Train L2 Loss :  0.06414114624261856  Rel. Test L2 Loss :  0.0687748646736145  Test L2 Loss :  0.09789481461048126  inv_L_scale:  [1.0, 1.0]
Epoch :  157  Time:  1.294  Rel. Train L2 Loss :  0.06377665340900421  Rel. Test L2 Loss :  0.06462920039892196  Test L2 Loss :  0.09233794301748276  inv_L_scale:  [1.0, 1.0]
Epoch :  158  Time:  1.338  Rel. Train L2 Loss :  0.06336540324820412  Rel. Test L2 Loss :  0.06542493999004365  Test L2 Loss :  0.09364422559738159  inv_L_scale:  [1.0, 1.0]
Epoch :  159  Time:  1.307  Rel. Train L2 Loss :  0.06361222285363409  Rel. Test L2 Loss :  0.06812049657106399  Test L2 Loss :  0.09720056474208832  inv_L_scale:  [1.0, 1.0]
Epoch :  160  Time:  1.276  Rel. Train L2 Loss :  0.06382099390029908  Rel. Test L2 Loss :  0.07146889835596085  Test L2 Loss :  0.10182923316955567  inv_L_scale:  [1.0, 1.0]
Epoch :  161  Time:  1.267  Rel. Train L2 Loss :  0.06371956311994129  Rel. Test L2 Loss :  0.06595756739377975  Test L2 Loss :  0.09434111982584  inv_L_scale:  [1.0, 1.0]
Epoch :  162  Time:  1.266  Rel. Train L2 Loss :  0.06340669562419256  Rel. Test L2 Loss :  0.06713990718126298  Test L2 Loss :  0.09601812481880188  inv_L_scale:  [1.0, 1.0]
Epoch :  163  Time:  1.32  Rel. Train L2 Loss :  0.06321842463480101  Rel. Test L2 Loss :  0.06656175911426544  Test L2 Loss :  0.09526565879583358  inv_L_scale:  [1.0, 1.0]
Epoch :  164  Time:  1.278  Rel. Train L2 Loss :  0.06316923942830828  Rel. Test L2 Loss :  0.06568582326173783  Test L2 Loss :  0.09380950897932053  inv_L_scale:  [1.0, 1.0]
Epoch :  165  Time:  1.261  Rel. Train L2 Loss :  0.06316675990819931  Rel. Test L2 Loss :  0.06537654310464859  Test L2 Loss :  0.09333341360092164  inv_L_scale:  [1.0, 1.0]
Epoch :  166  Time:  1.265  Rel. Train L2 Loss :  0.06298932376835081  Rel. Test L2 Loss :  0.06665646314620971  Test L2 Loss :  0.09485317885875702  inv_L_scale:  [1.0, 1.0]
Epoch :  167  Time:  1.267  Rel. Train L2 Loss :  0.06323054833544625  Rel. Test L2 Loss :  0.06533292710781097  Test L2 Loss :  0.09341933846473693  inv_L_scale:  [1.0, 1.0]
Epoch :  168  Time:  1.266  Rel. Train L2 Loss :  0.06291561635004149  Rel. Test L2 Loss :  0.06581068813800811  Test L2 Loss :  0.09432776033878326  inv_L_scale:  [1.0, 1.0]
Epoch :  169  Time:  1.264  Rel. Train L2 Loss :  0.06305613148543569  Rel. Test L2 Loss :  0.06546365708112717  Test L2 Loss :  0.09377735137939452  inv_L_scale:  [1.0, 1.0]
Epoch :  170  Time:  1.266  Rel. Train L2 Loss :  0.06271093401643965  Rel. Test L2 Loss :  0.06527639895677567  Test L2 Loss :  0.09327401757240296  inv_L_scale:  [1.0, 1.0]
Epoch :  171  Time:  1.265  Rel. Train L2 Loss :  0.06262976345088747  Rel. Test L2 Loss :  0.06568558752536774  Test L2 Loss :  0.09386989057064056  inv_L_scale:  [1.0, 1.0]
Epoch :  172  Time:  1.275  Rel. Train L2 Loss :  0.0632260775897238  Rel. Test L2 Loss :  0.06635603249073029  Test L2 Loss :  0.09518486976623536  inv_L_scale:  [1.0, 1.0]
Epoch :  173  Time:  1.313  Rel. Train L2 Loss :  0.06311274402671391  Rel. Test L2 Loss :  0.06651585221290589  Test L2 Loss :  0.09480046540498734  inv_L_scale:  [1.0, 1.0]
Epoch :  174  Time:  1.294  Rel. Train L2 Loss :  0.06280003901984957  Rel. Test L2 Loss :  0.06464659124612808  Test L2 Loss :  0.09232803583145141  inv_L_scale:  [1.0, 1.0]
Epoch :  175  Time:  1.264  Rel. Train L2 Loss :  0.06243386172586017  Rel. Test L2 Loss :  0.06592419892549514  Test L2 Loss :  0.09448421597480774  inv_L_scale:  [1.0, 1.0]
Epoch :  176  Time:  1.274  Rel. Train L2 Loss :  0.06264757295449574  Rel. Test L2 Loss :  0.06465924888849259  Test L2 Loss :  0.0924216490983963  inv_L_scale:  [1.0, 1.0]
Epoch :  177  Time:  1.274  Rel. Train L2 Loss :  0.06279485729005602  Rel. Test L2 Loss :  0.06444094538688659  Test L2 Loss :  0.09220951825380325  inv_L_scale:  [1.0, 1.0]
Epoch :  178  Time:  1.303  Rel. Train L2 Loss :  0.06259098278151617  Rel. Test L2 Loss :  0.06468469887971878  Test L2 Loss :  0.09284345299005509  inv_L_scale:  [1.0, 1.0]
Epoch :  179  Time:  1.263  Rel. Train L2 Loss :  0.06266693691412607  Rel. Test L2 Loss :  0.0662360754609108  Test L2 Loss :  0.09481161475181579  inv_L_scale:  [1.0, 1.0]
Epoch :  180  Time:  1.261  Rel. Train L2 Loss :  0.06239803317520354  Rel. Test L2 Loss :  0.06587785333395005  Test L2 Loss :  0.09422428131103516  inv_L_scale:  [1.0, 1.0]
Epoch :  181  Time:  1.267  Rel. Train L2 Loss :  0.06245128161377377  Rel. Test L2 Loss :  0.06600526213645935  Test L2 Loss :  0.09433512568473816  inv_L_scale:  [1.0, 1.0]
Epoch :  182  Time:  1.266  Rel. Train L2 Loss :  0.06247700774007373  Rel. Test L2 Loss :  0.06473140746355056  Test L2 Loss :  0.09250130951404571  inv_L_scale:  [1.0, 1.0]
Epoch :  183  Time:  1.262  Rel. Train L2 Loss :  0.062182302491532435  Rel. Test L2 Loss :  0.06522403359413147  Test L2 Loss :  0.09357748329639434  inv_L_scale:  [1.0, 1.0]
Epoch :  184  Time:  1.259  Rel. Train L2 Loss :  0.062138275139861636  Rel. Test L2 Loss :  0.06611026138067246  Test L2 Loss :  0.09467272639274597  inv_L_scale:  [1.0, 1.0]
Epoch :  185  Time:  1.264  Rel. Train L2 Loss :  0.062097913225491845  Rel. Test L2 Loss :  0.06452963173389435  Test L2 Loss :  0.09252064287662506  inv_L_scale:  [1.0, 1.0]
Epoch :  186  Time:  1.259  Rel. Train L2 Loss :  0.061807839804225495  Rel. Test L2 Loss :  0.06511330425739288  Test L2 Loss :  0.09360603481531143  inv_L_scale:  [1.0, 1.0]
Epoch :  187  Time:  1.261  Rel. Train L2 Loss :  0.061990733014212714  Rel. Test L2 Loss :  0.06554760962724686  Test L2 Loss :  0.09345394313335419  inv_L_scale:  [1.0, 1.0]
Epoch :  188  Time:  1.277  Rel. Train L2 Loss :  0.06177832977639304  Rel. Test L2 Loss :  0.06488909363746644  Test L2 Loss :  0.09259391903877258  inv_L_scale:  [1.0, 1.0]
Epoch :  189  Time:  1.273  Rel. Train L2 Loss :  0.06212887210978402  Rel. Test L2 Loss :  0.06515222191810607  Test L2 Loss :  0.0930017265677452  inv_L_scale:  [1.0, 1.0]
Epoch :  190  Time:  1.261  Rel. Train L2 Loss :  0.06188103293379148  Rel. Test L2 Loss :  0.06507193565368652  Test L2 Loss :  0.09302101522684098  inv_L_scale:  [1.0, 1.0]
Epoch :  191  Time:  1.266  Rel. Train L2 Loss :  0.06162608805629942  Rel. Test L2 Loss :  0.06643463611602783  Test L2 Loss :  0.09481155574321747  inv_L_scale:  [1.0, 1.0]
Epoch :  192  Time:  1.26  Rel. Train L2 Loss :  0.06164376500580046  Rel. Test L2 Loss :  0.06403262794017792  Test L2 Loss :  0.09172262877225876  inv_L_scale:  [1.0, 1.0]
Epoch :  193  Time:  1.259  Rel. Train L2 Loss :  0.06185606545872158  Rel. Test L2 Loss :  0.06549498200416565  Test L2 Loss :  0.09367119938135147  inv_L_scale:  [1.0, 1.0]
Epoch :  194  Time:  1.261  Rel. Train L2 Loss :  0.061812562064992055  Rel. Test L2 Loss :  0.06347243249416351  Test L2 Loss :  0.09111189395189286  inv_L_scale:  [1.0, 1.0]
Epoch :  195  Time:  1.271  Rel. Train L2 Loss :  0.06178464690844218  Rel. Test L2 Loss :  0.06278437197208404  Test L2 Loss :  0.08982549726963043  inv_L_scale:  [1.0, 1.0]
Epoch :  196  Time:  1.263  Rel. Train L2 Loss :  0.06145583030250337  Rel. Test L2 Loss :  0.06519968211650848  Test L2 Loss :  0.09355873942375183  inv_L_scale:  [1.0, 1.0]
Epoch :  197  Time:  1.259  Rel. Train L2 Loss :  0.061656734380457136  Rel. Test L2 Loss :  0.06471122533082962  Test L2 Loss :  0.09276679337024689  inv_L_scale:  [1.0, 1.0]
Epoch :  198  Time:  1.26  Rel. Train L2 Loss :  0.06175026873747508  Rel. Test L2 Loss :  0.06424757838249207  Test L2 Loss :  0.09184686988592147  inv_L_scale:  [1.0, 1.0]
Epoch :  199  Time:  1.258  Rel. Train L2 Loss :  0.06197636723518372  Rel. Test L2 Loss :  0.06472685933113098  Test L2 Loss :  0.09257129788398742  inv_L_scale:  [1.0, 1.0]
Epoch :  200  Time:  1.256  Rel. Train L2 Loss :  0.061060420142279734  Rel. Test L2 Loss :  0.06420600771903992  Test L2 Loss :  0.09171194314956665  inv_L_scale:  [1.0, 1.0]
Epoch :  201  Time:  1.259  Rel. Train L2 Loss :  0.061236842572689056  Rel. Test L2 Loss :  0.06373872458934784  Test L2 Loss :  0.09125869989395141  inv_L_scale:  [1.0, 1.0]
Epoch :  202  Time:  1.258  Rel. Train L2 Loss :  0.06107403662469652  Rel. Test L2 Loss :  0.06369383484125138  Test L2 Loss :  0.09112054139375686  inv_L_scale:  [1.0, 1.0]
Epoch :  203  Time:  1.26  Rel. Train L2 Loss :  0.06120170215765635  Rel. Test L2 Loss :  0.06427159547805786  Test L2 Loss :  0.09187586486339569  inv_L_scale:  [1.0, 1.0]
Epoch :  204  Time:  1.26  Rel. Train L2 Loss :  0.061367212169700196  Rel. Test L2 Loss :  0.06373129785060883  Test L2 Loss :  0.09117598682641984  inv_L_scale:  [1.0, 1.0]
Epoch :  205  Time:  1.258  Rel. Train L2 Loss :  0.06106435043944253  Rel. Test L2 Loss :  0.0648758551478386  Test L2 Loss :  0.09265947341918945  inv_L_scale:  [1.0, 1.0]
Epoch :  206  Time:  1.259  Rel. Train L2 Loss :  0.06131274895535575  Rel. Test L2 Loss :  0.06569750487804413  Test L2 Loss :  0.09400132298469543  inv_L_scale:  [1.0, 1.0]
Epoch :  207  Time:  1.275  Rel. Train L2 Loss :  0.06125887501570913  Rel. Test L2 Loss :  0.06419522106647492  Test L2 Loss :  0.09191145211458206  inv_L_scale:  [1.0, 1.0]
Epoch :  208  Time:  1.263  Rel. Train L2 Loss :  0.061039278474118976  Rel. Test L2 Loss :  0.0643381205201149  Test L2 Loss :  0.09243918418884277  inv_L_scale:  [1.0, 1.0]
Epoch :  209  Time:  1.266  Rel. Train L2 Loss :  0.06101188984182146  Rel. Test L2 Loss :  0.0640382844209671  Test L2 Loss :  0.09193478405475616  inv_L_scale:  [1.0, 1.0]
Epoch :  210  Time:  1.266  Rel. Train L2 Loss :  0.06077816476424535  Rel. Test L2 Loss :  0.06329423755407333  Test L2 Loss :  0.09052520632743835  inv_L_scale:  [1.0, 1.0]
Epoch :  211  Time:  1.271  Rel. Train L2 Loss :  0.06081525100602044  Rel. Test L2 Loss :  0.0636230131983757  Test L2 Loss :  0.09106455713510514  inv_L_scale:  [1.0, 1.0]
Epoch :  212  Time:  1.264  Rel. Train L2 Loss :  0.06083908968501621  Rel. Test L2 Loss :  0.06365328431129455  Test L2 Loss :  0.09134126543998718  inv_L_scale:  [1.0, 1.0]
Epoch :  213  Time:  1.267  Rel. Train L2 Loss :  0.060896099325683385  Rel. Test L2 Loss :  0.06437194138765336  Test L2 Loss :  0.09253931879997253  inv_L_scale:  [1.0, 1.0]
Epoch :  214  Time:  1.269  Rel. Train L2 Loss :  0.060837164024511975  Rel. Test L2 Loss :  0.06274146378040314  Test L2 Loss :  0.08980237483978272  inv_L_scale:  [1.0, 1.0]
Epoch :  215  Time:  1.263  Rel. Train L2 Loss :  0.06062418974108166  Rel. Test L2 Loss :  0.0630325037240982  Test L2 Loss :  0.09009887874126435  inv_L_scale:  [1.0, 1.0]
Epoch :  216  Time:  1.261  Rel. Train L2 Loss :  0.06054129014412562  Rel. Test L2 Loss :  0.06611110121011735  Test L2 Loss :  0.09439776688814164  inv_L_scale:  [1.0, 1.0]
Epoch :  217  Time:  1.262  Rel. Train L2 Loss :  0.060577317741182114  Rel. Test L2 Loss :  0.06336546778678893  Test L2 Loss :  0.09069481611251831  inv_L_scale:  [1.0, 1.0]
Epoch :  218  Time:  1.296  Rel. Train L2 Loss :  0.0605652650197347  Rel. Test L2 Loss :  0.06290932059288025  Test L2 Loss :  0.09014954268932343  inv_L_scale:  [1.0, 1.0]
Epoch :  219  Time:  1.26  Rel. Train L2 Loss :  0.060407320145103666  Rel. Test L2 Loss :  0.06331490725278854  Test L2 Loss :  0.09072208642959595  inv_L_scale:  [1.0, 1.0]
Epoch :  220  Time:  1.259  Rel. Train L2 Loss :  0.0607479089167383  Rel. Test L2 Loss :  0.0640495640039444  Test L2 Loss :  0.09177067816257477  inv_L_scale:  [1.0, 1.0]
Epoch :  221  Time:  1.275  Rel. Train L2 Loss :  0.060608813597096335  Rel. Test L2 Loss :  0.06293611913919449  Test L2 Loss :  0.09002951800823211  inv_L_scale:  [1.0, 1.0]
Epoch :  222  Time:  1.269  Rel. Train L2 Loss :  0.06026881597108311  Rel. Test L2 Loss :  0.06416532278060913  Test L2 Loss :  0.09194668918848038  inv_L_scale:  [1.0, 1.0]
Epoch :  223  Time:  1.262  Rel. Train L2 Loss :  0.06064100510544247  Rel. Test L2 Loss :  0.06434773564338685  Test L2 Loss :  0.0922116720676422  inv_L_scale:  [1.0, 1.0]
Epoch :  224  Time:  1.264  Rel. Train L2 Loss :  0.060413081579738195  Rel. Test L2 Loss :  0.06287402927875518  Test L2 Loss :  0.08989441126585007  inv_L_scale:  [1.0, 1.0]
Epoch :  225  Time:  1.265  Rel. Train L2 Loss :  0.060308947248591316  Rel. Test L2 Loss :  0.06449626564979553  Test L2 Loss :  0.09217768073081971  inv_L_scale:  [1.0, 1.0]
Epoch :  226  Time:  1.274  Rel. Train L2 Loss :  0.06058056049876743  Rel. Test L2 Loss :  0.0638822478055954  Test L2 Loss :  0.09179181933403015  inv_L_scale:  [1.0, 1.0]
Epoch :  227  Time:  1.268  Rel. Train L2 Loss :  0.06007580298516486  Rel. Test L2 Loss :  0.06343426883220672  Test L2 Loss :  0.09086202055215836  inv_L_scale:  [1.0, 1.0]
Epoch :  228  Time:  1.264  Rel. Train L2 Loss :  0.06022534946600596  Rel. Test L2 Loss :  0.06338714927434921  Test L2 Loss :  0.09059357047080993  inv_L_scale:  [1.0, 1.0]
Epoch :  229  Time:  1.267  Rel. Train L2 Loss :  0.05998960180415047  Rel. Test L2 Loss :  0.06290332049131393  Test L2 Loss :  0.09020820945501327  inv_L_scale:  [1.0, 1.0]
Epoch :  230  Time:  1.271  Rel. Train L2 Loss :  0.0604877028034793  Rel. Test L2 Loss :  0.06381115525960922  Test L2 Loss :  0.09114956736564636  inv_L_scale:  [1.0, 1.0]
Epoch :  231  Time:  1.285  Rel. Train L2 Loss :  0.06007909218470255  Rel. Test L2 Loss :  0.06310832023620605  Test L2 Loss :  0.09027341604232789  inv_L_scale:  [1.0, 1.0]
Epoch :  232  Time:  1.269  Rel. Train L2 Loss :  0.06013418384724193  Rel. Test L2 Loss :  0.06321760773658752  Test L2 Loss :  0.09052286028862  inv_L_scale:  [1.0, 1.0]
Epoch :  233  Time:  1.285  Rel. Train L2 Loss :  0.0603813930021392  Rel. Test L2 Loss :  0.06316810250282287  Test L2 Loss :  0.09014464110136032  inv_L_scale:  [1.0, 1.0]
Epoch :  234  Time:  1.277  Rel. Train L2 Loss :  0.059986025856600865  Rel. Test L2 Loss :  0.06328905284404755  Test L2 Loss :  0.0907641065120697  inv_L_scale:  [1.0, 1.0]
Epoch :  235  Time:  1.274  Rel. Train L2 Loss :  0.060037828849421604  Rel. Test L2 Loss :  0.0628204095363617  Test L2 Loss :  0.0896677976846695  inv_L_scale:  [1.0, 1.0]
Epoch :  236  Time:  1.28  Rel. Train L2 Loss :  0.05996050311459435  Rel. Test L2 Loss :  0.06388507157564163  Test L2 Loss :  0.09154681921005249  inv_L_scale:  [1.0, 1.0]
Epoch :  237  Time:  1.279  Rel. Train L2 Loss :  0.05976007474793328  Rel. Test L2 Loss :  0.06307350307703018  Test L2 Loss :  0.09033124208450317  inv_L_scale:  [1.0, 1.0]
Epoch :  238  Time:  1.265  Rel. Train L2 Loss :  0.059896254738171895  Rel. Test L2 Loss :  0.06309292286634445  Test L2 Loss :  0.09030704081058502  inv_L_scale:  [1.0, 1.0]
Epoch :  239  Time:  1.282  Rel. Train L2 Loss :  0.05986383080482483  Rel. Test L2 Loss :  0.0618285596370697  Test L2 Loss :  0.0884750896692276  inv_L_scale:  [1.0, 1.0]
Epoch :  240  Time:  1.261  Rel. Train L2 Loss :  0.05975687791903814  Rel. Test L2 Loss :  0.0633306148648262  Test L2 Loss :  0.09062987864017487  inv_L_scale:  [1.0, 1.0]