{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.5878, -0.3825, -1.5335,  ...,  1.7934,  0.3629, -0.8203],\n",
      "         [ 0.0000, -1.7480, -1.3370,  ...,  0.1800, -1.0036, -0.1825],\n",
      "         [ 0.0000,  0.0000, -0.5698,  ..., -0.4317, -0.6889,  0.5475],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.2098,  1.1672,  0.6841],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.2985,  0.9803],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.3093]],\n",
      "\n",
      "        [[ 1.0673,  1.6178,  1.7278,  ...,  1.2254,  0.5577, -1.6134],\n",
      "         [ 0.0000, -1.3760, -1.8791,  ..., -2.2858, -0.6441, -1.3165],\n",
      "         [ 0.0000,  0.0000,  3.0263,  ...,  0.6544, -0.0651,  0.1031],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -0.2165, -0.0347,  0.3096],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.7430,  0.4925],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.7092]],\n",
      "\n",
      "        [[ 0.8401, -0.8062, -0.9149,  ...,  0.4549, -0.9444, -0.0154],\n",
      "         [ 0.0000, -1.0263, -1.4823,  ..., -0.8108,  0.2351, -0.3099],\n",
      "         [ 0.0000,  0.0000,  0.7204,  ..., -1.3533, -1.1763,  0.6997],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.4272,  0.6369,  1.2527],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0269, -0.7496],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0772]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.8643, -0.2775, -1.3914,  ..., -0.0496, -1.6427,  0.0860],\n",
      "         [ 0.0000, -2.0295,  0.3593,  ..., -0.4681, -0.5330,  0.2741],\n",
      "         [ 0.0000,  0.0000, -0.3238,  ..., -0.2834, -0.7267,  0.3228],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.9314, -0.8689,  0.8944],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.4778,  2.2055],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.3826]],\n",
      "\n",
      "        [[-2.1680, -0.9048, -0.1989,  ..., -0.9445, -0.5864, -1.5595],\n",
      "         [ 0.0000, -0.7108,  0.2178,  ..., -0.1846,  0.0194,  0.5997],\n",
      "         [ 0.0000,  0.0000,  1.1346,  ...,  0.9765,  1.1029, -0.3897],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.2799,  0.4358,  0.5349],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  1.8947,  0.4781],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.9350]],\n",
      "\n",
      "        [[ 1.4154, -0.9493,  0.0852,  ...,  0.5404, -0.8709,  0.4391],\n",
      "         [ 0.0000, -0.1001, -0.7253,  ...,  1.4914,  0.7401, -0.2057],\n",
      "         [ 0.0000,  0.0000, -1.0002,  ...,  0.5110,  1.0805, -1.0530],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -1.5700,  1.0020, -1.8448],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.1506,  0.2611],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.2647]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "M=100\n",
    "N = 100\n",
    "num_upper_elements = N * (N + 1) // 2\n",
    "upper_triangular_elements = torch.randn(M,num_upper_elements)\n",
    "\n",
    "# 创建一个零矩阵\n",
    "A = torch.zeros(M,N, N)\n",
    "\n",
    "\n",
    "indices = torch.triu_indices(N,N)\n",
    "\n",
    "# 填充上三角部分，利用广播\n",
    "A[:, indices[0], indices[1]] = upper_triangular_elements\n",
    "\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_in.shape: (1024, 421, 421)\n",
      "data_out.shape (1024, 421, 421)\n",
      "x_train.shape:  torch.Size([800, 961, 3])\n",
      "y_train.shape:  torch.Size([800, 961, 1])\n",
      "Start SVD with data shape:  (800, 961)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from timeit import default_timer\n",
    "from scipy.io import loadmat\n",
    "import yaml\n",
    "import gc\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "\n",
    "from models import  newHGkNN_train, compute_2dFourier_bases, compute_2dpca_bases, compute_2dFourier_cbases, count_params\n",
    "\n",
    "from models.myGkNN11 import newHGkNN\n",
    "\n",
    "torch.set_printoptions(precision=16)\n",
    "\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "###################################\n",
    "# load configs\n",
    "###################################\n",
    "with open('config.yml', 'r', encoding='utf-8') as f:\n",
    "    config = yaml.full_load(f)\n",
    "\n",
    "config = config[\"Darcy_HGkNN\"]\n",
    "config = dict(config)\n",
    "config_data, config_model, config_train = (\n",
    "    config[\"data\"],\n",
    "    config[\"model\"],\n",
    "    config[\"train\"],\n",
    ")\n",
    "downsample_ratio = config_data[\"downsample_ratio\"]\n",
    "L = config_data[\"L\"]\n",
    "n_train = config_data[\"n_train\"]\n",
    "n_test = config_data[\"n_test\"]\n",
    "device = torch.device(config[\"train\"][\"device\"])\n",
    "\n",
    "\n",
    "###################################\n",
    "# load data\n",
    "###################################\n",
    "# data_path = \"../data/darcy_2d/piececonst_r421_N1024_smooth1\"\n",
    "# data1 = loadmat(data_path)\n",
    "# coeff1 = data1[\"coeff\"]\n",
    "# sol1 = data1[\"sol\"]\n",
    "# del data1\n",
    "# data_path = \"../data/darcy_2d/piececonst_r421_N1024_smooth2\"\n",
    "# data2 = loadmat(data_path)\n",
    "# coeff2 = data2[\"coeff\"][:300,:,:]\n",
    "# sol2 = data2[\"sol\"][:300,:,:]\n",
    "# del data2\n",
    "# gc.collect()\n",
    "\n",
    "# data_in = np.vstack((coeff1, coeff2))  # shape: 2048,421,421\n",
    "# data_out = np.vstack((sol1, sol2))     # shape: 2048,421,421\n",
    "\n",
    "data_path = \"../data/darcy_2d/piececonst_r421_N1024_smooth1\"\n",
    "data1 = loadmat(data_path)\n",
    "\n",
    "data_in = data1[\"coeff\"]\n",
    "data_out = data1[\"sol\"]\n",
    "# data_in = np.array([np.rot90(data_out[i,:,:], k=-1) for i in range(data_out.shape[0])])\n",
    "# data_out = np.array([np.rot90(data_in[i,:,:], k=-1) for i in range(data_in.shape[0])])\n",
    "print(\"data_in.shape:\" , data_in.shape)\n",
    "print(\"data_out.shape\", data_out.shape)\n",
    "\n",
    "Np_ref = data_in.shape[1]\n",
    "grid_1d = np.linspace(0, L, Np_ref)\n",
    "grid_x, grid_y = np.meshgrid(grid_1d, grid_1d)\n",
    "\n",
    "data_in_ds = data_in[0:n_train, 0::downsample_ratio, 0::downsample_ratio]\n",
    "grid_x_ds = grid_x[0::downsample_ratio, 0::downsample_ratio]\n",
    "grid_y_ds = grid_y[0::downsample_ratio, 0::downsample_ratio]\n",
    "data_out_ds = data_out[0:n_train, 0::downsample_ratio, 0::downsample_ratio]\n",
    "\n",
    "# x_train, y_train are [n_data, n_x, n_channel] arrays\n",
    "x_train = torch.from_numpy(\n",
    "    np.stack(\n",
    "        (\n",
    "            data_in_ds,\n",
    "            np.tile(grid_x_ds, (n_train, 1, 1)),\n",
    "            np.tile(grid_y_ds, (n_train, 1, 1)),\n",
    "        ),\n",
    "        axis=-1,\n",
    "    ).astype(np.float32)\n",
    ")\n",
    "y_train = torch.from_numpy(data_out_ds[:, :, :, np.newaxis].astype(np.float32))\n",
    "# x_test, y_test are [n_data, n_x, n_channel] arrays\n",
    "x_test = torch.from_numpy(\n",
    "    np.stack(\n",
    "        (\n",
    "            data_in[-n_test:, 0::downsample_ratio, 0::downsample_ratio],\n",
    "            np.tile(grid_x[0::downsample_ratio, 0::downsample_ratio], (n_test, 1, 1)),\n",
    "            np.tile(grid_y[0::downsample_ratio, 0::downsample_ratio], (n_test, 1, 1)),\n",
    "        ),\n",
    "        axis=-1,\n",
    "    ).astype(np.float32)\n",
    ")\n",
    "y_test = torch.from_numpy(\n",
    "    data_out[-n_test:, 0::downsample_ratio, 0::downsample_ratio, np.newaxis].astype(\n",
    "        np.float32\n",
    "    )\n",
    ")\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], -1, x_train.shape[-1])   # shape: 800,11236,3  (11236 = 106*106 , 106-1 = (421-1) /4)\n",
    "x_test = x_test.reshape(x_test.shape[0], -1, x_test.shape[-1])\n",
    "y_train = y_train.reshape(y_train.shape[0], -1, y_train.shape[-1])   # shape: 800,11236,1\n",
    "y_test = y_test.reshape(y_test.shape[0], -1, y_test.shape[-1])\n",
    "print(\"x_train.shape: \",x_train.shape)\n",
    "print(\"y_train.shape: \",y_train.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################################\n",
    "#compute pca bases\n",
    "####################################\n",
    "k_max = 512\n",
    "Np = (Np_ref + downsample_ratio - 1) // downsample_ratio\n",
    "pca_data_in = data_in_ds.reshape((data_in_ds.shape[0], -1))[:800,:]\n",
    "pca_data_out = data_out_ds.reshape((data_out_ds.shape[0], -1))[:800,:]\n",
    "# if config_model[\"pca_include_input\"]:\n",
    "#     pca_data = np.vstack(\n",
    "#         (pca_data, data_in_ds.reshape((data_in_ds.shape[0], -1)))\n",
    "#     )\n",
    "# if config_model[\"pca_include_grid\"]:\n",
    "#     n_grid = 1\n",
    "#     pca_data = np.vstack((pca_data, np.tile(grid_x_ds, (n_grid, 1))))\n",
    "#     pca_data = np.vstack((pca_data, np.tile(grid_y_ds, (n_grid, 1))))\n",
    "\n",
    "# percentage = 0.1\n",
    "# mask1 = torch.rand(pca_data_in.shape) > percentage\n",
    "# mask2 = torch.rand(pca_data_out.shape) > percentage\n",
    "# pca_data_in = (torch.from_numpy(pca_data_in)*mask1).numpy()\n",
    "# pca_data_out = (torch.from_numpy(pca_data_out)*mask2).numpy()\n",
    "\n",
    "\n",
    "print(\"Start SVD with data shape: \", pca_data_out.shape, flush = True)\n",
    "\n",
    "bases_pca_in, wbases_pca_in = compute_2dpca_bases(Np , k_max , L,  pca_data_in)\n",
    "bases_pca_in, wbases_pca_in = bases_pca_in.to(device), wbases_pca_in.to(device)\n",
    "\n",
    "bases_pca_out, wbases_pca_out = compute_2dpca_bases(Np , k_max , L,  pca_data_out)\n",
    "bases_pca_out, wbases_pca_out = bases_pca_out.to(device), wbases_pca_out.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 0.12202412657504426\n",
      "train 0.042574322955539555\n",
      "test 0.10809670493162908\n",
      "train 0.03811437766318393\n",
      "test 0.08922759853271657\n",
      "train 0.04113408883660831\n",
      "test 0.1217855504237831\n",
      "train 0.03779154900813395\n",
      "test 0.11049039876736404\n",
      "train 0.04703398522896091\n",
      "test 0.1070383313392972\n",
      "train 0.049982606421776384\n",
      "test 0.1107767581643044\n",
      "train 0.04795972416909893\n",
      "test 0.13861489552493955\n",
      "train 0.03869884652551351\n",
      "test 0.1274053949622127\n",
      "train 0.026094976996212455\n",
      "test 0.12279163722298808\n",
      "train 0.03668960453934911\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from models.losses import LpLoss\n",
    "from models import  FNN_train, compute_2dFourier_bases, compute_2dpca_bases, UnitGaussianNormalizer\n",
    "x_normalizer = UnitGaussianNormalizer(x_train, dim=[])\n",
    "y_normalizer = UnitGaussianNormalizer(y_train, dim=[])\n",
    "n=10\n",
    "myloss = LpLoss(d=1, p=2, size_average=False)\n",
    "# fig, axs = plt.subplots(n,2, figsize=(4*2,4*n))\n",
    "# mygrid = np.linspace(0, L, Np)\n",
    "# grid_x, grid_y = np.meshgrid(mygrid, mygrid)\n",
    "for i in range(n):\n",
    "    x = x_test[i,:,0].to(device)\n",
    "    # x1 = x_normalizer.encode(x)\n",
    "    x1=x\n",
    "    x_hat = torch.einsum('x,xk -> k',x1,wbases_pca_in)\n",
    "    x0 = torch.einsum('k,xk -> x',x_hat,bases_pca_in)\n",
    "    # x0 = x_normalizer.decode(x0)\n",
    "    print('test',torch.norm(x0-x).item()/torch.norm(x).item())\n",
    "    # print('xtest',myloss(x,x0).item())\n",
    "    # # im=axs[i,0].pcolormesh(grid_x, grid_y, x.to('cpu').reshape(Np,Np))\n",
    "    # # fig.colorbar(im, ax=axs[i,0])\n",
    "    # # im=axs[i,1].pcolormesh(grid_x, grid_y, x0.to('cpu').reshape(Np,Np))\n",
    "    # # fig.colorbar(im, ax=axs[i,1])\n",
    "\n",
    "    x = x_train[i,:,0].to(device)\n",
    "    # x1 = x_normalizer.encode(x)\n",
    "    x1=x\n",
    "    x_hat = torch.einsum('x,xk -> k',x1,wbases_pca_in)\n",
    "    x0 = torch.einsum('k,xk -> x',x_hat,bases_pca_in)\n",
    "    # x0 = x_normalizer.decode(x0)\n",
    "    print('train',torch.norm(x0-x).item()/torch.norm(x).item())\n",
    "    # print('xtrain',myloss(x,x0).item())\n",
    "\n",
    "    # x = y_test[i,:,0].to(device)\n",
    "    # # x1 = y_normalizer.encode(x)\n",
    "    # x1=x\n",
    "    # x_hat = torch.einsum('x,xk -> k',x1,wbases_pca_out)\n",
    "    # x0 = torch.einsum('k,xk -> x',x_hat,bases_pca_out)\n",
    "    # # x0 = y_normalizer.decode(x0)\n",
    "    # print('ytest',torch.norm(x0-x).item()/torch.norm(x).item())\n",
    "    # x = x.unsqueeze(0)\n",
    "    # x0 = x0.unsqueeze(0)\n",
    "    # loss = myloss(x,x0)\n",
    "    # print('test',loss.item())\n",
    "    # im=axs[i,0].pcolormesh(grid_x, grid_y, x.to('cpu').reshape(Np,Np))\n",
    "    # fig.colorbar(im, ax=axs[i,0])\n",
    "    # im=axs[i,1].pcolormesh(grid_x, grid_y, x0.to('cpu').reshape(Np,Np))\n",
    "    # fig.colorbar(im, ax=axs[i,1])\n",
    "    # x = y_train[i,:,0].to(device)\n",
    "    # # x1 = y_normalizer.encode(x)\n",
    "    # x1=x\n",
    "    # x_hat = torch.einsum('x,xk -> k',x1,wbases_pca_out)\n",
    "    # x0 = torch.einsum('k,xk -> x',x_hat,bases_pca_out)\n",
    "    # # x0 = y_normalizer.decode(x0)\n",
    "    # # print('ytrain',torch.norm(x0-x).item()/torch.norm(x).item())\n",
    "    # print('train',myloss(x,x0).item())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
