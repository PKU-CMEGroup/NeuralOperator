{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 2000, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "bsz = 50\n",
    "n = 2000\n",
    "in_channel = 200\n",
    "phy_in_channel = 3\n",
    "phy_out_channel = 100\n",
    "out_channel = 128\n",
    "liftpts = torch.rand(phy_out_channel,phy_in_channel)\n",
    "liftweight = torch.rand(phy_out_channel,phy_in_channel)\n",
    "x = torch.rand(bsz,n,in_channel)\n",
    "class Phylift(nn.Module):\n",
    "    def __init__(self,phy_in_channel,in_channel,out_channel,liftpts,liftweight):\n",
    "        super(Phylift, self).__init__()\n",
    "        self.phy_in_channel = phy_in_channel\n",
    "        self.phy_out_channel = liftpts.shape[0]\n",
    "        self.dim = liftpts.shape[1]\n",
    "        self.in_channel = in_channel\n",
    "        self.out_channel = out_channel\n",
    "        self.liftpts = liftpts  #shape: phy_out_channel, dim\n",
    "        self.liftweight = liftweight  #shape: phy_out_channel, dim\n",
    "\n",
    "        self.fc = nn.Linear(self.phy_out_channel - phy_in_channel + in_channel, out_channel)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x_phy_in = x[:,:,:self.phy_in_channel]\n",
    "        x_phy_out = self.compute_bases(x_phy_in)\n",
    "        x = torch.cat((x_phy_out,x[:,:,self.phy_in_channel:]),dim=2)\n",
    "        x = self.fc(x) \n",
    "        return x\n",
    "    def compute_bases(self,x_phy_in):\n",
    "        #x_phy_in.shape:  bsz,n,phy_in_channel\n",
    "        x_phy_in = x_phy_in.unsqueeze(2) #bsz,n,1,phy_in_channel\n",
    "        liftpts = self.liftpts.unsqueeze(0).unsqueeze(0) # 1,1,phy_out_channel,phy_in_channel\n",
    "        liftweight = self.liftweight.unsqueeze(0).unsqueeze(0)  #1,1,phy_out_channel,phy_in_channel\n",
    "        x_phy_out = torch.exp(-1*torch.sum(liftweight*(x_phy_in-liftpts)**2,dim=3))  #bsz,n,phy_out_channel,phy_in_channel-->bsz,n,phy_out_channel\n",
    "        return x_phy_out\n",
    "Phy = Phylift(phy_in_channel,in_channel,out_channel,liftpts,liftweight)\n",
    "linear = nn.Linear(in_channel,out_channel)\n",
    "x = Phy(x)\n",
    "# x = linear(x)\n",
    "print(x[:,:,-0:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from timeit import default_timer\n",
    "from scipy.io import loadmat\n",
    "import yaml\n",
    "import gc\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "\n",
    "from models import  PhyHGkNN_train, compute_2dFourier_bases, compute_2dpca_bases, compute_2dFourier_cbases, count_params\n",
    "\n",
    "from models.PhyHGkNN import PhyHGkNN\n",
    "\n",
    "torch.set_printoptions(precision=16)\n",
    "\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "###################################\n",
    "# load configs\n",
    "###################################\n",
    "with open('config.yml', 'r', encoding='utf-8') as f:\n",
    "    config = yaml.full_load(f)\n",
    "\n",
    "config = config[\"Darcy_HGkNN\"]\n",
    "config = dict(config)\n",
    "config_data, config_model, config_train = (\n",
    "    config[\"data\"],\n",
    "    config[\"model\"],\n",
    "    config[\"train\"],\n",
    ")\n",
    "downsample_ratio = config_data[\"downsample_ratio\"]\n",
    "L = config_data[\"L\"]\n",
    "n_train = config_data[\"n_train\"]\n",
    "n_test = config_data[\"n_test\"]\n",
    "device = torch.device(config[\"train\"][\"device\"])\n",
    "\n",
    "\n",
    "###################################\n",
    "# load data\n",
    "###################################\n",
    "# data_path = \"../data/darcy_2d/piececonst_r421_N1024_smooth1\"\n",
    "# data1 = loadmat(data_path)\n",
    "# coeff1 = data1[\"coeff\"]\n",
    "# sol1 = data1[\"sol\"]\n",
    "# del data1\n",
    "# data_path = \"../data/darcy_2d/piececonst_r421_N1024_smooth2\"\n",
    "# data2 = loadmat(data_path)\n",
    "# coeff2 = data2[\"coeff\"][:300,:,:]\n",
    "# sol2 = data2[\"sol\"][:300,:,:]\n",
    "# del data2\n",
    "# gc.collect()\n",
    "\n",
    "# data_in = np.vstack((coeff1, coeff2))  # shape: 2048,421,421\n",
    "# data_out = np.vstack((sol1, sol2))     # shape: 2048,421,421\n",
    "\n",
    "data_path = \"../data/darcy_2d/piececonst_r421_N1024_smooth1\"\n",
    "data1 = loadmat(data_path)\n",
    "\n",
    "data_in = data1[\"coeff\"]\n",
    "data_out = data1[\"sol\"]\n",
    "\n",
    "print(\"data_in.shape:\" , data_in.shape)\n",
    "print(\"data_out.shape\", data_out.shape)\n",
    "\n",
    "Np_ref = data_in.shape[1]\n",
    "grid_1d = np.linspace(0, L, Np_ref)\n",
    "grid_x, grid_y = np.meshgrid(grid_1d, grid_1d)\n",
    "\n",
    "data_in_ds = data_in[0:n_train, 0::downsample_ratio, 0::downsample_ratio]\n",
    "grid_x_ds = grid_x[0::downsample_ratio, 0::downsample_ratio]\n",
    "grid_y_ds = grid_y[0::downsample_ratio, 0::downsample_ratio]\n",
    "data_out_ds = data_out[0:n_train, 0::downsample_ratio, 0::downsample_ratio]\n",
    "\n",
    "# x_train, y_train are [n_data, n_x, n_channel] arrays\n",
    "x_train = torch.from_numpy(\n",
    "    np.stack(\n",
    "        (\n",
    "            data_in_ds,\n",
    "            np.tile(grid_x_ds, (n_train, 1, 1)),\n",
    "            np.tile(grid_y_ds, (n_train, 1, 1)),\n",
    "        ),\n",
    "        axis=-1,\n",
    "    ).astype(np.float32)\n",
    ")\n",
    "y_train = torch.from_numpy(data_out_ds[:, :, :, np.newaxis].astype(np.float32))\n",
    "# x_test, y_test are [n_data, n_x, n_channel] arrays\n",
    "x_test = torch.from_numpy(\n",
    "    np.stack(\n",
    "        (\n",
    "            data_in[-n_test:, 0::downsample_ratio, 0::downsample_ratio],\n",
    "            np.tile(grid_x[0::downsample_ratio, 0::downsample_ratio], (n_test, 1, 1)),\n",
    "            np.tile(grid_y[0::downsample_ratio, 0::downsample_ratio], (n_test, 1, 1)),\n",
    "        ),\n",
    "        axis=-1,\n",
    "    ).astype(np.float32)\n",
    ")\n",
    "y_test = torch.from_numpy(\n",
    "    data_out[-n_test:, 0::downsample_ratio, 0::downsample_ratio, np.newaxis].astype(\n",
    "        np.float32\n",
    "    )\n",
    ")\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], -1, x_train.shape[-1])   # shape: 800,11236,3  (11236 = 106*106 , 106-1 = (421-1) /4)\n",
    "x_test = x_test.reshape(x_test.shape[0], -1, x_test.shape[-1])\n",
    "y_train = y_train.reshape(y_train.shape[0], -1, y_train.shape[-1])   # shape: 800,11236,1\n",
    "y_test = y_test.reshape(y_test.shape[0], -1, y_test.shape[-1])\n",
    "print(\"x_train.shape: \",x_train.shape)\n",
    "print(\"y_train.shape: \",y_train.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################################\n",
    "#compute pca bases\n",
    "####################################\n",
    "k_max = max(config_model[\"GkNN_mode_in\"],config_model[\"GkNN_mode_out\"])\n",
    "Np = (Np_ref + downsample_ratio - 1) // downsample_ratio\n",
    "pca_data_in = data_in_ds.reshape((data_in_ds.shape[0], -1))\n",
    "pca_data_out = data_out_ds.reshape((data_out_ds.shape[0], -1))\n",
    "# if config_model[\"pca_include_input\"]:\n",
    "#     pca_data = np.vstack(\n",
    "#         (pca_data, data_in_ds.reshape((data_in_ds.shape[0], -1)))\n",
    "#     )\n",
    "# if config_model[\"pca_include_grid\"]:\n",
    "#     n_grid = 1\n",
    "#     pca_data = np.vstack((pca_data, np.tile(grid_x_ds, (n_grid, 1))))\n",
    "#     pca_data = np.vstack((pca_data, np.tile(grid_y_ds, (n_grid, 1))))\n",
    "\n",
    "# percentage = 0.1\n",
    "# mask1 = torch.rand(pca_data_in.shape) > percentage\n",
    "# mask2 = torch.rand(pca_data_out.shape) > percentage\n",
    "# pca_data_in = (torch.from_numpy(pca_data_in)*mask1).numpy()\n",
    "# pca_data_out = (torch.from_numpy(pca_data_out)*mask2).numpy()\n",
    "\n",
    "\n",
    "print(\"Start SVD with data shape: \", pca_data_out.shape, flush = True)\n",
    "\n",
    "bases_pca_in, wbases_pca_in = compute_2dpca_bases(Np , k_max , L,  pca_data_in)\n",
    "bases_pca_in, wbases_pca_in = bases_pca_in.to(device), wbases_pca_in.to(device)\n",
    "\n",
    "bases_pca_out, wbases_pca_out = compute_2dpca_bases(Np , k_max , L,  pca_data_out)\n",
    "bases_pca_out, wbases_pca_out = bases_pca_out.to(device), wbases_pca_out.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###################################\n",
    "#compute kernel bases\n",
    "###################################\n",
    "\n",
    "H_in = 0\n",
    "H_out = 0\n",
    "\n",
    "\n",
    "bases_list = [ bases_pca_out, wbases_pca_out, 0,0]\n",
    "###################################\n",
    "#construct model and train\n",
    "###################################\n",
    "model = PhyHGkNN(bases_list, **config_model).to(device)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 2]) tensor([[-0.7500, -0.7500],\n",
      "        [-0.7500, -0.2500],\n",
      "        [-0.7500,  0.2500],\n",
      "        [-0.7500,  0.7500],\n",
      "        [-0.2500, -0.7500],\n",
      "        [-0.2500, -0.2500],\n",
      "        [-0.2500,  0.2500],\n",
      "        [-0.2500,  0.7500],\n",
      "        [ 0.2500, -0.7500],\n",
      "        [ 0.2500, -0.2500],\n",
      "        [ 0.2500,  0.2500],\n",
      "        [ 0.2500,  0.7500],\n",
      "        [ 0.7500, -0.7500],\n",
      "        [ 0.7500, -0.2500],\n",
      "        [ 0.7500,  0.2500],\n",
      "        [ 0.7500,  0.7500]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def uniform_points(num_pts,dim,range_pts):\n",
    "    a = int(torch.pow(torch.tensor(num_pts),1/dim))\n",
    "    index_tensors = []\n",
    "    for k in range(dim):\n",
    "        xmin,xmax = range_pts[k][0],range_pts[k][1]\n",
    "        idx = xmin + (xmax-xmin)*torch.arange(a).float().add(0.5).div(a)\n",
    "        idx = idx.view((1,) * k+ (-1,) + (1,) * (dim - k - 1))\n",
    "        index_tensors.append(idx.expand(a, *([a] * (dim - 1))))\n",
    "    num_pts1 = int(torch.pow(torch.tensor(a),dim))\n",
    "    x = torch.stack(index_tensors, dim=dim).reshape(num_pts1,dim)\n",
    "    return x\n",
    "x = uniform_points(16,2,[[-1,1],[-1,1]])\n",
    "print(x.shape,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001279299998714123\n",
      "0.004285800001525786\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from timeit import default_timer\n",
    "# def fast_mul(x,wbases,base_mask):\n",
    "#     bsz = x.shape[0]\n",
    "#     channel_in = x.shape[1]\n",
    "#     modes_in = wbases.shape[-1]\n",
    "#     t4 = default_timer()\n",
    "#     x_hat = torch.zeros(bsz,channel_in,modes_in).to(x.device)\n",
    "#     t5 = default_timer()\n",
    "#     k=0\n",
    "#     x_mask = x[:,:,base_mask[:,k]]\n",
    "#     t6 = default_timer()\n",
    "#     wbases_mask = wbases[:,base_mask[:,k],k]\n",
    "#     t7 = default_timer()\n",
    "#     x_hat[:,:,k] = torch.einsum(\"bcx,bx->bc\", x_mask, wbases_mask)\n",
    "#     t8 = default_timer()\n",
    "#     print(t5-t4,t6-t5,t7-t6,t8-t7)\n",
    "    \n",
    "#     return x_hat\n",
    "\n",
    "b = 30\n",
    "c = 100\n",
    "k = 1000\n",
    "n = 50000\n",
    "# device = 'cuda'\n",
    "# x = torch.rand(b,c,n).to(device)\n",
    "# wbases = torch.rand(b,n,k).to(device)\n",
    "# base_mask = torch.zeros(n,k).to(device)\n",
    "# base_mask[:3,:] = 1\n",
    "# base_mask = base_mask.bool()\n",
    "# t1 = default_timer()\n",
    "# x_hat = torch.einsum(\"bcx,bxk->bck\", x, wbases)\n",
    "# t2 = default_timer()\n",
    "# x_hat = fast_mul(x,wbases,base_mask)\n",
    "# t3 = default_timer()\n",
    "# print(t2-t1)\n",
    "# print(t3-t2)\n",
    "t = default_timer()\n",
    "x_hat = torch.zeros(b,c,k)\n",
    "t_1 = default_timer()\n",
    "x_hat = x_hat.to('cuda')\n",
    "t_2 = default_timer()\n",
    "print(t_1-t)\n",
    "print(t_2-t_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
