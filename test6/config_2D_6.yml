FFT_2D:

  data:
    L: 1.0
    downsample_ratio: 14
    n_train: 800
    n_test: 200

  model:
    # layer_types: ['HGalerkinConv_pca','HGalerkinConv_pca','HGalerkinConv_pca','HGalerkinConv_pca']  # GalerkinConv_fourier ， GalerkinConv_pca ， FourierConv2d ，Attention
    layer_types: ['HGalerkinConv_doublepca','HGalerkinConv_doublepca','HGalerkinConv_doublepca','HGalerkinConv_doublepca']
    FNO_modes: [16,16,16,16]   # modes for FourierConv2d
    GkNN_modes: [96,96,96,96]  # modes for GkNN
    kernel_modes: [64,64,64,64]
    num_heads: [1,1,1,1]
    attention_types: ["galerkin","galerkin","galerkin","galerkin"]
    fc_dim: 128
    in_dim: 3  #default
    out_dim: 1  #default
    pca_include_input: False
    pca_include_grid: False
    layers_dim: [128,128,128,128,128]     # len(layers_dim) == len(..modes)+1 
    act: 'gelu'
    pad_ratio: 0.05
    residual : [False,False,False,False]
    get_H : 'learn_real_split'     #'compute' or 'learn_complex' or 'learn_real' or 'trained' or 'learn_real_split'
    # dropout: [0.1,0.1,0.1,0.1]
    dropout: [False,False,False,False]



  train:
    device: 'cuda'   #cpu or cuda
    base_lr: 0.001
    weight_decay: 0.0001
    epochs: 500
    scheduler: 'OneCycleLR'
    milestones: [200,300,400,500,800,900]
    scheduler_gamma: 0.5
    batch_size: 8
    normalization_x: True
    normalization_y: True
    normalization_dim: []

