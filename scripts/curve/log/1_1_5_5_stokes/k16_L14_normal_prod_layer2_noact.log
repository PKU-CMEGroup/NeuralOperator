Loading data from  ../../data/curve//pcno_curve_data_1_1_5_5_stokes.npz
(1000,) (1000, 1000, 1) (1000, 1000, 2)
use normalized raw measures
Casting to tensor
x_train shape torch.Size([900, 1000, 8]), y_train shape torch.Size([900, 1000, 1])
length of each dim:  tensor([6.6455335617065430, 6.6654777526855469])
kmax = 16
L =  14
In PCNO_train, ndims =  2
Epoch :  0  Time:  1.334  Rel. Train L2 Loss :  0.4070723987950219  Rel. Test L2 Loss :  0.2534681558609009  Test L2 Loss :  0.45873903393745424  inv_L_scale:  [1.0, 1.0]
Epoch :  1  Time:  0.947  Rel. Train L2 Loss :  0.1984879196352429  Rel. Test L2 Loss :  0.1525797003507614  Test L2 Loss :  0.28727721810340884  inv_L_scale:  [1.0, 1.0]
Epoch :  2  Time:  0.945  Rel. Train L2 Loss :  0.1466912959019343  Rel. Test L2 Loss :  0.13316428363323213  Test L2 Loss :  0.24697516560554506  inv_L_scale:  [1.0, 1.0]
Epoch :  3  Time:  0.944  Rel. Train L2 Loss :  0.12014824804332522  Rel. Test L2 Loss :  0.11816684871912003  Test L2 Loss :  0.22030144810676575  inv_L_scale:  [1.0, 1.0]
Epoch :  4  Time:  0.946  Rel. Train L2 Loss :  0.10707948078711828  Rel. Test L2 Loss :  0.10480268776416779  Test L2 Loss :  0.19574031591415406  inv_L_scale:  [1.0, 1.0]
Epoch :  5  Time:  0.943  Rel. Train L2 Loss :  0.10179052697287666  Rel. Test L2 Loss :  0.09247620612382888  Test L2 Loss :  0.170054327249527  inv_L_scale:  [1.0, 1.0]
Epoch :  6  Time:  0.943  Rel. Train L2 Loss :  0.09141377733813391  Rel. Test L2 Loss :  0.09040238201618195  Test L2 Loss :  0.16569997668266295  inv_L_scale:  [1.0, 1.0]
Epoch :  7  Time:  0.945  Rel. Train L2 Loss :  0.08090087609158622  Rel. Test L2 Loss :  0.08446635246276855  Test L2 Loss :  0.15346610188484192  inv_L_scale:  [1.0, 1.0]
Epoch :  8  Time:  0.943  Rel. Train L2 Loss :  0.08125155087974337  Rel. Test L2 Loss :  0.08496748089790344  Test L2 Loss :  0.15357277274131775  inv_L_scale:  [1.0, 1.0]
Epoch :  9  Time:  0.945  Rel. Train L2 Loss :  0.07802945743004482  Rel. Test L2 Loss :  0.07726495772600174  Test L2 Loss :  0.1414667671918869  inv_L_scale:  [1.0, 1.0]
Epoch :  10  Time:  0.944  Rel. Train L2 Loss :  0.07733470926682154  Rel. Test L2 Loss :  0.09053840160369873  Test L2 Loss :  0.1665014261007309  inv_L_scale:  [1.0, 1.0]
Epoch :  11  Time:  0.942  Rel. Train L2 Loss :  0.07221580968962775  Rel. Test L2 Loss :  0.07431087404489517  Test L2 Loss :  0.13305324137210847  inv_L_scale:  [1.0, 1.0]
Epoch :  12  Time:  0.943  Rel. Train L2 Loss :  0.0691779864165518  Rel. Test L2 Loss :  0.0764484253525734  Test L2 Loss :  0.14001733422279358  inv_L_scale:  [1.0, 1.0]
Epoch :  13  Time:  0.944  Rel. Train L2 Loss :  0.06843033509122001  Rel. Test L2 Loss :  0.08163889825344085  Test L2 Loss :  0.14575358748435974  inv_L_scale:  [1.0, 1.0]
Epoch :  14  Time:  0.944  Rel. Train L2 Loss :  0.06622102402978473  Rel. Test L2 Loss :  0.0676621052622795  Test L2 Loss :  0.12228082686662674  inv_L_scale:  [1.0, 1.0]
Epoch :  15  Time:  0.944  Rel. Train L2 Loss :  0.06418141656451755  Rel. Test L2 Loss :  0.06653721362352372  Test L2 Loss :  0.11968140870332718  inv_L_scale:  [1.0, 1.0]
Epoch :  16  Time:  0.943  Rel. Train L2 Loss :  0.06581730256477991  Rel. Test L2 Loss :  0.07244804739952088  Test L2 Loss :  0.131683087348938  inv_L_scale:  [1.0, 1.0]
Epoch :  17  Time:  0.946  Rel. Train L2 Loss :  0.06535352240006129  Rel. Test L2 Loss :  0.06592913955450058  Test L2 Loss :  0.11718141674995422  inv_L_scale:  [1.0, 1.0]
Epoch :  18  Time:  0.944  Rel. Train L2 Loss :  0.06180689424276352  Rel. Test L2 Loss :  0.06979632198810577  Test L2 Loss :  0.12633139312267302  inv_L_scale:  [1.0, 1.0]
Epoch :  19  Time:  0.943  Rel. Train L2 Loss :  0.0589147545893987  Rel. Test L2 Loss :  0.06141223415732384  Test L2 Loss :  0.1101745307445526  inv_L_scale:  [1.0, 1.0]
Epoch :  20  Time:  0.944  Rel. Train L2 Loss :  0.05839395562807719  Rel. Test L2 Loss :  0.0630815327167511  Test L2 Loss :  0.11358057975769043  inv_L_scale:  [1.0, 1.0]
Epoch :  21  Time:  0.944  Rel. Train L2 Loss :  0.059372295969062384  Rel. Test L2 Loss :  0.06854898408055306  Test L2 Loss :  0.12636876672506334  inv_L_scale:  [1.0, 1.0]
Epoch :  22  Time:  0.944  Rel. Train L2 Loss :  0.06012329649594095  Rel. Test L2 Loss :  0.06290275737643242  Test L2 Loss :  0.11284155011177063  inv_L_scale:  [1.0, 1.0]
Epoch :  23  Time:  0.944  Rel. Train L2 Loss :  0.05944036480453279  Rel. Test L2 Loss :  0.06178713724017143  Test L2 Loss :  0.11009556829929351  inv_L_scale:  [1.0, 1.0]
Epoch :  24  Time:  0.944  Rel. Train L2 Loss :  0.05748003764284981  Rel. Test L2 Loss :  0.061357666850090024  Test L2 Loss :  0.10792567610740661  inv_L_scale:  [1.0, 1.0]
Epoch :  25  Time:  0.945  Rel. Train L2 Loss :  0.05665128270785014  Rel. Test L2 Loss :  0.060893149077892304  Test L2 Loss :  0.10807618081569671  inv_L_scale:  [1.0, 1.0]
Epoch :  26  Time:  0.944  Rel. Train L2 Loss :  0.05713336767421828  Rel. Test L2 Loss :  0.06123454362154007  Test L2 Loss :  0.10929315268993378  inv_L_scale:  [1.0, 1.0]
Epoch :  27  Time:  0.943  Rel. Train L2 Loss :  0.05514168552226491  Rel. Test L2 Loss :  0.05801225244998932  Test L2 Loss :  0.10306317925453186  inv_L_scale:  [1.0, 1.0]
Epoch :  28  Time:  0.943  Rel. Train L2 Loss :  0.05778201093276342  Rel. Test L2 Loss :  0.06105183705687523  Test L2 Loss :  0.10823106497526169  inv_L_scale:  [1.0, 1.0]
Epoch :  29  Time:  0.942  Rel. Train L2 Loss :  0.05676198828551504  Rel. Test L2 Loss :  0.0638609804213047  Test L2 Loss :  0.1125156331062317  inv_L_scale:  [1.0, 1.0]
Epoch :  30  Time:  0.942  Rel. Train L2 Loss :  0.05561413218577703  Rel. Test L2 Loss :  0.05603297919034958  Test L2 Loss :  0.09914427608251572  inv_L_scale:  [1.0, 1.0]
Epoch :  31  Time:  0.942  Rel. Train L2 Loss :  0.054378624889585704  Rel. Test L2 Loss :  0.06045374765992165  Test L2 Loss :  0.10733582794666291  inv_L_scale:  [1.0, 1.0]
Epoch :  32  Time:  0.944  Rel. Train L2 Loss :  0.05416936521728834  Rel. Test L2 Loss :  0.05759790182113647  Test L2 Loss :  0.10242893069982528  inv_L_scale:  [1.0, 1.0]
Epoch :  33  Time:  0.943  Rel. Train L2 Loss :  0.05423131335112784  Rel. Test L2 Loss :  0.05561131328344345  Test L2 Loss :  0.09913882821798324  inv_L_scale:  [1.0, 1.0]
Epoch :  34  Time:  0.942  Rel. Train L2 Loss :  0.05284212259782685  Rel. Test L2 Loss :  0.05804037064313888  Test L2 Loss :  0.10192296922206878  inv_L_scale:  [1.0, 1.0]
Epoch :  35  Time:  0.942  Rel. Train L2 Loss :  0.0519606230325169  Rel. Test L2 Loss :  0.05728193566203117  Test L2 Loss :  0.10213321805000306  inv_L_scale:  [1.0, 1.0]
Epoch :  36  Time:  0.945  Rel. Train L2 Loss :  0.053771279437674416  Rel. Test L2 Loss :  0.0523638516664505  Test L2 Loss :  0.09340643405914306  inv_L_scale:  [1.0, 1.0]
Epoch :  37  Time:  0.943  Rel. Train L2 Loss :  0.054436377220683625  Rel. Test L2 Loss :  0.05681424722075462  Test L2 Loss :  0.10091538965702057  inv_L_scale:  [1.0, 1.0]
Epoch :  38  Time:  0.943  Rel. Train L2 Loss :  0.05253695100545883  Rel. Test L2 Loss :  0.05680035680532455  Test L2 Loss :  0.10088868796825409  inv_L_scale:  [1.0, 1.0]
Epoch :  39  Time:  0.942  Rel. Train L2 Loss :  0.05248637517293294  Rel. Test L2 Loss :  0.056861501336097714  Test L2 Loss :  0.1009917801618576  inv_L_scale:  [1.0, 1.0]
Epoch :  40  Time:  0.943  Rel. Train L2 Loss :  0.0554695290989346  Rel. Test L2 Loss :  0.0611817991733551  Test L2 Loss :  0.10828464925289154  inv_L_scale:  [1.0, 1.0]
Epoch :  41  Time:  0.943  Rel. Train L2 Loss :  0.052954969455798466  Rel. Test L2 Loss :  0.052908638417720796  Test L2 Loss :  0.09529398620128632  inv_L_scale:  [1.0, 1.0]
Epoch :  42  Time:  0.943  Rel. Train L2 Loss :  0.05142213824722502  Rel. Test L2 Loss :  0.05546472251415253  Test L2 Loss :  0.09904426664113998  inv_L_scale:  [1.0, 1.0]
Epoch :  43  Time:  0.943  Rel. Train L2 Loss :  0.05125185701582167  Rel. Test L2 Loss :  0.05115891247987747  Test L2 Loss :  0.09092887818813324  inv_L_scale:  [1.0, 1.0]
Epoch :  44  Time:  0.942  Rel. Train L2 Loss :  0.05183353884352578  Rel. Test L2 Loss :  0.053953404724597934  Test L2 Loss :  0.0953161758184433  inv_L_scale:  [1.0, 1.0]
Epoch :  45  Time:  0.943  Rel. Train L2 Loss :  0.04993404272529814  Rel. Test L2 Loss :  0.053356668055057524  Test L2 Loss :  0.09324296414852143  inv_L_scale:  [1.0, 1.0]
Epoch :  46  Time:  0.942  Rel. Train L2 Loss :  0.05082721170451906  Rel. Test L2 Loss :  0.05972412511706352  Test L2 Loss :  0.10580709099769592  inv_L_scale:  [1.0, 1.0]
Epoch :  47  Time:  0.945  Rel. Train L2 Loss :  0.05105900012784534  Rel. Test L2 Loss :  0.06243576765060425  Test L2 Loss :  0.11394244968891144  inv_L_scale:  [1.0, 1.0]
Epoch :  48  Time:  0.943  Rel. Train L2 Loss :  0.05287131177054511  Rel. Test L2 Loss :  0.05846371680498123  Test L2 Loss :  0.10505002111196518  inv_L_scale:  [1.0, 1.0]
Epoch :  49  Time:  0.942  Rel. Train L2 Loss :  0.05235135528776381  Rel. Test L2 Loss :  0.05506402090191841  Test L2 Loss :  0.0985414183139801  inv_L_scale:  [1.0, 1.0]
Epoch :  50  Time:  0.943  Rel. Train L2 Loss :  0.04985553769601716  Rel. Test L2 Loss :  0.0546284481883049  Test L2 Loss :  0.09754876255989074  inv_L_scale:  [1.0, 1.0]
Epoch :  51  Time:  0.943  Rel. Train L2 Loss :  0.05161698473824395  Rel. Test L2 Loss :  0.054355462491512296  Test L2 Loss :  0.09589036285877228  inv_L_scale:  [1.0, 1.0]
Epoch :  52  Time:  0.943  Rel. Train L2 Loss :  0.04937698251671261  Rel. Test L2 Loss :  0.05180988311767578  Test L2 Loss :  0.09085558623075485  inv_L_scale:  [1.0, 1.0]
Epoch :  53  Time:  0.942  Rel. Train L2 Loss :  0.05087845989399486  Rel. Test L2 Loss :  0.06773174166679383  Test L2 Loss :  0.12032873332500457  inv_L_scale:  [1.0, 1.0]
Epoch :  54  Time:  0.942  Rel. Train L2 Loss :  0.05145995827184783  Rel. Test L2 Loss :  0.05226487219333649  Test L2 Loss :  0.09217230916023254  inv_L_scale:  [1.0, 1.0]
Epoch :  55  Time:  0.944  Rel. Train L2 Loss :  0.05001539374391238  Rel. Test L2 Loss :  0.05106241077184677  Test L2 Loss :  0.090699442923069  inv_L_scale:  [1.0, 1.0]
Epoch :  56  Time:  0.942  Rel. Train L2 Loss :  0.04887588201297654  Rel. Test L2 Loss :  0.051154570877552034  Test L2 Loss :  0.08992178618907928  inv_L_scale:  [1.0, 1.0]
Epoch :  57  Time:  0.942  Rel. Train L2 Loss :  0.049370071589946746  Rel. Test L2 Loss :  0.04897525653243065  Test L2 Loss :  0.08682790279388428  inv_L_scale:  [1.0, 1.0]
Epoch :  58  Time:  0.942  Rel. Train L2 Loss :  0.04923090916540888  Rel. Test L2 Loss :  0.05228078156709671  Test L2 Loss :  0.09330972671508789  inv_L_scale:  [1.0, 1.0]
Epoch :  59  Time:  0.942  Rel. Train L2 Loss :  0.048407214350170556  Rel. Test L2 Loss :  0.050076225697994234  Test L2 Loss :  0.08810160875320434  inv_L_scale:  [1.0, 1.0]
Epoch :  60  Time:  0.944  Rel. Train L2 Loss :  0.0491227564546797  Rel. Test L2 Loss :  0.0483560061454773  Test L2 Loss :  0.08513914108276367  inv_L_scale:  [1.0, 1.0]
Epoch :  61  Time:  0.944  Rel. Train L2 Loss :  0.04759701364570194  Rel. Test L2 Loss :  0.051648734360933306  Test L2 Loss :  0.09080723285675049  inv_L_scale:  [1.0, 1.0]
Epoch :  62  Time:  0.942  Rel. Train L2 Loss :  0.047821528414885205  Rel. Test L2 Loss :  0.05343140095472336  Test L2 Loss :  0.09517230093479156  inv_L_scale:  [1.0, 1.0]
Epoch :  63  Time:  0.942  Rel. Train L2 Loss :  0.04772991091012955  Rel. Test L2 Loss :  0.04995981380343437  Test L2 Loss :  0.08787002116441726  inv_L_scale:  [1.0, 1.0]
Epoch :  64  Time:  0.943  Rel. Train L2 Loss :  0.04728289996584256  Rel. Test L2 Loss :  0.05288693413138389  Test L2 Loss :  0.09399972140789031  inv_L_scale:  [1.0, 1.0]
Epoch :  65  Time:  0.943  Rel. Train L2 Loss :  0.047803139752811856  Rel. Test L2 Loss :  0.054531583189964296  Test L2 Loss :  0.0945559749007225  inv_L_scale:  [1.0, 1.0]
Epoch :  66  Time:  0.942  Rel. Train L2 Loss :  0.04704066697094175  Rel. Test L2 Loss :  0.04991058513522148  Test L2 Loss :  0.08792039275169372  inv_L_scale:  [1.0, 1.0]
Epoch :  67  Time:  0.943  Rel. Train L2 Loss :  0.04742388649119271  Rel. Test L2 Loss :  0.05337696716189384  Test L2 Loss :  0.09551198542118072  inv_L_scale:  [1.0, 1.0]
Epoch :  68  Time:  0.942  Rel. Train L2 Loss :  0.04718897632426686  Rel. Test L2 Loss :  0.049419683665037156  Test L2 Loss :  0.08691408276557923  inv_L_scale:  [1.0, 1.0]
Epoch :  69  Time:  0.942  Rel. Train L2 Loss :  0.046186380320125155  Rel. Test L2 Loss :  0.05321131020784378  Test L2 Loss :  0.09442401170730591  inv_L_scale:  [1.0, 1.0]
Epoch :  70  Time:  0.944  Rel. Train L2 Loss :  0.04548417682449023  Rel. Test L2 Loss :  0.05187586486339569  Test L2 Loss :  0.09194406539201737  inv_L_scale:  [1.0, 1.0]
Epoch :  71  Time:  0.942  Rel. Train L2 Loss :  0.046695264346069756  Rel. Test L2 Loss :  0.051031097620725635  Test L2 Loss :  0.09038551449775696  inv_L_scale:  [1.0, 1.0]
Epoch :  72  Time:  0.942  Rel. Train L2 Loss :  0.04615995834271113  Rel. Test L2 Loss :  0.04782543003559112  Test L2 Loss :  0.08443631827831269  inv_L_scale:  [1.0, 1.0]
Epoch :  73  Time:  0.943  Rel. Train L2 Loss :  0.047274031076166366  Rel. Test L2 Loss :  0.05041950345039368  Test L2 Loss :  0.08802591741085053  inv_L_scale:  [1.0, 1.0]
Epoch :  74  Time:  0.942  Rel. Train L2 Loss :  0.046233632763226826  Rel. Test L2 Loss :  0.048766230344772336  Test L2 Loss :  0.08643782198429108  inv_L_scale:  [1.0, 1.0]
Epoch :  75  Time:  0.942  Rel. Train L2 Loss :  0.04588077785240279  Rel. Test L2 Loss :  0.04725872337818146  Test L2 Loss :  0.08361496269702912  inv_L_scale:  [1.0, 1.0]
Epoch :  76  Time:  0.943  Rel. Train L2 Loss :  0.045029227121008764  Rel. Test L2 Loss :  0.04977674961090088  Test L2 Loss :  0.08723587453365327  inv_L_scale:  [1.0, 1.0]
Epoch :  77  Time:  0.945  Rel. Train L2 Loss :  0.04516927555203438  Rel. Test L2 Loss :  0.05020207434892655  Test L2 Loss :  0.08929578334093094  inv_L_scale:  [1.0, 1.0]
Epoch :  78  Time:  0.943  Rel. Train L2 Loss :  0.044872410810656016  Rel. Test L2 Loss :  0.048129264712333676  Test L2 Loss :  0.08425189793109894  inv_L_scale:  [1.0, 1.0]
Epoch :  79  Time:  0.942  Rel. Train L2 Loss :  0.044691990051004625  Rel. Test L2 Loss :  0.05252962648868561  Test L2 Loss :  0.09258988887071609  inv_L_scale:  [1.0, 1.0]
Epoch :  80  Time:  0.943  Rel. Train L2 Loss :  0.04376002411047618  Rel. Test L2 Loss :  0.046991744935512544  Test L2 Loss :  0.08254967451095581  inv_L_scale:  [1.0, 1.0]
Epoch :  81  Time:  0.942  Rel. Train L2 Loss :  0.04540055813060866  Rel. Test L2 Loss :  0.045119010508060456  Test L2 Loss :  0.08021233916282654  inv_L_scale:  [1.0, 1.0]
Epoch :  82  Time:  0.943  Rel. Train L2 Loss :  0.04457863415280978  Rel. Test L2 Loss :  0.04784021586179733  Test L2 Loss :  0.08564434856176377  inv_L_scale:  [1.0, 1.0]
Epoch :  83  Time:  0.942  Rel. Train L2 Loss :  0.04405598767929607  Rel. Test L2 Loss :  0.04714986443519592  Test L2 Loss :  0.08348705649375915  inv_L_scale:  [1.0, 1.0]
Epoch :  84  Time:  0.943  Rel. Train L2 Loss :  0.04431505675117175  Rel. Test L2 Loss :  0.05180197909474373  Test L2 Loss :  0.09136256337165832  inv_L_scale:  [1.0, 1.0]
Epoch :  85  Time:  0.942  Rel. Train L2 Loss :  0.045532014369964596  Rel. Test L2 Loss :  0.045302100479602814  Test L2 Loss :  0.08048441290855407  inv_L_scale:  [1.0, 1.0]
Epoch :  86  Time:  0.942  Rel. Train L2 Loss :  0.04377011850476265  Rel. Test L2 Loss :  0.04523144856095314  Test L2 Loss :  0.08057264924049377  inv_L_scale:  [1.0, 1.0]
Epoch :  87  Time:  0.942  Rel. Train L2 Loss :  0.04342963210410542  Rel. Test L2 Loss :  0.051179329603910445  Test L2 Loss :  0.08968010485172272  inv_L_scale:  [1.0, 1.0]
Epoch :  88  Time:  0.943  Rel. Train L2 Loss :  0.043482721580399404  Rel. Test L2 Loss :  0.04707960739731789  Test L2 Loss :  0.08291567504405975  inv_L_scale:  [1.0, 1.0]
Epoch :  89  Time:  0.942  Rel. Train L2 Loss :  0.04358165598577923  Rel. Test L2 Loss :  0.04844935804605484  Test L2 Loss :  0.08656545251607894  inv_L_scale:  [1.0, 1.0]
Epoch :  90  Time:  0.943  Rel. Train L2 Loss :  0.042807518591483434  Rel. Test L2 Loss :  0.05421519815921783  Test L2 Loss :  0.09573968976736069  inv_L_scale:  [1.0, 1.0]
Epoch :  91  Time:  0.942  Rel. Train L2 Loss :  0.04360398166709476  Rel. Test L2 Loss :  0.043427466899156573  Test L2 Loss :  0.07672637820243836  inv_L_scale:  [1.0, 1.0]
Epoch :  92  Time:  0.944  Rel. Train L2 Loss :  0.04305499189429813  Rel. Test L2 Loss :  0.04740826904773712  Test L2 Loss :  0.08443664401769638  inv_L_scale:  [1.0, 1.0]
Epoch :  93  Time:  0.942  Rel. Train L2 Loss :  0.04346074256632063  Rel. Test L2 Loss :  0.04630790859460831  Test L2 Loss :  0.08239147216081619  inv_L_scale:  [1.0, 1.0]
Epoch :  94  Time:  0.943  Rel. Train L2 Loss :  0.04273208214177026  Rel. Test L2 Loss :  0.04375388577580452  Test L2 Loss :  0.07657140105962754  inv_L_scale:  [1.0, 1.0]
Epoch :  95  Time:  0.942  Rel. Train L2 Loss :  0.04193587606151899  Rel. Test L2 Loss :  0.04654798373579979  Test L2 Loss :  0.08162173420190812  inv_L_scale:  [1.0, 1.0]
Epoch :  96  Time:  0.942  Rel. Train L2 Loss :  0.041965140087736975  Rel. Test L2 Loss :  0.04397556081414223  Test L2 Loss :  0.07735185861587525  inv_L_scale:  [1.0, 1.0]
Epoch :  97  Time:  0.942  Rel. Train L2 Loss :  0.04217539370059967  Rel. Test L2 Loss :  0.04707636445760727  Test L2 Loss :  0.08287730932235718  inv_L_scale:  [1.0, 1.0]
Epoch :  98  Time:  0.942  Rel. Train L2 Loss :  0.04156946149137285  Rel. Test L2 Loss :  0.05286253109574318  Test L2 Loss :  0.09434182316064835  inv_L_scale:  [1.0, 1.0]
Epoch :  99  Time:  0.942  Rel. Train L2 Loss :  0.042595550467570624  Rel. Test L2 Loss :  0.05014553815126419  Test L2 Loss :  0.0893819910287857  inv_L_scale:  [1.0, 1.0]
Epoch :  100  Time:  0.945  Rel. Train L2 Loss :  0.04212602198123932  Rel. Test L2 Loss :  0.044085487574338916  Test L2 Loss :  0.0775892248749733  inv_L_scale:  [1.0, 1.0]
Epoch :  101  Time:  0.943  Rel. Train L2 Loss :  0.04184389708770646  Rel. Test L2 Loss :  0.04222703069448471  Test L2 Loss :  0.07467942595481873  inv_L_scale:  [1.0, 1.0]
Epoch :  102  Time:  0.942  Rel. Train L2 Loss :  0.041787172605593996  Rel. Test L2 Loss :  0.04253189519047737  Test L2 Loss :  0.07430081129074097  inv_L_scale:  [1.0, 1.0]
Epoch :  103  Time:  0.943  Rel. Train L2 Loss :  0.04125599086284638  Rel. Test L2 Loss :  0.044007203429937365  Test L2 Loss :  0.07793050467967987  inv_L_scale:  [1.0, 1.0]
Epoch :  104  Time:  0.943  Rel. Train L2 Loss :  0.04145462551050716  Rel. Test L2 Loss :  0.04470875144004822  Test L2 Loss :  0.07909915447235108  inv_L_scale:  [1.0, 1.0]
Epoch :  105  Time:  0.943  Rel. Train L2 Loss :  0.04169835322433048  Rel. Test L2 Loss :  0.04476585060358047  Test L2 Loss :  0.07893903732299805  inv_L_scale:  [1.0, 1.0]
Epoch :  106  Time:  0.942  Rel. Train L2 Loss :  0.04110098701384333  Rel. Test L2 Loss :  0.044382089972496035  Test L2 Loss :  0.07883535742759705  inv_L_scale:  [1.0, 1.0]
Epoch :  107  Time:  0.942  Rel. Train L2 Loss :  0.0412134117881457  Rel. Test L2 Loss :  0.04348722517490387  Test L2 Loss :  0.07648057609796524  inv_L_scale:  [1.0, 1.0]
Epoch :  108  Time:  0.942  Rel. Train L2 Loss :  0.04073569042815103  Rel. Test L2 Loss :  0.046854548156261444  Test L2 Loss :  0.08495414316654205  inv_L_scale:  [1.0, 1.0]
Epoch :  109  Time:  0.943  Rel. Train L2 Loss :  0.041059549268749024  Rel. Test L2 Loss :  0.04546774551272392  Test L2 Loss :  0.08036567151546478  inv_L_scale:  [1.0, 1.0]
Epoch :  110  Time:  0.943  Rel. Train L2 Loss :  0.04108960575527615  Rel. Test L2 Loss :  0.041231756210327146  Test L2 Loss :  0.07140423119068146  inv_L_scale:  [1.0, 1.0]
Epoch :  111  Time:  0.942  Rel. Train L2 Loss :  0.040366880397001904  Rel. Test L2 Loss :  0.049427361637353895  Test L2 Loss :  0.0890715017914772  inv_L_scale:  [1.0, 1.0]
Epoch :  112  Time:  0.943  Rel. Train L2 Loss :  0.04102657304869758  Rel. Test L2 Loss :  0.04328230381011963  Test L2 Loss :  0.07616505771875381  inv_L_scale:  [1.0, 1.0]
Epoch :  113  Time:  0.943  Rel. Train L2 Loss :  0.0404095104502307  Rel. Test L2 Loss :  0.04300815612077713  Test L2 Loss :  0.07552288562059402  inv_L_scale:  [1.0, 1.0]
Epoch :  114  Time:  0.943  Rel. Train L2 Loss :  0.040231615371174284  Rel. Test L2 Loss :  0.04180000245571137  Test L2 Loss :  0.07401431351900101  inv_L_scale:  [1.0, 1.0]
Epoch :  115  Time:  0.943  Rel. Train L2 Loss :  0.04046656773322158  Rel. Test L2 Loss :  0.043809082508087155  Test L2 Loss :  0.07696876764297485  inv_L_scale:  [1.0, 1.0]
Epoch :  116  Time:  0.942  Rel. Train L2 Loss :  0.03999157610866758  Rel. Test L2 Loss :  0.04455030009150505  Test L2 Loss :  0.07918646693229675  inv_L_scale:  [1.0, 1.0]
Epoch :  117  Time:  0.942  Rel. Train L2 Loss :  0.03947605977455775  Rel. Test L2 Loss :  0.041802654266357424  Test L2 Loss :  0.07408051878213882  inv_L_scale:  [1.0, 1.0]
Epoch :  118  Time:  0.943  Rel. Train L2 Loss :  0.03980731316738659  Rel. Test L2 Loss :  0.039713832139968874  Test L2 Loss :  0.07018013149499894  inv_L_scale:  [1.0, 1.0]
Epoch :  119  Time:  0.942  Rel. Train L2 Loss :  0.039320872227350874  Rel. Test L2 Loss :  0.044027558714151385  Test L2 Loss :  0.07720034599304199  inv_L_scale:  [1.0, 1.0]
Epoch :  120  Time:  0.943  Rel. Train L2 Loss :  0.03982870668172836  Rel. Test L2 Loss :  0.04116785824298859  Test L2 Loss :  0.07215981423854828  inv_L_scale:  [1.0, 1.0]
Epoch :  121  Time:  0.942  Rel. Train L2 Loss :  0.039427741517623266  Rel. Test L2 Loss :  0.04369334816932678  Test L2 Loss :  0.07828975588083267  inv_L_scale:  [1.0, 1.0]
Epoch :  122  Time:  0.942  Rel. Train L2 Loss :  0.039161966741085054  Rel. Test L2 Loss :  0.04251618444919586  Test L2 Loss :  0.07475486487150192  inv_L_scale:  [1.0, 1.0]
Epoch :  123  Time:  0.944  Rel. Train L2 Loss :  0.03950489376982053  Rel. Test L2 Loss :  0.03975002869963646  Test L2 Loss :  0.0698781281709671  inv_L_scale:  [1.0, 1.0]
Epoch :  124  Time:  0.944  Rel. Train L2 Loss :  0.03988357726070616  Rel. Test L2 Loss :  0.04235509604215622  Test L2 Loss :  0.07424564778804779  inv_L_scale:  [1.0, 1.0]
Epoch :  125  Time:  0.943  Rel. Train L2 Loss :  0.038621444371011525  Rel. Test L2 Loss :  0.040194047093391416  Test L2 Loss :  0.07033583104610443  inv_L_scale:  [1.0, 1.0]
Epoch :  126  Time:  0.943  Rel. Train L2 Loss :  0.03903787852989303  Rel. Test L2 Loss :  0.04162447318434715  Test L2 Loss :  0.0726322889328003  inv_L_scale:  [1.0, 1.0]
Epoch :  127  Time:  0.942  Rel. Train L2 Loss :  0.039027305444081624  Rel. Test L2 Loss :  0.04207004278898239  Test L2 Loss :  0.07471661269664764  inv_L_scale:  [1.0, 1.0]
Epoch :  128  Time:  0.943  Rel. Train L2 Loss :  0.03860751157005628  Rel. Test L2 Loss :  0.042171755284070966  Test L2 Loss :  0.0746141129732132  inv_L_scale:  [1.0, 1.0]
Epoch :  129  Time:  0.943  Rel. Train L2 Loss :  0.0385508041911655  Rel. Test L2 Loss :  0.0408768031001091  Test L2 Loss :  0.0721156308054924  inv_L_scale:  [1.0, 1.0]
Epoch :  130  Time:  0.942  Rel. Train L2 Loss :  0.03872782735360993  Rel. Test L2 Loss :  0.041033540368080136  Test L2 Loss :  0.07281621724367142  inv_L_scale:  [1.0, 1.0]
Epoch :  131  Time:  0.942  Rel. Train L2 Loss :  0.03843517980641789  Rel. Test L2 Loss :  0.04058805510401726  Test L2 Loss :  0.07202040612697601  inv_L_scale:  [1.0, 1.0]
Epoch :  132  Time:  0.942  Rel. Train L2 Loss :  0.0379873716003365  Rel. Test L2 Loss :  0.04362282142043114  Test L2 Loss :  0.07714480221271515  inv_L_scale:  [1.0, 1.0]
Epoch :  133  Time:  0.943  Rel. Train L2 Loss :  0.03908738263779216  Rel. Test L2 Loss :  0.04067916065454483  Test L2 Loss :  0.07136566907167435  inv_L_scale:  [1.0, 1.0]
Epoch :  134  Time:  0.943  Rel. Train L2 Loss :  0.0382538511024581  Rel. Test L2 Loss :  0.039977806210517886  Test L2 Loss :  0.0698913437128067  inv_L_scale:  [1.0, 1.0]
Epoch :  135  Time:  0.942  Rel. Train L2 Loss :  0.03832326552934117  Rel. Test L2 Loss :  0.04033212065696716  Test L2 Loss :  0.07065602362155915  inv_L_scale:  [1.0, 1.0]
Epoch :  136  Time:  0.942  Rel. Train L2 Loss :  0.03879046415289243  Rel. Test L2 Loss :  0.04014194056391716  Test L2 Loss :  0.07053496569395065  inv_L_scale:  [1.0, 1.0]
Epoch :  137  Time:  0.942  Rel. Train L2 Loss :  0.037770965703659586  Rel. Test L2 Loss :  0.041283372044563296  Test L2 Loss :  0.07217822790145874  inv_L_scale:  [1.0, 1.0]
Epoch :  138  Time:  0.942  Rel. Train L2 Loss :  0.0380545323010948  Rel. Test L2 Loss :  0.04079657018184662  Test L2 Loss :  0.07191155076026917  inv_L_scale:  [1.0, 1.0]
Epoch :  139  Time:  0.943  Rel. Train L2 Loss :  0.03752126908964581  Rel. Test L2 Loss :  0.03933879852294922  Test L2 Loss :  0.06961181342601776  inv_L_scale:  [1.0, 1.0]
Epoch :  140  Time:  0.944  Rel. Train L2 Loss :  0.037305733429061044  Rel. Test L2 Loss :  0.03943516463041306  Test L2 Loss :  0.0694555625319481  inv_L_scale:  [1.0, 1.0]
Epoch :  141  Time:  0.943  Rel. Train L2 Loss :  0.03784773707389832  Rel. Test L2 Loss :  0.04001895993947983  Test L2 Loss :  0.07002219200134277  inv_L_scale:  [1.0, 1.0]
Epoch :  142  Time:  0.942  Rel. Train L2 Loss :  0.037751508115066425  Rel. Test L2 Loss :  0.039508795589208605  Test L2 Loss :  0.06951584815979003  inv_L_scale:  [1.0, 1.0]
Epoch :  143  Time:  0.943  Rel. Train L2 Loss :  0.03814002045326763  Rel. Test L2 Loss :  0.044900862872600554  Test L2 Loss :  0.0785800951719284  inv_L_scale:  [1.0, 1.0]
Epoch :  144  Time:  0.942  Rel. Train L2 Loss :  0.03785441329081853  Rel. Test L2 Loss :  0.04125402927398682  Test L2 Loss :  0.0732628783583641  inv_L_scale:  [1.0, 1.0]
Epoch :  145  Time:  0.943  Rel. Train L2 Loss :  0.0377565208905273  Rel. Test L2 Loss :  0.04031309217214584  Test L2 Loss :  0.07132404208183289  inv_L_scale:  [1.0, 1.0]
Epoch :  146  Time:  0.943  Rel. Train L2 Loss :  0.037830610523621244  Rel. Test L2 Loss :  0.038938274681568144  Test L2 Loss :  0.06790081530809403  inv_L_scale:  [1.0, 1.0]
Epoch :  147  Time:  0.942  Rel. Train L2 Loss :  0.037219337738222544  Rel. Test L2 Loss :  0.0397082307934761  Test L2 Loss :  0.06983007669448853  inv_L_scale:  [1.0, 1.0]
Epoch :  148  Time:  0.942  Rel. Train L2 Loss :  0.0373300799396303  Rel. Test L2 Loss :  0.03854505807161331  Test L2 Loss :  0.06802043199539184  inv_L_scale:  [1.0, 1.0]
Epoch :  149  Time:  0.942  Rel. Train L2 Loss :  0.03749998628265328  Rel. Test L2 Loss :  0.04118695184588432  Test L2 Loss :  0.07278351753950119  inv_L_scale:  [1.0, 1.0]
Epoch :  150  Time:  0.943  Rel. Train L2 Loss :  0.037014796021911836  Rel. Test L2 Loss :  0.03871307715773582  Test L2 Loss :  0.06739699959754944  inv_L_scale:  [1.0, 1.0]
Epoch :  151  Time:  0.944  Rel. Train L2 Loss :  0.037279404087199104  Rel. Test L2 Loss :  0.040599223673343655  Test L2 Loss :  0.07130773603916168  inv_L_scale:  [1.0, 1.0]
Epoch :  152  Time:  0.944  Rel. Train L2 Loss :  0.03758049681782723  Rel. Test L2 Loss :  0.03907466322183609  Test L2 Loss :  0.06848125159740448  inv_L_scale:  [1.0, 1.0]
Epoch :  153  Time:  0.942  Rel. Train L2 Loss :  0.03682399766312705  Rel. Test L2 Loss :  0.03888740390539169  Test L2 Loss :  0.06820670932531357  inv_L_scale:  [1.0, 1.0]
Epoch :  154  Time:  0.943  Rel. Train L2 Loss :  0.03753660961985588  Rel. Test L2 Loss :  0.04073108673095703  Test L2 Loss :  0.07336655139923096  inv_L_scale:  [1.0, 1.0]
Epoch :  155  Time:  0.942  Rel. Train L2 Loss :  0.03666549070013894  Rel. Test L2 Loss :  0.03922159671783447  Test L2 Loss :  0.0685583546757698  inv_L_scale:  [1.0, 1.0]
Epoch :  156  Time:  0.943  Rel. Train L2 Loss :  0.037211067560646266  Rel. Test L2 Loss :  0.04176306590437889  Test L2 Loss :  0.0736810877919197  inv_L_scale:  [1.0, 1.0]
Epoch :  157  Time:  0.942  Rel. Train L2 Loss :  0.0374044631421566  Rel. Test L2 Loss :  0.042282570898532865  Test L2 Loss :  0.07588464677333832  inv_L_scale:  [1.0, 1.0]
Epoch :  158  Time:  0.943  Rel. Train L2 Loss :  0.036837411787774825  Rel. Test L2 Loss :  0.0396483314037323  Test L2 Loss :  0.07006590187549591  inv_L_scale:  [1.0, 1.0]
Epoch :  159  Time:  0.942  Rel. Train L2 Loss :  0.03631847684582074  Rel. Test L2 Loss :  0.03869673267006874  Test L2 Loss :  0.06779841840267181  inv_L_scale:  [1.0, 1.0]
Epoch :  160  Time:  0.942  Rel. Train L2 Loss :  0.03651296392083168  Rel. Test L2 Loss :  0.03927059918642044  Test L2 Loss :  0.06862762689590454  inv_L_scale:  [1.0, 1.0]
Epoch :  161  Time:  0.942  Rel. Train L2 Loss :  0.03670080890258153  Rel. Test L2 Loss :  0.03875533074140549  Test L2 Loss :  0.06776400417089462  inv_L_scale:  [1.0, 1.0]
Epoch :  162  Time:  0.941  Rel. Train L2 Loss :  0.03663750813239151  Rel. Test L2 Loss :  0.040154071748256685  Test L2 Loss :  0.07101959824562072  inv_L_scale:  [1.0, 1.0]
Epoch :  163  Time:  0.942  Rel. Train L2 Loss :  0.03640052714281612  Rel. Test L2 Loss :  0.03858295664191246  Test L2 Loss :  0.06776953607797623  inv_L_scale:  [1.0, 1.0]
Epoch :  164  Time:  0.942  Rel. Train L2 Loss :  0.03652461914552583  Rel. Test L2 Loss :  0.03769317299127579  Test L2 Loss :  0.06550436705350876  inv_L_scale:  [1.0, 1.0]
Epoch :  165  Time:  0.941  Rel. Train L2 Loss :  0.03606080159544945  Rel. Test L2 Loss :  0.03926927000284195  Test L2 Loss :  0.06837267875671386  inv_L_scale:  [1.0, 1.0]
Epoch :  166  Time:  0.941  Rel. Train L2 Loss :  0.03639815400871966  Rel. Test L2 Loss :  0.03962091267108917  Test L2 Loss :  0.06969663888216018  inv_L_scale:  [1.0, 1.0]
Epoch :  167  Time:  0.942  Rel. Train L2 Loss :  0.03629584973057111  Rel. Test L2 Loss :  0.037886840254068375  Test L2 Loss :  0.0664447546005249  inv_L_scale:  [1.0, 1.0]
Epoch :  168  Time:  0.943  Rel. Train L2 Loss :  0.036105322821272746  Rel. Test L2 Loss :  0.04029249265789986  Test L2 Loss :  0.07162354826927185  inv_L_scale:  [1.0, 1.0]
Epoch :  169  Time:  0.941  Rel. Train L2 Loss :  0.036119138093458285  Rel. Test L2 Loss :  0.03828061133623123  Test L2 Loss :  0.06713166773319244  inv_L_scale:  [1.0, 1.0]
Epoch :  170  Time:  0.941  Rel. Train L2 Loss :  0.035735331641303165  Rel. Test L2 Loss :  0.03838733673095703  Test L2 Loss :  0.0666785392165184  inv_L_scale:  [1.0, 1.0]
Epoch :  171  Time:  0.942  Rel. Train L2 Loss :  0.03610432412061426  Rel. Test L2 Loss :  0.03969136402010918  Test L2 Loss :  0.07032366633415223  inv_L_scale:  [1.0, 1.0]
Epoch :  172  Time:  0.942  Rel. Train L2 Loss :  0.03590387008256382  Rel. Test L2 Loss :  0.036677849292755124  Test L2 Loss :  0.06413340449333191  inv_L_scale:  [1.0, 1.0]
Epoch :  173  Time:  0.941  Rel. Train L2 Loss :  0.03599066746731599  Rel. Test L2 Loss :  0.04104004472494125  Test L2 Loss :  0.07345133900642395  inv_L_scale:  [1.0, 1.0]
Epoch :  174  Time:  0.942  Rel. Train L2 Loss :  0.036202811996142066  Rel. Test L2 Loss :  0.040330220758914945  Test L2 Loss :  0.07159201115369797  inv_L_scale:  [1.0, 1.0]
Epoch :  175  Time:  0.941  Rel. Train L2 Loss :  0.03584639287657208  Rel. Test L2 Loss :  0.0388319319486618  Test L2 Loss :  0.06778668284416199  inv_L_scale:  [1.0, 1.0]
Epoch :  176  Time:  0.942  Rel. Train L2 Loss :  0.03670700313316451  Rel. Test L2 Loss :  0.039077934026718136  Test L2 Loss :  0.0683673968911171  inv_L_scale:  [1.0, 1.0]
Epoch :  177  Time:  0.942  Rel. Train L2 Loss :  0.035652415835195114  Rel. Test L2 Loss :  0.038251114636659624  Test L2 Loss :  0.06689176678657532  inv_L_scale:  [1.0, 1.0]
Epoch :  178  Time:  0.941  Rel. Train L2 Loss :  0.036061010534564654  Rel. Test L2 Loss :  0.039216498285531996  Test L2 Loss :  0.06862609356641769  inv_L_scale:  [1.0, 1.0]
Epoch :  179  Time:  0.942  Rel. Train L2 Loss :  0.03557459768321779  Rel. Test L2 Loss :  0.03814385980367661  Test L2 Loss :  0.06744473159313202  inv_L_scale:  [1.0, 1.0]
Epoch :  180  Time:  0.942  Rel. Train L2 Loss :  0.03585799738764763  Rel. Test L2 Loss :  0.03835528552532196  Test L2 Loss :  0.06732786267995834  inv_L_scale:  [1.0, 1.0]
Epoch :  181  Time:  0.942  Rel. Train L2 Loss :  0.035826278461350336  Rel. Test L2 Loss :  0.04065207377076149  Test L2 Loss :  0.07143652677536011  inv_L_scale:  [1.0, 1.0]
Epoch :  182  Time:  0.941  Rel. Train L2 Loss :  0.035522862904601625  Rel. Test L2 Loss :  0.038038490861654284  Test L2 Loss :  0.06647623419761657  inv_L_scale:  [1.0, 1.0]
Epoch :  183  Time:  0.941  Rel. Train L2 Loss :  0.03552665851182408  Rel. Test L2 Loss :  0.038808867037296295  Test L2 Loss :  0.06904752761125564  inv_L_scale:  [1.0, 1.0]
Epoch :  184  Time:  0.941  Rel. Train L2 Loss :  0.03570821815066867  Rel. Test L2 Loss :  0.039260452091693876  Test L2 Loss :  0.06911652535200119  inv_L_scale:  [1.0, 1.0]
Epoch :  185  Time:  0.944  Rel. Train L2 Loss :  0.0355130873951647  Rel. Test L2 Loss :  0.03678521364927292  Test L2 Loss :  0.06425551176071168  inv_L_scale:  [1.0, 1.0]
Epoch :  186  Time:  0.942  Rel. Train L2 Loss :  0.03536889612674713  Rel. Test L2 Loss :  0.03873904213309288  Test L2 Loss :  0.06781188994646073  inv_L_scale:  [1.0, 1.0]
Epoch :  187  Time:  0.942  Rel. Train L2 Loss :  0.0353016971051693  Rel. Test L2 Loss :  0.03866006530821323  Test L2 Loss :  0.06750785231590271  inv_L_scale:  [1.0, 1.0]
Epoch :  188  Time:  0.942  Rel. Train L2 Loss :  0.03555074104004436  Rel. Test L2 Loss :  0.037552064061164854  Test L2 Loss :  0.06545450031757355  inv_L_scale:  [1.0, 1.0]
Epoch :  189  Time:  0.942  Rel. Train L2 Loss :  0.035228130999538636  Rel. Test L2 Loss :  0.03794590912759304  Test L2 Loss :  0.06705581545829772  inv_L_scale:  [1.0, 1.0]
Epoch :  190  Time:  0.942  Rel. Train L2 Loss :  0.03560701916615168  Rel. Test L2 Loss :  0.03652890413999557  Test L2 Loss :  0.06361702382564545  inv_L_scale:  [1.0, 1.0]
Epoch :  191  Time:  0.942  Rel. Train L2 Loss :  0.034833249631855225  Rel. Test L2 Loss :  0.03866415679454804  Test L2 Loss :  0.06762528270483018  inv_L_scale:  [1.0, 1.0]
Epoch :  192  Time:  0.941  Rel. Train L2 Loss :  0.03531413214074241  Rel. Test L2 Loss :  0.03782951563596725  Test L2 Loss :  0.06606348320841789  inv_L_scale:  [1.0, 1.0]
Epoch :  193  Time:  0.942  Rel. Train L2 Loss :  0.035362323025862376  Rel. Test L2 Loss :  0.043011670261621476  Test L2 Loss :  0.07689202964305877  inv_L_scale:  [1.0, 1.0]
Epoch :  194  Time:  0.942  Rel. Train L2 Loss :  0.035264286150534944  Rel. Test L2 Loss :  0.036706338748335836  Test L2 Loss :  0.06396638303995132  inv_L_scale:  [1.0, 1.0]
Epoch :  195  Time:  0.942  Rel. Train L2 Loss :  0.034881722331047055  Rel. Test L2 Loss :  0.03717591300606728  Test L2 Loss :  0.06522822916507721  inv_L_scale:  [1.0, 1.0]
Epoch :  196  Time:  0.941  Rel. Train L2 Loss :  0.035102776976095304  Rel. Test L2 Loss :  0.038133678436279295  Test L2 Loss :  0.06716935336589813  inv_L_scale:  [1.0, 1.0]
Epoch :  197  Time:  0.942  Rel. Train L2 Loss :  0.034992851027184066  Rel. Test L2 Loss :  0.039297898560762407  Test L2 Loss :  0.06862337172031402  inv_L_scale:  [1.0, 1.0]
Epoch :  198  Time:  0.941  Rel. Train L2 Loss :  0.03504116412666109  Rel. Test L2 Loss :  0.03696183741092682  Test L2 Loss :  0.06482541844248772  inv_L_scale:  [1.0, 1.0]
Epoch :  199  Time:  0.941  Rel. Train L2 Loss :  0.03487567386693425  Rel. Test L2 Loss :  0.03705858141183853  Test L2 Loss :  0.06518817961215972  inv_L_scale:  [1.0, 1.0]
Epoch :  200  Time:  0.942  Rel. Train L2 Loss :  0.03448084404071172  Rel. Test L2 Loss :  0.0360648062825203  Test L2 Loss :  0.06287233963608742  inv_L_scale:  [1.0, 1.0]
Epoch :  201  Time:  0.944  Rel. Train L2 Loss :  0.0346624309486813  Rel. Test L2 Loss :  0.03785460546612739  Test L2 Loss :  0.06601568341255187  inv_L_scale:  [1.0, 1.0]
Epoch :  202  Time:  0.941  Rel. Train L2 Loss :  0.034822347081369824  Rel. Test L2 Loss :  0.03718229666352272  Test L2 Loss :  0.06537485912442208  inv_L_scale:  [1.0, 1.0]
Epoch :  203  Time:  0.941  Rel. Train L2 Loss :  0.034772424598534905  Rel. Test L2 Loss :  0.03724586471915245  Test L2 Loss :  0.06578205168247223  inv_L_scale:  [1.0, 1.0]
Epoch :  204  Time:  0.941  Rel. Train L2 Loss :  0.03461122322413657  Rel. Test L2 Loss :  0.037533338367939  Test L2 Loss :  0.0656807678937912  inv_L_scale:  [1.0, 1.0]
Epoch :  205  Time:  0.941  Rel. Train L2 Loss :  0.03432569745514128  Rel. Test L2 Loss :  0.03671515792608261  Test L2 Loss :  0.06370687037706375  inv_L_scale:  [1.0, 1.0]
Epoch :  206  Time:  0.941  Rel. Train L2 Loss :  0.034647399601009155  Rel. Test L2 Loss :  0.036834768503904346  Test L2 Loss :  0.06389302864670754  inv_L_scale:  [1.0, 1.0]
Epoch :  207  Time:  0.941  Rel. Train L2 Loss :  0.03452419055832757  Rel. Test L2 Loss :  0.03726307734847069  Test L2 Loss :  0.06478038251399994  inv_L_scale:  [1.0, 1.0]
Epoch :  208  Time:  0.943  Rel. Train L2 Loss :  0.03455043913589584  Rel. Test L2 Loss :  0.037944317758083344  Test L2 Loss :  0.06661667943000793  inv_L_scale:  [1.0, 1.0]
Epoch :  209  Time:  0.941  Rel. Train L2 Loss :  0.03424327686429024  Rel. Test L2 Loss :  0.0370275866240263  Test L2 Loss :  0.06500763580203056  inv_L_scale:  [1.0, 1.0]
Epoch :  210  Time:  0.942  Rel. Train L2 Loss :  0.03452321252889103  Rel. Test L2 Loss :  0.03669877976179123  Test L2 Loss :  0.06400848388671875  inv_L_scale:  [1.0, 1.0]
Epoch :  211  Time:  0.942  Rel. Train L2 Loss :  0.034176967028114534  Rel. Test L2 Loss :  0.03732629373669624  Test L2 Loss :  0.065500208735466  inv_L_scale:  [1.0, 1.0]
Epoch :  212  Time:  0.942  Rel. Train L2 Loss :  0.03444401451283031  Rel. Test L2 Loss :  0.03637292042374611  Test L2 Loss :  0.06403658956289292  inv_L_scale:  [1.0, 1.0]
Epoch :  213  Time:  0.942  Rel. Train L2 Loss :  0.03447414401504729  Rel. Test L2 Loss :  0.03752764135599136  Test L2 Loss :  0.06587287738919258  inv_L_scale:  [1.0, 1.0]
Epoch :  214  Time:  0.941  Rel. Train L2 Loss :  0.034111546617415216  Rel. Test L2 Loss :  0.03838900953531265  Test L2 Loss :  0.06785714209079742  inv_L_scale:  [1.0, 1.0]
Epoch :  215  Time:  0.942  Rel. Train L2 Loss :  0.03439713276094861  Rel. Test L2 Loss :  0.036351291239261625  Test L2 Loss :  0.0641536195576191  inv_L_scale:  [1.0, 1.0]
Epoch :  216  Time:  0.941  Rel. Train L2 Loss :  0.034088453840878274  Rel. Test L2 Loss :  0.03798912048339844  Test L2 Loss :  0.0660618507862091  inv_L_scale:  [1.0, 1.0]
Epoch :  217  Time:  0.941  Rel. Train L2 Loss :  0.03429296405778991  Rel. Test L2 Loss :  0.03607838578522205  Test L2 Loss :  0.06324561789631844  inv_L_scale:  [1.0, 1.0]
Epoch :  218  Time:  0.942  Rel. Train L2 Loss :  0.03427885484364298  Rel. Test L2 Loss :  0.03760999366641045  Test L2 Loss :  0.06640044122934341  inv_L_scale:  [1.0, 1.0]
Epoch :  219  Time:  0.941  Rel. Train L2 Loss :  0.03393853916062249  Rel. Test L2 Loss :  0.037987139523029324  Test L2 Loss :  0.0669207987189293  inv_L_scale:  [1.0, 1.0]
Epoch :  220  Time:  0.941  Rel. Train L2 Loss :  0.03391311325960689  Rel. Test L2 Loss :  0.03784041464328766  Test L2 Loss :  0.06757161021232605  inv_L_scale:  [1.0, 1.0]
Epoch :  221  Time:  0.941  Rel. Train L2 Loss :  0.03391083353095584  Rel. Test L2 Loss :  0.03843991205096245  Test L2 Loss :  0.06717423379421233  inv_L_scale:  [1.0, 1.0]
Epoch :  222  Time:  0.942  Rel. Train L2 Loss :  0.03441029811898867  Rel. Test L2 Loss :  0.03514681726694107  Test L2 Loss :  0.06133156180381775  inv_L_scale:  [1.0, 1.0]
Epoch :  223  Time:  0.942  Rel. Train L2 Loss :  0.033769921138882636  Rel. Test L2 Loss :  0.03570235088467598  Test L2 Loss :  0.06230795636773109  inv_L_scale:  [1.0, 1.0]
Epoch :  224  Time:  0.941  Rel. Train L2 Loss :  0.03399532886015044  Rel. Test L2 Loss :  0.0367949254065752  Test L2 Loss :  0.06450943052768707  inv_L_scale:  [1.0, 1.0]
Epoch :  225  Time:  0.941  Rel. Train L2 Loss :  0.03405441257688734  Rel. Test L2 Loss :  0.03686048060655594  Test L2 Loss :  0.06510774403810501  inv_L_scale:  [1.0, 1.0]
Epoch :  226  Time:  0.941  Rel. Train L2 Loss :  0.03402058052519957  Rel. Test L2 Loss :  0.03647015288472175  Test L2 Loss :  0.06454329222440719  inv_L_scale:  [1.0, 1.0]
Epoch :  227  Time:  0.941  Rel. Train L2 Loss :  0.033735141108433404  Rel. Test L2 Loss :  0.035519356578588485  Test L2 Loss :  0.06230531245470047  inv_L_scale:  [1.0, 1.0]
Epoch :  228  Time:  0.941  Rel. Train L2 Loss :  0.03371109601524141  Rel. Test L2 Loss :  0.03635525345802307  Test L2 Loss :  0.06390049338340759  inv_L_scale:  [1.0, 1.0]
Epoch :  229  Time:  0.941  Rel. Train L2 Loss :  0.03338579901390606  Rel. Test L2 Loss :  0.03585140533745289  Test L2 Loss :  0.06335934460163116  inv_L_scale:  [1.0, 1.0]
Epoch :  230  Time:  0.941  Rel. Train L2 Loss :  0.033566614240407945  Rel. Test L2 Loss :  0.034944772124290466  Test L2 Loss :  0.06126341462135315  inv_L_scale:  [1.0, 1.0]
Epoch :  231  Time:  0.941  Rel. Train L2 Loss :  0.03320309365789095  Rel. Test L2 Loss :  0.038011995553970335  Test L2 Loss :  0.06731330960988999  inv_L_scale:  [1.0, 1.0]
Epoch :  232  Time:  0.941  Rel. Train L2 Loss :  0.0335980516175429  Rel. Test L2 Loss :  0.03505077138543129  Test L2 Loss :  0.06105043053627014  inv_L_scale:  [1.0, 1.0]
Epoch :  233  Time:  0.943  Rel. Train L2 Loss :  0.033361048731538986  Rel. Test L2 Loss :  0.036444992572069165  Test L2 Loss :  0.06382624030113221  inv_L_scale:  [1.0, 1.0]
Epoch :  234  Time:  0.942  Rel. Train L2 Loss :  0.0332383384472794  Rel. Test L2 Loss :  0.036726138144731524  Test L2 Loss :  0.06453896433115006  inv_L_scale:  [1.0, 1.0]
Epoch :  235  Time:  0.941  Rel. Train L2 Loss :  0.033353534440199534  Rel. Test L2 Loss :  0.0352198377251625  Test L2 Loss :  0.06158174961805343  inv_L_scale:  [1.0, 1.0]
Epoch :  236  Time:  0.941  Rel. Train L2 Loss :  0.033184906045595805  Rel. Test L2 Loss :  0.03527937762439251  Test L2 Loss :  0.06157448947429657  inv_L_scale:  [1.0, 1.0]
Epoch :  237  Time:  0.941  Rel. Train L2 Loss :  0.03347068091233572  Rel. Test L2 Loss :  0.03518682077527046  Test L2 Loss :  0.06159607380628586  inv_L_scale:  [1.0, 1.0]
Epoch :  238  Time:  0.941  Rel. Train L2 Loss :  0.03314387158387237  Rel. Test L2 Loss :  0.03723444879055023  Test L2 Loss :  0.06508163869380951  inv_L_scale:  [1.0, 1.0]
Epoch :  239  Time:  0.941  Rel. Train L2 Loss :  0.03339358910918236  Rel. Test L2 Loss :  0.03542666234076023  Test L2 Loss :  0.06224702805280685  inv_L_scale:  [1.0, 1.0]
Epoch :  240  Time:  0.941  Rel. Train L2 Loss :  0.033386216652062206  Rel. Test L2 Loss :  0.03682634264230728  Test L2 Loss :  0.06464088141918183  inv_L_scale:  [1.0, 1.0]
Epoch :  241  Time:  0.941  Rel. Train L2 Loss :  0.03303826539052857  Rel. Test L2 Loss :  0.03649299293756485  Test L2 Loss :  0.06416469812393188  inv_L_scale:  [1.0, 1.0]
Epoch :  242  Time:  0.941  Rel. Train L2 Loss :  0.03326095826096005  Rel. Test L2 Loss :  0.035511699020862576  Test L2 Loss :  0.06286619067192077  inv_L_scale:  [1.0, 1.0]
Epoch :  243  Time:  0.942  Rel. Train L2 Loss :  0.033431759145524764  Rel. Test L2 Loss :  0.03559521570801735  Test L2 Loss :  0.06241231888532638  inv_L_scale:  [1.0, 1.0]
Epoch :  244  Time:  0.941  Rel. Train L2 Loss :  0.03335443605979284  Rel. Test L2 Loss :  0.03505295544862747  Test L2 Loss :  0.06134795397520065  inv_L_scale:  [1.0, 1.0]
Epoch :  245  Time:  0.941  Rel. Train L2 Loss :  0.033182367384433746  Rel. Test L2 Loss :  0.035178516656160355  Test L2 Loss :  0.0614318810403347  inv_L_scale:  [1.0, 1.0]
Epoch :  246  Time:  0.941  Rel. Train L2 Loss :  0.033030040678050786  Rel. Test L2 Loss :  0.03522589549422264  Test L2 Loss :  0.06184006035327912  inv_L_scale:  [1.0, 1.0]
Epoch :  247  Time:  0.941  Rel. Train L2 Loss :  0.033008758086297246  Rel. Test L2 Loss :  0.03611486256122589  Test L2 Loss :  0.0631074783205986  inv_L_scale:  [1.0, 1.0]
Epoch :  248  Time:  0.941  Rel. Train L2 Loss :  0.03304362295402421  Rel. Test L2 Loss :  0.0364585480093956  Test L2 Loss :  0.06436723858118057  inv_L_scale:  [1.0, 1.0]
Epoch :  249  Time:  0.941  Rel. Train L2 Loss :  0.03319564261370235  Rel. Test L2 Loss :  0.03639493107795715  Test L2 Loss :  0.0644613853096962  inv_L_scale:  [1.0, 1.0]
Epoch :  250  Time:  0.941  Rel. Train L2 Loss :  0.03265778139233589  Rel. Test L2 Loss :  0.03537641614675522  Test L2 Loss :  0.061680195778608324  inv_L_scale:  [1.0, 1.0]
Epoch :  251  Time:  0.941  Rel. Train L2 Loss :  0.032905599176883696  Rel. Test L2 Loss :  0.03530805826187134  Test L2 Loss :  0.06130598768591881  inv_L_scale:  [1.0, 1.0]
Epoch :  252  Time:  0.942  Rel. Train L2 Loss :  0.032648995949162374  Rel. Test L2 Loss :  0.03462317392230034  Test L2 Loss :  0.06052435606718063  inv_L_scale:  [1.0, 1.0]
Epoch :  253  Time:  0.941  Rel. Train L2 Loss :  0.03300016508334213  Rel. Test L2 Loss :  0.034868545606732367  Test L2 Loss :  0.060946542322635654  inv_L_scale:  [1.0, 1.0]
Epoch :  254  Time:  0.941  Rel. Train L2 Loss :  0.032934399851494364  Rel. Test L2 Loss :  0.03536687880754471  Test L2 Loss :  0.06166569113731384  inv_L_scale:  [1.0, 1.0]
Epoch :  255  Time:  0.941  Rel. Train L2 Loss :  0.032669940027925705  Rel. Test L2 Loss :  0.03521133840084076  Test L2 Loss :  0.06194000154733658  inv_L_scale:  [1.0, 1.0]
Epoch :  256  Time:  0.941  Rel. Train L2 Loss :  0.03257630591591199  Rel. Test L2 Loss :  0.037491189688444136  Test L2 Loss :  0.06565963298082352  inv_L_scale:  [1.0, 1.0]
Epoch :  257  Time:  0.941  Rel. Train L2 Loss :  0.03299596573743555  Rel. Test L2 Loss :  0.03569028422236443  Test L2 Loss :  0.06252945452928543  inv_L_scale:  [1.0, 1.0]
Epoch :  258  Time:  0.941  Rel. Train L2 Loss :  0.0325474868549241  Rel. Test L2 Loss :  0.034472690671682356  Test L2 Loss :  0.060279528200626376  inv_L_scale:  [1.0, 1.0]
Epoch :  259  Time:  0.941  Rel. Train L2 Loss :  0.032287892740633754  Rel. Test L2 Loss :  0.036025635823607446  Test L2 Loss :  0.06329368844628334  inv_L_scale:  [1.0, 1.0]
Epoch :  260  Time:  0.941  Rel. Train L2 Loss :  0.03268706844912635  Rel. Test L2 Loss :  0.035141414850950244  Test L2 Loss :  0.062053768932819366  inv_L_scale:  [1.0, 1.0]
Epoch :  261  Time:  0.942  Rel. Train L2 Loss :  0.03230438022149934  Rel. Test L2 Loss :  0.03490932069718838  Test L2 Loss :  0.06123867571353912  inv_L_scale:  [1.0, 1.0]
Epoch :  262  Time:  0.942  Rel. Train L2 Loss :  0.03237439316180017  Rel. Test L2 Loss :  0.036129004433751104  Test L2 Loss :  0.06313077241182327  inv_L_scale:  [1.0, 1.0]
Epoch :  263  Time:  0.941  Rel. Train L2 Loss :  0.032235108440121014  Rel. Test L2 Loss :  0.03499366238713265  Test L2 Loss :  0.061492868065834046  inv_L_scale:  [1.0, 1.0]
Epoch :  264  Time:  0.941  Rel. Train L2 Loss :  0.032507023620936604  Rel. Test L2 Loss :  0.03484184145927429  Test L2 Loss :  0.06097594693303108  inv_L_scale:  [1.0, 1.0]
Epoch :  265  Time:  0.941  Rel. Train L2 Loss :  0.03266604167719682  Rel. Test L2 Loss :  0.03514629900455475  Test L2 Loss :  0.06149067759513855  inv_L_scale:  [1.0, 1.0]
Epoch :  266  Time:  0.941  Rel. Train L2 Loss :  0.03257635694411066  Rel. Test L2 Loss :  0.03427034243941307  Test L2 Loss :  0.06000517189502716  inv_L_scale:  [1.0, 1.0]
Epoch :  267  Time:  0.941  Rel. Train L2 Loss :  0.032371243089437486  Rel. Test L2 Loss :  0.033957115933299066  Test L2 Loss :  0.0592266047000885  inv_L_scale:  [1.0, 1.0]
Epoch :  268  Time:  0.941  Rel. Train L2 Loss :  0.03242163934641414  Rel. Test L2 Loss :  0.03509987756609917  Test L2 Loss :  0.06135574594140053  inv_L_scale:  [1.0, 1.0]
Epoch :  269  Time:  0.941  Rel. Train L2 Loss :  0.03235690348678165  Rel. Test L2 Loss :  0.034707910642027856  Test L2 Loss :  0.06106717079877853  inv_L_scale:  [1.0, 1.0]
Epoch :  270  Time:  0.941  Rel. Train L2 Loss :  0.03225395967562993  Rel. Test L2 Loss :  0.03530094623565674  Test L2 Loss :  0.06183204710483551  inv_L_scale:  [1.0, 1.0]
Epoch :  271  Time:  0.942  Rel. Train L2 Loss :  0.032048627419604195  Rel. Test L2 Loss :  0.03407688215374947  Test L2 Loss :  0.05963801994919777  inv_L_scale:  [1.0, 1.0]
Epoch :  272  Time:  0.941  Rel. Train L2 Loss :  0.032068809991081554  Rel. Test L2 Loss :  0.03441284939646721  Test L2 Loss :  0.05998040363192558  inv_L_scale:  [1.0, 1.0]
Epoch :  273  Time:  0.941  Rel. Train L2 Loss :  0.031959807243612075  Rel. Test L2 Loss :  0.03466826535761356  Test L2 Loss :  0.060521498471498486  inv_L_scale:  [1.0, 1.0]
Epoch :  274  Time:  0.941  Rel. Train L2 Loss :  0.03198808868726095  Rel. Test L2 Loss :  0.034463287144899366  Test L2 Loss :  0.060242999792098996  inv_L_scale:  [1.0, 1.0]
Epoch :  275  Time:  0.941  Rel. Train L2 Loss :  0.031952352970838545  Rel. Test L2 Loss :  0.03398180365562439  Test L2 Loss :  0.06002673417329788  inv_L_scale:  [1.0, 1.0]
Epoch :  276  Time:  0.941  Rel. Train L2 Loss :  0.03196712662776311  Rel. Test L2 Loss :  0.03442360043525696  Test L2 Loss :  0.06002196058630943  inv_L_scale:  [1.0, 1.0]
Epoch :  277  Time:  0.941  Rel. Train L2 Loss :  0.03184464608629545  Rel. Test L2 Loss :  0.03369934320449829  Test L2 Loss :  0.0586965200304985  inv_L_scale:  [1.0, 1.0]
Epoch :  278  Time:  0.941  Rel. Train L2 Loss :  0.03188668217096064  Rel. Test L2 Loss :  0.034455135464668274  Test L2 Loss :  0.06054055839776993  inv_L_scale:  [1.0, 1.0]
Epoch :  279  Time:  0.941  Rel. Train L2 Loss :  0.03218613358007537  Rel. Test L2 Loss :  0.034709197133779526  Test L2 Loss :  0.0604387928545475  inv_L_scale:  [1.0, 1.0]
Epoch :  280  Time:  0.941  Rel. Train L2 Loss :  0.03190934880740113  Rel. Test L2 Loss :  0.03445746138691902  Test L2 Loss :  0.06066314101219177  inv_L_scale:  [1.0, 1.0]
Epoch :  281  Time:  0.941  Rel. Train L2 Loss :  0.03204505496554905  Rel. Test L2 Loss :  0.034674700051546097  Test L2 Loss :  0.060921816527843474  inv_L_scale:  [1.0, 1.0]
Epoch :  282  Time:  0.943  Rel. Train L2 Loss :  0.031705762015448676  Rel. Test L2 Loss :  0.03493423357605934  Test L2 Loss :  0.0611230742931366  inv_L_scale:  [1.0, 1.0]
Epoch :  283  Time:  0.941  Rel. Train L2 Loss :  0.031855211241377725  Rel. Test L2 Loss :  0.03443262748420239  Test L2 Loss :  0.0600473940372467  inv_L_scale:  [1.0, 1.0]
Epoch :  284  Time:  0.94  Rel. Train L2 Loss :  0.03184586556421386  Rel. Test L2 Loss :  0.03441862121224403  Test L2 Loss :  0.06000606864690781  inv_L_scale:  [1.0, 1.0]
Epoch :  285  Time:  0.942  Rel. Train L2 Loss :  0.03159087873995304  Rel. Test L2 Loss :  0.03441863477230072  Test L2 Loss :  0.060436260253190995  inv_L_scale:  [1.0, 1.0]
Epoch :  286  Time:  0.944  Rel. Train L2 Loss :  0.031629440271192126  Rel. Test L2 Loss :  0.034221901744604113  Test L2 Loss :  0.05960049033164978  inv_L_scale:  [1.0, 1.0]
Epoch :  287  Time:  0.944  Rel. Train L2 Loss :  0.03175376834140883  Rel. Test L2 Loss :  0.03395558178424835  Test L2 Loss :  0.05925195172429085  inv_L_scale:  [1.0, 1.0]
Epoch :  288  Time:  0.944  Rel. Train L2 Loss :  0.031726977676153185  Rel. Test L2 Loss :  0.03525827586650848  Test L2 Loss :  0.061553323566913606  inv_L_scale:  [1.0, 1.0]
Epoch :  289  Time:  0.945  Rel. Train L2 Loss :  0.03176548813780149  Rel. Test L2 Loss :  0.03426245853304863  Test L2 Loss :  0.05967818737030029  inv_L_scale:  [1.0, 1.0]
Epoch :  290  Time:  0.943  Rel. Train L2 Loss :  0.03157982970277468  Rel. Test L2 Loss :  0.03401113256812096  Test L2 Loss :  0.05988639891147614  inv_L_scale:  [1.0, 1.0]
Epoch :  291  Time:  0.942  Rel. Train L2 Loss :  0.03154836025502947  Rel. Test L2 Loss :  0.033319799378514287  Test L2 Loss :  0.05839428037405014  inv_L_scale:  [1.0, 1.0]
Epoch :  292  Time:  0.944  Rel. Train L2 Loss :  0.03127873162428538  Rel. Test L2 Loss :  0.033640034794807434  Test L2 Loss :  0.05898546800017357  inv_L_scale:  [1.0, 1.0]
Epoch :  293  Time:  0.95  Rel. Train L2 Loss :  0.03142331782314513  Rel. Test L2 Loss :  0.033304956629872325  Test L2 Loss :  0.058479278087615966  inv_L_scale:  [1.0, 1.0]
Epoch :  294  Time:  0.962  Rel. Train L2 Loss :  0.03144526312748591  Rel. Test L2 Loss :  0.03355690650641918  Test L2 Loss :  0.058935395181179046  inv_L_scale:  [1.0, 1.0]
Epoch :  295  Time:  0.946  Rel. Train L2 Loss :  0.03136242083377308  Rel. Test L2 Loss :  0.03387644901871681  Test L2 Loss :  0.05924546480178833  inv_L_scale:  [1.0, 1.0]
Epoch :  296  Time:  0.945  Rel. Train L2 Loss :  0.03142499057783021  Rel. Test L2 Loss :  0.033778818622231484  Test L2 Loss :  0.059185511320829394  inv_L_scale:  [1.0, 1.0]
Epoch :  297  Time:  0.943  Rel. Train L2 Loss :  0.031325787189933986  Rel. Test L2 Loss :  0.034627460092306134  Test L2 Loss :  0.06096014469861984  inv_L_scale:  [1.0, 1.0]
Epoch :  298  Time:  0.943  Rel. Train L2 Loss :  0.03133654107650121  Rel. Test L2 Loss :  0.033852800950407984  Test L2 Loss :  0.059220876544713974  inv_L_scale:  [1.0, 1.0]
Epoch :  299  Time:  0.943  Rel. Train L2 Loss :  0.03139270074665546  Rel. Test L2 Loss :  0.03367803998291492  Test L2 Loss :  0.058849950283765794  inv_L_scale:  [1.0, 1.0]
Epoch :  300  Time:  0.94  Rel. Train L2 Loss :  0.03129105634159512  Rel. Test L2 Loss :  0.03317292496562004  Test L2 Loss :  0.05808968916535377  inv_L_scale:  [1.0, 1.0]
Epoch :  301  Time:  0.939  Rel. Train L2 Loss :  0.031113643960820305  Rel. Test L2 Loss :  0.03395445168018341  Test L2 Loss :  0.059359254837036135  inv_L_scale:  [1.0, 1.0]
Epoch :  302  Time:  0.939  Rel. Train L2 Loss :  0.031201006488667592  Rel. Test L2 Loss :  0.033482127115130426  Test L2 Loss :  0.05866966962814331  inv_L_scale:  [1.0, 1.0]
Epoch :  303  Time:  0.939  Rel. Train L2 Loss :  0.03117976777255535  Rel. Test L2 Loss :  0.033320771083235744  Test L2 Loss :  0.05842907041311264  inv_L_scale:  [1.0, 1.0]
Epoch :  304  Time:  0.94  Rel. Train L2 Loss :  0.031280295989579626  Rel. Test L2 Loss :  0.03424841672182083  Test L2 Loss :  0.0600218990445137  inv_L_scale:  [1.0, 1.0]
Epoch :  305  Time:  0.94  Rel. Train L2 Loss :  0.03125884499814775  Rel. Test L2 Loss :  0.033811389654874804  Test L2 Loss :  0.059079045057296754  inv_L_scale:  [1.0, 1.0]
Epoch :  306  Time:  0.939  Rel. Train L2 Loss :  0.031198084668980705  Rel. Test L2 Loss :  0.033288552910089496  Test L2 Loss :  0.05796168759465217  inv_L_scale:  [1.0, 1.0]
Epoch :  307  Time:  0.94  Rel. Train L2 Loss :  0.03116715043783188  Rel. Test L2 Loss :  0.033544368147850036  Test L2 Loss :  0.05885127276182175  inv_L_scale:  [1.0, 1.0]
Epoch :  308  Time:  0.943  Rel. Train L2 Loss :  0.030962110178338158  Rel. Test L2 Loss :  0.033656447529792785  Test L2 Loss :  0.05906366392970085  inv_L_scale:  [1.0, 1.0]
Epoch :  309  Time:  0.941  Rel. Train L2 Loss :  0.03100388205713696  Rel. Test L2 Loss :  0.034263916537165644  Test L2 Loss :  0.05968950524926186  inv_L_scale:  [1.0, 1.0]
Epoch :  310  Time:  0.939  Rel. Train L2 Loss :  0.03098593988352352  Rel. Test L2 Loss :  0.03404539830982685  Test L2 Loss :  0.05966330349445343  inv_L_scale:  [1.0, 1.0]
Epoch :  311  Time:  0.939  Rel. Train L2 Loss :  0.03091204908159044  Rel. Test L2 Loss :  0.03356634080410004  Test L2 Loss :  0.05854652017354965  inv_L_scale:  [1.0, 1.0]
Epoch :  312  Time:  0.939  Rel. Train L2 Loss :  0.030855953925185732  Rel. Test L2 Loss :  0.03295496389269829  Test L2 Loss :  0.0576960763335228  inv_L_scale:  [1.0, 1.0]
Epoch :  313  Time:  0.939  Rel. Train L2 Loss :  0.030869540042347376  Rel. Test L2 Loss :  0.033167323768138884  Test L2 Loss :  0.057777788788080216  inv_L_scale:  [1.0, 1.0]
Epoch :  314  Time:  0.939  Rel. Train L2 Loss :  0.03066871585117446  Rel. Test L2 Loss :  0.033526697307825086  Test L2 Loss :  0.058705672323703766  inv_L_scale:  [1.0, 1.0]
Epoch :  315  Time:  0.939  Rel. Train L2 Loss :  0.030708802714943886  Rel. Test L2 Loss :  0.03368056885898113  Test L2 Loss :  0.058672723919153215  inv_L_scale:  [1.0, 1.0]
Epoch :  316  Time:  0.939  Rel. Train L2 Loss :  0.03096692908141348  Rel. Test L2 Loss :  0.034575537294149396  Test L2 Loss :  0.06094700708985329  inv_L_scale:  [1.0, 1.0]
Epoch :  317  Time:  0.939  Rel. Train L2 Loss :  0.030803974626792803  Rel. Test L2 Loss :  0.03347911037504673  Test L2 Loss :  0.05838322907686234  inv_L_scale:  [1.0, 1.0]
Epoch :  318  Time:  0.939  Rel. Train L2 Loss :  0.03076415792107582  Rel. Test L2 Loss :  0.033230223432183265  Test L2 Loss :  0.057934983670711517  inv_L_scale:  [1.0, 1.0]
Epoch :  319  Time:  0.939  Rel. Train L2 Loss :  0.030821401725212732  Rel. Test L2 Loss :  0.03312444597482681  Test L2 Loss :  0.05795763581991196  inv_L_scale:  [1.0, 1.0]
Epoch :  320  Time:  0.939  Rel. Train L2 Loss :  0.030913403696484036  Rel. Test L2 Loss :  0.033734549209475516  Test L2 Loss :  0.058844192922115325  inv_L_scale:  [1.0, 1.0]
Epoch :  321  Time:  0.939  Rel. Train L2 Loss :  0.03069765481683943  Rel. Test L2 Loss :  0.03315295331180096  Test L2 Loss :  0.05780157759785652  inv_L_scale:  [1.0, 1.0]
Epoch :  322  Time:  0.939  Rel. Train L2 Loss :  0.030571243754691547  Rel. Test L2 Loss :  0.03352742820978165  Test L2 Loss :  0.05859722122550011  inv_L_scale:  [1.0, 1.0]
Epoch :  323  Time:  0.939  Rel. Train L2 Loss :  0.03058790348470211  Rel. Test L2 Loss :  0.03307027354836464  Test L2 Loss :  0.05797828644514084  inv_L_scale:  [1.0, 1.0]
Epoch :  324  Time:  0.939  Rel. Train L2 Loss :  0.03054672473006778  Rel. Test L2 Loss :  0.032989810332655904  Test L2 Loss :  0.05779823750257492  inv_L_scale:  [1.0, 1.0]
Epoch :  325  Time:  0.939  Rel. Train L2 Loss :  0.03054556165304449  Rel. Test L2 Loss :  0.033363860324025156  Test L2 Loss :  0.05818233400583267  inv_L_scale:  [1.0, 1.0]
Epoch :  326  Time:  0.939  Rel. Train L2 Loss :  0.030468093645241525  Rel. Test L2 Loss :  0.03275831244885921  Test L2 Loss :  0.0572835311293602  inv_L_scale:  [1.0, 1.0]
Epoch :  327  Time:  0.941  Rel. Train L2 Loss :  0.030463816589779324  Rel. Test L2 Loss :  0.03292284093797207  Test L2 Loss :  0.057959158718585965  inv_L_scale:  [1.0, 1.0]
Epoch :  328  Time:  0.94  Rel. Train L2 Loss :  0.030525658445225822  Rel. Test L2 Loss :  0.0328544919192791  Test L2 Loss :  0.057475442737340926  inv_L_scale:  [1.0, 1.0]
Epoch :  329  Time:  0.94  Rel. Train L2 Loss :  0.03039832491013739  Rel. Test L2 Loss :  0.032881594225764275  Test L2 Loss :  0.05799526035785675  inv_L_scale:  [1.0, 1.0]
Epoch :  330  Time:  0.939  Rel. Train L2 Loss :  0.03037775754928589  Rel. Test L2 Loss :  0.033165490180253984  Test L2 Loss :  0.05791973650455475  inv_L_scale:  [1.0, 1.0]
Epoch :  331  Time:  0.94  Rel. Train L2 Loss :  0.030532811648315852  Rel. Test L2 Loss :  0.03274551138281822  Test L2 Loss :  0.05726478189229965  inv_L_scale:  [1.0, 1.0]
Epoch :  332  Time:  0.939  Rel. Train L2 Loss :  0.03037667227288087  Rel. Test L2 Loss :  0.03307539395987988  Test L2 Loss :  0.058163297474384305  inv_L_scale:  [1.0, 1.0]
Epoch :  333  Time:  0.939  Rel. Train L2 Loss :  0.030415532307492364  Rel. Test L2 Loss :  0.032677130699157717  Test L2 Loss :  0.05704271674156189  inv_L_scale:  [1.0, 1.0]
Epoch :  334  Time:  0.939  Rel. Train L2 Loss :  0.030338908914062712  Rel. Test L2 Loss :  0.03299541711807251  Test L2 Loss :  0.05794193223118782  inv_L_scale:  [1.0, 1.0]
Epoch :  335  Time:  0.939  Rel. Train L2 Loss :  0.030297550310691198  Rel. Test L2 Loss :  0.032837170511484146  Test L2 Loss :  0.05741802752017975  inv_L_scale:  [1.0, 1.0]
Epoch :  336  Time:  0.939  Rel. Train L2 Loss :  0.030326495584514408  Rel. Test L2 Loss :  0.033308925926685336  Test L2 Loss :  0.058751395642757415  inv_L_scale:  [1.0, 1.0]
Epoch :  337  Time:  0.939  Rel. Train L2 Loss :  0.030202666885322995  Rel. Test L2 Loss :  0.03263249330222607  Test L2 Loss :  0.057097276002168657  inv_L_scale:  [1.0, 1.0]
Epoch :  338  Time:  0.939  Rel. Train L2 Loss :  0.030306636086768573  Rel. Test L2 Loss :  0.03373854048550129  Test L2 Loss :  0.0588287490606308  inv_L_scale:  [1.0, 1.0]
Epoch :  339  Time:  0.939  Rel. Train L2 Loss :  0.030343100428581238  Rel. Test L2 Loss :  0.032645147666335105  Test L2 Loss :  0.056952159702777866  inv_L_scale:  [1.0, 1.0]
Epoch :  340  Time:  0.938  Rel. Train L2 Loss :  0.030137267543209924  Rel. Test L2 Loss :  0.03252298876643181  Test L2 Loss :  0.05694205105304718  inv_L_scale:  [1.0, 1.0]
Epoch :  341  Time:  0.94  Rel. Train L2 Loss :  0.030066021929184596  Rel. Test L2 Loss :  0.032226133644580844  Test L2 Loss :  0.05637711137533188  inv_L_scale:  [1.0, 1.0]
Epoch :  342  Time:  0.94  Rel. Train L2 Loss :  0.030013662841584948  Rel. Test L2 Loss :  0.032630896270275114  Test L2 Loss :  0.05716054648160934  inv_L_scale:  [1.0, 1.0]
Epoch :  343  Time:  0.939  Rel. Train L2 Loss :  0.030326873494519128  Rel. Test L2 Loss :  0.03281051456928253  Test L2 Loss :  0.057652156054973605  inv_L_scale:  [1.0, 1.0]
Epoch :  344  Time:  0.938  Rel. Train L2 Loss :  0.030355683051877552  Rel. Test L2 Loss :  0.03302470341324806  Test L2 Loss :  0.05812206983566284  inv_L_scale:  [1.0, 1.0]
Epoch :  345  Time:  0.941  Rel. Train L2 Loss :  0.030125892841153676  Rel. Test L2 Loss :  0.03260568775236607  Test L2 Loss :  0.057059629559516906  inv_L_scale:  [1.0, 1.0]
Epoch :  346  Time:  0.94  Rel. Train L2 Loss :  0.02997279076112641  Rel. Test L2 Loss :  0.03325271099805832  Test L2 Loss :  0.058085618019104  inv_L_scale:  [1.0, 1.0]
Epoch :  347  Time:  0.939  Rel. Train L2 Loss :  0.03003005464043882  Rel. Test L2 Loss :  0.03237835511565208  Test L2 Loss :  0.05675222545862198  inv_L_scale:  [1.0, 1.0]
Epoch :  348  Time:  0.938  Rel. Train L2 Loss :  0.03008282325334019  Rel. Test L2 Loss :  0.03251108393073082  Test L2 Loss :  0.056622305065393445  inv_L_scale:  [1.0, 1.0]
Epoch :  349  Time:  0.938  Rel. Train L2 Loss :  0.02989200179775556  Rel. Test L2 Loss :  0.03261938333511352  Test L2 Loss :  0.057036879360675814  inv_L_scale:  [1.0, 1.0]
Epoch :  350  Time:  0.938  Rel. Train L2 Loss :  0.029938679337501526  Rel. Test L2 Loss :  0.03314267486333847  Test L2 Loss :  0.05807884618639946  inv_L_scale:  [1.0, 1.0]
Epoch :  351  Time:  0.939  Rel. Train L2 Loss :  0.029924661798609628  Rel. Test L2 Loss :  0.03295312061905861  Test L2 Loss :  0.057672962844371796  inv_L_scale:  [1.0, 1.0]
Epoch :  352  Time:  0.943  Rel. Train L2 Loss :  0.029822811509172122  Rel. Test L2 Loss :  0.03231370277702808  Test L2 Loss :  0.05634432464838028  inv_L_scale:  [1.0, 1.0]
Epoch :  353  Time:  0.942  Rel. Train L2 Loss :  0.029930358802278838  Rel. Test L2 Loss :  0.032508879229426385  Test L2 Loss :  0.05673415809869766  inv_L_scale:  [1.0, 1.0]
Epoch :  354  Time:  0.942  Rel. Train L2 Loss :  0.029758720927768285  Rel. Test L2 Loss :  0.032300972267985346  Test L2 Loss :  0.05636336207389832  inv_L_scale:  [1.0, 1.0]
Epoch :  355  Time:  0.942  Rel. Train L2 Loss :  0.029764006071620518  Rel. Test L2 Loss :  0.032484460920095444  Test L2 Loss :  0.05675667345523834  inv_L_scale:  [1.0, 1.0]
Epoch :  356  Time:  0.942  Rel. Train L2 Loss :  0.029724435144000583  Rel. Test L2 Loss :  0.03273654773831367  Test L2 Loss :  0.057600035518407824  inv_L_scale:  [1.0, 1.0]
Epoch :  357  Time:  0.941  Rel. Train L2 Loss :  0.029773082675205335  Rel. Test L2 Loss :  0.03250584982335567  Test L2 Loss :  0.056950657069683074  inv_L_scale:  [1.0, 1.0]
Epoch :  358  Time:  0.942  Rel. Train L2 Loss :  0.029758913682566748  Rel. Test L2 Loss :  0.03241464793682099  Test L2 Loss :  0.056578929722309115  inv_L_scale:  [1.0, 1.0]
Epoch :  359  Time:  0.942  Rel. Train L2 Loss :  0.029713479015562268  Rel. Test L2 Loss :  0.032768937647342684  Test L2 Loss :  0.05714657247066498  inv_L_scale:  [1.0, 1.0]
Epoch :  360  Time:  0.942  Rel. Train L2 Loss :  0.029708797650204764  Rel. Test L2 Loss :  0.03235827676951885  Test L2 Loss :  0.05668083399534225  inv_L_scale:  [1.0, 1.0]
Epoch :  361  Time:  0.942  Rel. Train L2 Loss :  0.02962783924407429  Rel. Test L2 Loss :  0.03215134166181088  Test L2 Loss :  0.05608562991023064  inv_L_scale:  [1.0, 1.0]
Epoch :  362  Time:  0.942  Rel. Train L2 Loss :  0.029676655183235805  Rel. Test L2 Loss :  0.032433350160717966  Test L2 Loss :  0.05669189259409904  inv_L_scale:  [1.0, 1.0]
Epoch :  363  Time:  0.942  Rel. Train L2 Loss :  0.029642535547415416  Rel. Test L2 Loss :  0.03266612954437733  Test L2 Loss :  0.05716051250696182  inv_L_scale:  [1.0, 1.0]
Epoch :  364  Time:  0.943  Rel. Train L2 Loss :  0.029613842202557458  Rel. Test L2 Loss :  0.03226272493600845  Test L2 Loss :  0.05650444000959396  inv_L_scale:  [1.0, 1.0]
Epoch :  365  Time:  0.942  Rel. Train L2 Loss :  0.029569881641202504  Rel. Test L2 Loss :  0.03256744809448719  Test L2 Loss :  0.05679539129137993  inv_L_scale:  [1.0, 1.0]
Epoch :  366  Time:  0.941  Rel. Train L2 Loss :  0.029607756584882735  Rel. Test L2 Loss :  0.031947197020053865  Test L2 Loss :  0.05574810579419136  inv_L_scale:  [1.0, 1.0]
Epoch :  367  Time:  0.941  Rel. Train L2 Loss :  0.029501659034026993  Rel. Test L2 Loss :  0.03213648147881031  Test L2 Loss :  0.05610078260302544  inv_L_scale:  [1.0, 1.0]
Epoch :  368  Time:  0.941  Rel. Train L2 Loss :  0.029600108630127377  Rel. Test L2 Loss :  0.032380269765853884  Test L2 Loss :  0.05674181938171387  inv_L_scale:  [1.0, 1.0]
Epoch :  369  Time:  0.941  Rel. Train L2 Loss :  0.029562196044458283  Rel. Test L2 Loss :  0.03252630949020386  Test L2 Loss :  0.05698051780462265  inv_L_scale:  [1.0, 1.0]
Epoch :  370  Time:  0.941  Rel. Train L2 Loss :  0.029482665691110823  Rel. Test L2 Loss :  0.032498442381620404  Test L2 Loss :  0.056930652111768724  inv_L_scale:  [1.0, 1.0]
Epoch :  371  Time:  0.941  Rel. Train L2 Loss :  0.0294426619178719  Rel. Test L2 Loss :  0.03233805656433106  Test L2 Loss :  0.05660906493663788  inv_L_scale:  [1.0, 1.0]
Epoch :  372  Time:  0.941  Rel. Train L2 Loss :  0.029450718727376726  Rel. Test L2 Loss :  0.03244109019637108  Test L2 Loss :  0.056732563823461535  inv_L_scale:  [1.0, 1.0]
Epoch :  373  Time:  0.941  Rel. Train L2 Loss :  0.02940844891799821  Rel. Test L2 Loss :  0.03216002278029919  Test L2 Loss :  0.056195176094770434  inv_L_scale:  [1.0, 1.0]
Epoch :  374  Time:  0.942  Rel. Train L2 Loss :  0.02932951687110795  Rel. Test L2 Loss :  0.032006391882896425  Test L2 Loss :  0.055990232825279235  inv_L_scale:  [1.0, 1.0]
Epoch :  375  Time:  0.942  Rel. Train L2 Loss :  0.029425590485334396  Rel. Test L2 Loss :  0.0319845823943615  Test L2 Loss :  0.056138365119695666  inv_L_scale:  [1.0, 1.0]
Epoch :  376  Time:  0.941  Rel. Train L2 Loss :  0.029328973475429745  Rel. Test L2 Loss :  0.03201322264969349  Test L2 Loss :  0.055900813043117524  inv_L_scale:  [1.0, 1.0]
Epoch :  377  Time:  0.941  Rel. Train L2 Loss :  0.02937278533147441  Rel. Test L2 Loss :  0.032147553488612174  Test L2 Loss :  0.05611490339040756  inv_L_scale:  [1.0, 1.0]
Epoch :  378  Time:  0.942  Rel. Train L2 Loss :  0.02935938950214121  Rel. Test L2 Loss :  0.03213981784880161  Test L2 Loss :  0.05604507982730866  inv_L_scale:  [1.0, 1.0]
Epoch :  379  Time:  0.941  Rel. Train L2 Loss :  0.029207401557101144  Rel. Test L2 Loss :  0.031989164650440216  Test L2 Loss :  0.055760585516691205  inv_L_scale:  [1.0, 1.0]
Epoch :  380  Time:  0.942  Rel. Train L2 Loss :  0.029246784448623657  Rel. Test L2 Loss :  0.031885735988616944  Test L2 Loss :  0.05553090512752533  inv_L_scale:  [1.0, 1.0]
Epoch :  381  Time:  0.941  Rel. Train L2 Loss :  0.02922578035129441  Rel. Test L2 Loss :  0.03205197811126709  Test L2 Loss :  0.05612439587712288  inv_L_scale:  [1.0, 1.0]
Epoch :  382  Time:  0.941  Rel. Train L2 Loss :  0.02921232925521003  Rel. Test L2 Loss :  0.0321106082201004  Test L2 Loss :  0.05605784073472023  inv_L_scale:  [1.0, 1.0]
Epoch :  383  Time:  0.941  Rel. Train L2 Loss :  0.029148800290293164  Rel. Test L2 Loss :  0.03198920272290707  Test L2 Loss :  0.055705883651971815  inv_L_scale:  [1.0, 1.0]
Epoch :  384  Time:  0.941  Rel. Train L2 Loss :  0.029227027520537376  Rel. Test L2 Loss :  0.032062608376145364  Test L2 Loss :  0.056073692142963406  inv_L_scale:  [1.0, 1.0]
Epoch :  385  Time:  0.941  Rel. Train L2 Loss :  0.029191204524702495  Rel. Test L2 Loss :  0.03222986154258251  Test L2 Loss :  0.056341546773910525  inv_L_scale:  [1.0, 1.0]
Epoch :  386  Time:  0.941  Rel. Train L2 Loss :  0.029266324854559368  Rel. Test L2 Loss :  0.032008755058050155  Test L2 Loss :  0.05583134412765503  inv_L_scale:  [1.0, 1.0]
Epoch :  387  Time:  0.941  Rel. Train L2 Loss :  0.029164801173739964  Rel. Test L2 Loss :  0.031845907866954806  Test L2 Loss :  0.055640701204538345  inv_L_scale:  [1.0, 1.0]
Epoch :  388  Time:  0.941  Rel. Train L2 Loss :  0.029072111265526876  Rel. Test L2 Loss :  0.03200214006006718  Test L2 Loss :  0.05602341592311859  inv_L_scale:  [1.0, 1.0]
Epoch :  389  Time:  0.942  Rel. Train L2 Loss :  0.02903909321460459  Rel. Test L2 Loss :  0.031938261464238164  Test L2 Loss :  0.05578655570745468  inv_L_scale:  [1.0, 1.0]
Epoch :  390  Time:  0.941  Rel. Train L2 Loss :  0.02906576073831982  Rel. Test L2 Loss :  0.03190884202718735  Test L2 Loss :  0.05575571835041046  inv_L_scale:  [1.0, 1.0]
Epoch :  391  Time:  0.941  Rel. Train L2 Loss :  0.029056570794847275  Rel. Test L2 Loss :  0.03201694652438164  Test L2 Loss :  0.05614270329475403  inv_L_scale:  [1.0, 1.0]
Epoch :  392  Time:  0.942  Rel. Train L2 Loss :  0.028950230081876117  Rel. Test L2 Loss :  0.03215178087353707  Test L2 Loss :  0.05605147391557694  inv_L_scale:  [1.0, 1.0]
Epoch :  393  Time:  0.942  Rel. Train L2 Loss :  0.02906780148545901  Rel. Test L2 Loss :  0.03203557446599006  Test L2 Loss :  0.056078416258096696  inv_L_scale:  [1.0, 1.0]
Epoch :  394  Time:  0.941  Rel. Train L2 Loss :  0.028938238637314904  Rel. Test L2 Loss :  0.03181487947702408  Test L2 Loss :  0.05554901167750358  inv_L_scale:  [1.0, 1.0]
Epoch :  395  Time:  0.941  Rel. Train L2 Loss :  0.028902964426411524  Rel. Test L2 Loss :  0.03196058288216591  Test L2 Loss :  0.05576554089784622  inv_L_scale:  [1.0, 1.0]
Epoch :  396  Time:  0.942  Rel. Train L2 Loss :  0.028946936196751066  Rel. Test L2 Loss :  0.031785113960504534  Test L2 Loss :  0.0555446407198906  inv_L_scale:  [1.0, 1.0]
Epoch :  397  Time:  0.942  Rel. Train L2 Loss :  0.028921976072920692  Rel. Test L2 Loss :  0.03162592902779579  Test L2 Loss :  0.055309954285621646  inv_L_scale:  [1.0, 1.0]
Epoch :  398  Time:  0.941  Rel. Train L2 Loss :  0.028924670037296082  Rel. Test L2 Loss :  0.03177408441901207  Test L2 Loss :  0.05571709334850311  inv_L_scale:  [1.0, 1.0]
Epoch :  399  Time:  0.941  Rel. Train L2 Loss :  0.028953191190958023  Rel. Test L2 Loss :  0.03199652053415775  Test L2 Loss :  0.05581541448831558  inv_L_scale:  [1.0, 1.0]
Epoch :  400  Time:  0.942  Rel. Train L2 Loss :  0.02882517809669177  Rel. Test L2 Loss :  0.0319816816598177  Test L2 Loss :  0.056033892929553984  inv_L_scale:  [1.0, 1.0]
Epoch :  401  Time:  0.941  Rel. Train L2 Loss :  0.02893073484301567  Rel. Test L2 Loss :  0.03194731883704662  Test L2 Loss :  0.05581180483102798  inv_L_scale:  [1.0, 1.0]
Epoch :  402  Time:  0.941  Rel. Train L2 Loss :  0.028897300197018517  Rel. Test L2 Loss :  0.03181758195161819  Test L2 Loss :  0.05552826642990112  inv_L_scale:  [1.0, 1.0]
Epoch :  403  Time:  0.941  Rel. Train L2 Loss :  0.02884635971652137  Rel. Test L2 Loss :  0.03223710909485817  Test L2 Loss :  0.056645799428224564  inv_L_scale:  [1.0, 1.0]
Epoch :  404  Time:  0.941  Rel. Train L2 Loss :  0.0288684355136421  Rel. Test L2 Loss :  0.0317053884267807  Test L2 Loss :  0.05531476840376854  inv_L_scale:  [1.0, 1.0]
Epoch :  405  Time:  0.942  Rel. Train L2 Loss :  0.02878637071284983  Rel. Test L2 Loss :  0.03183931708335876  Test L2 Loss :  0.0556260895729065  inv_L_scale:  [1.0, 1.0]
Epoch :  406  Time:  0.942  Rel. Train L2 Loss :  0.028740005344152452  Rel. Test L2 Loss :  0.03176990211009979  Test L2 Loss :  0.055657111406326294  inv_L_scale:  [1.0, 1.0]
Epoch :  407  Time:  0.942  Rel. Train L2 Loss :  0.028733078373803032  Rel. Test L2 Loss :  0.0317246637493372  Test L2 Loss :  0.05524737238883972  inv_L_scale:  [1.0, 1.0]
Epoch :  408  Time:  0.941  Rel. Train L2 Loss :  0.028726043419705496  Rel. Test L2 Loss :  0.031707828044891355  Test L2 Loss :  0.05550587683916092  inv_L_scale:  [1.0, 1.0]
Epoch :  409  Time:  0.94  Rel. Train L2 Loss :  0.02868415650394228  Rel. Test L2 Loss :  0.031601718738675115  Test L2 Loss :  0.055242761969566345  inv_L_scale:  [1.0, 1.0]
Epoch :  410  Time:  0.94  Rel. Train L2 Loss :  0.028724568469656837  Rel. Test L2 Loss :  0.03164605528116226  Test L2 Loss :  0.055160895586013795  inv_L_scale:  [1.0, 1.0]
Epoch :  411  Time:  0.94  Rel. Train L2 Loss :  0.028695773697561686  Rel. Test L2 Loss :  0.03156771838665009  Test L2 Loss :  0.05515357464551926  inv_L_scale:  [1.0, 1.0]
Epoch :  412  Time:  0.94  Rel. Train L2 Loss :  0.028625748107830685  Rel. Test L2 Loss :  0.031864863038063046  Test L2 Loss :  0.055580151975154875  inv_L_scale:  [1.0, 1.0]
Epoch :  413  Time:  0.939  Rel. Train L2 Loss :  0.028623088772098224  Rel. Test L2 Loss :  0.031726459562778475  Test L2 Loss :  0.05557503119111061  inv_L_scale:  [1.0, 1.0]
Epoch :  414  Time:  0.94  Rel. Train L2 Loss :  0.028618446961045266  Rel. Test L2 Loss :  0.03154605761170387  Test L2 Loss :  0.055038140416145326  inv_L_scale:  [1.0, 1.0]
Epoch :  415  Time:  0.94  Rel. Train L2 Loss :  0.028602574434545305  Rel. Test L2 Loss :  0.03163475900888443  Test L2 Loss :  0.05528557047247887  inv_L_scale:  [1.0, 1.0]
Epoch :  416  Time:  0.94  Rel. Train L2 Loss :  0.028595931058128674  Rel. Test L2 Loss :  0.03156235486268997  Test L2 Loss :  0.05529675155878067  inv_L_scale:  [1.0, 1.0]
Epoch :  417  Time:  0.939  Rel. Train L2 Loss :  0.02876090556383133  Rel. Test L2 Loss :  0.03168030746281147  Test L2 Loss :  0.055297685265541074  inv_L_scale:  [1.0, 1.0]
Epoch :  418  Time:  0.94  Rel. Train L2 Loss :  0.028568561888403364  Rel. Test L2 Loss :  0.031594018191099166  Test L2 Loss :  0.055294787287712095  inv_L_scale:  [1.0, 1.0]
Epoch :  419  Time:  0.939  Rel. Train L2 Loss :  0.02858097427421146  Rel. Test L2 Loss :  0.03155851006507873  Test L2 Loss :  0.05510973706841469  inv_L_scale:  [1.0, 1.0]
Epoch :  420  Time:  0.939  Rel. Train L2 Loss :  0.0285358915809128  Rel. Test L2 Loss :  0.03152329511940479  Test L2 Loss :  0.05506803974509239  inv_L_scale:  [1.0, 1.0]
Epoch :  421  Time:  0.94  Rel. Train L2 Loss :  0.0285239965799782  Rel. Test L2 Loss :  0.0315606202185154  Test L2 Loss :  0.05523576498031616  inv_L_scale:  [1.0, 1.0]
Epoch :  422  Time:  0.94  Rel. Train L2 Loss :  0.028545340879095927  Rel. Test L2 Loss :  0.031649987921118734  Test L2 Loss :  0.055209362655878065  inv_L_scale:  [1.0, 1.0]
Epoch :  423  Time:  0.939  Rel. Train L2 Loss :  0.028494134462542006  Rel. Test L2 Loss :  0.031605591177940366  Test L2 Loss :  0.05521213591098786  inv_L_scale:  [1.0, 1.0]
Epoch :  424  Time:  0.939  Rel. Train L2 Loss :  0.028443048944075903  Rel. Test L2 Loss :  0.03165085718035698  Test L2 Loss :  0.05534796044230461  inv_L_scale:  [1.0, 1.0]
Epoch :  425  Time:  0.939  Rel. Train L2 Loss :  0.028452321448259883  Rel. Test L2 Loss :  0.03152063295245171  Test L2 Loss :  0.054977877140045164  inv_L_scale:  [1.0, 1.0]
Epoch :  426  Time:  0.939  Rel. Train L2 Loss :  0.028429430201649664  Rel. Test L2 Loss :  0.031453797519207  Test L2 Loss :  0.05500331938266754  inv_L_scale:  [1.0, 1.0]
Epoch :  427  Time:  0.939  Rel. Train L2 Loss :  0.02842127682434188  Rel. Test L2 Loss :  0.03149423316121101  Test L2 Loss :  0.05507043302059174  inv_L_scale:  [1.0, 1.0]
Epoch :  428  Time:  0.939  Rel. Train L2 Loss :  0.028425828855898644  Rel. Test L2 Loss :  0.03157765321433544  Test L2 Loss :  0.0552595753967762  inv_L_scale:  [1.0, 1.0]
Epoch :  429  Time:  0.939  Rel. Train L2 Loss :  0.028414777451091344  Rel. Test L2 Loss :  0.031444542855024335  Test L2 Loss :  0.05494861960411072  inv_L_scale:  [1.0, 1.0]
Epoch :  430  Time:  0.939  Rel. Train L2 Loss :  0.02836841278605991  Rel. Test L2 Loss :  0.031521722301840784  Test L2 Loss :  0.05505380406975746  inv_L_scale:  [1.0, 1.0]
Epoch :  431  Time:  0.939  Rel. Train L2 Loss :  0.028377207666635512  Rel. Test L2 Loss :  0.031441969722509386  Test L2 Loss :  0.05498180255293846  inv_L_scale:  [1.0, 1.0]
Epoch :  432  Time:  0.939  Rel. Train L2 Loss :  0.02838707536458969  Rel. Test L2 Loss :  0.03154830053448677  Test L2 Loss :  0.05520384550094604  inv_L_scale:  [1.0, 1.0]
Epoch :  433  Time:  0.939  Rel. Train L2 Loss :  0.028327002657784355  Rel. Test L2 Loss :  0.03156279146671295  Test L2 Loss :  0.055068685710430144  inv_L_scale:  [1.0, 1.0]
Epoch :  434  Time:  0.939  Rel. Train L2 Loss :  0.02837046081821124  Rel. Test L2 Loss :  0.03152601778507233  Test L2 Loss :  0.055134386718273164  inv_L_scale:  [1.0, 1.0]
Epoch :  435  Time:  0.939  Rel. Train L2 Loss :  0.02832722708582878  Rel. Test L2 Loss :  0.03149107620120049  Test L2 Loss :  0.055046370327472685  inv_L_scale:  [1.0, 1.0]
Epoch :  436  Time:  0.939  Rel. Train L2 Loss :  0.028315878121389283  Rel. Test L2 Loss :  0.03144980326294899  Test L2 Loss :  0.05499254807829857  inv_L_scale:  [1.0, 1.0]
Epoch :  437  Time:  0.939  Rel. Train L2 Loss :  0.02831148306528727  Rel. Test L2 Loss :  0.031413340419530866  Test L2 Loss :  0.05484752982854843  inv_L_scale:  [1.0, 1.0]
Epoch :  438  Time:  0.939  Rel. Train L2 Loss :  0.02827331480052736  Rel. Test L2 Loss :  0.03138317443430424  Test L2 Loss :  0.05488476812839508  inv_L_scale:  [1.0, 1.0]
Epoch :  439  Time:  0.939  Rel. Train L2 Loss :  0.028264452831612694  Rel. Test L2 Loss :  0.031438664197921753  Test L2 Loss :  0.05488794833421707  inv_L_scale:  [1.0, 1.0]
Epoch :  440  Time:  0.939  Rel. Train L2 Loss :  0.0282617141554753  Rel. Test L2 Loss :  0.03149141192436218  Test L2 Loss :  0.05498378500342369  inv_L_scale:  [1.0, 1.0]
Epoch :  441  Time:  0.939  Rel. Train L2 Loss :  0.028246866315603258  Rel. Test L2 Loss :  0.03139961868524552  Test L2 Loss :  0.05484069496393204  inv_L_scale:  [1.0, 1.0]
Epoch :  442  Time:  0.939  Rel. Train L2 Loss :  0.028243645288878017  Rel. Test L2 Loss :  0.03137636989355087  Test L2 Loss :  0.05479144707322121  inv_L_scale:  [1.0, 1.0]
Epoch :  443  Time:  0.939  Rel. Train L2 Loss :  0.02823930745323499  Rel. Test L2 Loss :  0.031473109349608425  Test L2 Loss :  0.055006049275398254  inv_L_scale:  [1.0, 1.0]
Epoch :  444  Time:  0.939  Rel. Train L2 Loss :  0.028232034320632617  Rel. Test L2 Loss :  0.03143153876066208  Test L2 Loss :  0.05493837237358093  inv_L_scale:  [1.0, 1.0]
Epoch :  445  Time:  0.939  Rel. Train L2 Loss :  0.028212663051154878  Rel. Test L2 Loss :  0.031350429058074954  Test L2 Loss :  0.05475884839892387  inv_L_scale:  [1.0, 1.0]
Epoch :  446  Time:  0.939  Rel. Train L2 Loss :  0.02819411598973804  Rel. Test L2 Loss :  0.031480930522084234  Test L2 Loss :  0.055064648389816284  inv_L_scale:  [1.0, 1.0]
Epoch :  447  Time:  0.939  Rel. Train L2 Loss :  0.028204307506481806  Rel. Test L2 Loss :  0.03137431204319  Test L2 Loss :  0.05482357740402222  inv_L_scale:  [1.0, 1.0]
Epoch :  448  Time:  0.939  Rel. Train L2 Loss :  0.028197934958669874  Rel. Test L2 Loss :  0.031363089829683305  Test L2 Loss :  0.05475217804312706  inv_L_scale:  [1.0, 1.0]
Epoch :  449  Time:  0.939  Rel. Train L2 Loss :  0.028160623957713446  Rel. Test L2 Loss :  0.03139271683990955  Test L2 Loss :  0.054843074679374694  inv_L_scale:  [1.0, 1.0]
Epoch :  450  Time:  0.94  Rel. Train L2 Loss :  0.028137325826618407  Rel. Test L2 Loss :  0.03132299579679966  Test L2 Loss :  0.054722697734832765  inv_L_scale:  [1.0, 1.0]
Epoch :  451  Time:  0.94  Rel. Train L2 Loss :  0.028150979297028648  Rel. Test L2 Loss :  0.031335906088352204  Test L2 Loss :  0.054740274250507356  inv_L_scale:  [1.0, 1.0]
Epoch :  452  Time:  0.939  Rel. Train L2 Loss :  0.028122111153271463  Rel. Test L2 Loss :  0.031368205100297926  Test L2 Loss :  0.05486823439598083  inv_L_scale:  [1.0, 1.0]
Epoch :  453  Time:  0.939  Rel. Train L2 Loss :  0.028125404086377887  Rel. Test L2 Loss :  0.03137115389108658  Test L2 Loss :  0.054781558364629744  inv_L_scale:  [1.0, 1.0]
Epoch :  454  Time:  0.939  Rel. Train L2 Loss :  0.028125620782375335  Rel. Test L2 Loss :  0.031332242637872695  Test L2 Loss :  0.054743475914001465  inv_L_scale:  [1.0, 1.0]
Epoch :  455  Time:  0.939  Rel. Train L2 Loss :  0.028111358442240292  Rel. Test L2 Loss :  0.0314772580564022  Test L2 Loss :  0.05492693200707435  inv_L_scale:  [1.0, 1.0]
Epoch :  456  Time:  0.939  Rel. Train L2 Loss :  0.028106732103559705  Rel. Test L2 Loss :  0.0313170376420021  Test L2 Loss :  0.054745078682899476  inv_L_scale:  [1.0, 1.0]
Epoch :  457  Time:  0.939  Rel. Train L2 Loss :  0.028108012212647332  Rel. Test L2 Loss :  0.03130538061261177  Test L2 Loss :  0.05469194144010544  inv_L_scale:  [1.0, 1.0]
Epoch :  458  Time:  0.939  Rel. Train L2 Loss :  0.028073966726660727  Rel. Test L2 Loss :  0.03135953456163407  Test L2 Loss :  0.054780984818935397  inv_L_scale:  [1.0, 1.0]
Epoch :  459  Time:  0.939  Rel. Train L2 Loss :  0.028083192457755406  Rel. Test L2 Loss :  0.03130371756851673  Test L2 Loss :  0.054704652428627015  inv_L_scale:  [1.0, 1.0]
Epoch :  460  Time:  0.939  Rel. Train L2 Loss :  0.028051484839783775  Rel. Test L2 Loss :  0.031340526193380354  Test L2 Loss :  0.05476894497871399  inv_L_scale:  [1.0, 1.0]
Epoch :  461  Time:  0.939  Rel. Train L2 Loss :  0.02804774784379535  Rel. Test L2 Loss :  0.031294954642653465  Test L2 Loss :  0.054661716222763064  inv_L_scale:  [1.0, 1.0]
Epoch :  462  Time:  0.939  Rel. Train L2 Loss :  0.028028037970264753  Rel. Test L2 Loss :  0.03136582158505916  Test L2 Loss :  0.0547955234348774  inv_L_scale:  [1.0, 1.0]
Epoch :  463  Time:  0.939  Rel. Train L2 Loss :  0.02805131036374304  Rel. Test L2 Loss :  0.03135792680084706  Test L2 Loss :  0.05474001854658127  inv_L_scale:  [1.0, 1.0]
Epoch :  464  Time:  0.939  Rel. Train L2 Loss :  0.028027065578434204  Rel. Test L2 Loss :  0.03136250153183937  Test L2 Loss :  0.05478204905986786  inv_L_scale:  [1.0, 1.0]
Epoch :  465  Time:  0.939  Rel. Train L2 Loss :  0.028016598059071435  Rel. Test L2 Loss :  0.03135112650692463  Test L2 Loss :  0.05478443413972855  inv_L_scale:  [1.0, 1.0]
Epoch :  466  Time:  0.939  Rel. Train L2 Loss :  0.028018057445685068  Rel. Test L2 Loss :  0.031322299987077716  Test L2 Loss :  0.05473781481385231  inv_L_scale:  [1.0, 1.0]
Epoch :  467  Time:  0.939  Rel. Train L2 Loss :  0.028009808361530303  Rel. Test L2 Loss :  0.03131280466914177  Test L2 Loss :  0.05468999370932579  inv_L_scale:  [1.0, 1.0]
Epoch :  468  Time:  0.939  Rel. Train L2 Loss :  0.027993051227596072  Rel. Test L2 Loss :  0.03132741384208202  Test L2 Loss :  0.05476588413119316  inv_L_scale:  [1.0, 1.0]
Epoch :  469  Time:  0.939  Rel. Train L2 Loss :  0.027985196693076028  Rel. Test L2 Loss :  0.03132390074431896  Test L2 Loss :  0.05472293794155121  inv_L_scale:  [1.0, 1.0]
Epoch :  470  Time:  0.941  Rel. Train L2 Loss :  0.027981133262316386  Rel. Test L2 Loss :  0.03129075899720192  Test L2 Loss :  0.054640671461820604  inv_L_scale:  [1.0, 1.0]
Epoch :  471  Time:  0.94  Rel. Train L2 Loss :  0.02798478662967682  Rel. Test L2 Loss :  0.031297080740332606  Test L2 Loss :  0.05465500265359879  inv_L_scale:  [1.0, 1.0]
Epoch :  472  Time:  0.94  Rel. Train L2 Loss :  0.027973051104280684  Rel. Test L2 Loss :  0.03129763700067997  Test L2 Loss :  0.05469553411006928  inv_L_scale:  [1.0, 1.0]
Epoch :  473  Time:  0.94  Rel. Train L2 Loss :  0.027965799338287776  Rel. Test L2 Loss :  0.031297276467084884  Test L2 Loss :  0.05464201420545578  inv_L_scale:  [1.0, 1.0]
Epoch :  474  Time:  0.94  Rel. Train L2 Loss :  0.027968710818224482  Rel. Test L2 Loss :  0.031304185315966605  Test L2 Loss :  0.05469890415668487  inv_L_scale:  [1.0, 1.0]
Epoch :  475  Time:  0.94  Rel. Train L2 Loss :  0.027953734083308115  Rel. Test L2 Loss :  0.031296630278229716  Test L2 Loss :  0.05471605867147446  inv_L_scale:  [1.0, 1.0]
Epoch :  476  Time:  0.94  Rel. Train L2 Loss :  0.027966527375910016  Rel. Test L2 Loss :  0.03130714640021324  Test L2 Loss :  0.054668108224868776  inv_L_scale:  [1.0, 1.0]
Epoch :  477  Time:  0.94  Rel. Train L2 Loss :  0.027950410718719166  Rel. Test L2 Loss :  0.03130438096821308  Test L2 Loss :  0.054707048386335375  inv_L_scale:  [1.0, 1.0]
Epoch :  478  Time:  0.94  Rel. Train L2 Loss :  0.027939952181445227  Rel. Test L2 Loss :  0.03131906881928444  Test L2 Loss :  0.05471078753471374  inv_L_scale:  [1.0, 1.0]
Epoch :  479  Time:  0.94  Rel. Train L2 Loss :  0.027935900911688804  Rel. Test L2 Loss :  0.031302795931696895  Test L2 Loss :  0.05468578159809113  inv_L_scale:  [1.0, 1.0]
Epoch :  480  Time:  0.94  Rel. Train L2 Loss :  0.02793630835082796  Rel. Test L2 Loss :  0.03128927446901798  Test L2 Loss :  0.05465742349624634  inv_L_scale:  [1.0, 1.0]
Epoch :  481  Time:  0.94  Rel. Train L2 Loss :  0.027927827032075987  Rel. Test L2 Loss :  0.031316306889057156  Test L2 Loss :  0.05475109875202179  inv_L_scale:  [1.0, 1.0]
Epoch :  482  Time:  0.94  Rel. Train L2 Loss :  0.02792918998334143  Rel. Test L2 Loss :  0.031288258507847784  Test L2 Loss :  0.054664132595062254  inv_L_scale:  [1.0, 1.0]
Epoch :  483  Time:  0.94  Rel. Train L2 Loss :  0.02791603474153413  Rel. Test L2 Loss :  0.03128972336649895  Test L2 Loss :  0.05466547682881355  inv_L_scale:  [1.0, 1.0]
Epoch :  484  Time:  0.94  Rel. Train L2 Loss :  0.027914261925551628  Rel. Test L2 Loss :  0.031289983689785  Test L2 Loss :  0.05468143582344055  inv_L_scale:  [1.0, 1.0]
Epoch :  485  Time:  0.94  Rel. Train L2 Loss :  0.02791530826025539  Rel. Test L2 Loss :  0.03130933977663517  Test L2 Loss :  0.054755034297704695  inv_L_scale:  [1.0, 1.0]
Epoch :  486  Time:  0.94  Rel. Train L2 Loss :  0.027918312458528414  Rel. Test L2 Loss :  0.03128469035029411  Test L2 Loss :  0.054657023847103116  inv_L_scale:  [1.0, 1.0]
Epoch :  487  Time:  0.94  Rel. Train L2 Loss :  0.027908580592936938  Rel. Test L2 Loss :  0.03129126228392124  Test L2 Loss :  0.05468102723360062  inv_L_scale:  [1.0, 1.0]
Epoch :  488  Time:  0.94  Rel. Train L2 Loss :  0.027909597439898386  Rel. Test L2 Loss :  0.03130334690213203  Test L2 Loss :  0.05467155277729034  inv_L_scale:  [1.0, 1.0]
Epoch :  489  Time:  0.94  Rel. Train L2 Loss :  0.0279039912753635  Rel. Test L2 Loss :  0.03129646122455597  Test L2 Loss :  0.05466495126485824  inv_L_scale:  [1.0, 1.0]
Epoch :  490  Time:  0.94  Rel. Train L2 Loss :  0.02790179422332181  Rel. Test L2 Loss :  0.03127486899495125  Test L2 Loss :  0.05462417423725128  inv_L_scale:  [1.0, 1.0]
Epoch :  491  Time:  0.94  Rel. Train L2 Loss :  0.027901525696118673  Rel. Test L2 Loss :  0.031286152526736256  Test L2 Loss :  0.054661391377449034  inv_L_scale:  [1.0, 1.0]
Epoch :  492  Time:  0.94  Rel. Train L2 Loss :  0.02789704115026527  Rel. Test L2 Loss :  0.03129018574953079  Test L2 Loss :  0.054679528176784516  inv_L_scale:  [1.0, 1.0]
Epoch :  493  Time:  0.94  Rel. Train L2 Loss :  0.02789574166138967  Rel. Test L2 Loss :  0.03128557667136192  Test L2 Loss :  0.05466761022806168  inv_L_scale:  [1.0, 1.0]
Epoch :  494  Time:  0.94  Rel. Train L2 Loss :  0.02789522180126773  Rel. Test L2 Loss :  0.03128639005124569  Test L2 Loss :  0.054644463062286375  inv_L_scale:  [1.0, 1.0]
Epoch :  495  Time:  0.94  Rel. Train L2 Loss :  0.027892784236205947  Rel. Test L2 Loss :  0.031287230029702184  Test L2 Loss :  0.05468533128499985  inv_L_scale:  [1.0, 1.0]
Epoch :  496  Time:  0.94  Rel. Train L2 Loss :  0.027893681360615624  Rel. Test L2 Loss :  0.03128784134984017  Test L2 Loss :  0.054652786552906035  inv_L_scale:  [1.0, 1.0]
Epoch :  497  Time:  0.94  Rel. Train L2 Loss :  0.02789243444800377  Rel. Test L2 Loss :  0.03128660261631012  Test L2 Loss :  0.054650868624448776  inv_L_scale:  [1.0, 1.0]
Epoch :  498  Time:  0.94  Rel. Train L2 Loss :  0.02789037430451976  Rel. Test L2 Loss :  0.03128918416798115  Test L2 Loss :  0.0546747288107872  inv_L_scale:  [1.0, 1.0]
Epoch :  499  Time:  0.941  Rel. Train L2 Loss :  0.027895056671566432  Rel. Test L2 Loss :  0.03128154061734676  Test L2 Loss :  0.054657693952322006  inv_L_scale:  [1.0, 1.0]
