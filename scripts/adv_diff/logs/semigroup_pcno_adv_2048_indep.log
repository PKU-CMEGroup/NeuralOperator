equal_weight: True
train_inv_L_scale: independently
lr_ratio: 10
batch_size: 10
Casting to tensor
In PCNO_train, ndims =  1
Epoch :  0  Time:  16.496  Rel. Train L2 Loss :  0.15911396817366283  Rel. Test L2 Loss :  0.07215423509478569  Test L2 Loss :  0.032637774248917895  inv_L_scale:  [0.954]
Epoch :  1  Time:  10.006  Rel. Train L2 Loss :  0.09830983130137126  Rel. Test L2 Loss :  0.06082463468114535  Test L2 Loss :  0.02749427452683449  inv_L_scale:  [0.965]
Epoch :  2  Time:  9.948  Rel. Train L2 Loss :  0.09204051645596822  Rel. Test L2 Loss :  0.06812266608079275  Test L2 Loss :  0.03095386505126953  inv_L_scale:  [1.025]
Epoch :  3  Time:  9.95  Rel. Train L2 Loss :  0.10140654484430948  Rel. Test L2 Loss :  0.06909615576267242  Test L2 Loss :  0.03135636687278748  inv_L_scale:  [1.054]
Epoch :  4  Time:  9.959  Rel. Train L2 Loss :  0.09573817110061646  Rel. Test L2 Loss :  0.06285468225677808  Test L2 Loss :  0.028540272017319998  inv_L_scale:  [1.04]
Epoch :  5  Time:  9.937  Rel. Train L2 Loss :  0.08842134400208791  Rel. Test L2 Loss :  0.05901841580867767  Test L2 Loss :  0.026681361844142278  inv_L_scale:  [1.03]
Epoch :  6  Time:  9.934  Rel. Train L2 Loss :  0.08097036576271058  Rel. Test L2 Loss :  0.05254029467701912  Test L2 Loss :  0.023698868602514266  inv_L_scale:  [1.008]
Epoch :  7  Time:  9.924  Rel. Train L2 Loss :  0.0752968964378039  Rel. Test L2 Loss :  0.058704633961121244  Test L2 Loss :  0.026446612526973088  inv_L_scale:  [1.042]
Epoch :  8  Time:  9.941  Rel. Train L2 Loss :  0.08579158171017964  Rel. Test L2 Loss :  0.04903147270282109  Test L2 Loss :  0.02203854498763879  inv_L_scale:  [1.018]
Epoch :  9  Time:  10.001  Rel. Train L2 Loss :  0.0719814499616623  Rel. Test L2 Loss :  0.04929321487744649  Test L2 Loss :  0.02195619814097881  inv_L_scale:  [1.012]
Epoch :  10  Time:  10.108  Rel. Train L2 Loss :  0.07000554662942886  Rel. Test L2 Loss :  0.04502725144227346  Test L2 Loss :  0.0200143788009882  inv_L_scale:  [1.002]
Epoch :  11  Time:  10.533  Rel. Train L2 Loss :  0.06943419919411341  Rel. Test L2 Loss :  0.05057055294513702  Test L2 Loss :  0.022671530197064083  inv_L_scale:  [1.012]
Epoch :  12  Time:  10.098  Rel. Train L2 Loss :  0.07012465784947078  Rel. Test L2 Loss :  0.04498343179623286  Test L2 Loss :  0.02004068985581398  inv_L_scale:  [1.017]
Epoch :  13  Time:  10.103  Rel. Train L2 Loss :  0.07926383187373479  Rel. Test L2 Loss :  0.05481964548428853  Test L2 Loss :  0.024664344886938732  inv_L_scale:  [1.044]
Epoch :  14  Time:  10.062  Rel. Train L2 Loss :  0.0935740669965744  Rel. Test L2 Loss :  0.06321719974279404  Test L2 Loss :  0.028861046731472016  inv_L_scale:  [1.075]
Epoch :  15  Time:  10.039  Rel. Train L2 Loss :  0.09822633588314056  Rel. Test L2 Loss :  0.06261292348305385  Test L2 Loss :  0.02855526735385259  inv_L_scale:  [1.072]
Epoch :  16  Time:  9.969  Rel. Train L2 Loss :  0.095959920724233  Rel. Test L2 Loss :  0.061466736197471616  Test L2 Loss :  0.027966619059443473  inv_L_scale:  [1.066]
Epoch :  17  Time:  9.994  Rel. Train L2 Loss :  0.08899549353122711  Rel. Test L2 Loss :  0.060370288441578546  Test L2 Loss :  0.027527617961168288  inv_L_scale:  [1.063]
Epoch :  18  Time:  10.046  Rel. Train L2 Loss :  0.09172387075424195  Rel. Test L2 Loss :  0.055490058958530424  Test L2 Loss :  0.02541481758157412  inv_L_scale:  [1.071]
Epoch :  19  Time:  10.037  Rel. Train L2 Loss :  0.08795116591453553  Rel. Test L2 Loss :  0.05216145803531011  Test L2 Loss :  0.02373750346402327  inv_L_scale:  [1.048]
Epoch :  20  Time:  10.006  Rel. Train L2 Loss :  0.07467977730433147  Rel. Test L2 Loss :  0.04458042711019516  Test L2 Loss :  0.020238317772746085  inv_L_scale:  [0.999]
Epoch :  21  Time:  10.047  Rel. Train L2 Loss :  0.0709659431775411  Rel. Test L2 Loss :  0.047828451246023175  Test L2 Loss :  0.021379797955354055  inv_L_scale:  [1.006]
Epoch :  22  Time:  10.307  Rel. Train L2 Loss :  0.06829162593682607  Rel. Test L2 Loss :  0.04232080772519112  Test L2 Loss :  0.018967304254571597  inv_L_scale:  [1.006]
Epoch :  23  Time:  10.164  Rel. Train L2 Loss :  0.06616006920735042  Rel. Test L2 Loss :  0.04404131874442101  Test L2 Loss :  0.0196635190397501  inv_L_scale:  [0.989]
Epoch :  24  Time:  10.085  Rel. Train L2 Loss :  0.0716233451962471  Rel. Test L2 Loss :  0.04657765209674835  Test L2 Loss :  0.0211931594957908  inv_L_scale:  [0.961]
Epoch :  25  Time:  10.07  Rel. Train L2 Loss :  0.07213945829868317  Rel. Test L2 Loss :  0.053245712320009866  Test L2 Loss :  0.023998929833372432  inv_L_scale:  [0.936]
Epoch :  26  Time:  10.016  Rel. Train L2 Loss :  0.07105106703440349  Rel. Test L2 Loss :  0.044977361857891085  Test L2 Loss :  0.020440346300601958  inv_L_scale:  [0.943]
Epoch :  27  Time:  10.007  Rel. Train L2 Loss :  0.07192124956846237  Rel. Test L2 Loss :  0.05092112968365351  Test L2 Loss :  0.022861619144678116  inv_L_scale:  [0.933]
Epoch :  28  Time:  9.974  Rel. Train L2 Loss :  0.07573745203018188  Rel. Test L2 Loss :  0.04601103072365125  Test L2 Loss :  0.020832630718747774  inv_L_scale:  [0.904]
Epoch :  29  Time:  9.962  Rel. Train L2 Loss :  0.0724697213768959  Rel. Test L2 Loss :  0.04516670323908329  Test L2 Loss :  0.020331052218874296  inv_L_scale:  [0.913]
Epoch :  30  Time:  9.951  Rel. Train L2 Loss :  0.07152963701883952  Rel. Test L2 Loss :  0.04971949582298597  Test L2 Loss :  0.022497026671965917  inv_L_scale:  [0.9]
Epoch :  31  Time:  9.975  Rel. Train L2 Loss :  0.07171213595072429  Rel. Test L2 Loss :  0.04367963721354803  Test L2 Loss :  0.01953753039240837  inv_L_scale:  [0.9]
Epoch :  32  Time:  9.991  Rel. Train L2 Loss :  0.07178896635770798  Rel. Test L2 Loss :  0.050419207314650216  Test L2 Loss :  0.02274748017390569  inv_L_scale:  [0.896]
Epoch :  33  Time:  9.97  Rel. Train L2 Loss :  0.07201681286096573  Rel. Test L2 Loss :  0.04417180066307386  Test L2 Loss :  0.019734882762034733  inv_L_scale:  [0.903]
Epoch :  34  Time:  9.974  Rel. Train L2 Loss :  0.07219439351558685  Rel. Test L2 Loss :  0.04998348489403725  Test L2 Loss :  0.022496493036548295  inv_L_scale:  [0.904]
Epoch :  35  Time:  9.98  Rel. Train L2 Loss :  0.07491702369848888  Rel. Test L2 Loss :  0.050027403434117636  Test L2 Loss :  0.022467487553755442  inv_L_scale:  [0.898]
Epoch :  36  Time:  9.956  Rel. Train L2 Loss :  0.07520916845401128  Rel. Test L2 Loss :  0.051283446749051415  Test L2 Loss :  0.023188579355676968  inv_L_scale:  [0.904]
Epoch :  37  Time:  9.936  Rel. Train L2 Loss :  0.07359601014852524  Rel. Test L2 Loss :  0.050882857392231626  Test L2 Loss :  0.022796221375465393  inv_L_scale:  [0.926]
Epoch :  38  Time:  9.928  Rel. Train L2 Loss :  0.07383450625340143  Rel. Test L2 Loss :  0.04792097101608912  Test L2 Loss :  0.021403715858856837  inv_L_scale:  [0.922]
Epoch :  39  Time:  9.961  Rel. Train L2 Loss :  0.0746519004503886  Rel. Test L2 Loss :  0.04602059923112392  Test L2 Loss :  0.02054598363737265  inv_L_scale:  [0.932]
Epoch :  40  Time:  9.995  Rel. Train L2 Loss :  0.07173363314072291  Rel. Test L2 Loss :  0.04838893935084343  Test L2 Loss :  0.021612756277124088  inv_L_scale:  [0.918]
Epoch :  41  Time:  9.971  Rel. Train L2 Loss :  0.0729970722993215  Rel. Test L2 Loss :  0.04593571811914444  Test L2 Loss :  0.020656205664078393  inv_L_scale:  [0.893]
Epoch :  42  Time:  9.942  Rel. Train L2 Loss :  0.07290205061435699  Rel. Test L2 Loss :  0.04816924194494883  Test L2 Loss :  0.021629444137215615  inv_L_scale:  [0.87]
Epoch :  43  Time:  10.115  Rel. Train L2 Loss :  0.07724112921953201  Rel. Test L2 Loss :  0.050429769655068714  Test L2 Loss :  0.0226283061504364  inv_L_scale:  [0.873]
Epoch :  44  Time:  10.009  Rel. Train L2 Loss :  0.07742818190654119  Rel. Test L2 Loss :  0.04469882942736149  Test L2 Loss :  0.020058132782578467  inv_L_scale:  [0.845]
Epoch :  45  Time:  9.92  Rel. Train L2 Loss :  0.07357431999842326  Rel. Test L2 Loss :  0.04535226806998253  Test L2 Loss :  0.02038671411573887  inv_L_scale:  [0.846]
Epoch :  46  Time:  9.92  Rel. Train L2 Loss :  0.07446144912640254  Rel. Test L2 Loss :  0.04690331384539604  Test L2 Loss :  0.02116461897889773  inv_L_scale:  [0.864]
Epoch :  47  Time:  9.931  Rel. Train L2 Loss :  0.07719884167114893  Rel. Test L2 Loss :  0.05326852927605311  Test L2 Loss :  0.02385853131612142  inv_L_scale:  [0.859]
Epoch :  48  Time:  9.928  Rel. Train L2 Loss :  0.07629314166307449  Rel. Test L2 Loss :  0.04828982800245285  Test L2 Loss :  0.021635568737983703  inv_L_scale:  [0.875]
Epoch :  49  Time:  9.935  Rel. Train L2 Loss :  0.07678599639733633  Rel. Test L2 Loss :  0.0550952451924483  Test L2 Loss :  0.024272240648667016  inv_L_scale:  [0.865]
Epoch :  50  Time:  9.92  Rel. Train L2 Loss :  0.07435350771745046  Rel. Test L2 Loss :  0.051538856824239095  Test L2 Loss :  0.023135053043564162  inv_L_scale:  [0.869]
Epoch :  51  Time:  9.95  Rel. Train L2 Loss :  0.07752021016677221  Rel. Test L2 Loss :  0.04969653417666753  Test L2 Loss :  0.02227659391860167  inv_L_scale:  [0.879]
Epoch :  52  Time:  10.142  Rel. Train L2 Loss :  0.07572275700171789  Rel. Test L2 Loss :  0.050832524051268896  Test L2 Loss :  0.022799617151419323  inv_L_scale:  [0.914]
Epoch :  53  Time:  9.959  Rel. Train L2 Loss :  0.07776501401265462  Rel. Test L2 Loss :  0.04801468128959338  Test L2 Loss :  0.02147012727955977  inv_L_scale:  [0.914]
Epoch :  54  Time:  9.935  Rel. Train L2 Loss :  0.0767568368713061  Rel. Test L2 Loss :  0.05009086236357689  Test L2 Loss :  0.02231611522535483  inv_L_scale:  [0.897]
Epoch :  55  Time:  9.934  Rel. Train L2 Loss :  0.07695718504985173  Rel. Test L2 Loss :  0.05340538943807284  Test L2 Loss :  0.02398709163069725  inv_L_scale:  [0.933]
Epoch :  56  Time:  9.938  Rel. Train L2 Loss :  0.0845885015130043  Rel. Test L2 Loss :  0.049502569735050204  Test L2 Loss :  0.022108561744292578  inv_L_scale:  [0.926]
Epoch :  57  Time:  9.953  Rel. Train L2 Loss :  0.08024579846858979  Rel. Test L2 Loss :  0.05075670917828878  Test L2 Loss :  0.022544330234328905  inv_L_scale:  [0.888]
Epoch :  58  Time:  9.905  Rel. Train L2 Loss :  0.07650750946998597  Rel. Test L2 Loss :  0.05134692206978798  Test L2 Loss :  0.023021391307314235  inv_L_scale:  [0.858]
Epoch :  59  Time:  9.901  Rel. Train L2 Loss :  0.08040771279732387  Rel. Test L2 Loss :  0.044341070652008055  Test L2 Loss :  0.01978980116546154  inv_L_scale:  [0.894]
Epoch :  60  Time:  9.899  Rel. Train L2 Loss :  0.08359740149974823  Rel. Test L2 Loss :  0.05445435335238775  Test L2 Loss :  0.024320001875360805  inv_L_scale:  [0.894]
Epoch :  61  Time:  9.914  Rel. Train L2 Loss :  0.08100366828838984  Rel. Test L2 Loss :  0.05611002256472906  Test L2 Loss :  0.025264252449075382  inv_L_scale:  [0.841]
Epoch :  62  Time:  9.911  Rel. Train L2 Loss :  0.08678551044066747  Rel. Test L2 Loss :  0.05116508066654205  Test L2 Loss :  0.02286690133313338  inv_L_scale:  [0.83]
Epoch :  63  Time:  9.912  Rel. Train L2 Loss :  0.08362179140249888  Rel. Test L2 Loss :  0.051489283243815104  Test L2 Loss :  0.023207230021556217  inv_L_scale:  [0.853]
Epoch :  64  Time:  9.912  Rel. Train L2 Loss :  0.0798840221563975  Rel. Test L2 Loss :  0.05818701605002086  Test L2 Loss :  0.026025355209906897  inv_L_scale:  [0.852]
Epoch :  65  Time:  9.991  Rel. Train L2 Loss :  0.07875498869021734  Rel. Test L2 Loss :  0.04907125433286031  Test L2 Loss :  0.021965457399686177  inv_L_scale:  [0.85]
Epoch :  66  Time:  9.914  Rel. Train L2 Loss :  0.07741500651836396  Rel. Test L2 Loss :  0.04809734970331192  Test L2 Loss :  0.021617680937051773  inv_L_scale:  [0.878]
Epoch :  67  Time:  9.882  Rel. Train L2 Loss :  0.07751213463147481  Rel. Test L2 Loss :  0.04666027292609215  Test L2 Loss :  0.0210354092468818  inv_L_scale:  [0.922]
Epoch :  68  Time:  9.885  Rel. Train L2 Loss :  0.07551293345292409  Rel. Test L2 Loss :  0.043535343905289965  Test L2 Loss :  0.019536650056640306  inv_L_scale:  [0.886]
Epoch :  69  Time:  9.886  Rel. Train L2 Loss :  0.07753743006785711  Rel. Test L2 Loss :  0.04605356151858966  Test L2 Loss :  0.020654833267132442  inv_L_scale:  [0.902]
Epoch :  70  Time:  9.922  Rel. Train L2 Loss :  0.0769941415588061  Rel. Test L2 Loss :  0.043862248708804445  Test L2 Loss :  0.019539624725778897  inv_L_scale:  [0.899]
Epoch :  71  Time:  9.924  Rel. Train L2 Loss :  0.0753452708721161  Rel. Test L2 Loss :  0.04586739559968313  Test L2 Loss :  0.020513212606310845  inv_L_scale:  [0.889]
Epoch :  72  Time:  9.93  Rel. Train L2 Loss :  0.07738836441437404  Rel. Test L2 Loss :  0.04292906065781911  Test L2 Loss :  0.019332190329829853  inv_L_scale:  [0.949]
Epoch :  73  Time:  9.865  Rel. Train L2 Loss :  0.07611215072870255  Rel. Test L2 Loss :  0.04669371883074443  Test L2 Loss :  0.020978457232316335  inv_L_scale:  [0.885]
Epoch :  74  Time:  9.887  Rel. Train L2 Loss :  0.07702702273925145  Rel. Test L2 Loss :  0.048857921014229456  Test L2 Loss :  0.021898282046119374  inv_L_scale:  [0.877]
Epoch :  75  Time:  9.905  Rel. Train L2 Loss :  0.07443839782476425  Rel. Test L2 Loss :  0.04602812925974528  Test L2 Loss :  0.02050769535203775  inv_L_scale:  [0.873]
Epoch :  76  Time:  9.898  Rel. Train L2 Loss :  0.07561444646120072  Rel. Test L2 Loss :  0.05073737735549609  Test L2 Loss :  0.022939404547214506  inv_L_scale:  [0.871]
Epoch :  77  Time:  9.905  Rel. Train L2 Loss :  0.0794940738081932  Rel. Test L2 Loss :  0.04642107824484507  Test L2 Loss :  0.020834106529752414  inv_L_scale:  [0.863]
Epoch :  78  Time:  9.938  Rel. Train L2 Loss :  0.07770334382851919  Rel. Test L2 Loss :  0.05210820863644282  Test L2 Loss :  0.02327493501206239  inv_L_scale:  [0.874]
Epoch :  79  Time:  9.921  Rel. Train L2 Loss :  0.0746319150129954  Rel. Test L2 Loss :  0.04783179928859075  Test L2 Loss :  0.021374940946698187  inv_L_scale:  [0.879]
Epoch :  80  Time:  9.898  Rel. Train L2 Loss :  0.0778865978916486  Rel. Test L2 Loss :  0.05096056858698527  Test L2 Loss :  0.022806985477606456  inv_L_scale:  [0.881]
Epoch :  81  Time:  9.909  Rel. Train L2 Loss :  0.07698065612713496  Rel. Test L2 Loss :  0.05054824024438858  Test L2 Loss :  0.022815929104884464  inv_L_scale:  [0.892]
Epoch :  82  Time:  9.905  Rel. Train L2 Loss :  0.0777343203028043  Rel. Test L2 Loss :  0.04716666827599208  Test L2 Loss :  0.021102645720044774  inv_L_scale:  [0.875]
Epoch :  83  Time:  9.908  Rel. Train L2 Loss :  0.07714273242155711  Rel. Test L2 Loss :  0.043996391346057255  Test L2 Loss :  0.01966319757203261  inv_L_scale:  [0.876]
Epoch :  84  Time:  9.895  Rel. Train L2 Loss :  0.07600891641775767  Rel. Test L2 Loss :  0.05292527159055074  Test L2 Loss :  0.023723710030317306  inv_L_scale:  [0.878]
Epoch :  85  Time:  9.988  Rel. Train L2 Loss :  0.07570288332303365  Rel. Test L2 Loss :  0.04542537736395995  Test L2 Loss :  0.02045326493680477  inv_L_scale:  [0.875]
Epoch :  86  Time:  9.904  Rel. Train L2 Loss :  0.07775974833965302  Rel. Test L2 Loss :  0.0438468245168527  Test L2 Loss :  0.019676293755571048  inv_L_scale:  [0.895]
Epoch :  87  Time:  9.872  Rel. Train L2 Loss :  0.07972092076142628  Rel. Test L2 Loss :  0.04905997922023137  Test L2 Loss :  0.021930496543645858  inv_L_scale:  [0.868]
Epoch :  88  Time:  9.874  Rel. Train L2 Loss :  0.07670957332849503  Rel. Test L2 Loss :  0.04816897993286451  Test L2 Loss :  0.02153869698445002  inv_L_scale:  [0.873]
Epoch :  89  Time:  9.881  Rel. Train L2 Loss :  0.07758242662747701  Rel. Test L2 Loss :  0.04779877478877703  Test L2 Loss :  0.021317907596627873  inv_L_scale:  [0.858]
Epoch :  90  Time:  9.873  Rel. Train L2 Loss :  0.08084386646747589  Rel. Test L2 Loss :  0.052690088252226513  Test L2 Loss :  0.023386374389131864  inv_L_scale:  [0.804]
Epoch :  91  Time:  9.881  Rel. Train L2 Loss :  0.07981259644031524  Rel. Test L2 Loss :  0.045474718709786734  Test L2 Loss :  0.02044709990421931  inv_L_scale:  [0.787]
Epoch :  92  Time:  9.917  Rel. Train L2 Loss :  0.08256364023685456  Rel. Test L2 Loss :  0.048286896894375486  Test L2 Loss :  0.021656253164013227  inv_L_scale:  [0.791]
Epoch :  93  Time:  9.911  Rel. Train L2 Loss :  0.07590866009394327  Rel. Test L2 Loss :  0.04368357352912426  Test L2 Loss :  0.019582337190707524  inv_L_scale:  [0.795]
Epoch :  94  Time:  9.905  Rel. Train L2 Loss :  0.0770861434340477  Rel. Test L2 Loss :  0.042302960728605586  Test L2 Loss :  0.019054601242144902  inv_L_scale:  [0.808]
Epoch :  95  Time:  9.911  Rel. Train L2 Loss :  0.07570971375703811  Rel. Test L2 Loss :  0.04646730015675227  Test L2 Loss :  0.020778308014074962  inv_L_scale:  [0.787]
Epoch :  96  Time:  9.905  Rel. Train L2 Loss :  0.0783074908653895  Rel. Test L2 Loss :  0.048341034452120464  Test L2 Loss :  0.021684000641107558  inv_L_scale:  [0.818]
Epoch :  97  Time:  9.898  Rel. Train L2 Loss :  0.08094884405533473  Rel. Test L2 Loss :  0.0454129588107268  Test L2 Loss :  0.020375828395287197  inv_L_scale:  [0.761]
Epoch :  98  Time:  9.882  Rel. Train L2 Loss :  0.0825366738239924  Rel. Test L2 Loss :  0.05190209244688352  Test L2 Loss :  0.0231777540097634  inv_L_scale:  [0.775]
Epoch :  99  Time:  9.893  Rel. Train L2 Loss :  0.07555967617034912  Rel. Test L2 Loss :  0.04521358812848727  Test L2 Loss :  0.02041958605249723  inv_L_scale:  [0.765]
Epoch :  100  Time:  9.893  Rel. Train L2 Loss :  0.07656504507859548  Rel. Test L2 Loss :  0.04499418844779333  Test L2 Loss :  0.020101909960309663  inv_L_scale:  [0.785]
Epoch :  101  Time:  9.865  Rel. Train L2 Loss :  0.0759022815823555  Rel. Test L2 Loss :  0.050374768227338794  Test L2 Loss :  0.02257458359003067  inv_L_scale:  [0.818]
Epoch :  102  Time:  9.904  Rel. Train L2 Loss :  0.07458259024222692  Rel. Test L2 Loss :  0.04169339234630267  Test L2 Loss :  0.01863113890091578  inv_L_scale:  [0.817]
Epoch :  103  Time:  9.884  Rel. Train L2 Loss :  0.08688761331637701  Rel. Test L2 Loss :  0.04871486678719521  Test L2 Loss :  0.021742352445920307  inv_L_scale:  [0.756]
Epoch :  104  Time:  9.874  Rel. Train L2 Loss :  0.07590388057629267  Rel. Test L2 Loss :  0.04455167790253957  Test L2 Loss :  0.02001867470641931  inv_L_scale:  [0.749]
Epoch :  105  Time:  9.89  Rel. Train L2 Loss :  0.07735586714744568  Rel. Test L2 Loss :  0.04408602217833201  Test L2 Loss :  0.019657601366440455  inv_L_scale:  [0.749]
Epoch :  106  Time:  9.898  Rel. Train L2 Loss :  0.07369033378362656  Rel. Test L2 Loss :  0.04470690483848254  Test L2 Loss :  0.020019685501853623  inv_L_scale:  [0.749]
Epoch :  107  Time:  9.896  Rel. Train L2 Loss :  0.075205180366834  Rel. Test L2 Loss :  0.04499650473395984  Test L2 Loss :  0.020138910487294197  inv_L_scale:  [0.776]
Epoch :  108  Time:  9.879  Rel. Train L2 Loss :  0.07742714645465215  Rel. Test L2 Loss :  0.04413139934341113  Test L2 Loss :  0.019874392996231716  inv_L_scale:  [0.79]
Epoch :  109  Time:  9.914  Rel. Train L2 Loss :  0.07515102638800938  Rel. Test L2 Loss :  0.040268542369206746  Test L2 Loss :  0.01800607403119405  inv_L_scale:  [0.786]
Epoch :  110  Time:  9.899  Rel. Train L2 Loss :  0.07455221072832743  Rel. Test L2 Loss :  0.04039932663242022  Test L2 Loss :  0.01805224490662416  inv_L_scale:  [0.787]
Epoch :  111  Time:  9.918  Rel. Train L2 Loss :  0.07566536154349646  Rel. Test L2 Loss :  0.04145959824323654  Test L2 Loss :  0.018561622674266497  inv_L_scale:  [0.791]
Epoch :  112  Time:  9.914  Rel. Train L2 Loss :  0.0725362757643064  Rel. Test L2 Loss :  0.04848528782526652  Test L2 Loss :  0.02185006469488144  inv_L_scale:  [0.786]
Epoch :  113  Time:  9.907  Rel. Train L2 Loss :  0.07352178873618444  Rel. Test L2 Loss :  0.046908037215471265  Test L2 Loss :  0.02105194516479969  inv_L_scale:  [0.802]
Epoch :  114  Time:  9.896  Rel. Train L2 Loss :  0.07650275105237961  Rel. Test L2 Loss :  0.043192973931630456  Test L2 Loss :  0.019392442107200623  inv_L_scale:  [0.816]
Epoch :  115  Time:  9.911  Rel. Train L2 Loss :  0.07560831270615259  Rel. Test L2 Loss :  0.04512359167138735  Test L2 Loss :  0.02021359749138355  inv_L_scale:  [0.812]
Epoch :  116  Time:  9.903  Rel. Train L2 Loss :  0.07734674177567163  Rel. Test L2 Loss :  0.04499410092830658  Test L2 Loss :  0.020276516377925873  inv_L_scale:  [0.857]
Epoch :  117  Time:  9.898  Rel. Train L2 Loss :  0.07592807418107986  Rel. Test L2 Loss :  0.04401591181755066  Test L2 Loss :  0.019672568514943124  inv_L_scale:  [0.886]
Epoch :  118  Time:  9.885  Rel. Train L2 Loss :  0.07502738948663076  Rel. Test L2 Loss :  0.05106843257943789  Test L2 Loss :  0.02293380007147789  inv_L_scale:  [0.896]
Epoch :  119  Time:  9.928  Rel. Train L2 Loss :  0.07809687691926956  Rel. Test L2 Loss :  0.05096024582783381  Test L2 Loss :  0.02317290330926577  inv_L_scale:  [0.822]
Epoch :  120  Time:  9.931  Rel. Train L2 Loss :  0.07361832451820373  Rel. Test L2 Loss :  0.04370025629798571  Test L2 Loss :  0.01949734166264534  inv_L_scale:  [0.821]
Epoch :  121  Time:  9.912  Rel. Train L2 Loss :  0.07610941326618195  Rel. Test L2 Loss :  0.043437662894527114  Test L2 Loss :  0.01935777780910333  inv_L_scale:  [0.814]
Epoch :  122  Time:  9.902  Rel. Train L2 Loss :  0.0741385303735733  Rel. Test L2 Loss :  0.043404538631439206  Test L2 Loss :  0.019601300234595935  inv_L_scale:  [0.806]
Epoch :  123  Time:  9.897  Rel. Train L2 Loss :  0.0778115556637446  Rel. Test L2 Loss :  0.04399883329868317  Test L2 Loss :  0.019731544305880866  inv_L_scale:  [0.82]
Epoch :  124  Time:  9.929  Rel. Train L2 Loss :  0.07675860768556594  Rel. Test L2 Loss :  0.07230469728509585  Test L2 Loss :  0.03192081744472186  inv_L_scale:  [0.865]
Epoch :  125  Time:  9.926  Rel. Train L2 Loss :  0.07846943722168605  Rel. Test L2 Loss :  0.04141311342517535  Test L2 Loss :  0.018463964139421783  inv_L_scale:  [0.866]
Epoch :  126  Time:  9.917  Rel. Train L2 Loss :  0.07245532166957855  Rel. Test L2 Loss :  0.040856879055500034  Test L2 Loss :  0.018290381853779156  inv_L_scale:  [0.88]
Epoch :  127  Time:  9.9  Rel. Train L2 Loss :  0.07414836829900742  Rel. Test L2 Loss :  0.039699398999412855  Test L2 Loss :  0.017619975358247757  inv_L_scale:  [0.872]
Epoch :  128  Time:  9.929  Rel. Train L2 Loss :  0.07264851015806198  Rel. Test L2 Loss :  0.042330400173862776  Test L2 Loss :  0.01905220977962017  inv_L_scale:  [0.857]
Epoch :  129  Time:  9.901  Rel. Train L2 Loss :  0.07493024716774623  Rel. Test L2 Loss :  0.04119566957155863  Test L2 Loss :  0.018471216559410097  inv_L_scale:  [0.845]
Epoch :  130  Time:  9.877  Rel. Train L2 Loss :  0.07375146116813024  Rel. Test L2 Loss :  0.04066810672481855  Test L2 Loss :  0.018253238623340926  inv_L_scale:  [0.832]
Epoch :  131  Time:  9.906  Rel. Train L2 Loss :  0.07384775739908218  Rel. Test L2 Loss :  0.038070430929462114  Test L2 Loss :  0.01691821667055289  inv_L_scale:  [0.834]
Epoch :  132  Time:  9.891  Rel. Train L2 Loss :  0.07143948254982631  Rel. Test L2 Loss :  0.039458314379056295  Test L2 Loss :  0.017614903847376507  inv_L_scale:  [0.825]
Epoch :  133  Time:  9.887  Rel. Train L2 Loss :  0.07574944216012955  Rel. Test L2 Loss :  0.043532050251960754  Test L2 Loss :  0.019359461416800818  inv_L_scale:  [0.834]
Epoch :  134  Time:  9.923  Rel. Train L2 Loss :  0.07619513036807378  Rel. Test L2 Loss :  0.044652914901574456  Test L2 Loss :  0.020042674044768016  inv_L_scale:  [0.803]
Epoch :  135  Time:  10.041  Rel. Train L2 Loss :  0.08309948511918386  Rel. Test L2 Loss :  0.04552590524156888  Test L2 Loss :  0.020378769810001054  inv_L_scale:  [0.783]
Epoch :  136  Time:  10.02  Rel. Train L2 Loss :  0.08283426193396251  Rel. Test L2 Loss :  0.045947554806868234  Test L2 Loss :  0.020784705355763437  inv_L_scale:  [0.763]
Epoch :  137  Time:  9.896  Rel. Train L2 Loss :  0.07484402948617935  Rel. Test L2 Loss :  0.043729461034138994  Test L2 Loss :  0.019669134418169656  inv_L_scale:  [0.759]
Epoch :  138  Time:  9.9  Rel. Train L2 Loss :  0.07712386482954026  Rel. Test L2 Loss :  0.042725382273395854  Test L2 Loss :  0.019326712712645532  inv_L_scale:  [0.762]
Epoch :  139  Time:  9.896  Rel. Train L2 Loss :  0.07754545931021373  Rel. Test L2 Loss :  0.04006522784630458  Test L2 Loss :  0.017886694322029748  inv_L_scale:  [0.755]
Epoch :  140  Time:  9.908  Rel. Train L2 Loss :  0.07640589660406112  Rel. Test L2 Loss :  0.04170059929291407  Test L2 Loss :  0.01873943517605464  inv_L_scale:  [0.723]
Epoch :  141  Time:  9.917  Rel. Train L2 Loss :  0.07592019607623418  Rel. Test L2 Loss :  0.041779834826787314  Test L2 Loss :  0.018739745914936067  inv_L_scale:  [0.74]
Epoch :  142  Time:  9.921  Rel. Train L2 Loss :  0.07144805433352788  Rel. Test L2 Loss :  0.04316896225015322  Test L2 Loss :  0.019373592808842658  inv_L_scale:  [0.767]
Epoch :  143  Time:  9.92  Rel. Train L2 Loss :  0.07405625096956889  Rel. Test L2 Loss :  0.05555402378241221  Test L2 Loss :  0.02496002070605755  inv_L_scale:  [0.754]
Epoch :  144  Time:  9.923  Rel. Train L2 Loss :  0.07242713604370753  Rel. Test L2 Loss :  0.041830311467250185  Test L2 Loss :  0.01872014264265696  inv_L_scale:  [0.774]
Epoch :  145  Time:  9.906  Rel. Train L2 Loss :  0.07262574787934621  Rel. Test L2 Loss :  0.03882048321266969  Test L2 Loss :  0.017374862755338352  inv_L_scale:  [0.77]
Epoch :  146  Time:  9.882  Rel. Train L2 Loss :  0.08904765154918035  Rel. Test L2 Loss :  0.045815580834945045  Test L2 Loss :  0.02078427352011204  inv_L_scale:  [0.746]
Epoch :  147  Time:  9.877  Rel. Train L2 Loss :  0.07895684299866358  Rel. Test L2 Loss :  0.044900917013486225  Test L2 Loss :  0.020368817994991937  inv_L_scale:  [0.742]
Epoch :  148  Time:  9.867  Rel. Train L2 Loss :  0.0817738503019015  Rel. Test L2 Loss :  0.040761320789655046  Test L2 Loss :  0.018389820257822674  inv_L_scale:  [0.695]
Epoch :  149  Time:  9.879  Rel. Train L2 Loss :  0.07992985439300537  Rel. Test L2 Loss :  0.0415443754196167  Test L2 Loss :  0.01865616376201312  inv_L_scale:  [0.701]
Epoch :  150  Time:  9.866  Rel. Train L2 Loss :  0.07364764008919399  Rel. Test L2 Loss :  0.04133814128736655  Test L2 Loss :  0.018536160017053285  inv_L_scale:  [0.694]
Epoch :  151  Time:  9.884  Rel. Train L2 Loss :  0.07286405771970748  Rel. Test L2 Loss :  0.039773443043231965  Test L2 Loss :  0.017739612807830176  inv_L_scale:  [0.691]
Epoch :  152  Time:  9.955  Rel. Train L2 Loss :  0.07267271266380945  Rel. Test L2 Loss :  0.039077434862653415  Test L2 Loss :  0.017396085833509763  inv_L_scale:  [0.697]
Epoch :  153  Time:  9.915  Rel. Train L2 Loss :  0.07068351342280706  Rel. Test L2 Loss :  0.038460409243901574  Test L2 Loss :  0.017262166365981102  inv_L_scale:  [0.704]
Epoch :  154  Time:  9.906  Rel. Train L2 Loss :  0.07192782630523045  Rel. Test L2 Loss :  0.041054710100094476  Test L2 Loss :  0.018355580593148867  inv_L_scale:  [0.707]
Epoch :  155  Time:  9.933  Rel. Train L2 Loss :  0.07155249410867691  Rel. Test L2 Loss :  0.05395639051993688  Test L2 Loss :  0.024208294600248335  inv_L_scale:  [0.706]
Epoch :  156  Time:  9.932  Rel. Train L2 Loss :  0.07195502022902171  Rel. Test L2 Loss :  0.038915725946426394  Test L2 Loss :  0.017467418412367503  inv_L_scale:  [0.707]
Epoch :  157  Time:  9.946  Rel. Train L2 Loss :  0.07145444657405217  Rel. Test L2 Loss :  0.03818160504102707  Test L2 Loss :  0.01706125336388747  inv_L_scale:  [0.706]
Epoch :  158  Time:  9.929  Rel. Train L2 Loss :  0.07106723237037658  Rel. Test L2 Loss :  0.03576548293232918  Test L2 Loss :  0.015969230284293492  inv_L_scale:  [0.699]
Epoch :  159  Time:  9.933  Rel. Train L2 Loss :  0.0719522245724996  Rel. Test L2 Loss :  0.04184389551480611  Test L2 Loss :  0.018796919534603756  inv_L_scale:  [0.707]
Epoch :  160  Time:  9.915  Rel. Train L2 Loss :  0.07514351707696915  Rel. Test L2 Loss :  0.08578974455595016  Test L2 Loss :  0.03859198083480199  inv_L_scale:  [0.707]
Epoch :  161  Time:  9.911  Rel. Train L2 Loss :  0.07935042464733123  Rel. Test L2 Loss :  0.04195660427212715  Test L2 Loss :  0.018946167478958765  inv_L_scale:  [0.688]
Epoch :  162  Time:  9.916  Rel. Train L2 Loss :  0.07408636170625686  Rel. Test L2 Loss :  0.040324758142232894  Test L2 Loss :  0.018148482143878937  inv_L_scale:  [0.679]
Epoch :  163  Time:  9.894  Rel. Train L2 Loss :  0.07108093158404033  Rel. Test L2 Loss :  0.036704101487994197  Test L2 Loss :  0.016470262110233308  inv_L_scale:  [0.682]
Epoch :  164  Time:  9.875  Rel. Train L2 Loss :  0.07056330247720083  Rel. Test L2 Loss :  0.04029285654425621  Test L2 Loss :  0.018105206365386647  inv_L_scale:  [0.683]
Epoch :  165  Time:  9.874  Rel. Train L2 Loss :  0.07179342957337698  Rel. Test L2 Loss :  0.03997502719362577  Test L2 Loss :  0.017929166853427887  inv_L_scale:  [0.677]
Epoch :  166  Time:  9.886  Rel. Train L2 Loss :  0.08030707029501596  Rel. Test L2 Loss :  0.04331827109058698  Test L2 Loss :  0.01947680925329526  inv_L_scale:  [0.672]
Epoch :  167  Time:  9.879  Rel. Train L2 Loss :  0.07150764876604081  Rel. Test L2 Loss :  0.04231442073980967  Test L2 Loss :  0.019053740675250688  inv_L_scale:  [0.677]
Epoch :  168  Time:  9.863  Rel. Train L2 Loss :  0.07490282980600993  Rel. Test L2 Loss :  0.03906088516116142  Test L2 Loss :  0.01748432988921801  inv_L_scale:  [0.651]
Epoch :  169  Time:  9.923  Rel. Train L2 Loss :  0.07324657613039016  Rel. Test L2 Loss :  0.03792843207716942  Test L2 Loss :  0.01707914724946022  inv_L_scale:  [0.65]
Epoch :  170  Time:  9.937  Rel. Train L2 Loss :  0.07180527591705323  Rel. Test L2 Loss :  0.04302735522389412  Test L2 Loss :  0.01933871346215407  inv_L_scale:  [0.646]
Epoch :  171  Time:  9.95  Rel. Train L2 Loss :  0.09115996511777243  Rel. Test L2 Loss :  0.05328430896004041  Test L2 Loss :  0.02389173279205958  inv_L_scale:  [0.647]
Epoch :  172  Time:  10.017  Rel. Train L2 Loss :  0.07540855463345845  Rel. Test L2 Loss :  0.03951858711739381  Test L2 Loss :  0.017660307561357814  inv_L_scale:  [0.641]
Epoch :  173  Time:  10.151  Rel. Train L2 Loss :  0.07486507366100947  Rel. Test L2 Loss :  0.042444178958733876  Test L2 Loss :  0.019050398543477058  inv_L_scale:  [0.638]
Epoch :  174  Time:  9.961  Rel. Train L2 Loss :  0.0750224960843722  Rel. Test L2 Loss :  0.0407402299841245  Test L2 Loss :  0.018281051367521287  inv_L_scale:  [0.649]
Epoch :  175  Time:  9.925  Rel. Train L2 Loss :  0.0717845214009285  Rel. Test L2 Loss :  0.04070672114690145  Test L2 Loss :  0.018264136090874673  inv_L_scale:  [0.64]
Epoch :  176  Time:  9.947  Rel. Train L2 Loss :  0.07247668999433518  Rel. Test L2 Loss :  0.04027199000120163  Test L2 Loss :  0.018038785407940548  inv_L_scale:  [0.644]
Epoch :  177  Time:  9.939  Rel. Train L2 Loss :  0.07082999352614085  Rel. Test L2 Loss :  0.04012477785348892  Test L2 Loss :  0.017956324890255927  inv_L_scale:  [0.644]
Epoch :  178  Time:  9.945  Rel. Train L2 Loss :  0.07064770265420278  Rel. Test L2 Loss :  0.0368589477489392  Test L2 Loss :  0.016511358817418418  inv_L_scale:  [0.645]
Epoch :  179  Time:  9.952  Rel. Train L2 Loss :  0.07301823681592941  Rel. Test L2 Loss :  0.041027490943670274  Test L2 Loss :  0.018469922045866647  inv_L_scale:  [0.641]
Epoch :  180  Time:  10.052  Rel. Train L2 Loss :  0.07232626911004385  Rel. Test L2 Loss :  0.0408720575273037  Test L2 Loss :  0.018214428797364235  inv_L_scale:  [0.662]
Epoch :  181  Time:  9.935  Rel. Train L2 Loss :  0.07273383824030558  Rel. Test L2 Loss :  0.0399846176803112  Test L2 Loss :  0.01793479397892952  inv_L_scale:  [0.661]
Epoch :  182  Time:  10.049  Rel. Train L2 Loss :  0.10035571682453155  Rel. Test L2 Loss :  0.04853917961319287  Test L2 Loss :  0.02180279610057672  inv_L_scale:  [0.654]
Epoch :  183  Time:  10.047  Rel. Train L2 Loss :  0.07340894711017609  Rel. Test L2 Loss :  0.039516257842381795  Test L2 Loss :  0.017653457472721734  inv_L_scale:  [0.653]
Epoch :  184  Time:  9.908  Rel. Train L2 Loss :  0.07790527604023616  Rel. Test L2 Loss :  0.04311417505145073  Test L2 Loss :  0.019515537768602372  inv_L_scale:  [0.655]
Epoch :  185  Time:  9.902  Rel. Train L2 Loss :  0.07154440240065257  Rel. Test L2 Loss :  0.03918589137494564  Test L2 Loss :  0.017514968439936638  inv_L_scale:  [0.662]
Epoch :  186  Time:  9.93  Rel. Train L2 Loss :  0.07070528644323348  Rel. Test L2 Loss :  0.03836949944496155  Test L2 Loss :  0.01711232396463553  inv_L_scale:  [0.657]
Epoch :  187  Time:  9.924  Rel. Train L2 Loss :  0.06987752701838812  Rel. Test L2 Loss :  0.04115026613076528  Test L2 Loss :  0.01842066633204619  inv_L_scale:  [0.66]
Epoch :  188  Time:  9.903  Rel. Train L2 Loss :  0.07174082048734029  Rel. Test L2 Loss :  0.0406155206511418  Test L2 Loss :  0.018201475143432618  inv_L_scale:  [0.664]
Epoch :  189  Time:  9.945  Rel. Train L2 Loss :  0.07294416121641795  Rel. Test L2 Loss :  0.04059650120635827  Test L2 Loss :  0.018156866058707238  inv_L_scale:  [0.665]
Epoch :  190  Time:  10.084  Rel. Train L2 Loss :  0.07255764995018642  Rel. Test L2 Loss :  0.03869426121314367  Test L2 Loss :  0.017265174041191735  inv_L_scale:  [0.659]
Epoch :  191  Time:  9.916  Rel. Train L2 Loss :  0.07567619834343592  Rel. Test L2 Loss :  0.0407935297737519  Test L2 Loss :  0.018203608865539234  inv_L_scale:  [0.658]
Epoch :  192  Time:  9.903  Rel. Train L2 Loss :  0.07021028623978297  Rel. Test L2 Loss :  0.03943460777401924  Test L2 Loss :  0.017726615890860557  inv_L_scale:  [0.665]
Epoch :  193  Time:  9.895  Rel. Train L2 Loss :  0.06905863261222839  Rel. Test L2 Loss :  0.04257091318567594  Test L2 Loss :  0.019150017748276394  inv_L_scale:  [0.661]
Epoch :  194  Time:  9.919  Rel. Train L2 Loss :  0.06778197832902273  Rel. Test L2 Loss :  0.04027155766884486  Test L2 Loss :  0.017978161027034124  inv_L_scale:  [0.665]
Epoch :  195  Time:  9.902  Rel. Train L2 Loss :  0.07256727854410808  Rel. Test L2 Loss :  0.040432023157676064  Test L2 Loss :  0.01813458020488421  inv_L_scale:  [0.681]
Epoch :  196  Time:  9.917  Rel. Train L2 Loss :  0.07196182332436243  Rel. Test L2 Loss :  0.04242021766801675  Test L2 Loss :  0.0189365466684103  inv_L_scale:  [0.691]
Epoch :  197  Time:  9.92  Rel. Train L2 Loss :  0.06992551477750142  Rel. Test L2 Loss :  0.04231498792767525  Test L2 Loss :  0.01889735462764899  inv_L_scale:  [0.671]
Epoch :  198  Time:  9.921  Rel. Train L2 Loss :  0.06772332435846329  Rel. Test L2 Loss :  0.042207946653167405  Test L2 Loss :  0.018914758389194805  inv_L_scale:  [0.673]
Epoch :  199  Time:  10.189  Rel. Train L2 Loss :  0.06826566817363103  Rel. Test L2 Loss :  0.039552959253390634  Test L2 Loss :  0.017703870261708894  inv_L_scale:  [0.667]
Epoch :  200  Time:  9.922  Rel. Train L2 Loss :  0.06997555460532506  Rel. Test L2 Loss :  0.03878590573867162  Test L2 Loss :  0.017297868207097052  inv_L_scale:  [0.663]
Epoch :  201  Time:  9.933  Rel. Train L2 Loss :  0.0678104076385498  Rel. Test L2 Loss :  0.043611980974674225  Test L2 Loss :  0.019504582136869432  inv_L_scale:  [0.678]
Epoch :  202  Time:  9.956  Rel. Train L2 Loss :  0.06792518611749013  Rel. Test L2 Loss :  0.04415020843346914  Test L2 Loss :  0.01980723276734352  inv_L_scale:  [0.674]
Epoch :  203  Time:  10.078  Rel. Train L2 Loss :  0.06853345398108164  Rel. Test L2 Loss :  0.0489428366223971  Test L2 Loss :  0.022159303724765777  inv_L_scale:  [0.67]
Epoch :  204  Time:  9.928  Rel. Train L2 Loss :  0.09491641292969386  Rel. Test L2 Loss :  0.05897277265787124  Test L2 Loss :  0.02665541892250379  inv_L_scale:  [0.64]
Epoch :  205  Time:  9.921  Rel. Train L2 Loss :  0.07669130559762319  Rel. Test L2 Loss :  0.04265272334218025  Test L2 Loss :  0.019145818054676057  inv_L_scale:  [0.636]
Epoch :  206  Time:  11.93  Rel. Train L2 Loss :  0.07436201033989588  Rel. Test L2 Loss :  0.04083050767580668  Test L2 Loss :  0.01831349735458692  inv_L_scale:  [0.66]
Epoch :  207  Time:  9.962  Rel. Train L2 Loss :  0.06964076302448909  Rel. Test L2 Loss :  0.039980026831229525  Test L2 Loss :  0.017950690587361654  inv_L_scale:  [0.659]
Epoch :  208  Time:  9.951  Rel. Train L2 Loss :  0.0710574843287468  Rel. Test L2 Loss :  0.04219261705875397  Test L2 Loss :  0.018911556353171665  inv_L_scale:  [0.687]
Epoch :  209  Time:  10.007  Rel. Train L2 Loss :  0.06824708211421966  Rel. Test L2 Loss :  0.04136561488111814  Test L2 Loss :  0.01855419506629308  inv_L_scale:  [0.67]
Epoch :  210  Time:  9.928  Rel. Train L2 Loss :  0.07038514389594396  Rel. Test L2 Loss :  0.04157185398042202  Test L2 Loss :  0.01863657347857952  inv_L_scale:  [0.692]
Epoch :  211  Time:  9.874  Rel. Train L2 Loss :  0.0695855486591657  Rel. Test L2 Loss :  0.04255112205942472  Test L2 Loss :  0.019105514983336132  inv_L_scale:  [0.676]
Epoch :  212  Time:  10.028  Rel. Train L2 Loss :  0.06628186462322871  Rel. Test L2 Loss :  0.04068819751342138  Test L2 Loss :  0.018207878743608793  inv_L_scale:  [0.68]
Epoch :  213  Time:  10.359  Rel. Train L2 Loss :  0.06667773314317067  Rel. Test L2 Loss :  0.04401228385667006  Test L2 Loss :  0.019886187662680944  inv_L_scale:  [0.662]
Epoch :  214  Time:  9.935  Rel. Train L2 Loss :  0.06850750277439753  Rel. Test L2 Loss :  0.04471240853269895  Test L2 Loss :  0.02011955703298251  inv_L_scale:  [0.666]
Epoch :  215  Time:  9.91  Rel. Train L2 Loss :  0.06804928251107534  Rel. Test L2 Loss :  0.041682647292812666  Test L2 Loss :  0.01891709434489409  inv_L_scale:  [0.659]
Epoch :  216  Time:  9.901  Rel. Train L2 Loss :  0.0691522492369016  Rel. Test L2 Loss :  0.04202515140175819  Test L2 Loss :  0.018831798161069554  inv_L_scale:  [0.639]
Epoch :  217  Time:  9.912  Rel. Train L2 Loss :  0.06806181742747625  Rel. Test L2 Loss :  0.04106484810511271  Test L2 Loss :  0.018406871259212493  inv_L_scale:  [0.645]
Epoch :  218  Time:  9.914  Rel. Train L2 Loss :  0.06632674477497737  Rel. Test L2 Loss :  0.0413455339272817  Test L2 Loss :  0.01846638965109984  inv_L_scale:  [0.654]
Epoch :  219  Time:  10.091  Rel. Train L2 Loss :  0.0681587539712588  Rel. Test L2 Loss :  0.04294949792325497  Test L2 Loss :  0.01927830251554648  inv_L_scale:  [0.637]
Epoch :  220  Time:  9.906  Rel. Train L2 Loss :  0.07088324071963628  Rel. Test L2 Loss :  0.03899589389562607  Test L2 Loss :  0.017427618503570556  inv_L_scale:  [0.633]
Epoch :  221  Time:  10.044  Rel. Train L2 Loss :  0.06864155326286951  Rel. Test L2 Loss :  0.04115515612065792  Test L2 Loss :  0.018491239696741105  inv_L_scale:  [0.646]
Epoch :  222  Time:  9.963  Rel. Train L2 Loss :  0.06560395451386769  Rel. Test L2 Loss :  0.04243644642333189  Test L2 Loss :  0.019094347457091012  inv_L_scale:  [0.652]
Epoch :  223  Time:  9.918  Rel. Train L2 Loss :  0.0661328935821851  Rel. Test L2 Loss :  0.04170351016024749  Test L2 Loss :  0.018665460174282392  inv_L_scale:  [0.646]
Epoch :  224  Time:  10.65  Rel. Train L2 Loss :  0.06511051847537358  Rel. Test L2 Loss :  0.045718219876289365  Test L2 Loss :  0.020413095528880754  inv_L_scale:  [0.643]
Epoch :  225  Time:  9.9  Rel. Train L2 Loss :  0.06341942699750265  Rel. Test L2 Loss :  0.043647144362330435  Test L2 Loss :  0.019455995137492816  inv_L_scale:  [0.658]
Epoch :  226  Time:  9.896  Rel. Train L2 Loss :  0.06309658004840216  Rel. Test L2 Loss :  0.04072433369855086  Test L2 Loss :  0.0181747484455506  inv_L_scale:  [0.668]
Epoch :  227  Time:  9.902  Rel. Train L2 Loss :  0.06338569768269857  Rel. Test L2 Loss :  0.043747181644042336  Test L2 Loss :  0.019664362370967865  inv_L_scale:  [0.65]
Epoch :  228  Time:  9.917  Rel. Train L2 Loss :  0.06367434497674307  Rel. Test L2 Loss :  0.04262367196381092  Test L2 Loss :  0.019052416135867438  inv_L_scale:  [0.643]
Epoch :  229  Time:  9.907  Rel. Train L2 Loss :  0.061354360580444335  Rel. Test L2 Loss :  0.043562307357788085  Test L2 Loss :  0.019513280640045802  inv_L_scale:  [0.643]
Epoch :  230  Time:  9.875  Rel. Train L2 Loss :  0.06070212968190511  Rel. Test L2 Loss :  0.04391240174571673  Test L2 Loss :  0.01969522568086783  inv_L_scale:  [0.648]
Epoch :  231  Time:  9.911  Rel. Train L2 Loss :  0.061213255564371745  Rel. Test L2 Loss :  0.045415624603629114  Test L2 Loss :  0.020347716187437376  inv_L_scale:  [0.645]
Epoch :  232  Time:  9.909  Rel. Train L2 Loss :  0.05741830547650655  Rel. Test L2 Loss :  0.044178680280844373  Test L2 Loss :  0.019663444658120473  inv_L_scale:  [0.637]
Epoch :  233  Time:  9.876  Rel. Train L2 Loss :  0.06368911963701249  Rel. Test L2 Loss :  0.07054401869575183  Test L2 Loss :  0.031909627467393877  inv_L_scale:  [0.633]
Epoch :  234  Time:  9.875  Rel. Train L2 Loss :  0.062174495816230774  Rel. Test L2 Loss :  0.04534375583132108  Test L2 Loss :  0.020766589095195135  inv_L_scale:  [0.633]
Epoch :  235  Time:  9.919  Rel. Train L2 Loss :  0.06902446200450262  Rel. Test L2 Loss :  0.04766119621694088  Test L2 Loss :  0.021476484884818396  inv_L_scale:  [0.622]
Epoch :  236  Time:  9.898  Rel. Train L2 Loss :  0.06031863327821096  Rel. Test L2 Loss :  0.05368061989545822  Test L2 Loss :  0.02417019531130791  inv_L_scale:  [0.622]
Epoch :  237  Time:  10.031  Rel. Train L2 Loss :  0.05769636752208074  Rel. Test L2 Loss :  0.05281503587961197  Test L2 Loss :  0.023838947241504985  inv_L_scale:  [0.624]
Epoch :  238  Time:  10.088  Rel. Train L2 Loss :  0.05489222149054209  Rel. Test L2 Loss :  0.03957890490690867  Test L2 Loss :  0.017910504738489787  inv_L_scale:  [0.625]
Epoch :  239  Time:  10.027  Rel. Train L2 Loss :  0.05085276520252228  Rel. Test L2 Loss :  0.03988231698671977  Test L2 Loss :  0.017998472799857456  inv_L_scale:  [0.626]
Epoch :  240  Time:  12.74  Rel. Train L2 Loss :  0.05715397902329763  Rel. Test L2 Loss :  0.050043390293916065  Test L2 Loss :  0.022622298995653788  inv_L_scale:  [0.622]
Epoch :  241  Time:  10.215  Rel. Train L2 Loss :  0.0532446905374527  Rel. Test L2 Loss :  0.04287156189481418  Test L2 Loss :  0.01935284823179245  inv_L_scale:  [0.621]
Epoch :  242  Time:  9.974  Rel. Train L2 Loss :  0.04909692960977554  Rel. Test L2 Loss :  0.03998922690749168  Test L2 Loss :  0.018006590058406192  inv_L_scale:  [0.618]
Epoch :  243  Time:  10.466  Rel. Train L2 Loss :  0.04933524732788404  Rel. Test L2 Loss :  0.036523101379474  Test L2 Loss :  0.016418558731675147  inv_L_scale:  [0.617]
Epoch :  244  Time:  10.177  Rel. Train L2 Loss :  0.04941203468044599  Rel. Test L2 Loss :  0.03728962332010269  Test L2 Loss :  0.01686920570830504  inv_L_scale:  [0.61]
Epoch :  245  Time:  9.935  Rel. Train L2 Loss :  0.04445056899388631  Rel. Test L2 Loss :  0.0360188834865888  Test L2 Loss :  0.01622059757510821  inv_L_scale:  [0.614]
Epoch :  246  Time:  9.92  Rel. Train L2 Loss :  0.04483839892347654  Rel. Test L2 Loss :  0.03832329787313938  Test L2 Loss :  0.0171980678041776  inv_L_scale:  [0.605]
Epoch :  247  Time:  9.92  Rel. Train L2 Loss :  0.043607983271280924  Rel. Test L2 Loss :  0.03472958040734132  Test L2 Loss :  0.015687063311537106  inv_L_scale:  [0.605]
Epoch :  248  Time:  10.428  Rel. Train L2 Loss :  0.04251060868302981  Rel. Test L2 Loss :  0.03463870863119761  Test L2 Loss :  0.01558019034564495  inv_L_scale:  [0.606]
Epoch :  249  Time:  10.023  Rel. Train L2 Loss :  0.04065099441011747  Rel. Test L2 Loss :  0.03367592414220174  Test L2 Loss :  0.015148843191564083  inv_L_scale:  [0.608]
Epoch :  250  Time:  9.932  Rel. Train L2 Loss :  0.03944478319088618  Rel. Test L2 Loss :  0.03320564997692903  Test L2 Loss :  0.014960405342280865  inv_L_scale:  [0.609]
Epoch :  251  Time:  9.944  Rel. Train L2 Loss :  0.038666035771369935  Rel. Test L2 Loss :  0.03908965195218722  Test L2 Loss :  0.017627393479148545  inv_L_scale:  [0.61]
Epoch :  252  Time:  12.34  Rel. Train L2 Loss :  0.037732300182183584  Rel. Test L2 Loss :  0.02979595000545184  Test L2 Loss :  0.01340246746937434  inv_L_scale:  [0.61]
Epoch :  253  Time:  12.642  Rel. Train L2 Loss :  0.03698537216583888  Rel. Test L2 Loss :  0.02796914560099443  Test L2 Loss :  0.012614565814534823  inv_L_scale:  [0.612]
Epoch :  254  Time:  10.07  Rel. Train L2 Loss :  0.03675582697987557  Rel. Test L2 Loss :  0.02753175437450409  Test L2 Loss :  0.012458125688135624  inv_L_scale:  [0.613]
Epoch :  255  Time:  9.946  Rel. Train L2 Loss :  0.04203597575426102  Rel. Test L2 Loss :  0.03035306212802728  Test L2 Loss :  0.013689035971959432  inv_L_scale:  [0.633]
Epoch :  256  Time:  9.923  Rel. Train L2 Loss :  0.039439385334650676  Rel. Test L2 Loss :  0.02956787760059039  Test L2 Loss :  0.013448132462799548  inv_L_scale:  [0.645]
Epoch :  257  Time:  9.936  Rel. Train L2 Loss :  0.039186860154072446  Rel. Test L2 Loss :  0.027021771023670833  Test L2 Loss :  0.012228762979308765  inv_L_scale:  [0.643]
Epoch :  258  Time:  10.809  Rel. Train L2 Loss :  0.03601644263664881  Rel. Test L2 Loss :  0.02575346996386846  Test L2 Loss :  0.011675307316084703  inv_L_scale:  [0.642]
Epoch :  259  Time:  9.937  Rel. Train L2 Loss :  0.03462315378586451  Rel. Test L2 Loss :  0.025882934977610905  Test L2 Loss :  0.011687567867338657  inv_L_scale:  [0.645]
Epoch :  260  Time:  9.96  Rel. Train L2 Loss :  0.035577831824620564  Rel. Test L2 Loss :  0.024161942452192307  Test L2 Loss :  0.010981369949877261  inv_L_scale:  [0.644]
Epoch :  261  Time:  10.081  Rel. Train L2 Loss :  0.0341395601828893  Rel. Test L2 Loss :  0.024025758504867555  Test L2 Loss :  0.010940089275439581  inv_L_scale:  [0.641]
Epoch :  262  Time:  10.013  Rel. Train L2 Loss :  0.030921748369932174  Rel. Test L2 Loss :  0.0242990264048179  Test L2 Loss :  0.011096607347329458  inv_L_scale:  [0.64]
Epoch :  263  Time:  10.622  Rel. Train L2 Loss :  0.029719581643740337  Rel. Test L2 Loss :  0.023611619099974633  Test L2 Loss :  0.010757468566298485  inv_L_scale:  [0.636]
Epoch :  264  Time:  10.088  Rel. Train L2 Loss :  0.029279479205608368  Rel. Test L2 Loss :  0.02528328577677409  Test L2 Loss :  0.011456445592145125  inv_L_scale:  [0.638]
Epoch :  265  Time:  9.917  Rel. Train L2 Loss :  0.028642810593048733  Rel. Test L2 Loss :  0.024882518214484055  Test L2 Loss :  0.011341941095888614  inv_L_scale:  [0.63]
Epoch :  266  Time:  10.006  Rel. Train L2 Loss :  0.02952564811706543  Rel. Test L2 Loss :  0.02537376177807649  Test L2 Loss :  0.011417378162344297  inv_L_scale:  [0.632]
Epoch :  267  Time:  10.005  Rel. Train L2 Loss :  0.027766802956660588  Rel. Test L2 Loss :  0.024502050826946894  Test L2 Loss :  0.011087520383298397  inv_L_scale:  [0.632]
Epoch :  268  Time:  9.904  Rel. Train L2 Loss :  0.026750721295674643  Rel. Test L2 Loss :  0.023558134858806926  Test L2 Loss :  0.010741436183452606  inv_L_scale:  [0.63]
Epoch :  269  Time:  9.913  Rel. Train L2 Loss :  0.02661669798195362  Rel. Test L2 Loss :  0.022392688058316707  Test L2 Loss :  0.010093774708608786  inv_L_scale:  [0.633]
Epoch :  270  Time:  9.959  Rel. Train L2 Loss :  0.025343568657835325  Rel. Test L2 Loss :  0.023380097672343253  Test L2 Loss :  0.010541333916286628  inv_L_scale:  [0.633]
Epoch :  271  Time:  10.005  Rel. Train L2 Loss :  0.025382886916399002  Rel. Test L2 Loss :  0.023590887884298962  Test L2 Loss :  0.010640543873111407  inv_L_scale:  [0.629]
Epoch :  272  Time:  11.661  Rel. Train L2 Loss :  0.02487455486257871  Rel. Test L2 Loss :  0.022567627082268397  Test L2 Loss :  0.010197856488327186  inv_L_scale:  [0.628]
Epoch :  273  Time:  10.039  Rel. Train L2 Loss :  0.023697656626502674  Rel. Test L2 Loss :  0.022639814739425976  Test L2 Loss :  0.010285432189702988  inv_L_scale:  [0.633]
Epoch :  274  Time:  9.956  Rel. Train L2 Loss :  0.024106255451838175  Rel. Test L2 Loss :  0.021508452370762824  Test L2 Loss :  0.009752303188045819  inv_L_scale:  [0.639]
Epoch :  275  Time:  9.934  Rel. Train L2 Loss :  0.0234116600304842  Rel. Test L2 Loss :  0.02205341407408317  Test L2 Loss :  0.009951788323620954  inv_L_scale:  [0.639]
Epoch :  276  Time:  9.904  Rel. Train L2 Loss :  0.02458213149011135  Rel. Test L2 Loss :  0.02152711826066176  Test L2 Loss :  0.009790380348761877  inv_L_scale:  [0.637]
Epoch :  277  Time:  9.956  Rel. Train L2 Loss :  0.02911757242679596  Rel. Test L2 Loss :  0.02289969633022944  Test L2 Loss :  0.010360919535160065  inv_L_scale:  [0.619]
Epoch :  278  Time:  10.063  Rel. Train L2 Loss :  0.025787152553598085  Rel. Test L2 Loss :  0.02086460720747709  Test L2 Loss :  0.00944938112050295  inv_L_scale:  [0.621]
Epoch :  279  Time:  9.888  Rel. Train L2 Loss :  0.023831005920966465  Rel. Test L2 Loss :  0.019947676981488863  Test L2 Loss :  0.009048292276759943  inv_L_scale:  [0.621]
Epoch :  280  Time:  9.911  Rel. Train L2 Loss :  0.021513359035054844  Rel. Test L2 Loss :  0.01989306273559729  Test L2 Loss :  0.009042160498599211  inv_L_scale:  [0.623]
Epoch :  281  Time:  9.873  Rel. Train L2 Loss :  0.020987703651189803  Rel. Test L2 Loss :  0.018695009474953016  Test L2 Loss :  0.008495793802042802  inv_L_scale:  [0.622]
Epoch :  282  Time:  9.898  Rel. Train L2 Loss :  0.019834318627913794  Rel. Test L2 Loss :  0.018412009527285892  Test L2 Loss :  0.008384296720226605  inv_L_scale:  [0.622]
Epoch :  283  Time:  9.911  Rel. Train L2 Loss :  0.01953295747935772  Rel. Test L2 Loss :  0.018643651915093262  Test L2 Loss :  0.008436491365234057  inv_L_scale:  [0.622]
Epoch :  284  Time:  9.904  Rel. Train L2 Loss :  0.02633515925705433  Rel. Test L2 Loss :  0.019138912955919903  Test L2 Loss :  0.008804628898700078  inv_L_scale:  [0.646]
Epoch :  285  Time:  9.89  Rel. Train L2 Loss :  0.023800322661797206  Rel. Test L2 Loss :  0.017946535609662532  Test L2 Loss :  0.008233775049448014  inv_L_scale:  [0.645]
Epoch :  286  Time:  9.918  Rel. Train L2 Loss :  0.021483373219768207  Rel. Test L2 Loss :  0.01750689070671797  Test L2 Loss :  0.00802602137128512  inv_L_scale:  [0.645]
Epoch :  287  Time:  9.914  Rel. Train L2 Loss :  0.01992479932308197  Rel. Test L2 Loss :  0.018196338738004365  Test L2 Loss :  0.008302279816319546  inv_L_scale:  [0.645]
Epoch :  288  Time:  9.887  Rel. Train L2 Loss :  0.01960948831339677  Rel. Test L2 Loss :  0.023743210062384605  Test L2 Loss :  0.010909297751883667  inv_L_scale:  [0.644]
Epoch :  289  Time:  9.914  Rel. Train L2 Loss :  0.020077534005045892  Rel. Test L2 Loss :  0.017072527731458346  Test L2 Loss :  0.007843311969190836  inv_L_scale:  [0.644]
Epoch :  290  Time:  9.905  Rel. Train L2 Loss :  0.018579324026902516  Rel. Test L2 Loss :  0.016123078018426894  Test L2 Loss :  0.007341985354820888  inv_L_scale:  [0.645]
Epoch :  291  Time:  9.871  Rel. Train L2 Loss :  0.018102532039086024  Rel. Test L2 Loss :  0.021285185950497786  Test L2 Loss :  0.009620240467290084  inv_L_scale:  [0.645]
Epoch :  292  Time:  9.874  Rel. Train L2 Loss :  0.019386816774805388  Rel. Test L2 Loss :  0.01668700101474921  Test L2 Loss :  0.007553802784532309  inv_L_scale:  [0.645]
Epoch :  293  Time:  9.91  Rel. Train L2 Loss :  0.016994901612401008  Rel. Test L2 Loss :  0.01649975354472796  Test L2 Loss :  0.00755634494125843  inv_L_scale:  [0.644]
Epoch :  294  Time:  9.935  Rel. Train L2 Loss :  0.01661602219939232  Rel. Test L2 Loss :  0.01611452008287112  Test L2 Loss :  0.007312309655050437  inv_L_scale:  [0.644]
Epoch :  295  Time:  9.896  Rel. Train L2 Loss :  0.01638455286125342  Rel. Test L2 Loss :  0.01624912701547146  Test L2 Loss :  0.007413001687576373  inv_L_scale:  [0.645]
Epoch :  296  Time:  9.894  Rel. Train L2 Loss :  0.015995852400859198  Rel. Test L2 Loss :  0.016540477549036346  Test L2 Loss :  0.007555995117872954  inv_L_scale:  [0.644]
Epoch :  297  Time:  9.927  Rel. Train L2 Loss :  0.015739567577838898  Rel. Test L2 Loss :  0.017500143150488534  Test L2 Loss :  0.008013809931774933  inv_L_scale:  [0.644]
Epoch :  298  Time:  9.933  Rel. Train L2 Loss :  0.015477644046147664  Rel. Test L2 Loss :  0.015293936443825562  Test L2 Loss :  0.007023139658073585  inv_L_scale:  [0.645]
Epoch :  299  Time:  9.87  Rel. Train L2 Loss :  0.015188610593477885  Rel. Test L2 Loss :  0.015585337740679581  Test L2 Loss :  0.007076554422577222  inv_L_scale:  [0.643]
Epoch :  300  Time:  9.885  Rel. Train L2 Loss :  0.014825023278594017  Rel. Test L2 Loss :  0.017723047733306886  Test L2 Loss :  0.008085224231084188  inv_L_scale:  [0.642]
Epoch :  301  Time:  9.876  Rel. Train L2 Loss :  0.016320577482382456  Rel. Test L2 Loss :  0.024314665098985035  Test L2 Loss :  0.01098680750777324  inv_L_scale:  [0.642]
Epoch :  302  Time:  9.897  Rel. Train L2 Loss :  0.01774571781853835  Rel. Test L2 Loss :  0.01526720516383648  Test L2 Loss :  0.006981432884931565  inv_L_scale:  [0.641]
Epoch :  303  Time:  9.913  Rel. Train L2 Loss :  0.015050629377365113  Rel. Test L2 Loss :  0.016294549939533075  Test L2 Loss :  0.007459182602663835  inv_L_scale:  [0.642]
Epoch :  304  Time:  9.877  Rel. Train L2 Loss :  0.014360272337992986  Rel. Test L2 Loss :  0.015119969720641772  Test L2 Loss :  0.00695022314786911  inv_L_scale:  [0.64]
Epoch :  305  Time:  9.922  Rel. Train L2 Loss :  0.014574379277726014  Rel. Test L2 Loss :  0.01482845729837815  Test L2 Loss :  0.006776622893909613  inv_L_scale:  [0.641]
Epoch :  306  Time:  9.967  Rel. Train L2 Loss :  0.013773864656686783  Rel. Test L2 Loss :  0.014494920894503594  Test L2 Loss :  0.00662769777700305  inv_L_scale:  [0.643]
Epoch :  307  Time:  9.926  Rel. Train L2 Loss :  0.014025003870328267  Rel. Test L2 Loss :  0.013904363935192426  Test L2 Loss :  0.006381937811772029  inv_L_scale:  [0.643]
Epoch :  308  Time:  9.91  Rel. Train L2 Loss :  0.01329899958272775  Rel. Test L2 Loss :  0.013921420338253181  Test L2 Loss :  0.0063804620007673896  inv_L_scale:  [0.643]
Epoch :  309  Time:  9.922  Rel. Train L2 Loss :  0.013345496381322543  Rel. Test L2 Loss :  0.013592850069204966  Test L2 Loss :  0.00628313772380352  inv_L_scale:  [0.643]
Epoch :  310  Time:  9.944  Rel. Train L2 Loss :  0.01325039181113243  Rel. Test L2 Loss :  0.013275118706127008  Test L2 Loss :  0.006147411316633224  inv_L_scale:  [0.644]
Epoch :  311  Time:  9.917  Rel. Train L2 Loss :  0.012786254584789276  Rel. Test L2 Loss :  0.013392155232528846  Test L2 Loss :  0.006159359328448772  inv_L_scale:  [0.644]
Epoch :  312  Time:  9.935  Rel. Train L2 Loss :  0.013666143486897151  Rel. Test L2 Loss :  0.013485940918326379  Test L2 Loss :  0.006172528521468242  inv_L_scale:  [0.648]
Epoch :  313  Time:  9.971  Rel. Train L2 Loss :  0.013226025571425756  Rel. Test L2 Loss :  0.012745769135653973  Test L2 Loss :  0.005865188129246235  inv_L_scale:  [0.648]
Epoch :  314  Time:  10.221  Rel. Train L2 Loss :  0.013097650781273841  Rel. Test L2 Loss :  0.012271747613946596  Test L2 Loss :  0.005638493038713932  inv_L_scale:  [0.647]
Epoch :  315  Time:  9.911  Rel. Train L2 Loss :  0.012606615188221136  Rel. Test L2 Loss :  0.012384331598877907  Test L2 Loss :  0.005688880955179532  inv_L_scale:  [0.646]
Epoch :  316  Time:  9.903  Rel. Train L2 Loss :  0.01309518734117349  Rel. Test L2 Loss :  0.013372812742988268  Test L2 Loss :  0.00613645672177275  inv_L_scale:  [0.646]
Epoch :  317  Time:  9.888  Rel. Train L2 Loss :  0.012135435983538627  Rel. Test L2 Loss :  0.012808374377588432  Test L2 Loss :  0.00587016220514973  inv_L_scale:  [0.646]
Epoch :  318  Time:  9.886  Rel. Train L2 Loss :  0.01254173767566681  Rel. Test L2 Loss :  0.012107176010807356  Test L2 Loss :  0.00554532295713822  inv_L_scale:  [0.647]
Epoch :  319  Time:  12.748  Rel. Train L2 Loss :  0.011894102466603121  Rel. Test L2 Loss :  0.011761182596286139  Test L2 Loss :  0.005371686952809492  inv_L_scale:  [0.646]
Epoch :  320  Time:  9.985  Rel. Train L2 Loss :  0.011937075888117155  Rel. Test L2 Loss :  0.01134208295494318  Test L2 Loss :  0.005241517840574185  inv_L_scale:  [0.646]
Epoch :  321  Time:  9.977  Rel. Train L2 Loss :  0.011781663790345192  Rel. Test L2 Loss :  0.01175868060439825  Test L2 Loss :  0.005435682752480109  inv_L_scale:  [0.646]
Epoch :  322  Time:  9.962  Rel. Train L2 Loss :  0.011245079398155212  Rel. Test L2 Loss :  0.011450816864768664  Test L2 Loss :  0.005303782547513644  inv_L_scale:  [0.647]
Epoch :  323  Time:  9.906  Rel. Train L2 Loss :  0.011285492214063803  Rel. Test L2 Loss :  0.011769884762664636  Test L2 Loss :  0.005434298198670149  inv_L_scale:  [0.647]
Epoch :  324  Time:  9.901  Rel. Train L2 Loss :  0.011291963880260785  Rel. Test L2 Loss :  0.011573662720620633  Test L2 Loss :  0.005325906599561374  inv_L_scale:  [0.648]
Epoch :  325  Time:  9.909  Rel. Train L2 Loss :  0.011554515299697718  Rel. Test L2 Loss :  0.011447475515305996  Test L2 Loss :  0.005286391091843446  inv_L_scale:  [0.648]
Epoch :  326  Time:  9.926  Rel. Train L2 Loss :  0.011986578313012917  Rel. Test L2 Loss :  0.01122597341115276  Test L2 Loss :  0.005121156771977742  inv_L_scale:  [0.649]
Epoch :  327  Time:  9.92  Rel. Train L2 Loss :  0.011115255805353323  Rel. Test L2 Loss :  0.011998622063547373  Test L2 Loss :  0.0055215892444054285  inv_L_scale:  [0.651]
Epoch :  328  Time:  9.917  Rel. Train L2 Loss :  0.011960058155159155  Rel. Test L2 Loss :  0.011250216004749139  Test L2 Loss :  0.005205811702956756  inv_L_scale:  [0.643]
Epoch :  329  Time:  9.927  Rel. Train L2 Loss :  0.011777044927080472  Rel. Test L2 Loss :  0.011577656554679076  Test L2 Loss :  0.005364299571762482  inv_L_scale:  [0.646]
Epoch :  330  Time:  10.054  Rel. Train L2 Loss :  0.011075625864168008  Rel. Test L2 Loss :  0.012264552482714255  Test L2 Loss :  0.005681296295175949  inv_L_scale:  [0.641]
Epoch :  331  Time:  9.924  Rel. Train L2 Loss :  0.01151433048894008  Rel. Test L2 Loss :  0.012088266437252363  Test L2 Loss :  0.005603996676703294  inv_L_scale:  [0.643]
Epoch :  332  Time:  9.905  Rel. Train L2 Loss :  0.010751684993505478  Rel. Test L2 Loss :  0.011455915433665117  Test L2 Loss :  0.005356257787595193  inv_L_scale:  [0.643]
Epoch :  333  Time:  9.927  Rel. Train L2 Loss :  0.010420187550286453  Rel. Test L2 Loss :  0.011260121253629525  Test L2 Loss :  0.005224781483411789  inv_L_scale:  [0.643]
Epoch :  334  Time:  9.946  Rel. Train L2 Loss :  0.010269090794026851  Rel. Test L2 Loss :  0.011649891672035059  Test L2 Loss :  0.0053975875986119115  inv_L_scale:  [0.644]
Epoch :  335  Time:  9.969  Rel. Train L2 Loss :  0.009796749783058962  Rel. Test L2 Loss :  0.011277077173193296  Test L2 Loss :  0.0052228578800956405  inv_L_scale:  [0.643]
Epoch :  336  Time:  10.061  Rel. Train L2 Loss :  0.009511034414172172  Rel. Test L2 Loss :  0.011245620356251797  Test L2 Loss :  0.005234609842300415  inv_L_scale:  [0.644]
Epoch :  337  Time:  9.925  Rel. Train L2 Loss :  0.009825609271725018  Rel. Test L2 Loss :  0.010820234566926957  Test L2 Loss :  0.00504450752089421  inv_L_scale:  [0.644]
Epoch :  338  Time:  9.957  Rel. Train L2 Loss :  0.009859135640164217  Rel. Test L2 Loss :  0.011115958243608474  Test L2 Loss :  0.005157168724884589  inv_L_scale:  [0.643]
Epoch :  339  Time:  9.938  Rel. Train L2 Loss :  0.009617612682282924  Rel. Test L2 Loss :  0.010999954181412856  Test L2 Loss :  0.00510841970021526  inv_L_scale:  [0.642]
Epoch :  340  Time:  10.025  Rel. Train L2 Loss :  0.009706494472920895  Rel. Test L2 Loss :  0.010411145326991876  Test L2 Loss :  0.0048193729389458895  inv_L_scale:  [0.642]
Epoch :  341  Time:  9.901  Rel. Train L2 Loss :  0.009337937412162621  Rel. Test L2 Loss :  0.010373519038160642  Test L2 Loss :  0.004805649928748608  inv_L_scale:  [0.642]
Epoch :  342  Time:  10.051  Rel. Train L2 Loss :  0.009581849676867326  Rel. Test L2 Loss :  0.010951545772453148  Test L2 Loss :  0.005044663051764171  inv_L_scale:  [0.643]
Epoch :  343  Time:  9.932  Rel. Train L2 Loss :  0.00976559886833032  Rel. Test L2 Loss :  0.010866789581875006  Test L2 Loss :  0.005064918864518404  inv_L_scale:  [0.639]
Epoch :  344  Time:  9.934  Rel. Train L2 Loss :  0.009260939414302508  Rel. Test L2 Loss :  0.01023520172884067  Test L2 Loss :  0.0047570129670202735  inv_L_scale:  [0.641]
Epoch :  345  Time:  9.929  Rel. Train L2 Loss :  0.008948045447468758  Rel. Test L2 Loss :  0.010247773366669814  Test L2 Loss :  0.004813544594993194  inv_L_scale:  [0.642]
Epoch :  346  Time:  9.881  Rel. Train L2 Loss :  0.008943551629781723  Rel. Test L2 Loss :  0.009836622991909584  Test L2 Loss :  0.004533960111439228  inv_L_scale:  [0.644]
Epoch :  347  Time:  9.888  Rel. Train L2 Loss :  0.008853844600419204  Rel. Test L2 Loss :  0.010214156322181225  Test L2 Loss :  0.0047133930027484896  inv_L_scale:  [0.642]
Epoch :  348  Time:  9.902  Rel. Train L2 Loss :  0.008870320635537306  Rel. Test L2 Loss :  0.010445798095315696  Test L2 Loss :  0.0048579594865441325  inv_L_scale:  [0.642]
Epoch :  349  Time:  9.895  Rel. Train L2 Loss :  0.009025562291344007  Rel. Test L2 Loss :  0.010252360552549362  Test L2 Loss :  0.0047845782712101935  inv_L_scale:  [0.642]
Epoch :  350  Time:  9.937  Rel. Train L2 Loss :  0.009543095191319784  Rel. Test L2 Loss :  0.010192980611075958  Test L2 Loss :  0.004771744428823391  inv_L_scale:  [0.64]
Epoch :  351  Time:  9.901  Rel. Train L2 Loss :  0.008281707147757212  Rel. Test L2 Loss :  0.010122019164264202  Test L2 Loss :  0.00470150887966156  inv_L_scale:  [0.641]
Epoch :  352  Time:  9.875  Rel. Train L2 Loss :  0.00812591486175855  Rel. Test L2 Loss :  0.009932359798500935  Test L2 Loss :  0.004600297827273607  inv_L_scale:  [0.641]
Epoch :  353  Time:  9.888  Rel. Train L2 Loss :  0.008411674432456493  Rel. Test L2 Loss :  0.009900015257298946  Test L2 Loss :  0.0045892181371649104  inv_L_scale:  [0.641]
Epoch :  354  Time:  9.877  Rel. Train L2 Loss :  0.008131458769241968  Rel. Test L2 Loss :  0.009636166666944822  Test L2 Loss :  0.004485293158019582  inv_L_scale:  [0.641]
Epoch :  355  Time:  9.882  Rel. Train L2 Loss :  0.0081338929956158  Rel. Test L2 Loss :  0.009597200434654951  Test L2 Loss :  0.0044299854710698125  inv_L_scale:  [0.643]
Epoch :  356  Time:  9.873  Rel. Train L2 Loss :  0.007944172874093056  Rel. Test L2 Loss :  0.009437106239298979  Test L2 Loss :  0.004366044563551744  inv_L_scale:  [0.642]
Epoch :  357  Time:  9.89  Rel. Train L2 Loss :  0.0078031175062060355  Rel. Test L2 Loss :  0.009692907830079396  Test L2 Loss :  0.004506468723217646  inv_L_scale:  [0.641]
Epoch :  358  Time:  9.921  Rel. Train L2 Loss :  0.007690804245571296  Rel. Test L2 Loss :  0.009323284917821487  Test L2 Loss :  0.00433672468488415  inv_L_scale:  [0.642]
Epoch :  359  Time:  9.908  Rel. Train L2 Loss :  0.007483905923863252  Rel. Test L2 Loss :  0.009390242354323466  Test L2 Loss :  0.004355232827365398  inv_L_scale:  [0.642]
Epoch :  360  Time:  9.902  Rel. Train L2 Loss :  0.007453906334936619  Rel. Test L2 Loss :  0.009229728387047846  Test L2 Loss :  0.004286691683034102  inv_L_scale:  [0.641]
Epoch :  361  Time:  9.881  Rel. Train L2 Loss :  0.007511708463231723  Rel. Test L2 Loss :  0.009050425322105487  Test L2 Loss :  0.004210355716447035  inv_L_scale:  [0.641]
Epoch :  362  Time:  9.903  Rel. Train L2 Loss :  0.008434400327503682  Rel. Test L2 Loss :  0.008844420686364174  Test L2 Loss :  0.004111815492312113  inv_L_scale:  [0.642]
Epoch :  363  Time:  9.9  Rel. Train L2 Loss :  0.007572510441144307  Rel. Test L2 Loss :  0.00899708786358436  Test L2 Loss :  0.004187071823204557  inv_L_scale:  [0.642]
Epoch :  364  Time:  9.914  Rel. Train L2 Loss :  0.007498602812488874  Rel. Test L2 Loss :  0.00982914445300897  Test L2 Loss :  0.004571782313287258  inv_L_scale:  [0.643]
Epoch :  365  Time:  9.909  Rel. Train L2 Loss :  0.006823876741031806  Rel. Test L2 Loss :  0.009431281574070454  Test L2 Loss :  0.0043849240181346736  inv_L_scale:  [0.642]
Epoch :  366  Time:  9.884  Rel. Train L2 Loss :  0.007024760728081067  Rel. Test L2 Loss :  0.0091152190665404  Test L2 Loss :  0.004225505407278737  inv_L_scale:  [0.642]
Epoch :  367  Time:  9.914  Rel. Train L2 Loss :  0.007081132012108962  Rel. Test L2 Loss :  0.009323384426534177  Test L2 Loss :  0.0043133502236257  inv_L_scale:  [0.642]
Epoch :  368  Time:  9.934  Rel. Train L2 Loss :  0.007141201173265775  Rel. Test L2 Loss :  0.009115976647784312  Test L2 Loss :  0.004244356335451205  inv_L_scale:  [0.64]
Epoch :  369  Time:  9.897  Rel. Train L2 Loss :  0.007145981249709924  Rel. Test L2 Loss :  0.009200707481553157  Test L2 Loss :  0.00427108115516603  inv_L_scale:  [0.641]
Epoch :  370  Time:  9.981  Rel. Train L2 Loss :  0.006821922873457273  Rel. Test L2 Loss :  0.008926855189104875  Test L2 Loss :  0.004141696371758977  inv_L_scale:  [0.641]
Epoch :  371  Time:  10.199  Rel. Train L2 Loss :  0.006705884198347728  Rel. Test L2 Loss :  0.009103346075862646  Test L2 Loss :  0.004255068978915612  inv_L_scale:  [0.642]
Epoch :  372  Time:  12.136  Rel. Train L2 Loss :  0.006718772889425358  Rel. Test L2 Loss :  0.008848326553901036  Test L2 Loss :  0.004088087972874443  inv_L_scale:  [0.642]
Epoch :  373  Time:  10.041  Rel. Train L2 Loss :  0.006645068198442459  Rel. Test L2 Loss :  0.009146445194880167  Test L2 Loss :  0.004257567419360082  inv_L_scale:  [0.642]
Epoch :  374  Time:  10.003  Rel. Train L2 Loss :  0.00669397580375274  Rel. Test L2 Loss :  0.00883287077769637  Test L2 Loss :  0.004106113407760859  inv_L_scale:  [0.643]
Epoch :  375  Time:  9.962  Rel. Train L2 Loss :  0.0063072685251633325  Rel. Test L2 Loss :  0.00919738154237469  Test L2 Loss :  0.004272424209242066  inv_L_scale:  [0.642]
Epoch :  376  Time:  9.951  Rel. Train L2 Loss :  0.007046118962268035  Rel. Test L2 Loss :  0.00897012093414863  Test L2 Loss :  0.004176927624891202  inv_L_scale:  [0.641]
Epoch :  377  Time:  9.972  Rel. Train L2 Loss :  0.00653203113997976  Rel. Test L2 Loss :  0.008715899648765723  Test L2 Loss :  0.004055792180200418  inv_L_scale:  [0.641]
Epoch :  378  Time:  9.926  Rel. Train L2 Loss :  0.006407101524372896  Rel. Test L2 Loss :  0.00841357059776783  Test L2 Loss :  0.003905879016965628  inv_L_scale:  [0.642]
Epoch :  379  Time:  9.943  Rel. Train L2 Loss :  0.006034633134802183  Rel. Test L2 Loss :  0.008653560802340508  Test L2 Loss :  0.004032404397924741  inv_L_scale:  [0.642]
Epoch :  380  Time:  9.942  Rel. Train L2 Loss :  0.006314879968762397  Rel. Test L2 Loss :  0.008760573000957568  Test L2 Loss :  0.004067790163680911  inv_L_scale:  [0.642]
Epoch :  381  Time:  9.956  Rel. Train L2 Loss :  0.006211556913952033  Rel. Test L2 Loss :  0.008849428662409385  Test L2 Loss :  0.0041130170288185275  inv_L_scale:  [0.642]
Epoch :  382  Time:  10.022  Rel. Train L2 Loss :  0.00606449710826079  Rel. Test L2 Loss :  0.008612035438418389  Test L2 Loss :  0.004016182782749335  inv_L_scale:  [0.641]
Epoch :  383  Time:  9.934  Rel. Train L2 Loss :  0.006093576986342669  Rel. Test L2 Loss :  0.008572539283583562  Test L2 Loss :  0.003991770129650831  inv_L_scale:  [0.641]
Epoch :  384  Time:  10.014  Rel. Train L2 Loss :  0.005898227756222089  Rel. Test L2 Loss :  0.008932756359378497  Test L2 Loss :  0.004176211059093476  inv_L_scale:  [0.642]
Epoch :  385  Time:  9.929  Rel. Train L2 Loss :  0.005990611010541519  Rel. Test L2 Loss :  0.008586278582612673  Test L2 Loss :  0.004032039828598499  inv_L_scale:  [0.641]
Epoch :  386  Time:  9.968  Rel. Train L2 Loss :  0.005810347716013591  Rel. Test L2 Loss :  0.008576376258085171  Test L2 Loss :  0.003994950223714113  inv_L_scale:  [0.642]
Epoch :  387  Time:  9.91  Rel. Train L2 Loss :  0.0057482507651050885  Rel. Test L2 Loss :  0.008512381271769603  Test L2 Loss :  0.003993161329999566  inv_L_scale:  [0.642]
Epoch :  388  Time:  9.912  Rel. Train L2 Loss :  0.005761825770139694  Rel. Test L2 Loss :  0.008492073472589255  Test L2 Loss :  0.003959442224974434  inv_L_scale:  [0.642]
Epoch :  389  Time:  9.941  Rel. Train L2 Loss :  0.005685245901346206  Rel. Test L2 Loss :  0.008308709847430389  Test L2 Loss :  0.0038819317954281968  inv_L_scale:  [0.642]
Epoch :  390  Time:  9.925  Rel. Train L2 Loss :  0.005575139886389176  Rel. Test L2 Loss :  0.008476014770567418  Test L2 Loss :  0.003962704393391808  inv_L_scale:  [0.641]
Epoch :  391  Time:  10.154  Rel. Train L2 Loss :  0.005511643537630637  Rel. Test L2 Loss :  0.008480232196549574  Test L2 Loss :  0.003974653404826919  inv_L_scale:  [0.642]
Epoch :  392  Time:  10.002  Rel. Train L2 Loss :  0.0052869007562597594  Rel. Test L2 Loss :  0.008542474675923586  Test L2 Loss :  0.003984352617214124  inv_L_scale:  [0.642]
Epoch :  393  Time:  10.085  Rel. Train L2 Loss :  0.005434132232020298  Rel. Test L2 Loss :  0.008446681766460339  Test L2 Loss :  0.003941857169071833  inv_L_scale:  [0.642]
Epoch :  394  Time:  10.199  Rel. Train L2 Loss :  0.005296932683636745  Rel. Test L2 Loss :  0.008360218598196904  Test L2 Loss :  0.0039058899662146964  inv_L_scale:  [0.642]
Epoch :  395  Time:  10.009  Rel. Train L2 Loss :  0.005287964209914208  Rel. Test L2 Loss :  0.008339637039850155  Test L2 Loss :  0.0038953974563628434  inv_L_scale:  [0.641]
Epoch :  396  Time:  9.931  Rel. Train L2 Loss :  0.0053355916192134225  Rel. Test L2 Loss :  0.00850794704630971  Test L2 Loss :  0.003983058619002501  inv_L_scale:  [0.642]
Epoch :  397  Time:  9.951  Rel. Train L2 Loss :  0.005254500808815161  Rel. Test L2 Loss :  0.008595975823700428  Test L2 Loss :  0.004018308163310091  inv_L_scale:  [0.642]
Epoch :  398  Time:  10.158  Rel. Train L2 Loss :  0.004915252527842919  Rel. Test L2 Loss :  0.008453747468690077  Test L2 Loss :  0.00396466137530903  inv_L_scale:  [0.642]
Epoch :  399  Time:  9.922  Rel. Train L2 Loss :  0.004990140371024608  Rel. Test L2 Loss :  0.008504391964524984  Test L2 Loss :  0.003982441133509079  inv_L_scale:  [0.642]
Epoch :  400  Time:  9.951  Rel. Train L2 Loss :  0.00503535417219003  Rel. Test L2 Loss :  0.008426571302115916  Test L2 Loss :  0.003948192466050386  inv_L_scale:  [0.642]
Epoch :  401  Time:  9.925  Rel. Train L2 Loss :  0.004984168918182453  Rel. Test L2 Loss :  0.008358842581510545  Test L2 Loss :  0.003924610059087475  inv_L_scale:  [0.642]
Epoch :  402  Time:  9.947  Rel. Train L2 Loss :  0.004951842108120521  Rel. Test L2 Loss :  0.00836440914000074  Test L2 Loss :  0.003922969847917557  inv_L_scale:  [0.642]
Epoch :  403  Time:  9.961  Rel. Train L2 Loss :  0.004706612980614106  Rel. Test L2 Loss :  0.00825341410934925  Test L2 Loss :  0.003873193108787139  inv_L_scale:  [0.642]
Epoch :  404  Time:  10.096  Rel. Train L2 Loss :  0.004821689945956071  Rel. Test L2 Loss :  0.008245005545516809  Test L2 Loss :  0.0038651109238465628  inv_L_scale:  [0.642]
Epoch :  405  Time:  11.336  Rel. Train L2 Loss :  0.004755477756261826  Rel. Test L2 Loss :  0.008152560982853174  Test L2 Loss :  0.0038185407718022662  inv_L_scale:  [0.642]
Epoch :  406  Time:  10.081  Rel. Train L2 Loss :  0.004650779337932666  Rel. Test L2 Loss :  0.008292232304811478  Test L2 Loss :  0.003891961301366488  inv_L_scale:  [0.642]
Epoch :  407  Time:  10.057  Rel. Train L2 Loss :  0.004558245987941821  Rel. Test L2 Loss :  0.00829379566013813  Test L2 Loss :  0.003886453090235591  inv_L_scale:  [0.642]
Epoch :  408  Time:  10.028  Rel. Train L2 Loss :  0.004537218067795038  Rel. Test L2 Loss :  0.008312415704131127  Test L2 Loss :  0.00390039068646729  inv_L_scale:  [0.642]
Epoch :  409  Time:  10.066  Rel. Train L2 Loss :  0.004581156541903814  Rel. Test L2 Loss :  0.008212532649437587  Test L2 Loss :  0.003861617154131333  inv_L_scale:  [0.642]
Epoch :  410  Time:  10.148  Rel. Train L2 Loss :  0.004448447495698928  Rel. Test L2 Loss :  0.008064114296187957  Test L2 Loss :  0.003792478662605087  inv_L_scale:  [0.642]
Epoch :  411  Time:  10.231  Rel. Train L2 Loss :  0.0044832257653276125  Rel. Test L2 Loss :  0.008180433834592502  Test L2 Loss :  0.003839176126445333  inv_L_scale:  [0.642]
Epoch :  412  Time:  10.1  Rel. Train L2 Loss :  0.0045284226896862186  Rel. Test L2 Loss :  0.008134237956255674  Test L2 Loss :  0.00381499701179564  inv_L_scale:  [0.642]
Epoch :  413  Time:  10.195  Rel. Train L2 Loss :  0.0045207519394656025  Rel. Test L2 Loss :  0.008029990823318562  Test L2 Loss :  0.0037654526624828575  inv_L_scale:  [0.642]
Epoch :  414  Time:  10.159  Rel. Train L2 Loss :  0.004451131983349721  Rel. Test L2 Loss :  0.008028849537173907  Test L2 Loss :  0.003769067501028379  inv_L_scale:  [0.642]
Epoch :  415  Time:  10.255  Rel. Train L2 Loss :  0.004267177391797304  Rel. Test L2 Loss :  0.008141513795902331  Test L2 Loss :  0.0038241837670405705  inv_L_scale:  [0.642]
Epoch :  416  Time:  10.066  Rel. Train L2 Loss :  0.004225850028296312  Rel. Test L2 Loss :  0.008043266801784436  Test L2 Loss :  0.0037760197278112174  inv_L_scale:  [0.642]
Epoch :  417  Time:  10.095  Rel. Train L2 Loss :  0.004325820221255223  Rel. Test L2 Loss :  0.008134531558801731  Test L2 Loss :  0.0038244843296706675  inv_L_scale:  [0.642]
Epoch :  418  Time:  10.151  Rel. Train L2 Loss :  0.004355507766207059  Rel. Test L2 Loss :  0.00804868488262097  Test L2 Loss :  0.0037825851825376354  inv_L_scale:  [0.642]
Epoch :  419  Time:  10.401  Rel. Train L2 Loss :  0.0041827807016670705  Rel. Test L2 Loss :  0.007913364991545678  Test L2 Loss :  0.003725006574143966  inv_L_scale:  [0.642]
Epoch :  420  Time:  10.354  Rel. Train L2 Loss :  0.004131877322991689  Rel. Test L2 Loss :  0.007956656788786253  Test L2 Loss :  0.003747205485900243  inv_L_scale:  [0.642]
Epoch :  421  Time:  10.418  Rel. Train L2 Loss :  0.004094625222186248  Rel. Test L2 Loss :  0.00796036621555686  Test L2 Loss :  0.0037359803977111976  inv_L_scale:  [0.642]
Epoch :  422  Time:  10.471  Rel. Train L2 Loss :  0.004203998224188884  Rel. Test L2 Loss :  0.007978281794736782  Test L2 Loss :  0.0037443817655245463  inv_L_scale:  [0.642]
Epoch :  423  Time:  10.613  Rel. Train L2 Loss :  0.0040809020735323425  Rel. Test L2 Loss :  0.008063673507422209  Test L2 Loss :  0.003789697264631589  inv_L_scale:  [0.642]
Epoch :  424  Time:  10.743  Rel. Train L2 Loss :  0.003988123476505279  Rel. Test L2 Loss :  0.007951736388107141  Test L2 Loss :  0.0037372609010587134  inv_L_scale:  [0.642]
Epoch :  425  Time:  10.363  Rel. Train L2 Loss :  0.003942581166823705  Rel. Test L2 Loss :  0.007888733421762785  Test L2 Loss :  0.003703653272241354  inv_L_scale:  [0.642]
Epoch :  426  Time:  10.337  Rel. Train L2 Loss :  0.003970351975411177  Rel. Test L2 Loss :  0.007861387096345424  Test L2 Loss :  0.0036984565885116658  inv_L_scale:  [0.642]
Epoch :  427  Time:  10.42  Rel. Train L2 Loss :  0.003913114714125792  Rel. Test L2 Loss :  0.00792603986337781  Test L2 Loss :  0.0037281585795183978  inv_L_scale:  [0.642]
Epoch :  428  Time:  10.44  Rel. Train L2 Loss :  0.0038134128774205845  Rel. Test L2 Loss :  0.007848611703763405  Test L2 Loss :  0.003697497071698308  inv_L_scale:  [0.642]
Epoch :  429  Time:  10.37  Rel. Train L2 Loss :  0.0038462648416558902  Rel. Test L2 Loss :  0.007863494157791138  Test L2 Loss :  0.003696742998436093  inv_L_scale:  [0.642]
Epoch :  430  Time:  10.395  Rel. Train L2 Loss :  0.003917064669231573  Rel. Test L2 Loss :  0.007804642599076032  Test L2 Loss :  0.0036796813923865557  inv_L_scale:  [0.642]
Epoch :  431  Time:  10.389  Rel. Train L2 Loss :  0.0038115190913279853  Rel. Test L2 Loss :  0.007829832565039396  Test L2 Loss :  0.003679003498206536  inv_L_scale:  [0.642]
Epoch :  432  Time:  10.373  Rel. Train L2 Loss :  0.0037939397543668746  Rel. Test L2 Loss :  0.007803090711434682  Test L2 Loss :  0.0036713066635032494  inv_L_scale:  [0.642]
Epoch :  433  Time:  11.572  Rel. Train L2 Loss :  0.0037232274847726027  Rel. Test L2 Loss :  0.007821804899722338  Test L2 Loss :  0.003681502277031541  inv_L_scale:  [0.642]
Epoch :  434  Time:  10.798  Rel. Train L2 Loss :  0.003691719898333152  Rel. Test L2 Loss :  0.007768104486167431  Test L2 Loss :  0.0036587881607313953  inv_L_scale:  [0.642]
Epoch :  435  Time:  10.151  Rel. Train L2 Loss :  0.003690267417579889  Rel. Test L2 Loss :  0.00778165806705753  Test L2 Loss :  0.0036559753523518644  inv_L_scale:  [0.642]
Epoch :  436  Time:  10.655  Rel. Train L2 Loss :  0.0036915461644530297  Rel. Test L2 Loss :  0.007860629819333553  Test L2 Loss :  0.003700020145624876  inv_L_scale:  [0.642]
Epoch :  437  Time:  10.081  Rel. Train L2 Loss :  0.0037266080832729738  Rel. Test L2 Loss :  0.007751519704858462  Test L2 Loss :  0.003640852135916551  inv_L_scale:  [0.642]
Epoch :  438  Time:  10.092  Rel. Train L2 Loss :  0.003650178510695696  Rel. Test L2 Loss :  0.007743880748748779  Test L2 Loss :  0.0036477748242517314  inv_L_scale:  [0.642]
Epoch :  439  Time:  10.111  Rel. Train L2 Loss :  0.0036275907382369043  Rel. Test L2 Loss :  0.0077691667154431345  Test L2 Loss :  0.00365635536921521  inv_L_scale:  [0.642]
Epoch :  440  Time:  10.157  Rel. Train L2 Loss :  0.003566064106921355  Rel. Test L2 Loss :  0.007705752433588107  Test L2 Loss :  0.0036289731071641046  inv_L_scale:  [0.642]
Epoch :  441  Time:  10.065  Rel. Train L2 Loss :  0.003561452159037193  Rel. Test L2 Loss :  0.007772717202703158  Test L2 Loss :  0.003662851502497991  inv_L_scale:  [0.642]
Epoch :  442  Time:  10.032  Rel. Train L2 Loss :  0.0035780514429012934  Rel. Test L2 Loss :  0.0077700034342706205  Test L2 Loss :  0.0036638000421226023  inv_L_scale:  [0.642]
Epoch :  443  Time:  10.252  Rel. Train L2 Loss :  0.003480311196297407  Rel. Test L2 Loss :  0.007729175376395384  Test L2 Loss :  0.00363698560744524  inv_L_scale:  [0.642]
Epoch :  444  Time:  10.066  Rel. Train L2 Loss :  0.0034474397748708724  Rel. Test L2 Loss :  0.007677868325263262  Test L2 Loss :  0.0036151409645875294  inv_L_scale:  [0.642]
Epoch :  445  Time:  10.081  Rel. Train L2 Loss :  0.00349112918227911  Rel. Test L2 Loss :  0.007754212319850922  Test L2 Loss :  0.0036551998959233364  inv_L_scale:  [0.642]
Epoch :  446  Time:  10.127  Rel. Train L2 Loss :  0.0034601947789390883  Rel. Test L2 Loss :  0.007711352352052927  Test L2 Loss :  0.0036359446744124095  inv_L_scale:  [0.642]
Epoch :  447  Time:  10.04  Rel. Train L2 Loss :  0.00342065770427386  Rel. Test L2 Loss :  0.0077599993782738845  Test L2 Loss :  0.003655825493236383  inv_L_scale:  [0.642]
Epoch :  448  Time:  10.073  Rel. Train L2 Loss :  0.003449054703116417  Rel. Test L2 Loss :  0.007752970481912295  Test L2 Loss :  0.0036500000767409804  inv_L_scale:  [0.642]
Epoch :  449  Time:  10.051  Rel. Train L2 Loss :  0.003429654501378536  Rel. Test L2 Loss :  0.007674028184264898  Test L2 Loss :  0.0036189335367331904  inv_L_scale:  [0.642]
Epoch :  450  Time:  10.048  Rel. Train L2 Loss :  0.0033609222440669933  Rel. Test L2 Loss :  0.007664023712277412  Test L2 Loss :  0.003606315323462089  inv_L_scale:  [0.642]
Epoch :  451  Time:  10.228  Rel. Train L2 Loss :  0.0033538717174281677  Rel. Test L2 Loss :  0.007665042554338773  Test L2 Loss :  0.0036079724815984565  inv_L_scale:  [0.642]
Epoch :  452  Time:  10.197  Rel. Train L2 Loss :  0.0033129640358189744  Rel. Test L2 Loss :  0.007660896523545186  Test L2 Loss :  0.0036070190897832316  inv_L_scale:  [0.642]
Epoch :  453  Time:  10.33  Rel. Train L2 Loss :  0.003301058573027452  Rel. Test L2 Loss :  0.0076433355237046875  Test L2 Loss :  0.003602186186860005  inv_L_scale:  [0.642]
Epoch :  454  Time:  10.155  Rel. Train L2 Loss :  0.0033267923866709074  Rel. Test L2 Loss :  0.00763676205649972  Test L2 Loss :  0.0035995336001118025  inv_L_scale:  [0.642]
Epoch :  455  Time:  10.246  Rel. Train L2 Loss :  0.003318289540708065  Rel. Test L2 Loss :  0.0076518941173950835  Test L2 Loss :  0.0036058607635398704  inv_L_scale:  [0.642]
Epoch :  456  Time:  10.136  Rel. Train L2 Loss :  0.0032992094283302623  Rel. Test L2 Loss :  0.007658020798116922  Test L2 Loss :  0.0036082608594248692  inv_L_scale:  [0.642]
Epoch :  457  Time:  10.042  Rel. Train L2 Loss :  0.003221847934027513  Rel. Test L2 Loss :  0.007637160221735636  Test L2 Loss :  0.0035982673925658067  inv_L_scale:  [0.642]
Epoch :  458  Time:  10.056  Rel. Train L2 Loss :  0.003225727451965213  Rel. Test L2 Loss :  0.007651896091798941  Test L2 Loss :  0.003602645304054022  inv_L_scale:  [0.642]
Epoch :  459  Time:  10.052  Rel. Train L2 Loss :  0.0031658444460481404  Rel. Test L2 Loss :  0.007663318136086067  Test L2 Loss :  0.0036149320813516775  inv_L_scale:  [0.642]
Epoch :  460  Time:  10.233  Rel. Train L2 Loss :  0.0032555455987652144  Rel. Test L2 Loss :  0.007648952764769395  Test L2 Loss :  0.003606489629795154  inv_L_scale:  [0.642]
Epoch :  461  Time:  10.135  Rel. Train L2 Loss :  0.003163276252647241  Rel. Test L2 Loss :  0.007624154643466075  Test L2 Loss :  0.0035922516975551845  inv_L_scale:  [0.642]
Epoch :  462  Time:  10.081  Rel. Train L2 Loss :  0.003144676364958286  Rel. Test L2 Loss :  0.007632143087685108  Test L2 Loss :  0.0035985836014151575  inv_L_scale:  [0.642]
Epoch :  463  Time:  10.123  Rel. Train L2 Loss :  0.003135094065219164  Rel. Test L2 Loss :  0.007621930396805207  Test L2 Loss :  0.0035935525223612787  inv_L_scale:  [0.642]
Epoch :  464  Time:  10.052  Rel. Train L2 Loss :  0.003140024292593201  Rel. Test L2 Loss :  0.0076167451590299605  Test L2 Loss :  0.0035892618633806706  inv_L_scale:  [0.642]
Epoch :  465  Time:  10.065  Rel. Train L2 Loss :  0.0031328225123385587  Rel. Test L2 Loss :  0.007616802553335826  Test L2 Loss :  0.0035902145877480507  inv_L_scale:  [0.642]
Epoch :  466  Time:  10.075  Rel. Train L2 Loss :  0.0030650657719622056  Rel. Test L2 Loss :  0.0076027796107033885  Test L2 Loss :  0.00358536494585375  inv_L_scale:  [0.642]
Epoch :  467  Time:  10.164  Rel. Train L2 Loss :  0.0031383515124519664  Rel. Test L2 Loss :  0.007591433841735124  Test L2 Loss :  0.003578254071374734  inv_L_scale:  [0.642]
Epoch :  468  Time:  10.053  Rel. Train L2 Loss :  0.0031108396798372267  Rel. Test L2 Loss :  0.007601953353732824  Test L2 Loss :  0.003580569876357913  inv_L_scale:  [0.642]
Epoch :  469  Time:  10.118  Rel. Train L2 Loss :  0.003162393322835366  Rel. Test L2 Loss :  0.007562576110164324  Test L2 Loss :  0.0035654887091368438  inv_L_scale:  [0.642]
Epoch :  470  Time:  10.054  Rel. Train L2 Loss :  0.003114013597369194  Rel. Test L2 Loss :  0.007572941991190116  Test L2 Loss :  0.0035703307731697956  inv_L_scale:  [0.642]
Epoch :  471  Time:  10.194  Rel. Train L2 Loss :  0.003122674389431874  Rel. Test L2 Loss :  0.007587919632593791  Test L2 Loss :  0.0035762142545233172  inv_L_scale:  [0.642]
Epoch :  472  Time:  10.061  Rel. Train L2 Loss :  0.0030772749334573744  Rel. Test L2 Loss :  0.007578630298376084  Test L2 Loss :  0.0035700224029521148  inv_L_scale:  [0.642]
Epoch :  473  Time:  10.031  Rel. Train L2 Loss :  0.0029828508446613946  Rel. Test L2 Loss :  0.007585856088747581  Test L2 Loss :  0.0035752607323229313  inv_L_scale:  [0.642]
Epoch :  474  Time:  10.077  Rel. Train L2 Loss :  0.003073479775339365  Rel. Test L2 Loss :  0.00756845165664951  Test L2 Loss :  0.003568327488998572  inv_L_scale:  [0.642]
Epoch :  475  Time:  10.351  Rel. Train L2 Loss :  0.0030878082948426404  Rel. Test L2 Loss :  0.007570892988393704  Test L2 Loss :  0.003567950455471873  inv_L_scale:  [0.642]
Epoch :  476  Time:  10.071  Rel. Train L2 Loss :  0.0030528530615071456  Rel. Test L2 Loss :  0.0075742830460270244  Test L2 Loss :  0.0035682636530448993  inv_L_scale:  [0.642]
Epoch :  477  Time:  10.14  Rel. Train L2 Loss :  0.003014265504355232  Rel. Test L2 Loss :  0.007584499822308619  Test L2 Loss :  0.0035763005694995323  inv_L_scale:  [0.642]
Epoch :  478  Time:  10.037  Rel. Train L2 Loss :  0.002994420570631822  Rel. Test L2 Loss :  0.007594988985608022  Test L2 Loss :  0.0035774369941403467  inv_L_scale:  [0.642]
Epoch :  479  Time:  10.091  Rel. Train L2 Loss :  0.003050716197739045  Rel. Test L2 Loss :  0.0075858082746466  Test L2 Loss :  0.003575142417103052  inv_L_scale:  [0.642]
Epoch :  480  Time:  10.027  Rel. Train L2 Loss :  0.003063825746377309  Rel. Test L2 Loss :  0.007574676771958669  Test L2 Loss :  0.003569889770199855  inv_L_scale:  [0.642]
Epoch :  481  Time:  10.098  Rel. Train L2 Loss :  0.0030232976153492927  Rel. Test L2 Loss :  0.007581524675091108  Test L2 Loss :  0.003574727748831113  inv_L_scale:  [0.642]
Epoch :  482  Time:  10.076  Rel. Train L2 Loss :  0.0030221665017306806  Rel. Test L2 Loss :  0.007554824178417524  Test L2 Loss :  0.0035617957326273125  inv_L_scale:  [0.642]
Epoch :  483  Time:  10.044  Rel. Train L2 Loss :  0.0030039632401118676  Rel. Test L2 Loss :  0.007577723519255717  Test L2 Loss :  0.003570806048810482  inv_L_scale:  [0.642]
Epoch :  484  Time:  10.042  Rel. Train L2 Loss :  0.003005957550058762  Rel. Test L2 Loss :  0.007562075331807136  Test L2 Loss :  0.0035633347959568105  inv_L_scale:  [0.642]
Epoch :  485  Time:  10.034  Rel. Train L2 Loss :  0.003010376513004303  Rel. Test L2 Loss :  0.007562015100071828  Test L2 Loss :  0.0035636858828365803  inv_L_scale:  [0.642]
Epoch :  486  Time:  10.031  Rel. Train L2 Loss :  0.0029639793112874032  Rel. Test L2 Loss :  0.00755153551697731  Test L2 Loss :  0.003558839652687311  inv_L_scale:  [0.642]
Epoch :  487  Time:  10.037  Rel. Train L2 Loss :  0.002989148415625095  Rel. Test L2 Loss :  0.007553496124843757  Test L2 Loss :  0.0035585420796026787  inv_L_scale:  [0.642]
Epoch :  488  Time:  10.03  Rel. Train L2 Loss :  0.002967174834261338  Rel. Test L2 Loss :  0.007552944036821524  Test L2 Loss :  0.0035595618995527428  inv_L_scale:  [0.642]
Epoch :  489  Time:  10.026  Rel. Train L2 Loss :  0.0029496401858826477  Rel. Test L2 Loss :  0.00754338222866257  Test L2 Loss :  0.0035553993036349612  inv_L_scale:  [0.642]
Epoch :  490  Time:  10.005  Rel. Train L2 Loss :  0.002929087327172359  Rel. Test L2 Loss :  0.007568837727109591  Test L2 Loss :  0.003567023364206155  inv_L_scale:  [0.642]
Epoch :  491  Time:  9.992  Rel. Train L2 Loss :  0.0029940458262960115  Rel. Test L2 Loss :  0.007560242755959431  Test L2 Loss :  0.0035635983509322007  inv_L_scale:  [0.642]
Epoch :  492  Time:  9.982  Rel. Train L2 Loss :  0.0029257248441378276  Rel. Test L2 Loss :  0.007563554340352615  Test L2 Loss :  0.0035637975049515563  inv_L_scale:  [0.642]
Epoch :  493  Time:  9.98  Rel. Train L2 Loss :  0.0029621114501108725  Rel. Test L2 Loss :  0.007567530237138271  Test L2 Loss :  0.003564852010458708  inv_L_scale:  [0.642]
Epoch :  494  Time:  9.996  Rel. Train L2 Loss :  0.002959773659706116  Rel. Test L2 Loss :  0.0075476665173967675  Test L2 Loss :  0.0035554340574890375  inv_L_scale:  [0.642]
Epoch :  495  Time:  9.973  Rel. Train L2 Loss :  0.0029352260455489157  Rel. Test L2 Loss :  0.007545127682387829  Test L2 Loss :  0.003554484602063894  inv_L_scale:  [0.642]
Epoch :  496  Time:  10.016  Rel. Train L2 Loss :  0.002949734486018618  Rel. Test L2 Loss :  0.007554113330940406  Test L2 Loss :  0.0035609746413926284  inv_L_scale:  [0.642]
Epoch :  497  Time:  9.999  Rel. Train L2 Loss :  0.0029475868189086517  Rel. Test L2 Loss :  0.007555534765124321  Test L2 Loss :  0.003561608803768953  inv_L_scale:  [0.642]
Epoch :  498  Time:  9.978  Rel. Train L2 Loss :  0.0029514362004896006  Rel. Test L2 Loss :  0.007559961806982755  Test L2 Loss :  0.0035615729509542384  inv_L_scale:  [0.642]
Epoch :  499  Time:  9.982  Rel. Train L2 Loss :  0.0028926383424550295  Rel. Test L2 Loss :  0.0075503407853345075  Test L2 Loss :  0.003556153830140829  inv_L_scale:  [0.642]
