Loading data from  ../../data/curve//pcno_curve_data_1_1_5_5_stokes.npz
(1000,) (1000, 1000, 1) (1000, 1000, 2)
use normalized raw measures
Casting to tensor
x_train shape torch.Size([900, 1000, 6]), y_train shape torch.Size([900, 1000, 1])
length of each dim:  tensor([6.6455335617065430, 6.6654777526855469])
kmax = 32
L =  14
In PCNO_train, ndims =  2
Epoch :  0  Time:  2.632  Rel. Train L2 Loss :  0.5014640006754133  Rel. Test L2 Loss :  0.30312044620513917  Test L2 Loss :  0.5480794191360474  inv_L_scale:  [1.0, 1.0]
Epoch :  1  Time:  2.363  Rel. Train L2 Loss :  0.24924918982717725  Rel. Test L2 Loss :  0.2113228917121887  Test L2 Loss :  0.38809372782707213  inv_L_scale:  [1.0, 1.0]
Epoch :  2  Time:  2.361  Rel. Train L2 Loss :  0.1834526296456655  Rel. Test L2 Loss :  0.17444373905658722  Test L2 Loss :  0.3314604139328003  inv_L_scale:  [1.0, 1.0]
Epoch :  3  Time:  2.362  Rel. Train L2 Loss :  0.1515702881415685  Rel. Test L2 Loss :  0.1404583552479744  Test L2 Loss :  0.2616118097305298  inv_L_scale:  [1.0, 1.0]
Epoch :  4  Time:  2.362  Rel. Train L2 Loss :  0.12658162070645226  Rel. Test L2 Loss :  0.12427448034286499  Test L2 Loss :  0.231860990524292  inv_L_scale:  [1.0, 1.0]
Epoch :  5  Time:  2.361  Rel. Train L2 Loss :  0.11468356917301814  Rel. Test L2 Loss :  0.11582359731197357  Test L2 Loss :  0.22029370129108428  inv_L_scale:  [1.0, 1.0]
Epoch :  6  Time:  2.36  Rel. Train L2 Loss :  0.10988335175646675  Rel. Test L2 Loss :  0.10950436413288117  Test L2 Loss :  0.20421595811843873  inv_L_scale:  [1.0, 1.0]
Epoch :  7  Time:  2.361  Rel. Train L2 Loss :  0.09728115826845168  Rel. Test L2 Loss :  0.09766554176807403  Test L2 Loss :  0.1813020610809326  inv_L_scale:  [1.0, 1.0]
Epoch :  8  Time:  2.36  Rel. Train L2 Loss :  0.08846606969833375  Rel. Test L2 Loss :  0.0961867955327034  Test L2 Loss :  0.17837921321392058  inv_L_scale:  [1.0, 1.0]
Epoch :  9  Time:  2.361  Rel. Train L2 Loss :  0.08340152117941114  Rel. Test L2 Loss :  0.0855930757522583  Test L2 Loss :  0.1579766047000885  inv_L_scale:  [1.0, 1.0]
Epoch :  10  Time:  2.36  Rel. Train L2 Loss :  0.07897818783919017  Rel. Test L2 Loss :  0.08336824595928193  Test L2 Loss :  0.15324263870716096  inv_L_scale:  [1.0, 1.0]
Epoch :  11  Time:  2.36  Rel. Train L2 Loss :  0.07572805252340105  Rel. Test L2 Loss :  0.08082149446010589  Test L2 Loss :  0.14920951068401336  inv_L_scale:  [1.0, 1.0]
Epoch :  12  Time:  2.36  Rel. Train L2 Loss :  0.07179646207226648  Rel. Test L2 Loss :  0.07699548125267029  Test L2 Loss :  0.14332212448120119  inv_L_scale:  [1.0, 1.0]
Epoch :  13  Time:  2.361  Rel. Train L2 Loss :  0.07290922370221879  Rel. Test L2 Loss :  0.07212832391262054  Test L2 Loss :  0.13312419414520263  inv_L_scale:  [1.0, 1.0]
Epoch :  14  Time:  2.36  Rel. Train L2 Loss :  0.06518143099215296  Rel. Test L2 Loss :  0.06940554141998291  Test L2 Loss :  0.12733039796352386  inv_L_scale:  [1.0, 1.0]
Epoch :  15  Time:  2.36  Rel. Train L2 Loss :  0.06353370575441254  Rel. Test L2 Loss :  0.06898862391710281  Test L2 Loss :  0.12938323259353637  inv_L_scale:  [1.0, 1.0]
Epoch :  16  Time:  2.361  Rel. Train L2 Loss :  0.06048764771885342  Rel. Test L2 Loss :  0.06842763841152191  Test L2 Loss :  0.12582019686698914  inv_L_scale:  [1.0, 1.0]
Epoch :  17  Time:  2.36  Rel. Train L2 Loss :  0.061898405585024095  Rel. Test L2 Loss :  0.06499145716428757  Test L2 Loss :  0.11801231414079666  inv_L_scale:  [1.0, 1.0]
Epoch :  18  Time:  2.36  Rel. Train L2 Loss :  0.05865994359056155  Rel. Test L2 Loss :  0.07172224640846253  Test L2 Loss :  0.1298980450630188  inv_L_scale:  [1.0, 1.0]
Epoch :  19  Time:  2.36  Rel. Train L2 Loss :  0.05765116337272856  Rel. Test L2 Loss :  0.06093710526823998  Test L2 Loss :  0.11155107289552689  inv_L_scale:  [1.0, 1.0]
Epoch :  20  Time:  2.359  Rel. Train L2 Loss :  0.05456280670232243  Rel. Test L2 Loss :  0.060113594233989716  Test L2 Loss :  0.10981465935707092  inv_L_scale:  [1.0, 1.0]
Epoch :  21  Time:  2.362  Rel. Train L2 Loss :  0.054513684180047775  Rel. Test L2 Loss :  0.055747080296278  Test L2 Loss :  0.10258005321025848  inv_L_scale:  [1.0, 1.0]
Epoch :  22  Time:  2.359  Rel. Train L2 Loss :  0.052360893107122844  Rel. Test L2 Loss :  0.058520435988903045  Test L2 Loss :  0.10581119924783706  inv_L_scale:  [1.0, 1.0]
Epoch :  23  Time:  2.36  Rel. Train L2 Loss :  0.05274711079067654  Rel. Test L2 Loss :  0.06086581617593765  Test L2 Loss :  0.11023523449897767  inv_L_scale:  [1.0, 1.0]
Epoch :  24  Time:  2.36  Rel. Train L2 Loss :  0.05230718413988749  Rel. Test L2 Loss :  0.0579096919298172  Test L2 Loss :  0.10450303614139557  inv_L_scale:  [1.0, 1.0]
Epoch :  25  Time:  2.359  Rel. Train L2 Loss :  0.05170222537385093  Rel. Test L2 Loss :  0.053682742714881895  Test L2 Loss :  0.09818831622600556  inv_L_scale:  [1.0, 1.0]
Epoch :  26  Time:  2.362  Rel. Train L2 Loss :  0.0543319132592943  Rel. Test L2 Loss :  0.056788410246372226  Test L2 Loss :  0.10287186950445175  inv_L_scale:  [1.0, 1.0]
Epoch :  27  Time:  2.36  Rel. Train L2 Loss :  0.053280394689904316  Rel. Test L2 Loss :  0.05216080203652382  Test L2 Loss :  0.09437019258737564  inv_L_scale:  [1.0, 1.0]
Epoch :  28  Time:  2.359  Rel. Train L2 Loss :  0.049056842658254836  Rel. Test L2 Loss :  0.05741502329707146  Test L2 Loss :  0.10638715207576752  inv_L_scale:  [1.0, 1.0]
Epoch :  29  Time:  2.36  Rel. Train L2 Loss :  0.05145427387621668  Rel. Test L2 Loss :  0.055342050343751906  Test L2 Loss :  0.10176720410585403  inv_L_scale:  [1.0, 1.0]
Epoch :  30  Time:  2.359  Rel. Train L2 Loss :  0.04983131753073798  Rel. Test L2 Loss :  0.0553141975402832  Test L2 Loss :  0.10313732117414474  inv_L_scale:  [1.0, 1.0]
Epoch :  31  Time:  2.36  Rel. Train L2 Loss :  0.04892361377676328  Rel. Test L2 Loss :  0.05271877825260162  Test L2 Loss :  0.09470543116331101  inv_L_scale:  [1.0, 1.0]
Epoch :  32  Time:  2.36  Rel. Train L2 Loss :  0.04683944150805473  Rel. Test L2 Loss :  0.05194258347153664  Test L2 Loss :  0.09436199367046356  inv_L_scale:  [1.0, 1.0]
Epoch :  33  Time:  2.361  Rel. Train L2 Loss :  0.04661274466249678  Rel. Test L2 Loss :  0.049938109666109086  Test L2 Loss :  0.09043862372636795  inv_L_scale:  [1.0, 1.0]
Epoch :  34  Time:  2.359  Rel. Train L2 Loss :  0.04658863825930489  Rel. Test L2 Loss :  0.046558825969696044  Test L2 Loss :  0.08489920318126679  inv_L_scale:  [1.0, 1.0]
Epoch :  35  Time:  2.359  Rel. Train L2 Loss :  0.043967375059922535  Rel. Test L2 Loss :  0.05835595965385437  Test L2 Loss :  0.10377168357372284  inv_L_scale:  [1.0, 1.0]
Epoch :  36  Time:  2.36  Rel. Train L2 Loss :  0.04449075397517946  Rel. Test L2 Loss :  0.04910654813051224  Test L2 Loss :  0.08859695971012116  inv_L_scale:  [1.0, 1.0]
Epoch :  37  Time:  2.36  Rel. Train L2 Loss :  0.0431562921570407  Rel. Test L2 Loss :  0.050567822456359865  Test L2 Loss :  0.09114819496870041  inv_L_scale:  [1.0, 1.0]
Epoch :  38  Time:  2.36  Rel. Train L2 Loss :  0.04502975607911746  Rel. Test L2 Loss :  0.06325799107551575  Test L2 Loss :  0.11750291228294373  inv_L_scale:  [1.0, 1.0]
Epoch :  39  Time:  2.359  Rel. Train L2 Loss :  0.04552488456169764  Rel. Test L2 Loss :  0.046885616183280944  Test L2 Loss :  0.08560036599636078  inv_L_scale:  [1.0, 1.0]
Epoch :  40  Time:  2.361  Rel. Train L2 Loss :  0.046939863678481845  Rel. Test L2 Loss :  0.048301485627889634  Test L2 Loss :  0.08686830401420594  inv_L_scale:  [1.0, 1.0]
Epoch :  41  Time:  2.36  Rel. Train L2 Loss :  0.046446024047003855  Rel. Test L2 Loss :  0.05164694741368294  Test L2 Loss :  0.09267713248729706  inv_L_scale:  [1.0, 1.0]
Epoch :  42  Time:  2.359  Rel. Train L2 Loss :  0.04493554482857386  Rel. Test L2 Loss :  0.04435804024338722  Test L2 Loss :  0.07913165211677552  inv_L_scale:  [1.0, 1.0]
Epoch :  43  Time:  2.359  Rel. Train L2 Loss :  0.04054012265470293  Rel. Test L2 Loss :  0.04612393468618393  Test L2 Loss :  0.08317944467067719  inv_L_scale:  [1.0, 1.0]
Epoch :  44  Time:  2.359  Rel. Train L2 Loss :  0.042615768528646895  Rel. Test L2 Loss :  0.05213236570358276  Test L2 Loss :  0.09574097782373428  inv_L_scale:  [1.0, 1.0]
Epoch :  45  Time:  2.36  Rel. Train L2 Loss :  0.043745043526093166  Rel. Test L2 Loss :  0.04831956177949905  Test L2 Loss :  0.08738935559988022  inv_L_scale:  [1.0, 1.0]
Epoch :  46  Time:  2.359  Rel. Train L2 Loss :  0.04383548499809371  Rel. Test L2 Loss :  0.04869862109422684  Test L2 Loss :  0.0875184977054596  inv_L_scale:  [1.0, 1.0]
Epoch :  47  Time:  2.36  Rel. Train L2 Loss :  0.041520464420318606  Rel. Test L2 Loss :  0.045769691467285156  Test L2 Loss :  0.08210425525903702  inv_L_scale:  [1.0, 1.0]
Epoch :  48  Time:  2.359  Rel. Train L2 Loss :  0.04200642489724689  Rel. Test L2 Loss :  0.04715033322572708  Test L2 Loss :  0.08507830798625945  inv_L_scale:  [1.0, 1.0]
Epoch :  49  Time:  2.361  Rel. Train L2 Loss :  0.038766943415006  Rel. Test L2 Loss :  0.04469980150461197  Test L2 Loss :  0.0796721938252449  inv_L_scale:  [1.0, 1.0]
Epoch :  50  Time:  2.361  Rel. Train L2 Loss :  0.03898083668616083  Rel. Test L2 Loss :  0.043096942007541654  Test L2 Loss :  0.07711253702640533  inv_L_scale:  [1.0, 1.0]
Epoch :  51  Time:  2.36  Rel. Train L2 Loss :  0.0387142110367616  Rel. Test L2 Loss :  0.0526780766248703  Test L2 Loss :  0.0951065719127655  inv_L_scale:  [1.0, 1.0]
Epoch :  52  Time:  2.36  Rel. Train L2 Loss :  0.04086772322654724  Rel. Test L2 Loss :  0.04219147399067879  Test L2 Loss :  0.07654104232788086  inv_L_scale:  [1.0, 1.0]
Epoch :  53  Time:  2.359  Rel. Train L2 Loss :  0.040378878166278206  Rel. Test L2 Loss :  0.04992532104253769  Test L2 Loss :  0.0898100534081459  inv_L_scale:  [1.0, 1.0]
Epoch :  54  Time:  2.359  Rel. Train L2 Loss :  0.04116881180140707  Rel. Test L2 Loss :  0.043867360800504684  Test L2 Loss :  0.07880396574735642  inv_L_scale:  [1.0, 1.0]
Epoch :  55  Time:  2.361  Rel. Train L2 Loss :  0.03994158575932185  Rel. Test L2 Loss :  0.04431638300418854  Test L2 Loss :  0.07998222887516021  inv_L_scale:  [1.0, 1.0]
Epoch :  56  Time:  2.359  Rel. Train L2 Loss :  0.03863841711646981  Rel. Test L2 Loss :  0.04280580699443817  Test L2 Loss :  0.07662473946809768  inv_L_scale:  [1.0, 1.0]
Epoch :  57  Time:  2.359  Rel. Train L2 Loss :  0.03764382500615385  Rel. Test L2 Loss :  0.05030448779463768  Test L2 Loss :  0.09026693433523178  inv_L_scale:  [1.0, 1.0]
Epoch :  58  Time:  2.359  Rel. Train L2 Loss :  0.03905172713928753  Rel. Test L2 Loss :  0.04254923433065414  Test L2 Loss :  0.07610605478286743  inv_L_scale:  [1.0, 1.0]
Epoch :  59  Time:  2.358  Rel. Train L2 Loss :  0.03788393153084649  Rel. Test L2 Loss :  0.039762618839740756  Test L2 Loss :  0.07126932561397553  inv_L_scale:  [1.0, 1.0]
Epoch :  60  Time:  2.359  Rel. Train L2 Loss :  0.03733047884371546  Rel. Test L2 Loss :  0.04473797917366028  Test L2 Loss :  0.07953261733055114  inv_L_scale:  [1.0, 1.0]
Epoch :  61  Time:  2.362  Rel. Train L2 Loss :  0.03667546378241645  Rel. Test L2 Loss :  0.0492037433385849  Test L2 Loss :  0.08719440817832946  inv_L_scale:  [1.0, 1.0]
Epoch :  62  Time:  2.359  Rel. Train L2 Loss :  0.037761030006739825  Rel. Test L2 Loss :  0.03766507402062416  Test L2 Loss :  0.06734555661678314  inv_L_scale:  [1.0, 1.0]
Epoch :  63  Time:  2.359  Rel. Train L2 Loss :  0.035645280281702676  Rel. Test L2 Loss :  0.03890951618552208  Test L2 Loss :  0.07057334899902344  inv_L_scale:  [1.0, 1.0]
Epoch :  64  Time:  2.359  Rel. Train L2 Loss :  0.038438655369811586  Rel. Test L2 Loss :  0.042986189872026445  Test L2 Loss :  0.0776526015996933  inv_L_scale:  [1.0, 1.0]
Epoch :  65  Time:  2.359  Rel. Train L2 Loss :  0.03554698963960012  Rel. Test L2 Loss :  0.042386271953582765  Test L2 Loss :  0.07710265040397644  inv_L_scale:  [1.0, 1.0]
Epoch :  66  Time:  2.361  Rel. Train L2 Loss :  0.035141971732179325  Rel. Test L2 Loss :  0.03750215157866478  Test L2 Loss :  0.06695279002189636  inv_L_scale:  [1.0, 1.0]
Epoch :  67  Time:  2.364  Rel. Train L2 Loss :  0.036264110836717815  Rel. Test L2 Loss :  0.048931394815444944  Test L2 Loss :  0.08766645699739456  inv_L_scale:  [1.0, 1.0]
Epoch :  68  Time:  2.363  Rel. Train L2 Loss :  0.03728065315220091  Rel. Test L2 Loss :  0.03704717859625816  Test L2 Loss :  0.06610998958349228  inv_L_scale:  [1.0, 1.0]
Epoch :  69  Time:  2.363  Rel. Train L2 Loss :  0.0345252958436807  Rel. Test L2 Loss :  0.03630171611905098  Test L2 Loss :  0.06537148118019104  inv_L_scale:  [1.0, 1.0]
Epoch :  70  Time:  2.363  Rel. Train L2 Loss :  0.0355676888095008  Rel. Test L2 Loss :  0.040381959527730944  Test L2 Loss :  0.07225873947143555  inv_L_scale:  [1.0, 1.0]
Epoch :  71  Time:  2.362  Rel. Train L2 Loss :  0.03385097904337777  Rel. Test L2 Loss :  0.04088402733206749  Test L2 Loss :  0.07268969833850861  inv_L_scale:  [1.0, 1.0]
Epoch :  72  Time:  2.363  Rel. Train L2 Loss :  0.03272750202152464  Rel. Test L2 Loss :  0.035873332843184474  Test L2 Loss :  0.06377704620361328  inv_L_scale:  [1.0, 1.0]
Epoch :  73  Time:  2.363  Rel. Train L2 Loss :  0.03481429795424144  Rel. Test L2 Loss :  0.03708915457129478  Test L2 Loss :  0.06653684735298157  inv_L_scale:  [1.0, 1.0]
Epoch :  74  Time:  2.365  Rel. Train L2 Loss :  0.03371911350223753  Rel. Test L2 Loss :  0.03739760860800743  Test L2 Loss :  0.0677871459722519  inv_L_scale:  [1.0, 1.0]
Epoch :  75  Time:  2.363  Rel. Train L2 Loss :  0.03403013633357154  Rel. Test L2 Loss :  0.03683811157941818  Test L2 Loss :  0.06621540904045105  inv_L_scale:  [1.0, 1.0]
Epoch :  76  Time:  2.362  Rel. Train L2 Loss :  0.03351025414135721  Rel. Test L2 Loss :  0.0340675362944603  Test L2 Loss :  0.06059030175209045  inv_L_scale:  [1.0, 1.0]
Epoch :  77  Time:  2.363  Rel. Train L2 Loss :  0.03206735922230614  Rel. Test L2 Loss :  0.038164392262697217  Test L2 Loss :  0.07035284101963044  inv_L_scale:  [1.0, 1.0]
Epoch :  78  Time:  2.362  Rel. Train L2 Loss :  0.03201808093322648  Rel. Test L2 Loss :  0.035887330770492554  Test L2 Loss :  0.06411305144429207  inv_L_scale:  [1.0, 1.0]
Epoch :  79  Time:  2.362  Rel. Train L2 Loss :  0.03245796414713065  Rel. Test L2 Loss :  0.03558096542954445  Test L2 Loss :  0.06351851612329483  inv_L_scale:  [1.0, 1.0]
Epoch :  80  Time:  2.362  Rel. Train L2 Loss :  0.03157206522921721  Rel. Test L2 Loss :  0.03507305428385735  Test L2 Loss :  0.06276710838079452  inv_L_scale:  [1.0, 1.0]
Epoch :  81  Time:  2.362  Rel. Train L2 Loss :  0.03160289777649773  Rel. Test L2 Loss :  0.04606198862195015  Test L2 Loss :  0.08766175508499145  inv_L_scale:  [1.0, 1.0]
Epoch :  82  Time:  2.364  Rel. Train L2 Loss :  0.032844171822071076  Rel. Test L2 Loss :  0.04110297307372093  Test L2 Loss :  0.07456352710723876  inv_L_scale:  [1.0, 1.0]
Epoch :  83  Time:  2.363  Rel. Train L2 Loss :  0.032815655577513904  Rel. Test L2 Loss :  0.03482628390192986  Test L2 Loss :  0.06164596036076546  inv_L_scale:  [1.0, 1.0]
Epoch :  84  Time:  2.363  Rel. Train L2 Loss :  0.031970698551999195  Rel. Test L2 Loss :  0.03388857461512089  Test L2 Loss :  0.06024575516581535  inv_L_scale:  [1.0, 1.0]
Epoch :  85  Time:  2.364  Rel. Train L2 Loss :  0.031439544707536696  Rel. Test L2 Loss :  0.03491359315812588  Test L2 Loss :  0.06209434852004051  inv_L_scale:  [1.0, 1.0]
Epoch :  86  Time:  2.362  Rel. Train L2 Loss :  0.03168378180927701  Rel. Test L2 Loss :  0.03653476268053055  Test L2 Loss :  0.06508508831262588  inv_L_scale:  [1.0, 1.0]
Epoch :  87  Time:  2.363  Rel. Train L2 Loss :  0.03130015471743213  Rel. Test L2 Loss :  0.03553005740046501  Test L2 Loss :  0.06299217134714126  inv_L_scale:  [1.0, 1.0]
Epoch :  88  Time:  2.363  Rel. Train L2 Loss :  0.029984174917141598  Rel. Test L2 Loss :  0.0332757481187582  Test L2 Loss :  0.05941529959440231  inv_L_scale:  [1.0, 1.0]
Epoch :  89  Time:  2.363  Rel. Train L2 Loss :  0.030759498592880036  Rel. Test L2 Loss :  0.03499540731310844  Test L2 Loss :  0.06275568813085557  inv_L_scale:  [1.0, 1.0]
Epoch :  90  Time:  2.366  Rel. Train L2 Loss :  0.03096141298611959  Rel. Test L2 Loss :  0.03263289093971253  Test L2 Loss :  0.05842147320508957  inv_L_scale:  [1.0, 1.0]
Epoch :  91  Time:  2.363  Rel. Train L2 Loss :  0.02898659345176485  Rel. Test L2 Loss :  0.03149826765060425  Test L2 Loss :  0.057064839154481885  inv_L_scale:  [1.0, 1.0]
Epoch :  92  Time:  2.363  Rel. Train L2 Loss :  0.02959843733244472  Rel. Test L2 Loss :  0.03410795629024506  Test L2 Loss :  0.06112159073352814  inv_L_scale:  [1.0, 1.0]
Epoch :  93  Time:  2.364  Rel. Train L2 Loss :  0.02924580372042126  Rel. Test L2 Loss :  0.0330790214240551  Test L2 Loss :  0.05858563750982285  inv_L_scale:  [1.0, 1.0]
Epoch :  94  Time:  2.363  Rel. Train L2 Loss :  0.03031400246752633  Rel. Test L2 Loss :  0.03154266037046909  Test L2 Loss :  0.056353567093610765  inv_L_scale:  [1.0, 1.0]
Epoch :  95  Time:  2.363  Rel. Train L2 Loss :  0.028666814780897564  Rel. Test L2 Loss :  0.03384498298168182  Test L2 Loss :  0.06076843798160553  inv_L_scale:  [1.0, 1.0]
Epoch :  96  Time:  2.363  Rel. Train L2 Loss :  0.028596576443976826  Rel. Test L2 Loss :  0.033025435507297515  Test L2 Loss :  0.05936906605958939  inv_L_scale:  [1.0, 1.0]
Epoch :  97  Time:  2.362  Rel. Train L2 Loss :  0.030126237753364773  Rel. Test L2 Loss :  0.032558634728193286  Test L2 Loss :  0.05844513133168221  inv_L_scale:  [1.0, 1.0]
Epoch :  98  Time:  2.363  Rel. Train L2 Loss :  0.02881056868367725  Rel. Test L2 Loss :  0.03748221203684807  Test L2 Loss :  0.06664775788784028  inv_L_scale:  [1.0, 1.0]
Epoch :  99  Time:  2.364  Rel. Train L2 Loss :  0.029113750846849546  Rel. Test L2 Loss :  0.033071116060018536  Test L2 Loss :  0.05881901144981384  inv_L_scale:  [1.0, 1.0]
Epoch :  100  Time:  2.363  Rel. Train L2 Loss :  0.028234163232975534  Rel. Test L2 Loss :  0.03329278379678726  Test L2 Loss :  0.05970001637935638  inv_L_scale:  [1.0, 1.0]
Epoch :  101  Time:  2.363  Rel. Train L2 Loss :  0.027704773098230363  Rel. Test L2 Loss :  0.03305636435747147  Test L2 Loss :  0.05932677388191223  inv_L_scale:  [1.0, 1.0]
Epoch :  102  Time:  2.363  Rel. Train L2 Loss :  0.027821135289139216  Rel. Test L2 Loss :  0.03394095413386822  Test L2 Loss :  0.06043101236224174  inv_L_scale:  [1.0, 1.0]
Epoch :  103  Time:  2.363  Rel. Train L2 Loss :  0.028439011681411  Rel. Test L2 Loss :  0.030385805815458296  Test L2 Loss :  0.05443581849336624  inv_L_scale:  [1.0, 1.0]
Epoch :  104  Time:  2.363  Rel. Train L2 Loss :  0.0277049411005444  Rel. Test L2 Loss :  0.030199619382619856  Test L2 Loss :  0.053961406350135806  inv_L_scale:  [1.0, 1.0]
Epoch :  105  Time:  2.363  Rel. Train L2 Loss :  0.026833674874570633  Rel. Test L2 Loss :  0.03120258279144764  Test L2 Loss :  0.056311901956796646  inv_L_scale:  [1.0, 1.0]
Epoch :  106  Time:  2.363  Rel. Train L2 Loss :  0.02728888526558876  Rel. Test L2 Loss :  0.030393526181578635  Test L2 Loss :  0.05453803762793541  inv_L_scale:  [1.0, 1.0]
Epoch :  107  Time:  2.363  Rel. Train L2 Loss :  0.026580169912841584  Rel. Test L2 Loss :  0.041381597220897674  Test L2 Loss :  0.07511771440505982  inv_L_scale:  [1.0, 1.0]
Epoch :  108  Time:  2.362  Rel. Train L2 Loss :  0.0284706186172035  Rel. Test L2 Loss :  0.033908338397741315  Test L2 Loss :  0.06022689491510391  inv_L_scale:  [1.0, 1.0]
Epoch :  109  Time:  2.365  Rel. Train L2 Loss :  0.027714155779944526  Rel. Test L2 Loss :  0.029248143285512923  Test L2 Loss :  0.05252606868743896  inv_L_scale:  [1.0, 1.0]
Epoch :  110  Time:  2.364  Rel. Train L2 Loss :  0.02588746451669269  Rel. Test L2 Loss :  0.028001285791397094  Test L2 Loss :  0.04993230044841766  inv_L_scale:  [1.0, 1.0]
Epoch :  111  Time:  2.363  Rel. Train L2 Loss :  0.02632320562998454  Rel. Test L2 Loss :  0.027339080572128294  Test L2 Loss :  0.04851379454135895  inv_L_scale:  [1.0, 1.0]
Epoch :  112  Time:  2.362  Rel. Train L2 Loss :  0.025505258101556037  Rel. Test L2 Loss :  0.028897605761885645  Test L2 Loss :  0.0516317880153656  inv_L_scale:  [1.0, 1.0]
Epoch :  113  Time:  2.363  Rel. Train L2 Loss :  0.02536999738878674  Rel. Test L2 Loss :  0.027751403748989104  Test L2 Loss :  0.049414078891277316  inv_L_scale:  [1.0, 1.0]
Epoch :  114  Time:  2.363  Rel. Train L2 Loss :  0.025322706980837717  Rel. Test L2 Loss :  0.028410406336188316  Test L2 Loss :  0.05033741980791092  inv_L_scale:  [1.0, 1.0]
Epoch :  115  Time:  2.363  Rel. Train L2 Loss :  0.025252128375901118  Rel. Test L2 Loss :  0.03165448874235153  Test L2 Loss :  0.05686022728681564  inv_L_scale:  [1.0, 1.0]
Epoch :  116  Time:  2.362  Rel. Train L2 Loss :  0.02655234651433097  Rel. Test L2 Loss :  0.028052823841571806  Test L2 Loss :  0.049748630374670026  inv_L_scale:  [1.0, 1.0]
Epoch :  117  Time:  2.362  Rel. Train L2 Loss :  0.025511477531658278  Rel. Test L2 Loss :  0.02737819567322731  Test L2 Loss :  0.04904594615101814  inv_L_scale:  [1.0, 1.0]
Epoch :  118  Time:  2.359  Rel. Train L2 Loss :  0.02488713166779942  Rel. Test L2 Loss :  0.031105798706412315  Test L2 Loss :  0.05529358386993408  inv_L_scale:  [1.0, 1.0]
Epoch :  119  Time:  2.359  Rel. Train L2 Loss :  0.026263212578164205  Rel. Test L2 Loss :  0.027421242147684096  Test L2 Loss :  0.04900523975491524  inv_L_scale:  [1.0, 1.0]
Epoch :  120  Time:  2.36  Rel. Train L2 Loss :  0.024739427318175633  Rel. Test L2 Loss :  0.027407478839159012  Test L2 Loss :  0.04890378206968307  inv_L_scale:  [1.0, 1.0]
Epoch :  121  Time:  2.36  Rel. Train L2 Loss :  0.025425083364049594  Rel. Test L2 Loss :  0.02885299064218998  Test L2 Loss :  0.05135654464364052  inv_L_scale:  [1.0, 1.0]
Epoch :  122  Time:  2.359  Rel. Train L2 Loss :  0.025463437388340632  Rel. Test L2 Loss :  0.029939887076616288  Test L2 Loss :  0.05329084679484367  inv_L_scale:  [1.0, 1.0]
Epoch :  123  Time:  2.359  Rel. Train L2 Loss :  0.026638378409875763  Rel. Test L2 Loss :  0.029494814723730087  Test L2 Loss :  0.052648422122001645  inv_L_scale:  [1.0, 1.0]
Epoch :  124  Time:  2.359  Rel. Train L2 Loss :  0.025608918219804763  Rel. Test L2 Loss :  0.028956043124198912  Test L2 Loss :  0.05230347290635109  inv_L_scale:  [1.0, 1.0]
Epoch :  125  Time:  2.359  Rel. Train L2 Loss :  0.024650055054161284  Rel. Test L2 Loss :  0.028627728670835496  Test L2 Loss :  0.050840753316879275  inv_L_scale:  [1.0, 1.0]
Epoch :  126  Time:  2.359  Rel. Train L2 Loss :  0.024474030443363718  Rel. Test L2 Loss :  0.03102172613143921  Test L2 Loss :  0.054834936559200284  inv_L_scale:  [1.0, 1.0]
Epoch :  127  Time:  2.359  Rel. Train L2 Loss :  0.02444486391213205  Rel. Test L2 Loss :  0.026447892636060715  Test L2 Loss :  0.04686172008514404  inv_L_scale:  [1.0, 1.0]
Epoch :  128  Time:  2.359  Rel. Train L2 Loss :  0.02462615901397334  Rel. Test L2 Loss :  0.027660536617040633  Test L2 Loss :  0.049125108122825625  inv_L_scale:  [1.0, 1.0]
Epoch :  129  Time:  2.359  Rel. Train L2 Loss :  0.024519873079326418  Rel. Test L2 Loss :  0.027159959077835083  Test L2 Loss :  0.048484425842762  inv_L_scale:  [1.0, 1.0]
Epoch :  130  Time:  2.359  Rel. Train L2 Loss :  0.02394746896293428  Rel. Test L2 Loss :  0.02630640707910061  Test L2 Loss :  0.04691595271229744  inv_L_scale:  [1.0, 1.0]
Epoch :  131  Time:  2.361  Rel. Train L2 Loss :  0.024529510802692837  Rel. Test L2 Loss :  0.02736839771270752  Test L2 Loss :  0.04869135782122612  inv_L_scale:  [1.0, 1.0]
Epoch :  132  Time:  2.36  Rel. Train L2 Loss :  0.024488944593403075  Rel. Test L2 Loss :  0.03036167234182358  Test L2 Loss :  0.05437938421964646  inv_L_scale:  [1.0, 1.0]
Epoch :  133  Time:  2.359  Rel. Train L2 Loss :  0.02427310571074486  Rel. Test L2 Loss :  0.02613690875470638  Test L2 Loss :  0.04664590686559677  inv_L_scale:  [1.0, 1.0]
Epoch :  134  Time:  2.359  Rel. Train L2 Loss :  0.023743101722664302  Rel. Test L2 Loss :  0.026775567904114724  Test L2 Loss :  0.04749278292059898  inv_L_scale:  [1.0, 1.0]
Epoch :  135  Time:  2.359  Rel. Train L2 Loss :  0.023359960516293844  Rel. Test L2 Loss :  0.02616173729300499  Test L2 Loss :  0.04674479350447655  inv_L_scale:  [1.0, 1.0]
Epoch :  136  Time:  2.359  Rel. Train L2 Loss :  0.023489262031184302  Rel. Test L2 Loss :  0.028436900600790977  Test L2 Loss :  0.05093363344669342  inv_L_scale:  [1.0, 1.0]
Epoch :  137  Time:  2.359  Rel. Train L2 Loss :  0.023841637339856888  Rel. Test L2 Loss :  0.025981180518865585  Test L2 Loss :  0.04650011390447616  inv_L_scale:  [1.0, 1.0]
Epoch :  138  Time:  2.359  Rel. Train L2 Loss :  0.023993326483501328  Rel. Test L2 Loss :  0.028092181384563444  Test L2 Loss :  0.04976057186722756  inv_L_scale:  [1.0, 1.0]
Epoch :  139  Time:  2.359  Rel. Train L2 Loss :  0.023917945788966284  Rel. Test L2 Loss :  0.0268791364133358  Test L2 Loss :  0.047892078012228015  inv_L_scale:  [1.0, 1.0]
Epoch :  140  Time:  2.359  Rel. Train L2 Loss :  0.02392915037771066  Rel. Test L2 Loss :  0.025096822902560233  Test L2 Loss :  0.04467407554388046  inv_L_scale:  [1.0, 1.0]
Epoch :  141  Time:  2.358  Rel. Train L2 Loss :  0.023670591562986374  Rel. Test L2 Loss :  0.0246459948271513  Test L2 Loss :  0.043993684947490695  inv_L_scale:  [1.0, 1.0]
Epoch :  142  Time:  2.36  Rel. Train L2 Loss :  0.02258901404009925  Rel. Test L2 Loss :  0.025177162438631058  Test L2 Loss :  0.04468449726700783  inv_L_scale:  [1.0, 1.0]
Epoch :  143  Time:  2.359  Rel. Train L2 Loss :  0.023275471337967448  Rel. Test L2 Loss :  0.025199147313833235  Test L2 Loss :  0.04455207198858261  inv_L_scale:  [1.0, 1.0]
Epoch :  144  Time:  2.359  Rel. Train L2 Loss :  0.023086683534913593  Rel. Test L2 Loss :  0.029053545892238616  Test L2 Loss :  0.05163605153560638  inv_L_scale:  [1.0, 1.0]
Epoch :  145  Time:  2.359  Rel. Train L2 Loss :  0.02326550850437747  Rel. Test L2 Loss :  0.027727592140436172  Test L2 Loss :  0.050704005360603335  inv_L_scale:  [1.0, 1.0]
Epoch :  146  Time:  2.359  Rel. Train L2 Loss :  0.02252820622589853  Rel. Test L2 Loss :  0.02734577566385269  Test L2 Loss :  0.048938192576169964  inv_L_scale:  [1.0, 1.0]
Epoch :  147  Time:  2.36  Rel. Train L2 Loss :  0.022761022730006113  Rel. Test L2 Loss :  0.02776128575205803  Test L2 Loss :  0.04898263797163963  inv_L_scale:  [1.0, 1.0]
Epoch :  148  Time:  2.359  Rel. Train L2 Loss :  0.022922079579697715  Rel. Test L2 Loss :  0.0260327934473753  Test L2 Loss :  0.046517708599567414  inv_L_scale:  [1.0, 1.0]
Epoch :  149  Time:  2.359  Rel. Train L2 Loss :  0.02252635856469472  Rel. Test L2 Loss :  0.026507065296173096  Test L2 Loss :  0.047195644080638886  inv_L_scale:  [1.0, 1.0]
Epoch :  150  Time:  2.359  Rel. Train L2 Loss :  0.022966013981236353  Rel. Test L2 Loss :  0.02746708184480667  Test L2 Loss :  0.049984173476696016  inv_L_scale:  [1.0, 1.0]
Epoch :  151  Time:  2.359  Rel. Train L2 Loss :  0.023469134602281783  Rel. Test L2 Loss :  0.02493789032101631  Test L2 Loss :  0.04399153888225556  inv_L_scale:  [1.0, 1.0]
Epoch :  152  Time:  2.359  Rel. Train L2 Loss :  0.023141634662946064  Rel. Test L2 Loss :  0.02586549296975136  Test L2 Loss :  0.04682099625468254  inv_L_scale:  [1.0, 1.0]
Epoch :  153  Time:  2.362  Rel. Train L2 Loss :  0.022482342165377405  Rel. Test L2 Loss :  0.026227677688002587  Test L2 Loss :  0.04665462329983711  inv_L_scale:  [1.0, 1.0]
Epoch :  154  Time:  2.359  Rel. Train L2 Loss :  0.02243141153620349  Rel. Test L2 Loss :  0.025025568529963495  Test L2 Loss :  0.04457120820879936  inv_L_scale:  [1.0, 1.0]
Epoch :  155  Time:  2.359  Rel. Train L2 Loss :  0.02196540286143621  Rel. Test L2 Loss :  0.024676780477166177  Test L2 Loss :  0.043853172659873964  inv_L_scale:  [1.0, 1.0]
Epoch :  156  Time:  2.359  Rel. Train L2 Loss :  0.022464784251319037  Rel. Test L2 Loss :  0.025354070216417314  Test L2 Loss :  0.04491246834397316  inv_L_scale:  [1.0, 1.0]
Epoch :  157  Time:  2.359  Rel. Train L2 Loss :  0.02280826704369651  Rel. Test L2 Loss :  0.02431630253791809  Test L2 Loss :  0.043337611258029936  inv_L_scale:  [1.0, 1.0]
Epoch :  158  Time:  2.359  Rel. Train L2 Loss :  0.022242635356055366  Rel. Test L2 Loss :  0.024578491300344465  Test L2 Loss :  0.0435633710026741  inv_L_scale:  [1.0, 1.0]
Epoch :  159  Time:  2.359  Rel. Train L2 Loss :  0.022907597141133416  Rel. Test L2 Loss :  0.02404931902885437  Test L2 Loss :  0.042411492466926576  inv_L_scale:  [1.0, 1.0]
Epoch :  160  Time:  2.359  Rel. Train L2 Loss :  0.02189471441010634  Rel. Test L2 Loss :  0.023246137797832488  Test L2 Loss :  0.04109650120139122  inv_L_scale:  [1.0, 1.0]
Epoch :  161  Time:  2.359  Rel. Train L2 Loss :  0.021641020013226403  Rel. Test L2 Loss :  0.02425237402319908  Test L2 Loss :  0.04323160350322723  inv_L_scale:  [1.0, 1.0]
Epoch :  162  Time:  2.359  Rel. Train L2 Loss :  0.02313957576950391  Rel. Test L2 Loss :  0.02447362184524536  Test L2 Loss :  0.0435017329454422  inv_L_scale:  [1.0, 1.0]
Epoch :  163  Time:  2.359  Rel. Train L2 Loss :  0.02148338091870149  Rel. Test L2 Loss :  0.025510675013065337  Test L2 Loss :  0.04530666381120682  inv_L_scale:  [1.0, 1.0]
Epoch :  164  Time:  2.36  Rel. Train L2 Loss :  0.02242750777138604  Rel. Test L2 Loss :  0.025903268009424208  Test L2 Loss :  0.04599786639213562  inv_L_scale:  [1.0, 1.0]
Epoch :  165  Time:  2.359  Rel. Train L2 Loss :  0.022012674676047433  Rel. Test L2 Loss :  0.02324877791106701  Test L2 Loss :  0.041201554238796234  inv_L_scale:  [1.0, 1.0]
Epoch :  166  Time:  2.36  Rel. Train L2 Loss :  0.021776943728327752  Rel. Test L2 Loss :  0.024639943540096285  Test L2 Loss :  0.04356258630752564  inv_L_scale:  [1.0, 1.0]
Epoch :  167  Time:  2.359  Rel. Train L2 Loss :  0.02166105947560734  Rel. Test L2 Loss :  0.02618212714791298  Test L2 Loss :  0.04661397069692612  inv_L_scale:  [1.0, 1.0]
Epoch :  168  Time:  2.359  Rel. Train L2 Loss :  0.021440179083082413  Rel. Test L2 Loss :  0.02460269346833229  Test L2 Loss :  0.043614021241664885  inv_L_scale:  [1.0, 1.0]
Epoch :  169  Time:  2.36  Rel. Train L2 Loss :  0.02151477468510469  Rel. Test L2 Loss :  0.023676971271634102  Test L2 Loss :  0.04189524918794632  inv_L_scale:  [1.0, 1.0]
Epoch :  170  Time:  2.359  Rel. Train L2 Loss :  0.0213743257522583  Rel. Test L2 Loss :  0.023771005272865294  Test L2 Loss :  0.04211386978626251  inv_L_scale:  [1.0, 1.0]
Epoch :  171  Time:  2.359  Rel. Train L2 Loss :  0.02124567317465941  Rel. Test L2 Loss :  0.023425081744790077  Test L2 Loss :  0.04116611003875732  inv_L_scale:  [1.0, 1.0]
Epoch :  172  Time:  2.359  Rel. Train L2 Loss :  0.02117863064010938  Rel. Test L2 Loss :  0.023777052164077758  Test L2 Loss :  0.04216257840394974  inv_L_scale:  [1.0, 1.0]
Epoch :  173  Time:  2.359  Rel. Train L2 Loss :  0.02101127513580852  Rel. Test L2 Loss :  0.024124432057142257  Test L2 Loss :  0.042684313058853146  inv_L_scale:  [1.0, 1.0]
Epoch :  174  Time:  2.359  Rel. Train L2 Loss :  0.021585456687543126  Rel. Test L2 Loss :  0.02614346668124199  Test L2 Loss :  0.04700246810913086  inv_L_scale:  [1.0, 1.0]
Epoch :  175  Time:  2.362  Rel. Train L2 Loss :  0.021383581774102316  Rel. Test L2 Loss :  0.02412299007177353  Test L2 Loss :  0.04263617157936096  inv_L_scale:  [1.0, 1.0]
Epoch :  176  Time:  2.36  Rel. Train L2 Loss :  0.02192068062722683  Rel. Test L2 Loss :  0.026826605126261713  Test L2 Loss :  0.048407939821481706  inv_L_scale:  [1.0, 1.0]
Epoch :  177  Time:  2.359  Rel. Train L2 Loss :  0.021208326634433533  Rel. Test L2 Loss :  0.023249128982424736  Test L2 Loss :  0.04085507124662399  inv_L_scale:  [1.0, 1.0]
Epoch :  178  Time:  2.359  Rel. Train L2 Loss :  0.021560861907071537  Rel. Test L2 Loss :  0.023993692249059676  Test L2 Loss :  0.04225656628608704  inv_L_scale:  [1.0, 1.0]
Epoch :  179  Time:  2.359  Rel. Train L2 Loss :  0.021223839248220126  Rel. Test L2 Loss :  0.023392483294010162  Test L2 Loss :  0.04137876719236374  inv_L_scale:  [1.0, 1.0]
Epoch :  180  Time:  2.359  Rel. Train L2 Loss :  0.021182189500994153  Rel. Test L2 Loss :  0.022797966450452803  Test L2 Loss :  0.040366332530975345  inv_L_scale:  [1.0, 1.0]
Epoch :  181  Time:  2.359  Rel. Train L2 Loss :  0.02094889582031303  Rel. Test L2 Loss :  0.02568315848708153  Test L2 Loss :  0.04614572018384933  inv_L_scale:  [1.0, 1.0]
Epoch :  182  Time:  2.359  Rel. Train L2 Loss :  0.02114668877588378  Rel. Test L2 Loss :  0.02331226997077465  Test L2 Loss :  0.04105672135949135  inv_L_scale:  [1.0, 1.0]
Epoch :  183  Time:  2.359  Rel. Train L2 Loss :  0.020876076767841974  Rel. Test L2 Loss :  0.022282331138849257  Test L2 Loss :  0.03927462592720985  inv_L_scale:  [1.0, 1.0]
Epoch :  184  Time:  2.359  Rel. Train L2 Loss :  0.020694307585557303  Rel. Test L2 Loss :  0.022747687250375747  Test L2 Loss :  0.04007302895188332  inv_L_scale:  [1.0, 1.0]
Epoch :  185  Time:  2.359  Rel. Train L2 Loss :  0.020608898144629267  Rel. Test L2 Loss :  0.022900498062372206  Test L2 Loss :  0.04026870727539063  inv_L_scale:  [1.0, 1.0]
Epoch :  186  Time:  2.36  Rel. Train L2 Loss :  0.02090641541613473  Rel. Test L2 Loss :  0.022785395085811615  Test L2 Loss :  0.040160784125328065  inv_L_scale:  [1.0, 1.0]
Epoch :  187  Time:  2.359  Rel. Train L2 Loss :  0.02061961223681768  Rel. Test L2 Loss :  0.025318110585212706  Test L2 Loss :  0.04471103012561798  inv_L_scale:  [1.0, 1.0]
Epoch :  188  Time:  2.359  Rel. Train L2 Loss :  0.021100432806544833  Rel. Test L2 Loss :  0.021962583288550375  Test L2 Loss :  0.038792064785957335  inv_L_scale:  [1.0, 1.0]
Epoch :  189  Time:  2.359  Rel. Train L2 Loss :  0.020231710945566497  Rel. Test L2 Loss :  0.0228541549295187  Test L2 Loss :  0.04027890652418137  inv_L_scale:  [1.0, 1.0]
Epoch :  190  Time:  2.359  Rel. Train L2 Loss :  0.020586715067426365  Rel. Test L2 Loss :  0.022284041345119476  Test L2 Loss :  0.039133992493152615  inv_L_scale:  [1.0, 1.0]
Epoch :  191  Time:  2.359  Rel. Train L2 Loss :  0.020920557578404744  Rel. Test L2 Loss :  0.022761448472738265  Test L2 Loss :  0.04048732176423073  inv_L_scale:  [1.0, 1.0]
Epoch :  192  Time:  2.359  Rel. Train L2 Loss :  0.02082353726029396  Rel. Test L2 Loss :  0.021882594153285025  Test L2 Loss :  0.038582617938518526  inv_L_scale:  [1.0, 1.0]
Epoch :  193  Time:  2.359  Rel. Train L2 Loss :  0.020323988339967198  Rel. Test L2 Loss :  0.024554856494069098  Test L2 Loss :  0.04300671979784965  inv_L_scale:  [1.0, 1.0]
Epoch :  194  Time:  2.359  Rel. Train L2 Loss :  0.02050875769721137  Rel. Test L2 Loss :  0.024130952507257462  Test L2 Loss :  0.04259377554059029  inv_L_scale:  [1.0, 1.0]
Epoch :  195  Time:  2.359  Rel. Train L2 Loss :  0.02100258633494377  Rel. Test L2 Loss :  0.024198151528835296  Test L2 Loss :  0.04293172776699066  inv_L_scale:  [1.0, 1.0]
Epoch :  196  Time:  2.358  Rel. Train L2 Loss :  0.020635443818238047  Rel. Test L2 Loss :  0.023579068332910538  Test L2 Loss :  0.04221987634897232  inv_L_scale:  [1.0, 1.0]
Epoch :  197  Time:  2.362  Rel. Train L2 Loss :  0.02051693153878053  Rel. Test L2 Loss :  0.023824439719319343  Test L2 Loss :  0.04201229453086853  inv_L_scale:  [1.0, 1.0]
Epoch :  198  Time:  2.359  Rel. Train L2 Loss :  0.020396946022907893  Rel. Test L2 Loss :  0.024200739860534667  Test L2 Loss :  0.04281561747193337  inv_L_scale:  [1.0, 1.0]
Epoch :  199  Time:  2.359  Rel. Train L2 Loss :  0.02029986491633786  Rel. Test L2 Loss :  0.02236448973417282  Test L2 Loss :  0.039995010048151015  inv_L_scale:  [1.0, 1.0]
Epoch :  200  Time:  2.359  Rel. Train L2 Loss :  0.020164583143260743  Rel. Test L2 Loss :  0.02246087320148945  Test L2 Loss :  0.03962278753519058  inv_L_scale:  [1.0, 1.0]
Epoch :  201  Time:  2.359  Rel. Train L2 Loss :  0.020205474239256647  Rel. Test L2 Loss :  0.02292932853102684  Test L2 Loss :  0.040503669381141666  inv_L_scale:  [1.0, 1.0]
Epoch :  202  Time:  2.359  Rel. Train L2 Loss :  0.020088133282131618  Rel. Test L2 Loss :  0.02290298730134964  Test L2 Loss :  0.04027619779109955  inv_L_scale:  [1.0, 1.0]
Epoch :  203  Time:  2.359  Rel. Train L2 Loss :  0.020232428188125293  Rel. Test L2 Loss :  0.021790573969483376  Test L2 Loss :  0.0382728374004364  inv_L_scale:  [1.0, 1.0]
Epoch :  204  Time:  2.359  Rel. Train L2 Loss :  0.019782323290904364  Rel. Test L2 Loss :  0.02248281627893448  Test L2 Loss :  0.03987272441387177  inv_L_scale:  [1.0, 1.0]
Epoch :  205  Time:  2.359  Rel. Train L2 Loss :  0.019727900756729973  Rel. Test L2 Loss :  0.021608182191848756  Test L2 Loss :  0.038167111575603485  inv_L_scale:  [1.0, 1.0]
Epoch :  206  Time:  2.359  Rel. Train L2 Loss :  0.020072842753595777  Rel. Test L2 Loss :  0.023278960138559342  Test L2 Loss :  0.04103678017854691  inv_L_scale:  [1.0, 1.0]
Epoch :  207  Time:  2.359  Rel. Train L2 Loss :  0.02009180738694138  Rel. Test L2 Loss :  0.0220250453799963  Test L2 Loss :  0.03887777417898178  inv_L_scale:  [1.0, 1.0]
Epoch :  208  Time:  2.36  Rel. Train L2 Loss :  0.01986443125539356  Rel. Test L2 Loss :  0.02239225581288338  Test L2 Loss :  0.039401105642318725  inv_L_scale:  [1.0, 1.0]
Epoch :  209  Time:  2.359  Rel. Train L2 Loss :  0.019612674622072113  Rel. Test L2 Loss :  0.021963865160942078  Test L2 Loss :  0.03865396738052368  inv_L_scale:  [1.0, 1.0]
Epoch :  210  Time:  2.359  Rel. Train L2 Loss :  0.019952814247873093  Rel. Test L2 Loss :  0.021388689577579497  Test L2 Loss :  0.0374276864528656  inv_L_scale:  [1.0, 1.0]
Epoch :  211  Time:  2.359  Rel. Train L2 Loss :  0.020000201687216758  Rel. Test L2 Loss :  0.02405257523059845  Test L2 Loss :  0.04286783337593079  inv_L_scale:  [1.0, 1.0]
Epoch :  212  Time:  2.359  Rel. Train L2 Loss :  0.01950715264512433  Rel. Test L2 Loss :  0.022880444824695586  Test L2 Loss :  0.040315815806388856  inv_L_scale:  [1.0, 1.0]
Epoch :  213  Time:  2.359  Rel. Train L2 Loss :  0.020575568245516884  Rel. Test L2 Loss :  0.02178038641810417  Test L2 Loss :  0.03825374931097031  inv_L_scale:  [1.0, 1.0]
Epoch :  214  Time:  2.359  Rel. Train L2 Loss :  0.019631700441241264  Rel. Test L2 Loss :  0.022020597234368323  Test L2 Loss :  0.039030889719724654  inv_L_scale:  [1.0, 1.0]
Epoch :  215  Time:  2.359  Rel. Train L2 Loss :  0.01971572486890687  Rel. Test L2 Loss :  0.022651099264621735  Test L2 Loss :  0.04000682279467583  inv_L_scale:  [1.0, 1.0]
Epoch :  216  Time:  2.358  Rel. Train L2 Loss :  0.020155421387818125  Rel. Test L2 Loss :  0.02320494182407856  Test L2 Loss :  0.04101527214050293  inv_L_scale:  [1.0, 1.0]
Epoch :  217  Time:  2.359  Rel. Train L2 Loss :  0.01969031727976269  Rel. Test L2 Loss :  0.021379649713635443  Test L2 Loss :  0.03757180362939835  inv_L_scale:  [1.0, 1.0]
Epoch :  218  Time:  2.359  Rel. Train L2 Loss :  0.019243522360920907  Rel. Test L2 Loss :  0.021592038124799727  Test L2 Loss :  0.03791961222887039  inv_L_scale:  [1.0, 1.0]
Epoch :  219  Time:  2.362  Rel. Train L2 Loss :  0.01963877028889126  Rel. Test L2 Loss :  0.021764170080423355  Test L2 Loss :  0.03827795177698135  inv_L_scale:  [1.0, 1.0]
Epoch :  220  Time:  2.359  Rel. Train L2 Loss :  0.01941634301510122  Rel. Test L2 Loss :  0.021822999119758605  Test L2 Loss :  0.03810986965894699  inv_L_scale:  [1.0, 1.0]
Epoch :  221  Time:  2.358  Rel. Train L2 Loss :  0.01934684264163176  Rel. Test L2 Loss :  0.021825594305992128  Test L2 Loss :  0.038774337619543076  inv_L_scale:  [1.0, 1.0]
Epoch :  222  Time:  2.359  Rel. Train L2 Loss :  0.019524786530269518  Rel. Test L2 Loss :  0.022689948230981825  Test L2 Loss :  0.04054651603102684  inv_L_scale:  [1.0, 1.0]
Epoch :  223  Time:  2.359  Rel. Train L2 Loss :  0.019753602639668518  Rel. Test L2 Loss :  0.021337412223219873  Test L2 Loss :  0.0379130682349205  inv_L_scale:  [1.0, 1.0]
Epoch :  224  Time:  2.359  Rel. Train L2 Loss :  0.01960866655740473  Rel. Test L2 Loss :  0.022271834909915925  Test L2 Loss :  0.03927601218223572  inv_L_scale:  [1.0, 1.0]
Epoch :  225  Time:  2.359  Rel. Train L2 Loss :  0.019506405749254756  Rel. Test L2 Loss :  0.022336145490407945  Test L2 Loss :  0.03914150640368461  inv_L_scale:  [1.0, 1.0]
Epoch :  226  Time:  2.359  Rel. Train L2 Loss :  0.019186180267069076  Rel. Test L2 Loss :  0.021303560063242914  Test L2 Loss :  0.037383749037981036  inv_L_scale:  [1.0, 1.0]
Epoch :  227  Time:  2.359  Rel. Train L2 Loss :  0.018969150309761366  Rel. Test L2 Loss :  0.02191739246249199  Test L2 Loss :  0.038533871471881864  inv_L_scale:  [1.0, 1.0]
Epoch :  228  Time:  2.358  Rel. Train L2 Loss :  0.019157836238543193  Rel. Test L2 Loss :  0.02244561620056629  Test L2 Loss :  0.03993536293506622  inv_L_scale:  [1.0, 1.0]
Epoch :  229  Time:  2.359  Rel. Train L2 Loss :  0.019335073944595126  Rel. Test L2 Loss :  0.023146182745695115  Test L2 Loss :  0.04141144722700119  inv_L_scale:  [1.0, 1.0]
Epoch :  230  Time:  2.36  Rel. Train L2 Loss :  0.019293748984734217  Rel. Test L2 Loss :  0.0216798834502697  Test L2 Loss :  0.03808676704764366  inv_L_scale:  [1.0, 1.0]
Epoch :  231  Time:  2.359  Rel. Train L2 Loss :  0.019279155110319454  Rel. Test L2 Loss :  0.024091195166110992  Test L2 Loss :  0.042948717772960665  inv_L_scale:  [1.0, 1.0]
Epoch :  232  Time:  2.359  Rel. Train L2 Loss :  0.01889358323481348  Rel. Test L2 Loss :  0.021848768442869187  Test L2 Loss :  0.038490306735038754  inv_L_scale:  [1.0, 1.0]
Epoch :  233  Time:  2.359  Rel. Train L2 Loss :  0.01903247686723868  Rel. Test L2 Loss :  0.02039423704147339  Test L2 Loss :  0.03578829526901245  inv_L_scale:  [1.0, 1.0]
Epoch :  234  Time:  2.359  Rel. Train L2 Loss :  0.01900518914891614  Rel. Test L2 Loss :  0.020739676654338835  Test L2 Loss :  0.036545408815145494  inv_L_scale:  [1.0, 1.0]
Epoch :  235  Time:  2.359  Rel. Train L2 Loss :  0.019068528078496457  Rel. Test L2 Loss :  0.0213741035759449  Test L2 Loss :  0.03745647102594376  inv_L_scale:  [1.0, 1.0]
Epoch :  236  Time:  2.359  Rel. Train L2 Loss :  0.01921666581597593  Rel. Test L2 Loss :  0.02122853547334671  Test L2 Loss :  0.037097614854574204  inv_L_scale:  [1.0, 1.0]
Epoch :  237  Time:  2.36  Rel. Train L2 Loss :  0.018966345269646908  Rel. Test L2 Loss :  0.02081085115671158  Test L2 Loss :  0.036672984957695005  inv_L_scale:  [1.0, 1.0]
Epoch :  238  Time:  2.359  Rel. Train L2 Loss :  0.019188848005400765  Rel. Test L2 Loss :  0.020454783588647843  Test L2 Loss :  0.035851503163576125  inv_L_scale:  [1.0, 1.0]
Epoch :  239  Time:  2.359  Rel. Train L2 Loss :  0.01885387811395857  Rel. Test L2 Loss :  0.02130025789141655  Test L2 Loss :  0.037530210018157956  inv_L_scale:  [1.0, 1.0]
Epoch :  240  Time:  2.36  Rel. Train L2 Loss :  0.018554563017355072  Rel. Test L2 Loss :  0.021827015429735183  Test L2 Loss :  0.03894091188907623  inv_L_scale:  [1.0, 1.0]
Epoch :  241  Time:  2.361  Rel. Train L2 Loss :  0.018714434877038003  Rel. Test L2 Loss :  0.02622104063630104  Test L2 Loss :  0.047835218757390975  inv_L_scale:  [1.0, 1.0]
Epoch :  242  Time:  2.359  Rel. Train L2 Loss :  0.01904008829759227  Rel. Test L2 Loss :  0.020421567410230636  Test L2 Loss :  0.03573805883526802  inv_L_scale:  [1.0, 1.0]
Epoch :  243  Time:  2.36  Rel. Train L2 Loss :  0.018615202638838025  Rel. Test L2 Loss :  0.02119813293218613  Test L2 Loss :  0.037251151502132415  inv_L_scale:  [1.0, 1.0]
Epoch :  244  Time:  2.359  Rel. Train L2 Loss :  0.01895066714121236  Rel. Test L2 Loss :  0.021743243634700773  Test L2 Loss :  0.03824095606803894  inv_L_scale:  [1.0, 1.0]
Epoch :  245  Time:  2.359  Rel. Train L2 Loss :  0.01870398773915238  Rel. Test L2 Loss :  0.02137793682515621  Test L2 Loss :  0.03773249417543411  inv_L_scale:  [1.0, 1.0]
Epoch :  246  Time:  2.359  Rel. Train L2 Loss :  0.01859861752225293  Rel. Test L2 Loss :  0.02121955543756485  Test L2 Loss :  0.03780697211623192  inv_L_scale:  [1.0, 1.0]
Epoch :  247  Time:  2.359  Rel. Train L2 Loss :  0.018644241583016183  Rel. Test L2 Loss :  0.02007137417793274  Test L2 Loss :  0.035272624641656876  inv_L_scale:  [1.0, 1.0]
Epoch :  248  Time:  2.359  Rel. Train L2 Loss :  0.018709717906183667  Rel. Test L2 Loss :  0.02119308464229107  Test L2 Loss :  0.037558324337005615  inv_L_scale:  [1.0, 1.0]
Epoch :  249  Time:  2.359  Rel. Train L2 Loss :  0.018675546940002178  Rel. Test L2 Loss :  0.02192387357354164  Test L2 Loss :  0.03896849974989891  inv_L_scale:  [1.0, 1.0]
Epoch :  250  Time:  2.359  Rel. Train L2 Loss :  0.018597776032984258  Rel. Test L2 Loss :  0.02048730254173279  Test L2 Loss :  0.035842464566230775  inv_L_scale:  [1.0, 1.0]
Epoch :  251  Time:  2.36  Rel. Train L2 Loss :  0.018430298285351858  Rel. Test L2 Loss :  0.020708765611052515  Test L2 Loss :  0.036321731209754946  inv_L_scale:  [1.0, 1.0]
Epoch :  252  Time:  2.36  Rel. Train L2 Loss :  0.018470313648382822  Rel. Test L2 Loss :  0.020721593871712685  Test L2 Loss :  0.03638648360967636  inv_L_scale:  [1.0, 1.0]
Epoch :  253  Time:  2.359  Rel. Train L2 Loss :  0.01854245220621427  Rel. Test L2 Loss :  0.020974261313676835  Test L2 Loss :  0.03663721680641174  inv_L_scale:  [1.0, 1.0]
Epoch :  254  Time:  2.359  Rel. Train L2 Loss :  0.01835990441342195  Rel. Test L2 Loss :  0.02101542167365551  Test L2 Loss :  0.03675682172179222  inv_L_scale:  [1.0, 1.0]
Epoch :  255  Time:  2.359  Rel. Train L2 Loss :  0.018216400866707165  Rel. Test L2 Loss :  0.020840562507510187  Test L2 Loss :  0.03651492595672608  inv_L_scale:  [1.0, 1.0]
Epoch :  256  Time:  2.359  Rel. Train L2 Loss :  0.018188640077908835  Rel. Test L2 Loss :  0.021269760131835937  Test L2 Loss :  0.03746280863881111  inv_L_scale:  [1.0, 1.0]
Epoch :  257  Time:  2.359  Rel. Train L2 Loss :  0.01844917965432008  Rel. Test L2 Loss :  0.021617015674710274  Test L2 Loss :  0.037868981957435606  inv_L_scale:  [1.0, 1.0]
Epoch :  258  Time:  2.359  Rel. Train L2 Loss :  0.018493750881817605  Rel. Test L2 Loss :  0.021121875643730165  Test L2 Loss :  0.03709241703152657  inv_L_scale:  [1.0, 1.0]
Epoch :  259  Time:  2.359  Rel. Train L2 Loss :  0.01821425845225652  Rel. Test L2 Loss :  0.02103596232831478  Test L2 Loss :  0.03700247824192047  inv_L_scale:  [1.0, 1.0]
Epoch :  260  Time:  2.359  Rel. Train L2 Loss :  0.018360519723759756  Rel. Test L2 Loss :  0.02053750291466713  Test L2 Loss :  0.03616218596696854  inv_L_scale:  [1.0, 1.0]
Epoch :  261  Time:  2.359  Rel. Train L2 Loss :  0.01810959904558129  Rel. Test L2 Loss :  0.02089692488312721  Test L2 Loss :  0.036672831773757936  inv_L_scale:  [1.0, 1.0]
Epoch :  262  Time:  2.36  Rel. Train L2 Loss :  0.018152151273356544  Rel. Test L2 Loss :  0.02040690802037716  Test L2 Loss :  0.03630038857460022  inv_L_scale:  [1.0, 1.0]
Epoch :  263  Time:  2.36  Rel. Train L2 Loss :  0.0183755197458797  Rel. Test L2 Loss :  0.020947169661521912  Test L2 Loss :  0.03679044216871261  inv_L_scale:  [1.0, 1.0]
Epoch :  264  Time:  2.359  Rel. Train L2 Loss :  0.017978207940856614  Rel. Test L2 Loss :  0.020631854012608527  Test L2 Loss :  0.036094113737344745  inv_L_scale:  [1.0, 1.0]
Epoch :  265  Time:  2.359  Rel. Train L2 Loss :  0.018024106464452214  Rel. Test L2 Loss :  0.020171864554286004  Test L2 Loss :  0.035332792848348615  inv_L_scale:  [1.0, 1.0]
Epoch :  266  Time:  2.359  Rel. Train L2 Loss :  0.018045244183805254  Rel. Test L2 Loss :  0.02036498598754406  Test L2 Loss :  0.035754062831401826  inv_L_scale:  [1.0, 1.0]
Epoch :  267  Time:  2.359  Rel. Train L2 Loss :  0.017952152912815413  Rel. Test L2 Loss :  0.019889128431677817  Test L2 Loss :  0.03525877773761749  inv_L_scale:  [1.0, 1.0]
Epoch :  268  Time:  2.359  Rel. Train L2 Loss :  0.017836432986789278  Rel. Test L2 Loss :  0.020286922454833985  Test L2 Loss :  0.03536987140774727  inv_L_scale:  [1.0, 1.0]
Epoch :  269  Time:  2.359  Rel. Train L2 Loss :  0.01777896842194928  Rel. Test L2 Loss :  0.020183933898806572  Test L2 Loss :  0.03548101469874382  inv_L_scale:  [1.0, 1.0]
Epoch :  270  Time:  2.359  Rel. Train L2 Loss :  0.018168457142180867  Rel. Test L2 Loss :  0.020365725010633468  Test L2 Loss :  0.03568869739770889  inv_L_scale:  [1.0, 1.0]
Epoch :  271  Time:  2.358  Rel. Train L2 Loss :  0.01815517650710212  Rel. Test L2 Loss :  0.020020869970321657  Test L2 Loss :  0.0351415154337883  inv_L_scale:  [1.0, 1.0]
Epoch :  272  Time:  2.359  Rel. Train L2 Loss :  0.017808011182480387  Rel. Test L2 Loss :  0.021053387746214867  Test L2 Loss :  0.03728105381131172  inv_L_scale:  [1.0, 1.0]
Epoch :  273  Time:  2.359  Rel. Train L2 Loss :  0.017955236120356453  Rel. Test L2 Loss :  0.023276900053024293  Test L2 Loss :  0.041502161473035815  inv_L_scale:  [1.0, 1.0]
Epoch :  274  Time:  2.359  Rel. Train L2 Loss :  0.018067857267128097  Rel. Test L2 Loss :  0.019910760149359705  Test L2 Loss :  0.034783334881067274  inv_L_scale:  [1.0, 1.0]
Epoch :  275  Time:  2.359  Rel. Train L2 Loss :  0.017692256114549106  Rel. Test L2 Loss :  0.019899034276604652  Test L2 Loss :  0.03465855121612549  inv_L_scale:  [1.0, 1.0]
Epoch :  276  Time:  2.359  Rel. Train L2 Loss :  0.0178287057330211  Rel. Test L2 Loss :  0.020488157868385315  Test L2 Loss :  0.03604272246360779  inv_L_scale:  [1.0, 1.0]
Epoch :  277  Time:  2.359  Rel. Train L2 Loss :  0.017735068396561676  Rel. Test L2 Loss :  0.02033978432416916  Test L2 Loss :  0.03561520516872406  inv_L_scale:  [1.0, 1.0]
Epoch :  278  Time:  2.359  Rel. Train L2 Loss :  0.0177007371518347  Rel. Test L2 Loss :  0.02038015514612198  Test L2 Loss :  0.03606650933623314  inv_L_scale:  [1.0, 1.0]
Epoch :  279  Time:  2.359  Rel. Train L2 Loss :  0.017907968958218893  Rel. Test L2 Loss :  0.020213950872421265  Test L2 Loss :  0.03543638542294502  inv_L_scale:  [1.0, 1.0]
Epoch :  280  Time:  2.359  Rel. Train L2 Loss :  0.01768236523701085  Rel. Test L2 Loss :  0.02019137464463711  Test L2 Loss :  0.03527145594358444  inv_L_scale:  [1.0, 1.0]
Epoch :  281  Time:  2.36  Rel. Train L2 Loss :  0.017657715338799687  Rel. Test L2 Loss :  0.019697734788060188  Test L2 Loss :  0.034432345181703565  inv_L_scale:  [1.0, 1.0]
Epoch :  282  Time:  2.359  Rel. Train L2 Loss :  0.01758808312730657  Rel. Test L2 Loss :  0.0200850710272789  Test L2 Loss :  0.03512451946735382  inv_L_scale:  [1.0, 1.0]
Epoch :  283  Time:  2.359  Rel. Train L2 Loss :  0.017395284349719684  Rel. Test L2 Loss :  0.01976097986102104  Test L2 Loss :  0.0345974425971508  inv_L_scale:  [1.0, 1.0]
Epoch :  284  Time:  2.361  Rel. Train L2 Loss :  0.017511136912637285  Rel. Test L2 Loss :  0.019347725212574007  Test L2 Loss :  0.033973016142845154  inv_L_scale:  [1.0, 1.0]
Epoch :  285  Time:  2.36  Rel. Train L2 Loss :  0.01746110292772452  Rel. Test L2 Loss :  0.020153280198574066  Test L2 Loss :  0.035606909096241  inv_L_scale:  [1.0, 1.0]
Epoch :  286  Time:  2.359  Rel. Train L2 Loss :  0.01746357849902577  Rel. Test L2 Loss :  0.019300848245620728  Test L2 Loss :  0.033855940103530886  inv_L_scale:  [1.0, 1.0]
Epoch :  287  Time:  2.359  Rel. Train L2 Loss :  0.017386633389525945  Rel. Test L2 Loss :  0.021233240514993666  Test L2 Loss :  0.03779968410730362  inv_L_scale:  [1.0, 1.0]
Epoch :  288  Time:  2.359  Rel. Train L2 Loss :  0.017735119155711597  Rel. Test L2 Loss :  0.020109038129448892  Test L2 Loss :  0.03520137026906014  inv_L_scale:  [1.0, 1.0]
Epoch :  289  Time:  2.359  Rel. Train L2 Loss :  0.017365366708901195  Rel. Test L2 Loss :  0.019645252078771592  Test L2 Loss :  0.034246696382761004  inv_L_scale:  [1.0, 1.0]
Epoch :  290  Time:  2.359  Rel. Train L2 Loss :  0.01738830035759343  Rel. Test L2 Loss :  0.020166632756590842  Test L2 Loss :  0.03548257678747177  inv_L_scale:  [1.0, 1.0]
Epoch :  291  Time:  2.359  Rel. Train L2 Loss :  0.01745123487379816  Rel. Test L2 Loss :  0.02040027305483818  Test L2 Loss :  0.03591109097003937  inv_L_scale:  [1.0, 1.0]
Epoch :  292  Time:  2.359  Rel. Train L2 Loss :  0.01729227387242847  Rel. Test L2 Loss :  0.019298713505268097  Test L2 Loss :  0.0337864588201046  inv_L_scale:  [1.0, 1.0]
Epoch :  293  Time:  2.359  Rel. Train L2 Loss :  0.017561636434661018  Rel. Test L2 Loss :  0.018828750848770143  Test L2 Loss :  0.032812690883874895  inv_L_scale:  [1.0, 1.0]
Epoch :  294  Time:  2.359  Rel. Train L2 Loss :  0.017355955574247572  Rel. Test L2 Loss :  0.019715681001544  Test L2 Loss :  0.034537263214588165  inv_L_scale:  [1.0, 1.0]
Epoch :  295  Time:  2.36  Rel. Train L2 Loss :  0.017140225850873523  Rel. Test L2 Loss :  0.02037119448184967  Test L2 Loss :  0.03602355971932411  inv_L_scale:  [1.0, 1.0]
Epoch :  296  Time:  2.359  Rel. Train L2 Loss :  0.01741312437587314  Rel. Test L2 Loss :  0.021474974155426027  Test L2 Loss :  0.03794498771429062  inv_L_scale:  [1.0, 1.0]
Epoch :  297  Time:  2.359  Rel. Train L2 Loss :  0.01727614324953821  Rel. Test L2 Loss :  0.019421799778938292  Test L2 Loss :  0.0338434948027134  inv_L_scale:  [1.0, 1.0]
Epoch :  298  Time:  2.359  Rel. Train L2 Loss :  0.01713183885647191  Rel. Test L2 Loss :  0.02021891698241234  Test L2 Loss :  0.03549138262867928  inv_L_scale:  [1.0, 1.0]
Epoch :  299  Time:  2.359  Rel. Train L2 Loss :  0.01708564786447419  Rel. Test L2 Loss :  0.019578598588705063  Test L2 Loss :  0.03431915804743767  inv_L_scale:  [1.0, 1.0]
Epoch :  300  Time:  2.359  Rel. Train L2 Loss :  0.01728885220984618  Rel. Test L2 Loss :  0.018947628512978553  Test L2 Loss :  0.032932318449020385  inv_L_scale:  [1.0, 1.0]
Epoch :  301  Time:  2.359  Rel. Train L2 Loss :  0.01713894623849127  Rel. Test L2 Loss :  0.019688480496406556  Test L2 Loss :  0.034477760195732114  inv_L_scale:  [1.0, 1.0]
Epoch :  302  Time:  2.359  Rel. Train L2 Loss :  0.017026082923014958  Rel. Test L2 Loss :  0.01951175816357136  Test L2 Loss :  0.034203524738550185  inv_L_scale:  [1.0, 1.0]
Epoch :  303  Time:  2.359  Rel. Train L2 Loss :  0.01714017689228058  Rel. Test L2 Loss :  0.018857165426015853  Test L2 Loss :  0.03296944499015808  inv_L_scale:  [1.0, 1.0]
Epoch :  304  Time:  2.359  Rel. Train L2 Loss :  0.016891751827465162  Rel. Test L2 Loss :  0.019614654406905175  Test L2 Loss :  0.03414760559797287  inv_L_scale:  [1.0, 1.0]
Epoch :  305  Time:  2.359  Rel. Train L2 Loss :  0.016880248404211467  Rel. Test L2 Loss :  0.020205314010381697  Test L2 Loss :  0.03556070268154144  inv_L_scale:  [1.0, 1.0]
Epoch :  306  Time:  2.361  Rel. Train L2 Loss :  0.016911263060238626  Rel. Test L2 Loss :  0.01924510858952999  Test L2 Loss :  0.03350271388888359  inv_L_scale:  [1.0, 1.0]
Epoch :  307  Time:  2.36  Rel. Train L2 Loss :  0.01692648751868142  Rel. Test L2 Loss :  0.01932926297187805  Test L2 Loss :  0.03377274781465531  inv_L_scale:  [1.0, 1.0]
Epoch :  308  Time:  2.359  Rel. Train L2 Loss :  0.016974709125028718  Rel. Test L2 Loss :  0.02041788339614868  Test L2 Loss :  0.036133760064840315  inv_L_scale:  [1.0, 1.0]
Epoch :  309  Time:  2.358  Rel. Train L2 Loss :  0.017031636974877782  Rel. Test L2 Loss :  0.019296514391899108  Test L2 Loss :  0.033561509996652604  inv_L_scale:  [1.0, 1.0]
Epoch :  310  Time:  2.359  Rel. Train L2 Loss :  0.01685538020398882  Rel. Test L2 Loss :  0.01934731677174568  Test L2 Loss :  0.03371877551078797  inv_L_scale:  [1.0, 1.0]
Epoch :  311  Time:  2.359  Rel. Train L2 Loss :  0.016738690187533697  Rel. Test L2 Loss :  0.0189519302546978  Test L2 Loss :  0.03317057050764561  inv_L_scale:  [1.0, 1.0]
Epoch :  312  Time:  2.359  Rel. Train L2 Loss :  0.01693868694206079  Rel. Test L2 Loss :  0.019815116077661513  Test L2 Loss :  0.03471640452742577  inv_L_scale:  [1.0, 1.0]
Epoch :  313  Time:  2.359  Rel. Train L2 Loss :  0.016890022936794494  Rel. Test L2 Loss :  0.019539823159575462  Test L2 Loss :  0.03446024730801582  inv_L_scale:  [1.0, 1.0]
Epoch :  314  Time:  2.359  Rel. Train L2 Loss :  0.016749444463186793  Rel. Test L2 Loss :  0.01889041766524315  Test L2 Loss :  0.03306170269846916  inv_L_scale:  [1.0, 1.0]
Epoch :  315  Time:  2.358  Rel. Train L2 Loss :  0.01673599417010943  Rel. Test L2 Loss :  0.018948082625865937  Test L2 Loss :  0.033101274371147155  inv_L_scale:  [1.0, 1.0]
Epoch :  316  Time:  2.359  Rel. Train L2 Loss :  0.01689462848007679  Rel. Test L2 Loss :  0.0188519536703825  Test L2 Loss :  0.032981426566839216  inv_L_scale:  [1.0, 1.0]
Epoch :  317  Time:  2.36  Rel. Train L2 Loss :  0.01664645846105284  Rel. Test L2 Loss :  0.02009734570980072  Test L2 Loss :  0.03553864240646362  inv_L_scale:  [1.0, 1.0]
Epoch :  318  Time:  2.359  Rel. Train L2 Loss :  0.0167548921952645  Rel. Test L2 Loss :  0.01897933252155781  Test L2 Loss :  0.033302477151155474  inv_L_scale:  [1.0, 1.0]
Epoch :  319  Time:  2.359  Rel. Train L2 Loss :  0.016605456612176366  Rel. Test L2 Loss :  0.01880551390349865  Test L2 Loss :  0.03285725206136703  inv_L_scale:  [1.0, 1.0]
Epoch :  320  Time:  2.358  Rel. Train L2 Loss :  0.01655447829928663  Rel. Test L2 Loss :  0.01867596685886383  Test L2 Loss :  0.032484203577041626  inv_L_scale:  [1.0, 1.0]
Epoch :  321  Time:  2.359  Rel. Train L2 Loss :  0.016549000963568688  Rel. Test L2 Loss :  0.019599550291895865  Test L2 Loss :  0.03418365806341171  inv_L_scale:  [1.0, 1.0]
Epoch :  322  Time:  2.358  Rel. Train L2 Loss :  0.016596559228168592  Rel. Test L2 Loss :  0.01903151497244835  Test L2 Loss :  0.03323980093002319  inv_L_scale:  [1.0, 1.0]
Epoch :  323  Time:  2.359  Rel. Train L2 Loss :  0.016496154616276425  Rel. Test L2 Loss :  0.018716932386159898  Test L2 Loss :  0.03262248441576958  inv_L_scale:  [1.0, 1.0]
Epoch :  324  Time:  2.359  Rel. Train L2 Loss :  0.016512244534161356  Rel. Test L2 Loss :  0.018921316638588905  Test L2 Loss :  0.032874912470579144  inv_L_scale:  [1.0, 1.0]
Epoch :  325  Time:  2.359  Rel. Train L2 Loss :  0.016494239709443515  Rel. Test L2 Loss :  0.01867091439664364  Test L2 Loss :  0.03259302794933319  inv_L_scale:  [1.0, 1.0]
Epoch :  326  Time:  2.358  Rel. Train L2 Loss :  0.01662895386417707  Rel. Test L2 Loss :  0.018536563962697983  Test L2 Loss :  0.03228713646531105  inv_L_scale:  [1.0, 1.0]
Epoch :  327  Time:  2.359  Rel. Train L2 Loss :  0.016507668279939228  Rel. Test L2 Loss :  0.018500677049160003  Test L2 Loss :  0.03229393318295479  inv_L_scale:  [1.0, 1.0]
Epoch :  328  Time:  2.361  Rel. Train L2 Loss :  0.01649225938651297  Rel. Test L2 Loss :  0.01894891567528248  Test L2 Loss :  0.03302842527627945  inv_L_scale:  [1.0, 1.0]
Epoch :  329  Time:  2.36  Rel. Train L2 Loss :  0.016361453764968448  Rel. Test L2 Loss :  0.01870056740939617  Test L2 Loss :  0.03262318700551987  inv_L_scale:  [1.0, 1.0]
Epoch :  330  Time:  2.359  Rel. Train L2 Loss :  0.01636913114123874  Rel. Test L2 Loss :  0.018723694160580635  Test L2 Loss :  0.0325424787402153  inv_L_scale:  [1.0, 1.0]
Epoch :  331  Time:  2.359  Rel. Train L2 Loss :  0.016421995121571754  Rel. Test L2 Loss :  0.018460652530193328  Test L2 Loss :  0.03222038999199867  inv_L_scale:  [1.0, 1.0]
Epoch :  332  Time:  2.359  Rel. Train L2 Loss :  0.016438266866736943  Rel. Test L2 Loss :  0.018904690593481065  Test L2 Loss :  0.032918864041566846  inv_L_scale:  [1.0, 1.0]
Epoch :  333  Time:  2.359  Rel. Train L2 Loss :  0.01632708731210894  Rel. Test L2 Loss :  0.018088342696428297  Test L2 Loss :  0.03150672622025013  inv_L_scale:  [1.0, 1.0]
Epoch :  334  Time:  2.359  Rel. Train L2 Loss :  0.016340065598487854  Rel. Test L2 Loss :  0.01903017982840538  Test L2 Loss :  0.03314690604805946  inv_L_scale:  [1.0, 1.0]
Epoch :  335  Time:  2.359  Rel. Train L2 Loss :  0.016338745860589875  Rel. Test L2 Loss :  0.018639903739094733  Test L2 Loss :  0.032469776421785355  inv_L_scale:  [1.0, 1.0]
Epoch :  336  Time:  2.359  Rel. Train L2 Loss :  0.01632090484102567  Rel. Test L2 Loss :  0.01866573005914688  Test L2 Loss :  0.032579575926065446  inv_L_scale:  [1.0, 1.0]
Epoch :  337  Time:  2.358  Rel. Train L2 Loss :  0.01637862098713716  Rel. Test L2 Loss :  0.018230141997337343  Test L2 Loss :  0.031773809790611264  inv_L_scale:  [1.0, 1.0]
Epoch :  338  Time:  2.359  Rel. Train L2 Loss :  0.016230097115039824  Rel. Test L2 Loss :  0.01871668331325054  Test L2 Loss :  0.03266837373375893  inv_L_scale:  [1.0, 1.0]
Epoch :  339  Time:  2.36  Rel. Train L2 Loss :  0.01623230791754193  Rel. Test L2 Loss :  0.0183718853443861  Test L2 Loss :  0.03191042870283127  inv_L_scale:  [1.0, 1.0]
Epoch :  340  Time:  2.359  Rel. Train L2 Loss :  0.016182289140092003  Rel. Test L2 Loss :  0.018765304908156394  Test L2 Loss :  0.03260322853922844  inv_L_scale:  [1.0, 1.0]
Epoch :  341  Time:  2.359  Rel. Train L2 Loss :  0.016205407480398813  Rel. Test L2 Loss :  0.018225922510027887  Test L2 Loss :  0.031793998777866365  inv_L_scale:  [1.0, 1.0]
Epoch :  342  Time:  2.359  Rel. Train L2 Loss :  0.01611677250928349  Rel. Test L2 Loss :  0.018600779622793197  Test L2 Loss :  0.03242461152374745  inv_L_scale:  [1.0, 1.0]
Epoch :  343  Time:  2.358  Rel. Train L2 Loss :  0.01615772792862521  Rel. Test L2 Loss :  0.018313731998205185  Test L2 Loss :  0.03188833400607109  inv_L_scale:  [1.0, 1.0]
Epoch :  344  Time:  2.359  Rel. Train L2 Loss :  0.01622572262254026  Rel. Test L2 Loss :  0.018499628379940986  Test L2 Loss :  0.032420966923236844  inv_L_scale:  [1.0, 1.0]
Epoch :  345  Time:  2.359  Rel. Train L2 Loss :  0.016104074327482117  Rel. Test L2 Loss :  0.018760320097208023  Test L2 Loss :  0.03281216099858284  inv_L_scale:  [1.0, 1.0]
Epoch :  346  Time:  2.359  Rel. Train L2 Loss :  0.016071671172976493  Rel. Test L2 Loss :  0.018304894641041757  Test L2 Loss :  0.03180976390838623  inv_L_scale:  [1.0, 1.0]
Epoch :  347  Time:  2.359  Rel. Train L2 Loss :  0.016028045295841165  Rel. Test L2 Loss :  0.01789986677467823  Test L2 Loss :  0.031175056099891664  inv_L_scale:  [1.0, 1.0]
Epoch :  348  Time:  2.358  Rel. Train L2 Loss :  0.016052141971886157  Rel. Test L2 Loss :  0.018379832953214645  Test L2 Loss :  0.032063693031668665  inv_L_scale:  [1.0, 1.0]
Epoch :  349  Time:  2.359  Rel. Train L2 Loss :  0.016024965734945402  Rel. Test L2 Loss :  0.018285301178693772  Test L2 Loss :  0.031800051927566526  inv_L_scale:  [1.0, 1.0]
Epoch :  350  Time:  2.361  Rel. Train L2 Loss :  0.015944202956226138  Rel. Test L2 Loss :  0.018320037275552748  Test L2 Loss :  0.03182645842432976  inv_L_scale:  [1.0, 1.0]
Epoch :  351  Time:  2.36  Rel. Train L2 Loss :  0.01596732990609275  Rel. Test L2 Loss :  0.018258847966790198  Test L2 Loss :  0.031871771439909935  inv_L_scale:  [1.0, 1.0]
Epoch :  352  Time:  2.359  Rel. Train L2 Loss :  0.015988369223972163  Rel. Test L2 Loss :  0.018214340284466744  Test L2 Loss :  0.031787804067134856  inv_L_scale:  [1.0, 1.0]
Epoch :  353  Time:  2.359  Rel. Train L2 Loss :  0.015990773890581397  Rel. Test L2 Loss :  0.018143995180726052  Test L2 Loss :  0.03161773309111595  inv_L_scale:  [1.0, 1.0]
Epoch :  354  Time:  2.359  Rel. Train L2 Loss :  0.015890537338952224  Rel. Test L2 Loss :  0.018370789140462876  Test L2 Loss :  0.03179340064525604  inv_L_scale:  [1.0, 1.0]
Epoch :  355  Time:  2.359  Rel. Train L2 Loss :  0.01590386373301347  Rel. Test L2 Loss :  0.01825674019753933  Test L2 Loss :  0.03169584982097149  inv_L_scale:  [1.0, 1.0]
Epoch :  356  Time:  2.359  Rel. Train L2 Loss :  0.015779654896921583  Rel. Test L2 Loss :  0.018101747855544092  Test L2 Loss :  0.031439624279737476  inv_L_scale:  [1.0, 1.0]
Epoch :  357  Time:  2.359  Rel. Train L2 Loss :  0.015848889574408533  Rel. Test L2 Loss :  0.01826102890074253  Test L2 Loss :  0.031810010075569155  inv_L_scale:  [1.0, 1.0]
Epoch :  358  Time:  2.359  Rel. Train L2 Loss :  0.015839672312140465  Rel. Test L2 Loss :  0.017993505075573922  Test L2 Loss :  0.03128133334219456  inv_L_scale:  [1.0, 1.0]
Epoch :  359  Time:  2.359  Rel. Train L2 Loss :  0.015859014532632297  Rel. Test L2 Loss :  0.01867675095796585  Test L2 Loss :  0.03282573163509369  inv_L_scale:  [1.0, 1.0]
Epoch :  360  Time:  2.359  Rel. Train L2 Loss :  0.015969471145007345  Rel. Test L2 Loss :  0.01788807861506939  Test L2 Loss :  0.031125355511903763  inv_L_scale:  [1.0, 1.0]
Epoch :  361  Time:  2.36  Rel. Train L2 Loss :  0.015781316550241575  Rel. Test L2 Loss :  0.018039458766579627  Test L2 Loss :  0.03134036794304848  inv_L_scale:  [1.0, 1.0]
Epoch :  362  Time:  2.359  Rel. Train L2 Loss :  0.015853217567006746  Rel. Test L2 Loss :  0.0180808524787426  Test L2 Loss :  0.03132918104529381  inv_L_scale:  [1.0, 1.0]
Epoch :  363  Time:  2.359  Rel. Train L2 Loss :  0.015679430891242293  Rel. Test L2 Loss :  0.018166224285960198  Test L2 Loss :  0.03157841667532921  inv_L_scale:  [1.0, 1.0]
Epoch :  364  Time:  2.359  Rel. Train L2 Loss :  0.015758014279935097  Rel. Test L2 Loss :  0.01808759681880474  Test L2 Loss :  0.031432579755783084  inv_L_scale:  [1.0, 1.0]
Epoch :  365  Time:  2.359  Rel. Train L2 Loss :  0.0156447661585278  Rel. Test L2 Loss :  0.018014448657631875  Test L2 Loss :  0.0313626928627491  inv_L_scale:  [1.0, 1.0]
Epoch :  366  Time:  2.359  Rel. Train L2 Loss :  0.015691347709960408  Rel. Test L2 Loss :  0.017815905436873437  Test L2 Loss :  0.03096809297800064  inv_L_scale:  [1.0, 1.0]
Epoch :  367  Time:  2.359  Rel. Train L2 Loss :  0.01564980023437076  Rel. Test L2 Loss :  0.01792271599173546  Test L2 Loss :  0.031146437525749207  inv_L_scale:  [1.0, 1.0]
Epoch :  368  Time:  2.359  Rel. Train L2 Loss :  0.01559654428727097  Rel. Test L2 Loss :  0.017926211208105086  Test L2 Loss :  0.030978576466441154  inv_L_scale:  [1.0, 1.0]
Epoch :  369  Time:  2.359  Rel. Train L2 Loss :  0.01568949150956339  Rel. Test L2 Loss :  0.017887243777513506  Test L2 Loss :  0.031068754345178605  inv_L_scale:  [1.0, 1.0]
Epoch :  370  Time:  2.359  Rel. Train L2 Loss :  0.01560158595856693  Rel. Test L2 Loss :  0.01793876923620701  Test L2 Loss :  0.031171220988035202  inv_L_scale:  [1.0, 1.0]
Epoch :  371  Time:  2.359  Rel. Train L2 Loss :  0.015607464520467653  Rel. Test L2 Loss :  0.017994825169444083  Test L2 Loss :  0.03134374350309372  inv_L_scale:  [1.0, 1.0]
Epoch :  372  Time:  2.361  Rel. Train L2 Loss :  0.015572691617740525  Rel. Test L2 Loss :  0.018009285032749175  Test L2 Loss :  0.031166199892759323  inv_L_scale:  [1.0, 1.0]
Epoch :  373  Time:  2.359  Rel. Train L2 Loss :  0.015611555907461378  Rel. Test L2 Loss :  0.01796087272465229  Test L2 Loss :  0.03126329571008682  inv_L_scale:  [1.0, 1.0]
Epoch :  374  Time:  2.359  Rel. Train L2 Loss :  0.015553332128458552  Rel. Test L2 Loss :  0.01788827545940876  Test L2 Loss :  0.031078639924526214  inv_L_scale:  [1.0, 1.0]
Epoch :  375  Time:  2.358  Rel. Train L2 Loss :  0.015594976366394096  Rel. Test L2 Loss :  0.01836952827870846  Test L2 Loss :  0.032150827050209045  inv_L_scale:  [1.0, 1.0]
Epoch :  376  Time:  2.358  Rel. Train L2 Loss :  0.015563293827904594  Rel. Test L2 Loss :  0.017813125252723695  Test L2 Loss :  0.030934803113341333  inv_L_scale:  [1.0, 1.0]
Epoch :  377  Time:  2.359  Rel. Train L2 Loss :  0.015501702432003286  Rel. Test L2 Loss :  0.017832414284348487  Test L2 Loss :  0.030941722989082335  inv_L_scale:  [1.0, 1.0]
Epoch :  378  Time:  2.359  Rel. Train L2 Loss :  0.015448528056343397  Rel. Test L2 Loss :  0.017793930992484094  Test L2 Loss :  0.030939038395881652  inv_L_scale:  [1.0, 1.0]
Epoch :  379  Time:  2.359  Rel. Train L2 Loss :  0.015465573714011246  Rel. Test L2 Loss :  0.018138688057661057  Test L2 Loss :  0.03161129459738731  inv_L_scale:  [1.0, 1.0]
Epoch :  380  Time:  2.359  Rel. Train L2 Loss :  0.015421734071440167  Rel. Test L2 Loss :  0.0175295839458704  Test L2 Loss :  0.03034917965531349  inv_L_scale:  [1.0, 1.0]
Epoch :  381  Time:  2.359  Rel. Train L2 Loss :  0.015438619926571846  Rel. Test L2 Loss :  0.017823209539055824  Test L2 Loss :  0.030877294093370436  inv_L_scale:  [1.0, 1.0]
Epoch :  382  Time:  2.359  Rel. Train L2 Loss :  0.01538576967186398  Rel. Test L2 Loss :  0.017971942201256752  Test L2 Loss :  0.03134760931134224  inv_L_scale:  [1.0, 1.0]
Epoch :  383  Time:  2.36  Rel. Train L2 Loss :  0.01542470481660631  Rel. Test L2 Loss :  0.01771632820367813  Test L2 Loss :  0.030731932520866395  inv_L_scale:  [1.0, 1.0]
Epoch :  384  Time:  2.359  Rel. Train L2 Loss :  0.015323715640438927  Rel. Test L2 Loss :  0.01767415776848793  Test L2 Loss :  0.03064141869544983  inv_L_scale:  [1.0, 1.0]
Epoch :  385  Time:  2.359  Rel. Train L2 Loss :  0.015356042178140746  Rel. Test L2 Loss :  0.01749251179397106  Test L2 Loss :  0.03041590452194214  inv_L_scale:  [1.0, 1.0]
Epoch :  386  Time:  2.359  Rel. Train L2 Loss :  0.015401406966977648  Rel. Test L2 Loss :  0.01762963503599167  Test L2 Loss :  0.030664897933602334  inv_L_scale:  [1.0, 1.0]
Epoch :  387  Time:  2.359  Rel. Train L2 Loss :  0.015275001203020415  Rel. Test L2 Loss :  0.01763488456606865  Test L2 Loss :  0.030628628060221673  inv_L_scale:  [1.0, 1.0]
Epoch :  388  Time:  2.359  Rel. Train L2 Loss :  0.015284014344215393  Rel. Test L2 Loss :  0.017537303641438483  Test L2 Loss :  0.030449036955833435  inv_L_scale:  [1.0, 1.0]
Epoch :  389  Time:  2.359  Rel. Train L2 Loss :  0.015267611891031265  Rel. Test L2 Loss :  0.01761544995009899  Test L2 Loss :  0.030499057546257972  inv_L_scale:  [1.0, 1.0]
Epoch :  390  Time:  2.359  Rel. Train L2 Loss :  0.015318894311785698  Rel. Test L2 Loss :  0.01787655137479305  Test L2 Loss :  0.031184409856796266  inv_L_scale:  [1.0, 1.0]
Epoch :  391  Time:  2.359  Rel. Train L2 Loss :  0.015296102489034335  Rel. Test L2 Loss :  0.017523784637451172  Test L2 Loss :  0.030382615402340888  inv_L_scale:  [1.0, 1.0]
Epoch :  392  Time:  2.359  Rel. Train L2 Loss :  0.015216565570897527  Rel. Test L2 Loss :  0.017793291062116624  Test L2 Loss :  0.03085218146443367  inv_L_scale:  [1.0, 1.0]
Epoch :  393  Time:  2.359  Rel. Train L2 Loss :  0.015225054381622208  Rel. Test L2 Loss :  0.01749915361404419  Test L2 Loss :  0.030325369238853456  inv_L_scale:  [1.0, 1.0]
Epoch :  394  Time:  2.361  Rel. Train L2 Loss :  0.015159300987919172  Rel. Test L2 Loss :  0.017550944685935974  Test L2 Loss :  0.03050480380654335  inv_L_scale:  [1.0, 1.0]
Epoch :  395  Time:  2.36  Rel. Train L2 Loss :  0.015170992948114873  Rel. Test L2 Loss :  0.0176790551841259  Test L2 Loss :  0.030590653270483017  inv_L_scale:  [1.0, 1.0]
Epoch :  396  Time:  2.359  Rel. Train L2 Loss :  0.015248610613246758  Rel. Test L2 Loss :  0.017534852474927903  Test L2 Loss :  0.03032196544110775  inv_L_scale:  [1.0, 1.0]
Epoch :  397  Time:  2.359  Rel. Train L2 Loss :  0.015152199574642712  Rel. Test L2 Loss :  0.017634690925478935  Test L2 Loss :  0.03072310745716095  inv_L_scale:  [1.0, 1.0]
Epoch :  398  Time:  2.359  Rel. Train L2 Loss :  0.015117882970306609  Rel. Test L2 Loss :  0.017595215141773222  Test L2 Loss :  0.030531700998544693  inv_L_scale:  [1.0, 1.0]
Epoch :  399  Time:  2.359  Rel. Train L2 Loss :  0.015147457619508108  Rel. Test L2 Loss :  0.017594211623072623  Test L2 Loss :  0.030515603572130203  inv_L_scale:  [1.0, 1.0]
Epoch :  400  Time:  2.359  Rel. Train L2 Loss :  0.015100401809646023  Rel. Test L2 Loss :  0.01746375538408756  Test L2 Loss :  0.030404886156320574  inv_L_scale:  [1.0, 1.0]
Epoch :  401  Time:  2.359  Rel. Train L2 Loss :  0.01508632414870792  Rel. Test L2 Loss :  0.017409045323729513  Test L2 Loss :  0.03020753487944603  inv_L_scale:  [1.0, 1.0]
Epoch :  402  Time:  2.359  Rel. Train L2 Loss :  0.015028414390981197  Rel. Test L2 Loss :  0.017550245970487596  Test L2 Loss :  0.030331486389040947  inv_L_scale:  [1.0, 1.0]
Epoch :  403  Time:  2.359  Rel. Train L2 Loss :  0.015048247327407201  Rel. Test L2 Loss :  0.01745596930384636  Test L2 Loss :  0.030340498387813566  inv_L_scale:  [1.0, 1.0]
Epoch :  404  Time:  2.359  Rel. Train L2 Loss :  0.015045332693391375  Rel. Test L2 Loss :  0.017377792000770567  Test L2 Loss :  0.03017166957259178  inv_L_scale:  [1.0, 1.0]
Epoch :  405  Time:  2.36  Rel. Train L2 Loss :  0.015023954982558886  Rel. Test L2 Loss :  0.017504092678427695  Test L2 Loss :  0.030276466831564902  inv_L_scale:  [1.0, 1.0]
Epoch :  406  Time:  2.359  Rel. Train L2 Loss :  0.015070241490999857  Rel. Test L2 Loss :  0.017355657666921615  Test L2 Loss :  0.030071075558662414  inv_L_scale:  [1.0, 1.0]
Epoch :  407  Time:  2.358  Rel. Train L2 Loss :  0.015026732521752517  Rel. Test L2 Loss :  0.017307570800185204  Test L2 Loss :  0.030017735511064528  inv_L_scale:  [1.0, 1.0]
Epoch :  408  Time:  2.359  Rel. Train L2 Loss :  0.015015262398454878  Rel. Test L2 Loss :  0.017347122803330423  Test L2 Loss :  0.030071673393249513  inv_L_scale:  [1.0, 1.0]
Epoch :  409  Time:  2.359  Rel. Train L2 Loss :  0.014971425260106723  Rel. Test L2 Loss :  0.017506990283727646  Test L2 Loss :  0.03031291760504246  inv_L_scale:  [1.0, 1.0]
Epoch :  410  Time:  2.359  Rel. Train L2 Loss :  0.014971093932787578  Rel. Test L2 Loss :  0.01743073746562004  Test L2 Loss :  0.030286688208580017  inv_L_scale:  [1.0, 1.0]
Epoch :  411  Time:  2.359  Rel. Train L2 Loss :  0.014979490720563465  Rel. Test L2 Loss :  0.017328446656465532  Test L2 Loss :  0.030037603229284286  inv_L_scale:  [1.0, 1.0]
Epoch :  412  Time:  2.359  Rel. Train L2 Loss :  0.01492710186375512  Rel. Test L2 Loss :  0.017373789474368094  Test L2 Loss :  0.030078492313623428  inv_L_scale:  [1.0, 1.0]
Epoch :  413  Time:  2.359  Rel. Train L2 Loss :  0.01489013993077808  Rel. Test L2 Loss :  0.01746174618601799  Test L2 Loss :  0.030260387510061264  inv_L_scale:  [1.0, 1.0]
Epoch :  414  Time:  2.359  Rel. Train L2 Loss :  0.01490782342851162  Rel. Test L2 Loss :  0.017294653728604316  Test L2 Loss :  0.029949732199311255  inv_L_scale:  [1.0, 1.0]
Epoch :  415  Time:  2.359  Rel. Train L2 Loss :  0.014925356383124987  Rel. Test L2 Loss :  0.017348664924502374  Test L2 Loss :  0.030038840845227243  inv_L_scale:  [1.0, 1.0]
Epoch :  416  Time:  2.362  Rel. Train L2 Loss :  0.01489250135090616  Rel. Test L2 Loss :  0.017378216534852983  Test L2 Loss :  0.03007524982094765  inv_L_scale:  [1.0, 1.0]
Epoch :  417  Time:  2.359  Rel. Train L2 Loss :  0.014876748596628507  Rel. Test L2 Loss :  0.017183218076825144  Test L2 Loss :  0.029777352809906007  inv_L_scale:  [1.0, 1.0]
Epoch :  418  Time:  2.359  Rel. Train L2 Loss :  0.01483189229749971  Rel. Test L2 Loss :  0.017338744550943374  Test L2 Loss :  0.0299534360319376  inv_L_scale:  [1.0, 1.0]
Epoch :  419  Time:  2.358  Rel. Train L2 Loss :  0.01487485480391317  Rel. Test L2 Loss :  0.017455208078026772  Test L2 Loss :  0.030311823040246964  inv_L_scale:  [1.0, 1.0]
Epoch :  420  Time:  2.358  Rel. Train L2 Loss :  0.014844130012724135  Rel. Test L2 Loss :  0.017304038181900978  Test L2 Loss :  0.03002241678535938  inv_L_scale:  [1.0, 1.0]
Epoch :  421  Time:  2.359  Rel. Train L2 Loss :  0.014827520930104785  Rel. Test L2 Loss :  0.017233983054757117  Test L2 Loss :  0.02984066918492317  inv_L_scale:  [1.0, 1.0]
Epoch :  422  Time:  2.359  Rel. Train L2 Loss :  0.014788037919335894  Rel. Test L2 Loss :  0.017254199758172037  Test L2 Loss :  0.029867233633995058  inv_L_scale:  [1.0, 1.0]
Epoch :  423  Time:  2.359  Rel. Train L2 Loss :  0.014788790022333463  Rel. Test L2 Loss :  0.01725896880030632  Test L2 Loss :  0.029832360222935676  inv_L_scale:  [1.0, 1.0]
Epoch :  424  Time:  2.358  Rel. Train L2 Loss :  0.014779873448941442  Rel. Test L2 Loss :  0.0172096686065197  Test L2 Loss :  0.029796780794858934  inv_L_scale:  [1.0, 1.0]
Epoch :  425  Time:  2.358  Rel. Train L2 Loss :  0.014802495232886738  Rel. Test L2 Loss :  0.017249545380473137  Test L2 Loss :  0.02985147513449192  inv_L_scale:  [1.0, 1.0]
Epoch :  426  Time:  2.358  Rel. Train L2 Loss :  0.014806188104881182  Rel. Test L2 Loss :  0.01728317677974701  Test L2 Loss :  0.029942178130149842  inv_L_scale:  [1.0, 1.0]
Epoch :  427  Time:  2.36  Rel. Train L2 Loss :  0.014754809596472317  Rel. Test L2 Loss :  0.017271396964788438  Test L2 Loss :  0.029907075613737108  inv_L_scale:  [1.0, 1.0]
Epoch :  428  Time:  2.358  Rel. Train L2 Loss :  0.014735224694013595  Rel. Test L2 Loss :  0.017215334847569465  Test L2 Loss :  0.029857640266418458  inv_L_scale:  [1.0, 1.0]
Epoch :  429  Time:  2.36  Rel. Train L2 Loss :  0.014754823603563838  Rel. Test L2 Loss :  0.01726332113146782  Test L2 Loss :  0.029853394776582717  inv_L_scale:  [1.0, 1.0]
Epoch :  430  Time:  2.359  Rel. Train L2 Loss :  0.014722608952886528  Rel. Test L2 Loss :  0.017176604196429253  Test L2 Loss :  0.029740288257598876  inv_L_scale:  [1.0, 1.0]
Epoch :  431  Time:  2.359  Rel. Train L2 Loss :  0.014710737230877081  Rel. Test L2 Loss :  0.01721968948841095  Test L2 Loss :  0.02983168050646782  inv_L_scale:  [1.0, 1.0]
Epoch :  432  Time:  2.36  Rel. Train L2 Loss :  0.014697571214702394  Rel. Test L2 Loss :  0.017257675230503082  Test L2 Loss :  0.02982334829866886  inv_L_scale:  [1.0, 1.0]
Epoch :  433  Time:  2.359  Rel. Train L2 Loss :  0.014685222258170446  Rel. Test L2 Loss :  0.017279810532927514  Test L2 Loss :  0.02993287280201912  inv_L_scale:  [1.0, 1.0]
Epoch :  434  Time:  2.358  Rel. Train L2 Loss :  0.01468263233701388  Rel. Test L2 Loss :  0.017269693687558173  Test L2 Loss :  0.029929886162281035  inv_L_scale:  [1.0, 1.0]
Epoch :  435  Time:  2.358  Rel. Train L2 Loss :  0.014657560230957137  Rel. Test L2 Loss :  0.017171126827597617  Test L2 Loss :  0.029711157009005548  inv_L_scale:  [1.0, 1.0]
Epoch :  436  Time:  2.358  Rel. Train L2 Loss :  0.014664055580894153  Rel. Test L2 Loss :  0.01719159699976444  Test L2 Loss :  0.029778014570474624  inv_L_scale:  [1.0, 1.0]
Epoch :  437  Time:  2.358  Rel. Train L2 Loss :  0.014652505467335384  Rel. Test L2 Loss :  0.017179973274469375  Test L2 Loss :  0.029730647280812265  inv_L_scale:  [1.0, 1.0]
Epoch :  438  Time:  2.361  Rel. Train L2 Loss :  0.01465672874202331  Rel. Test L2 Loss :  0.017170832008123398  Test L2 Loss :  0.029687188342213632  inv_L_scale:  [1.0, 1.0]
Epoch :  439  Time:  2.358  Rel. Train L2 Loss :  0.01464446057875951  Rel. Test L2 Loss :  0.017181630954146387  Test L2 Loss :  0.029789549559354783  inv_L_scale:  [1.0, 1.0]
Epoch :  440  Time:  2.358  Rel. Train L2 Loss :  0.014639800302684308  Rel. Test L2 Loss :  0.017192194759845732  Test L2 Loss :  0.02973775804042816  inv_L_scale:  [1.0, 1.0]
Epoch :  441  Time:  2.358  Rel. Train L2 Loss :  0.014614274220334159  Rel. Test L2 Loss :  0.017161502316594125  Test L2 Loss :  0.02973241627216339  inv_L_scale:  [1.0, 1.0]
Epoch :  442  Time:  2.358  Rel. Train L2 Loss :  0.01461728443702062  Rel. Test L2 Loss :  0.01720033586025238  Test L2 Loss :  0.029778686463832856  inv_L_scale:  [1.0, 1.0]
Epoch :  443  Time:  2.359  Rel. Train L2 Loss :  0.014603935753305753  Rel. Test L2 Loss :  0.01716453716158867  Test L2 Loss :  0.029722343534231185  inv_L_scale:  [1.0, 1.0]
Epoch :  444  Time:  2.358  Rel. Train L2 Loss :  0.014577996730804444  Rel. Test L2 Loss :  0.017229028195142746  Test L2 Loss :  0.029842068254947663  inv_L_scale:  [1.0, 1.0]
Epoch :  445  Time:  2.358  Rel. Train L2 Loss :  0.014578391632272137  Rel. Test L2 Loss :  0.017199235707521437  Test L2 Loss :  0.02976890154182911  inv_L_scale:  [1.0, 1.0]
Epoch :  446  Time:  2.358  Rel. Train L2 Loss :  0.014547522154947121  Rel. Test L2 Loss :  0.01713839128613472  Test L2 Loss :  0.029677273631095888  inv_L_scale:  [1.0, 1.0]
Epoch :  447  Time:  2.358  Rel. Train L2 Loss :  0.01456049382686615  Rel. Test L2 Loss :  0.017148199006915093  Test L2 Loss :  0.029689173996448517  inv_L_scale:  [1.0, 1.0]
Epoch :  448  Time:  2.358  Rel. Train L2 Loss :  0.014551468408770031  Rel. Test L2 Loss :  0.017134110629558563  Test L2 Loss :  0.02967094734311104  inv_L_scale:  [1.0, 1.0]
Epoch :  449  Time:  2.359  Rel. Train L2 Loss :  0.014544075520502197  Rel. Test L2 Loss :  0.01710948087275028  Test L2 Loss :  0.029638433009386064  inv_L_scale:  [1.0, 1.0]
Epoch :  450  Time:  2.359  Rel. Train L2 Loss :  0.014544211253523827  Rel. Test L2 Loss :  0.017095534950494765  Test L2 Loss :  0.029618127048015596  inv_L_scale:  [1.0, 1.0]
Epoch :  451  Time:  2.358  Rel. Train L2 Loss :  0.014515294772055414  Rel. Test L2 Loss :  0.017107670679688453  Test L2 Loss :  0.029612606093287468  inv_L_scale:  [1.0, 1.0]
Epoch :  452  Time:  2.358  Rel. Train L2 Loss :  0.01450957869903909  Rel. Test L2 Loss :  0.01710020028054714  Test L2 Loss :  0.029606675058603288  inv_L_scale:  [1.0, 1.0]
Epoch :  453  Time:  2.358  Rel. Train L2 Loss :  0.014505202265249359  Rel. Test L2 Loss :  0.017157869189977647  Test L2 Loss :  0.029712004214525224  inv_L_scale:  [1.0, 1.0]
Epoch :  454  Time:  2.359  Rel. Train L2 Loss :  0.014488264947301812  Rel. Test L2 Loss :  0.01710574120283127  Test L2 Loss :  0.029624215364456176  inv_L_scale:  [1.0, 1.0]
Epoch :  455  Time:  2.359  Rel. Train L2 Loss :  0.014495484394331773  Rel. Test L2 Loss :  0.01711397334933281  Test L2 Loss :  0.029641403704881667  inv_L_scale:  [1.0, 1.0]
Epoch :  456  Time:  2.359  Rel. Train L2 Loss :  0.014483280355731647  Rel. Test L2 Loss :  0.01712892435491085  Test L2 Loss :  0.029657927379012107  inv_L_scale:  [1.0, 1.0]
Epoch :  457  Time:  2.358  Rel. Train L2 Loss :  0.014474437062939008  Rel. Test L2 Loss :  0.01712516516447067  Test L2 Loss :  0.02963381677865982  inv_L_scale:  [1.0, 1.0]
Epoch :  458  Time:  2.359  Rel. Train L2 Loss :  0.014472627267241477  Rel. Test L2 Loss :  0.01710925154387951  Test L2 Loss :  0.02961204931139946  inv_L_scale:  [1.0, 1.0]
Epoch :  459  Time:  2.36  Rel. Train L2 Loss :  0.014475364709893862  Rel. Test L2 Loss :  0.017102055177092554  Test L2 Loss :  0.029580663964152334  inv_L_scale:  [1.0, 1.0]
Epoch :  460  Time:  2.36  Rel. Train L2 Loss :  0.014458628557622432  Rel. Test L2 Loss :  0.017084317579865456  Test L2 Loss :  0.029568430930376054  inv_L_scale:  [1.0, 1.0]
Epoch :  461  Time:  2.358  Rel. Train L2 Loss :  0.01443584735194842  Rel. Test L2 Loss :  0.017091294080019  Test L2 Loss :  0.029583991318941117  inv_L_scale:  [1.0, 1.0]
Epoch :  462  Time:  2.358  Rel. Train L2 Loss :  0.014448777793182268  Rel. Test L2 Loss :  0.017113795131444932  Test L2 Loss :  0.0296061322838068  inv_L_scale:  [1.0, 1.0]
Epoch :  463  Time:  2.358  Rel. Train L2 Loss :  0.01444255608651373  Rel. Test L2 Loss :  0.01707497864961624  Test L2 Loss :  0.029548478722572328  inv_L_scale:  [1.0, 1.0]
Epoch :  464  Time:  2.358  Rel. Train L2 Loss :  0.014428644039564663  Rel. Test L2 Loss :  0.017089523375034332  Test L2 Loss :  0.02957182615995407  inv_L_scale:  [1.0, 1.0]
Epoch :  465  Time:  2.358  Rel. Train L2 Loss :  0.014423612401717238  Rel. Test L2 Loss :  0.017066163942217827  Test L2 Loss :  0.029540062546730042  inv_L_scale:  [1.0, 1.0]
Epoch :  466  Time:  2.358  Rel. Train L2 Loss :  0.01442378919157717  Rel. Test L2 Loss :  0.017091936096549035  Test L2 Loss :  0.029591261148452758  inv_L_scale:  [1.0, 1.0]
Epoch :  467  Time:  2.358  Rel. Train L2 Loss :  0.014406106542381975  Rel. Test L2 Loss :  0.017079523801803588  Test L2 Loss :  0.029545485526323318  inv_L_scale:  [1.0, 1.0]
Epoch :  468  Time:  2.358  Rel. Train L2 Loss :  0.014406285128659673  Rel. Test L2 Loss :  0.017100725695490836  Test L2 Loss :  0.02961792066693306  inv_L_scale:  [1.0, 1.0]
Epoch :  469  Time:  2.358  Rel. Train L2 Loss :  0.014408179298043252  Rel. Test L2 Loss :  0.017082710936665534  Test L2 Loss :  0.029548805952072144  inv_L_scale:  [1.0, 1.0]
Epoch :  470  Time:  2.359  Rel. Train L2 Loss :  0.014391800152758757  Rel. Test L2 Loss :  0.0170829801261425  Test L2 Loss :  0.02956135407090187  inv_L_scale:  [1.0, 1.0]
Epoch :  471  Time:  2.359  Rel. Train L2 Loss :  0.014394320588972833  Rel. Test L2 Loss :  0.01707904189825058  Test L2 Loss :  0.02955421894788742  inv_L_scale:  [1.0, 1.0]
Epoch :  472  Time:  2.358  Rel. Train L2 Loss :  0.014380217914779982  Rel. Test L2 Loss :  0.01707110583782196  Test L2 Loss :  0.029551269710063933  inv_L_scale:  [1.0, 1.0]
Epoch :  473  Time:  2.359  Rel. Train L2 Loss :  0.014378961953851912  Rel. Test L2 Loss :  0.017076287269592285  Test L2 Loss :  0.02954146847128868  inv_L_scale:  [1.0, 1.0]
Epoch :  474  Time:  2.358  Rel. Train L2 Loss :  0.014379910777012507  Rel. Test L2 Loss :  0.017068824395537377  Test L2 Loss :  0.029533175677061083  inv_L_scale:  [1.0, 1.0]
Epoch :  475  Time:  2.358  Rel. Train L2 Loss :  0.014369128064976798  Rel. Test L2 Loss :  0.01705920197069645  Test L2 Loss :  0.029518117755651475  inv_L_scale:  [1.0, 1.0]
Epoch :  476  Time:  2.359  Rel. Train L2 Loss :  0.01436561113430394  Rel. Test L2 Loss :  0.01706964202225208  Test L2 Loss :  0.02953243926167488  inv_L_scale:  [1.0, 1.0]
Epoch :  477  Time:  2.357  Rel. Train L2 Loss :  0.014357162358032333  Rel. Test L2 Loss :  0.017077308148145676  Test L2 Loss :  0.02955146014690399  inv_L_scale:  [1.0, 1.0]
Epoch :  478  Time:  2.358  Rel. Train L2 Loss :  0.014360504158669048  Rel. Test L2 Loss :  0.01706439822912216  Test L2 Loss :  0.02952057607471943  inv_L_scale:  [1.0, 1.0]
Epoch :  479  Time:  2.358  Rel. Train L2 Loss :  0.014353440569506751  Rel. Test L2 Loss :  0.017068915292620657  Test L2 Loss :  0.029531176537275314  inv_L_scale:  [1.0, 1.0]
Epoch :  480  Time:  2.358  Rel. Train L2 Loss :  0.01435068440520101  Rel. Test L2 Loss :  0.01705885834991932  Test L2 Loss :  0.029531724080443383  inv_L_scale:  [1.0, 1.0]
Epoch :  481  Time:  2.361  Rel. Train L2 Loss :  0.014342517438862059  Rel. Test L2 Loss :  0.01706243507564068  Test L2 Loss :  0.029519722312688828  inv_L_scale:  [1.0, 1.0]
Epoch :  482  Time:  2.359  Rel. Train L2 Loss :  0.014342757397227818  Rel. Test L2 Loss :  0.01706953227519989  Test L2 Loss :  0.02954338178038597  inv_L_scale:  [1.0, 1.0]
Epoch :  483  Time:  2.358  Rel. Train L2 Loss :  0.014341461062431336  Rel. Test L2 Loss :  0.017057154551148413  Test L2 Loss :  0.02952009320259094  inv_L_scale:  [1.0, 1.0]
Epoch :  484  Time:  2.358  Rel. Train L2 Loss :  0.014336626620756255  Rel. Test L2 Loss :  0.017062098681926728  Test L2 Loss :  0.029519491642713547  inv_L_scale:  [1.0, 1.0]
Epoch :  485  Time:  2.358  Rel. Train L2 Loss :  0.014335838709440496  Rel. Test L2 Loss :  0.01705882489681244  Test L2 Loss :  0.02951204150915146  inv_L_scale:  [1.0, 1.0]
Epoch :  486  Time:  2.358  Rel. Train L2 Loss :  0.014332341684235467  Rel. Test L2 Loss :  0.017056363224983214  Test L2 Loss :  0.029516040086746215  inv_L_scale:  [1.0, 1.0]
Epoch :  487  Time:  2.358  Rel. Train L2 Loss :  0.014331805345912774  Rel. Test L2 Loss :  0.017057997807860374  Test L2 Loss :  0.029521155655384063  inv_L_scale:  [1.0, 1.0]
Epoch :  488  Time:  2.358  Rel. Train L2 Loss :  0.014326831408672863  Rel. Test L2 Loss :  0.01706159844994545  Test L2 Loss :  0.029529546722769737  inv_L_scale:  [1.0, 1.0]
Epoch :  489  Time:  2.358  Rel. Train L2 Loss :  0.014326527069012324  Rel. Test L2 Loss :  0.01706420987844467  Test L2 Loss :  0.02953459180891514  inv_L_scale:  [1.0, 1.0]
Epoch :  490  Time:  2.358  Rel. Train L2 Loss :  0.014325028107398085  Rel. Test L2 Loss :  0.017060321867465974  Test L2 Loss :  0.029516734853386878  inv_L_scale:  [1.0, 1.0]
Epoch :  491  Time:  2.358  Rel. Train L2 Loss :  0.014321940019726753  Rel. Test L2 Loss :  0.01705608017742634  Test L2 Loss :  0.029511514902114868  inv_L_scale:  [1.0, 1.0]
Epoch :  492  Time:  2.358  Rel. Train L2 Loss :  0.014321347748239835  Rel. Test L2 Loss :  0.017058772742748262  Test L2 Loss :  0.029516047090291975  inv_L_scale:  [1.0, 1.0]
Epoch :  493  Time:  2.358  Rel. Train L2 Loss :  0.014318703475097816  Rel. Test L2 Loss :  0.017056774869561194  Test L2 Loss :  0.0295180057734251  inv_L_scale:  [1.0, 1.0]
Epoch :  494  Time:  2.358  Rel. Train L2 Loss :  0.01431720085028145  Rel. Test L2 Loss :  0.01706028200685978  Test L2 Loss :  0.02951692633330822  inv_L_scale:  [1.0, 1.0]
Epoch :  495  Time:  2.358  Rel. Train L2 Loss :  0.014318148030175103  Rel. Test L2 Loss :  0.017062563598155975  Test L2 Loss :  0.029533549621701242  inv_L_scale:  [1.0, 1.0]
Epoch :  496  Time:  2.358  Rel. Train L2 Loss :  0.014318743505411678  Rel. Test L2 Loss :  0.017062284275889395  Test L2 Loss :  0.029520163014531135  inv_L_scale:  [1.0, 1.0]
Epoch :  497  Time:  2.358  Rel. Train L2 Loss :  0.014315090883109305  Rel. Test L2 Loss :  0.017057416662573814  Test L2 Loss :  0.029518498033285143  inv_L_scale:  [1.0, 1.0]
Epoch :  498  Time:  2.358  Rel. Train L2 Loss :  0.014315014220774174  Rel. Test L2 Loss :  0.017058234885334967  Test L2 Loss :  0.029522931426763533  inv_L_scale:  [1.0, 1.0]
Epoch :  499  Time:  2.358  Rel. Train L2 Loss :  0.014317875347203678  Rel. Test L2 Loss :  0.01705491192638874  Test L2 Loss :  0.029510464891791342  inv_L_scale:  [1.0, 1.0]
