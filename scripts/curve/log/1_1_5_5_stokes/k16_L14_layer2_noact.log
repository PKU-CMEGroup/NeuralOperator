Loading data from  ../../data/curve//pcno_curve_data_1_1_5_5_stokes.npz
(1000,) (1000, 1000, 1) (1000, 1000, 2)
use normalized raw measures
Casting to tensor
x_train shape torch.Size([900, 1000, 6]), y_train shape torch.Size([900, 1000, 1])
length of each dim:  tensor([6.6455335617065430, 6.6654777526855469])
kmax = 16
L =  14
In PCNO_train, ndims =  2
Epoch :  0  Time:  1.433  Rel. Train L2 Loss :  0.39769758926497567  Rel. Test L2 Loss :  0.22900768399238586  Test L2 Loss :  0.44010323762893677  inv_L_scale:  [1.0, 1.0]
Epoch :  1  Time:  0.944  Rel. Train L2 Loss :  0.18712593154774773  Rel. Test L2 Loss :  0.15472540974617005  Test L2 Loss :  0.29059715747833254  inv_L_scale:  [1.0, 1.0]
Epoch :  2  Time:  0.94  Rel. Train L2 Loss :  0.1387566903233528  Rel. Test L2 Loss :  0.11897225975990296  Test L2 Loss :  0.2195119947195053  inv_L_scale:  [1.0, 1.0]
Epoch :  3  Time:  0.94  Rel. Train L2 Loss :  0.11645528021785947  Rel. Test L2 Loss :  0.10372165203094483  Test L2 Loss :  0.191718670129776  inv_L_scale:  [1.0, 1.0]
Epoch :  4  Time:  0.942  Rel. Train L2 Loss :  0.09844057086441252  Rel. Test L2 Loss :  0.09942039787769318  Test L2 Loss :  0.18143890798091888  inv_L_scale:  [1.0, 1.0]
Epoch :  5  Time:  0.94  Rel. Train L2 Loss :  0.09367666926648882  Rel. Test L2 Loss :  0.10173364251852035  Test L2 Loss :  0.18158555746078492  inv_L_scale:  [1.0, 1.0]
Epoch :  6  Time:  0.94  Rel. Train L2 Loss :  0.08606409211953481  Rel. Test L2 Loss :  0.08974316477775574  Test L2 Loss :  0.16294646620750428  inv_L_scale:  [1.0, 1.0]
Epoch :  7  Time:  0.94  Rel. Train L2 Loss :  0.07991607768668069  Rel. Test L2 Loss :  0.08802593350410462  Test L2 Loss :  0.15735693275928497  inv_L_scale:  [1.0, 1.0]
Epoch :  8  Time:  0.94  Rel. Train L2 Loss :  0.08085217283831703  Rel. Test L2 Loss :  0.0855927136540413  Test L2 Loss :  0.154729722738266  inv_L_scale:  [1.0, 1.0]
Epoch :  9  Time:  0.941  Rel. Train L2 Loss :  0.07689219885402256  Rel. Test L2 Loss :  0.07901892095804214  Test L2 Loss :  0.14294687151908875  inv_L_scale:  [1.0, 1.0]
Epoch :  10  Time:  0.941  Rel. Train L2 Loss :  0.07460776017771827  Rel. Test L2 Loss :  0.07872454673051835  Test L2 Loss :  0.13930444478988646  inv_L_scale:  [1.0, 1.0]
Epoch :  11  Time:  0.943  Rel. Train L2 Loss :  0.07263592468367683  Rel. Test L2 Loss :  0.081576629281044  Test L2 Loss :  0.14850958645343781  inv_L_scale:  [1.0, 1.0]
Epoch :  12  Time:  0.942  Rel. Train L2 Loss :  0.07180283900764253  Rel. Test L2 Loss :  0.08558418929576873  Test L2 Loss :  0.15365204811096192  inv_L_scale:  [1.0, 1.0]
Epoch :  13  Time:  0.941  Rel. Train L2 Loss :  0.07004246761401495  Rel. Test L2 Loss :  0.07102910250425339  Test L2 Loss :  0.12709846019744872  inv_L_scale:  [1.0, 1.0]
Epoch :  14  Time:  0.94  Rel. Train L2 Loss :  0.06657973097430335  Rel. Test L2 Loss :  0.07653198957443237  Test L2 Loss :  0.13677556157112122  inv_L_scale:  [1.0, 1.0]
Epoch :  15  Time:  0.941  Rel. Train L2 Loss :  0.06792751090394127  Rel. Test L2 Loss :  0.06609550178050995  Test L2 Loss :  0.11768232762813569  inv_L_scale:  [1.0, 1.0]
Epoch :  16  Time:  0.94  Rel. Train L2 Loss :  0.0651396843459871  Rel. Test L2 Loss :  0.07106164693832398  Test L2 Loss :  0.12581281185150148  inv_L_scale:  [1.0, 1.0]
Epoch :  17  Time:  0.939  Rel. Train L2 Loss :  0.06846296519041062  Rel. Test L2 Loss :  0.07301741153001785  Test L2 Loss :  0.12861717462539674  inv_L_scale:  [1.0, 1.0]
Epoch :  18  Time:  0.939  Rel. Train L2 Loss :  0.06459281533956528  Rel. Test L2 Loss :  0.0679833297431469  Test L2 Loss :  0.11936592519283294  inv_L_scale:  [1.0, 1.0]
Epoch :  19  Time:  0.941  Rel. Train L2 Loss :  0.06387590550714069  Rel. Test L2 Loss :  0.07071224868297576  Test L2 Loss :  0.12463270843029023  inv_L_scale:  [1.0, 1.0]
Epoch :  20  Time:  0.942  Rel. Train L2 Loss :  0.06402989672289955  Rel. Test L2 Loss :  0.06734211564064026  Test L2 Loss :  0.11862987339496613  inv_L_scale:  [1.0, 1.0]
Epoch :  21  Time:  0.939  Rel. Train L2 Loss :  0.0653925151295132  Rel. Test L2 Loss :  0.06672385185956956  Test L2 Loss :  0.11793618649244308  inv_L_scale:  [1.0, 1.0]
Epoch :  22  Time:  0.94  Rel. Train L2 Loss :  0.06270313403672642  Rel. Test L2 Loss :  0.06654241725802422  Test L2 Loss :  0.11718929141759872  inv_L_scale:  [1.0, 1.0]
Epoch :  23  Time:  0.939  Rel. Train L2 Loss :  0.06251213557190365  Rel. Test L2 Loss :  0.06789296641945838  Test L2 Loss :  0.11992979377508163  inv_L_scale:  [1.0, 1.0]
Epoch :  24  Time:  0.94  Rel. Train L2 Loss :  0.0629363052546978  Rel. Test L2 Loss :  0.06555441215634346  Test L2 Loss :  0.11590923219919205  inv_L_scale:  [1.0, 1.0]
Epoch :  25  Time:  0.94  Rel. Train L2 Loss :  0.0622368758254581  Rel. Test L2 Loss :  0.06411299884319305  Test L2 Loss :  0.1121709406375885  inv_L_scale:  [1.0, 1.0]
Epoch :  26  Time:  0.939  Rel. Train L2 Loss :  0.0601298361354404  Rel. Test L2 Loss :  0.06524776875972747  Test L2 Loss :  0.11585499584674835  inv_L_scale:  [1.0, 1.0]
Epoch :  27  Time:  0.939  Rel. Train L2 Loss :  0.06131117691596349  Rel. Test L2 Loss :  0.06144851952791214  Test L2 Loss :  0.10858557105064393  inv_L_scale:  [1.0, 1.0]
Epoch :  28  Time:  0.942  Rel. Train L2 Loss :  0.06145029624303182  Rel. Test L2 Loss :  0.07291858106851577  Test L2 Loss :  0.1294083920121193  inv_L_scale:  [1.0, 1.0]
Epoch :  29  Time:  0.94  Rel. Train L2 Loss :  0.060317825277646384  Rel. Test L2 Loss :  0.06409885808825493  Test L2 Loss :  0.11261423110961914  inv_L_scale:  [1.0, 1.0]
Epoch :  30  Time:  0.939  Rel. Train L2 Loss :  0.06016064614057541  Rel. Test L2 Loss :  0.06372988253831863  Test L2 Loss :  0.11156098663806915  inv_L_scale:  [1.0, 1.0]
Epoch :  31  Time:  0.939  Rel. Train L2 Loss :  0.05931731664472156  Rel. Test L2 Loss :  0.06253634423017501  Test L2 Loss :  0.11031960219144821  inv_L_scale:  [1.0, 1.0]
Epoch :  32  Time:  0.939  Rel. Train L2 Loss :  0.06003020326296488  Rel. Test L2 Loss :  0.06589801460504532  Test L2 Loss :  0.11631604075431824  inv_L_scale:  [1.0, 1.0]
Epoch :  33  Time:  0.939  Rel. Train L2 Loss :  0.0585231610470348  Rel. Test L2 Loss :  0.0627464473247528  Test L2 Loss :  0.11019039630889893  inv_L_scale:  [1.0, 1.0]
Epoch :  34  Time:  0.94  Rel. Train L2 Loss :  0.05816029750638538  Rel. Test L2 Loss :  0.06349012792110444  Test L2 Loss :  0.11088559180498123  inv_L_scale:  [1.0, 1.0]
Epoch :  35  Time:  0.938  Rel. Train L2 Loss :  0.05836283279789819  Rel. Test L2 Loss :  0.06570776477456093  Test L2 Loss :  0.11636951506137848  inv_L_scale:  [1.0, 1.0]
Epoch :  36  Time:  0.939  Rel. Train L2 Loss :  0.06044116944074631  Rel. Test L2 Loss :  0.06011349618434906  Test L2 Loss :  0.10698204815387725  inv_L_scale:  [1.0, 1.0]
Epoch :  37  Time:  0.939  Rel. Train L2 Loss :  0.05892343853910764  Rel. Test L2 Loss :  0.061182019412517545  Test L2 Loss :  0.10772879540920258  inv_L_scale:  [1.0, 1.0]
Epoch :  38  Time:  0.941  Rel. Train L2 Loss :  0.05804475867085987  Rel. Test L2 Loss :  0.06583271518349648  Test L2 Loss :  0.1157030564546585  inv_L_scale:  [1.0, 1.0]
Epoch :  39  Time:  0.94  Rel. Train L2 Loss :  0.05873515483405855  Rel. Test L2 Loss :  0.060959467142820356  Test L2 Loss :  0.10660489976406097  inv_L_scale:  [1.0, 1.0]
Epoch :  40  Time:  0.938  Rel. Train L2 Loss :  0.05730006554060512  Rel. Test L2 Loss :  0.059910110086202624  Test L2 Loss :  0.10546590566635132  inv_L_scale:  [1.0, 1.0]
Epoch :  41  Time:  0.939  Rel. Train L2 Loss :  0.056944928897751705  Rel. Test L2 Loss :  0.061438850462436675  Test L2 Loss :  0.10701531231403351  inv_L_scale:  [1.0, 1.0]
Epoch :  42  Time:  0.939  Rel. Train L2 Loss :  0.05846929368045595  Rel. Test L2 Loss :  0.0608176451921463  Test L2 Loss :  0.10669069707393647  inv_L_scale:  [1.0, 1.0]
Epoch :  43  Time:  0.94  Rel. Train L2 Loss :  0.05715520547495948  Rel. Test L2 Loss :  0.06168033555150032  Test L2 Loss :  0.10805626511573792  inv_L_scale:  [1.0, 1.0]
Epoch :  44  Time:  0.938  Rel. Train L2 Loss :  0.05778886586427689  Rel. Test L2 Loss :  0.06009238734841347  Test L2 Loss :  0.10524103373289108  inv_L_scale:  [1.0, 1.0]
Epoch :  45  Time:  0.939  Rel. Train L2 Loss :  0.05697627478175693  Rel. Test L2 Loss :  0.056006979346275326  Test L2 Loss :  0.09810651361942291  inv_L_scale:  [1.0, 1.0]
Epoch :  46  Time:  0.939  Rel. Train L2 Loss :  0.056723592976729076  Rel. Test L2 Loss :  0.05871429577469826  Test L2 Loss :  0.10245403528213501  inv_L_scale:  [1.0, 1.0]
Epoch :  47  Time:  0.938  Rel. Train L2 Loss :  0.058040518048736785  Rel. Test L2 Loss :  0.06605699941515923  Test L2 Loss :  0.11586714595556259  inv_L_scale:  [1.0, 1.0]
Epoch :  48  Time:  0.939  Rel. Train L2 Loss :  0.05609352313809925  Rel. Test L2 Loss :  0.059253715574741364  Test L2 Loss :  0.1032063126564026  inv_L_scale:  [1.0, 1.0]
Epoch :  49  Time:  0.938  Rel. Train L2 Loss :  0.05597765051656299  Rel. Test L2 Loss :  0.059392364621162416  Test L2 Loss :  0.10356753408908843  inv_L_scale:  [1.0, 1.0]
Epoch :  50  Time:  0.94  Rel. Train L2 Loss :  0.05830329212877485  Rel. Test L2 Loss :  0.05543508023023605  Test L2 Loss :  0.09690743923187256  inv_L_scale:  [1.0, 1.0]
Epoch :  51  Time:  0.941  Rel. Train L2 Loss :  0.05475010257628229  Rel. Test L2 Loss :  0.058960144519805906  Test L2 Loss :  0.10194180130958558  inv_L_scale:  [1.0, 1.0]
Epoch :  52  Time:  0.939  Rel. Train L2 Loss :  0.055047220504946176  Rel. Test L2 Loss :  0.05794184371829033  Test L2 Loss :  0.10124115973711013  inv_L_scale:  [1.0, 1.0]
Epoch :  53  Time:  0.939  Rel. Train L2 Loss :  0.05590321855412589  Rel. Test L2 Loss :  0.06093578100204468  Test L2 Loss :  0.10696465432643891  inv_L_scale:  [1.0, 1.0]
Epoch :  54  Time:  0.938  Rel. Train L2 Loss :  0.05535363614559174  Rel. Test L2 Loss :  0.0644824606180191  Test L2 Loss :  0.11324073374271393  inv_L_scale:  [1.0, 1.0]
Epoch :  55  Time:  0.938  Rel. Train L2 Loss :  0.05567753745449914  Rel. Test L2 Loss :  0.05869456559419632  Test L2 Loss :  0.10338432461023331  inv_L_scale:  [1.0, 1.0]
Epoch :  56  Time:  0.939  Rel. Train L2 Loss :  0.055410413444042204  Rel. Test L2 Loss :  0.05762243241071701  Test L2 Loss :  0.1007199627161026  inv_L_scale:  [1.0, 1.0]
Epoch :  57  Time:  0.938  Rel. Train L2 Loss :  0.055982170932822754  Rel. Test L2 Loss :  0.0577327287197113  Test L2 Loss :  0.09913310170173645  inv_L_scale:  [1.0, 1.0]
Epoch :  58  Time:  0.939  Rel. Train L2 Loss :  0.05612653715742959  Rel. Test L2 Loss :  0.056327439993619915  Test L2 Loss :  0.09737219601869583  inv_L_scale:  [1.0, 1.0]
Epoch :  59  Time:  0.94  Rel. Train L2 Loss :  0.054285698963536154  Rel. Test L2 Loss :  0.06037091463804245  Test L2 Loss :  0.1054492273926735  inv_L_scale:  [1.0, 1.0]
Epoch :  60  Time:  0.938  Rel. Train L2 Loss :  0.05444060762723287  Rel. Test L2 Loss :  0.05830010399222374  Test L2 Loss :  0.10193946689367295  inv_L_scale:  [1.0, 1.0]
Epoch :  61  Time:  0.938  Rel. Train L2 Loss :  0.053218230108420056  Rel. Test L2 Loss :  0.056339398324489594  Test L2 Loss :  0.09868277072906494  inv_L_scale:  [1.0, 1.0]
Epoch :  62  Time:  0.938  Rel. Train L2 Loss :  0.053135337664021384  Rel. Test L2 Loss :  0.05906506717205048  Test L2 Loss :  0.10382760524749755  inv_L_scale:  [1.0, 1.0]
Epoch :  63  Time:  0.938  Rel. Train L2 Loss :  0.0550623586277167  Rel. Test L2 Loss :  0.054112376868724825  Test L2 Loss :  0.09446090817451477  inv_L_scale:  [1.0, 1.0]
Epoch :  64  Time:  0.938  Rel. Train L2 Loss :  0.05405088239245945  Rel. Test L2 Loss :  0.05600969821214676  Test L2 Loss :  0.09738036155700684  inv_L_scale:  [1.0, 1.0]
Epoch :  65  Time:  0.94  Rel. Train L2 Loss :  0.05382840037345886  Rel. Test L2 Loss :  0.057498679459095  Test L2 Loss :  0.0999853840470314  inv_L_scale:  [1.0, 1.0]
Epoch :  66  Time:  0.94  Rel. Train L2 Loss :  0.054863781746890807  Rel. Test L2 Loss :  0.06351131290197372  Test L2 Loss :  0.11139255732297898  inv_L_scale:  [1.0, 1.0]
Epoch :  67  Time:  0.938  Rel. Train L2 Loss :  0.05373743893371688  Rel. Test L2 Loss :  0.05593831121921539  Test L2 Loss :  0.09770064413547516  inv_L_scale:  [1.0, 1.0]
Epoch :  68  Time:  0.939  Rel. Train L2 Loss :  0.05322264896498786  Rel. Test L2 Loss :  0.05672710001468659  Test L2 Loss :  0.10013643622398377  inv_L_scale:  [1.0, 1.0]
Epoch :  69  Time:  0.938  Rel. Train L2 Loss :  0.053197936216990156  Rel. Test L2 Loss :  0.06154656410217285  Test L2 Loss :  0.10570365399122238  inv_L_scale:  [1.0, 1.0]
Epoch :  70  Time:  0.938  Rel. Train L2 Loss :  0.05339711240596241  Rel. Test L2 Loss :  0.054308858662843705  Test L2 Loss :  0.09543114870786668  inv_L_scale:  [1.0, 1.0]
Epoch :  71  Time:  0.938  Rel. Train L2 Loss :  0.052117919342385396  Rel. Test L2 Loss :  0.06069453686475754  Test L2 Loss :  0.10603877663612366  inv_L_scale:  [1.0, 1.0]
Epoch :  72  Time:  0.939  Rel. Train L2 Loss :  0.052593841056029  Rel. Test L2 Loss :  0.05431816190481186  Test L2 Loss :  0.09492949604988098  inv_L_scale:  [1.0, 1.0]
Epoch :  73  Time:  0.938  Rel. Train L2 Loss :  0.052370268785291246  Rel. Test L2 Loss :  0.056455364972352984  Test L2 Loss :  0.09879762828350067  inv_L_scale:  [1.0, 1.0]
Epoch :  74  Time:  0.938  Rel. Train L2 Loss :  0.05233432802889082  Rel. Test L2 Loss :  0.055767097771167756  Test L2 Loss :  0.09566837638616561  inv_L_scale:  [1.0, 1.0]
Epoch :  75  Time:  0.939  Rel. Train L2 Loss :  0.05218863841560152  Rel. Test L2 Loss :  0.05544449344277382  Test L2 Loss :  0.09713660061359405  inv_L_scale:  [1.0, 1.0]
Epoch :  76  Time:  0.939  Rel. Train L2 Loss :  0.05190910869174534  Rel. Test L2 Loss :  0.05757242888212204  Test L2 Loss :  0.10348853170871734  inv_L_scale:  [1.0, 1.0]
Epoch :  77  Time:  0.938  Rel. Train L2 Loss :  0.05225929654306836  Rel. Test L2 Loss :  0.0552875816822052  Test L2 Loss :  0.09614113450050354  inv_L_scale:  [1.0, 1.0]
Epoch :  78  Time:  0.938  Rel. Train L2 Loss :  0.052318018641736776  Rel. Test L2 Loss :  0.054671254158020016  Test L2 Loss :  0.09500857800245285  inv_L_scale:  [1.0, 1.0]
Epoch :  79  Time:  0.939  Rel. Train L2 Loss :  0.05146168773372968  Rel. Test L2 Loss :  0.054017645120620725  Test L2 Loss :  0.09467059910297394  inv_L_scale:  [1.0, 1.0]
Epoch :  80  Time:  0.937  Rel. Train L2 Loss :  0.05205467336707645  Rel. Test L2 Loss :  0.056471165418624875  Test L2 Loss :  0.09950845241546631  inv_L_scale:  [1.0, 1.0]
Epoch :  81  Time:  0.936  Rel. Train L2 Loss :  0.05173539059029685  Rel. Test L2 Loss :  0.057995555996894835  Test L2 Loss :  0.10124162316322327  inv_L_scale:  [1.0, 1.0]
Epoch :  82  Time:  0.937  Rel. Train L2 Loss :  0.05153035210238563  Rel. Test L2 Loss :  0.0538978773355484  Test L2 Loss :  0.09420242428779602  inv_L_scale:  [1.0, 1.0]
Epoch :  83  Time:  0.94  Rel. Train L2 Loss :  0.05171791586611006  Rel. Test L2 Loss :  0.055379063189029694  Test L2 Loss :  0.09535301327705384  inv_L_scale:  [1.0, 1.0]
Epoch :  84  Time:  0.939  Rel. Train L2 Loss :  0.05066233644882838  Rel. Test L2 Loss :  0.05441084951162338  Test L2 Loss :  0.09521027863025665  inv_L_scale:  [1.0, 1.0]
Epoch :  85  Time:  0.937  Rel. Train L2 Loss :  0.05088559230168661  Rel. Test L2 Loss :  0.0519181552529335  Test L2 Loss :  0.08998574733734131  inv_L_scale:  [1.0, 1.0]
Epoch :  86  Time:  0.938  Rel. Train L2 Loss :  0.050764524274402194  Rel. Test L2 Loss :  0.05130209028720856  Test L2 Loss :  0.08919162541627884  inv_L_scale:  [1.0, 1.0]
Epoch :  87  Time:  0.938  Rel. Train L2 Loss :  0.0501996857755714  Rel. Test L2 Loss :  0.052531661689281466  Test L2 Loss :  0.09143473893404007  inv_L_scale:  [1.0, 1.0]
Epoch :  88  Time:  0.938  Rel. Train L2 Loss :  0.05045558619830343  Rel. Test L2 Loss :  0.057572540789842606  Test L2 Loss :  0.10161188155412675  inv_L_scale:  [1.0, 1.0]
Epoch :  89  Time:  0.938  Rel. Train L2 Loss :  0.05090674592389001  Rel. Test L2 Loss :  0.05215711832046509  Test L2 Loss :  0.09027556717395782  inv_L_scale:  [1.0, 1.0]
Epoch :  90  Time:  0.938  Rel. Train L2 Loss :  0.04954407433668773  Rel. Test L2 Loss :  0.05324663013219833  Test L2 Loss :  0.09322603464126587  inv_L_scale:  [1.0, 1.0]
Epoch :  91  Time:  0.939  Rel. Train L2 Loss :  0.050020805696646374  Rel. Test L2 Loss :  0.056799305826425554  Test L2 Loss :  0.0990948474407196  inv_L_scale:  [1.0, 1.0]
Epoch :  92  Time:  0.938  Rel. Train L2 Loss :  0.04944634033573998  Rel. Test L2 Loss :  0.052600757479667665  Test L2 Loss :  0.09131815016269684  inv_L_scale:  [1.0, 1.0]
Epoch :  93  Time:  0.938  Rel. Train L2 Loss :  0.05014252881209055  Rel. Test L2 Loss :  0.054461380541324614  Test L2 Loss :  0.09454662144184113  inv_L_scale:  [1.0, 1.0]
Epoch :  94  Time:  0.938  Rel. Train L2 Loss :  0.04986678133408229  Rel. Test L2 Loss :  0.05442878901958466  Test L2 Loss :  0.09451271921396255  inv_L_scale:  [1.0, 1.0]
Epoch :  95  Time:  0.939  Rel. Train L2 Loss :  0.049425013777282506  Rel. Test L2 Loss :  0.05346304655075073  Test L2 Loss :  0.09360475689172745  inv_L_scale:  [1.0, 1.0]
Epoch :  96  Time:  0.938  Rel. Train L2 Loss :  0.04910757096277343  Rel. Test L2 Loss :  0.05431900352239609  Test L2 Loss :  0.09400022566318512  inv_L_scale:  [1.0, 1.0]
Epoch :  97  Time:  0.938  Rel. Train L2 Loss :  0.04884029037422604  Rel. Test L2 Loss :  0.05471366435289383  Test L2 Loss :  0.09489425659179687  inv_L_scale:  [1.0, 1.0]
Epoch :  98  Time:  0.938  Rel. Train L2 Loss :  0.04927151025997268  Rel. Test L2 Loss :  0.05357989102602005  Test L2 Loss :  0.09322327613830567  inv_L_scale:  [1.0, 1.0]
Epoch :  99  Time:  0.938  Rel. Train L2 Loss :  0.04942096443639861  Rel. Test L2 Loss :  0.05226625829935074  Test L2 Loss :  0.09101091623306275  inv_L_scale:  [1.0, 1.0]
Epoch :  100  Time:  0.938  Rel. Train L2 Loss :  0.048666750440994895  Rel. Test L2 Loss :  0.052552314400672914  Test L2 Loss :  0.0911849182844162  inv_L_scale:  [1.0, 1.0]
Epoch :  101  Time:  0.938  Rel. Train L2 Loss :  0.0495389954580201  Rel. Test L2 Loss :  0.051574507355690004  Test L2 Loss :  0.088965425491333  inv_L_scale:  [1.0, 1.0]
Epoch :  102  Time:  0.938  Rel. Train L2 Loss :  0.04887180325057772  Rel. Test L2 Loss :  0.051686547100543975  Test L2 Loss :  0.090651835501194  inv_L_scale:  [1.0, 1.0]
Epoch :  103  Time:  0.938  Rel. Train L2 Loss :  0.04945247176620695  Rel. Test L2 Loss :  0.05311164170503616  Test L2 Loss :  0.09185421526432037  inv_L_scale:  [1.0, 1.0]
Epoch :  104  Time:  0.941  Rel. Train L2 Loss :  0.04853144331110848  Rel. Test L2 Loss :  0.051424335539340976  Test L2 Loss :  0.08891190648078919  inv_L_scale:  [1.0, 1.0]
Epoch :  105  Time:  0.94  Rel. Train L2 Loss :  0.048928605483637914  Rel. Test L2 Loss :  0.05283173829317093  Test L2 Loss :  0.09206697821617127  inv_L_scale:  [1.0, 1.0]
Epoch :  106  Time:  0.938  Rel. Train L2 Loss :  0.04862257209089067  Rel. Test L2 Loss :  0.053141540586948394  Test L2 Loss :  0.09166045367717743  inv_L_scale:  [1.0, 1.0]
Epoch :  107  Time:  0.938  Rel. Train L2 Loss :  0.04847829951180352  Rel. Test L2 Loss :  0.05684561371803284  Test L2 Loss :  0.0992132693529129  inv_L_scale:  [1.0, 1.0]
Epoch :  108  Time:  0.938  Rel. Train L2 Loss :  0.0494472652177016  Rel. Test L2 Loss :  0.05855387300252914  Test L2 Loss :  0.10328339755535126  inv_L_scale:  [1.0, 1.0]
Epoch :  109  Time:  0.938  Rel. Train L2 Loss :  0.04848224921358956  Rel. Test L2 Loss :  0.0502603679895401  Test L2 Loss :  0.08707329094409942  inv_L_scale:  [1.0, 1.0]
Epoch :  110  Time:  0.937  Rel. Train L2 Loss :  0.04757829113139046  Rel. Test L2 Loss :  0.05137154370546341  Test L2 Loss :  0.0894718638062477  inv_L_scale:  [1.0, 1.0]
Epoch :  111  Time:  0.938  Rel. Train L2 Loss :  0.04807371288537979  Rel. Test L2 Loss :  0.0497502651810646  Test L2 Loss :  0.08602521479129792  inv_L_scale:  [1.0, 1.0]
Epoch :  112  Time:  0.938  Rel. Train L2 Loss :  0.04775893968012598  Rel. Test L2 Loss :  0.05084803432226181  Test L2 Loss :  0.08919230163097382  inv_L_scale:  [1.0, 1.0]
Epoch :  113  Time:  0.939  Rel. Train L2 Loss :  0.04746532056066725  Rel. Test L2 Loss :  0.05103181332349777  Test L2 Loss :  0.0883387303352356  inv_L_scale:  [1.0, 1.0]
Epoch :  114  Time:  0.938  Rel. Train L2 Loss :  0.04800390515062544  Rel. Test L2 Loss :  0.05034986674785614  Test L2 Loss :  0.0874683791399002  inv_L_scale:  [1.0, 1.0]
Epoch :  115  Time:  0.937  Rel. Train L2 Loss :  0.04770998390184508  Rel. Test L2 Loss :  0.05236990660429001  Test L2 Loss :  0.09217341065406799  inv_L_scale:  [1.0, 1.0]
Epoch :  116  Time:  0.938  Rel. Train L2 Loss :  0.0480036152071423  Rel. Test L2 Loss :  0.05025902897119522  Test L2 Loss :  0.08857139348983764  inv_L_scale:  [1.0, 1.0]
Epoch :  117  Time:  0.938  Rel. Train L2 Loss :  0.04715911888413959  Rel. Test L2 Loss :  0.05004688858985901  Test L2 Loss :  0.08805707693099976  inv_L_scale:  [1.0, 1.0]
Epoch :  118  Time:  0.938  Rel. Train L2 Loss :  0.047541210220919713  Rel. Test L2 Loss :  0.05275101825594902  Test L2 Loss :  0.09189456403255462  inv_L_scale:  [1.0, 1.0]
Epoch :  119  Time:  0.939  Rel. Train L2 Loss :  0.04773305666115549  Rel. Test L2 Loss :  0.04862109810113907  Test L2 Loss :  0.08485164523124694  inv_L_scale:  [1.0, 1.0]
Epoch :  120  Time:  0.938  Rel. Train L2 Loss :  0.048129855973853004  Rel. Test L2 Loss :  0.051829621493816376  Test L2 Loss :  0.09027954995632172  inv_L_scale:  [1.0, 1.0]
Epoch :  121  Time:  0.937  Rel. Train L2 Loss :  0.04747909744580587  Rel. Test L2 Loss :  0.049515085816383364  Test L2 Loss :  0.08522184520959854  inv_L_scale:  [1.0, 1.0]
Epoch :  122  Time:  0.937  Rel. Train L2 Loss :  0.047284274366166855  Rel. Test L2 Loss :  0.04991226404905319  Test L2 Loss :  0.08619496464729309  inv_L_scale:  [1.0, 1.0]
Epoch :  123  Time:  0.937  Rel. Train L2 Loss :  0.04749431957801183  Rel. Test L2 Loss :  0.04892944008111954  Test L2 Loss :  0.08461122184991837  inv_L_scale:  [1.0, 1.0]
Epoch :  124  Time:  0.938  Rel. Train L2 Loss :  0.04679530425204171  Rel. Test L2 Loss :  0.049471246004104616  Test L2 Loss :  0.08563344478607178  inv_L_scale:  [1.0, 1.0]
Epoch :  125  Time:  0.938  Rel. Train L2 Loss :  0.04697336388958825  Rel. Test L2 Loss :  0.0502511128783226  Test L2 Loss :  0.08756848752498626  inv_L_scale:  [1.0, 1.0]
Epoch :  126  Time:  0.938  Rel. Train L2 Loss :  0.046729249440961414  Rel. Test L2 Loss :  0.048869607150554654  Test L2 Loss :  0.08475088745355606  inv_L_scale:  [1.0, 1.0]
Epoch :  127  Time:  0.938  Rel. Train L2 Loss :  0.046724864542484285  Rel. Test L2 Loss :  0.05158848077058792  Test L2 Loss :  0.09071181535720825  inv_L_scale:  [1.0, 1.0]
Epoch :  128  Time:  0.938  Rel. Train L2 Loss :  0.04730141046974394  Rel. Test L2 Loss :  0.050100276172161104  Test L2 Loss :  0.08696869313716889  inv_L_scale:  [1.0, 1.0]
Epoch :  129  Time:  0.938  Rel. Train L2 Loss :  0.047257544116841424  Rel. Test L2 Loss :  0.051189612746238705  Test L2 Loss :  0.08835633486509323  inv_L_scale:  [1.0, 1.0]
Epoch :  130  Time:  0.941  Rel. Train L2 Loss :  0.046825115780035655  Rel. Test L2 Loss :  0.048922397941350934  Test L2 Loss :  0.08409406363964081  inv_L_scale:  [1.0, 1.0]
Epoch :  131  Time:  0.938  Rel. Train L2 Loss :  0.046569781932565904  Rel. Test L2 Loss :  0.05282669678330421  Test L2 Loss :  0.09228006958961486  inv_L_scale:  [1.0, 1.0]
Epoch :  132  Time:  0.938  Rel. Train L2 Loss :  0.04736895591020584  Rel. Test L2 Loss :  0.0512523278594017  Test L2 Loss :  0.08831569194793701  inv_L_scale:  [1.0, 1.0]
Epoch :  133  Time:  0.938  Rel. Train L2 Loss :  0.0472035637166765  Rel. Test L2 Loss :  0.04831291347742081  Test L2 Loss :  0.08351792454719544  inv_L_scale:  [1.0, 1.0]
Epoch :  134  Time:  0.938  Rel. Train L2 Loss :  0.04643327588836352  Rel. Test L2 Loss :  0.05062347799539566  Test L2 Loss :  0.08765519201755524  inv_L_scale:  [1.0, 1.0]
Epoch :  135  Time:  0.937  Rel. Train L2 Loss :  0.04643449938959546  Rel. Test L2 Loss :  0.04826106950640678  Test L2 Loss :  0.08297619938850403  inv_L_scale:  [1.0, 1.0]
Epoch :  136  Time:  0.938  Rel. Train L2 Loss :  0.04662184036440319  Rel. Test L2 Loss :  0.04968710064888  Test L2 Loss :  0.08628247618675232  inv_L_scale:  [1.0, 1.0]
Epoch :  137  Time:  0.938  Rel. Train L2 Loss :  0.0464930082195335  Rel. Test L2 Loss :  0.05170559257268906  Test L2 Loss :  0.08937998712062836  inv_L_scale:  [1.0, 1.0]
Epoch :  138  Time:  0.938  Rel. Train L2 Loss :  0.04676913638909658  Rel. Test L2 Loss :  0.049107346832752224  Test L2 Loss :  0.08428632229566574  inv_L_scale:  [1.0, 1.0]
Epoch :  139  Time:  0.936  Rel. Train L2 Loss :  0.046202694608105555  Rel. Test L2 Loss :  0.049829133003950116  Test L2 Loss :  0.08675816118717193  inv_L_scale:  [1.0, 1.0]
Epoch :  140  Time:  0.936  Rel. Train L2 Loss :  0.047249253557788  Rel. Test L2 Loss :  0.053241530805826186  Test L2 Loss :  0.09251317948102951  inv_L_scale:  [1.0, 1.0]
Epoch :  141  Time:  0.937  Rel. Train L2 Loss :  0.04617210167977545  Rel. Test L2 Loss :  0.0535605862736702  Test L2 Loss :  0.09357239365577698  inv_L_scale:  [1.0, 1.0]
Epoch :  142  Time:  0.937  Rel. Train L2 Loss :  0.04682742714881897  Rel. Test L2 Loss :  0.05036963045597077  Test L2 Loss :  0.08721108555793762  inv_L_scale:  [1.0, 1.0]
Epoch :  143  Time:  0.937  Rel. Train L2 Loss :  0.046435760905345284  Rel. Test L2 Loss :  0.04994603395462036  Test L2 Loss :  0.08597111731767654  inv_L_scale:  [1.0, 1.0]
Epoch :  144  Time:  0.937  Rel. Train L2 Loss :  0.04587339053551356  Rel. Test L2 Loss :  0.04846621036529541  Test L2 Loss :  0.08355594485998154  inv_L_scale:  [1.0, 1.0]
Epoch :  145  Time:  0.936  Rel. Train L2 Loss :  0.045885723647144105  Rel. Test L2 Loss :  0.04967633187770844  Test L2 Loss :  0.08585115134716034  inv_L_scale:  [1.0, 1.0]
Epoch :  146  Time:  0.937  Rel. Train L2 Loss :  0.0466912565794256  Rel. Test L2 Loss :  0.050218604356050495  Test L2 Loss :  0.08708583414554597  inv_L_scale:  [1.0, 1.0]
Epoch :  147  Time:  0.938  Rel. Train L2 Loss :  0.04582381457090378  Rel. Test L2 Loss :  0.04766430139541626  Test L2 Loss :  0.08259346812963486  inv_L_scale:  [1.0, 1.0]
Epoch :  148  Time:  0.938  Rel. Train L2 Loss :  0.04573015962209966  Rel. Test L2 Loss :  0.047971665263175964  Test L2 Loss :  0.08267145097255707  inv_L_scale:  [1.0, 1.0]
Epoch :  149  Time:  0.937  Rel. Train L2 Loss :  0.04604161688023144  Rel. Test L2 Loss :  0.04715083420276642  Test L2 Loss :  0.08158764123916626  inv_L_scale:  [1.0, 1.0]
Epoch :  150  Time:  0.937  Rel. Train L2 Loss :  0.04631563925080829  Rel. Test L2 Loss :  0.04805621474981308  Test L2 Loss :  0.08305753648281097  inv_L_scale:  [1.0, 1.0]
Epoch :  151  Time:  0.937  Rel. Train L2 Loss :  0.04596856986482938  Rel. Test L2 Loss :  0.04999462515115738  Test L2 Loss :  0.08737909644842148  inv_L_scale:  [1.0, 1.0]
Epoch :  152  Time:  0.938  Rel. Train L2 Loss :  0.04579481275545226  Rel. Test L2 Loss :  0.050990884453058244  Test L2 Loss :  0.08781733334064484  inv_L_scale:  [1.0, 1.0]
Epoch :  153  Time:  0.938  Rel. Train L2 Loss :  0.045757785340150195  Rel. Test L2 Loss :  0.047645622193813325  Test L2 Loss :  0.08215425401926041  inv_L_scale:  [1.0, 1.0]
Epoch :  154  Time:  0.938  Rel. Train L2 Loss :  0.04544324138098293  Rel. Test L2 Loss :  0.04779760628938675  Test L2 Loss :  0.0827356642484665  inv_L_scale:  [1.0, 1.0]
Epoch :  155  Time:  0.938  Rel. Train L2 Loss :  0.04545529315869013  Rel. Test L2 Loss :  0.050257910043001175  Test L2 Loss :  0.0872817200422287  inv_L_scale:  [1.0, 1.0]
Epoch :  156  Time:  0.939  Rel. Train L2 Loss :  0.04580259364512232  Rel. Test L2 Loss :  0.04782503306865692  Test L2 Loss :  0.08244153499603271  inv_L_scale:  [1.0, 1.0]
Epoch :  157  Time:  0.939  Rel. Train L2 Loss :  0.04568437515033616  Rel. Test L2 Loss :  0.04766183063387871  Test L2 Loss :  0.08257329165935516  inv_L_scale:  [1.0, 1.0]
Epoch :  158  Time:  0.939  Rel. Train L2 Loss :  0.04555718370609813  Rel. Test L2 Loss :  0.048874223977327345  Test L2 Loss :  0.08439801752567291  inv_L_scale:  [1.0, 1.0]
Epoch :  159  Time:  0.938  Rel. Train L2 Loss :  0.04583555516269472  Rel. Test L2 Loss :  0.04744709312915802  Test L2 Loss :  0.08186873197555541  inv_L_scale:  [1.0, 1.0]
Epoch :  160  Time:  0.94  Rel. Train L2 Loss :  0.045464538468254934  Rel. Test L2 Loss :  0.048370261192321774  Test L2 Loss :  0.08310406535863876  inv_L_scale:  [1.0, 1.0]
Epoch :  161  Time:  0.941  Rel. Train L2 Loss :  0.045629041228029465  Rel. Test L2 Loss :  0.048002290427684786  Test L2 Loss :  0.08273153424263001  inv_L_scale:  [1.0, 1.0]
Epoch :  162  Time:  0.939  Rel. Train L2 Loss :  0.04535651963618067  Rel. Test L2 Loss :  0.04833589196205139  Test L2 Loss :  0.08376716554164887  inv_L_scale:  [1.0, 1.0]
Epoch :  163  Time:  0.939  Rel. Train L2 Loss :  0.045165737453434204  Rel. Test L2 Loss :  0.049007294327020647  Test L2 Loss :  0.085401009619236  inv_L_scale:  [1.0, 1.0]
Epoch :  164  Time:  0.939  Rel. Train L2 Loss :  0.045624709443913565  Rel. Test L2 Loss :  0.048371699452400205  Test L2 Loss :  0.08401967257261277  inv_L_scale:  [1.0, 1.0]
Epoch :  165  Time:  0.939  Rel. Train L2 Loss :  0.04522801501883401  Rel. Test L2 Loss :  0.04644166812300682  Test L2 Loss :  0.08022090911865234  inv_L_scale:  [1.0, 1.0]
Epoch :  166  Time:  0.938  Rel. Train L2 Loss :  0.045237165076865093  Rel. Test L2 Loss :  0.04762203425168991  Test L2 Loss :  0.08184264957904816  inv_L_scale:  [1.0, 1.0]
Epoch :  167  Time:  0.939  Rel. Train L2 Loss :  0.04541232104102771  Rel. Test L2 Loss :  0.04795742675662041  Test L2 Loss :  0.0831469339132309  inv_L_scale:  [1.0, 1.0]
Epoch :  168  Time:  0.939  Rel. Train L2 Loss :  0.046023084537850485  Rel. Test L2 Loss :  0.047761899828910825  Test L2 Loss :  0.08206746608018875  inv_L_scale:  [1.0, 1.0]
Epoch :  169  Time:  0.939  Rel. Train L2 Loss :  0.04511685631341404  Rel. Test L2 Loss :  0.04682465195655823  Test L2 Loss :  0.08102529644966125  inv_L_scale:  [1.0, 1.0]
Epoch :  170  Time:  0.938  Rel. Train L2 Loss :  0.045155450138780806  Rel. Test L2 Loss :  0.046771607995033264  Test L2 Loss :  0.08056466162204742  inv_L_scale:  [1.0, 1.0]
Epoch :  171  Time:  0.938  Rel. Train L2 Loss :  0.04530657667252753  Rel. Test L2 Loss :  0.051778161227703096  Test L2 Loss :  0.08994357407093048  inv_L_scale:  [1.0, 1.0]
Epoch :  172  Time:  0.938  Rel. Train L2 Loss :  0.04570621896121237  Rel. Test L2 Loss :  0.04671832859516144  Test L2 Loss :  0.08088116109371185  inv_L_scale:  [1.0, 1.0]
Epoch :  173  Time:  0.938  Rel. Train L2 Loss :  0.0446796214249399  Rel. Test L2 Loss :  0.04795185282826424  Test L2 Loss :  0.08294532001018524  inv_L_scale:  [1.0, 1.0]
Epoch :  174  Time:  0.938  Rel. Train L2 Loss :  0.045253385222620436  Rel. Test L2 Loss :  0.047523381114006044  Test L2 Loss :  0.08257550090551376  inv_L_scale:  [1.0, 1.0]
Epoch :  175  Time:  0.938  Rel. Train L2 Loss :  0.04468070566654205  Rel. Test L2 Loss :  0.04781472265720368  Test L2 Loss :  0.08307377934455872  inv_L_scale:  [1.0, 1.0]
Epoch :  176  Time:  0.94  Rel. Train L2 Loss :  0.04470980470379193  Rel. Test L2 Loss :  0.04712588429450989  Test L2 Loss :  0.08147866159677505  inv_L_scale:  [1.0, 1.0]
Epoch :  177  Time:  0.937  Rel. Train L2 Loss :  0.04491577496131261  Rel. Test L2 Loss :  0.04767798259854317  Test L2 Loss :  0.08226790964603424  inv_L_scale:  [1.0, 1.0]
Epoch :  178  Time:  0.937  Rel. Train L2 Loss :  0.044853847258620794  Rel. Test L2 Loss :  0.048038611710071566  Test L2 Loss :  0.08328531920909882  inv_L_scale:  [1.0, 1.0]
Epoch :  179  Time:  0.937  Rel. Train L2 Loss :  0.045004211515188214  Rel. Test L2 Loss :  0.04773887664079666  Test L2 Loss :  0.08345488607883453  inv_L_scale:  [1.0, 1.0]
Epoch :  180  Time:  0.937  Rel. Train L2 Loss :  0.0444534098274178  Rel. Test L2 Loss :  0.046546874344348906  Test L2 Loss :  0.08004174798727036  inv_L_scale:  [1.0, 1.0]
Epoch :  181  Time:  0.937  Rel. Train L2 Loss :  0.04510247939162784  Rel. Test L2 Loss :  0.048275156915187835  Test L2 Loss :  0.08395638555288315  inv_L_scale:  [1.0, 1.0]
Epoch :  182  Time:  0.939  Rel. Train L2 Loss :  0.044726290702819825  Rel. Test L2 Loss :  0.05062557205557823  Test L2 Loss :  0.08730494350194931  inv_L_scale:  [1.0, 1.0]
Epoch :  183  Time:  0.938  Rel. Train L2 Loss :  0.0452353402475516  Rel. Test L2 Loss :  0.04682278364896774  Test L2 Loss :  0.08121717631816865  inv_L_scale:  [1.0, 1.0]
Epoch :  184  Time:  0.937  Rel. Train L2 Loss :  0.04460739634103245  Rel. Test L2 Loss :  0.0477327561378479  Test L2 Loss :  0.08235153794288635  inv_L_scale:  [1.0, 1.0]
Epoch :  185  Time:  0.937  Rel. Train L2 Loss :  0.044894689056608414  Rel. Test L2 Loss :  0.04934582144021988  Test L2 Loss :  0.08628486901521683  inv_L_scale:  [1.0, 1.0]
Epoch :  186  Time:  0.939  Rel. Train L2 Loss :  0.04475055976046456  Rel. Test L2 Loss :  0.0464478400349617  Test L2 Loss :  0.07973565995693206  inv_L_scale:  [1.0, 1.0]
Epoch :  187  Time:  0.946  Rel. Train L2 Loss :  0.044594861020644506  Rel. Test L2 Loss :  0.04943330675363541  Test L2 Loss :  0.08617905586957932  inv_L_scale:  [1.0, 1.0]
Epoch :  188  Time:  0.945  Rel. Train L2 Loss :  0.04448157898253865  Rel. Test L2 Loss :  0.047298620343208315  Test L2 Loss :  0.08120604127645492  inv_L_scale:  [1.0, 1.0]
Epoch :  189  Time:  0.945  Rel. Train L2 Loss :  0.04459791400366359  Rel. Test L2 Loss :  0.047425431609153745  Test L2 Loss :  0.08131150484085083  inv_L_scale:  [1.0, 1.0]
Epoch :  190  Time:  0.945  Rel. Train L2 Loss :  0.044425945331652957  Rel. Test L2 Loss :  0.04988344728946686  Test L2 Loss :  0.08590483039617539  inv_L_scale:  [1.0, 1.0]
Epoch :  191  Time:  0.945  Rel. Train L2 Loss :  0.0446920030646854  Rel. Test L2 Loss :  0.046792587637901305  Test L2 Loss :  0.08070379614830017  inv_L_scale:  [1.0, 1.0]
Epoch :  192  Time:  0.945  Rel. Train L2 Loss :  0.04490720570087433  Rel. Test L2 Loss :  0.049059671759605405  Test L2 Loss :  0.08569821268320084  inv_L_scale:  [1.0, 1.0]
Epoch :  193  Time:  0.945  Rel. Train L2 Loss :  0.04450065753526158  Rel. Test L2 Loss :  0.04723898723721504  Test L2 Loss :  0.08115339666604995  inv_L_scale:  [1.0, 1.0]
Epoch :  194  Time:  0.945  Rel. Train L2 Loss :  0.04482289238108529  Rel. Test L2 Loss :  0.046044391393661496  Test L2 Loss :  0.07932875603437424  inv_L_scale:  [1.0, 1.0]
Epoch :  195  Time:  0.945  Rel. Train L2 Loss :  0.04446241014533573  Rel. Test L2 Loss :  0.04648059606552124  Test L2 Loss :  0.08024454712867737  inv_L_scale:  [1.0, 1.0]
Epoch :  196  Time:  0.944  Rel. Train L2 Loss :  0.04459123513764805  Rel. Test L2 Loss :  0.04611384987831116  Test L2 Loss :  0.07940050899982452  inv_L_scale:  [1.0, 1.0]
Epoch :  197  Time:  0.944  Rel. Train L2 Loss :  0.04414235293865204  Rel. Test L2 Loss :  0.04631856679916382  Test L2 Loss :  0.07966041743755341  inv_L_scale:  [1.0, 1.0]
Epoch :  198  Time:  0.943  Rel. Train L2 Loss :  0.04432862909303771  Rel. Test L2 Loss :  0.04619596302509308  Test L2 Loss :  0.0798808604478836  inv_L_scale:  [1.0, 1.0]
Epoch :  199  Time:  0.941  Rel. Train L2 Loss :  0.04457262655099233  Rel. Test L2 Loss :  0.046702527850866316  Test L2 Loss :  0.08025629222393035  inv_L_scale:  [1.0, 1.0]
Epoch :  200  Time:  0.941  Rel. Train L2 Loss :  0.04410951677295897  Rel. Test L2 Loss :  0.04874646335840225  Test L2 Loss :  0.08423783421516419  inv_L_scale:  [1.0, 1.0]
Epoch :  201  Time:  0.941  Rel. Train L2 Loss :  0.04422974068257544  Rel. Test L2 Loss :  0.04622047603130341  Test L2 Loss :  0.08007290989160537  inv_L_scale:  [1.0, 1.0]
Epoch :  202  Time:  0.941  Rel. Train L2 Loss :  0.044233817193243236  Rel. Test L2 Loss :  0.048235798180103304  Test L2 Loss :  0.08343899786472321  inv_L_scale:  [1.0, 1.0]
Epoch :  203  Time:  0.941  Rel. Train L2 Loss :  0.04462250875102149  Rel. Test L2 Loss :  0.04819123119115829  Test L2 Loss :  0.08420274764299393  inv_L_scale:  [1.0, 1.0]
Epoch :  204  Time:  0.941  Rel. Train L2 Loss :  0.044548189904954696  Rel. Test L2 Loss :  0.046311895549297336  Test L2 Loss :  0.07951777040958405  inv_L_scale:  [1.0, 1.0]
Epoch :  205  Time:  0.941  Rel. Train L2 Loss :  0.04399322486586041  Rel. Test L2 Loss :  0.04693047896027565  Test L2 Loss :  0.0809081256389618  inv_L_scale:  [1.0, 1.0]
Epoch :  206  Time:  0.942  Rel. Train L2 Loss :  0.043926624639166724  Rel. Test L2 Loss :  0.0476463919878006  Test L2 Loss :  0.08282797187566757  inv_L_scale:  [1.0, 1.0]
Epoch :  207  Time:  0.941  Rel. Train L2 Loss :  0.044185242123074  Rel. Test L2 Loss :  0.046650444865226744  Test L2 Loss :  0.08036757230758668  inv_L_scale:  [1.0, 1.0]
Epoch :  208  Time:  0.941  Rel. Train L2 Loss :  0.044015558080540765  Rel. Test L2 Loss :  0.04603985041379929  Test L2 Loss :  0.07924638241529465  inv_L_scale:  [1.0, 1.0]
Epoch :  209  Time:  0.942  Rel. Train L2 Loss :  0.044420009719000925  Rel. Test L2 Loss :  0.046994304955005645  Test L2 Loss :  0.08131129741668701  inv_L_scale:  [1.0, 1.0]
Epoch :  210  Time:  0.94  Rel. Train L2 Loss :  0.044183838135666315  Rel. Test L2 Loss :  0.0457245272397995  Test L2 Loss :  0.07913272947072983  inv_L_scale:  [1.0, 1.0]
Epoch :  211  Time:  0.94  Rel. Train L2 Loss :  0.044185259971353745  Rel. Test L2 Loss :  0.04708147883415222  Test L2 Loss :  0.08106270611286163  inv_L_scale:  [1.0, 1.0]
Epoch :  212  Time:  0.941  Rel. Train L2 Loss :  0.04418616720371776  Rel. Test L2 Loss :  0.045431649088859556  Test L2 Loss :  0.07790309846401215  inv_L_scale:  [1.0, 1.0]
Epoch :  213  Time:  0.941  Rel. Train L2 Loss :  0.044017715288533106  Rel. Test L2 Loss :  0.04984708160161972  Test L2 Loss :  0.08836184322834015  inv_L_scale:  [1.0, 1.0]
Epoch :  214  Time:  0.941  Rel. Train L2 Loss :  0.043807993845807185  Rel. Test L2 Loss :  0.04661811649799347  Test L2 Loss :  0.08015721321105956  inv_L_scale:  [1.0, 1.0]
Epoch :  215  Time:  0.94  Rel. Train L2 Loss :  0.04405564473734962  Rel. Test L2 Loss :  0.046897809803485874  Test L2 Loss :  0.08081205248832703  inv_L_scale:  [1.0, 1.0]
Epoch :  216  Time:  0.94  Rel. Train L2 Loss :  0.04385509823759397  Rel. Test L2 Loss :  0.04689674630761147  Test L2 Loss :  0.08092482268810272  inv_L_scale:  [1.0, 1.0]
Epoch :  217  Time:  0.941  Rel. Train L2 Loss :  0.044064807444810866  Rel. Test L2 Loss :  0.04719810038805008  Test L2 Loss :  0.0819536155462265  inv_L_scale:  [1.0, 1.0]
Epoch :  218  Time:  0.941  Rel. Train L2 Loss :  0.04381456279092365  Rel. Test L2 Loss :  0.04683431297540665  Test L2 Loss :  0.08091853141784668  inv_L_scale:  [1.0, 1.0]
Epoch :  219  Time:  0.94  Rel. Train L2 Loss :  0.04385950917998949  Rel. Test L2 Loss :  0.046229673475027086  Test L2 Loss :  0.07956048905849457  inv_L_scale:  [1.0, 1.0]
Epoch :  220  Time:  0.942  Rel. Train L2 Loss :  0.043730578869581226  Rel. Test L2 Loss :  0.04539888620376587  Test L2 Loss :  0.07825359851121902  inv_L_scale:  [1.0, 1.0]
Epoch :  221  Time:  0.941  Rel. Train L2 Loss :  0.043703200833665  Rel. Test L2 Loss :  0.046641857624053956  Test L2 Loss :  0.08051920115947724  inv_L_scale:  [1.0, 1.0]
Epoch :  222  Time:  0.941  Rel. Train L2 Loss :  0.04392361652519968  Rel. Test L2 Loss :  0.04781255155801773  Test L2 Loss :  0.08233068525791168  inv_L_scale:  [1.0, 1.0]
Epoch :  223  Time:  0.941  Rel. Train L2 Loss :  0.0439935414161947  Rel. Test L2 Loss :  0.047840284407138826  Test L2 Loss :  0.08339123547077179  inv_L_scale:  [1.0, 1.0]
Epoch :  224  Time:  0.94  Rel. Train L2 Loss :  0.04364280455642276  Rel. Test L2 Loss :  0.04605448395013809  Test L2 Loss :  0.07874312669038773  inv_L_scale:  [1.0, 1.0]
Epoch :  225  Time:  0.94  Rel. Train L2 Loss :  0.043792006903224524  Rel. Test L2 Loss :  0.04638427168130874  Test L2 Loss :  0.08014773726463317  inv_L_scale:  [1.0, 1.0]
Epoch :  226  Time:  0.94  Rel. Train L2 Loss :  0.043890483147568174  Rel. Test L2 Loss :  0.04608500152826309  Test L2 Loss :  0.07933892250061035  inv_L_scale:  [1.0, 1.0]
Epoch :  227  Time:  0.94  Rel. Train L2 Loss :  0.04391133947504891  Rel. Test L2 Loss :  0.046783223152160644  Test L2 Loss :  0.08048970401287078  inv_L_scale:  [1.0, 1.0]
Epoch :  228  Time:  0.94  Rel. Train L2 Loss :  0.04356818094849586  Rel. Test L2 Loss :  0.04581821992993355  Test L2 Loss :  0.07881423532962799  inv_L_scale:  [1.0, 1.0]
Epoch :  229  Time:  0.94  Rel. Train L2 Loss :  0.04367088046338823  Rel. Test L2 Loss :  0.04675388008356094  Test L2 Loss :  0.08091991007328034  inv_L_scale:  [1.0, 1.0]
Epoch :  230  Time:  0.94  Rel. Train L2 Loss :  0.04354662674996588  Rel. Test L2 Loss :  0.044462410807609556  Test L2 Loss :  0.07669581741094589  inv_L_scale:  [1.0, 1.0]
Epoch :  231  Time:  0.941  Rel. Train L2 Loss :  0.04340133866502179  Rel. Test L2 Loss :  0.04618667677044869  Test L2 Loss :  0.0794996702671051  inv_L_scale:  [1.0, 1.0]
Epoch :  232  Time:  0.941  Rel. Train L2 Loss :  0.04326010637813144  Rel. Test L2 Loss :  0.04560662180185318  Test L2 Loss :  0.07859073102474212  inv_L_scale:  [1.0, 1.0]
Epoch :  233  Time:  0.941  Rel. Train L2 Loss :  0.04349257248971197  Rel. Test L2 Loss :  0.04561051234602928  Test L2 Loss :  0.07886409729719163  inv_L_scale:  [1.0, 1.0]
Epoch :  234  Time:  0.94  Rel. Train L2 Loss :  0.043507041384776436  Rel. Test L2 Loss :  0.04597766011953354  Test L2 Loss :  0.07902878314256669  inv_L_scale:  [1.0, 1.0]
Epoch :  235  Time:  0.94  Rel. Train L2 Loss :  0.043521862592962056  Rel. Test L2 Loss :  0.04620538219809532  Test L2 Loss :  0.07931134939193725  inv_L_scale:  [1.0, 1.0]
Epoch :  236  Time:  0.94  Rel. Train L2 Loss :  0.0435174055563079  Rel. Test L2 Loss :  0.04529717177152634  Test L2 Loss :  0.07811509549617768  inv_L_scale:  [1.0, 1.0]
Epoch :  237  Time:  0.941  Rel. Train L2 Loss :  0.04341894725958506  Rel. Test L2 Loss :  0.04835916668176651  Test L2 Loss :  0.08460025697946548  inv_L_scale:  [1.0, 1.0]
Epoch :  238  Time:  0.94  Rel. Train L2 Loss :  0.043752336651086805  Rel. Test L2 Loss :  0.04570333480834961  Test L2 Loss :  0.07860010415315628  inv_L_scale:  [1.0, 1.0]
Epoch :  239  Time:  0.94  Rel. Train L2 Loss :  0.04301397114992142  Rel. Test L2 Loss :  0.046018846333026886  Test L2 Loss :  0.07929574429988862  inv_L_scale:  [1.0, 1.0]
Epoch :  240  Time:  0.94  Rel. Train L2 Loss :  0.04332944187853072  Rel. Test L2 Loss :  0.04636700972914696  Test L2 Loss :  0.07993280112743378  inv_L_scale:  [1.0, 1.0]
Epoch :  241  Time:  0.94  Rel. Train L2 Loss :  0.0435764037238227  Rel. Test L2 Loss :  0.04604270741343498  Test L2 Loss :  0.07938230872154235  inv_L_scale:  [1.0, 1.0]
Epoch :  242  Time:  0.942  Rel. Train L2 Loss :  0.043362528185049695  Rel. Test L2 Loss :  0.045515204817056655  Test L2 Loss :  0.07876921176910401  inv_L_scale:  [1.0, 1.0]
Epoch :  243  Time:  0.94  Rel. Train L2 Loss :  0.0433727778825495  Rel. Test L2 Loss :  0.04618290662765503  Test L2 Loss :  0.0799206754565239  inv_L_scale:  [1.0, 1.0]
Epoch :  244  Time:  0.94  Rel. Train L2 Loss :  0.043158998919857874  Rel. Test L2 Loss :  0.046679812967777255  Test L2 Loss :  0.08038750737905502  inv_L_scale:  [1.0, 1.0]
Epoch :  245  Time:  0.94  Rel. Train L2 Loss :  0.04337261006236076  Rel. Test L2 Loss :  0.04484464555978775  Test L2 Loss :  0.07718968391418457  inv_L_scale:  [1.0, 1.0]
Epoch :  246  Time:  0.94  Rel. Train L2 Loss :  0.04326274863547749  Rel. Test L2 Loss :  0.047420907318592075  Test L2 Loss :  0.08132516145706177  inv_L_scale:  [1.0, 1.0]
Epoch :  247  Time:  0.94  Rel. Train L2 Loss :  0.04341120171878073  Rel. Test L2 Loss :  0.0451864667236805  Test L2 Loss :  0.07803951621055603  inv_L_scale:  [1.0, 1.0]
Epoch :  248  Time:  0.94  Rel. Train L2 Loss :  0.04300842253698243  Rel. Test L2 Loss :  0.04704236775636673  Test L2 Loss :  0.08192267119884492  inv_L_scale:  [1.0, 1.0]
Epoch :  249  Time:  0.941  Rel. Train L2 Loss :  0.043255311134788726  Rel. Test L2 Loss :  0.04595373511314392  Test L2 Loss :  0.07951807171106338  inv_L_scale:  [1.0, 1.0]
Epoch :  250  Time:  0.942  Rel. Train L2 Loss :  0.043435934633016586  Rel. Test L2 Loss :  0.04525520280003548  Test L2 Loss :  0.07772428154945374  inv_L_scale:  [1.0, 1.0]
Epoch :  251  Time:  0.94  Rel. Train L2 Loss :  0.04328173206912147  Rel. Test L2 Loss :  0.04562300056219101  Test L2 Loss :  0.07830483734607696  inv_L_scale:  [1.0, 1.0]
Epoch :  252  Time:  0.94  Rel. Train L2 Loss :  0.04328102403216892  Rel. Test L2 Loss :  0.04509545505046844  Test L2 Loss :  0.07759487122297287  inv_L_scale:  [1.0, 1.0]
Epoch :  253  Time:  0.94  Rel. Train L2 Loss :  0.04318050483862559  Rel. Test L2 Loss :  0.0455482380092144  Test L2 Loss :  0.07883263111114502  inv_L_scale:  [1.0, 1.0]
Epoch :  254  Time:  0.94  Rel. Train L2 Loss :  0.042994685222705206  Rel. Test L2 Loss :  0.04514103263616562  Test L2 Loss :  0.07738587617874146  inv_L_scale:  [1.0, 1.0]
Epoch :  255  Time:  0.94  Rel. Train L2 Loss :  0.0430547451807393  Rel. Test L2 Loss :  0.04549445986747742  Test L2 Loss :  0.07792617738246918  inv_L_scale:  [1.0, 1.0]
Epoch :  256  Time:  0.94  Rel. Train L2 Loss :  0.043219076212909484  Rel. Test L2 Loss :  0.04568863481283188  Test L2 Loss :  0.07841003447771072  inv_L_scale:  [1.0, 1.0]
Epoch :  257  Time:  0.94  Rel. Train L2 Loss :  0.04312474727630615  Rel. Test L2 Loss :  0.04520545855164528  Test L2 Loss :  0.07752561628818512  inv_L_scale:  [1.0, 1.0]
Epoch :  258  Time:  0.94  Rel. Train L2 Loss :  0.042816139310598376  Rel. Test L2 Loss :  0.04514009565114975  Test L2 Loss :  0.07783980429172516  inv_L_scale:  [1.0, 1.0]
Epoch :  259  Time:  0.94  Rel. Train L2 Loss :  0.042953078945477806  Rel. Test L2 Loss :  0.04591738924384117  Test L2 Loss :  0.07885091304779053  inv_L_scale:  [1.0, 1.0]
Epoch :  260  Time:  0.94  Rel. Train L2 Loss :  0.0429596252573861  Rel. Test L2 Loss :  0.04587944403290749  Test L2 Loss :  0.07891232639551163  inv_L_scale:  [1.0, 1.0]
Epoch :  261  Time:  0.94  Rel. Train L2 Loss :  0.043044636216428546  Rel. Test L2 Loss :  0.04602595314383507  Test L2 Loss :  0.07944271713495255  inv_L_scale:  [1.0, 1.0]
Epoch :  262  Time:  0.94  Rel. Train L2 Loss :  0.042861154245005716  Rel. Test L2 Loss :  0.045181490778923035  Test L2 Loss :  0.07737038671970367  inv_L_scale:  [1.0, 1.0]
Epoch :  263  Time:  0.94  Rel. Train L2 Loss :  0.04286617924769719  Rel. Test L2 Loss :  0.045220731794834136  Test L2 Loss :  0.07806163281202316  inv_L_scale:  [1.0, 1.0]
Epoch :  264  Time:  0.94  Rel. Train L2 Loss :  0.04298327065176434  Rel. Test L2 Loss :  0.046858194768428806  Test L2 Loss :  0.08114045977592468  inv_L_scale:  [1.0, 1.0]
Epoch :  265  Time:  0.94  Rel. Train L2 Loss :  0.043093351572752  Rel. Test L2 Loss :  0.046084196865558626  Test L2 Loss :  0.07943857550621032  inv_L_scale:  [1.0, 1.0]
Epoch :  266  Time:  0.94  Rel. Train L2 Loss :  0.04270074178775152  Rel. Test L2 Loss :  0.04466221660375595  Test L2 Loss :  0.07661153227090836  inv_L_scale:  [1.0, 1.0]
Epoch :  267  Time:  0.94  Rel. Train L2 Loss :  0.04269224592381053  Rel. Test L2 Loss :  0.04654179185628891  Test L2 Loss :  0.08099204123020172  inv_L_scale:  [1.0, 1.0]
Epoch :  268  Time:  0.94  Rel. Train L2 Loss :  0.04271986694799529  Rel. Test L2 Loss :  0.044914987981319425  Test L2 Loss :  0.07739059865474701  inv_L_scale:  [1.0, 1.0]
Epoch :  269  Time:  0.941  Rel. Train L2 Loss :  0.04280989244580269  Rel. Test L2 Loss :  0.044986236989498135  Test L2 Loss :  0.07725108623504638  inv_L_scale:  [1.0, 1.0]
Epoch :  270  Time:  0.94  Rel. Train L2 Loss :  0.042585106359587774  Rel. Test L2 Loss :  0.04595614045858383  Test L2 Loss :  0.07855118542909623  inv_L_scale:  [1.0, 1.0]
Epoch :  271  Time:  0.94  Rel. Train L2 Loss :  0.04278054902950923  Rel. Test L2 Loss :  0.045492082238197326  Test L2 Loss :  0.0781025704741478  inv_L_scale:  [1.0, 1.0]
Epoch :  272  Time:  0.94  Rel. Train L2 Loss :  0.04278037612636884  Rel. Test L2 Loss :  0.04590838253498077  Test L2 Loss :  0.07926997005939483  inv_L_scale:  [1.0, 1.0]
Epoch :  273  Time:  0.94  Rel. Train L2 Loss :  0.04262201456560029  Rel. Test L2 Loss :  0.04499578669667244  Test L2 Loss :  0.07744210064411164  inv_L_scale:  [1.0, 1.0]
Epoch :  274  Time:  0.94  Rel. Train L2 Loss :  0.042541422761148875  Rel. Test L2 Loss :  0.045515011548995975  Test L2 Loss :  0.07795312404632568  inv_L_scale:  [1.0, 1.0]
Epoch :  275  Time:  0.94  Rel. Train L2 Loss :  0.04246278761161698  Rel. Test L2 Loss :  0.0445654821395874  Test L2 Loss :  0.07697267115116119  inv_L_scale:  [1.0, 1.0]
Epoch :  276  Time:  0.94  Rel. Train L2 Loss :  0.04244288664725092  Rel. Test L2 Loss :  0.04468956619501114  Test L2 Loss :  0.0770434331893921  inv_L_scale:  [1.0, 1.0]
Epoch :  277  Time:  0.94  Rel. Train L2 Loss :  0.042469512124856314  Rel. Test L2 Loss :  0.045192620009183886  Test L2 Loss :  0.07773966372013091  inv_L_scale:  [1.0, 1.0]
Epoch :  278  Time:  0.94  Rel. Train L2 Loss :  0.04266505814260907  Rel. Test L2 Loss :  0.04484453707933426  Test L2 Loss :  0.07702764153480529  inv_L_scale:  [1.0, 1.0]
Epoch :  279  Time:  0.94  Rel. Train L2 Loss :  0.042501444386111364  Rel. Test L2 Loss :  0.04543666109442711  Test L2 Loss :  0.07808458417654038  inv_L_scale:  [1.0, 1.0]
Epoch :  280  Time:  0.94  Rel. Train L2 Loss :  0.042323565185070036  Rel. Test L2 Loss :  0.0454807348549366  Test L2 Loss :  0.07837306469678879  inv_L_scale:  [1.0, 1.0]
Epoch :  281  Time:  0.94  Rel. Train L2 Loss :  0.042485348027613425  Rel. Test L2 Loss :  0.044928883016109464  Test L2 Loss :  0.07727645844221115  inv_L_scale:  [1.0, 1.0]
Epoch :  282  Time:  0.94  Rel. Train L2 Loss :  0.04247997444536951  Rel. Test L2 Loss :  0.044833088666200636  Test L2 Loss :  0.07713888883590699  inv_L_scale:  [1.0, 1.0]
Epoch :  283  Time:  0.94  Rel. Train L2 Loss :  0.04226939333809747  Rel. Test L2 Loss :  0.04559977620840073  Test L2 Loss :  0.07847560226917266  inv_L_scale:  [1.0, 1.0]
Epoch :  284  Time:  0.939  Rel. Train L2 Loss :  0.04247941836714744  Rel. Test L2 Loss :  0.04483967572450638  Test L2 Loss :  0.07676516205072403  inv_L_scale:  [1.0, 1.0]
Epoch :  285  Time:  0.939  Rel. Train L2 Loss :  0.04240527465939522  Rel. Test L2 Loss :  0.04490141749382019  Test L2 Loss :  0.0768401288986206  inv_L_scale:  [1.0, 1.0]
Epoch :  286  Time:  0.939  Rel. Train L2 Loss :  0.04231595895356602  Rel. Test L2 Loss :  0.04445779412984848  Test L2 Loss :  0.07620505303144455  inv_L_scale:  [1.0, 1.0]
Epoch :  287  Time:  0.938  Rel. Train L2 Loss :  0.0421734041472276  Rel. Test L2 Loss :  0.044425599575042725  Test L2 Loss :  0.07611595720052719  inv_L_scale:  [1.0, 1.0]
Epoch :  288  Time:  0.939  Rel. Train L2 Loss :  0.0422514342268308  Rel. Test L2 Loss :  0.04455318346619606  Test L2 Loss :  0.07636621981859207  inv_L_scale:  [1.0, 1.0]
Epoch :  289  Time:  0.938  Rel. Train L2 Loss :  0.04227439098887974  Rel. Test L2 Loss :  0.045248328149318694  Test L2 Loss :  0.07764458566904069  inv_L_scale:  [1.0, 1.0]
Epoch :  290  Time:  0.939  Rel. Train L2 Loss :  0.04221340156263775  Rel. Test L2 Loss :  0.04629273250699043  Test L2 Loss :  0.07936151742935181  inv_L_scale:  [1.0, 1.0]
Epoch :  291  Time:  0.94  Rel. Train L2 Loss :  0.04227416354748938  Rel. Test L2 Loss :  0.04479333221912384  Test L2 Loss :  0.07692470610141754  inv_L_scale:  [1.0, 1.0]
Epoch :  292  Time:  0.939  Rel. Train L2 Loss :  0.04207840291990174  Rel. Test L2 Loss :  0.0444939649105072  Test L2 Loss :  0.07666498482227325  inv_L_scale:  [1.0, 1.0]
Epoch :  293  Time:  0.94  Rel. Train L2 Loss :  0.042197192973560754  Rel. Test L2 Loss :  0.044482831209897995  Test L2 Loss :  0.0766326329112053  inv_L_scale:  [1.0, 1.0]
Epoch :  294  Time:  0.939  Rel. Train L2 Loss :  0.04208842264281379  Rel. Test L2 Loss :  0.04439117252826691  Test L2 Loss :  0.07605280220508576  inv_L_scale:  [1.0, 1.0]
Epoch :  295  Time:  0.939  Rel. Train L2 Loss :  0.042029807716608046  Rel. Test L2 Loss :  0.04429497838020325  Test L2 Loss :  0.0760403561592102  inv_L_scale:  [1.0, 1.0]
Epoch :  296  Time:  0.94  Rel. Train L2 Loss :  0.04197031084034178  Rel. Test L2 Loss :  0.04413156807422638  Test L2 Loss :  0.0758051136136055  inv_L_scale:  [1.0, 1.0]
Epoch :  297  Time:  0.94  Rel. Train L2 Loss :  0.042152386489841674  Rel. Test L2 Loss :  0.045025959759950634  Test L2 Loss :  0.0772780978679657  inv_L_scale:  [1.0, 1.0]
Epoch :  298  Time:  0.94  Rel. Train L2 Loss :  0.042122499429517325  Rel. Test L2 Loss :  0.04456870198249817  Test L2 Loss :  0.07657187283039094  inv_L_scale:  [1.0, 1.0]
Epoch :  299  Time:  0.939  Rel. Train L2 Loss :  0.04209237896733814  Rel. Test L2 Loss :  0.04470238253474235  Test L2 Loss :  0.07722076058387756  inv_L_scale:  [1.0, 1.0]
Epoch :  300  Time:  0.939  Rel. Train L2 Loss :  0.042127427789900036  Rel. Test L2 Loss :  0.04401464059948921  Test L2 Loss :  0.07566262125968932  inv_L_scale:  [1.0, 1.0]
Epoch :  301  Time:  0.938  Rel. Train L2 Loss :  0.04203967251711421  Rel. Test L2 Loss :  0.04432893559336662  Test L2 Loss :  0.07605601906776428  inv_L_scale:  [1.0, 1.0]
Epoch :  302  Time:  0.937  Rel. Train L2 Loss :  0.042143031342162025  Rel. Test L2 Loss :  0.044226137697696684  Test L2 Loss :  0.07585141122341156  inv_L_scale:  [1.0, 1.0]
Epoch :  303  Time:  0.937  Rel. Train L2 Loss :  0.041896787054008906  Rel. Test L2 Loss :  0.044544113129377366  Test L2 Loss :  0.07651752769947053  inv_L_scale:  [1.0, 1.0]
Epoch :  304  Time:  0.937  Rel. Train L2 Loss :  0.04196553389231364  Rel. Test L2 Loss :  0.044825722277164456  Test L2 Loss :  0.07735951602458954  inv_L_scale:  [1.0, 1.0]
Epoch :  305  Time:  0.937  Rel. Train L2 Loss :  0.04200262024998665  Rel. Test L2 Loss :  0.044449303150177005  Test L2 Loss :  0.07617379665374756  inv_L_scale:  [1.0, 1.0]
Epoch :  306  Time:  0.936  Rel. Train L2 Loss :  0.04177993289298482  Rel. Test L2 Loss :  0.04441172063350678  Test L2 Loss :  0.07631897926330566  inv_L_scale:  [1.0, 1.0]
Epoch :  307  Time:  0.938  Rel. Train L2 Loss :  0.04201734421981706  Rel. Test L2 Loss :  0.04489943966269493  Test L2 Loss :  0.07777011454105377  inv_L_scale:  [1.0, 1.0]
Epoch :  308  Time:  0.937  Rel. Train L2 Loss :  0.041924035516050125  Rel. Test L2 Loss :  0.04436433404684067  Test L2 Loss :  0.07616135776042939  inv_L_scale:  [1.0, 1.0]
Epoch :  309  Time:  0.936  Rel. Train L2 Loss :  0.04189041026764446  Rel. Test L2 Loss :  0.04457721918821335  Test L2 Loss :  0.07689141213893891  inv_L_scale:  [1.0, 1.0]
Epoch :  310  Time:  0.936  Rel. Train L2 Loss :  0.0420758843421936  Rel. Test L2 Loss :  0.04446983501315117  Test L2 Loss :  0.07659325361251831  inv_L_scale:  [1.0, 1.0]
Epoch :  311  Time:  0.936  Rel. Train L2 Loss :  0.04167478367686272  Rel. Test L2 Loss :  0.04509374797344208  Test L2 Loss :  0.07749972343444825  inv_L_scale:  [1.0, 1.0]
Epoch :  312  Time:  0.937  Rel. Train L2 Loss :  0.041708487048745156  Rel. Test L2 Loss :  0.0441227699816227  Test L2 Loss :  0.07585710644721985  inv_L_scale:  [1.0, 1.0]
Epoch :  313  Time:  0.939  Rel. Train L2 Loss :  0.04194983076718119  Rel. Test L2 Loss :  0.044436646103858946  Test L2 Loss :  0.07647742211818695  inv_L_scale:  [1.0, 1.0]
Epoch :  314  Time:  0.937  Rel. Train L2 Loss :  0.04176083794898457  Rel. Test L2 Loss :  0.045650680512189866  Test L2 Loss :  0.07839730262756348  inv_L_scale:  [1.0, 1.0]
Epoch :  315  Time:  0.936  Rel. Train L2 Loss :  0.041625087642007404  Rel. Test L2 Loss :  0.044615076780319216  Test L2 Loss :  0.07683245062828065  inv_L_scale:  [1.0, 1.0]
Epoch :  316  Time:  0.937  Rel. Train L2 Loss :  0.04175218787458208  Rel. Test L2 Loss :  0.044810170233249666  Test L2 Loss :  0.07744204580783844  inv_L_scale:  [1.0, 1.0]
Epoch :  317  Time:  0.937  Rel. Train L2 Loss :  0.041843293060859044  Rel. Test L2 Loss :  0.045007104575634005  Test L2 Loss :  0.0774665492773056  inv_L_scale:  [1.0, 1.0]
Epoch :  318  Time:  0.937  Rel. Train L2 Loss :  0.041631023238102596  Rel. Test L2 Loss :  0.044105250388383865  Test L2 Loss :  0.07562988519668579  inv_L_scale:  [1.0, 1.0]
Epoch :  319  Time:  0.937  Rel. Train L2 Loss :  0.04162354156374931  Rel. Test L2 Loss :  0.04427750676870346  Test L2 Loss :  0.07601281553506851  inv_L_scale:  [1.0, 1.0]
Epoch :  320  Time:  0.937  Rel. Train L2 Loss :  0.041775478538539676  Rel. Test L2 Loss :  0.04469920873641968  Test L2 Loss :  0.07696199357509613  inv_L_scale:  [1.0, 1.0]
Epoch :  321  Time:  0.937  Rel. Train L2 Loss :  0.04167370370692677  Rel. Test L2 Loss :  0.04421386018395424  Test L2 Loss :  0.07587152361869812  inv_L_scale:  [1.0, 1.0]
Epoch :  322  Time:  0.937  Rel. Train L2 Loss :  0.04159813572963079  Rel. Test L2 Loss :  0.0448665201663971  Test L2 Loss :  0.07741278171539306  inv_L_scale:  [1.0, 1.0]
Epoch :  323  Time:  0.937  Rel. Train L2 Loss :  0.04163220180405511  Rel. Test L2 Loss :  0.04436547920107842  Test L2 Loss :  0.07631212174892425  inv_L_scale:  [1.0, 1.0]
Epoch :  324  Time:  0.937  Rel. Train L2 Loss :  0.041399978581402035  Rel. Test L2 Loss :  0.044341235607862475  Test L2 Loss :  0.07623003929853439  inv_L_scale:  [1.0, 1.0]
Epoch :  325  Time:  0.937  Rel. Train L2 Loss :  0.04148995141188304  Rel. Test L2 Loss :  0.04520561695098877  Test L2 Loss :  0.07745882332324981  inv_L_scale:  [1.0, 1.0]
Epoch :  326  Time:  0.936  Rel. Train L2 Loss :  0.041593893840909  Rel. Test L2 Loss :  0.04374934464693069  Test L2 Loss :  0.07504978388547898  inv_L_scale:  [1.0, 1.0]
Epoch :  327  Time:  0.936  Rel. Train L2 Loss :  0.04137814414170053  Rel. Test L2 Loss :  0.044398835003376005  Test L2 Loss :  0.07610762178897858  inv_L_scale:  [1.0, 1.0]
Epoch :  328  Time:  0.936  Rel. Train L2 Loss :  0.04148634981777933  Rel. Test L2 Loss :  0.04496257930994034  Test L2 Loss :  0.0778790658712387  inv_L_scale:  [1.0, 1.0]
Epoch :  329  Time:  0.938  Rel. Train L2 Loss :  0.041528691516982186  Rel. Test L2 Loss :  0.044131326973438266  Test L2 Loss :  0.07589907974004745  inv_L_scale:  [1.0, 1.0]
Epoch :  330  Time:  0.936  Rel. Train L2 Loss :  0.04145583210719956  Rel. Test L2 Loss :  0.04496485859155655  Test L2 Loss :  0.0777723678946495  inv_L_scale:  [1.0, 1.0]
Epoch :  331  Time:  0.936  Rel. Train L2 Loss :  0.041574371407429374  Rel. Test L2 Loss :  0.04421077743172645  Test L2 Loss :  0.07578203737735749  inv_L_scale:  [1.0, 1.0]
Epoch :  332  Time:  0.936  Rel. Train L2 Loss :  0.04151683977908558  Rel. Test L2 Loss :  0.044212965965270995  Test L2 Loss :  0.07596222907304764  inv_L_scale:  [1.0, 1.0]
Epoch :  333  Time:  0.936  Rel. Train L2 Loss :  0.04134099163942867  Rel. Test L2 Loss :  0.043941892981529236  Test L2 Loss :  0.0756103140115738  inv_L_scale:  [1.0, 1.0]
Epoch :  334  Time:  0.936  Rel. Train L2 Loss :  0.04159447761045562  Rel. Test L2 Loss :  0.04428073078393936  Test L2 Loss :  0.07583975851535797  inv_L_scale:  [1.0, 1.0]
Epoch :  335  Time:  0.935  Rel. Train L2 Loss :  0.041171069261100555  Rel. Test L2 Loss :  0.04392304822802544  Test L2 Loss :  0.07562802255153656  inv_L_scale:  [1.0, 1.0]
Epoch :  336  Time:  0.936  Rel. Train L2 Loss :  0.0413716924107737  Rel. Test L2 Loss :  0.04393350720405578  Test L2 Loss :  0.07533432126045227  inv_L_scale:  [1.0, 1.0]
Epoch :  337  Time:  0.937  Rel. Train L2 Loss :  0.04137737366888258  Rel. Test L2 Loss :  0.04403849795460701  Test L2 Loss :  0.0755434313416481  inv_L_scale:  [1.0, 1.0]
Epoch :  338  Time:  0.936  Rel. Train L2 Loss :  0.04137508066164123  Rel. Test L2 Loss :  0.044300957918167114  Test L2 Loss :  0.07614384889602661  inv_L_scale:  [1.0, 1.0]
Epoch :  339  Time:  0.936  Rel. Train L2 Loss :  0.041311238374974996  Rel. Test L2 Loss :  0.04433878600597382  Test L2 Loss :  0.07626301437616348  inv_L_scale:  [1.0, 1.0]
Epoch :  340  Time:  0.938  Rel. Train L2 Loss :  0.04133538365364075  Rel. Test L2 Loss :  0.04439024955034256  Test L2 Loss :  0.07649932742118835  inv_L_scale:  [1.0, 1.0]
Epoch :  341  Time:  0.935  Rel. Train L2 Loss :  0.041275134450859494  Rel. Test L2 Loss :  0.044189904779195786  Test L2 Loss :  0.07571929901838302  inv_L_scale:  [1.0, 1.0]
Epoch :  342  Time:  0.935  Rel. Train L2 Loss :  0.04132525260249774  Rel. Test L2 Loss :  0.043988163471221926  Test L2 Loss :  0.07556584566831588  inv_L_scale:  [1.0, 1.0]
Epoch :  343  Time:  0.935  Rel. Train L2 Loss :  0.04121847571598159  Rel. Test L2 Loss :  0.04399247884750366  Test L2 Loss :  0.07546233803033829  inv_L_scale:  [1.0, 1.0]
Epoch :  344  Time:  0.935  Rel. Train L2 Loss :  0.04130427165163888  Rel. Test L2 Loss :  0.044616383910179136  Test L2 Loss :  0.07709797143936158  inv_L_scale:  [1.0, 1.0]
Epoch :  345  Time:  0.936  Rel. Train L2 Loss :  0.04135725536280208  Rel. Test L2 Loss :  0.04429221019148827  Test L2 Loss :  0.07598372280597687  inv_L_scale:  [1.0, 1.0]
Epoch :  346  Time:  0.935  Rel. Train L2 Loss :  0.04128011205957995  Rel. Test L2 Loss :  0.04402875423431397  Test L2 Loss :  0.0754492673277855  inv_L_scale:  [1.0, 1.0]
Epoch :  347  Time:  0.935  Rel. Train L2 Loss :  0.04113372368945016  Rel. Test L2 Loss :  0.044246417880058286  Test L2 Loss :  0.07598975241184235  inv_L_scale:  [1.0, 1.0]
Epoch :  348  Time:  0.936  Rel. Train L2 Loss :  0.04108510366744465  Rel. Test L2 Loss :  0.0437853330373764  Test L2 Loss :  0.07521243691444397  inv_L_scale:  [1.0, 1.0]
Epoch :  349  Time:  0.936  Rel. Train L2 Loss :  0.04099870421820217  Rel. Test L2 Loss :  0.044056845754384996  Test L2 Loss :  0.07592373490333557  inv_L_scale:  [1.0, 1.0]
Epoch :  350  Time:  0.936  Rel. Train L2 Loss :  0.041131374918752246  Rel. Test L2 Loss :  0.04412483513355255  Test L2 Loss :  0.07565688192844391  inv_L_scale:  [1.0, 1.0]
Epoch :  351  Time:  0.936  Rel. Train L2 Loss :  0.041059979995091755  Rel. Test L2 Loss :  0.04371204018592834  Test L2 Loss :  0.07508396059274673  inv_L_scale:  [1.0, 1.0]
Epoch :  352  Time:  0.935  Rel. Train L2 Loss :  0.041009064647886485  Rel. Test L2 Loss :  0.04370570704340935  Test L2 Loss :  0.07506086349487305  inv_L_scale:  [1.0, 1.0]
Epoch :  353  Time:  0.935  Rel. Train L2 Loss :  0.04118192584978209  Rel. Test L2 Loss :  0.043547717332839964  Test L2 Loss :  0.07486299365758896  inv_L_scale:  [1.0, 1.0]
Epoch :  354  Time:  0.935  Rel. Train L2 Loss :  0.041094194932116405  Rel. Test L2 Loss :  0.044065935909748076  Test L2 Loss :  0.07558863937854766  inv_L_scale:  [1.0, 1.0]
Epoch :  355  Time:  0.935  Rel. Train L2 Loss :  0.04100653049018648  Rel. Test L2 Loss :  0.043467209935188295  Test L2 Loss :  0.07451518505811691  inv_L_scale:  [1.0, 1.0]
Epoch :  356  Time:  0.935  Rel. Train L2 Loss :  0.041006432258420523  Rel. Test L2 Loss :  0.04418832585215569  Test L2 Loss :  0.0757612043619156  inv_L_scale:  [1.0, 1.0]
Epoch :  357  Time:  0.935  Rel. Train L2 Loss :  0.040964887423647775  Rel. Test L2 Loss :  0.04389729470014572  Test L2 Loss :  0.075365070104599  inv_L_scale:  [1.0, 1.0]
Epoch :  358  Time:  0.936  Rel. Train L2 Loss :  0.0409519182311164  Rel. Test L2 Loss :  0.043783018887043  Test L2 Loss :  0.07535832703113556  inv_L_scale:  [1.0, 1.0]
Epoch :  359  Time:  0.936  Rel. Train L2 Loss :  0.04094629916879866  Rel. Test L2 Loss :  0.04432118058204651  Test L2 Loss :  0.0765323704481125  inv_L_scale:  [1.0, 1.0]
Epoch :  360  Time:  0.936  Rel. Train L2 Loss :  0.04093641959958606  Rel. Test L2 Loss :  0.044139744341373445  Test L2 Loss :  0.07569472312927246  inv_L_scale:  [1.0, 1.0]
Epoch :  361  Time:  0.936  Rel. Train L2 Loss :  0.04093759280112055  Rel. Test L2 Loss :  0.04389772340655327  Test L2 Loss :  0.07554740846157074  inv_L_scale:  [1.0, 1.0]
Epoch :  362  Time:  0.936  Rel. Train L2 Loss :  0.04083773665957981  Rel. Test L2 Loss :  0.043823742270469666  Test L2 Loss :  0.07509458690881729  inv_L_scale:  [1.0, 1.0]
Epoch :  363  Time:  0.936  Rel. Train L2 Loss :  0.040833865304787956  Rel. Test L2 Loss :  0.044065520912408826  Test L2 Loss :  0.07559248834848403  inv_L_scale:  [1.0, 1.0]
Epoch :  364  Time:  0.935  Rel. Train L2 Loss :  0.040789446350600986  Rel. Test L2 Loss :  0.043675589561462405  Test L2 Loss :  0.07504083395004273  inv_L_scale:  [1.0, 1.0]
Epoch :  365  Time:  0.936  Rel. Train L2 Loss :  0.040814758704768285  Rel. Test L2 Loss :  0.04396009236574173  Test L2 Loss :  0.0757267266511917  inv_L_scale:  [1.0, 1.0]
Epoch :  366  Time:  0.935  Rel. Train L2 Loss :  0.04084079714285003  Rel. Test L2 Loss :  0.04379470124840736  Test L2 Loss :  0.07514904081821441  inv_L_scale:  [1.0, 1.0]
Epoch :  367  Time:  0.935  Rel. Train L2 Loss :  0.040817125000887446  Rel. Test L2 Loss :  0.04371976912021637  Test L2 Loss :  0.07515223503112793  inv_L_scale:  [1.0, 1.0]
Epoch :  368  Time:  0.936  Rel. Train L2 Loss :  0.04079378581709332  Rel. Test L2 Loss :  0.043549762666225435  Test L2 Loss :  0.0748432868719101  inv_L_scale:  [1.0, 1.0]
Epoch :  369  Time:  0.935  Rel. Train L2 Loss :  0.0408796818388833  Rel. Test L2 Loss :  0.04386567234992981  Test L2 Loss :  0.07531132340431214  inv_L_scale:  [1.0, 1.0]
Epoch :  370  Time:  0.935  Rel. Train L2 Loss :  0.040822489890787336  Rel. Test L2 Loss :  0.04372181832790375  Test L2 Loss :  0.07501852750778198  inv_L_scale:  [1.0, 1.0]
Epoch :  371  Time:  0.935  Rel. Train L2 Loss :  0.04070446512765354  Rel. Test L2 Loss :  0.04371787190437317  Test L2 Loss :  0.07500578552484512  inv_L_scale:  [1.0, 1.0]
Epoch :  372  Time:  0.935  Rel. Train L2 Loss :  0.04063522136873669  Rel. Test L2 Loss :  0.04375901743769646  Test L2 Loss :  0.07490949004888535  inv_L_scale:  [1.0, 1.0]
Epoch :  373  Time:  0.936  Rel. Train L2 Loss :  0.04078802810774909  Rel. Test L2 Loss :  0.04365991711616516  Test L2 Loss :  0.07488031566143036  inv_L_scale:  [1.0, 1.0]
Epoch :  374  Time:  0.935  Rel. Train L2 Loss :  0.04073577362630102  Rel. Test L2 Loss :  0.04376741498708725  Test L2 Loss :  0.07491891890764237  inv_L_scale:  [1.0, 1.0]
Epoch :  375  Time:  0.935  Rel. Train L2 Loss :  0.04078802484605047  Rel. Test L2 Loss :  0.04331263303756714  Test L2 Loss :  0.07432589143514633  inv_L_scale:  [1.0, 1.0]
Epoch :  376  Time:  0.936  Rel. Train L2 Loss :  0.04064887954129113  Rel. Test L2 Loss :  0.043750459253787996  Test L2 Loss :  0.07530528992414474  inv_L_scale:  [1.0, 1.0]
Epoch :  377  Time:  0.936  Rel. Train L2 Loss :  0.04069068026211527  Rel. Test L2 Loss :  0.043566344678401946  Test L2 Loss :  0.07451530635356902  inv_L_scale:  [1.0, 1.0]
Epoch :  378  Time:  0.935  Rel. Train L2 Loss :  0.040595333576202396  Rel. Test L2 Loss :  0.04418586939573288  Test L2 Loss :  0.07614998042583465  inv_L_scale:  [1.0, 1.0]
Epoch :  379  Time:  0.935  Rel. Train L2 Loss :  0.04077048442429966  Rel. Test L2 Loss :  0.043280063569545744  Test L2 Loss :  0.0743849503993988  inv_L_scale:  [1.0, 1.0]
Epoch :  380  Time:  0.935  Rel. Train L2 Loss :  0.04064995851781633  Rel. Test L2 Loss :  0.043704164326190946  Test L2 Loss :  0.07507402896881103  inv_L_scale:  [1.0, 1.0]
Epoch :  381  Time:  0.935  Rel. Train L2 Loss :  0.040527734922038185  Rel. Test L2 Loss :  0.043640878051519394  Test L2 Loss :  0.07493597775697708  inv_L_scale:  [1.0, 1.0]
Epoch :  382  Time:  0.935  Rel. Train L2 Loss :  0.04058136606381999  Rel. Test L2 Loss :  0.04368791729211807  Test L2 Loss :  0.07497667908668518  inv_L_scale:  [1.0, 1.0]
Epoch :  383  Time:  0.937  Rel. Train L2 Loss :  0.04062212856279479  Rel. Test L2 Loss :  0.043576520383358  Test L2 Loss :  0.07493429481983185  inv_L_scale:  [1.0, 1.0]
Epoch :  384  Time:  0.935  Rel. Train L2 Loss :  0.04055087728632821  Rel. Test L2 Loss :  0.04342751830816269  Test L2 Loss :  0.07427521765232087  inv_L_scale:  [1.0, 1.0]
Epoch :  385  Time:  0.935  Rel. Train L2 Loss :  0.04054008760386043  Rel. Test L2 Loss :  0.04384004354476929  Test L2 Loss :  0.07546251654624939  inv_L_scale:  [1.0, 1.0]
Epoch :  386  Time:  0.935  Rel. Train L2 Loss :  0.04057689886954095  Rel. Test L2 Loss :  0.04343539357185364  Test L2 Loss :  0.07446737170219421  inv_L_scale:  [1.0, 1.0]
Epoch :  387  Time:  0.935  Rel. Train L2 Loss :  0.040475836628013184  Rel. Test L2 Loss :  0.04343218445777893  Test L2 Loss :  0.07450628578662873  inv_L_scale:  [1.0, 1.0]
Epoch :  388  Time:  0.935  Rel. Train L2 Loss :  0.04042996858557065  Rel. Test L2 Loss :  0.043356798589229584  Test L2 Loss :  0.07441526830196381  inv_L_scale:  [1.0, 1.0]
Epoch :  389  Time:  0.935  Rel. Train L2 Loss :  0.040462236834896935  Rel. Test L2 Loss :  0.04356633096933365  Test L2 Loss :  0.07472437471151352  inv_L_scale:  [1.0, 1.0]
Epoch :  390  Time:  0.935  Rel. Train L2 Loss :  0.04047622135943837  Rel. Test L2 Loss :  0.0435372556746006  Test L2 Loss :  0.07464798599481583  inv_L_scale:  [1.0, 1.0]
Epoch :  391  Time:  0.935  Rel. Train L2 Loss :  0.04045848440792826  Rel. Test L2 Loss :  0.04352081850171089  Test L2 Loss :  0.07465161323547363  inv_L_scale:  [1.0, 1.0]
Epoch :  392  Time:  0.935  Rel. Train L2 Loss :  0.04042500605185827  Rel. Test L2 Loss :  0.04347722768783569  Test L2 Loss :  0.07458887100219727  inv_L_scale:  [1.0, 1.0]
Epoch :  393  Time:  0.935  Rel. Train L2 Loss :  0.04038924435774485  Rel. Test L2 Loss :  0.04336579144001007  Test L2 Loss :  0.07444008350372315  inv_L_scale:  [1.0, 1.0]
Epoch :  394  Time:  0.936  Rel. Train L2 Loss :  0.04045051413277785  Rel. Test L2 Loss :  0.043448831886053085  Test L2 Loss :  0.0745167002081871  inv_L_scale:  [1.0, 1.0]
Epoch :  395  Time:  0.935  Rel. Train L2 Loss :  0.04037698964277903  Rel. Test L2 Loss :  0.043241380155086516  Test L2 Loss :  0.07411439657211304  inv_L_scale:  [1.0, 1.0]
Epoch :  396  Time:  0.935  Rel. Train L2 Loss :  0.04040014801753892  Rel. Test L2 Loss :  0.043455456793308256  Test L2 Loss :  0.07472073376178741  inv_L_scale:  [1.0, 1.0]
Epoch :  397  Time:  0.935  Rel. Train L2 Loss :  0.04036365709371037  Rel. Test L2 Loss :  0.043781471252441403  Test L2 Loss :  0.07514007031917572  inv_L_scale:  [1.0, 1.0]
Epoch :  398  Time:  0.935  Rel. Train L2 Loss :  0.0403669632309013  Rel. Test L2 Loss :  0.04347992315888405  Test L2 Loss :  0.07444415271282195  inv_L_scale:  [1.0, 1.0]
Epoch :  399  Time:  0.935  Rel. Train L2 Loss :  0.040310852411720485  Rel. Test L2 Loss :  0.04324217617511749  Test L2 Loss :  0.07426180064678192  inv_L_scale:  [1.0, 1.0]
Epoch :  400  Time:  0.935  Rel. Train L2 Loss :  0.040309840573204886  Rel. Test L2 Loss :  0.043305092453956605  Test L2 Loss :  0.07425723433494567  inv_L_scale:  [1.0, 1.0]
Epoch :  401  Time:  0.935  Rel. Train L2 Loss :  0.04029483573304282  Rel. Test L2 Loss :  0.04340481966733933  Test L2 Loss :  0.07444116324186326  inv_L_scale:  [1.0, 1.0]
Epoch :  402  Time:  0.935  Rel. Train L2 Loss :  0.040266114175319674  Rel. Test L2 Loss :  0.043462521731853485  Test L2 Loss :  0.07447933703660965  inv_L_scale:  [1.0, 1.0]
Epoch :  403  Time:  0.935  Rel. Train L2 Loss :  0.040313940131002  Rel. Test L2 Loss :  0.04328349322080612  Test L2 Loss :  0.07428924292325974  inv_L_scale:  [1.0, 1.0]
Epoch :  404  Time:  0.935  Rel. Train L2 Loss :  0.04034470443924268  Rel. Test L2 Loss :  0.043388012796640396  Test L2 Loss :  0.07449427276849746  inv_L_scale:  [1.0, 1.0]
Epoch :  405  Time:  0.935  Rel. Train L2 Loss :  0.04026592425174183  Rel. Test L2 Loss :  0.04341486930847168  Test L2 Loss :  0.0744039124250412  inv_L_scale:  [1.0, 1.0]
Epoch :  406  Time:  0.935  Rel. Train L2 Loss :  0.04022683351404137  Rel. Test L2 Loss :  0.04349683403968811  Test L2 Loss :  0.0745015013217926  inv_L_scale:  [1.0, 1.0]
Epoch :  407  Time:  0.935  Rel. Train L2 Loss :  0.04018597137596872  Rel. Test L2 Loss :  0.043547828197479245  Test L2 Loss :  0.07459574162960053  inv_L_scale:  [1.0, 1.0]
Epoch :  408  Time:  0.935  Rel. Train L2 Loss :  0.04020710221595234  Rel. Test L2 Loss :  0.04328987330198288  Test L2 Loss :  0.07415761977434158  inv_L_scale:  [1.0, 1.0]
Epoch :  409  Time:  0.935  Rel. Train L2 Loss :  0.04019264400005341  Rel. Test L2 Loss :  0.04340155243873596  Test L2 Loss :  0.07435681521892548  inv_L_scale:  [1.0, 1.0]
Epoch :  410  Time:  0.935  Rel. Train L2 Loss :  0.04023040090998014  Rel. Test L2 Loss :  0.043229438066482544  Test L2 Loss :  0.07413882493972779  inv_L_scale:  [1.0, 1.0]
Epoch :  411  Time:  0.935  Rel. Train L2 Loss :  0.04012055155303743  Rel. Test L2 Loss :  0.04318656325340271  Test L2 Loss :  0.07414000868797302  inv_L_scale:  [1.0, 1.0]
Epoch :  412  Time:  0.936  Rel. Train L2 Loss :  0.0402089997049835  Rel. Test L2 Loss :  0.04353668808937073  Test L2 Loss :  0.0747511076927185  inv_L_scale:  [1.0, 1.0]
Epoch :  413  Time:  0.936  Rel. Train L2 Loss :  0.04021630547112889  Rel. Test L2 Loss :  0.043238517642021176  Test L2 Loss :  0.07402974665164948  inv_L_scale:  [1.0, 1.0]
Epoch :  414  Time:  0.935  Rel. Train L2 Loss :  0.040180571559402675  Rel. Test L2 Loss :  0.04342308759689331  Test L2 Loss :  0.07438945233821868  inv_L_scale:  [1.0, 1.0]
Epoch :  415  Time:  0.935  Rel. Train L2 Loss :  0.04011770534846518  Rel. Test L2 Loss :  0.04342645272612572  Test L2 Loss :  0.0745212259888649  inv_L_scale:  [1.0, 1.0]
Epoch :  416  Time:  0.935  Rel. Train L2 Loss :  0.04009239140484068  Rel. Test L2 Loss :  0.043245580494403836  Test L2 Loss :  0.07417414724826812  inv_L_scale:  [1.0, 1.0]
Epoch :  417  Time:  0.935  Rel. Train L2 Loss :  0.040065824919276766  Rel. Test L2 Loss :  0.04322016015648842  Test L2 Loss :  0.07401456356048584  inv_L_scale:  [1.0, 1.0]
Epoch :  418  Time:  0.935  Rel. Train L2 Loss :  0.04010511752631929  Rel. Test L2 Loss :  0.043291009515523914  Test L2 Loss :  0.07419227004051208  inv_L_scale:  [1.0, 1.0]
Epoch :  419  Time:  0.935  Rel. Train L2 Loss :  0.040176998211277855  Rel. Test L2 Loss :  0.043174778819084166  Test L2 Loss :  0.07406877398490906  inv_L_scale:  [1.0, 1.0]
Epoch :  420  Time:  0.936  Rel. Train L2 Loss :  0.040102098319265575  Rel. Test L2 Loss :  0.04327062875032425  Test L2 Loss :  0.07411275565624237  inv_L_scale:  [1.0, 1.0]
Epoch :  421  Time:  0.936  Rel. Train L2 Loss :  0.0400586374849081  Rel. Test L2 Loss :  0.04330147355794907  Test L2 Loss :  0.07422873705625534  inv_L_scale:  [1.0, 1.0]
Epoch :  422  Time:  0.936  Rel. Train L2 Loss :  0.03999251109030512  Rel. Test L2 Loss :  0.04315001219511032  Test L2 Loss :  0.07397729635238648  inv_L_scale:  [1.0, 1.0]
Epoch :  423  Time:  0.936  Rel. Train L2 Loss :  0.04005444044868151  Rel. Test L2 Loss :  0.04318455278873443  Test L2 Loss :  0.07410969674587249  inv_L_scale:  [1.0, 1.0]
Epoch :  424  Time:  0.936  Rel. Train L2 Loss :  0.040003738204638165  Rel. Test L2 Loss :  0.04325172275304794  Test L2 Loss :  0.0742049166560173  inv_L_scale:  [1.0, 1.0]
Epoch :  425  Time:  0.936  Rel. Train L2 Loss :  0.039981621205806735  Rel. Test L2 Loss :  0.043239877820014955  Test L2 Loss :  0.07404502242803573  inv_L_scale:  [1.0, 1.0]
Epoch :  426  Time:  0.936  Rel. Train L2 Loss :  0.04000203215413623  Rel. Test L2 Loss :  0.04321351021528244  Test L2 Loss :  0.07408860325813293  inv_L_scale:  [1.0, 1.0]
Epoch :  427  Time:  0.938  Rel. Train L2 Loss :  0.03996520991126696  Rel. Test L2 Loss :  0.043126558661460875  Test L2 Loss :  0.07386903524398804  inv_L_scale:  [1.0, 1.0]
Epoch :  428  Time:  0.935  Rel. Train L2 Loss :  0.03997723730074035  Rel. Test L2 Loss :  0.04320779368281365  Test L2 Loss :  0.074048772752285  inv_L_scale:  [1.0, 1.0]
Epoch :  429  Time:  0.935  Rel. Train L2 Loss :  0.03994458531339963  Rel. Test L2 Loss :  0.043374732881784436  Test L2 Loss :  0.07438566744327545  inv_L_scale:  [1.0, 1.0]
Epoch :  430  Time:  0.935  Rel. Train L2 Loss :  0.03995206011666192  Rel. Test L2 Loss :  0.04321263700723648  Test L2 Loss :  0.0740586793422699  inv_L_scale:  [1.0, 1.0]
Epoch :  431  Time:  0.934  Rel. Train L2 Loss :  0.03990148613022433  Rel. Test L2 Loss :  0.043083461970090865  Test L2 Loss :  0.07392181694507599  inv_L_scale:  [1.0, 1.0]
Epoch :  432  Time:  0.934  Rel. Train L2 Loss :  0.039959271219041616  Rel. Test L2 Loss :  0.043306251168251035  Test L2 Loss :  0.07427484661340714  inv_L_scale:  [1.0, 1.0]
Epoch :  433  Time:  0.935  Rel. Train L2 Loss :  0.03991147705250316  Rel. Test L2 Loss :  0.043231324702501295  Test L2 Loss :  0.07400763392448426  inv_L_scale:  [1.0, 1.0]
Epoch :  434  Time:  0.934  Rel. Train L2 Loss :  0.0398985279765394  Rel. Test L2 Loss :  0.04307010665535927  Test L2 Loss :  0.07388816207647324  inv_L_scale:  [1.0, 1.0]
Epoch :  435  Time:  0.935  Rel. Train L2 Loss :  0.03989115370644464  Rel. Test L2 Loss :  0.04318562984466553  Test L2 Loss :  0.07418098479509354  inv_L_scale:  [1.0, 1.0]
Epoch :  436  Time:  0.935  Rel. Train L2 Loss :  0.03991952013638284  Rel. Test L2 Loss :  0.04317927867174148  Test L2 Loss :  0.0740547987818718  inv_L_scale:  [1.0, 1.0]
Epoch :  437  Time:  0.935  Rel. Train L2 Loss :  0.03991157275107172  Rel. Test L2 Loss :  0.04307888239622116  Test L2 Loss :  0.07394766986370087  inv_L_scale:  [1.0, 1.0]
Epoch :  438  Time:  0.935  Rel. Train L2 Loss :  0.03988520137137837  Rel. Test L2 Loss :  0.043243295401334765  Test L2 Loss :  0.07406598389148712  inv_L_scale:  [1.0, 1.0]
Epoch :  439  Time:  0.935  Rel. Train L2 Loss :  0.039844244635767405  Rel. Test L2 Loss :  0.043318586945533755  Test L2 Loss :  0.07424998939037324  inv_L_scale:  [1.0, 1.0]
Epoch :  440  Time:  0.935  Rel. Train L2 Loss :  0.0398396570318275  Rel. Test L2 Loss :  0.04311260610818863  Test L2 Loss :  0.07390978783369065  inv_L_scale:  [1.0, 1.0]
Epoch :  441  Time:  0.935  Rel. Train L2 Loss :  0.03983098581433296  Rel. Test L2 Loss :  0.04322600126266479  Test L2 Loss :  0.07414355933666229  inv_L_scale:  [1.0, 1.0]
Epoch :  442  Time:  0.935  Rel. Train L2 Loss :  0.039814087549845376  Rel. Test L2 Loss :  0.04311139732599258  Test L2 Loss :  0.07388419061899185  inv_L_scale:  [1.0, 1.0]
Epoch :  443  Time:  0.935  Rel. Train L2 Loss :  0.03983550937639342  Rel. Test L2 Loss :  0.043099305331707  Test L2 Loss :  0.07387994855642319  inv_L_scale:  [1.0, 1.0]
Epoch :  444  Time:  0.935  Rel. Train L2 Loss :  0.039806525707244876  Rel. Test L2 Loss :  0.043167614340782166  Test L2 Loss :  0.07395581543445587  inv_L_scale:  [1.0, 1.0]
Epoch :  445  Time:  0.935  Rel. Train L2 Loss :  0.03979259466131528  Rel. Test L2 Loss :  0.043125036358833316  Test L2 Loss :  0.07388163864612579  inv_L_scale:  [1.0, 1.0]
Epoch :  446  Time:  0.935  Rel. Train L2 Loss :  0.03978898114628262  Rel. Test L2 Loss :  0.04312370881438255  Test L2 Loss :  0.07389909446239472  inv_L_scale:  [1.0, 1.0]
Epoch :  447  Time:  0.935  Rel. Train L2 Loss :  0.03977411323123508  Rel. Test L2 Loss :  0.04308948367834091  Test L2 Loss :  0.07389788478612899  inv_L_scale:  [1.0, 1.0]
Epoch :  448  Time:  0.935  Rel. Train L2 Loss :  0.039772799329625234  Rel. Test L2 Loss :  0.043171660602092744  Test L2 Loss :  0.0739873194694519  inv_L_scale:  [1.0, 1.0]
Epoch :  449  Time:  0.935  Rel. Train L2 Loss :  0.03977210161586602  Rel. Test L2 Loss :  0.04317078396677971  Test L2 Loss :  0.07413756340742111  inv_L_scale:  [1.0, 1.0]
Epoch :  450  Time:  0.935  Rel. Train L2 Loss :  0.039755094796419144  Rel. Test L2 Loss :  0.04305411070585251  Test L2 Loss :  0.07380891919136047  inv_L_scale:  [1.0, 1.0]
Epoch :  451  Time:  0.935  Rel. Train L2 Loss :  0.03975986917813619  Rel. Test L2 Loss :  0.0430892276763916  Test L2 Loss :  0.07389416486024857  inv_L_scale:  [1.0, 1.0]
Epoch :  452  Time:  0.936  Rel. Train L2 Loss :  0.039742417335510254  Rel. Test L2 Loss :  0.04313802361488342  Test L2 Loss :  0.07397175490856171  inv_L_scale:  [1.0, 1.0]
Epoch :  453  Time:  0.936  Rel. Train L2 Loss :  0.03973256371087498  Rel. Test L2 Loss :  0.043189523220062254  Test L2 Loss :  0.07398785054683685  inv_L_scale:  [1.0, 1.0]
Epoch :  454  Time:  0.934  Rel. Train L2 Loss :  0.03973000670472781  Rel. Test L2 Loss :  0.04312066525220871  Test L2 Loss :  0.07395910412073135  inv_L_scale:  [1.0, 1.0]
Epoch :  455  Time:  0.934  Rel. Train L2 Loss :  0.0397284860495064  Rel. Test L2 Loss :  0.04307809382677078  Test L2 Loss :  0.07382729530334473  inv_L_scale:  [1.0, 1.0]
Epoch :  456  Time:  0.934  Rel. Train L2 Loss :  0.03972231111592717  Rel. Test L2 Loss :  0.04307975515723229  Test L2 Loss :  0.07385151058435441  inv_L_scale:  [1.0, 1.0]
Epoch :  457  Time:  0.934  Rel. Train L2 Loss :  0.039705482208066516  Rel. Test L2 Loss :  0.04307972371578216  Test L2 Loss :  0.07386625438928604  inv_L_scale:  [1.0, 1.0]
Epoch :  458  Time:  0.934  Rel. Train L2 Loss :  0.03969105271829499  Rel. Test L2 Loss :  0.04309029817581177  Test L2 Loss :  0.07384476900100707  inv_L_scale:  [1.0, 1.0]
Epoch :  459  Time:  0.934  Rel. Train L2 Loss :  0.03970463178224034  Rel. Test L2 Loss :  0.04304955035448074  Test L2 Loss :  0.07375426173210144  inv_L_scale:  [1.0, 1.0]
Epoch :  460  Time:  0.934  Rel. Train L2 Loss :  0.039677422030104534  Rel. Test L2 Loss :  0.043113843649625776  Test L2 Loss :  0.07390056371688843  inv_L_scale:  [1.0, 1.0]
Epoch :  461  Time:  0.934  Rel. Train L2 Loss :  0.039677903552850086  Rel. Test L2 Loss :  0.04308788791298866  Test L2 Loss :  0.07383434295654297  inv_L_scale:  [1.0, 1.0]
Epoch :  462  Time:  0.934  Rel. Train L2 Loss :  0.03966502563820945  Rel. Test L2 Loss :  0.04307027548551559  Test L2 Loss :  0.07389670133590698  inv_L_scale:  [1.0, 1.0]
Epoch :  463  Time:  0.934  Rel. Train L2 Loss :  0.03966383890973197  Rel. Test L2 Loss :  0.04307560622692108  Test L2 Loss :  0.07382167309522629  inv_L_scale:  [1.0, 1.0]
Epoch :  464  Time:  0.934  Rel. Train L2 Loss :  0.039670798811647624  Rel. Test L2 Loss :  0.04307634055614471  Test L2 Loss :  0.07383902609348297  inv_L_scale:  [1.0, 1.0]
Epoch :  465  Time:  0.934  Rel. Train L2 Loss :  0.03965132206678391  Rel. Test L2 Loss :  0.043064078390598295  Test L2 Loss :  0.0739082258939743  inv_L_scale:  [1.0, 1.0]
Epoch :  466  Time:  0.934  Rel. Train L2 Loss :  0.03965707687868012  Rel. Test L2 Loss :  0.04305342599749565  Test L2 Loss :  0.07382356345653535  inv_L_scale:  [1.0, 1.0]
Epoch :  467  Time:  0.934  Rel. Train L2 Loss :  0.03963532184561094  Rel. Test L2 Loss :  0.04306623086333275  Test L2 Loss :  0.07381242841482162  inv_L_scale:  [1.0, 1.0]
Epoch :  468  Time:  0.934  Rel. Train L2 Loss :  0.039637083560228346  Rel. Test L2 Loss :  0.043062083274126056  Test L2 Loss :  0.07379555195569992  inv_L_scale:  [1.0, 1.0]
Epoch :  469  Time:  0.934  Rel. Train L2 Loss :  0.03962114782796966  Rel. Test L2 Loss :  0.043093706965446475  Test L2 Loss :  0.0738481992483139  inv_L_scale:  [1.0, 1.0]
Epoch :  470  Time:  0.934  Rel. Train L2 Loss :  0.03962921761804157  Rel. Test L2 Loss :  0.04309611797332764  Test L2 Loss :  0.07383248835802078  inv_L_scale:  [1.0, 1.0]
Epoch :  471  Time:  0.934  Rel. Train L2 Loss :  0.03962032717135217  Rel. Test L2 Loss :  0.0431054699420929  Test L2 Loss :  0.0738886046409607  inv_L_scale:  [1.0, 1.0]
Epoch :  472  Time:  0.934  Rel. Train L2 Loss :  0.03961683726973004  Rel. Test L2 Loss :  0.043078302890062335  Test L2 Loss :  0.07383696407079697  inv_L_scale:  [1.0, 1.0]
Epoch :  473  Time:  0.934  Rel. Train L2 Loss :  0.039616220361656615  Rel. Test L2 Loss :  0.04309346079826355  Test L2 Loss :  0.07385145962238311  inv_L_scale:  [1.0, 1.0]
Epoch :  474  Time:  0.934  Rel. Train L2 Loss :  0.039608890662590664  Rel. Test L2 Loss :  0.04305011972784996  Test L2 Loss :  0.07381027340888976  inv_L_scale:  [1.0, 1.0]
Epoch :  475  Time:  0.934  Rel. Train L2 Loss :  0.039600373307863874  Rel. Test L2 Loss :  0.04305363982915878  Test L2 Loss :  0.07380273044109345  inv_L_scale:  [1.0, 1.0]
Epoch :  476  Time:  0.934  Rel. Train L2 Loss :  0.03959768336680201  Rel. Test L2 Loss :  0.04307565152645111  Test L2 Loss :  0.07384485781192779  inv_L_scale:  [1.0, 1.0]
Epoch :  477  Time:  0.934  Rel. Train L2 Loss :  0.0395979321665234  Rel. Test L2 Loss :  0.043058830201625826  Test L2 Loss :  0.07380983769893647  inv_L_scale:  [1.0, 1.0]
Epoch :  478  Time:  0.934  Rel. Train L2 Loss :  0.03959197089076042  Rel. Test L2 Loss :  0.04305366337299347  Test L2 Loss :  0.07380011320114135  inv_L_scale:  [1.0, 1.0]
Epoch :  479  Time:  0.934  Rel. Train L2 Loss :  0.039596521407365796  Rel. Test L2 Loss :  0.04304589375853538  Test L2 Loss :  0.07378228902816772  inv_L_scale:  [1.0, 1.0]
Epoch :  480  Time:  0.934  Rel. Train L2 Loss :  0.03958677483101686  Rel. Test L2 Loss :  0.043065477013587955  Test L2 Loss :  0.07381618857383727  inv_L_scale:  [1.0, 1.0]
Epoch :  481  Time:  0.933  Rel. Train L2 Loss :  0.03957517724898126  Rel. Test L2 Loss :  0.0430452273786068  Test L2 Loss :  0.07379160791635514  inv_L_scale:  [1.0, 1.0]
Epoch :  482  Time:  0.934  Rel. Train L2 Loss :  0.039579130394591225  Rel. Test L2 Loss :  0.04306312143802643  Test L2 Loss :  0.07382023930549622  inv_L_scale:  [1.0, 1.0]
Epoch :  483  Time:  0.934  Rel. Train L2 Loss :  0.03957486023505529  Rel. Test L2 Loss :  0.04306431829929352  Test L2 Loss :  0.0738237428665161  inv_L_scale:  [1.0, 1.0]
Epoch :  484  Time:  0.934  Rel. Train L2 Loss :  0.03957167587346501  Rel. Test L2 Loss :  0.04307624623179436  Test L2 Loss :  0.07383574366569519  inv_L_scale:  [1.0, 1.0]
Epoch :  485  Time:  0.933  Rel. Train L2 Loss :  0.03957278243369526  Rel. Test L2 Loss :  0.04305679231882095  Test L2 Loss :  0.07383040755987168  inv_L_scale:  [1.0, 1.0]
Epoch :  486  Time:  0.934  Rel. Train L2 Loss :  0.03956607735819287  Rel. Test L2 Loss :  0.043061495572328565  Test L2 Loss :  0.07382996618747711  inv_L_scale:  [1.0, 1.0]
Epoch :  487  Time:  0.934  Rel. Train L2 Loss :  0.03956287435359425  Rel. Test L2 Loss :  0.04308029770851135  Test L2 Loss :  0.07383946388959885  inv_L_scale:  [1.0, 1.0]
Epoch :  488  Time:  0.935  Rel. Train L2 Loss :  0.03956804898050096  Rel. Test L2 Loss :  0.04306393593549728  Test L2 Loss :  0.07383931368589401  inv_L_scale:  [1.0, 1.0]
Epoch :  489  Time:  0.934  Rel. Train L2 Loss :  0.03955934873885578  Rel. Test L2 Loss :  0.04306983143091202  Test L2 Loss :  0.07382548868656158  inv_L_scale:  [1.0, 1.0]
Epoch :  490  Time:  0.934  Rel. Train L2 Loss :  0.0395627232392629  Rel. Test L2 Loss :  0.043064278960227964  Test L2 Loss :  0.0738324248790741  inv_L_scale:  [1.0, 1.0]
Epoch :  491  Time:  0.934  Rel. Train L2 Loss :  0.03956119880080223  Rel. Test L2 Loss :  0.04306287407875061  Test L2 Loss :  0.07382254272699357  inv_L_scale:  [1.0, 1.0]
Epoch :  492  Time:  0.934  Rel. Train L2 Loss :  0.0395563852869802  Rel. Test L2 Loss :  0.04306601956486702  Test L2 Loss :  0.07381781935691833  inv_L_scale:  [1.0, 1.0]
Epoch :  493  Time:  0.934  Rel. Train L2 Loss :  0.03955298044615322  Rel. Test L2 Loss :  0.04306919753551483  Test L2 Loss :  0.07382842659950256  inv_L_scale:  [1.0, 1.0]
Epoch :  494  Time:  0.934  Rel. Train L2 Loss :  0.03955484109620253  Rel. Test L2 Loss :  0.04306245356798172  Test L2 Loss :  0.0738184380531311  inv_L_scale:  [1.0, 1.0]
Epoch :  495  Time:  0.934  Rel. Train L2 Loss :  0.03955272646413909  Rel. Test L2 Loss :  0.04306366190314293  Test L2 Loss :  0.07381870329380036  inv_L_scale:  [1.0, 1.0]
Epoch :  496  Time:  0.934  Rel. Train L2 Loss :  0.03955285503632493  Rel. Test L2 Loss :  0.04306109055876732  Test L2 Loss :  0.07382462024688721  inv_L_scale:  [1.0, 1.0]
Epoch :  497  Time:  0.934  Rel. Train L2 Loss :  0.03955279630091455  Rel. Test L2 Loss :  0.04305883258581161  Test L2 Loss :  0.073821422457695  inv_L_scale:  [1.0, 1.0]
Epoch :  498  Time:  0.934  Rel. Train L2 Loss :  0.03955136855443319  Rel. Test L2 Loss :  0.04308769017457962  Test L2 Loss :  0.0738438481092453  inv_L_scale:  [1.0, 1.0]
Epoch :  499  Time:  0.934  Rel. Train L2 Loss :  0.03955517564382818  Rel. Test L2 Loss :  0.043071976006031035  Test L2 Loss :  0.07382900476455688  inv_L_scale:  [1.0, 1.0]
