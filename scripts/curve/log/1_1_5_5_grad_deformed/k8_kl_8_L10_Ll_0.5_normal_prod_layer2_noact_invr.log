(1000,) (1000, 1000, 1) (1000, 1000, 2)
use normalized raw measures
Preprocessing data : computing close_node_pairs
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:15<00:00, 64.29it/s] 
maximum number of close node pairs is  10000
Casting to tensor
x train:torch.Size([900, 1000, 8]), y train:torch.Size([900, 1000, 1]), x test:torch.Size([100, 1000, 8]), y test:torch.Size([100, 1000, 1])
length of each dim:  tensor([6.5573987960815430, 6.1420288085937500])
kmax = 8, kmax_local = 8
L =  10  L_local =  0.5
In PCNO_train, ndims =  2
Epoch :  0  Time:  2.038  Rel. Train L2 Loss :  0.501610335111618  Rel. Test L2 Loss :  0.3556045627593994  Test L2 Loss :  0.508461880683899  inv_L_scale:  [1.0, 1.0]
Epoch :  1  Time:  1.633  Rel. Train L2 Loss :  0.3002351588010788  Rel. Test L2 Loss :  0.2458017373085022  Test L2 Loss :  0.3524529802799225  inv_L_scale:  [1.0, 1.0]
Epoch :  2  Time:  1.661  Rel. Train L2 Loss :  0.22371232589085896  Rel. Test L2 Loss :  0.20745055198669435  Test L2 Loss :  0.2949017262458801  inv_L_scale:  [1.0, 1.0]
Epoch :  3  Time:  1.615  Rel. Train L2 Loss :  0.19610197729534573  Rel. Test L2 Loss :  0.1825382876396179  Test L2 Loss :  0.26291118264198304  inv_L_scale:  [1.0, 1.0]
Epoch :  4  Time:  1.613  Rel. Train L2 Loss :  0.18121912313832178  Rel. Test L2 Loss :  0.17903984785079957  Test L2 Loss :  0.258116802573204  inv_L_scale:  [1.0, 1.0]
Epoch :  5  Time:  1.609  Rel. Train L2 Loss :  0.17595294061634276  Rel. Test L2 Loss :  0.17622942328453065  Test L2 Loss :  0.2511903655529022  inv_L_scale:  [1.0, 1.0]
Epoch :  6  Time:  1.604  Rel. Train L2 Loss :  0.16978827608956232  Rel. Test L2 Loss :  0.15824033677577973  Test L2 Loss :  0.22846349954605102  inv_L_scale:  [1.0, 1.0]
Epoch :  7  Time:  1.654  Rel. Train L2 Loss :  0.164535175230768  Rel. Test L2 Loss :  0.16191656708717347  Test L2 Loss :  0.234001145362854  inv_L_scale:  [1.0, 1.0]
Epoch :  8  Time:  1.608  Rel. Train L2 Loss :  0.16450131409698063  Rel. Test L2 Loss :  0.16327498435974122  Test L2 Loss :  0.23545110285282134  inv_L_scale:  [1.0, 1.0]
Epoch :  9  Time:  1.633  Rel. Train L2 Loss :  0.16142011423905692  Rel. Test L2 Loss :  0.15919246196746825  Test L2 Loss :  0.22930495262145997  inv_L_scale:  [1.0, 1.0]
Epoch :  10  Time:  1.613  Rel. Train L2 Loss :  0.15871883657243516  Rel. Test L2 Loss :  0.15493752896785737  Test L2 Loss :  0.2233851110935211  inv_L_scale:  [1.0, 1.0]
Epoch :  11  Time:  1.626  Rel. Train L2 Loss :  0.15503205186790892  Rel. Test L2 Loss :  0.14942184686660767  Test L2 Loss :  0.2164839458465576  inv_L_scale:  [1.0, 1.0]
Epoch :  12  Time:  1.623  Rel. Train L2 Loss :  0.15464419570234086  Rel. Test L2 Loss :  0.1496589559316635  Test L2 Loss :  0.2162072902917862  inv_L_scale:  [1.0, 1.0]
Epoch :  13  Time:  1.61  Rel. Train L2 Loss :  0.1533625524573856  Rel. Test L2 Loss :  0.14829654037952422  Test L2 Loss :  0.2138323414325714  inv_L_scale:  [1.0, 1.0]
Epoch :  14  Time:  1.64  Rel. Train L2 Loss :  0.1534420712126626  Rel. Test L2 Loss :  0.15494839549064637  Test L2 Loss :  0.22263018608093263  inv_L_scale:  [1.0, 1.0]
Epoch :  15  Time:  1.669  Rel. Train L2 Loss :  0.15230577223830752  Rel. Test L2 Loss :  0.15343478858470916  Test L2 Loss :  0.22073852479457856  inv_L_scale:  [1.0, 1.0]
Epoch :  16  Time:  1.63  Rel. Train L2 Loss :  0.14937343332502578  Rel. Test L2 Loss :  0.14645385205745698  Test L2 Loss :  0.21087892532348632  inv_L_scale:  [1.0, 1.0]
Epoch :  17  Time:  1.618  Rel. Train L2 Loss :  0.1504072008530299  Rel. Test L2 Loss :  0.1462221312522888  Test L2 Loss :  0.21034487307071686  inv_L_scale:  [1.0, 1.0]
Epoch :  18  Time:  1.616  Rel. Train L2 Loss :  0.14661553515328302  Rel. Test L2 Loss :  0.14860871016979219  Test L2 Loss :  0.21529226064682006  inv_L_scale:  [1.0, 1.0]
Epoch :  19  Time:  1.615  Rel. Train L2 Loss :  0.14675493763552772  Rel. Test L2 Loss :  0.14838575720787048  Test L2 Loss :  0.21359209418296815  inv_L_scale:  [1.0, 1.0]
Epoch :  20  Time:  1.639  Rel. Train L2 Loss :  0.14745249569416047  Rel. Test L2 Loss :  0.1461903864145279  Test L2 Loss :  0.210347284078598  inv_L_scale:  [1.0, 1.0]
Epoch :  21  Time:  1.612  Rel. Train L2 Loss :  0.14540162715646957  Rel. Test L2 Loss :  0.1481560003757477  Test L2 Loss :  0.21574480772018434  inv_L_scale:  [1.0, 1.0]
Epoch :  22  Time:  1.62  Rel. Train L2 Loss :  0.14730557686752743  Rel. Test L2 Loss :  0.14372513949871063  Test L2 Loss :  0.20782736897468568  inv_L_scale:  [1.0, 1.0]
Epoch :  23  Time:  1.638  Rel. Train L2 Loss :  0.14375752627849578  Rel. Test L2 Loss :  0.14098107814788818  Test L2 Loss :  0.20456127107143401  inv_L_scale:  [1.0, 1.0]
Epoch :  24  Time:  1.62  Rel. Train L2 Loss :  0.14480295638243357  Rel. Test L2 Loss :  0.13847732543945312  Test L2 Loss :  0.2005413317680359  inv_L_scale:  [1.0, 1.0]
Epoch :  25  Time:  1.618  Rel. Train L2 Loss :  0.14424905558427176  Rel. Test L2 Loss :  0.14619272887706758  Test L2 Loss :  0.21157113671302796  inv_L_scale:  [1.0, 1.0]
Epoch :  26  Time:  1.626  Rel. Train L2 Loss :  0.14520933442645603  Rel. Test L2 Loss :  0.1391713058948517  Test L2 Loss :  0.2011000382900238  inv_L_scale:  [1.0, 1.0]
Epoch :  27  Time:  1.614  Rel. Train L2 Loss :  0.14214388416873083  Rel. Test L2 Loss :  0.1394358366727829  Test L2 Loss :  0.20140179872512817  inv_L_scale:  [1.0, 1.0]
Epoch :  28  Time:  1.612  Rel. Train L2 Loss :  0.14213501012987562  Rel. Test L2 Loss :  0.14366012752056123  Test L2 Loss :  0.20795151710510254  inv_L_scale:  [1.0, 1.0]
Epoch :  29  Time:  1.614  Rel. Train L2 Loss :  0.1427232199907303  Rel. Test L2 Loss :  0.1432796859741211  Test L2 Loss :  0.20744855403900148  inv_L_scale:  [1.0, 1.0]
Epoch :  30  Time:  1.624  Rel. Train L2 Loss :  0.140886229607794  Rel. Test L2 Loss :  0.13955407738685607  Test L2 Loss :  0.2018261045217514  inv_L_scale:  [1.0, 1.0]
Epoch :  31  Time:  1.62  Rel. Train L2 Loss :  0.13913258751233418  Rel. Test L2 Loss :  0.13886289298534393  Test L2 Loss :  0.20166583299636842  inv_L_scale:  [1.0, 1.0]
Epoch :  32  Time:  1.616  Rel. Train L2 Loss :  0.14067262205812667  Rel. Test L2 Loss :  0.13614984154701232  Test L2 Loss :  0.19720456063747405  inv_L_scale:  [1.0, 1.0]
Epoch :  33  Time:  1.63  Rel. Train L2 Loss :  0.13998949358860652  Rel. Test L2 Loss :  0.14584027767181396  Test L2 Loss :  0.21030747950077056  inv_L_scale:  [1.0, 1.0]
Epoch :  34  Time:  1.626  Rel. Train L2 Loss :  0.14019435558054183  Rel. Test L2 Loss :  0.14002777099609376  Test L2 Loss :  0.20230622947216034  inv_L_scale:  [1.0, 1.0]
Epoch :  35  Time:  1.615  Rel. Train L2 Loss :  0.13929686698648663  Rel. Test L2 Loss :  0.1386972427368164  Test L2 Loss :  0.20195249795913697  inv_L_scale:  [1.0, 1.0]
Epoch :  36  Time:  1.622  Rel. Train L2 Loss :  0.13883668376339806  Rel. Test L2 Loss :  0.13543399810791015  Test L2 Loss :  0.19572453439235687  inv_L_scale:  [1.0, 1.0]
Epoch :  37  Time:  1.628  Rel. Train L2 Loss :  0.13972717172569699  Rel. Test L2 Loss :  0.1368027561903  Test L2 Loss :  0.19785403251647948  inv_L_scale:  [1.0, 1.0]
Epoch :  38  Time:  1.679  Rel. Train L2 Loss :  0.13838178031974369  Rel. Test L2 Loss :  0.13452742099761963  Test L2 Loss :  0.1953248381614685  inv_L_scale:  [1.0, 1.0]
Epoch :  39  Time:  1.62  Rel. Train L2 Loss :  0.13856911341349284  Rel. Test L2 Loss :  0.13816716372966767  Test L2 Loss :  0.19972581863403321  inv_L_scale:  [1.0, 1.0]
Epoch :  40  Time:  1.647  Rel. Train L2 Loss :  0.13871669212977092  Rel. Test L2 Loss :  0.137562353014946  Test L2 Loss :  0.19863704085350037  inv_L_scale:  [1.0, 1.0]
Epoch :  41  Time:  1.608  Rel. Train L2 Loss :  0.13858166032367283  Rel. Test L2 Loss :  0.13682109117507935  Test L2 Loss :  0.1979842495918274  inv_L_scale:  [1.0, 1.0]
Epoch :  42  Time:  1.676  Rel. Train L2 Loss :  0.13754599803023868  Rel. Test L2 Loss :  0.13418354332447052  Test L2 Loss :  0.19482549011707306  inv_L_scale:  [1.0, 1.0]
Epoch :  43  Time:  1.623  Rel. Train L2 Loss :  0.13889677504698436  Rel. Test L2 Loss :  0.1449890261888504  Test L2 Loss :  0.20946030855178832  inv_L_scale:  [1.0, 1.0]
Epoch :  44  Time:  1.679  Rel. Train L2 Loss :  0.13797612077660032  Rel. Test L2 Loss :  0.134673610329628  Test L2 Loss :  0.1953185147047043  inv_L_scale:  [1.0, 1.0]
Epoch :  45  Time:  1.618  Rel. Train L2 Loss :  0.13774695343441434  Rel. Test L2 Loss :  0.13356378614902498  Test L2 Loss :  0.19460340857505798  inv_L_scale:  [1.0, 1.0]
Epoch :  46  Time:  1.618  Rel. Train L2 Loss :  0.1364920969804128  Rel. Test L2 Loss :  0.13635450780391692  Test L2 Loss :  0.19747602462768554  inv_L_scale:  [1.0, 1.0]
Epoch :  47  Time:  1.619  Rel. Train L2 Loss :  0.13629384530915153  Rel. Test L2 Loss :  0.13404059380292893  Test L2 Loss :  0.19457990169525147  inv_L_scale:  [1.0, 1.0]
Epoch :  48  Time:  1.621  Rel. Train L2 Loss :  0.13656036469671462  Rel. Test L2 Loss :  0.13628750503063203  Test L2 Loss :  0.1981135630607605  inv_L_scale:  [1.0, 1.0]
Epoch :  49  Time:  1.616  Rel. Train L2 Loss :  0.13603644092877706  Rel. Test L2 Loss :  0.1380827933549881  Test L2 Loss :  0.19938594102859497  inv_L_scale:  [1.0, 1.0]
Epoch :  50  Time:  1.627  Rel. Train L2 Loss :  0.1358985368410746  Rel. Test L2 Loss :  0.13496735215187072  Test L2 Loss :  0.19569243133068084  inv_L_scale:  [1.0, 1.0]
Epoch :  51  Time:  1.641  Rel. Train L2 Loss :  0.13565921915902032  Rel. Test L2 Loss :  0.1335562950372696  Test L2 Loss :  0.1933089429140091  inv_L_scale:  [1.0, 1.0]
Epoch :  52  Time:  1.612  Rel. Train L2 Loss :  0.13763610197438134  Rel. Test L2 Loss :  0.13591431438922882  Test L2 Loss :  0.19807889461517333  inv_L_scale:  [1.0, 1.0]
Epoch :  53  Time:  1.64  Rel. Train L2 Loss :  0.13681915084520976  Rel. Test L2 Loss :  0.1329553985595703  Test L2 Loss :  0.19278219401836394  inv_L_scale:  [1.0, 1.0]
Epoch :  54  Time:  1.634  Rel. Train L2 Loss :  0.1360801805059115  Rel. Test L2 Loss :  0.13596242785453796  Test L2 Loss :  0.19684922456741333  inv_L_scale:  [1.0, 1.0]
Epoch :  55  Time:  1.616  Rel. Train L2 Loss :  0.1364633937014474  Rel. Test L2 Loss :  0.13275384426116943  Test L2 Loss :  0.19292738437652587  inv_L_scale:  [1.0, 1.0]
Epoch :  56  Time:  1.634  Rel. Train L2 Loss :  0.13516656438509622  Rel. Test L2 Loss :  0.1329883188009262  Test L2 Loss :  0.19265469431877136  inv_L_scale:  [1.0, 1.0]
Epoch :  57  Time:  1.617  Rel. Train L2 Loss :  0.13500366310278575  Rel. Test L2 Loss :  0.13527837991714478  Test L2 Loss :  0.1961939078569412  inv_L_scale:  [1.0, 1.0]
Epoch :  58  Time:  1.626  Rel. Train L2 Loss :  0.13556959638992946  Rel. Test L2 Loss :  0.1333448386192322  Test L2 Loss :  0.19321204662323  inv_L_scale:  [1.0, 1.0]
Epoch :  59  Time:  1.643  Rel. Train L2 Loss :  0.13388159579700895  Rel. Test L2 Loss :  0.1321660280227661  Test L2 Loss :  0.19164444208145143  inv_L_scale:  [1.0, 1.0]
Epoch :  60  Time:  1.623  Rel. Train L2 Loss :  0.1341126396258672  Rel. Test L2 Loss :  0.13274875819683074  Test L2 Loss :  0.19241199254989624  inv_L_scale:  [1.0, 1.0]
Epoch :  61  Time:  1.629  Rel. Train L2 Loss :  0.1343296753697925  Rel. Test L2 Loss :  0.1319480937719345  Test L2 Loss :  0.19123049020767213  inv_L_scale:  [1.0, 1.0]
Epoch :  62  Time:  1.616  Rel. Train L2 Loss :  0.13475226236714258  Rel. Test L2 Loss :  0.13133450627326965  Test L2 Loss :  0.1921513020992279  inv_L_scale:  [1.0, 1.0]
Epoch :  63  Time:  1.616  Rel. Train L2 Loss :  0.13409958091047075  Rel. Test L2 Loss :  0.12890560925006866  Test L2 Loss :  0.18779828548431396  inv_L_scale:  [1.0, 1.0]
Epoch :  64  Time:  1.626  Rel. Train L2 Loss :  0.1336664418048329  Rel. Test L2 Loss :  0.1330658948421478  Test L2 Loss :  0.1929280376434326  inv_L_scale:  [1.0, 1.0]
Epoch :  65  Time:  1.627  Rel. Train L2 Loss :  0.13458656032880148  Rel. Test L2 Loss :  0.13081520259380341  Test L2 Loss :  0.1894447511434555  inv_L_scale:  [1.0, 1.0]
Epoch :  66  Time:  1.649  Rel. Train L2 Loss :  0.1335431459877226  Rel. Test L2 Loss :  0.13104933500289917  Test L2 Loss :  0.19105473577976226  inv_L_scale:  [1.0, 1.0]
Epoch :  67  Time:  1.614  Rel. Train L2 Loss :  0.13309084779686398  Rel. Test L2 Loss :  0.1324267244338989  Test L2 Loss :  0.19184348821640015  inv_L_scale:  [1.0, 1.0]
Epoch :  68  Time:  1.635  Rel. Train L2 Loss :  0.13414344370365142  Rel. Test L2 Loss :  0.13037934362888337  Test L2 Loss :  0.18941064476966857  inv_L_scale:  [1.0, 1.0]
Epoch :  69  Time:  1.611  Rel. Train L2 Loss :  0.13306811544630262  Rel. Test L2 Loss :  0.13101513743400572  Test L2 Lo0, 1.0]
Epoch :  70  Time:  1.611  Rel. Train L2 Loss :  0.13305494652854072  Rel. Test L2 Loss :  0.13434675931930543  Test L2 Loss :  0.19450441956520081  inv_L_scale:  [1.0, 1.0]
Epoch :  71  Time:  1.634  Rel. Train L2 Loss :  0.1345200765132904  Rel. Test L2 Loss :  0.13013654679059983  Test L2 Loss :  0.18971444308757782  inv_L_scale:  [1.0, 1.0]
Epoch :  72  Time:  1.641  Rel. Train L2 Loss :  0.13319654160075717  Rel. Test L2 Loss :  0.13124744594097137  Test L2 Loss :  0.19052374601364136  inv_L_scale:  [1.0, 1.0]
Epoch :  73  Time:  1.636  Rel. Train L2 Loss :  0.13276766869756912  Rel. Test L2 Loss :  0.1361715692281723  Test L2 Loss :  0.19611122608184814  inv_L_scale:  [1.0, 1.0]
Epoch :  74  Time:  1.627  Rel. Train L2 Loss :  0.1336959871980879  Rel. Test L2 Loss :  0.1304708331823349  Test L2 Loss :  0.1898493218421936  inv_L_scale:  [1.0, 1.0]
Epoch :  75  Time:  1.662  Rel. Train L2 Loss :  0.13196620477570428  Rel. Test L2 Loss :  0.13472547709941865  Test L2 Loss :  0.19551472663879393  inv_L_scale:  [1.0, 1.0]
Epoch :  76  Time:  1.625  Rel. Train L2 Loss :  0.1323220403326882  Rel. Test L2 Loss :  0.13303879916667938  Test L2 Loss :  0.19331520318984985  inv_L_scale:  [1.0, 1.0]
Epoch :  77  Time:  1.653  Rel. Train L2 Loss :  0.1332486895720164  Rel. Test L2 Loss :  0.1313381040096283  Test L2 Loss :  0.19158413529396057  inv_L_scale:  [1.0, 1.0]
Epoch :  78  Time:  1.626  Rel. Train L2 Loss :  0.13185727887683443  Rel. Test L2 Loss :  0.13713051795959472  Test L2 Loss :  0.19838168144226073  inv_L_scale:  [1.0, 1.0]
Epoch :  79  Time:  1.656  Rel. Train L2 Loss :  0.13220001336601045  Rel. Test L2 Loss :  0.13035609006881713  Test L2 Loss :  0.18980368733406067  inv_L_scale:  [1.0, 1.0]
Epoch :  80  Time:  1.734  Rel. Train L2 Loss :  0.13263750195503235  Rel. Test L2 Loss :  0.13664806246757508  Test L2 Loss :  0.19895830750465393  inv_L_scale:  [1.0, 1.0]
Epoch :  81  Time:  1.653  Rel. Train L2 Loss :  0.1325992402103212  Rel. Test L2 Loss :  0.1305499118566513  Test L2 Loss :  0.19038177967071535  inv_L_scale:  [1.0, 1.0]
Epoch :  82  Time:  1.692  Rel. Train L2 Loss :  0.1314091177781423  Rel. Test L2 Loss :  0.13182467699050904  Test L2 Loss :  0.1912548041343689  inv_L_scale:  [1.0, 1.0]
Epoch :  83  Time:  1.632  Rel. Train L2 Loss :  0.13305722885661656  Rel. Test L2 Loss :  0.12876806139945984  Test L2 Loss :  0.1871326172351837  inv_L_scale:  [1.0, 1.0]
Epoch :  84  Time:  1.618  Rel. Train L2 Loss :  0.1309151362710529  Rel. Test L2 Loss :  0.13263181805610658  Test L2 Loss :  0.1929240369796753  inv_L_scale:  [1.0, 1.0]
Epoch :  85  Time:  1.619  Rel. Train L2 Loss :  0.13234916150569917  Rel. Test L2 Loss :  0.13309997081756592  Test L2 Loss :  0.19326216340065003  inv_L_scale: ss :  0.19326216340065003  inv_L_scale:  [1.0, 1.0]
Epoch :  86  Time:  1.707  Rel. Train L2 Loss :  0.13103424724605348  Rel. Test L2 Loss :  0.12690749078989028  Test L2 Loss :  0.1850727367401123  inv_L_scale:  [1.0, 1.0]
Epoch :  87  Time:  1.619  Rel. Train L2 Loss :  0.1318445344765981  Rel. Test L2 Loss :  0.12977927505970002  Test L2 Loss :  0.18897729158401488  inv_L_scale:  [1.0, 1.0]
Epoch :  88  Time:  1.617  Rel. Train L2 Loss :  0.1319157565302319  Rel. Test L2 Loss :  0.12911342740058898  Test L2 Loss :  0.18814457178115845  inv_L_scale:  [1.0, 1.0]
Epoch :  89  Time:  1.642  Rel. Train L2 Loss :  0.131435409784317  Rel. Test L2 Loss :  0.12901705324649812  Test L2 Loss :  0.18765568912029265  inv_L_scale:  [1.0, 1.0]
Epoch :  90  Time:  1.622  Rel. Train L2 Loss :  0.13154633581638336  Rel. Test L2 Loss :  0.12820352971553803  Test L2 Loss :  0.185962210893631  inv_L_scale:  [1.0, 1.0]
Epoch :  91  Time:  1.632  Rel. Train L2 Loss :  0.13119380921125412  Rel. Test L2 Loss :  0.12975039422512055  Test L2 Loss :  0.18797506809234618  inv_L_scale:  [1.0, 1.0]
Epoch :  92  Time:  1.627  Rel. Train L2 Loss :  0.13194867077800962  Rel. Test L2 Loss :  0.13004102170467377  Test L2 Loss :  0.18972522020339966  inv_L_scale:  [1.0, 1.0]
Epoch :  93  Time:  1.636  Rel. Train L2 Loss :  0.13045943074756197  Rel. Test L2 Loss :  0.13020041465759277  Test L2 Loss :  0.1903353214263916  inv_L_scale:  [1.0, 1.0]
Epoch :  94  Time:  1.631  Rel. Train L2 Loss :  0.13052684923013053  Rel. Test L2 Loss :  0.12912860244512558  Test L2 Loss :  0.1884011721611023  inv_L_scale:  [1.0, 1.0]
Epoch :  95  Time:  1.66  Rel. Train L2 Loss :  0.13064944763978323  Rel. Test L2 Loss :  0.12807293057441713  Test L2 Loss :  0.18601632833480836  inv_L_scale:  [1.0, 1.0]
Epoch :  96  Time:  1.735  Rel. Train L2 Loss :  0.13042183988624148  Rel. Test L2 Loss :  0.12961494773626328  Test L2 Loss :  0.18780815124511718  inv_L_scale:  [1.0, 1.0]
Epoch :  97  Time:  1.685  Rel. Train L2 Loss :  0.12995083305570815  Rel. Test L2 Loss :  0.127899928689003  Test L2 Loss :  0.18609815955162048  inv_L_scale:  [1.0, 1.0]
Epoch :  98  Time:  1.636  Rel. Train L2 Loss :  0.13057811578114828  Rel. Test L2 Loss :  0.1287177485227585  Test L2 Loss :  0.18673392057418822  inv_L_scale:  [1.0, 1.0]
Epoch :  99  Time:  1.634  Rel. Train L2 Loss :  0.12957282337877485  Rel. Test L2 Loss :  0.12762646555900573  Test L2 Loss :  0.18592772245407105  inv_L_scale:  [1.0, 1.0]