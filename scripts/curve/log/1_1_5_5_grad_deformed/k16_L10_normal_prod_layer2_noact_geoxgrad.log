
(1000,) (1000, 1000, 1) (1000, 1000, 2)
use normalized raw measures
Casting to tensor
x_train shape torch.Size([900, 1000, 8]), y_train shape torch.Size([900, 1000, 1])
length of each dim:  tensor([6.5573987960815430, 6.1420288085937500])
kmax = 16
L = 10
use cube modes, scale = 0 (544, 2, 1)
geo_dims = [1, 2, 5, 6]
In PCNO_train, ndims =  2
Epoch :  0  Time:  1.699  Rel. Train L2 Loss :  0.590866355366177  Rel. Test L2 Loss :  0.48463849544525145  Test L2 Loss :  0.7057569622993469  inv_L_scale:  [1.0, 1.0]
Epoch :  1  Time:  1.286  Rel. Train L2 Loss :  0.409095624950197  Rel. Test L2 Loss :  0.34613665103912356  Test L2 Loss :  0.4998138737678528  inv_L_scale:  [1.0, 1.0]
Epoch :  2  Time:  1.277  Rel. Train L2 Loss :  0.29763078490893047  Rel. Test L2 Loss :  0.2688311302661896  Test L2 Loss :  0.38395926356315613  inv_L_scale:  [1.0, 1.0]
Epoch :  3  Time:  1.278  Rel. Train L2 Loss :  0.23373000462849935  Rel. Test L2 Loss :  0.21932703852653504  Test L2 Loss :  0.31275695919990537  inv_L_scale:  [1.0, 1.0]
Epoch :  4  Time:  1.274  Rel. Train L2 Loss :  0.1999702728456921  Rel. Test L2 Loss :  0.1916908073425293  Test L2 Loss :  0.2737561857700348  inv_L_scale:  [1.0, 1.0]
Epoch :  5  Time:  1.284  Rel. Train L2 Loss :  0.18872225410408444  Rel. Test L2 Loss :  0.18462942838668822  Test L2 Loss :  0.26277549505233766  inv_L_scale:  [1.0, 1.0]
Epoch :  6  Time:  1.283  Rel. Train L2 Loss :  0.17335493392414517  Rel. Test L2 Loss :  0.16260988831520082  Test L2 Loss :  0.23323938846588135  inv_L_scale:  [1.0, 1.0]
Epoch :  7  Time:  1.292  Rel. Train L2 Loss :  0.15827367630269792  Rel. Test L2 Loss :  0.1527366715669632  Test L2 Loss :  0.21774123966693879  inv_L_scale:  [1.0, 1.0]
Epoch :  8  Time:  1.282  Rel. Train L2 Loss :  0.15042886793613433  Rel. Test L2 Loss :  0.14698545694351195  Test L2 Loss :  0.21072073817253112  inv_L_scale:  [1.0, 1.0]
Epoch :  9  Time:  1.284  Rel. Train L2 Loss :  0.14444435252083673  Rel. Test L2 Loss :  0.14397904455661772  Test L2 Loss :  0.2060423767566681  inv_L_scale:  [1.0, 1.0]
Epoch :  10  Time:  1.283  Rel. Train L2 Loss :  0.13880430618921916  Rel. Test L2 Loss :  0.140524023771286  Test L2 Loss :  0.20029358983039855  inv_L_scale:  [1.0, 1.0]
Epoch :  11  Time:  1.283  Rel. Train L2 Loss :  0.1324366158246994  Rel. Test L2 Loss :  0.133235445022583  Test L2 Loss :  0.19136534333229066  inv_L_scale:  [1.0, 1.0]
Epoch :  12  Time:  1.298  Rel. Train L2 Loss :  0.12749345103899637  Rel. Test L2 Loss :  0.1285830146074295  Test L2 Loss :  0.18508456647396088  inv_L_scale:  [1.0, 1.0]
Epoch :  13  Time:  1.315  Rel. Train L2 Loss :  0.12466409636868371  Rel. Test L2 Loss :  0.12707700788974763  Test L2 Loss :  0.18346723914146423  inv_L_scale:  [1.0, 1.0]
Epoch :  14  Time:  1.298  Rel. Train L2 Loss :  0.12110978951056799  Rel. Test L2 Loss :  0.1190189528465271  Test L2 Loss :  0.17018959760665894  inv_L_scale:  [1.0, 1.0]
Epoch :  15  Time:  1.282  Rel. Train L2 Loss :  0.11805123739772373  Rel. Test L2 Loss :  0.1147482743859291  Test L2 Loss :  0.16555435717105865  inv_L_scale:  [1.0, 1.0]
Epoch :  16  Time:  1.281  Rel. Train L2 Loss :  0.11434856573740641  Rel. Test L2 Loss :  0.11636857509613037  Test L2 Loss :  0.1676747226715088  inv_L_scale:  [1.0, 1.0]
Epoch :  17  Time:  1.28  Rel. Train L2 Loss :  0.11309374392032623  Rel. Test L2 Loss :  0.11199480563402175  Test L2 Loss :  0.1613157069683075  inv_L_scale:  [1.0, 1.0]
Epoch :  18  Time:  1.279  Rel. Train L2 Loss :  0.10978479577435388  Rel. Test L2 Loss :  0.1078277599811554  Test L2 Loss :  0.15432116031646728  inv_L_scale:  [1.0, 1.0]
Epoch :  19  Time:  1.278  Rel. Train L2 Loss :  0.10585556768708759  Rel. Test L2 Loss :  0.10958372324705123  Test L2 Loss :  0.15726425886154174  inv_L_scale:  [1.0, 1.0]
Epoch :  20  Time:  1.28  Rel. Train L2 Loss :  0.10468779020839267  Rel. Test L2 Loss :  0.1047066992521286  Test L2 Loss :  0.15036150991916655  inv_L_scale:  [1.0, 1.0]
Epoch :  21  Time:  1.287  Rel. Train L2 Loss :  0.10376381191942427  Rel. Test L2 Loss :  0.10824865996837615  Test L2 Loss :  0.15637053608894347  inv_L_scale:  [1.0, 1.0]
Epoch :  22  Time:  1.288  Rel. Train L2 Loss :  0.10281229555606843  Rel. Test L2 Loss :  0.10559105008840561  Test L2 Loss :  0.1523364019393921  inv_L_scale:  [1.0, 1.0]
Epoch :  23  Time:  1.296  Rel. Train L2 Loss :  0.10174074802133772  Rel. Test L2 Loss :  0.10076719403266907  Test L2 Loss :  0.14509110927581786  inv_L_scale:  [1.0, 1.0]
Epoch :  24  Time:  1.295  Rel. Train L2 Loss :  0.0985515151421229  Rel. Test L2 Loss :  0.09879478812217712  Test L2 Loss :  0.14248741328716277  inv_L_scale:  [1.0, 1.0]
Epoch :  25  Time:  1.288  Rel. Train L2 Loss :  0.09863460948069891  Rel. Test L2 Loss :  0.09678603082895279  Test L2 Loss :  0.13886382102966308  inv_L_scale:  [1.0, 1.0]
Epoch :  26  Time:  1.299  Rel. Train L2 Loss :  0.09766335606575012  Rel. Test L2 Loss :  0.09711836874485016  Test L2 Loss :  0.1397354072332382  inv_L_scale:  [1.0, 1.0]
Epoch :  27  Time:  1.288  Rel. Train L2 Loss :  0.09461821946832868  Rel. Test L2 Loss :  0.09443824589252472  Test L2 Loss :  0.1359526824951172  inv_L_scale:  [1.0, 1.0]
Epoch :  28  Time:  1.28  Rel. Train L2 Loss :  0.09366978873809179  Rel. Test L2 Loss :  0.0963722175359726  Test L2 Loss :  0.13793107390403747  inv_L_scale:  [1.0, 1.0]
Epoch :  29  Time:  1.287  Rel. Train L2 Loss :  0.09156243370638953  Rel. Test L2 Loss :  0.09635814756155014  Test L2 Loss :  0.13883882105350495  inv_L_scale:  [1.0, 1.0]
Epoch :  30  Time:  1.284  Rel. Train L2 Loss :  0.09302903844250573  Rel. Test L2 Loss :  0.09480416417121887  Test L2 Loss :  0.13609943151474  inv_L_scale:  [1.0, 1.0]
Epoch :  31  Time:  1.286  Rel. Train L2 Loss :  0.0919854473736551  Rel. Test L2 Loss :  0.0992028096318245  Test L2 Loss :  0.14268145382404326  inv_L_scale:  [1.0, 1.0]
Epoch :  32  Time:  1.281  Rel. Train L2 Loss :  0.09376591990391413  Rel. Test L2 Loss :  0.09354759454727173  Test L2 Loss :  0.13454631209373474  inv_L_scale:  [1.0, 1.0]
Epoch :  33  Time:  1.291  Rel. Train L2 Loss :  0.0912243687444263  Rel. Test L2 Loss :  0.08963267296552659  Test L2 Loss :  0.12858080565929414  inv_L_scale:  [1.0, 1.0]
Epoch :  34  Time:  1.288  Rel. Train L2 Loss :  0.08896698037783304  Rel. Test L2 Loss :  0.09051264017820358  Test L2 Loss :  0.12992033123970032  inv_L_scale:  [1.0, 1.0]
Epoch :  35  Time:  1.287  Rel. Train L2 Loss :  0.0880788485871421  Rel. Test L2 Loss :  0.090017891228199  Test L2 Loss :  0.1291781771183014  inv_L_scale:  [1.0, 1.0]
Epoch :  36  Time:  1.288  Rel. Train L2 Loss :  0.08956463757488463  Rel. Test L2 Loss :  0.08603325545787811  Test L2 Loss :  0.1237898701429367  inv_L_scale:  [1.0, 1.0]
Epoch :  37  Time:  1.291  Rel. Train L2 Loss :  0.08712979230615828  Rel. Test L2 Loss :  0.08636244177818299  Test L2 Loss :  0.12410343587398528  inv_L_scale:  [1.0, 1.0]
Epoch :  38  Time:  1.286  Rel. Train L2 Loss :  0.0841952813996209  Rel. Test L2 Loss :  0.08634568482637406  Test L2 Loss :  0.12398586839437485  inv_L_scale:  [1.0, 1.0]
Epoch :  39  Time:  1.284  Rel. Train L2 Loss :  0.08590111855003568  Rel. Test L2 Loss :  0.087804054915905  Test L2 Loss :  0.12683039903640747  inv_L_scale:  [1.0, 1.0]
Epoch :  40  Time:  1.28  Rel. Train L2 Loss :  0.08474720421764585  Rel. Test L2 Loss :  0.0846258294582367  Test L2 Loss :  0.12182109534740448  inv_L_scale:  [1.0, 1.0]
Epoch :  41  Time:  1.279  Rel. Train L2 Loss :  0.08459533042377895  Rel. Test L2 Loss :  0.08280594617128373  Test L2 Loss :  0.11908025741577148  inv_L_scale:  [1.0, 1.0]
Epoch :  42  Time:  1.275  Rel. Train L2 Loss :  0.08376350584957334  Rel. Test L2 Loss :  0.08462681263685226  Test L2 Loss :  0.12175535410642624  inv_L_scale:  [1.0, 1.0]
Epoch :  43  Time:  1.275  Rel. Train L2 Loss :  0.08464446773131688  Rel. Test L2 Loss :  0.08677425920963287  Test L2 Loss :  0.12451479345560074  inv_L_scale:  [1.0, 1.0]
Epoch :  44  Time:  1.276  Rel. Train L2 Loss :  0.0837093918522199  Rel. Test L2 Loss :  0.08562705188989639  Test L2 Loss :  0.12318041652441025  inv_L_scale:  [1.0, 1.0]
Epoch :  45  Time:  1.283  Rel. Train L2 Loss :  0.08159627964099249  Rel. Test L2 Loss :  0.08218011379241943  Test L2 Loss :  0.11869955092668533  inv_L_scale:  [1.0, 1.0]
Epoch :  46  Time:  1.3  Rel. Train L2 Loss :  0.08265479044781791  Rel. Test L2 Loss :  0.08444673627614975  Test L2 Loss :  0.12203559964895248  inv_L_scale:  [1.0, 1.0]
Epoch :  47  Time:  1.281  Rel. Train L2 Loss :  0.0821865314245224  Rel. Test L2 Loss :  0.08055520534515381  Test L2 Loss :  0.11620046436786652  inv_L_scale:  [1.0, 1.0]
Epoch :  48  Time:  1.279  Rel. Train L2 Loss :  0.08265870938698451  Rel. Test L2 Loss :  0.08559750765562057  Test L2 Loss :  0.12260372132062912  inv_L_scale:  [1.0, 1.0]
Epoch :  49  Time:  1.273  Rel. Train L2 Loss :  0.08093003513084518  Rel. Test L2 Loss :  0.07873754322528839  Test L2 Loss :  0.11320694774389267  inv_L_scale:  [1.0, 1.0]
Epoch :  50  Time:  1.281  Rel. Train L2 Loss :  0.08032785481876797  Rel. Test L2 Loss :  0.08154016494750976  Test L2 Loss :  0.11733380258083344  inv_L_scale:  [1.0, 1.0]
Epoch :  51  Time:  1.287  Rel. Train L2 Loss :  0.07877728323141733  Rel. Test L2 Loss :  0.07974782109260559  Test L2 Loss :  0.1149355161190033  inv_L_scale:  [1.0, 1.0]
Epoch :  52  Time:  1.284  Rel. Train L2 Loss :  0.0793461642993821  Rel. Test L2 Loss :  0.07851690739393234  Test L2 Loss :  0.11293432980775833  inv_L_scale:  [1.0, 1.0]
Epoch :  53  Time:  1.28  Rel. Train L2 Loss :  0.07817181229591369  Rel. Test L2 Loss :  0.08167363077402115  Test L2 Loss :  0.11771329700946807  inv_L_scale:  [1.0, 1.0]
Epoch :  54  Time:  1.279  Rel. Train L2 Loss :  0.07944923828045528  Rel. Test L2 Loss :  0.07846634835004807  Test L2 Loss :  0.11300539016723633  inv_L_scale:  [1.0, 1.0]
Epoch :  55  Time:  1.279  Rel. Train L2 Loss :  0.07873843169874616  Rel. Test L2 Loss :  0.08488854825496674  Test L2 Loss :  0.12121950805187226  inv_L_scale:  [1.0, 1.0]
Epoch :  56  Time:  1.282  Rel. Train L2 Loss :  0.07902924415138032  Rel. Test L2 Loss :  0.07987470000982284  Test L2 Loss :  0.11460667699575425  inv_L_scale:  [1.0, 1.0]
Epoch :  57  Time:  1.277  Rel. Train L2 Loss :  0.07776631000969145  Rel. Test L2 Loss :  0.07724666059017181  Test L2 Loss :  0.11123105645179748  inv_L_scale:  [1.0, 1.0]
Epoch :  58  Time:  1.279  Rel. Train L2 Loss :  0.07782890654272503  Rel. Test L2 Loss :  0.08198158979415894  Test L2 Loss :  0.11741746604442596  inv_L_scale:  [1.0, 1.0]
Epoch :  59  Time:  1.283  Rel. Train L2 Loss :  0.0774774201048745  Rel. Test L2 Loss :  0.07827499330043793  Test L2 Loss :  0.11232184290885926  inv_L_scale:  [1.0, 1.0]
Epoch :  60  Time:  1.279  Rel. Train L2 Loss :  0.07625735842519336  Rel. Test L2 Loss :  0.07492720305919648  Test L2 Loss :  0.10809525370597839  inv_L_scale:  [1.0, 1.0]
Epoch :  61  Time:  1.279  Rel. Train L2 Loss :  0.07644511449668143  Rel. Test L2 Loss :  0.07475608736276626  Test L2 Loss :  0.10730218589305877  inv_L_scale:  [1.0, 1.0]
Epoch :  62  Time:  1.284  Rel. Train L2 Loss :  0.07533857928382026  Rel. Test L2 Loss :  0.07706142306327819  Test L2 Loss :  0.11075296103954316  inv_L_scale:  [1.0, 1.0]
Epoch :  63  Time:  1.281  Rel. Train L2 Loss :  0.07525046179691951  Rel. Test L2 Loss :  0.07789957046508789  Test L2 Loss :  0.1125681146979332  inv_L_scale:  [1.0, 1.0]
Epoch :  64  Time:  1.289  Rel. Train L2 Loss :  0.07566094279289245  Rel. Test L2 Loss :  0.07494431763887405  Test L2 Loss :  0.10756616592407227  inv_L_scale:  [1.0, 1.0]
Epoch :  65  Time:  1.286  Rel. Train L2 Loss :  0.07501652467581961  Rel. Test L2 Loss :  0.07357787638902664  Test L2 Loss :  0.10605870723724366  inv_L_scale:  [1.0, 1.0]
Epoch :  66  Time:  1.293  Rel. Train L2 Loss :  0.07511758656965362  Rel. Test L2 Loss :  0.07726102709770202  Test L2 Loss :  0.1113700583577156  inv_L_scale:  [1.0, 1.0]
Epoch :  67  Time:  1.284  Rel. Train L2 Loss :  0.0746435828672515  Rel. Test L2 Loss :  0.07678653508424758  Test L2 Loss :  0.1103799271583557  inv_L_scale:  [1.0, 1.0]
Epoch :  68  Time:  1.287  Rel. Train L2 Loss :  0.07533261279265085  Rel. Test L2 Loss :  0.07499780595302581  Test L2 Loss :  0.10796179771423339  inv_L_scale:  [1.0, 1.0]
Epoch :  69  Time:  1.282  Rel. Train L2 Loss :  0.0725345183743371  Rel. Test L2 Loss :  0.07882859885692596  Test L2 Loss :  0.11365048170089721  inv_L_scale:  [1.0, 1.0]
Epoch :  70  Time:  1.282  Rel. Train L2 Loss :  0.0737275089820226  Rel. Test L2 Loss :  0.07319320350885392  Test L2 Loss :  0.10542547583580017  inv_L_scale:  [1.0, 1.0]
Epoch :  71  Time:  1.28  Rel. Train L2 Loss :  0.07335819045702617  Rel. Test L2 Loss :  0.0785550993680954  Test L2 Loss :  0.112853744328022  inv_L_scale:  [1.0, 1.0]
Epoch :  72  Time:  1.283  Rel. Train L2 Loss :  0.07322424398528204  Rel. Test L2 Loss :  0.07368181884288788  Test L2 Loss :  0.1056505525112152  inv_L_scale:  [1.0, 1.0]
Epoch :  73  Time:  1.284  Rel. Train L2 Loss :  0.07216688728994794  Rel. Test L2 Loss :  0.07523239314556122  Test L2 Loss :  0.10790290117263794  inv_L_scale:  [1.0, 1.0]
Epoch :  74  Time:  1.284  Rel. Train L2 Loss :  0.07231614430745442  Rel. Test L2 Loss :  0.07325357973575591  Test L2 Loss :  0.105786072909832  inv_L_scale:  [1.0, 1.0]
Epoch :  75  Time:  1.282  Rel. Train L2 Loss :  0.07218167377842798  Rel. Test L2 Loss :  0.07906043350696564  Test L2 Loss :  0.11309845358133316  inv_L_scale:  [1.0, 1.0]
Epoch :  76  Time:  1.284  Rel. Train L2 Loss :  0.07308605894446372  Rel. Test L2 Loss :  0.07011136710643769  Test L2 Loss :  0.10100864589214326  inv_L_scale:  [1.0, 1.0]
Epoch :  77  Time:  1.28  Rel. Train L2 Loss :  0.0709266272187233  Rel. Test L2 Loss :  0.07024400919675827  Test L2 Loss :  0.10137326717376709  inv_L_scale:  [1.0, 1.0]
Epoch :  78  Time:  1.282  Rel. Train L2 Loss :  0.07112509654627906  Rel. Test L2 Loss :  0.06961538583040237  Test L2 Loss :  0.10022840857505798  inv_L_scale:  [1.0, 1.0]
Epoch :  79  Time:  1.282  Rel. Train L2 Loss :  0.0707102738486396  Rel. Test L2 Loss :  0.06861521631479263  Test L2 Loss :  0.09881456315517426  inv_L_scale:  [1.0, 1.0]
Epoch :  80  Time:  1.292  Rel. Train L2 Loss :  0.07124931772549947  Rel. Test L2 Loss :  0.07114470541477204  Test L2 Loss :  0.10242863595485688  inv_L_scale:  [1.0, 1.0]
Epoch :  81  Time:  1.285  Rel. Train L2 Loss :  0.07095558676454757  Rel. Test L2 Loss :  0.07211937367916108  Test L2 Loss :  0.10345151245594025  inv_L_scale:  [1.0, 1.0]
Epoch :  82  Time:  1.296  Rel. Train L2 Loss :  0.07033748749229643  Rel. Test L2 Loss :  0.07422967553138733  Test L2 Loss :  0.10661322861909867  inv_L_scale:  [1.0, 1.0]
Epoch :  83  Time:  1.302  Rel. Train L2 Loss :  0.07110652529531054  Rel. Test L2 Loss :  0.0693295180797577  Test L2 Loss :  0.1000431752204895  inv_L_scale:  [1.0, 1.0]
Epoch :  84  Time:  1.282  Rel. Train L2 Loss :  0.07072625282737943  Rel. Test L2 Loss :  0.07215894639492035  Test L2 Loss :  0.103765589594841  inv_L_scale:  [1.0, 1.0]
Epoch :  85  Time:  1.297  Rel. Train L2 Loss :  0.0705666940079795  Rel. Test L2 Loss :  0.07186966776847839  Test L2 Loss :  0.10413769483566285  inv_L_scale:  [1.0, 1.0]
Epoch :  86  Time:  1.29  Rel. Train L2 Loss :  0.06932724965943231  Rel. Test L2 Loss :  0.07137180298566818  Test L2 Loss :  0.10265164256095886  inv_L_scale:  [1.0, 1.0]
Epoch :  87  Time:  1.281  Rel. Train L2 Loss :  0.06892430322037803  Rel. Test L2 Loss :  0.07130889236927032  Test L2 Loss :  0.1024414399266243  inv_L_scale:  [1.0, 1.0]
Epoch :  88  Time:  1.281  Rel. Train L2 Loss :  0.07046802229351468  Rel. Test L2 Loss :  0.07182278096675873  Test L2 Loss :  0.103191277384758  inv_L_scale:  [1.0, 1.0]
Epoch :  89  Time:  1.282  Rel. Train L2 Loss :  0.06931552078988817  Rel. Test L2 Loss :  0.07150801032781601  Test L2 Loss :  0.10288494408130645  inv_L_scale:  [1.0, 1.0]
Epoch :  90  Time:  1.282  Rel. Train L2 Loss :  0.06885702321926752  Rel. Test L2 Loss :  0.0734348738193512  Test L2 Loss :  0.1058335891366005  inv_L_scale:  [1.0, 1.0]
Epoch :  91  Time:  1.287  Rel. Train L2 Loss :  0.06866363604863485  Rel. Test L2 Loss :  0.06877669125795365  Test L2 Loss :  0.09945963144302368  inv_L_scale:  [1.0, 1.0]
Epoch :  92  Time:  1.29  Rel. Train L2 Loss :  0.06889042930470572  Rel. Test L2 Loss :  0.06966683477163314  Test L2 Loss :  0.1002128180861473  inv_L_scale:  [1.0, 1.0]
Epoch :  93  Time:  1.291  Rel. Train L2 Loss :  0.06937391416894065  Rel. Test L2 Loss :  0.07180086404085159  Test L2 Loss :  0.10353914439678193  inv_L_scale:  [1.0, 1.0]
Epoch :  94  Time:  1.284  Rel. Train L2 Loss :  0.06847714338037703  Rel. Test L2 Loss :  0.06972545832395553  Test L2 Loss :  0.10065946519374848  inv_L_scale:  [1.0, 1.0]
Epoch :  95  Time:  1.284  Rel. Train L2 Loss :  0.0682563558055295  Rel. Test L2 Loss :  0.07053129374980927  Test L2 Loss :  0.10139509379863738  inv_L_scale:  [1.0, 1.0]
Epoch :  96  Time:  1.279  Rel. Train L2 Loss :  0.06900149563948313  Rel. Test L2 Loss :  0.06859334766864776  Test L2 Loss :  0.09922580987215042  inv_L_scale:  [1.0, 1.0]
Epoch :  97  Time:  1.285  Rel. Train L2 Loss :  0.06723784708314472  Rel. Test L2 Loss :  0.06881295412778854  Test L2 Loss :  0.09912309706211091  inv_L_scale:  [1.0, 1.0]
Epoch :  98  Time:  1.281  Rel. Train L2 Loss :  0.0680498875843154  Rel. Test L2 Loss :  0.06873097538948059  Test L2 Loss :  0.09914659559726716  inv_L_scale:  [1.0, 1.0]
Epoch :  99  Time:  1.287  Rel. Train L2 Loss :  0.06761299573712878  Rel. Test L2 Loss :  0.06660481810569763  Test L2 Loss :  0.09601192086935044  inv_L_scale:  [1.0, 1.0]
Epoch :  100  Time:  1.282  Rel. Train L2 Loss :  0.06551572859287262  Rel. Test L2 Loss :  0.06769393473863601  Test L2 Loss :  0.09751707673072815  inv_L_scale:  [1.0, 1.0]
Epoch :  101  Time:  1.294  Rel. Train L2 Loss :  0.06797423157427046  Rel. Test L2 Loss :  0.06632938295602799  Test L2 Loss :  0.09556108325719834  inv_L_scale:  [1.0, 1.0]
Epoch :  102  Time:  1.297  Rel. Train L2 Loss :  0.06699340381556088  Rel. Test L2 Loss :  0.07008448421955109  Test L2 Loss :  0.10101734489202499  inv_L_scale:  [1.0, 1.0]
Epoch :  103  Time:  1.294  Rel. Train L2 Loss :  0.06648811201254527  Rel. Test L2 Loss :  0.0677854323387146  Test L2 Loss :  0.09814337223768234  inv_L_scale:  [1.0, 1.0]
Epoch :  104  Time:  1.286  Rel. Train L2 Loss :  0.06537494824992286  Rel. Test L2 Loss :  0.06474453032016754  Test L2 Loss :  0.09344475328922272  inv_L_scale:  [1.0, 1.0]
Epoch :  105  Time:  1.283  Rel. Train L2 Loss :  0.06465909669796625  Rel. Test L2 Loss :  0.06715309888124465  Test L2 Loss :  0.09686638534069061  inv_L_scale:  [1.0, 1.0]
Epoch :  106  Time:  1.288  Rel. Train L2 Loss :  0.06450415541728338  Rel. Test L2 Loss :  0.06712337791919708  Test L2 Loss :  0.096672945022583  inv_L_scale:  [1.0, 1.0]
Epoch :  107  Time:  1.297  Rel. Train L2 Loss :  0.06507281579905086  Rel. Test L2 Loss :  0.06689386904239654  Test L2 Loss :  0.09619749546051025  inv_L_scale:  [1.0, 1.0]
Epoch :  108  Time:  1.291  Rel. Train L2 Loss :  0.06404880406128036  Rel. Test L2 Loss :  0.06511488914489746  Test L2 Loss :  0.09398608386516571  inv_L_scale:  [1.0, 1.0]
Epoch :  109  Time:  1.29  Rel. Train L2 Loss :  0.06384004599518246  Rel. Test L2 Loss :  0.07030322432518005  Test L2 Loss :  0.1003573414683342  inv_L_scale:  [1.0, 1.0]
Epoch :  110  Time:  1.285  Rel. Train L2 Loss :  0.06399543851613998  Rel. Test L2 Loss :  0.0676815801858902  Test L2 Loss :  0.09700927525758743  inv_L_scale:  [1.0, 1.0]
Epoch :  111  Time:  1.279  Rel. Train L2 Loss :  0.06374465227127075  Rel. Test L2 Loss :  0.06638171851634979  Test L2 Loss :  0.09570873618125915  inv_L_scale:  [1.0, 1.0]
Epoch :  112  Time:  1.289  Rel. Train L2 Loss :  0.06294702483548058  Rel. Test L2 Loss :  0.06502252459526062  Test L2 Loss :  0.09358885407447814  inv_L_scale:  [1.0, 1.0]
Epoch :  113  Time:  1.286  Rel. Train L2 Loss :  0.06339953384465641  Rel. Test L2 Loss :  0.06509997844696044  Test L2 Loss :  0.09383060157299042  inv_L_scale:  [1.0, 1.0]
Epoch :  114  Time:  1.286  Rel. Train L2 Loss :  0.06337911052836312  Rel. Test L2 Loss :  0.06993013590574265  Test L2 Loss :  0.10024251759052277  inv_L_scale:  [1.0, 1.0]
Epoch :  115  Time:  1.291  Rel. Train L2 Loss :  0.06411574790875117  Rel. Test L2 Loss :  0.07007798850536347  Test L2 Loss :  0.10052294731140136  inv_L_scale:  [1.0, 1.0]
Epoch :  116  Time:  1.293  Rel. Train L2 Loss :  0.06304452915986379  Rel. Test L2 Loss :  0.06554031223058701  Test L2 Loss :  0.09423924028873444  inv_L_scale:  [1.0, 1.0]
Epoch :  117  Time:  1.288  Rel. Train L2 Loss :  0.06360464945435523  Rel. Test L2 Loss :  0.0643139711022377  Test L2 Loss :  0.09296485841274262  inv_L_scale:  [1.0, 1.0]
Epoch :  118  Time:  1.295  Rel. Train L2 Loss :  0.06459985676738951  Rel. Test L2 Loss :  0.06426195412874222  Test L2 Loss :  0.09265317231416702  inv_L_scale:  [1.0, 1.0]
Epoch :  119  Time:  1.294  Rel. Train L2 Loss :  0.06242195331388049  Rel. Test L2 Loss :  0.06206507205963135  Test L2 Loss :  0.08921654492616654  inv_L_scale:  [1.0, 1.0]
Epoch :  120  Time:  1.297  Rel. Train L2 Loss :  0.06177413377496931  Rel. Test L2 Loss :  0.06299878090620041  Test L2 Loss :  0.09100744366645813  inv_L_scale:  [1.0, 1.0]
Epoch :  121  Time:  1.299  Rel. Train L2 Loss :  0.06164860003524356  Rel. Test L2 Loss :  0.06520197063684463  Test L2 Loss :  0.09398698955774307  inv_L_scale:  [1.0, 1.0]
Epoch :  122  Time:  1.287  Rel. Train L2 Loss :  0.062078938119941286  Rel. Test L2 Loss :  0.06505929589271546  Test L2 Loss :  0.09371193110942841  inv_L_scale:  [1.0, 1.0]
Epoch :  123  Time:  1.293  Rel. Train L2 Loss :  0.061722119053204856  Rel. Test L2 Loss :  0.06165140777826309  Test L2 Loss :  0.08878294348716737  inv_L_scale:  [1.0, 1.0]
Epoch :  124  Time:  1.282  Rel. Train L2 Loss :  0.06143122421370612  Rel. Test L2 Loss :  0.06595662534236908  Test L2 Loss :  0.09508275151252747  inv_L_scale:  [1.0, 1.0]
Epoch :  125  Time:  1.289  Rel. Train L2 Loss :  0.06095506287283368  Rel. Test L2 Loss :  0.06211107477545738  Test L2 Loss :  0.08941641360521317  inv_L_scale:  [1.0, 1.0]
Epoch :  126  Time:  1.291  Rel. Train L2 Loss :  0.06330556369490094  Rel. Test L2 Loss :  0.06505141109228134  Test L2 Loss :  0.09416221648454666  inv_L_scale:  [1.0, 1.0]
Epoch :  127  Time:  1.294  Rel. Train L2 Loss :  0.06319301966163847  Rel. Test L2 Loss :  0.0657217401266098  Test L2 Loss :  0.09516954004764556  inv_L_scale:  [1.0, 1.0]
Epoch :  128  Time:  1.299  Rel. Train L2 Loss :  0.0628363199532032  Rel. Test L2 Loss :  0.06360377699136734  Test L2 Loss :  0.09174287170171738  inv_L_scale:  [1.0, 1.0]
Epoch :  129  Time:  1.294  Rel. Train L2 Loss :  0.062182915111382804  Rel. Test L2 Loss :  0.06478535920381547  Test L2 Loss :  0.09357212960720063  inv_L_scale:  [1.0, 1.0]
Epoch :  130  Time:  1.302  Rel. Train L2 Loss :  0.06254201014836629  Rel. Test L2 Loss :  0.06475921452045441  Test L2 Loss :  0.09317492425441742  inv_L_scale:  [1.0, 1.0]
Epoch :  131  Time:  1.284  Rel. Train L2 Loss :  0.061519694593217635  Rel. Test L2 Loss :  0.062197078764438626  Test L2 Loss :  0.08945726275444031  inv_L_scale:  [1.0, 1.0]
Epoch :  132  Time:  1.29  Rel. Train L2 Loss :  0.06214206549856398  Rel. Test L2 Loss :  0.06199093952775001  Test L2 Loss :  0.08938577473163604  inv_L_scale:  [1.0, 1.0]
Epoch :  133  Time:  1.287  Rel. Train L2 Loss :  0.0601994264125824  Rel. Test L2 Loss :  0.06311617821455001  Test L2 Loss :  0.0905086100101471  inv_L_scale:  [1.0, 1.0]
Epoch :  134  Time:  1.288  Rel. Train L2 Loss :  0.06039824974205759  Rel. Test L2 Loss :  0.06374235451221466  Test L2 Loss :  0.09157918035984039  inv_L_scale:  [1.0, 1.0]
Epoch :  135  Time:  1.286  Rel. Train L2 Loss :  0.060079299575752684  Rel. Test L2 Loss :  0.06148092404007912  Test L2 Loss :  0.08864353001117706  inv_L_scale:  [1.0, 1.0]
Epoch :  136  Time:  1.288  Rel. Train L2 Loss :  0.059425091561343936  Rel. Test L2 Loss :  0.06075572490692139  Test L2 Loss :  0.08779367506504059  inv_L_scale:  [1.0, 1.0]
Epoch :  137  Time:  1.302  Rel. Train L2 Loss :  0.05943642175859875  Rel. Test L2 Loss :  0.0622190397977829  Test L2 Loss :  0.08966134905815125  inv_L_scale:  [1.0, 1.0]
Epoch :  138  Time:  1.306  Rel. Train L2 Loss :  0.05988484319713381  Rel. Test L2 Loss :  0.0628534784913063  Test L2 Loss :  0.09074349939823151  inv_L_scale:  [1.0, 1.0]
Epoch :  139  Time:  1.289  Rel. Train L2 Loss :  0.05997301808661885  Rel. Test L2 Loss :  0.06327864021062851  Test L2 Loss :  0.09111168801784515  inv_L_scale:  [1.0, 1.0]
Epoch :  140  Time:  1.283  Rel. Train L2 Loss :  0.060508234683010316  Rel. Test L2 Loss :  0.06329299673438073  Test L2 Loss :  0.09147585928440094  inv_L_scale:  [1.0, 1.0]
Epoch :  141  Time:  1.287  Rel. Train L2 Loss :  0.06064387904273139  Rel. Test L2 Loss :  0.062107456028461454  Test L2 Loss :  0.08947941422462463  inv_L_scale:  [1.0, 1.0]
Epoch :  142  Time:  1.283  Rel. Train L2 Loss :  0.05947730282942454  Rel. Test L2 Loss :  0.06158973842859268  Test L2 Loss :  0.08873795330524445  inv_L_scale:  [1.0, 1.0]
Epoch :  143  Time:  1.284  Rel. Train L2 Loss :  0.059887771987252765  Rel. Test L2 Loss :  0.06077990859746933  Test L2 Loss :  0.08772045612335205  inv_L_scale:  [1.0, 1.0]
Epoch :  144  Time:  1.287  Rel. Train L2 Loss :  0.05916645156012641  Rel. Test L2 Loss :  0.06007845491170883  Test L2 Loss :  0.08666594505310059  inv_L_scale:  [1.0, 1.0]
Epoch :  145  Time:  1.284  Rel. Train L2 Loss :  0.05813577797677782  Rel. Test L2 Loss :  0.061111168265342714  Test L2 Loss :  0.0879372626543045  inv_L_scale:  [1.0, 1.0]
Epoch :  146  Time:  1.288  Rel. Train L2 Loss :  0.05826219881574313  Rel. Test L2 Loss :  0.06112676590681076  Test L2 Loss :  0.08826303660869599  inv_L_scale:  [1.0, 1.0]
Epoch :  147  Time:  1.28  Rel. Train L2 Loss :  0.05813552733924654  Rel. Test L2 Loss :  0.06289151787757874  Test L2 Loss :  0.09074733883142472  inv_L_scale:  [1.0, 1.0]
Epoch :  148  Time:  1.282  Rel. Train L2 Loss :  0.05860301618774732  Rel. Test L2 Loss :  0.06258192479610443  Test L2 Loss :  0.08997732698917389  inv_L_scale:  [1.0, 1.0]
Epoch :  149  Time:  1.289  Rel. Train L2 Loss :  0.05790908631351259  Rel. Test L2 Loss :  0.06061980798840523  Test L2 Loss :  0.08727195650339127  inv_L_scale:  [1.0, 1.0]
Epoch :  150  Time:  1.287  Rel. Train L2 Loss :  0.057811400691668194  Rel. Test L2 Loss :  0.05925063043832779  Test L2 Loss :  0.08533722639083863  inv_L_scale:  [1.0, 1.0]
Epoch :  151  Time:  1.287  Rel. Train L2 Loss :  0.05740973432858785  Rel. Test L2 Loss :  0.05947679489850998  Test L2 Loss :  0.08596709191799164  inv_L_scale:  [1.0, 1.0]
Epoch :  152  Time:  1.286  Rel. Train L2 Loss :  0.057729463477929434  Rel. Test L2 Loss :  0.05903907954692841  Test L2 Loss :  0.08507707178592681  inv_L_scale:  [1.0, 1.0]
Epoch :  153  Time:  1.282  Rel. Train L2 Loss :  0.05700960351361169  Rel. Test L2 Loss :  0.05916069969534874  Test L2 Loss :  0.08550419509410859  inv_L_scale:  [1.0, 1.0]
Epoch :  154  Time:  1.288  Rel. Train L2 Loss :  0.05663530904385779  Rel. Test L2 Loss :  0.061825922429561614  Test L2 Loss :  0.08899815797805787  inv_L_scale:  [1.0, 1.0]
Epoch :  155  Time:  1.283  Rel. Train L2 Loss :  0.056980003052287634  Rel. Test L2 Loss :  0.05977686911821365  Test L2 Loss :  0.08617862462997436  inv_L_scale:  [1.0, 1.0]
Epoch :  156  Time:  1.283  Rel. Train L2 Loss :  0.05732150534788767  Rel. Test L2 Loss :  0.06130734235048294  Test L2 Loss :  0.08873156666755676  inv_L_scale:  [1.0, 1.0]
Epoch :  157  Time:  1.286  Rel. Train L2 Loss :  0.05728824737999174  Rel. Test L2 Loss :  0.05808961361646652  Test L2 Loss :  0.08397100925445557  inv_L_scale:  [1.0, 1.0]
Epoch :  158  Time:  1.288  Rel. Train L2 Loss :  0.057010660933123694  Rel. Test L2 Loss :  0.06000027373433113  Test L2 Loss :  0.08654934883117676  inv_L_scale:  [1.0, 1.0]
Epoch :  159  Time:  1.283  Rel. Train L2 Loss :  0.05743494381507238  Rel. Test L2 Loss :  0.059683701246976854  Test L2 Loss :  0.08633226692676545  inv_L_scale:  [1.0, 1.0]
Epoch :  160  Time:  1.285  Rel. Train L2 Loss :  0.05705627136760288  Rel. Test L2 Loss :  0.061975110173225406  Test L2 Loss :  0.08909226417541503  inv_L_scale:  [1.0, 1.0]
Epoch :  161  Time:  1.285  Rel. Train L2 Loss :  0.05701877024438646  Rel. Test L2 Loss :  0.059473564624786375  Test L2 Loss :  0.0853421425819397  inv_L_scale:  [1.0, 1.0]
Epoch :  162  Time:  1.284  Rel. Train L2 Loss :  0.05661390147275395  Rel. Test L2 Loss :  0.05830262288451195  Test L2 Loss :  0.08400236904621124  inv_L_scale:  [1.0, 1.0]
Epoch :  163  Time:  1.282  Rel. Train L2 Loss :  0.05627051467696826  Rel. Test L2 Loss :  0.058016300350427624  Test L2 Loss :  0.08371664524078369  inv_L_scale:  [1.0, 1.0]
Epoch :  164  Time:  1.284  Rel. Train L2 Loss :  0.05607147014803356  Rel. Test L2 Loss :  0.057977856397628785  Test L2 Loss :  0.08376987129449845  inv_L_scale:  [1.0, 1.0]
Epoch :  165  Time:  1.281  Rel. Train L2 Loss :  0.05654659368925624  Rel. Test L2 Loss :  0.05819361567497253  Test L2 Loss :  0.08403112769126891  inv_L_scale:  [1.0, 1.0]
Epoch :  166  Time:  1.282  Rel. Train L2 Loss :  0.05778803679678175  Rel. Test L2 Loss :  0.05827491208910942  Test L2 Loss :  0.0840711098909378  inv_L_scale:  [1.0, 1.0]
Epoch :  167  Time:  1.286  Rel. Train L2 Loss :  0.056263436211480035  Rel. Test L2 Loss :  0.05868867456912994  Test L2 Loss :  0.08456129133701325  inv_L_scale:  [1.0, 1.0]
Epoch :  168  Time:  1.281  Rel. Train L2 Loss :  0.05640617597434256  Rel. Test L2 Loss :  0.059194409251213075  Test L2 Loss :  0.08523441433906555  inv_L_scale:  [1.0, 1.0]
Epoch :  169  Time:  1.291  Rel. Train L2 Loss :  0.056656402978632184  Rel. Test L2 Loss :  0.05727912649512291  Test L2 Loss :  0.08261676400899887  inv_L_scale:  [1.0, 1.0]
Epoch :  170  Time:  1.283  Rel. Train L2 Loss :  0.055974081820911833  Rel. Test L2 Loss :  0.057549057602882384  Test L2 Loss :  0.08336883425712585  inv_L_scale:  [1.0, 1.0]
Epoch :  171  Time:  1.282  Rel. Train L2 Loss :  0.05764191018210517  Rel. Test L2 Loss :  0.058400152921676635  Test L2 Loss :  0.08432657212018967  inv_L_scale:  [1.0, 1.0]
Epoch :  172  Time:  1.278  Rel. Train L2 Loss :  0.05627142310142517  Rel. Test L2 Loss :  0.05907229244709015  Test L2 Loss :  0.085702902674675  inv_L_scale:  [1.0, 1.0]
Epoch :  173  Time:  1.285  Rel. Train L2 Loss :  0.05581700089904997  Rel. Test L2 Loss :  0.057577456682920455  Test L2 Loss :  0.08287619531154633  inv_L_scale:  [1.0, 1.0]
Epoch :  174  Time:  1.279  Rel. Train L2 Loss :  0.05567878304256333  Rel. Test L2 Loss :  0.05887676522135735  Test L2 Loss :  0.08481364399194717  inv_L_scale:  [1.0, 1.0]
Epoch :  175  Time:  1.28  Rel. Train L2 Loss :  0.055831219454606375  Rel. Test L2 Loss :  0.058189902007579807  Test L2 Loss :  0.08392999291419984  inv_L_scale:  [1.0, 1.0]
Epoch :  176  Time:  1.287  Rel. Train L2 Loss :  0.05514124612013499  Rel. Test L2 Loss :  0.05742537721991539  Test L2 Loss :  0.08253860443830491  inv_L_scale:  [1.0, 1.0]
Epoch :  177  Time:  1.293  Rel. Train L2 Loss :  0.05525741837090916  Rel. Test L2 Loss :  0.05871233582496643  Test L2 Loss :  0.08454119741916656  inv_L_scale:  [1.0, 1.0]
Epoch :  178  Time:  1.278  Rel. Train L2 Loss :  0.05588292433155907  Rel. Test L2 Loss :  0.05781390219926834  Test L2 Loss :  0.08340981483459473  inv_L_scale:  [1.0, 1.0]
Epoch :  179  Time:  1.299  Rel. Train L2 Loss :  0.05602714171012243  Rel. Test L2 Loss :  0.05955635920166969  Test L2 Loss :  0.0860548061132431  inv_L_scale:  [1.0, 1.0]
Epoch :  180  Time:  1.285  Rel. Train L2 Loss :  0.056248710536294516  Rel. Test L2 Loss :  0.06122989058494568  Test L2 Loss :  0.08825775623321533  inv_L_scale:  [1.0, 1.0]
Epoch :  181  Time:  1.288  Rel. Train L2 Loss :  0.05618882687555419  Rel. Test L2 Loss :  0.059159433990716936  Test L2 Loss :  0.08503871828317643  inv_L_scale:  [1.0, 1.0]
Epoch :  182  Time:  1.284  Rel. Train L2 Loss :  0.05612190306186676  Rel. Test L2 Loss :  0.05868314266204834  Test L2 Loss :  0.08465652525424958  inv_L_scale:  [1.0, 1.0]
Epoch :  183  Time:  1.282  Rel. Train L2 Loss :  0.055583174328009285  Rel. Test L2 Loss :  0.06034630954265594  Test L2 Loss :  0.08713686555624008  inv_L_scale:  [1.0, 1.0]
Epoch :  184  Time:  1.278  Rel. Train L2 Loss :  0.05496625887023078  Rel. Test L2 Loss :  0.056522231996059415  Test L2 Loss :  0.0816895878314972  inv_L_scale:  [1.0, 1.0]
Epoch :  185  Time:  1.283  Rel. Train L2 Loss :  0.05482328136761983  Rel. Test L2 Loss :  0.0579252715408802  Test L2 Loss :  0.08348266959190369  inv_L_scale:  [1.0, 1.0]
Epoch :  186  Time:  1.281  Rel. Train L2 Loss :  0.05513356036610074  Rel. Test L2 Loss :  0.05618522688746452  Test L2 Loss :  0.0808270126581192  inv_L_scale:  [1.0, 1.0]
Epoch :  187  Time:  1.284  Rel. Train L2 Loss :  0.05512125826544232  Rel. Test L2 Loss :  0.0569924658536911  Test L2 Loss :  0.08215052545070649  inv_L_scale:  [1.0, 1.0]
Epoch :  188  Time:  1.278  Rel. Train L2 Loss :  0.053890481028291914  Rel. Test L2 Loss :  0.05604525104165077  Test L2 Loss :  0.08075767964124679  inv_L_scale:  [1.0, 1.0]
Epoch :  189  Time:  1.279  Rel. Train L2 Loss :  0.05370872560474608  Rel. Test L2 Loss :  0.05721124291419983  Test L2 Loss :  0.08253419071435929  inv_L_scale:  [1.0, 1.0]
Epoch :  190  Time:  1.281  Rel. Train L2 Loss :  0.05381534477074941  Rel. Test L2 Loss :  0.057507531344890596  Test L2 Loss :  0.08293540745973588  inv_L_scale:  [1.0, 1.0]
Epoch :  191  Time:  1.281  Rel. Train L2 Loss :  0.054207326504919266  Rel. Test L2 Loss :  0.057047759741544725  Test L2 Loss :  0.0824097764492035  inv_L_scale:  [1.0, 1.0]
Epoch :  192  Time:  1.274  Rel. Train L2 Loss :  0.053567055761814114  Rel. Test L2 Loss :  0.05869383931159973  Test L2 Loss :  0.08493933260440827  inv_L_scale:  [1.0, 1.0]
Epoch :  193  Time:  1.278  Rel. Train L2 Loss :  0.054568674630588954  Rel. Test L2 Loss :  0.05763860240578651  Test L2 Loss :  0.08306005328893662  inv_L_scale:  [1.0, 1.0]
Epoch :  194  Time:  1.275  Rel. Train L2 Loss :  0.05419969651434157  Rel. Test L2 Loss :  0.05660701870918274  Test L2 Loss :  0.08171341896057129  inv_L_scale:  [1.0, 1.0]
Epoch :  195  Time:  1.278  Rel. Train L2 Loss :  0.05356757561365763  Rel. Test L2 Loss :  0.055849260538816455  Test L2 Loss :  0.08071413159370422  inv_L_scale:  [1.0, 1.0]
Epoch :  196  Time:  1.278  Rel. Train L2 Loss :  0.05346730493836933  Rel. Test L2 Loss :  0.05480643078684807  Test L2 Loss :  0.07898024439811707  inv_L_scale:  [1.0, 1.0]
Epoch :  197  Time:  1.285  Rel. Train L2 Loss :  0.053148555275466705  Rel. Test L2 Loss :  0.05579078733921051  Test L2 Loss :  0.08068872600793839  inv_L_scale:  [1.0, 1.0]
Epoch :  198  Time:  1.276  Rel. Train L2 Loss :  0.05284046452906397  Rel. Test L2 Loss :  0.05463404953479767  Test L2 Loss :  0.07890418887138367  inv_L_scale:  [1.0, 1.0]
Epoch :  199  Time:  1.279  Rel. Train L2 Loss :  0.05260425213310454  Rel. Test L2 Loss :  0.05425903469324112  Test L2 Loss :  0.07821441799402237  inv_L_scale:  [1.0, 1.0]
Epoch :  200  Time:  1.28  Rel. Train L2 Loss :  0.052794630461268956  Rel. Test L2 Loss :  0.055728670358657834  Test L2 Loss :  0.08023717314004898  inv_L_scale:  [1.0, 1.0]
Epoch :  201  Time:  1.276  Rel. Train L2 Loss :  0.05230601108736462  Rel. Test L2 Loss :  0.05484924510121345  Test L2 Loss :  0.07901557981967926  inv_L_scale:  [1.0, 1.0]
Epoch :  202  Time:  1.282  Rel. Train L2 Loss :  0.0524512752228313  Rel. Test L2 Loss :  0.0551123046875  Test L2 Loss :  0.07962257534265518  inv_L_scale:  [1.0, 1.0]
Epoch :  203  Time:  1.278  Rel. Train L2 Loss :  0.05221313446760178  Rel. Test L2 Loss :  0.055668226182460784  Test L2 Loss :  0.0802479463815689  inv_L_scale:  [1.0, 1.0]
Epoch :  204  Time:  1.282  Rel. Train L2 Loss :  0.05329132318496704  Rel. Test L2 Loss :  0.05927725031971932  Test L2 Loss :  0.08488020718097687  inv_L_scale:  [1.0, 1.0]
Epoch :  205  Time:  1.28  Rel. Train L2 Loss :  0.053503434740834764  Rel. Test L2 Loss :  0.055741802752017976  Test L2 Loss :  0.08069395273923874  inv_L_scale:  [1.0, 1.0]
Epoch :  206  Time:  1.28  Rel. Train L2 Loss :  0.052475569049517314  Rel. Test L2 Loss :  0.056880334913730624  Test L2 Loss :  0.0821717619895935  inv_L_scale:  [1.0, 1.0]
Epoch :  207  Time:  1.275  Rel. Train L2 Loss :  0.05304399076435301  Rel. Test L2 Loss :  0.056781722456216814  Test L2 Loss :  0.08182621151208877  inv_L_scale:  [1.0, 1.0]
Epoch :  208  Time:  1.287  Rel. Train L2 Loss :  0.05233816044198142  Rel. Test L2 Loss :  0.05479481786489487  Test L2 Loss :  0.07913812220096589  inv_L_scale:  [1.0, 1.0]
Epoch :  209  Time:  1.279  Rel. Train L2 Loss :  0.05270821193854014  Rel. Test L2 Loss :  0.05642849922180176  Test L2 Loss :  0.08152170956134797  inv_L_scale:  [1.0, 1.0]
Epoch :  210  Time:  1.279  Rel. Train L2 Loss :  0.053635230892234376  Rel. Test L2 Loss :  0.05517088949680329  Test L2 Loss :  0.07961119323968888  inv_L_scale:  [1.0, 1.0]
Epoch :  211  Time:  1.278  Rel. Train L2 Loss :  0.05254947943819894  Rel. Test L2 Loss :  0.055173829197883606  Test L2 Loss :  0.07953124612569809  inv_L_scale:  [1.0, 1.0]
Epoch :  212  Time:  1.278  Rel. Train L2 Loss :  0.051749083995819095  Rel. Test L2 Loss :  0.05455931380391121  Test L2 Loss :  0.07859251916408538  inv_L_scale:  [1.0, 1.0]
Epoch :  213  Time:  1.273  Rel. Train L2 Loss :  0.05197780430316925  Rel. Test L2 Loss :  0.05470439463853836  Test L2 Loss :  0.07901513814926148  inv_L_scale:  [1.0, 1.0]
Epoch :  214  Time:  1.276  Rel. Train L2 Loss :  0.052398178825775785  Rel. Test L2 Loss :  0.054933411478996275  Test L2 Loss :  0.07922500640153884  inv_L_scale:  [1.0, 1.0]
Epoch :  215  Time:  1.275  Rel. Train L2 Loss :  0.052456590947177674  Rel. Test L2 Loss :  0.057548089027404783  Test L2 Loss :  0.08292971551418304  inv_L_scale:  [1.0, 1.0]
Epoch :  216  Time:  1.276  Rel. Train L2 Loss :  0.05248873730500539  Rel. Test L2 Loss :  0.05598459333181381  Test L2 Loss :  0.08051066160202026  inv_L_scale:  [1.0, 1.0]
Epoch :  217  Time:  1.283  Rel. Train L2 Loss :  0.05208943376938502  Rel. Test L2 Loss :  0.05483022689819336  Test L2 Loss :  0.07911812126636505  inv_L_scale:  [1.0, 1.0]
Epoch :  218  Time:  1.276  Rel. Train L2 Loss :  0.05202331327729755  Rel. Test L2 Loss :  0.056296052783727644  Test L2 Loss :  0.08101102173328399  inv_L_scale:  [1.0, 1.0]
Epoch :  219  Time:  1.278  Rel. Train L2 Loss :  0.052507454322444067  Rel. Test L2 Loss :  0.0535296967625618  Test L2 Loss :  0.0771843621134758  inv_L_scale:  [1.0, 1.0]
Epoch :  220  Time:  1.277  Rel. Train L2 Loss :  0.051947035756376055  Rel. Test L2 Loss :  0.054582113921642306  Test L2 Loss :  0.07879156947135925  inv_L_scale:  [1.0, 1.0]
Epoch :  221  Time:  1.279  Rel. Train L2 Loss :  0.0511971092555258  Rel. Test L2 Loss :  0.0544718724489212  Test L2 Loss :  0.07856577813625336  inv_L_scale:  [1.0, 1.0]
Epoch :  222  Time:  1.277  Rel. Train L2 Loss :  0.05127741906378004  Rel. Test L2 Loss :  0.05401068657636642  Test L2 Loss :  0.07802651971578597  inv_L_scale:  [1.0, 1.0]
Epoch :  223  Time:  1.279  Rel. Train L2 Loss :  0.05158729652563731  Rel. Test L2 Loss :  0.054352557212114336  Test L2 Loss :  0.07866658866405488  inv_L_scale:  [1.0, 1.0]
Epoch :  224  Time:  1.278  Rel. Train L2 Loss :  0.051151037712891895  Rel. Test L2 Loss :  0.054137690663337706  Test L2 Loss :  0.07823430776596069  inv_L_scale:  [1.0, 1.0]
Epoch :  225  Time:  1.276  Rel. Train L2 Loss :  0.05141613082753287  Rel. Test L2 Loss :  0.05416843861341476  Test L2 Loss :  0.0782514527440071  inv_L_scale:  [1.0, 1.0]
Epoch :  226  Time:  1.282  Rel. Train L2 Loss :  0.05071142335732778  Rel. Test L2 Loss :  0.05436716079711914  Test L2 Loss :  0.07848527312278747  inv_L_scale:  [1.0, 1.0]
Epoch :  227  Time:  1.276  Rel. Train L2 Loss :  0.05149175390601158  Rel. Test L2 Loss :  0.05332442715764046  Test L2 Loss :  0.0770225813984871  inv_L_scale:  [1.0, 1.0]
Epoch :  228  Time:  1.283  Rel. Train L2 Loss :  0.051058362358146245  Rel. Test L2 Loss :  0.05410519391298294  Test L2 Loss :  0.07815380781888961  inv_L_scale:  [1.0, 1.0]
Epoch :  229  Time:  1.282  Rel. Train L2 Loss :  0.050941454933749304  Rel. Test L2 Loss :  0.053540004193782804  Test L2 Loss :  0.07714314550161362  inv_L_scale:  [1.0, 1.0]
Epoch :  230  Time:  1.285  Rel. Train L2 Loss :  0.05062688873873816  Rel. Test L2 Loss :  0.052281182110309604  Test L2 Loss :  0.0755191546678543  inv_L_scale:  [1.0, 1.0]
Epoch :  231  Time:  1.3  Rel. Train L2 Loss :  0.05021210844318072  Rel. Test L2 Loss :  0.054063207358121874  Test L2 Loss :  0.07819234520196915  inv_L_scale:  [1.0, 1.0]
Epoch :  232  Time:  1.308  Rel. Train L2 Loss :  0.05012589184774293  Rel. Test L2 Loss :  0.05297801613807678  Test L2 Loss :  0.07653881669044495  inv_L_scale:  [1.0, 1.0]
Epoch :  233  Time:  1.339  Rel. Train L2 Loss :  0.0507582539319992  Rel. Test L2 Loss :  0.0535247951745987  Test L2 Loss :  0.07735459774732589  inv_L_scale:  [1.0, 1.0]
Epoch :  234  Time:  1.293  Rel. Train L2 Loss :  0.050720374368959  Rel. Test L2 Loss :  0.053362539410591124  Test L2 Loss :  0.07701310753822327  inv_L_scale:  [1.0, 1.0]
Epoch :  235  Time:  1.304  Rel. Train L2 Loss :  0.050704629719257356  Rel. Test L2 Loss :  0.05355719104409218  Test L2 Loss :  0.07702911764383316  inv_L_scale:  [1.0, 1.0]
Epoch :  236  Time:  1.292  Rel. Train L2 Loss :  0.05078661648763551  Rel. Test L2 Loss :  0.053670896291732786  Test L2 Loss :  0.07735979110002518  inv_L_scale:  [1.0, 1.0]
Epoch :  237  Time:  1.286  Rel. Train L2 Loss :  0.050616147054566275  Rel. Test L2 Loss :  0.05273008301854134  Test L2 Loss :  0.07610100597143173  inv_L_scale:  [1.0, 1.0]
Epoch :  238  Time:  1.284  Rel. Train L2 Loss :  0.04986300157176124  Rel. Test L2 Loss :  0.05211407005786896  Test L2 Loss :  0.07523091942071915  inv_L_scale:  [1.0, 1.0]
Epoch :  239  Time:  1.289  Rel. Train L2 Loss :  0.05050056821770138  Rel. Test L2 Loss :  0.05332833305001259  Test L2 Loss :  0.076847502887249  inv_L_scale:  [1.0, 1.0]
Epoch :  240  Time:  1.287  Rel. Train L2 Loss :  0.05007102304034763  Rel. Test L2 Loss :  0.054293102622032165  Test L2 Loss :  0.07818980783224105  inv_L_scale:  [1.0, 1.0]
Epoch :  241  Time:  1.282  Rel. Train L2 Loss :  0.050275301784276964  Rel. Test L2 Loss :  0.05316490888595581  Test L2 Loss :  0.07646340817213058  inv_L_scale:  [1.0, 1.0]
Epoch :  242  Time:  1.29  Rel. Train L2 Loss :  0.050023743344677817  Rel. Test L2 Loss :  0.05237560823559761  Test L2 Loss :  0.07559595018625259  inv_L_scale:  [1.0, 1.0]
Epoch :  243  Time:  1.284  Rel. Train L2 Loss :  0.04987194624212053  Rel. Test L2 Loss :  0.052645761519670486  Test L2 Loss :  0.07607124775648116  inv_L_scale:  [1.0, 1.0]
Epoch :  244  Time:  1.284  Rel. Train L2 Loss :  0.04983724080853992  Rel. Test L2 Loss :  0.052214232981204985  Test L2 Loss :  0.07537331491708756  inv_L_scale:  [1.0, 1.0]
Epoch :  245  Time:  1.288  Rel. Train L2 Loss :  0.04954784563846058  Rel. Test L2 Loss :  0.05275436013936997  Test L2 Loss :  0.076270372569561  inv_L_scale:  [1.0, 1.0]
Epoch :  246  Time:  1.287  Rel. Train L2 Loss :  0.04942068699333403  Rel. Test L2 Loss :  0.05233864963054657  Test L2 Loss :  0.07545923739671707  inv_L_scale:  [1.0, 1.0]
Epoch :  247  Time:  1.294  Rel. Train L2 Loss :  0.049548245850536556  Rel. Test L2 Loss :  0.05429442137479782  Test L2 Loss :  0.07807122319936752  inv_L_scale:  [1.0, 1.0]
Epoch :  248  Time:  1.289  Rel. Train L2 Loss :  0.049471041510502495  Rel. Test L2 Loss :  0.0523931722342968  Test L2 Loss :  0.07568314492702484  inv_L_scale:  [1.0, 1.0]
Epoch :  249  Time:  1.282  Rel. Train L2 Loss :  0.0502807793352339  Rel. Test L2 Loss :  0.05294317245483399  Test L2 Loss :  0.07647706389427185  inv_L_scale:  [1.0, 1.0]
Epoch :  250  Time:  1.285  Rel. Train L2 Loss :  0.049835568534003366  Rel. Test L2 Loss :  0.052346739917993546  Test L2 Loss :  0.07554944157600403  inv_L_scale:  [1.0, 1.0]
Epoch :  251  Time:  1.283  Rel. Train L2 Loss :  0.049437331292364335  Rel. Test L2 Loss :  0.05192809268832207  Test L2 Loss :  0.07482955753803253  inv_L_scale:  [1.0, 1.0]
Epoch :  252  Time:  1.293  Rel. Train L2 Loss :  0.049199271847804385  Rel. Test L2 Loss :  0.05232570171356201  Test L2 Loss :  0.07545094847679139  inv_L_scale:  [1.0, 1.0]
Epoch :  253  Time:  1.281  Rel. Train L2 Loss :  0.0494805645942688  Rel. Test L2 Loss :  0.05290287733078003  Test L2 Loss :  0.07613589763641357  inv_L_scale:  [1.0, 1.0]
Epoch :  254  Time:  1.283  Rel. Train L2 Loss :  0.04971179616120126  Rel. Test L2 Loss :  0.052512547373771666  Test L2 Loss :  0.07572355091571809  inv_L_scale:  [1.0, 1.0]
Epoch :  255  Time:  1.287  Rel. Train L2 Loss :  0.04959691050979826  Rel. Test L2 Loss :  0.05324090972542763  Test L2 Loss :  0.07655381202697754  inv_L_scale:  [1.0, 1.0]
Epoch :  256  Time:  1.29  Rel. Train L2 Loss :  0.04946977239516046  Rel. Test L2 Loss :  0.052391370683908464  Test L2 Loss :  0.075545075237751  inv_L_scale:  [1.0, 1.0]
Epoch :  257  Time:  1.285  Rel. Train L2 Loss :  0.050013747248384685  Rel. Test L2 Loss :  0.053906536847352984  Test L2 Loss :  0.07795056134462357  inv_L_scale:  [1.0, 1.0]
Epoch :  258  Time:  1.284  Rel. Train L2 Loss :  0.049157821635405226  Rel. Test L2 Loss :  0.05216732382774353  Test L2 Loss :  0.07531398802995681  inv_L_scale:  [1.0, 1.0]
Epoch :  259  Time:  1.288  Rel. Train L2 Loss :  0.04908494553632206  Rel. Test L2 Loss :  0.0523785637319088  Test L2 Loss :  0.07547328799962998  inv_L_scale:  [1.0, 1.0]
Epoch :  260  Time:  1.294  Rel. Train L2 Loss :  0.04895660762985547  Rel. Test L2 Loss :  0.051885395646095275  Test L2 Loss :  0.0749891909956932  inv_L_scale:  [1.0, 1.0]
Epoch :  261  Time:  1.286  Rel. Train L2 Loss :  0.04910511453946431  Rel. Test L2 Loss :  0.05170492440462113  Test L2 Loss :  0.07455399483442307  inv_L_scale:  [1.0, 1.0]
Epoch :  262  Time:  1.289  Rel. Train L2 Loss :  0.0487393227716287  Rel. Test L2 Loss :  0.05186422049999237  Test L2 Loss :  0.07478666156530381  inv_L_scale:  [1.0, 1.0]
Epoch :  263  Time:  1.29  Rel. Train L2 Loss :  0.04858826317720943  Rel. Test L2 Loss :  0.05260741755366325  Test L2 Loss :  0.07586777329444885  inv_L_scale:  [1.0, 1.0]
Epoch :  264  Time:  1.284  Rel. Train L2 Loss :  0.0484370818734169  Rel. Test L2 Loss :  0.051560911238193514  Test L2 Loss :  0.0745516586303711  inv_L_scale:  [1.0, 1.0]
Epoch :  265  Time:  1.286  Rel. Train L2 Loss :  0.049156750324699613  Rel. Test L2 Loss :  0.051897499859333035  Test L2 Loss :  0.07484066337347031  inv_L_scale:  [1.0, 1.0]
Epoch :  266  Time:  1.293  Rel. Train L2 Loss :  0.048641468203730054  Rel. Test L2 Loss :  0.051560818552970886  Test L2 Loss :  0.07454858928918838  inv_L_scale:  [1.0, 1.0]
Epoch :  267  Time:  1.29  Rel. Train L2 Loss :  0.04849270741144816  Rel. Test L2 Loss :  0.05300506114959717  Test L2 Loss :  0.07640415161848069  inv_L_scale:  [1.0, 1.0]
Epoch :  268  Time:  1.292  Rel. Train L2 Loss :  0.04885719080766042  Rel. Test L2 Loss :  0.05143157333135605  Test L2 Loss :  0.07424691379070282  inv_L_scale:  [1.0, 1.0]
Epoch :  269  Time:  1.29  Rel. Train L2 Loss :  0.04822543140914705  Rel. Test L2 Loss :  0.05126055777072906  Test L2 Loss :  0.07394574940204621  inv_L_scale:  [1.0, 1.0]
Epoch :  270  Time:  1.29  Rel. Train L2 Loss :  0.048053180442916024  Rel. Test L2 Loss :  0.051577783823013305  Test L2 Loss :  0.07451512545347214  inv_L_scale:  [1.0, 1.0]
Epoch :  271  Time:  1.283  Rel. Train L2 Loss :  0.04807220935821533  Rel. Test L2 Loss :  0.051573540270328525  Test L2 Loss :  0.07448033481836319  inv_L_scale:  [1.0, 1.0]
Epoch :  272  Time:  1.287  Rel. Train L2 Loss :  0.04903965151972241  Rel. Test L2 Loss :  0.05179244458675385  Test L2 Loss :  0.07481750965118408  inv_L_scale:  [1.0, 1.0]
Epoch :  273  Time:  1.287  Rel. Train L2 Loss :  0.04880409800344043  Rel. Test L2 Loss :  0.052080816626548766  Test L2 Loss :  0.07525078654289245  inv_L_scale:  [1.0, 1.0]
Epoch :  274  Time:  1.28  Rel. Train L2 Loss :  0.0488326613439454  Rel. Test L2 Loss :  0.05193120002746582  Test L2 Loss :  0.0751134330034256  inv_L_scale:  [1.0, 1.0]
Epoch :  275  Time:  1.287  Rel. Train L2 Loss :  0.04815999946660466  Rel. Test L2 Loss :  0.05049269005656242  Test L2 Loss :  0.07293968558311463  inv_L_scale:  [1.0, 1.0]
Epoch :  276  Time:  1.282  Rel. Train L2 Loss :  0.04799298543069098  Rel. Test L2 Loss :  0.051982635408639906  Test L2 Loss :  0.07494704246520996  inv_L_scale:  [1.0, 1.0]
Epoch :  277  Time:  1.287  Rel. Train L2 Loss :  0.04792540109819836  Rel. Test L2 Loss :  0.051081071346998214  Test L2 Loss :  0.07364994466304779  inv_L_scale:  [1.0, 1.0]
Epoch :  278  Time:  1.277  Rel. Train L2 Loss :  0.04771412847770585  Rel. Test L2 Loss :  0.050354877412319185  Test L2 Loss :  0.07282660067081452  inv_L_scale:  [1.0, 1.0]
Epoch :  279  Time:  1.282  Rel. Train L2 Loss :  0.04757586553692818  Rel. Test L2 Loss :  0.05084006905555725  Test L2 Loss :  0.07345556288957596  inv_L_scale:  [1.0, 1.0]
Epoch :  280  Time:  1.287  Rel. Train L2 Loss :  0.0477528775897291  Rel. Test L2 Loss :  0.0512287825345993  Test L2 Loss :  0.07387084275484085  inv_L_scale:  [1.0, 1.0]
Epoch :  281  Time:  1.285  Rel. Train L2 Loss :  0.04772884670231078  Rel. Test L2 Loss :  0.05088617756962776  Test L2 Loss :  0.07343561559915543  inv_L_scale:  [1.0, 1.0]
Epoch :  282  Time:  1.286  Rel. Train L2 Loss :  0.04773791816499498  Rel. Test L2 Loss :  0.05222676426172256  Test L2 Loss :  0.07519648373126983  inv_L_scale:  [1.0, 1.0]
Epoch :  283  Time:  1.283  Rel. Train L2 Loss :  0.04834100109007623  Rel. Test L2 Loss :  0.0514071649312973  Test L2 Loss :  0.07434791803359986  inv_L_scale:  [1.0, 1.0]
Epoch :  284  Time:  1.282  Rel. Train L2 Loss :  0.04802367064687941  Rel. Test L2 Loss :  0.05126417919993401  Test L2 Loss :  0.07404311537742615  inv_L_scale:  [1.0, 1.0]
Epoch :  285  Time:  1.286  Rel. Train L2 Loss :  0.047603760030534535  Rel. Test L2 Loss :  0.050865228772163394  Test L2 Loss :  0.07329003065824509  inv_L_scale:  [1.0, 1.0]
Epoch :  286  Time:  1.284  Rel. Train L2 Loss :  0.047682651860846414  Rel. Test L2 Loss :  0.051401395946741105  Test L2 Loss :  0.07416960299015045  inv_L_scale:  [1.0, 1.0]
Epoch :  287  Time:  1.285  Rel. Train L2 Loss :  0.04765905711385939  Rel. Test L2 Loss :  0.05153325021266937  Test L2 Loss :  0.07443501055240631  inv_L_scale:  [1.0, 1.0]
Epoch :  288  Time:  1.284  Rel. Train L2 Loss :  0.04758135288953781  Rel. Test L2 Loss :  0.05142566740512848  Test L2 Loss :  0.0741232430934906  inv_L_scale:  [1.0, 1.0]
Epoch :  289  Time:  1.291  Rel. Train L2 Loss :  0.04746481658683883  Rel. Test L2 Loss :  0.05258460074663162  Test L2 Loss :  0.07599386617541314  inv_L_scale:  [1.0, 1.0]
Epoch :  290  Time:  1.287  Rel. Train L2 Loss :  0.04726249312361081  Rel. Test L2 Loss :  0.05046594351530075  Test L2 Loss :  0.07285614788532258  inv_L_scale:  [1.0, 1.0]
Epoch :  291  Time:  1.286  Rel. Train L2 Loss :  0.04701926632059945  Rel. Test L2 Loss :  0.05131945759057999  Test L2 Loss :  0.07409044325351716  inv_L_scale:  [1.0, 1.0]
Epoch :  292  Time:  1.287  Rel. Train L2 Loss :  0.047729629344410364  Rel. Test L2 Loss :  0.05143900007009506  Test L2 Loss :  0.07428756207227707  inv_L_scale:  [1.0, 1.0]
Epoch :  293  Time:  1.284  Rel. Train L2 Loss :  0.047396140843629836  Rel. Test L2 Loss :  0.0509031480550766  Test L2 Loss :  0.07343446135520935  inv_L_scale:  [1.0, 1.0]
Epoch :  294  Time:  1.281  Rel. Train L2 Loss :  0.04739996913406584  Rel. Test L2 Loss :  0.05185807943344116  Test L2 Loss :  0.07484257280826569  inv_L_scale:  [1.0, 1.0]
Epoch :  295  Time:  1.282  Rel. Train L2 Loss :  0.04718904559810956  Rel. Test L2 Loss :  0.05075480923056602  Test L2 Loss :  0.07335137516260147  inv_L_scale:  [1.0, 1.0]
Epoch :  296  Time:  1.284  Rel. Train L2 Loss :  0.046911250882678564  Rel. Test L2 Loss :  0.051169976592063904  Test L2 Loss :  0.07385076358914375  inv_L_scale:  [1.0, 1.0]
Epoch :  297  Time:  1.287  Rel. Train L2 Loss :  0.04675651437706418  Rel. Test L2 Loss :  0.050054052025079725  Test L2 Loss :  0.07226129412651063  inv_L_scale:  [1.0, 1.0]
Epoch :  298  Time:  1.289  Rel. Train L2 Loss :  0.04724964319003953  Rel. Test L2 Loss :  0.05078264713287353  Test L2 Loss :  0.07341673612594604  inv_L_scale:  [1.0, 1.0]
Epoch :  299  Time:  1.289  Rel. Train L2 Loss :  0.047006553179687924  Rel. Test L2 Loss :  0.05070829257369042  Test L2 Loss :  0.07338610172271728  inv_L_scale:  [1.0, 1.0]
Epoch :  300  Time:  1.282  Rel. Train L2 Loss :  0.046938946942488353  Rel. Test L2 Loss :  0.05102550983428955  Test L2 Loss :  0.07379016697406769  inv_L_scale:  [1.0, 1.0]
Epoch :  301  Time:  1.28  Rel. Train L2 Loss :  0.04668688868482908  Rel. Test L2 Loss :  0.04976118206977844  Test L2 Loss :  0.07185420110821723  inv_L_scale:  [1.0, 1.0]
Epoch :  302  Time:  1.284  Rel. Train L2 Loss :  0.046401915484004554  Rel. Test L2 Loss :  0.05043992817401886  Test L2 Loss :  0.07283552512526512  inv_L_scale:  [1.0, 1.0]
Epoch :  303  Time:  1.283  Rel. Train L2 Loss :  0.046388124351700144  Rel. Test L2 Loss :  0.050500936806201935  Test L2 Loss :  0.07290318012237548  inv_L_scale:  [1.0, 1.0]
Epoch :  304  Time:  1.28  Rel. Train L2 Loss :  0.04652714568707678  Rel. Test L2 Loss :  0.04988014087080955  Test L2 Loss :  0.0719963026046753  inv_L_scale:  [1.0, 1.0]
Epoch :  305  Time:  1.278  Rel. Train L2 Loss :  0.04627104186349445  Rel. Test L2 Loss :  0.05019727200269699  Test L2 Loss :  0.07254732519388199  inv_L_scale:  [1.0, 1.0]
Epoch :  306  Time:  1.282  Rel. Train L2 Loss :  0.04656419042083952  Rel. Test L2 Loss :  0.050877101868391034  Test L2 Loss :  0.07328717425465583  inv_L_scale:  [1.0, 1.0]
Epoch :  307  Time:  1.278  Rel. Train L2 Loss :  0.04643730574183994  Rel. Test L2 Loss :  0.05043536946177483  Test L2 Loss :  0.07273160010576248  inv_L_scale:  [1.0, 1.0]
Epoch :  308  Time:  1.279  Rel. Train L2 Loss :  0.046021016008324096  Rel. Test L2 Loss :  0.050369419157505035  Test L2 Loss :  0.07254978552460671  inv_L_scale:  [1.0, 1.0]
Epoch :  309  Time:  1.277  Rel. Train L2 Loss :  0.046361792998181446  Rel. Test L2 Loss :  0.049855653941631314  Test L2 Loss :  0.07194159120321274  inv_L_scale:  [1.0, 1.0]
Epoch :  310  Time:  1.278  Rel. Train L2 Loss :  0.04599814598759015  Rel. Test L2 Loss :  0.05052253395318985  Test L2 Loss :  0.0727563652396202  inv_L_scale:  [1.0, 1.0]
Epoch :  311  Time:  1.276  Rel. Train L2 Loss :  0.04588071506884363  Rel. Test L2 Loss :  0.0499581304192543  Test L2 Loss :  0.07206644281744957  inv_L_scale:  [1.0, 1.0]
Epoch :  312  Time:  1.28  Rel. Train L2 Loss :  0.045932765867975026  Rel. Test L2 Loss :  0.049781636595726014  Test L2 Loss :  0.07191226452589035  inv_L_scale:  [1.0, 1.0]
Epoch :  313  Time:  1.276  Rel. Train L2 Loss :  0.04580156733592351  Rel. Test L2 Loss :  0.049994545727968215  Test L2 Loss :  0.07219758123159409  inv_L_scale:  [1.0, 1.0]
Epoch :  314  Time:  1.273  Rel. Train L2 Loss :  0.04565681689315372  Rel. Test L2 Loss :  0.050421306490898134  Test L2 Loss :  0.07281781762838363  inv_L_scale:  [1.0, 1.0]
Epoch :  315  Time:  1.279  Rel. Train L2 Loss :  0.04575522973305649  Rel. Test L2 Loss :  0.04996797889471054  Test L2 Loss :  0.07227900639176368  inv_L_scale:  [1.0, 1.0]
Epoch :  316  Time:  1.275  Rel. Train L2 Loss :  0.04587290388014582  Rel. Test L2 Loss :  0.04990195497870445  Test L2 Loss :  0.07207822501659393  inv_L_scale:  [1.0, 1.0]
Epoch :  317  Time:  1.292  Rel. Train L2 Loss :  0.04607568300432629  Rel. Test L2 Loss :  0.049946946203708646  Test L2 Loss :  0.07223118275403977  inv_L_scale:  [1.0, 1.0]
Epoch :  318  Time:  1.29  Rel. Train L2 Loss :  0.04564555403259066  Rel. Test L2 Loss :  0.050147664248943326  Test L2 Loss :  0.072493876516819  inv_L_scale:  [1.0, 1.0]
Epoch :  319  Time:  1.28  Rel. Train L2 Loss :  0.04559079435136583  Rel. Test L2 Loss :  0.049283864796161654  Test L2 Loss :  0.0711830797791481  inv_L_scale:  [1.0, 1.0]
Epoch :  320  Time:  1.28  Rel. Train L2 Loss :  0.04569874266783396  Rel. Test L2 Loss :  0.0492742483317852  Test L2 Loss :  0.07121585339307784  inv_L_scale:  [1.0, 1.0]
Epoch :  321  Time:  1.275  Rel. Train L2 Loss :  0.045301640994018975  Rel. Test L2 Loss :  0.049555735886096956  Test L2 Loss :  0.07153493613004684  inv_L_scale:  [1.0, 1.0]
Epoch :  322  Time:  1.275  Rel. Train L2 Loss :  0.0458631684548325  Rel. Test L2 Loss :  0.050004105418920516  Test L2 Loss :  0.07226869314908982  inv_L_scale:  [1.0, 1.0]
Epoch :  323  Time:  1.279  Rel. Train L2 Loss :  0.04539678436186578  Rel. Test L2 Loss :  0.050673849284648895  Test L2 Loss :  0.07310215041041374  inv_L_scale:  [1.0, 1.0]
Epoch :  324  Time:  1.274  Rel. Train L2 Loss :  0.04568814294205772  Rel. Test L2 Loss :  0.05011913552880287  Test L2 Loss :  0.07216315925121307  inv_L_scale:  [1.0, 1.0]
Epoch :  325  Time:  1.278  Rel. Train L2 Loss :  0.0453744448059135  Rel. Test L2 Loss :  0.049117965698242186  Test L2 Loss :  0.07094824925065041  inv_L_scale:  [1.0, 1.0]
Epoch :  326  Time:  1.272  Rel. Train L2 Loss :  0.045074234414431785  Rel. Test L2 Loss :  0.04993478074669838  Test L2 Loss :  0.07203175008296966  inv_L_scale:  [1.0, 1.0]
Epoch :  327  Time:  1.302  Rel. Train L2 Loss :  0.04527057647705078  Rel. Test L2 Loss :  0.049446932077407836  Test L2 Loss :  0.07129183009266854  inv_L_scale:  [1.0, 1.0]
Epoch :  328  Time:  1.281  Rel. Train L2 Loss :  0.044912690818309786  Rel. Test L2 Loss :  0.04914785668253899  Test L2 Loss :  0.07102922543883324  inv_L_scale:  [1.0, 1.0]
Epoch :  329  Time:  1.28  Rel. Train L2 Loss :  0.045010364635123146  Rel. Test L2 Loss :  0.049324944019317626  Test L2 Loss :  0.07124694779515267  inv_L_scale:  [1.0, 1.0]
Epoch :  330  Time:  1.289  Rel. Train L2 Loss :  0.044944858021206326  Rel. Test L2 Loss :  0.04887968569993973  Test L2 Loss :  0.07067434534430504  inv_L_scale:  [1.0, 1.0]
Epoch :  331  Time:  1.278  Rel. Train L2 Loss :  0.04476229117976294  Rel. Test L2 Loss :  0.04869646042585373  Test L2 Loss :  0.07028629377484322  inv_L_scale:  [1.0, 1.0]
Epoch :  332  Time:  1.278  Rel. Train L2 Loss :  0.04488291629486614  Rel. Test L2 Loss :  0.04976200804114342  Test L2 Loss :  0.07189159244298934  inv_L_scale:  [1.0, 1.0]
Epoch :  333  Time:  1.28  Rel. Train L2 Loss :  0.04489177770084805  Rel. Test L2 Loss :  0.04900577515363693  Test L2 Loss :  0.07081937983632088  inv_L_scale:  [1.0, 1.0]
Epoch :  334  Time:  1.279  Rel. Train L2 Loss :  0.04455643742448754  Rel. Test L2 Loss :  0.0488234980404377  Test L2 Loss :  0.07047634482383729  inv_L_scale:  [1.0, 1.0]
Epoch :  335  Time:  1.281  Rel. Train L2 Loss :  0.04462182020147642  Rel. Test L2 Loss :  0.04932775318622589  Test L2 Loss :  0.0711708776652813  inv_L_scale:  [1.0, 1.0]
Epoch :  336  Time:  1.285  Rel. Train L2 Loss :  0.044512586891651156  Rel. Test L2 Loss :  0.04892587706446647  Test L2 Loss :  0.07068478614091873  inv_L_scale:  [1.0, 1.0]
Epoch :  337  Time:  1.281  Rel. Train L2 Loss :  0.04455334424972534  Rel. Test L2 Loss :  0.04862263485789299  Test L2 Loss :  0.07021799832582473  inv_L_scale:  [1.0, 1.0]
Epoch :  338  Time:  1.282  Rel. Train L2 Loss :  0.04430531632569101  Rel. Test L2 Loss :  0.04861284241080284  Test L2 Loss :  0.07029681220650673  inv_L_scale:  [1.0, 1.0]
Epoch :  339  Time:  1.284  Rel. Train L2 Loss :  0.04431546956300735  Rel. Test L2 Loss :  0.04827227234840393  Test L2 Loss :  0.06980973079800606  inv_L_scale:  [1.0, 1.0]
Epoch :  340  Time:  1.283  Rel. Train L2 Loss :  0.044287656678093805  Rel. Test L2 Loss :  0.048706560134887694  Test L2 Loss :  0.0702992981672287  inv_L_scale:  [1.0, 1.0]
Epoch :  341  Time:  1.285  Rel. Train L2 Loss :  0.044563786735137306  Rel. Test L2 Loss :  0.04915627390146256  Test L2 Loss :  0.07101300731301308  inv_L_scale:  [1.0, 1.0]
Epoch :  342  Time:  1.287  Rel. Train L2 Loss :  0.04449138801958826  Rel. Test L2 Loss :  0.04850452035665512  Test L2 Loss :  0.07005579203367233  inv_L_scale:  [1.0, 1.0]
Epoch :  343  Time:  1.29  Rel. Train L2 Loss :  0.044048668328258725  Rel. Test L2 Loss :  0.04894122034311295  Test L2 Loss :  0.07082132384181022  inv_L_scale:  [1.0, 1.0]
Epoch :  344  Time:  1.292  Rel. Train L2 Loss :  0.04412431783146328  Rel. Test L2 Loss :  0.04852248564362526  Test L2 Loss :  0.07012197315692902  inv_L_scale:  [1.0, 1.0]
Epoch :  345  Time:  1.285  Rel. Train L2 Loss :  0.044289283255736035  Rel. Test L2 Loss :  0.04848777085542679  Test L2 Loss :  0.07012745201587677  inv_L_scale:  [1.0, 1.0]
Epoch :  346  Time:  1.275  Rel. Train L2 Loss :  0.04397765970892376  Rel. Test L2 Loss :  0.04846707195043564  Test L2 Loss :  0.06997727155685425  inv_L_scale:  [1.0, 1.0]
Epoch :  347  Time:  1.276  Rel. Train L2 Loss :  0.04399065022667249  Rel. Test L2 Loss :  0.048689998388290405  Test L2 Loss :  0.07024625808000565  inv_L_scale:  [1.0, 1.0]
Epoch :  348  Time:  1.278  Rel. Train L2 Loss :  0.04396551999780867  Rel. Test L2 Loss :  0.04831582754850387  Test L2 Loss :  0.06989697709679604  inv_L_scale:  [1.0, 1.0]
Epoch :  349  Time:  1.281  Rel. Train L2 Loss :  0.04406814265582296  Rel. Test L2 Loss :  0.04832744807004929  Test L2 Loss :  0.06990612342953682  inv_L_scale:  [1.0, 1.0]
Epoch :  350  Time:  1.275  Rel. Train L2 Loss :  0.04387029657761256  Rel. Test L2 Loss :  0.048438385128974915  Test L2 Loss :  0.0700430479645729  inv_L_scale:  [1.0, 1.0]
Epoch :  351  Time:  1.279  Rel. Train L2 Loss :  0.0438597980969482  Rel. Test L2 Loss :  0.04835722029209137  Test L2 Loss :  0.06987245202064514  inv_L_scale:  [1.0, 1.0]
Epoch :  352  Time:  1.28  Rel. Train L2 Loss :  0.043641868829727176  Rel. Test L2 Loss :  0.04822017669677734  Test L2 Loss :  0.06968848377466202  inv_L_scale:  [1.0, 1.0]
Epoch :  353  Time:  1.279  Rel. Train L2 Loss :  0.0436160145037704  Rel. Test L2 Loss :  0.04845489382743835  Test L2 Loss :  0.07005758181214333  inv_L_scale:  [1.0, 1.0]
Epoch :  354  Time:  1.281  Rel. Train L2 Loss :  0.04363474435276456  Rel. Test L2 Loss :  0.048275483399629594  Test L2 Loss :  0.06967175304889679  inv_L_scale:  [1.0, 1.0]
Epoch :  355  Time:  1.28  Rel. Train L2 Loss :  0.043626328193479114  Rel. Test L2 Loss :  0.048199914395809174  Test L2 Loss :  0.06974097132682801  inv_L_scale:  [1.0, 1.0]
Epoch :  356  Time:  1.282  Rel. Train L2 Loss :  0.04353541900714238  Rel. Test L2 Loss :  0.048302430808544156  Test L2 Loss :  0.06974004328250885  inv_L_scale:  [1.0, 1.0]
Epoch :  357  Time:  1.28  Rel. Train L2 Loss :  0.04364354156785541  Rel. Test L2 Loss :  0.048115743100643156  Test L2 Loss :  0.06948078706860543  inv_L_scale:  [1.0, 1.0]
Epoch :  358  Time:  1.281  Rel. Train L2 Loss :  0.043432803551355995  Rel. Test L2 Loss :  0.04772232949733734  Test L2 Loss :  0.06898546695709229  inv_L_scale:  [1.0, 1.0]
Epoch :  359  Time:  1.284  Rel. Train L2 Loss :  0.04326516365011533  Rel. Test L2 Loss :  0.04796101465821266  Test L2 Loss :  0.06930259838700295  inv_L_scale:  [1.0, 1.0]
Epoch :  360  Time:  1.282  Rel. Train L2 Loss :  0.043492065784004  Rel. Test L2 Loss :  0.04828550159931183  Test L2 Loss :  0.06981492966413498  inv_L_scale:  [1.0, 1.0]
Epoch :  361  Time:  1.281  Rel. Train L2 Loss :  0.043551858398649425  Rel. Test L2 Loss :  0.04837013483047485  Test L2 Loss :  0.0697967278957367  inv_L_scale:  [1.0, 1.0]
Epoch :  362  Time:  1.282  Rel. Train L2 Loss :  0.04350325768192609  Rel. Test L2 Loss :  0.048254444748163226  Test L2 Loss :  0.06957858577370643  inv_L_scale:  [1.0, 1.0]
Epoch :  363  Time:  1.278  Rel. Train L2 Loss :  0.04342670847972234  Rel. Test L2 Loss :  0.048088140040636065  Test L2 Loss :  0.0694821485877037  inv_L_scale:  [1.0, 1.0]
Epoch :  364  Time:  1.282  Rel. Train L2 Loss :  0.04324440711074405  Rel. Test L2 Loss :  0.04801914095878601  Test L2 Loss :  0.06933110326528549  inv_L_scale:  [1.0, 1.0]
Epoch :  365  Time:  1.285  Rel. Train L2 Loss :  0.043122948805491126  Rel. Test L2 Loss :  0.04802660584449768  Test L2 Loss :  0.06941630765795707  inv_L_scale:  [1.0, 1.0]
Epoch :  366  Time:  1.279  Rel. Train L2 Loss :  0.043164800488286546  Rel. Test L2 Loss :  0.0478109821677208  Test L2 Loss :  0.0691438502073288  inv_L_scale:  [1.0, 1.0]
Epoch :  367  Time:  1.287  Rel. Train L2 Loss :  0.04320629469222493  Rel. Test L2 Loss :  0.04751452028751373  Test L2 Loss :  0.06871975556015969  inv_L_scale:  [1.0, 1.0]
Epoch :  368  Time:  1.282  Rel. Train L2 Loss :  0.043002246701055104  Rel. Test L2 Loss :  0.04797925069928169  Test L2 Loss :  0.06926975548267364  inv_L_scale:  [1.0, 1.0]
Epoch :  369  Time:  1.285  Rel. Train L2 Loss :  0.0430674932565954  Rel. Test L2 Loss :  0.04831267178058624  Test L2 Loss :  0.06978611350059509  inv_L_scale:  [1.0, 1.0]
Epoch :  370  Time:  1.288  Rel. Train L2 Loss :  0.043307825244135324  Rel. Test L2 Loss :  0.04795930400490761  Test L2 Loss :  0.06935398817062378  inv_L_scale:  [1.0, 1.0]
Epoch :  371  Time:  1.291  Rel. Train L2 Loss :  0.04288143810298708  Rel. Test L2 Loss :  0.04786408424377441  Test L2 Loss :  0.06920955762267113  inv_L_scale:  [1.0, 1.0]
Epoch :  372  Time:  1.285  Rel. Train L2 Loss :  0.042910608450571694  Rel. Test L2 Loss :  0.04762211471796036  Test L2 Loss :  0.06881454527378082  inv_L_scale:  [1.0, 1.0]
Epoch :  373  Time:  1.288  Rel. Train L2 Loss :  0.04269686445593834  Rel. Test L2 Loss :  0.047939195334911346  Test L2 Loss :  0.06926141142845153  inv_L_scale:  [1.0, 1.0]
Epoch :  374  Time:  1.28  Rel. Train L2 Loss :  0.04275634378194809  Rel. Test L2 Loss :  0.0477617047727108  Test L2 Loss :  0.06895220130681992  inv_L_scale:  [1.0, 1.0]
Epoch :  375  Time:  1.281  Rel. Train L2 Loss :  0.04275655801097552  Rel. Test L2 Loss :  0.04793552279472351  Test L2 Loss :  0.06926819607615471  inv_L_scale:  [1.0, 1.0]
Epoch :  376  Time:  1.284  Rel. Train L2 Loss :  0.042816112836201986  Rel. Test L2 Loss :  0.047616779804229736  Test L2 Loss :  0.06883126348257065  inv_L_scale:  [1.0, 1.0]
Epoch :  377  Time:  1.281  Rel. Train L2 Loss :  0.04269779779016972  Rel. Test L2 Loss :  0.047691737711429594  Test L2 Loss :  0.06887634307146072  inv_L_scale:  [1.0, 1.0]
Epoch :  378  Time:  1.28  Rel. Train L2 Loss :  0.04266977263821496  Rel. Test L2 Loss :  0.04772387385368347  Test L2 Loss :  0.06894896566867828  inv_L_scale:  [1.0, 1.0]
Epoch :  379  Time:  1.287  Rel. Train L2 Loss :  0.042599885645839906  Rel. Test L2 Loss :  0.04744892984628677  Test L2 Loss :  0.06859030470252037  inv_L_scale:  [1.0, 1.0]
Epoch :  380  Time:  1.293  Rel. Train L2 Loss :  0.042490321944157285  Rel. Test L2 Loss :  0.047393656820058826  Test L2 Loss :  0.06850659683346748  inv_L_scale:  [1.0, 1.0]
Epoch :  381  Time:  1.278  Rel. Train L2 Loss :  0.04248676715625657  Rel. Test L2 Loss :  0.04796512499451637  Test L2 Loss :  0.06928823381662369  inv_L_scale:  [1.0, 1.0]
Epoch :  382  Time:  1.28  Rel. Train L2 Loss :  0.04257131563292609  Rel. Test L2 Loss :  0.04749146401882172  Test L2 Loss :  0.06860494241118431  inv_L_scale:  [1.0, 1.0]
Epoch :  383  Time:  1.286  Rel. Train L2 Loss :  0.0423896919687589  Rel. Test L2 Loss :  0.047721099257469174  Test L2 Loss :  0.06891219675540924  inv_L_scale:  [1.0, 1.0]
Epoch :  384  Time:  1.284  Rel. Train L2 Loss :  0.04250566818647915  Rel. Test L2 Loss :  0.04739486664533615  Test L2 Loss :  0.06837845101952553  inv_L_scale:  [1.0, 1.0]
Epoch :  385  Time:  1.282  Rel. Train L2 Loss :  0.04239194663034545  Rel. Test L2 Loss :  0.04748921543359756  Test L2 Loss :  0.06855420261621475  inv_L_scale:  [1.0, 1.0]
Epoch :  386  Time:  1.284  Rel. Train L2 Loss :  0.04224395298295551  Rel. Test L2 Loss :  0.047601782977581025  Test L2 Loss :  0.06873039901256561  inv_L_scale:  [1.0, 1.0]
Epoch :  387  Time:  1.282  Rel. Train L2 Loss :  0.04238045305013657  Rel. Test L2 Loss :  0.04747414320707321  Test L2 Loss :  0.06857620760798454  inv_L_scale:  [1.0, 1.0]
Epoch :  388  Time:  1.284  Rel. Train L2 Loss :  0.04221467047929764  Rel. Test L2 Loss :  0.047385203689336776  Test L2 Loss :  0.06843960851430893  inv_L_scale:  [1.0, 1.0]
Epoch :  389  Time:  1.281  Rel. Train L2 Loss :  0.04217899796035555  Rel. Test L2 Loss :  0.047417679280042646  Test L2 Loss :  0.0685044239461422  inv_L_scale:  [1.0, 1.0]
Epoch :  390  Time:  1.281  Rel. Train L2 Loss :  0.04223484209842152  Rel. Test L2 Loss :  0.04765931472182274  Test L2 Loss :  0.06890443876385689  inv_L_scale:  [1.0, 1.0]
Epoch :  391  Time:  1.282  Rel. Train L2 Loss :  0.04218737872110473  Rel. Test L2 Loss :  0.04715951889753342  Test L2 Loss :  0.06813086748123169  inv_L_scale:  [1.0, 1.0]
Epoch :  392  Time:  1.278  Rel. Train L2 Loss :  0.04228003473745452  Rel. Test L2 Loss :  0.04764425829052925  Test L2 Loss :  0.06882684633135795  inv_L_scale:  [1.0, 1.0]
Epoch :  393  Time:  1.278  Rel. Train L2 Loss :  0.04207179844379425  Rel. Test L2 Loss :  0.04703126788139343  Test L2 Loss :  0.06799594327807426  inv_L_scale:  [1.0, 1.0]
Epoch :  394  Time:  1.289  Rel. Train L2 Loss :  0.042068443513578836  Rel. Test L2 Loss :  0.047600717544555665  Test L2 Loss :  0.06880845546722412  inv_L_scale:  [1.0, 1.0]
Epoch :  395  Time:  1.286  Rel. Train L2 Loss :  0.04215800679392285  Rel. Test L2 Loss :  0.04737792193889618  Test L2 Loss :  0.06842744693160058  inv_L_scale:  [1.0, 1.0]
Epoch :  396  Time:  1.281  Rel. Train L2 Loss :  0.04198848477668232  Rel. Test L2 Loss :  0.047326800525188444  Test L2 Loss :  0.06832416966557503  inv_L_scale:  [1.0, 1.0]
Epoch :  397  Time:  1.285  Rel. Train L2 Loss :  0.042068554394774964  Rel. Test L2 Loss :  0.04723001852631569  Test L2 Loss :  0.06822255045175553  inv_L_scale:  [1.0, 1.0]
Epoch :  398  Time:  1.287  Rel. Train L2 Loss :  0.04199470755126741  Rel. Test L2 Loss :  0.047403682768344876  Test L2 Loss :  0.06848755180835724  inv_L_scale:  [1.0, 1.0]
Epoch :  399  Time:  1.29  Rel. Train L2 Loss :  0.0418677235311932  Rel. Test L2 Loss :  0.047172583639621735  Test L2 Loss :  0.06815082833170891  inv_L_scale:  [1.0, 1.0]
Epoch :  400  Time:  1.28  Rel. Train L2 Loss :  0.04187308273381657  Rel. Test L2 Loss :  0.04730198562145233  Test L2 Loss :  0.06823966115713119  inv_L_scale:  [1.0, 1.0]
Epoch :  401  Time:  1.281  Rel. Train L2 Loss :  0.0417619009481536  Rel. Test L2 Loss :  0.04717700198292732  Test L2 Loss :  0.06814986884593964  inv_L_scale:  [1.0, 1.0]
Epoch :  402  Time:  1.282  Rel. Train L2 Loss :  0.04183168888092041  Rel. Test L2 Loss :  0.04690286189317703  Test L2 Loss :  0.06784569561481475  inv_L_scale:  [1.0, 1.0]
Epoch :  403  Time:  1.287  Rel. Train L2 Loss :  0.04175811358624035  Rel. Test L2 Loss :  0.047322368323802946  Test L2 Loss :  0.06834643468260765  inv_L_scale:  [1.0, 1.0]
Epoch :  404  Time:  1.286  Rel. Train L2 Loss :  0.04177909132507112  Rel. Test L2 Loss :  0.04737117677927017  Test L2 Loss :  0.06849286943674088  inv_L_scale:  [1.0, 1.0]
Epoch :  405  Time:  1.284  Rel. Train L2 Loss :  0.04167924761772156  Rel. Test L2 Loss :  0.04706967934966087  Test L2 Loss :  0.06800274163484574  inv_L_scale:  [1.0, 1.0]
Epoch :  406  Time:  1.281  Rel. Train L2 Loss :  0.041572379105620914  Rel. Test L2 Loss :  0.04694764599204063  Test L2 Loss :  0.06783908322453498  inv_L_scale:  [1.0, 1.0]
Epoch :  407  Time:  1.283  Rel. Train L2 Loss :  0.041556039336654874  Rel. Test L2 Loss :  0.04699537575244903  Test L2 Loss :  0.06787693053483963  inv_L_scale:  [1.0, 1.0]
Epoch :  408  Time:  1.28  Rel. Train L2 Loss :  0.04151300210919645  Rel. Test L2 Loss :  0.047065998017787936  Test L2 Loss :  0.0680210442841053  inv_L_scale:  [1.0, 1.0]
Epoch :  409  Time:  1.283  Rel. Train L2 Loss :  0.04152179438206884  Rel. Test L2 Loss :  0.04693900227546692  Test L2 Loss :  0.06783374637365341  inv_L_scale:  [1.0, 1.0]
Epoch :  410  Time:  1.286  Rel. Train L2 Loss :  0.04149700027373102  Rel. Test L2 Loss :  0.0470635998249054  Test L2 Loss :  0.0680287429690361  inv_L_scale:  [1.0, 1.0]
Epoch :  411  Time:  1.28  Rel. Train L2 Loss :  0.041503856943713294  Rel. Test L2 Loss :  0.0468038409948349  Test L2 Loss :  0.0676174795627594  inv_L_scale:  [1.0, 1.0]
Epoch :  412  Time:  1.276  Rel. Train L2 Loss :  0.04148365694615576  Rel. Test L2 Loss :  0.04700283333659172  Test L2 Loss :  0.0679236251115799  inv_L_scale:  [1.0, 1.0]
Epoch :  413  Time:  1.284  Rel. Train L2 Loss :  0.041400126897626455  Rel. Test L2 Loss :  0.04694619536399841  Test L2 Loss :  0.06786181479692459  inv_L_scale:  [1.0, 1.0]
Epoch :  414  Time:  1.294  Rel. Train L2 Loss :  0.04143092066049576  Rel. Test L2 Loss :  0.04710717231035232  Test L2 Loss :  0.06805120259523392  inv_L_scale:  [1.0, 1.0]
Epoch :  415  Time:  1.291  Rel. Train L2 Loss :  0.04141675894459089  Rel. Test L2 Loss :  0.047096361517906186  Test L2 Loss :  0.0680317460000515  inv_L_scale:  [1.0, 1.0]
Epoch :  416  Time:  1.283  Rel. Train L2 Loss :  0.04139506952630149  Rel. Test L2 Loss :  0.04698014110326767  Test L2 Loss :  0.0678541386127472  inv_L_scale:  [1.0, 1.0]
Epoch :  417  Time:  1.287  Rel. Train L2 Loss :  0.041431170884105896  Rel. Test L2 Loss :  0.04710098296403885  Test L2 Loss :  0.06809398710727692  inv_L_scale:  [1.0, 1.0]
Epoch :  418  Time:  1.283  Rel. Train L2 Loss :  0.041369051486253736  Rel. Test L2 Loss :  0.04691183045506477  Test L2 Loss :  0.06776868060231209  inv_L_scale:  [1.0, 1.0]
Epoch :  419  Time:  1.288  Rel. Train L2 Loss :  0.04126747904552354  Rel. Test L2 Loss :  0.047075595259666446  Test L2 Loss :  0.06801647782325744  inv_L_scale:  [1.0, 1.0]
Epoch :  420  Time:  1.288  Rel. Train L2 Loss :  0.04127520678771867  Rel. Test L2 Loss :  0.04677295446395874  Test L2 Loss :  0.06764240115880966  inv_L_scale:  [1.0, 1.0]
Epoch :  421  Time:  1.291  Rel. Train L2 Loss :  0.04125503051612112  Rel. Test L2 Loss :  0.046774121075868605  Test L2 Loss :  0.06756182447075844  inv_L_scale:  [1.0, 1.0]
Epoch :  422  Time:  1.294  Rel. Train L2 Loss :  0.041175881624221804  Rel. Test L2 Loss :  0.046778873354196546  Test L2 Loss :  0.0675822864472866  inv_L_scale:  [1.0, 1.0]
Epoch :  423  Time:  1.285  Rel. Train L2 Loss :  0.041153594354788464  Rel. Test L2 Loss :  0.04676976203918457  Test L2 Loss :  0.06758180886507034  inv_L_scale:  [1.0, 1.0]
Epoch :  424  Time:  1.286  Rel. Train L2 Loss :  0.04114880306025346  Rel. Test L2 Loss :  0.04673040896654129  Test L2 Loss :  0.06759113892912864  inv_L_scale:  [1.0, 1.0]
Epoch :  425  Time:  1.288  Rel. Train L2 Loss :  0.04108524193366369  Rel. Test L2 Loss :  0.046783605217933656  Test L2 Loss :  0.06760888129472732  inv_L_scale:  [1.0, 1.0]
Epoch :  426  Time:  1.285  Rel. Train L2 Loss :  0.04107351173957189  Rel. Test L2 Loss :  0.046744235008955  Test L2 Loss :  0.0676020422577858  inv_L_scale:  [1.0, 1.0]
Epoch :  427  Time:  1.292  Rel. Train L2 Loss :  0.04106447391211986  Rel. Test L2 Loss :  0.04678473263978958  Test L2 Loss :  0.06763923555612564  inv_L_scale:  [1.0, 1.0]
Epoch :  428  Time:  1.293  Rel. Train L2 Loss :  0.04100248439444436  Rel. Test L2 Loss :  0.04679151922464371  Test L2 Loss :  0.06768298789858818  inv_L_scale:  [1.0, 1.0]
Epoch :  429  Time:  1.285  Rel. Train L2 Loss :  0.04094455493821038  Rel. Test L2 Loss :  0.04685180932283402  Test L2 Loss :  0.06775130957365036  inv_L_scale:  [1.0, 1.0]
Epoch :  430  Time:  1.286  Rel. Train L2 Loss :  0.040956553137964674  Rel. Test L2 Loss :  0.04689158871769905  Test L2 Loss :  0.0677744671702385  inv_L_scale:  [1.0, 1.0]
Epoch :  431  Time:  1.281  Rel. Train L2 Loss :  0.040971776826514136  Rel. Test L2 Loss :  0.046782586723566055  Test L2 Loss :  0.06761283993721008  inv_L_scale:  [1.0, 1.0]
Epoch :  432  Time:  1.282  Rel. Train L2 Loss :  0.04091839535368813  Rel. Test L2 Loss :  0.046752138882875445  Test L2 Loss :  0.06756233066320419  inv_L_scale:  [1.0, 1.0]
Epoch :  433  Time:  1.281  Rel. Train L2 Loss :  0.0408870862921079  Rel. Test L2 Loss :  0.04680728226900101  Test L2 Loss :  0.06770195618271828  inv_L_scale:  [1.0, 1.0]
Epoch :  434  Time:  1.283  Rel. Train L2 Loss :  0.04084982797503471  Rel. Test L2 Loss :  0.046727944165468216  Test L2 Loss :  0.06753213167190551  inv_L_scale:  [1.0, 1.0]
Epoch :  435  Time:  1.283  Rel. Train L2 Loss :  0.040861006163888505  Rel. Test L2 Loss :  0.046719902008771894  Test L2 Loss :  0.067526403516531  inv_L_scale:  [1.0, 1.0]
Epoch :  436  Time:  1.28  Rel. Train L2 Loss :  0.040828002360132  Rel. Test L2 Loss :  0.046837945878505705  Test L2 Loss :  0.06765111833810807  inv_L_scale:  [1.0, 1.0]
Epoch :  437  Time:  1.281  Rel. Train L2 Loss :  0.040802526440885334  Rel. Test L2 Loss :  0.046636839359998704  Test L2 Loss :  0.06742367789149284  inv_L_scale:  [1.0, 1.0]
Epoch :  438  Time:  1.276  Rel. Train L2 Loss :  0.040755621840556464  Rel. Test L2 Loss :  0.04674765154719353  Test L2 Loss :  0.06755934715270996  inv_L_scale:  [1.0, 1.0]
Epoch :  439  Time:  1.282  Rel. Train L2 Loss :  0.04076898457275496  Rel. Test L2 Loss :  0.0468743921816349  Test L2 Loss :  0.06771688759326935  inv_L_scale:  [1.0, 1.0]
Epoch :  440  Time:  1.281  Rel. Train L2 Loss :  0.04078577020102077  Rel. Test L2 Loss :  0.046629905551671985  Test L2 Loss :  0.06736342385411262  inv_L_scale:  [1.0, 1.0]
Epoch :  441  Time:  1.278  Rel. Train L2 Loss :  0.04072588973575168  Rel. Test L2 Loss :  0.04669366806745529  Test L2 Loss :  0.06750933706760406  inv_L_scale:  [1.0, 1.0]
Epoch :  442  Time:  1.276  Rel. Train L2 Loss :  0.040727329817083144  Rel. Test L2 Loss :  0.04679070010781288  Test L2 Loss :  0.06760747745633125  inv_L_scale:  [1.0, 1.0]
Epoch :  443  Time:  1.279  Rel. Train L2 Loss :  0.040679608268870245  Rel. Test L2 Loss :  0.04676535740494728  Test L2 Loss :  0.06756752371788025  inv_L_scale:  [1.0, 1.0]
Epoch :  444  Time:  1.274  Rel. Train L2 Loss :  0.040665771630075245  Rel. Test L2 Loss :  0.04666272193193435  Test L2 Loss :  0.06739205688238144  inv_L_scale:  [1.0, 1.0]
Epoch :  445  Time:  1.279  Rel. Train L2 Loss :  0.04063381642103195  Rel. Test L2 Loss :  0.04669151768088341  Test L2 Loss :  0.06747019827365876  inv_L_scale:  [1.0, 1.0]
Epoch :  446  Time:  1.29  Rel. Train L2 Loss :  0.040631801949607  Rel. Test L2 Loss :  0.04669304698705673  Test L2 Loss :  0.06749734103679657  inv_L_scale:  [1.0, 1.0]
Epoch :  447  Time:  1.275  Rel. Train L2 Loss :  0.04058978688385752  Rel. Test L2 Loss :  0.04663043558597565  Test L2 Loss :  0.06742173582315444  inv_L_scale:  [1.0, 1.0]
Epoch :  448  Time:  1.278  Rel. Train L2 Loss :  0.040599018616808785  Rel. Test L2 Loss :  0.04661730766296387  Test L2 Loss :  0.06737885028123855  inv_L_scale:  [1.0, 1.0]
Epoch :  449  Time:  1.275  Rel. Train L2 Loss :  0.040564333448807395  Rel. Test L2 Loss :  0.04670245990157127  Test L2 Loss :  0.0674862402677536  inv_L_scale:  [1.0, 1.0]
Epoch :  450  Time:  1.283  Rel. Train L2 Loss :  0.04055321415265401  Rel. Test L2 Loss :  0.04655968904495239  Test L2 Loss :  0.06732970416545868  inv_L_scale:  [1.0, 1.0]
Epoch :  451  Time:  1.278  Rel. Train L2 Loss :  0.040527134637037915  Rel. Test L2 Loss :  0.046682889610528945  Test L2 Loss :  0.06748675405979157  inv_L_scale:  [1.0, 1.0]
Epoch :  452  Time:  1.282  Rel. Train L2 Loss :  0.040521892772780524  Rel. Test L2 Loss :  0.04662428170442581  Test L2 Loss :  0.06736738666892052  inv_L_scale:  [1.0, 1.0]
Epoch :  453  Time:  1.284  Rel. Train L2 Loss :  0.04050798979898294  Rel. Test L2 Loss :  0.046663492470979694  Test L2 Loss :  0.06744827657938003  inv_L_scale:  [1.0, 1.0]
Epoch :  454  Time:  1.29  Rel. Train L2 Loss :  0.04048931035730574  Rel. Test L2 Loss :  0.046609940975904464  Test L2 Loss :  0.06737128630280495  inv_L_scale:  [1.0, 1.0]
Epoch :  455  Time:  1.279  Rel. Train L2 Loss :  0.04047332611348894  Rel. Test L2 Loss :  0.046667789071798325  Test L2 Loss :  0.06742989808321  inv_L_scale:  [1.0, 1.0]
Epoch :  456  Time:  1.282  Rel. Train L2 Loss :  0.04043981358408928  Rel. Test L2 Loss :  0.046617828607559204  Test L2 Loss :  0.06736489534378051  inv_L_scale:  [1.0, 1.0]
Epoch :  457  Time:  1.285  Rel. Train L2 Loss :  0.0404516720937358  Rel. Test L2 Loss :  0.0466305673122406  Test L2 Loss :  0.06738278895616531  inv_L_scale:  [1.0, 1.0]
Epoch :  458  Time:  1.287  Rel. Train L2 Loss :  0.04044770513971647  Rel. Test L2 Loss :  0.04666068032383919  Test L2 Loss :  0.06743960991501809  inv_L_scale:  [1.0, 1.0]
Epoch :  459  Time:  1.285  Rel. Train L2 Loss :  0.04041536092758179  Rel. Test L2 Loss :  0.04666503578424454  Test L2 Loss :  0.06743449822068215  inv_L_scale:  [1.0, 1.0]
Epoch :  460  Time:  1.285  Rel. Train L2 Loss :  0.04039698801934719  Rel. Test L2 Loss :  0.046641100645065305  Test L2 Loss :  0.06741617590188981  inv_L_scale:  [1.0, 1.0]
Epoch :  461  Time:  1.281  Rel. Train L2 Loss :  0.04039266395899985  Rel. Test L2 Loss :  0.04662208989262581  Test L2 Loss :  0.06737491995096206  inv_L_scale:  [1.0, 1.0]
Epoch :  462  Time:  1.281  Rel. Train L2 Loss :  0.04038832358188099  Rel. Test L2 Loss :  0.046643288731575014  Test L2 Loss :  0.06743088766932487  inv_L_scale:  [1.0, 1.0]
Epoch :  463  Time:  1.277  Rel. Train L2 Loss :  0.04036656618118286  Rel. Test L2 Loss :  0.04659833863377571  Test L2 Loss :  0.06736419975757599  inv_L_scale:  [1.0, 1.0]
Epoch :  464  Time:  1.281  Rel. Train L2 Loss :  0.040347927146487765  Rel. Test L2 Loss :  0.04659300923347473  Test L2 Loss :  0.06734285414218903  inv_L_scale:  [1.0, 1.0]
Epoch :  465  Time:  1.285  Rel. Train L2 Loss :  0.04032391573819849  Rel. Test L2 Loss :  0.04660235911607742  Test L2 Loss :  0.06736611053347588  inv_L_scale:  [1.0, 1.0]
Epoch :  466  Time:  1.283  Rel. Train L2 Loss :  0.04031361680891779  Rel. Test L2 Loss :  0.04659829273819924  Test L2 Loss :  0.06733795613050461  inv_L_scale:  [1.0, 1.0]
Epoch :  467  Time:  1.279  Rel. Train L2 Loss :  0.04030242886808184  Rel. Test L2 Loss :  0.04660502225160599  Test L2 Loss :  0.06735940963029861  inv_L_scale:  [1.0, 1.0]
Epoch :  468  Time:  1.288  Rel. Train L2 Loss :  0.04029231384396553  Rel. Test L2 Loss :  0.04660853371024132  Test L2 Loss :  0.06736276432871818  inv_L_scale:  [1.0, 1.0]
Epoch :  469  Time:  1.288  Rel. Train L2 Loss :  0.04027721222903993  Rel. Test L2 Loss :  0.04656098812818527  Test L2 Loss :  0.06731253057718277  inv_L_scale:  [1.0, 1.0]
Epoch :  470  Time:  1.285  Rel. Train L2 Loss :  0.040281407054927616  Rel. Test L2 Loss :  0.04657939821481705  Test L2 Loss :  0.06734139770269394  inv_L_scale:  [1.0, 1.0]
Epoch :  471  Time:  1.291  Rel. Train L2 Loss :  0.04027267461021741  Rel. Test L2 Loss :  0.04657294243574142  Test L2 Loss :  0.06731555923819542  inv_L_scale:  [1.0, 1.0]
Epoch :  472  Time:  1.29  Rel. Train L2 Loss :  0.04024240753716893  Rel. Test L2 Loss :  0.04658105865120888  Test L2 Loss :  0.06734636530280114  inv_L_scale:  [1.0, 1.0]
Epoch :  473  Time:  1.287  Rel. Train L2 Loss :  0.040234288523594536  Rel. Test L2 Loss :  0.04658311575651169  Test L2 Loss :  0.06733301043510437  inv_L_scale:  [1.0, 1.0]
Epoch :  474  Time:  1.294  Rel. Train L2 Loss :  0.040227440827422675  Rel. Test L2 Loss :  0.04658759757876396  Test L2 Loss :  0.06734154775738715  inv_L_scale:  [1.0, 1.0]
Epoch :  475  Time:  1.288  Rel. Train L2 Loss :  0.040211356894837486  Rel. Test L2 Loss :  0.046568387150764466  Test L2 Loss :  0.0673170816898346  inv_L_scale:  [1.0, 1.0]
Epoch :  476  Time:  1.286  Rel. Train L2 Loss :  0.04021645786033736  Rel. Test L2 Loss :  0.046570671796798704  Test L2 Loss :  0.06732075557112693  inv_L_scale:  [1.0, 1.0]
Epoch :  477  Time:  1.285  Rel. Train L2 Loss :  0.04020392701029778  Rel. Test L2 Loss :  0.04653925970196724  Test L2 Loss :  0.06727855071425438  inv_L_scale:  [1.0, 1.0]
Epoch :  478  Time:  1.289  Rel. Train L2 Loss :  0.040192230608728195  Rel. Test L2 Loss :  0.046567999273538586  Test L2 Loss :  0.0673223865032196  inv_L_scale:  [1.0, 1.0]
Epoch :  479  Time:  1.291  Rel. Train L2 Loss :  0.040185107356972165  Rel. Test L2 Loss :  0.04658973067998886  Test L2 Loss :  0.06734706103801727  inv_L_scale:  [1.0, 1.0]
Epoch :  480  Time:  1.291  Rel. Train L2 Loss :  0.04018533488114675  Rel. Test L2 Loss :  0.046568274796009064  Test L2 Loss :  0.06732178941369056  inv_L_scale:  [1.0, 1.0]
Epoch :  481  Time:  1.284  Rel. Train L2 Loss :  0.04016855403780937  Rel. Test L2 Loss :  0.046554459035396574  Test L2 Loss :  0.06729721680283546  inv_L_scale:  [1.0, 1.0]
Epoch :  482  Time:  1.283  Rel. Train L2 Loss :  0.04015985369682312  Rel. Test L2 Loss :  0.04657244876027107  Test L2 Loss :  0.06732192784547805  inv_L_scale:  [1.0, 1.0]
Epoch :  483  Time:  1.292  Rel. Train L2 Loss :  0.04015648831923803  Rel. Test L2 Loss :  0.046573857069015505  Test L2 Loss :  0.06732823580503464  inv_L_scale:  [1.0, 1.0]
Epoch :  484  Time:  1.293  Rel. Train L2 Loss :  0.04015427670545048  Rel. Test L2 Loss :  0.046554448008537294  Test L2 Loss :  0.06730189546942711  inv_L_scale:  [1.0, 1.0]
Epoch :  485  Time:  1.288  Rel. Train L2 Loss :  0.04014569459689988  Rel. Test L2 Loss :  0.04657415777444839  Test L2 Loss :  0.06732799708843232  inv_L_scale:  [1.0, 1.0]
Epoch :  486  Time:  1.283  Rel. Train L2 Loss :  0.04014079377055168  Rel. Test L2 Loss :  0.04656917780637741  Test L2 Loss :  0.0673263794183731  inv_L_scale:  [1.0, 1.0]
Epoch :  487  Time:  1.283  Rel. Train L2 Loss :  0.04013831635316213  Rel. Test L2 Loss :  0.046548019349575046  Test L2 Loss :  0.0672871732711792  inv_L_scale:  [1.0, 1.0]
Epoch :  488  Time:  1.284  Rel. Train L2 Loss :  0.040140628549787734  Rel. Test L2 Loss :  0.04656439632177353  Test L2 Loss :  0.06731749296188355  inv_L_scale:  [1.0, 1.0]
Epoch :  489  Time:  1.284  Rel. Train L2 Loss :  0.040126483937104544  Rel. Test L2 Loss :  0.046564762890338895  Test L2 Loss :  0.06731880709528923  inv_L_scale:  [1.0, 1.0]
Epoch :  490  Time:  1.283  Rel. Train L2 Loss :  0.040130125979582466  Rel. Test L2 Loss :  0.046562320291996  Test L2 Loss :  0.0673132798075676  inv_L_scale:  [1.0, 1.0]
Epoch :  491  Time:  1.298  Rel. Train L2 Loss :  0.040123650862110984  Rel. Test L2 Loss :  0.04656195744872093  Test L2 Loss :  0.06731320142745972  inv_L_scale:  [1.0, 1.0]
Epoch :  492  Time:  1.285  Rel. Train L2 Loss :  0.04012102906902631  Rel. Test L2 Loss :  0.04656725287437439  Test L2 Loss :  0.06731861531734466  inv_L_scale:  [1.0, 1.0]
Epoch :  493  Time:  1.289  Rel. Train L2 Loss :  0.04011736972464455  Rel. Test L2 Loss :  0.04655829206109047  Test L2 Loss :  0.06731081306934357  inv_L_scale:  [1.0, 1.0]
Epoch :  494  Time:  1.286  Rel. Train L2 Loss :  0.04011950686573982  Rel. Test L2 Loss :  0.046560550034046175  Test L2 Loss :  0.06731218874454498  inv_L_scale:  [1.0, 1.0]
Epoch :  495  Time:  1.286  Rel. Train L2 Loss :  0.040116114914417265  Rel. Test L2 Loss :  0.04656213104724884  Test L2 Loss :  0.06731504067778588  inv_L_scale:  [1.0, 1.0]
Epoch :  496  Time:  1.288  Rel. Train L2 Loss :  0.04011332384414143  Rel. Test L2 Loss :  0.0465620282292366  Test L2 Loss :  0.06731320887804032  inv_L_scale:  [1.0, 1.0]
Epoch :  497  Time:  1.294  Rel. Train L2 Loss :  0.04011141447557343  Rel. Test L2 Loss :  0.046565389931201934  Test L2 Loss :  0.06731561958789825  inv_L_scale:  [1.0, 1.0]
Epoch :  498  Time:  1.285  Rel. Train L2 Loss :  0.040111936976512275  Rel. Test L2 Loss :  0.04655941188335419  Test L2 Loss :  0.06730709552764892  inv_L_scale:  [1.0, 1.0]
Epoch :  499  Time:  1.286  Rel. Train L2 Loss :  0.04011146013935407  Rel. Test L2 Loss :  0.0465634149312973  Test L2 Loss :  0.06731520041823387  inv_L_scale:  [1.0, 1.0]


(1000,) (1000, 1000, 1) (1000, 1000, 2)
use normalized raw measures
Casting to tensor
x_train shape torch.Size([900, 1000, 8]), y_train shape torch.Size([900, 1000, 1])
length of each dim:  tensor([6.5573987960815430, 6.1420288085937500])
kmax = 16
L = 10
geo_dims = [1, 2, 5, 6]
In PCNO_train, ndims =  2
Epoch :  0  Time:  1.685  Rel. Train L2 Loss :  0.5140815756056044  Rel. Test L2 Loss :  0.31484886646270754  Test L2 Loss :  0.4505479955673218  inv_L_scale:  [1.0, 1.0]
Epoch :  1  Time:  1.32  Rel. Train L2 Loss :  0.2574389611350165  Rel. Test L2 Loss :  0.21641814947128296  Test L2 Loss :  0.3131206321716309  inv_L_scale:  [1.0, 1.0]
Epoch :  2  Time:  1.312  Rel. Train L2 Loss :  0.20780716896057128  Rel. Test L2 Loss :  0.18420228242874145  Test L2 Loss :  0.2630044734477997  inv_L_scale:  [1.0, 1.0]
Epoch :  3  Time:  1.337  Rel. Train L2 Loss :  0.17735412425465055  Rel. Test L2 Loss :  0.17338616728782655  Test L2 Loss :  0.2516422462463379  inv_L_scale:  [1.0, 1.0]
Epoch :  4  Time:  1.322  Rel. Train L2 Loss :  0.16587198396523795  Rel. Test L2 Loss :  0.15818407356739045  Test L2 Loss :  0.22813309609889984  inv_L_scale:  [1.0, 1.0]
Epoch :  5  Time:  1.324  Rel. Train L2 Loss :  0.15243558208147684  Rel. Test L2 Loss :  0.14882929027080535  Test L2 Loss :  0.21509195506572723  inv_L_scale:  [1.0, 1.0]
Epoch :  6  Time:  1.365  Rel. Train L2 Loss :  0.1439481786886851  Rel. Test L2 Loss :  0.14258487284183502  Test L2 Loss :  0.20432113647460937  inv_L_scale:  [1.0, 1.0]
Epoch :  7  Time:  1.348  Rel. Train L2 Loss :  0.13702504681216346  Rel. Test L2 Loss :  0.13181447446346284  Test L2 Loss :  0.19012912154197692  inv_L_scale:  [1.0, 1.0]
Epoch :  8  Time:  1.313  Rel. Train L2 Loss :  0.132477728260888  Rel. Test L2 Loss :  0.13259114503860472  Test L2 Loss :  0.19045817494392395  inv_L_scale:  [1.0, 1.0]
Epoch :  9  Time:  1.314  Rel. Train L2 Loss :  0.12966408318943448  Rel. Test L2 Loss :  0.12899763584136964  Test L2 Loss :  0.18594360172748567  inv_L_scale:  [1.0, 1.0]
Epoch :  10  Time:  1.333  Rel. Train L2 Loss :  0.1251399768061108  Rel. Test L2 Loss :  0.12037755131721496  Test L2 Loss :  0.17359303832054138  inv_L_scale:  [1.0, 1.0]
Epoch :  11  Time:  1.335  Rel. Train L2 Loss :  0.12017749051253  Rel. Test L2 Loss :  0.12185687959194183  Test L2 Loss :  0.17515764951705934  inv_L_scale:  [1.0, 1.0]
Epoch :  12  Time:  1.314  Rel. Train L2 Loss :  0.11951886475086212  Rel. Test L2 Loss :  0.12134317517280578  Test L2 Loss :  0.17427109003067018  inv_L_scale:  [1.0, 1.0]
Epoch :  13  Time:  1.322  Rel. Train L2 Loss :  0.11776711020204755  Rel. Test L2 Loss :  0.12064160645008087  Test L2 Loss :  0.1735483592748642  inv_L_scale:  [1.0, 1.0]
Epoch :  14  Time:  1.312  Rel. Train L2 Loss :  0.11468886997964647  Rel. Test L2 Loss :  0.11330350130796432  Test L2 Loss :  0.16284377694129945  inv_L_scale:  [1.0, 1.0]
Epoch :  15  Time:  1.31  Rel. Train L2 Loss :  0.11277721881866455  Rel. Test L2 Loss :  0.11585034936666488  Test L2 Loss :  0.16651127576828004  inv_L_scale:  [1.0, 1.0]
Epoch :  16  Time:  1.31  Rel. Train L2 Loss :  0.11320668253633712  Rel. Test L2 Loss :  0.1081220555305481  Test L2 Loss :  0.15626278698444365  inv_L_scale:  [1.0, 1.0]
Epoch :  17  Time:  1.306  Rel. Train L2 Loss :  0.1103287097480562  Rel. Test L2 Loss :  0.10956616014242172  Test L2 Loss :  0.1576880371570587  inv_L_scale:  [1.0, 1.0]
Epoch :  18  Time:  1.372  Rel. Train L2 Loss :  0.110471454527643  Rel. Test L2 Loss :  0.11429962038993835  Test L2 Loss :  0.16393531799316408  inv_L_scale:  [1.0, 1.0]
Epoch :  19  Time:  1.34  Rel. Train L2 Loss :  0.1064135421315829  Rel. Test L2 Loss :  0.10493536412715912  Test L2 Loss :  0.15115781366825104  inv_L_scale:  [1.0, 1.0]
Epoch :  20  Time:  1.311  Rel. Train L2 Loss :  0.10548219939072927  Rel. Test L2 Loss :  0.10525827676057815  Test L2 Loss :  0.15176313519477844  inv_L_scale:  [1.0, 1.0]
Epoch :  21  Time:  1.311  Rel. Train L2 Loss :  0.10451473368538751  Rel. Test L2 Loss :  0.10605201989412308  Test L2 Loss :  0.15287722945213317  inv_L_scale:  [1.0, 1.0]
Epoch :  22  Time:  1.312  Rel. Train L2 Loss :  0.10342060572571225  Rel. Test L2 Loss :  0.10022898912429809  Test L2 Loss :  0.14372588694095612  inv_L_scale:  [1.0, 1.0]
Epoch :  23  Time:  1.311  Rel. Train L2 Loss :  0.10149043311675389  Rel. Test L2 Loss :  0.10646819025278091  Test L2 Loss :  0.15345601737499237  inv_L_scale:  [1.0, 1.0]
Epoch :  24  Time:  1.307  Rel. Train L2 Loss :  0.1027470123105579  Rel. Test L2 Loss :  0.10699671298265458  Test L2 Loss :  0.15414371192455292  inv_L_scale:  [1.0, 1.0]
Epoch :  25  Time:  1.308  Rel. Train L2 Loss :  0.10155797726578182  Rel. Test L2 Loss :  0.09666606217622757  Test L2 Loss :  0.1388712304830551  inv_L_scale:  [1.0, 1.0]
Epoch :  26  Time:  1.31  Rel. Train L2 Loss :  0.09917518960105048  Rel. Test L2 Loss :  0.0991261300444603  Test L2 Loss :  0.14251135647296906  inv_L_scale:  [1.0, 1.0]
Epoch :  27  Time:  1.308  Rel. Train L2 Loss :  0.0992601121796502  Rel. Test L2 Loss :  0.09741694033145905  Test L2 Loss :  0.14080415666103363  inv_L_scale:  [1.0, 1.0]
Epoch :  28  Time:  1.31  Rel. Train L2 Loss :  0.09895030435588625  Rel. Test L2 Loss :  0.10161619156599044  Test L2 Loss :  0.14667111307382583  inv_L_scale:  [1.0, 1.0]
Epoch :  29  Time:  1.335  Rel. Train L2 Loss :  0.09814556118514803  Rel. Test L2 Loss :  0.1015775066614151  Test L2 Loss :  0.14562216758728028  inv_L_scale:  [1.0, 1.0]
Epoch :  30  Time:  1.307  Rel. Train L2 Loss :  0.09880740738577314  Rel. Test L2 Loss :  0.0992784109711647  Test L2 Loss :  0.14260001838207245  inv_L_scale:  [1.0, 1.0]
Epoch :  31  Time:  1.308  Rel. Train L2 Loss :  0.09592349410057067  Rel. Test L2 Loss :  0.09738690257072449  Test L2 Loss :  0.13975590616464614  inv_L_scale:  [1.0, 1.0]
Epoch :  32  Time:  1.308  Rel. Train L2 Loss :  0.09652632531192568  Rel. Test L2 Loss :  0.09627672076225281  Test L2 Loss :  0.13824135303497315  inv_L_scale:  [1.0, 1.0]