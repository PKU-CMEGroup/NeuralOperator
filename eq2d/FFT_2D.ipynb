{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D FNO Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %config InlineBackend.figure_format = 'svg'\n",
    "import random\n",
    "import torch\n",
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from timeit import default_timer\n",
    "from scipy.io import loadmat\n",
    "\n",
    "sys.path.append('../')\n",
    "from models import FNN1d, FNN_train, construct_model, compute_1dFourier_bases, compute_2dFourier_bases\n",
    "torch.set_printoptions(precision=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../mytest/data/piececonst_r421_N1024_smooth1\"\n",
    "data = loadmat(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_in = data[\"coeff\"]\n",
    "data_out = data[\"sol\"]\n",
    "print(\"input date size: \", data_in.shape, \"output data size: \", data_out.shape)\n",
    "\n",
    "L = 1 \n",
    "Np_ref = data_in.shape[1]\n",
    "grid_1d = np.linspace(0, L, Np_ref)\n",
    "\n",
    "grid_x, grid_y = np.meshgrid(grid_1d, grid_1d)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(6,3))\n",
    "axs[0].pcolormesh(grid_x, grid_y, data_in[0,:,:])\n",
    "axs[1].pcolormesh(grid_x, grid_y, data_out[0,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D Fourier Transform\n",
    "\n",
    "We compute the Fourier transform for the last 2 dimensions of x. We first define the mode set \n",
    "\n",
    "\\begin{align*}\n",
    "K_x = \\{k_x | k_x = 0,1,...,n_x/2-1, -n_x/2, -n_x/2+1, ... -1 \\} \\\\\n",
    "K_y = \\{k_y | k_y = 0,1,...,n_y/2-1, -n_y/2, -n_y/2+1, ... -1 \\} \n",
    "\\end{align*}\n",
    "\n",
    "Then the Fourier transform and inverse Fourier transform give the relation between \n",
    "$\\{\\hat{f}[k_x, k_y]: k_x \\in K_x, k_y \\in K_y \\}$ and $\\{f[j_x, j_y] : 0 \\leq j_x \\leq n_x, 0 \\leq j_y \\leq n_y\\}$\n",
    "\n",
    "\\begin{align*}\n",
    "   f(x,y) &= \\frac{1}{n_x n_y} \\sum_{k_x \\in K_x, k_y \\in K_y}  \\hat{f}[k_x, k_y]  e^{i k_x \\frac{2\\pi x}{L_x} + i k_y \\frac{2\\pi y}{L_y}} \n",
    "   \\\\ \n",
    "   f[j_x, j_y] &= \\frac{1}{n_x n_y} \\sum_{k_x \\in K_x, k_y \\in K_y}  \\hat{f}[k_x, k_y]  e^{i k_x \\frac{2\\pi j_x \\Delta x}{L_x} + i k_y \\frac{2\\pi j_y \\Delta y}{L_y}} \n",
    "   \\\\ \n",
    "   \\hat{f}[k_x, k_y] &= \\frac{n_x n_y}{L_x L_y} \\int f(x, y)  e^{-i k_x \\frac{2\\pi x}{L_x} - i k_y \\frac{2\\pi y}{L_y}} dx dy\\\\\n",
    "                &\\approx \\frac{n_x n_y}{L_x L_y}  \\sum_{j_x = 0}^{n_x - 1}\\sum_{j_y = 0}^{n_y - 1} f[j_x, j_y]  e^{-i k_x \\frac{2\\pi j_x \\Delta x }{L_x} - i k_y \\frac{2\\pi j_y \\Delta y }{L_y}} \\Delta x \\Delta y \\qquad \\textrm{when f has certain form, this is accurate.}\\\\\n",
    "                &= \\sum_{j_x = 0}^{n_x - 1}\\sum_{j_y = 0}^{n_y - 1} f[j_x, j_y]  e^{-i k_x \\frac{2\\pi  j_x}{n_x}-i k_y \\frac{2\\pi  j_y}{n_y}}\n",
    "\\end{align*}\n",
    "\n",
    "When $f(x)$ is real, we have $\\hat{f}[k_x, k_y] = conj(\\hat{f}[-k_x, -k_y])$, and hence `rfftn` only need to save the subset of $K$ \n",
    "\n",
    "\\begin{align*}\n",
    "&K_x^r = \\{k_x | k_x = 0,1,...,n_x/2-1, -n_x/2, -n_x/2+1, ... -1\\} \\\\\n",
    "&K_y^r = \\{k_y | k_y = 0,1,...,n_y/2-1, -n_y/2\\} \n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "In FNO, when we truncate to first $k_{xf}$ and $k_{yf}$ modes, we keep\n",
    "\\begin{align*}\n",
    "& \\{(k_x, k_y) | \n",
    "k_x = 0,1,...,k_{xf}-1,  -k_{xf}+1, ... -1, \n",
    "k_y = 0,1,...,k_{yf}-1\\} \n",
    "\\end{align*}\n",
    "In the original FNO implementation, $k_x = -k_{xf}$ is also included.\n",
    "\n",
    "\\begin{align*}\n",
    "f(x,y) \n",
    "&= \\frac{1}{n_x n_y}  \n",
    "Re\\Bigl(\n",
    "  \\sum_{k_x=-k_{xf}+1}^{k_{xf}-1} \\sum_{k_y=0}^{k_{yf}-1} \\hat{f}[k_x, k_y]  \\phi_{k_x, k_y}(x,y) \n",
    "+ \\sum_{k_x=-k_{xf}+1}^{k_{xf}-1} \\sum_{k_y=-k_{yf}-1}^{-1} \\hat{f}[k_x, k_y]  \\phi_{k_x, k_y}(x,y) \n",
    "\\Bigr) \n",
    "\\\\\n",
    "&= \\frac{1}{n_x n_y} Re\\Bigl(\\sum_{k_x=-k_{xf}+1}^{k_{xf}-1} \\hat{f}[k_x, 0]  \\phi_{k_x, 0}(x)  +  \\sum_{k_x=-k_{xf}+1}^{k_{xf}-1}\\sum_{k_y=1}^{k_{yf}-1}  (\\hat{f}[k_x, k_y]  \\phi_{k_x, k_y}(x,y) + \\hat{f}[-k_x, -k_y]  \\phi_{-k_x, -k_y}(x,y))\\Bigr)\n",
    "\\\\\n",
    "&= \\frac{1}{n_x n_y} Re\\Bigl(\\sum_{k_x=-k_{xf}+1}^{k_{xf}-1} \\hat{f}[k_x, 0]  \\phi_{k_x, 0}(x)  +  2\\sum_{k_x=-k_{xf}+1}^{k_{xf}-1}\\sum_{k_y=1}^{k_{yf}-1}  \\hat{f}[k_x, k_y]  \\phi_{k_x, k_y}(x,y) \\Bigr)\n",
    "\\end{align*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The shape of x is  torch.Size([16, 3, 22, 22])  the shape of x_ft is  torch.Size([16, 3, 22, 12])\n",
      "len(Kr_x), len(Kr_y) =  22 12\n",
      "Error between x_ft and x_ft2 is  tensor(2.3064641066838742e-11, dtype=torch.float64)\n",
      "Error between x_ft and x_ft2 is  tensor(2.8806366063147641e-11, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Here is a test, be careful, the torch will generally use float32. \n",
    "# To get accurate error estimate, use float64\n",
    "\n",
    "downsample_ratio = 20\n",
    "n_train = 2**10\n",
    "x_train = torch.from_numpy(np.stack((data_in[0:n_train, 0::downsample_ratio, 0::downsample_ratio], \n",
    "                           np.tile(grid_x[0::downsample_ratio,0::downsample_ratio], (n_train,1,1)), \n",
    "                           np.tile(grid_y[0::downsample_ratio,0::downsample_ratio], (n_train,1,1))), axis=-1))\n",
    "batchsize = 16\n",
    "x = x_train[0:batchsize]\n",
    "# batch, channel, x, y\n",
    "x = x.permute(0, 3, 1, 2)\n",
    "x_ft = torch.fft.rfftn(x, dim=[2,3])\n",
    "print(\" The shape of x is \", x.shape, \" the shape of x_ft is \", x_ft.shape)\n",
    "\n",
    "n_b, n_c, n_x, n_y = x.shape\n",
    "assert(n_x%2 == 0)\n",
    "n_k = n_y//2\n",
    "\n",
    "x = x.to(torch.complex128)\n",
    "\n",
    "\n",
    "# Implementation 1\n",
    "Kr_x = list(range(0, n_k)) + [-n_k] + list(range(-n_k+1, 0))\n",
    "Kr_y = list(range(0, n_k)) + [-n_k]\n",
    "print(\"len(Kr_x), len(Kr_y) = \", len(Kr_x), len(Kr_y))\n",
    "x_ft2 = torch.zeros(n_b, n_c, n_x, n_k+1, dtype=torch.complex128)\n",
    "for j_xk in range(len(Kr_x)):\n",
    "    for j_yk in range(len(Kr_y)):\n",
    "        basis = torch.einsum('x,y->xy',\n",
    "        torch.exp((-Kr_x[j_xk] * 2*np.pi/n_x * 1.0j * torch.linspace(0, n_x-1, n_x, dtype=torch.float64))),\n",
    "        torch.exp((-Kr_y[j_yk] * 2*np.pi/n_y * 1.0j * torch.linspace(0, n_y-1, n_y, dtype=torch.float64)))\n",
    "        )\n",
    "        x_ft2[:, :, j_xk, j_yk] += torch.einsum('bcxy,xy->bc', x, basis)\n",
    "print(\"Error between x_ft and x_ft2 is \", torch.norm(x_ft - x_ft2))\n",
    "\n",
    "\n",
    "# Implementation 2\n",
    "Kr_x = torch.tensor(list(range(0, n_k)) + [-n_k] + list(range(-n_k+1, 0)), dtype=torch.float64)\n",
    "Kr_y = torch.tensor(list(range(0, n_k)) + [-n_k], dtype=torch.float64)\n",
    "bases = torch.einsum('xk,yl->xykl',\n",
    "                     torch.exp( torch.outer(torch.linspace(0, n_x-1, n_x, dtype=torch.float64), -2*np.pi/n_x * 1.0j * Kr_x) ),\n",
    "                     torch.exp( torch.outer(torch.linspace(0, n_y-1, n_y, dtype=torch.float64), -2*np.pi/n_y * 1.0j * Kr_y) )  \n",
    "                    )\n",
    "x_ft2 = torch.einsum('bcxy,xykl->bckl', x, bases)\n",
    "print(\"Error between x_ft and x_ft2 is \", torch.norm(x_ft - x_ft2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ift = torch.fft.irfftn(x_ft, dim=[2,3])\n",
    "print(\"Error between x and x_ift is \", torch.norm(x - x_ift))\n",
    "\n",
    "# For the irfftn, it takes the real part\n",
    "x_ft_test = torch.clone(x_ft)\n",
    "print(x_ft_test[0, 0, 2,0], x_ft_test[0,0,-2,0])\n",
    "x_ft_test[0,0,0,0] += 10.0e10j\n",
    "x_ft_test[0,0, -2,0] += 10e4j\n",
    "x_ft_test[0,0,  2,0] += 10e4j\n",
    "print(x_ft_test.shape)\n",
    "x_ift = torch.fft.irfftn(x_ft_test, dim=[2,3])\n",
    "print(\"Error between x and x_ift is \", torch.norm(x - x_ift))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error between x and x_ift is  tensor(1.3465297236977153e-13, dtype=torch.float64)\n",
      "Error between x and x_ift2 is  tensor(3.5653540552682406e-13, dtype=torch.float64)\n",
      "Error between x and x_ift2 is  tensor(3.5653540552682406e-13, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x_ift = torch.fft.irfftn(x_ft, dim=[2, 3])\n",
    "print(\"Error between x and x_ift is \", torch.norm(x - x_ift))\n",
    "\n",
    "modes = 6\n",
    "#  Truncate to the first m modes\n",
    "x_ft_trunc = torch.zeros(n_b, n_c, n_x, n_k + 1, dtype=torch.complex128)\n",
    "x_ft_trunc[:, :, :modes, :modes] = x_ft[:, :, :modes, :modes]\n",
    "x_ft_trunc[:, :, -modes + 1 :, :modes] = x_ft[:, :, -modes + 1 :, :modes]\n",
    "\n",
    "x_ift_trunc = torch.fft.irfftn(x_ft_trunc, dim=[2, 3])\n",
    "\n",
    "# Implementation 1\n",
    "Kr_x = torch.tensor(\n",
    "    list(range(0, n_k)) + [-n_k] + list(range(-n_k + 1, 0)), dtype=torch.float64\n",
    ")\n",
    "Kr_y = torch.tensor(list(range(0, n_k)) + [-n_k], dtype=torch.float64)\n",
    "bases = torch.einsum(\n",
    "    \"xk,yl->xykl\",\n",
    "    torch.exp(\n",
    "        torch.outer(\n",
    "            torch.linspace(0, n_x - 1, n_x, dtype=torch.float64),\n",
    "            2 * np.pi / n_x * 1.0j * Kr_x,\n",
    "        )\n",
    "    ),\n",
    "    torch.exp(\n",
    "        torch.outer(\n",
    "            torch.linspace(0, n_y - 1, n_y, dtype=torch.float64),\n",
    "            2 * np.pi / n_y * 1.0j * Kr_y,\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "bases[:, :, :, 1:-1] *= 2.0\n",
    "x_ift2 = torch.real(torch.einsum(\"bckl,xykl->bcxy\", x_ft_trunc, bases)) / (n_x * n_y)\n",
    "print(\"Error between x and x_ift2 is \", torch.norm(x_ift_trunc - x_ift2))\n",
    "\n",
    "# Low Rank Implementation\n",
    "Kr_x = torch.tensor(\n",
    "    list(range(0, modes)) + list(range(-modes + 1, 0)), dtype=torch.float64\n",
    ")\n",
    "Kr_y = torch.tensor(list(range(0, modes)), dtype=torch.float64)\n",
    "Kr = torch.tensor(list(range(0, modes)), dtype=torch.float64)\n",
    "bases = torch.einsum(\n",
    "    \"xk,yl->xykl\",\n",
    "    torch.exp(\n",
    "        torch.outer(\n",
    "            torch.linspace(0, n_x - 1, n_x, dtype=torch.float64),\n",
    "            2 * np.pi / n_x * 1.0j * Kr_x,\n",
    "        )\n",
    "    ),\n",
    "    torch.exp(\n",
    "        torch.outer(\n",
    "            torch.linspace(0, n_y - 1, n_y, dtype=torch.float64),\n",
    "            2 * np.pi / n_y * 1.0j * Kr_y,\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "bases[:, :, :, 1:] *= 2.0\n",
    "x_ift2 = torch.real(\n",
    "    torch.einsum(\n",
    "        \"bckl,xykl->bcxy\",\n",
    "        x_ft_trunc[:, :, list(range(0, modes)) + list(range(-modes + 1, 0)), :modes],\n",
    "        bases,\n",
    "    )\n",
    ") / (n_x * n_y)\n",
    "print(\"Error between x and x_ift2 is \", torch.norm(x_ift_trunc - x_ift2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral Transform\n",
    "\n",
    "We compute the spectral transform for the last dimension of x. \n",
    "We first define $n_k$ orthonal bases $\\{ \\phi_k \\}_{k = 0}^{n_k-1}$\n",
    "\n",
    "\n",
    "Then the spectral transform and inverse spectral transform give the relation between \n",
    "$\\{\\hat{f}[k]: k \\in K \\}$ and $\\{f(x_j) : 0 \\leq j \\leq n_x\\}$\n",
    "\n",
    "\\begin{align*}\n",
    "   f(x) &= \\sum_{k=0}^{n_k-1}  \\hat{f}[k]  \\phi_k(x) \n",
    "   \\\\ \n",
    "   f(x_j) &= \\sum_{k_x=0}^{n_k-1}  \\hat{f}[k]  \\phi_k(x_j)\n",
    "   \\\\ \n",
    "   \\hat{f}[k] &= \\int  f(x)  \\phi_k(x) dx  \\\\\n",
    "                &= \\sum_{j = 0}^{n_x}  f(x_j)  \\phi_k(x_j) \\Delta x_j\n",
    "\\end{align*}\n",
    "Here $\\phi_k(x)$ are orthogonal bases with $$\\int \\phi_i(x) \\overline{\\phi_k(x)} dx = \\delta_{ik},$$ and at the discrete level\n",
    "$$\\sum_{j = 0}^{n_x} \\phi_i(x_j) \\overline{\\phi_j(x_j)} \\Delta x_j = \\delta_{ik}$$\n",
    "\n",
    "\n",
    "\n",
    "We set bases \n",
    "\\begin{equation}\n",
    "B = \n",
    "\\begin{bmatrix}\n",
    "\\phi_0(x_j)  & \\phi_1(x_j)  &  \\cdots &  \\phi_{n_k-1}(x_j)  \n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "and weighted bases \n",
    "\\begin{equation}\n",
    "B = \n",
    "\\begin{bmatrix}\n",
    "\\phi_0(x_j) \\Delta x_j  & \\phi_1(x_j) \\Delta x_j &  \\cdots &  \\phi_{n_k-1}(x_j) \\Delta x_j\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "To recover 2D Fourier Transform, we set \n",
    "\\begin{align*}\n",
    "\\phi_k(x) = \\begin{cases}\n",
    "\\frac{a_{k}}{\\sqrt{L_xL_y}}\\sin(\\frac{2\\pi k_x x}{L_x} + \\frac{2\\pi k_y y}{L_y}) & k_y > 0 \\cup  k_y=0 \\, k_x \\geq 0\\\\ \n",
    "\\frac{a_{k}}{\\sqrt{L_xL_y}}\\cos(\\frac{2\\pi k_x x}{L_x} + \\frac{2\\pi k_y y}{L_y}) & \n",
    "\\end{cases}\n",
    "\\end{align*}\n",
    "with $a_{0,0} = 1$ and $a_{k} = \\sqrt{2}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start SVD with data shape:  (800, 11236)\n",
      "(11236, 800) (800,) (800, 800)\n",
      "(11236, 33) (11236, 33)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "downsample_ratio = 4\n",
    "\n",
    "L = 1.0\n",
    "Np_ref = data_in.shape[1]\n",
    "grid_1d = np.linspace(0, L, Np_ref)\n",
    "grid_x, grid_y = np.meshgrid(grid_1d, grid_1d)\n",
    "\n",
    "\n",
    "n_train, n_test = 800, 200\n",
    "data_in_ds = data_in[0:n_train, 0::downsample_ratio, 0::downsample_ratio]\n",
    "grid_x_ds = grid_x[0::downsample_ratio, 0::downsample_ratio]\n",
    "grid_y_ds = grid_y[0::downsample_ratio, 0::downsample_ratio]\n",
    "data_out_ds = data_out[0:n_train, 0::downsample_ratio, 0::downsample_ratio]\n",
    "\n",
    "\n",
    "x_train = torch.from_numpy(\n",
    "    np.stack(\n",
    "        (\n",
    "            data_in_ds,\n",
    "            np.tile(grid_x_ds, (n_train, 1, 1)),\n",
    "            np.tile(grid_y_ds, (n_train, 1, 1)),\n",
    "        ),\n",
    "        axis=-1,\n",
    "    ).astype(np.float32)\n",
    ")\n",
    "y_train = torch.from_numpy(data_out_ds[:, :, :, np.newaxis].astype(np.float32))\n",
    "\n",
    "\n",
    "x_test = torch.from_numpy(\n",
    "    np.stack(\n",
    "        (\n",
    "            data_in[-n_test:, 0::downsample_ratio, 0::downsample_ratio],\n",
    "            np.tile(grid_x[0::downsample_ratio, 0::downsample_ratio], (n_test, 1, 1)),\n",
    "            np.tile(grid_y[0::downsample_ratio, 0::downsample_ratio], (n_test, 1, 1)),\n",
    "        ),\n",
    "        axis=-1,\n",
    "    ).astype(np.float32)\n",
    ")\n",
    "y_test = torch.from_numpy(\n",
    "    data_out[-n_test:, 0::downsample_ratio, 0::downsample_ratio, np.newaxis].astype(\n",
    "        np.float32\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "n_fno_layers = 3\n",
    "k_max = 33\n",
    "d_f = 128\n",
    "# fourier k_max\n",
    "modes = [k_max] * n_fno_layers\n",
    "# channel d_f\n",
    "layers = [d_f] * (n_fno_layers + 1)\n",
    "fc_dim = d_f\n",
    "in_dim = 3\n",
    "out_dim = 1\n",
    "act = \"gelu\"\n",
    "\n",
    "epochs = 1000\n",
    "base_lr = 0.001\n",
    "\n",
    "\n",
    "milestones = [200, 300, 400, 500, 800, 900]\n",
    "scheduler_gamma = 0.5\n",
    "pad_ratio = 0.05\n",
    "scheduler = \"MultiStepLR\"\n",
    "weight_decay = 1.0e-4\n",
    "# batch_size=32\n",
    "dim = 2\n",
    "\n",
    "# scheduler = \"CosineAnnealingLR\"\n",
    "# weight_decay = 1.0e-4\n",
    "batch_size = 64\n",
    "\n",
    "normalization_x = True\n",
    "normalization_y = True\n",
    "normalization_dim = []\n",
    "\n",
    "\n",
    "basis_type = \"Galerkin_bases\"\n",
    "\n",
    "if basis_type == \"Fast_Fourier_Transform\":\n",
    "\n",
    "    k_max = k_max // 2\n",
    "    modes = [k_max] * n_fno_layers\n",
    "\n",
    "    bases = None\n",
    "    wbases = None\n",
    "    model_type = \"FNO\"\n",
    "else:\n",
    "    # reshape the data\n",
    "    x_train = x_train.reshape(x_train.shape[0], -1, x_train.shape[-1])\n",
    "    x_test = x_test.reshape(x_test.shape[0], -1, x_test.shape[-1])\n",
    "    y_train = y_train.reshape(y_train.shape[0], -1, y_train.shape[-1])\n",
    "    y_test = y_test.reshape(y_test.shape[0], -1, y_test.shape[-1])\n",
    "\n",
    "    model_type = \"GalerkinNO\"\n",
    "    Np = (Np_ref + downsample_ratio - 1) // downsample_ratio\n",
    "    gridx, gridy, fbases, weights = compute_2dFourier_bases(Np, Np, k_max, L, L)\n",
    "\n",
    "    if basis_type == \"Fourier_bases\":\n",
    "        fbases = fbases.reshape(-1, k_max)\n",
    "        weights = weights.reshape(-1)\n",
    "        wfbases = fbases * np.tile(weights, (k_max, 1)).T\n",
    "        bases = [torch.from_numpy(fbases.astype(np.float32))]\n",
    "        wbases = [torch.from_numpy(wfbases.astype(np.float32))]\n",
    "\n",
    "    elif basis_type == \"Galerkin_bases\":\n",
    "        pca_data = data_out_ds.reshape((data_out_ds.shape[0], -1))\n",
    "        pca_include_input = False\n",
    "        pca_include_grid = False\n",
    "        if pca_include_input:\n",
    "            pca_data = np.vstack(\n",
    "                (pca_data, data_in_ds.reshape((data_in_ds.shape[0], -1)))\n",
    "            )\n",
    "        if pca_include_grid:\n",
    "            n_grid = 1\n",
    "            pca_data = np.vstack((pca_data, np.tile(grid_x_ds, (n_grid, 1))))\n",
    "            pca_data = np.vstack((pca_data, np.tile(grid_y_ds, (n_grid, 1))))\n",
    "        print(\"Start SVD with data shape: \", pca_data.shape)\n",
    "        U, S, VT = np.linalg.svd(pca_data.T, full_matrices=False)\n",
    "        print(U.shape, S.shape, VT.shape)\n",
    "        # the integration of the basis is 1.\n",
    "        fbases = U[:, 0:k_max] / np.sqrt(L * L / Np**2)\n",
    "        wfbases = L * L / Np**2 * fbases\n",
    "        print(fbases.shape,wfbases.shape)\n",
    "        bases = [torch.from_numpy(fbases.astype(np.float32))]\n",
    "        wbases = [torch.from_numpy(wfbases.astype(np.float32))]\n",
    "\n",
    "    else:\n",
    "\n",
    "        print(\"Bases construction error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"model\": {\n",
    "        \"model\": model_type,\n",
    "        \"dim\": dim,\n",
    "        \"modes\": modes,\n",
    "        \"fc_dim\": fc_dim,\n",
    "        \"layers\": layers,\n",
    "        \"in_dim\": in_dim,\n",
    "        \"out_dim\": out_dim,\n",
    "        \"act\": act,\n",
    "        \"pad_ratio\": pad_ratio,\n",
    "    },\n",
    "    \"train\": {\n",
    "        \"base_lr\": base_lr,\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"epochs\": epochs,\n",
    "        \"scheduler\": scheduler,\n",
    "        \"milestones\": milestones,\n",
    "        \"scheduler_gamma\": scheduler_gamma,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"normalization_x\": normalization_x,\n",
    "        \"normalization_y\": normalization_y,\n",
    "        \"normalization_dim\": normalization_dim,\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "model = construct_model(config, bases, wbases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Start training \", config[\"model\"][\"model\"])\n",
    "print(\"x_train shape: \", x_train.shape, \"y_train shape: \", y_train.shape)\n",
    "print(\"x_test shape: \", x_train.shape, \"y_test shape: \", y_train.shape)\n",
    "\n",
    "train_rel_l2_losses, test_rel_l2_losses, test_l2_losses, cost = FNN_train(\n",
    "    x_train, y_train, x_test, y_test, config, model, save_model_name=\"models/test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Start training  GalerkinNO\n",
    "Epoch :  0  Rel. Train L2 Loss :  0.5530278962105513  Rel. Test L2 Loss :  0.3639783691614866  Test L2 Loss :  0.16688358411192894\n",
    "Epoch :  10  Rel. Train L2 Loss :  0.05540479300543666  Rel. Test L2 Loss :  0.06010106788016856  Test L2 Loss :  0.027525703771971166\n",
    "Epoch :  20  Rel. Train L2 Loss :  0.02729798946529627  Rel. Test L2 Loss :  0.030181090580299497  Test L2 Loss :  0.014549962885212153\n",
    "Epoch :  30  Rel. Train L2 Loss :  0.023524480871856213  Rel. Test L2 Loss :  0.02733145747333765  Test L2 Loss :  0.012954483041539788\n",
    "Epoch :  40  Rel. Train L2 Loss :  0.03390151506755501  Rel. Test L2 Loss :  0.032641293248161674  Test L2 Loss :  0.014019099180586636\n",
    "Epoch :  50  Rel. Train L2 Loss :  0.028370561194606125  Rel. Test L2 Loss :  0.02992247836664319  Test L2 Loss :  0.013746349257417023\n",
    "Epoch :  60  Rel. Train L2 Loss :  0.016377027553971857  Rel. Test L2 Loss :  0.02047357289120555  Test L2 Loss :  0.009557288809446618\n",
    "Epoch :  70  Rel. Train L2 Loss :  0.016247911378741264  Rel. Test L2 Loss :  0.0221169067081064  Test L2 Loss :  0.009881779027637094\n",
    "Epoch :  80  Rel. Train L2 Loss :  0.018533223308622837  Rel. Test L2 Loss :  0.019773047999478877  Test L2 Loss :  0.009210543415974826\n",
    "Epoch :  90  Rel. Train L2 Loss :  0.014880945847835392  Rel. Test L2 Loss :  0.0222996415104717  Test L2 Loss :  0.01034952379995957\n",
    "Epoch :  100  Rel. Train L2 Loss :  0.023593697929754853  Rel. Test L2 Loss :  0.026125550735741854  Test L2 Loss :  0.012204635073430836\n",
    "Epoch :  110  Rel. Train L2 Loss :  0.0163455773727037  Rel. Test L2 Loss :  0.019539905828423798  Test L2 Loss :  0.009263549611205235\n",
    "Epoch :  120  Rel. Train L2 Loss :  0.012967587856110185  Rel. Test L2 Loss :  0.020988903241232038  Test L2 Loss :  0.009709200297947973\n",
    "Epoch :  130  Rel. Train L2 Loss :  0.014892612001858652  Rel. Test L2 Loss :  0.021787052624858916  Test L2 Loss :  0.009926729835569859\n",
    "Epoch :  140  Rel. Train L2 Loss :  0.022582464618608356  Rel. Test L2 Loss :  0.03254837263375521  Test L2 Loss :  0.014737804944161326\n",
    "Epoch :  150  Rel. Train L2 Loss :  0.017551998258568347  Rel. Test L2 Loss :  0.01922531088348478  Test L2 Loss :  0.008974029566161335\n",
    "Epoch :  160  Rel. Train L2 Loss :  0.01702975877560675  Rel. Test L2 Loss :  0.01916457514744252  Test L2 Loss :  0.00896387847024016\n",
    "Epoch :  170  Rel. Train L2 Loss :  0.01095853850711137  Rel. Test L2 Loss :  0.011898183031007648  Test L2 Loss :  0.005927028658334166\n",
    "Epoch :  180  Rel. Train L2 Loss :  0.01998165505938232  Rel. Test L2 Loss :  0.026575087918899953  Test L2 Loss :  0.012266059755347669\n",
    "Epoch :  190  Rel. Train L2 Loss :  0.010873873543459922  Rel. Test L2 Loss :  0.014671170676592737  Test L2 Loss :  0.007119098474504426\n",
    "Epoch :  200  Rel. Train L2 Loss :  0.01028971589403227  Rel. Test L2 Loss :  0.013454765372443944  Test L2 Loss :  0.006566085590748116\n",
    "Epoch :  210  Rel. Train L2 Loss :  0.006467006693128496  Rel. Test L2 Loss :  0.011402946896851063  Test L2 Loss :  0.0056951247388496995\n",
    "Epoch :  220  Rel. Train L2 Loss :  0.007936486625112593  Rel. Test L2 Loss :  0.010351956530939788  Test L2 Loss :  0.005171463039005175\n",
    "Epoch :  230  Rel. Train L2 Loss :  0.005818177392939106  Rel. Test L2 Loss :  0.009853201336227357  Test L2 Loss :  0.005036661037593149\n",
    "Epoch :  240  Rel. Train L2 Loss :  0.011104872624855489  Rel. Test L2 Loss :  0.01421331736491993  Test L2 Loss :  0.006690551701467484\n",
    "Epoch :  250  Rel. Train L2 Loss :  0.007700835034484044  Rel. Test L2 Loss :  0.010917078296188265  Test L2 Loss :  0.005546584783587605\n",
    "Epoch :  260  Rel. Train L2 Loss :  0.0068678474926855415  Rel. Test L2 Loss :  0.011556127166841179  Test L2 Loss :  0.005775771656772122\n",
    "Epoch :  270  Rel. Train L2 Loss :  0.006902240013005212  Rel. Test L2 Loss :  0.011474454251583666  Test L2 Loss :  0.005823984072776511\n",
    "Epoch :  280  Rel. Train L2 Loss :  0.007895537943113595  Rel. Test L2 Loss :  0.011459440807811916  Test L2 Loss :  0.005707353935576975\n",
    "Epoch :  290  Rel. Train L2 Loss :  0.007066981052048504  Rel. Test L2 Loss :  0.012559539813082665  Test L2 Loss :  0.0060487362497951835\n",
    "Epoch :  300  Rel. Train L2 Loss :  0.007625468191690743  Rel. Test L2 Loss :  0.009424212155863643  Test L2 Loss :  0.004864282789640129\n",
    "Epoch :  310  Rel. Train L2 Loss :  0.0034248315932927653  Rel. Test L2 Loss :  0.008168773783836514  Test L2 Loss :  0.004320120162446983\n",
    "Epoch :  320  Rel. Train L2 Loss :  0.0033389161253580824  Rel. Test L2 Loss :  0.008337368431966752  Test L2 Loss :  0.0043621797958621755\n",
    "Epoch :  330  Rel. Train L2 Loss :  0.0035498587385518476  Rel. Test L2 Loss :  0.008126365311909467  Test L2 Loss :  0.004305309703340754\n",
    "Epoch :  340  Rel. Train L2 Loss :  0.0035115051723551005  Rel. Test L2 Loss :  0.008424282394116744  Test L2 Loss :  0.004376467477413826\n",
    "Epoch :  350  Rel. Train L2 Loss :  0.0035720229643629864  Rel. Test L2 Loss :  0.008311846031574532  Test L2 Loss :  0.004340929983300157\n",
    "Epoch :  360  Rel. Train L2 Loss :  0.0037024067278252915  Rel. Test L2 Loss :  0.008369034912902862  Test L2 Loss :  0.004366784778540023\n",
    "Epoch :  370  Rel. Train L2 Loss :  0.003762367312447168  Rel. Test L2 Loss :  0.008014965802431107  Test L2 Loss :  0.00422419115784578\n",
    "Epoch :  380  Rel. Train L2 Loss :  0.005504093074705452  Rel. Test L2 Loss :  0.011670866864733398  Test L2 Loss :  0.0056989417935255915\n",
    "Epoch :  390  Rel. Train L2 Loss :  0.0038136375951580703  Rel. Test L2 Loss :  0.008301144553115591  Test L2 Loss :  0.004283903515897691"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fourier bases\n",
    "\n",
    "Epoch :  0  Rel. Train L2 Loss :  0.5343242827802896  Rel. Test L2 Loss :  0.35652035661041737  Test L2 Loss :  0.16434418968856335\n",
    "Epoch :  10  Rel. Train L2 Loss :  0.05252824304625392  Rel. Test L2 Loss :  0.08707353239879012  Test L2 Loss :  0.038476263638585806\n",
    "Epoch :  20  Rel. Train L2 Loss :  0.03379512997344136  Rel. Test L2 Loss :  0.034905026433989406  Test L2 Loss :  0.016287033446133137\n",
    "Epoch :  30  Rel. Train L2 Loss :  0.03300807299092412  Rel. Test L2 Loss :  0.035803209990262985  Test L2 Loss :  0.0160839143791236\n",
    "Epoch :  40  Rel. Train L2 Loss :  0.02496281557250768  Rel. Test L2 Loss :  0.031191959278658032  Test L2 Loss :  0.01455920428270474\n",
    "Epoch :  50  Rel. Train L2 Loss :  0.019304369459860027  Rel. Test L2 Loss :  0.025718713994137943  Test L2 Loss :  0.01162591646425426\n",
    "Epoch :  60  Rel. Train L2 Loss :  0.019517153152264655  Rel. Test L2 Loss :  0.022306667640805244  Test L2 Loss :  0.010376633668784052\n",
    "Epoch :  70  Rel. Train L2 Loss :  0.02815706399269402  Rel. Test L2 Loss :  0.024218744249083102  Test L2 Loss :  0.011378672847058624\n",
    "Epoch :  80  Rel. Train L2 Loss :  0.01887817436363548  Rel. Test L2 Loss :  0.02192652691155672  Test L2 Loss :  0.01027321710716933\n",
    "Epoch :  90  Rel. Train L2 Loss :  0.01543609204236418  Rel. Test L2 Loss :  0.027948095579631627  Test L2 Loss :  0.012622756243217736\n",
    "Epoch :  100  Rel. Train L2 Loss :  0.018864598590880632  Rel. Test L2 Loss :  0.022070111241191626  Test L2 Loss :  0.010092632728628814\n",
    "Epoch :  110  Rel. Train L2 Loss :  0.01430836075451225  Rel. Test L2 Loss :  0.022063812939450145  Test L2 Loss :  0.010145931446459144\n",
    "Epoch :  120  Rel. Train L2 Loss :  0.025544452480971813  Rel. Test L2 Loss :  0.027506385231390595  Test L2 Loss :  0.012613549712114036"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Start training  FNO\n",
    "x_train shape:  torch.Size([800, 106, 106, 3]) y_train shape:  torch.Size([800, 106, 106, 1])\n",
    "x_test shape:  torch.Size([800, 106, 106, 3]) y_test shape:  torch.Size([800, 106, 106, 1])\n",
    "Epoch :  0  Rel. Train L2 Loss :  0.4634079229831696  Rel. Test L2 Loss :  0.2793087589740753  Test L2 Loss :  0.0018948454689234496\n",
    "Epoch :  10  Rel. Train L2 Loss :  0.036598108410835266  Rel. Test L2 Loss :  0.039496539533138274  Test L2 Loss :  0.0002694653638172895"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
