message_exact = torch.einsum('bei, be->bei', f[torch.arange(batch_size).unsqueeze(1),source], node_weights[...,m])
f_out.scatter_add_(dim=1, src=message_exact*(-inv_r), index=target.unsqueeze(2).repeat(1,1,in_channels))



(1000,) (1000, 1000, 1) (1000, 1000, 2)
use normalized raw measures
Preprocessing data : computing close_node_pairs
100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:15<00:00, 63.30it/s]
maximum number of close node pairs is  10000
Casting to tensor
x train:torch.Size([900, 1000, 8]), y train:torch.Size([900, 1000, 1]), x test:torch.Size([100, 1000, 8]), y test:torch.Size([100, 1000, 1])
length of each dim:  tensor([6.5573987960815430, 6.1420288085937500])
kmax = 8, kmax_local = 8
L =  10  L_local =  0.5
In PCNO_train, ndims =  2
Epoch :  0  Time:  1.336  Rel. Train L2 Loss :  0.5013441067271762  Rel. Test L2 Loss :  0.3553750169277191  Test L2 Loss :  0.507995058298111  inv_L_scale:  [1.0, 1.0]
Epoch :  1  Time:  0.978  Rel. Train L2 Loss :  0.299465954568651  Rel. Test L2 Loss :  0.24465395212173463  Test L2 Loss :  0.35073511362075804  inv_L_scale:  [1.0, 1.0]
Epoch :  2  Time:  0.973  Rel. Train L2 Loss :  0.22275325708919103  Rel. Test L2 Loss :  0.20590702056884766  Test L2 Loss :  0.2927472805976868  inv_L_scale:  [1.0, 1.0]
Epoch :  3  Time:  0.982  Rel. Train L2 Loss :  0.19485503746403587  Rel. Test L2 Loss :  0.18086140632629394  Test L2 Loss :  0.2605157941579819  inv_L_scale:  [1.0, 1.0]
Epoch :  4  Time:  0.996  Rel. Train L2 Loss :  0.17988258315457237  Rel. Test L2 Loss :  0.17780037999153137  Test L2 Loss :  0.2564575546979904  inv_L_scale:  [1.0, 1.0]
Epoch :  5  Time:  0.96  Rel. Train L2 Loss :  0.17409131202432845  Rel. Test L2 Loss :  0.1755785197019577  Test L2 Loss :  0.25022202253341674  inv_L_scale:  [1.0, 1.0]
Epoch :  6  Time:  0.969  Rel. Train L2 Loss :  0.16790264858139886  Rel. Test L2 Loss :  0.1573523223400116  Test L2 Loss :  0.2271886098384857  inv_L_scale:  [1.0, 1.0]
Epoch :  7  Time:  1.023  Rel. Train L2 Loss :  0.16273773796028562  Rel. Test L2 Loss :  0.15961464166641234  Test L2 Loss :  0.23063656747341155  inv_L_scale:  [1.0, 1.0]
Epoch :  8  Time:  0.994  Rel. Train L2 Loss :  0.16245885252952574  Rel. Test L2 Loss :  0.16069880723953248  Test L2 Loss :  0.2318403923511505  inv_L_scale:  [1.0, 1.0]
Epoch :  9  Time:  1.035  Rel. Train L2 Loss :  0.15950157394011816  Rel. Test L2 Loss :  0.15852587461471557  Test L2 Loss :  0.22829752862453462  inv_L_scale:  [1.0, 1.0]
Epoch :  10  Time:  0.966  Rel. Train L2 Loss :  0.15704779830243853  Rel. Test L2 Loss :  0.15300300240516662  Test L2 Loss :  0.2204328781366348  inv_L_scale:  [1.0, 1.0]
Epoch :  11  Time:  0.987  Rel. Train L2 Loss :  0.15347039308812882  Rel. Test L2 Loss :  0.1491520231962204  Test L2 Loss :  0.21596889495849608  inv_L_scale:  [1.0, 1.0]
Epoch :  12  Time:  0.967  Rel. Train L2 Loss :  0.15321352183818818  Rel. Test L2 Loss :  0.1489020973443985  Test L2 Loss :  0.21518123865127564  inv_L_scale:  [1.0, 1.0]
Epoch :  13  Time:  0.967  Rel. Train L2 Loss :  0.15249407794740466  Rel. Test L2 Loss :  0.14654078364372253  Test L2 Loss :  0.211540784239769  inv_L_scale:  [1.0, 1.0]
Epoch :  14  Time:  0.978  Rel. Train L2 Loss :  0.15249112390809588  Rel. Test L2 Loss :  0.15119847476482393  Test L2 Loss :  0.21797405660152436  inv_L_scale:  [1.0, 1.0]
Epoch :  15  Time:  0.973  Rel. Train L2 Loss :  0.15120555275016362  Rel. Test L2 Loss :  0.1538507515192032  Test L2 Loss :  0.22120687007904052  inv_L_scale:  [1.0, 1.0]
Epoch :  16  Time:  0.999  Rel. Train L2 Loss :  0.14874309798081717  Rel. Test L2 Loss :  0.14428384900093078  Test L2 Loss :  0.20817874431610106  inv_L_scale:  [1.0, 1.0]
Epoch :  17  Time:  0.965  Rel. Train L2 Loss :  0.149815247853597  Rel. Test L2 Loss :  0.1448645532131195  Test L2 Loss :  0.20848673224449157  inv_L_scale:  [1.0, 1.0]
Epoch :  18  Time:  0.978  Rel. Train L2 Loss :  0.14655013269848294  Rel. Test L2 Loss :  0.14699783205986022  Test L2 Loss :  0.2128152358531952  inv_L_scale:  [1.0, 1.0]
Epoch :  19  Time:  0.988  Rel. Train L2 Loss :  0.1465296087000105  Rel. Test L2 Loss :  0.14941217482089997  Test L2 Loss :  0.21523135423660278  inv_L_scale:  [1.0, 1.0]
Epoch :  20  Time:  0.982  Rel. Train L2 Loss :  0.14785932693216536  Rel. Test L2 Loss :  0.14731290876865388  Test L2 Loss :  0.21196525037288666  inv_L_scale:  [1.0, 1.0]
Epoch :  21  Time:  0.987  Rel. Train L2 Loss :  0.14582027832667033  Rel. Test L2 Loss :  0.1498880249261856  Test L2 Loss :  0.2183445328474045  inv_L_scale:  [1.0, 1.0]
Epoch :  22  Time:  0.996  Rel. Train L2 Loss :  0.1491593768199285  Rel. Test L2 Loss :  0.1426910799741745  Test L2 Loss :  0.2065773183107376  inv_L_scale:  [1.0, 1.0]
Epoch :  23  Time:  1.024  Rel. Train L2 Loss :  0.1451245387395223  Rel. Test L2 Loss :  0.1393429583311081  Test L2 Loss :  0.20250409126281738  inv_L_scale:  [1.0, 1.0]
Epoch :  24  Time:  1.026  Rel. Train L2 Loss :  0.14640097445911832  Rel. Test L2 Loss :  0.14210471987724305  Test L2 Loss :  0.20598098874092102  inv_L_scale:  [1.0, 1.0]
Epoch :  25  Time:  0.975  Rel. Train L2 Loss :  0.14473603275087144  Rel. Test L2 Loss :  0.14542367339134216  Test L2 Loss :  0.21072511553764342  inv_L_scale:  [1.0, 1.0]
Epoch :  26  Time:  0.973  Rel. Train L2 Loss :  0.1454928035206265  Rel. Test L2 Loss :  0.14072917580604552  Test L2 Loss :  0.2032982051372528  inv_L_scale:  [1.0, 1.0]
Epoch :  27  Time:  0.963  Rel. Train L2 Loss :  0.14479152176115248  Rel. Test L2 Loss :  0.14344206273555757  Test L2 Loss :  0.20784929037094116  inv_L_scale:  [1.0, 1.0]
Epoch :  28  Time:  1.018  Rel. Train L2 Loss :  0.1441469026936425  Rel. Test L2 Loss :  0.14244684278964997  Test L2 Loss :  0.20666584074497224  inv_L_scale:  [1.0, 1.0]
Epoch :  29  Time:  1.023  Rel. Train L2 Loss :  0.14414957377645704  Rel. Test L2 Loss :  0.14457106053829194  Test L2 Loss :  0.20952962279319765  inv_L_scale:  [1.0, 1.0]
Epoch :  30  Time:  0.979  Rel. Train L2 Loss :  0.14340746521949768  Rel. Test L2 Loss :  0.1423519879579544  Test L2 Loss :  0.2058698570728302  inv_L_scale:  [1.0, 1.0]
Epoch :  31  Time:  0.976  Rel. Train L2 Loss :  0.14250202973683676  Rel. Test L2 Loss :  0.1392612886428833  Test L2 Loss :  0.2016158092021942  inv_L_scale:  [1.0, 1.0]
Epoch :  32  Time:  0.962  Rel. Train L2 Loss :  0.14394899053706064  Rel. Test L2 Loss :  0.14149410247802735  Test L2 Loss :  0.20487393379211427  inv_L_scale:  [1.0, 1.0]
Epoch :  33  Time:  0.988  Rel. Train L2 Loss :  0.14294472138086955  Rel. Test L2 Loss :  0.15029456615447997  Test L2 Loss :  0.2163248610496521  inv_L_scale:  [1.0, 1.0]
Epoch :  34  Time:  0.977  Rel. Train L2 Loss :  0.14343836996290418  Rel. Test L2 Loss :  0.14230239391326904  Test L2 Loss :  0.20608984231948851  inv_L_scale:  [1.0, 1.0]
Epoch :  35  Time:  0.963  Rel. Train L2 Loss :  0.14214027841885885  Rel. Test L2 Loss :  0.14141043841838838  Test L2 Loss :  0.20600835382938384  inv_L_scale:  [1.0, 1.0]
Epoch :  36  Time:  0.97  Rel. Train L2 Loss :  0.14238115893469916  Rel. Test L2 Loss :  0.1362031000852585  Test L2 Loss :  0.19754119992256164  inv_L_scale:  [1.0, 1.0]
Epoch :  37  Time:  0.961  Rel. Train L2 Loss :  0.14318022052447002  Rel. Test L2 Loss :  0.14082231342792512  Test L2 Loss :  0.20407625854015352  inv_L_scale:  [1.0, 1.0]
Epoch :  38  Time:  0.964  Rel. Train L2 Loss :  0.1415821137693193  Rel. Test L2 Loss :  0.1390039664506912  Test L2 Loss :  0.20133665978908538  inv_L_scale:  [1.0, 1.0]
Epoch :  39  Time:  0.961  Rel. Train L2 Loss :  0.14219506015380223  Rel. Test L2 Loss :  0.14190471410751343  Test L2 Loss :  0.20471327245235443  inv_L_scale:  [1.0, 1.0]
Epoch :  40  Time:  0.997  Rel. Train L2 Loss :  0.1417900514602661  Rel. Test L2 Loss :  0.1409492987394333  Test L2 Loss :  0.2036896139383316  inv_L_scale:  [1.0, 1.0]
Epoch :  41  Time:  0.964  Rel. Train L2 Loss :  0.14275882651408514  Rel. Test L2 Loss :  0.14071160018444062  Test L2 Loss :  0.20366015315055847  inv_L_scale:  [1.0, 1.0]
Epoch :  42  Time:  0.961  Rel. Train L2 Loss :  0.14153414534197914  Rel. Test L2 Loss :  0.1394951969385147  Test L2 Loss :  0.20223261237144471  inv_L_scale:  [1.0, 1.0]
Epoch :  43  Time:  0.964  Rel. Train L2 Loss :  0.14128518693976932  Rel. Test L2 Loss :  0.14423520088195801  Test L2 Loss :  0.2082776176929474  inv_L_scale:  [1.0, 1.0]
Epoch :  44  Time:  1.016  Rel. Train L2 Loss :  0.14241614162921906  Rel. Test L2 Loss :  0.1387439626455307  Test L2 Loss :  0.20158599853515624  inv_L_scale:  [1.0, 1.0]
Epoch :  45  Time:  1.016  Rel. Train L2 Loss :  0.1408920712603463  Rel. Test L2 Loss :  0.1375477522611618  Test L2 Loss :  0.20021563410758972  inv_L_scale:  [1.0, 1.0]
Epoch :  46  Time:  0.987  Rel. Train L2 Loss :  0.14066318564944796  Rel. Test L2 Loss :  0.1398057061433792  Test L2 Loss :  0.20259811103343964  inv_L_scale:  [1.0, 1.0]
Epoch :  47  Time:  0.979  Rel. Train L2 Loss :  0.14096910880671606  Rel. Test L2 Loss :  0.13694223284721374  Test L2 Loss :  0.1989912736415863  inv_L_scale:  [1.0, 1.0]
Epoch :  48  Time:  0.977  Rel. Train L2 Loss :  0.14088765992058647  Rel. Test L2 Loss :  0.1416330349445343  Test L2 Loss :  0.20526161968708037  inv_L_scale:  [1.0, 1.0]
Epoch :  49  Time:  1.032  Rel. Train L2 Loss :  0.14074634651343026  Rel. Test L2 Loss :  0.14299142599105835  Test L2 Loss :  0.2067646324634552  inv_L_scale:  [1.0, 1.0]
Epoch :  50  Time:  0.971  Rel. Train L2 Loss :  0.14059500522083707  Rel. Test L2 Loss :  0.13926951229572296  Test L2 Loss :  0.2018078261613846  inv_L_scale:  [1.0, 1.0]
Epoch :  51  Time:  1.106  Rel. Train L2 Loss :  0.14159781489107343  Rel. Test L2 Loss :  0.1396261566877365  Test L2 Loss :  0.20205416560173034  inv_L_scale:  [1.0, 1.0]
Epoch :  52  Time:  0.987  Rel. Train L2 Loss :  0.14230607009596294  Rel. Test L2 Loss :  0.13665188550949098  Test L2 Loss :  0.19901373147964477  inv_L_scale:  [1.0, 1.0]
Epoch :  53  Time:  0.967  Rel. Train L2 Loss :  0.14046931193934548  Rel. Test L2 Loss :  0.1376281839609146  Test L2 Loss :  0.19995147824287415  inv_L_scale:  [1.0, 1.0]
Epoch :  54  Time:  0.965  Rel. Train L2 Loss :  0.14115731272432538  Rel. Test L2 Loss :  0.14262257277965545  Test L2 Loss :  0.206456715464592  inv_L_scale:  [1.0, 1.0]
Epoch :  55  Time:  0.973  Rel. Train L2 Loss :  0.14074999299314286  Rel. Test L2 Loss :  0.13604125380516052  Test L2 Loss :  0.1979793632030487  inv_L_scale:  [1.0, 1.0]
Epoch :  56  Time:  0.973  Rel. Train L2 Loss :  0.1403267749812868  Rel. Test L2 Loss :  0.1391257679462433  Test L2 Loss :  0.20184351980686188  inv_L_scale:  [1.0, 1.0]
Epoch :  57  Time:  0.967  Rel. Train L2 Loss :  0.1404341491394573  Rel. Test L2 Loss :  0.13839859783649444  Test L2 Loss :  0.20060719788074494  inv_L_scale:  [1.0, 1.0]
Epoch :  58  Time:  0.965  Rel. Train L2 Loss :  0.1405396051208178  Rel. Test L2 Loss :  0.1395642328262329  Test L2 Loss :  0.202101868391037  inv_L_scale:  [1.0, 1.0]
Epoch :  59  Time:  0.979  Rel. Train L2 Loss :  0.13924324989318848  Rel. Test L2 Loss :  0.13648460268974305  Test L2 Loss :  0.19827200829982758  inv_L_scale:  [1.0, 1.0]
Epoch :  60  Time:  0.963  Rel. Train L2 Loss :  0.13960463292068906  Rel. Test L2 Loss :  0.13748428761959075  Test L2 Loss :  0.19964198708534242  inv_L_scale:  [1.0, 1.0]
Epoch :  61  Time:  0.971  Rel. Train L2 Loss :  0.13966282255119747  Rel. Test L2 Loss :  0.13830411016941072  Test L2 Loss :  0.20086001515388488  inv_L_scale:  [1.0, 1.0]
Epoch :  62  Time:  0.96  Rel. Train L2 Loss :  0.1398095308409797  Rel. Test L2 Loss :  0.13672951757907867  Test L2 Loss :  0.19959429264068604  inv_L_scale:  [1.0, 1.0]
Epoch :  63  Time:  0.963  Rel. Train L2 Loss :  0.1394697544309828  Rel. Test L2 Loss :  0.13541230618953704  Test L2 Loss :  0.19757428407669067  inv_L_scale:  [1.0, 1.0]
Epoch :  64  Time:  0.964  Rel. Train L2 Loss :  0.13839374283949535  Rel. Test L2 Loss :  0.13606061100959776  Test L2 Loss :  0.19757806420326232  inv_L_scale:  [1.0, 1.0]
Epoch :  65  Time:  1.042  Rel. Train L2 Loss :  0.13991788781351513  Rel. Test L2 Loss :  0.1358117300271988  Test L2 Loss :  0.1969091808795929  inv_L_scale:  [1.0, 1.0]
Epoch :  66  Time:  0.965  Rel. Train L2 Loss :  0.13928609834776984  Rel. Test L2 Loss :  0.13597035825252532  Test L2 Loss :  0.19787560105323793  inv_L_scale:  [1.0, 1.0]
Epoch :  67  Time:  0.964  Rel. Train L2 Loss :  0.13858111566967435  Rel. Test L2 Loss :  0.13596779048442842  Test L2 Loss :  0.1973622715473175  inv_L_scale:  [1.0, 1.0]
Epoch :  68  Time:  0.962  Rel. Train L2 Loss :  0.13944895287354786  Rel. Test L2 Loss :  0.13598631381988524  Test L2 Loss :  0.19792953073978425  inv_L_scale:  [1.0, 1.0]