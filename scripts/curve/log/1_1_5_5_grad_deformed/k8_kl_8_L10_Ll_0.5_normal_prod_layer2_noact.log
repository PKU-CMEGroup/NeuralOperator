(1000,) (1000, 1000, 1) (1000, 1000, 2)
use normalized raw measures
Preprocessing data : computing close_node_pairs
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:15<00:00, 63.47it/s] 
maximum number of close node pairs is  10000
Casting to tensor
x train:torch.Size([900, 1000, 8]), y train:torch.Size([900, 1000, 1]), x test:torch.Size([100, 1000, 8]), y test:torch.Size([100, 1000, 1])
length of each dim:  tensor([6.5573987960815430, 6.1420288085937500])
kmax = 8, kmax_local = 8
L =  10  L_local =  0.5
In PCNO_train, ndims =  2
Epoch :  0  Time:  1.913  Rel. Train L2 Loss :  0.5015360713005066  Rel. Test L2 Loss :  0.35607605934143066  Test L2 Loss :  0.5090445613861084  inv_L_scale:  [1.0, 1.0]
Epoch :  1  Time:  1.512  Rel. Train L2 Loss :  0.3003350857893626  Rel. Test L2 Loss :  0.24556247234344483  Test L2 Loss :  0.3521004581451416  inv_L_scale:  [1.0, 1.0]
Epoch :  2  Time:  1.536  Rel. Train L2 Loss :  0.22404999123679267  Rel. Test L2 Loss :  0.20710953891277314  Test L2 Loss :  0.2944756591320038  inv_L_scale:  [1.0, 1.0]
Epoch :  3  Time:  1.583  Rel. Train L2 Loss :  0.19647097607453665  Rel. Test L2 Loss :  0.18212284564971923  Test L2 Loss :  0.2623800843954086  inv_L_scale:  [1.0, 1.0]
Epoch :  4  Time:  1.531  Rel. Train L2 Loss :  0.18145749767621358  Rel. Test L2 Loss :  0.18015424609184266  Test L2 Loss :  0.25979097723960876  inv_L_scale:  [1.0, 1.0]
Epoch :  5  Time:  1.547  Rel. Train L2 Loss :  0.17620949996842278  Rel. Test L2 Loss :  0.17630862236022948  Test L2 Loss :  0.2512654399871826  inv_L_scale:  [1.0, 1.0]
Epoch :  6  Time:  1.538  Rel. Train L2 Loss :  0.17001612133449978  Rel. Test L2 Loss :  0.1577094328403473  Test L2 Loss :  0.22769136250019073  inv_L_scale:  [1.0, 1.0]
Epoch :  7  Time:  1.531  Rel. Train L2 Loss :  0.16487705051898957  Rel. Test L2 Loss :  0.16338574707508088  Test L2 Loss :  0.23588318169116973  inv_L_scale:  [1.0, 1.0]
Epoch :  8  Time:  1.541  Rel. Train L2 Loss :  0.16517849975162083  Rel. Test L2 Loss :  0.16301536798477173  Test L2 Loss :  0.23531142830848695  inv_L_scale:  [1.0, 1.0]
Epoch :  9  Time:  1.519  Rel. Train L2 Loss :  0.16220383644104003  Rel. Test L2 Loss :  0.16029691219329834  Test L2 Loss :  0.2308443146944046  inv_L_scale:  [1.0, 1.0]
Epoch :  10  Time:  1.528  Rel. Train L2 Loss :  0.15985935621791417  Rel. Test L2 Loss :  0.15553635954856873  Test L2 Loss :  0.224355331659317  inv_L_scale:  [1.0, 1.0]
Epoch :  11  Time:  1.537  Rel. Train L2 Loss :  0.15669616083304086  Rel. Test L2 Loss :  0.15281038701534272  Test L2 Loss :  0.22120099663734435  inv_L_scale:  [1.0, 1.0]
Epoch :  12  Time:  1.525  Rel. Train L2 Loss :  0.15506681422392526  Rel. Test L2 Loss :  0.14955179870128632  Test L2 Loss :  0.21620675325393676  inv_L_scale:  [1.0, 1.0]
Epoch :  13  Time:  1.535  Rel. Train L2 Loss :  0.15472605817847782  Rel. Test L2 Loss :  0.14929719567298888  Test L2 Loss :  0.21544186711311342  inv_L_scale:  [1.0, 1.0]
Epoch :  14  Time:  1.536  Rel. Train L2 Loss :  0.154449789027373  Rel. Test L2 Loss :  0.1542389577627182  Test L2 Loss :  0.22199175655841827  inv_L_scale:  [1.0, 1.0]
Epoch :  15  Time:  1.527  Rel. Train L2 Loss :  0.15310726934009128  Rel. Test L2 Loss :  0.15607537269592286  Test L2 Loss :  0.22432915925979613  inv_L_scale:  [1.0, 1.0]
Epoch :  16  Time:  1.531  Rel. Train L2 Loss :  0.15122170031070709  Rel. Test L2 Loss :  0.14731393337249757  Test L2 Loss :  0.2126046460866928  inv_L_scale:  [1.0, 1.0]
Epoch :  17  Time:  1.536  Rel. Train L2 Loss :  0.1521397269434399  Rel. Test L2 Loss :  0.14783316135406493  Test L2 Loss :  0.21256203532218934  inv_L_scale:  [1.0, 1.0]
Epoch :  18  Time:  1.546  Rel. Train L2 Loss :  0.1493756651216083  Rel. Test L2 Loss :  0.14876238703727723  Test L2 Loss :  0.2152017116546631  inv_L_scale:  [1.0, 1.0]
Epoch :  19  Time:  1.567  Rel. Train L2 Loss :  0.14879578014214834  Rel. Test L2 Loss :  0.15045299172401427  Test L2 Loss :  0.21653009533882142  inv_L_scale:  [1.0, 1.0]
Epoch :  20  Time:  1.537  Rel. Train L2 Loss :  0.15008877356847128  Rel. Test L2 Loss :  0.14876595556735991  Test L2 Loss :  0.21422635793685912  inv_L_scale:  [1.0, 1.0]
Epoch :  21  Time:  1.54  Rel. Train L2 Loss :  0.14837476631005606  Rel. Test L2 Loss :  0.15262381315231324  Test L2 Loss :  0.222265625  inv_L_scale:  [1.0, 1.0]
Epoch :  22  Time:  1.533  Rel. Train L2 Loss :  0.1512091991636488  Rel. Test L2 Loss :  0.14534081995487214  Test L2 Loss :  0.2103321534395218  inv_L_scale:  [1.0, 1.0]
Epoch :  23  Time:  1.536  Rel. Train L2 Loss :  0.14711139722002878  Rel. Test L2 Loss :  0.1409023869037628  Test L2 Loss :  0.20460530996322632  inv_L_scale:  [1.0, 1.0]
Epoch :  24  Time:  1.526  Rel. Train L2 Loss :  0.14784090565310584  Rel. Test L2 Loss :  0.144054656624794  Test L2 Loss :  0.20889323353767394  inv_L_scale:  [1.0, 1.0]
Epoch :  25  Time:  1.56  Rel. Train L2 Loss :  0.14724025514390734  Rel. Test L2 Loss :  0.14906652688980102  Test L2 Loss :  0.2157222104072571  inv_L_scale:  [1.0, 1.0]
Epoch :  26  Time:  1.532  Rel. Train L2 Loss :  0.1480410299036238  Rel. Test L2 Loss :  0.14313623666763306  Test L2 Loss :  0.20672117531299591  inv_L_scale:  [1.0, 1.0]
Epoch :  27  Time:  1.532  Rel. Train L2 Loss :  0.14694622529877557  Rel. Test L2 Loss :  0.14522675037384034  Test L2 Loss :  0.21079444885253906  inv_L_scale:  [1.0, 1.0]
Epoch :  28  Time:  1.545  Rel. Train L2 Loss :  0.14616946008470325  Rel. Test L2 Loss :  0.1448429888486862  Test L2 Loss :  0.21007393956184386  inv_L_scale:  [1.0, 1.0]
Epoch :  29  Time:  1.527  Rel. Train L2 Loss :  0.1463077336549759  Rel. Test L2 Loss :  0.14659734010696412  Test L2 Loss :  0.21271657824516296  inv_L_scale:  [1.0, 1.0]
Epoch :  30  Time:  1.53  Rel. Train L2 Loss :  0.14566231581899855  Rel. Test L2 Loss :  0.1440094703435898  Test L2 Loss :  0.20808788776397705  inv_L_scale:  [1.0, 1.0]
Epoch :  31  Time:  1.533  Rel. Train L2 Loss :  0.1443705199824439  Rel. Test L2 Loss :  0.14096743881702423  Test L2 Loss :  0.2039680314064026  inv_L_scale:  [1.0, 1.0]
Epoch :  32  Time:  1.532  Rel. Train L2 Loss :  0.14549194041225647  Rel. Test L2 Loss :  0.14155464112758637  Test L2 Loss :  0.2049918591976166  inv_L_scale:  [1.0, 1.0]
Epoch :  33  Time:  1.538  Rel. Train L2 Loss :  0.144886774122715  Rel. Test L2 Loss :  0.1502721357345581  Test L2 Loss :  0.21638269186019898  inv_L_scale:  [1.0, 1.0]
Epoch :  34  Time:  1.55  Rel. Train L2 Loss :  0.14570412854353587  Rel. Test L2 Loss :  0.14422613978385926  Test L2 Loss :  0.20872494637966155  inv_L_scale:  [1.0, 1.0]
Epoch :  35  Time:  1.549  Rel. Train L2 Loss :  0.14430414583947923  Rel. Test L2 Loss :  0.143528134226799  Test L2 Loss :  0.2094181489944458  inv_L_scale:  [1.0, 1.0]
Epoch :  36  Time:  1.538  Rel. Train L2 Loss :  0.14446168031957415  Rel. Test L2 Loss :  0.13808779835700988  Test L2 Loss :  0.20026740312576294  inv_L_scale:  [1.0, 1.0]
Epoch :  37  Time:  1.59  Rel. Train L2 Loss :  0.14492125782701704  Rel. Test L2 Loss :  0.14249761044979095  Test L2 Loss :  0.20640598773956298  inv_L_scale:  [1.0, 1.0]
Epoch :  38  Time:  1.543  Rel. Train L2 Loss :  0.14356802304585775  Rel. Test L2 Loss :  0.14105315685272216  Test L2 Loss :  0.2042249870300293  inv_L_scale:  [1.0, 1.0]
Epoch :  39  Time:  1.528  Rel. Train L2 Loss :  0.1438855188091596  Rel. Test L2 Loss :  0.14281559348106385  Test L2 Loss :  0.20603355646133423  inv_L_scale:  [1.0, 1.0]
Epoch :  40  Time:  1.55  Rel. Train L2 Loss :  0.14356632855203416  Rel. Test L2 Loss :  0.14377888143062592  Test L2 Loss :  0.20753089427948  inv_L_scale:  [1.0, 1.0]
Epoch :  41  Time:  1.53  Rel. Train L2 Loss :  0.14482221060329015  Rel. Test L2 Loss :  0.1418403333425522  Test L2 Loss :  0.20502840101718903  inv_L_scale:  [1.0, 1.0]
Epoch :  42  Time:  1.542  Rel. Train L2 Loss :  0.1430957493517134  Rel. Test L2 Loss :  0.1412368267774582  Test L2 Loss :  0.20459255635738371  inv_L_scale:  [1.0, 1.0]
Epoch :  43  Time:  1.548  Rel. Train L2 Loss :  0.1432595796717538  Rel. Test L2 Loss :  0.14722120225429536  Test L2 Loss :  0.21268204748630523  inv_L_scale:  [1.0, 1.0]
Epoch :  44  Time:  1.533  Rel. Train L2 Loss :  0.14415058235327402  Rel. Test L2 Loss :  0.14049559891223906  Test L2 Loss :  0.20408519148826598  inv_L_scale:  [1.0, 1.0]
Epoch :  45  Time:  1.546  Rel. Train L2 Loss :  0.14267956535021464  Rel. Test L2 Loss :  0.13846455216407777  Test L2 Loss :  0.20139542937278748  inv_L_scale:  [1.0, 1.0]
Epoch :  46  Time:  1.552  Rel. Train L2 Loss :  0.14240126027001274  Rel. Test L2 Loss :  0.14239486217498779  Test L2 Loss :  0.20615705609321594  inv_L_scale:  [1.0, 1.0]
Epoch :  47  Time:  1.533  Rel. Train L2 Loss :  0.14255113058620028  Rel. Test L2 Loss :  0.13829880595207214  Test L2 Loss :  0.20088788866996765  inv_L_scale:  [1.0, 1.0]
Epoch :  48  Time:  1.544  Rel. Train L2 Loss :  0.14265527195400662  Rel. Test L2 Loss :  0.1436859703063965  Test L2 Loss :  0.20803239047527314  inv_L_scale:  [1.0, 1.0]
Epoch :  49  Time:  1.531  Rel. Train L2 Loss :  0.14269036723507775  Rel. Test L2 Loss :  0.14471710503101348  Test L2 Loss :  0.20920259714126588  inv_L_scale:  [1.0, 1.0]
Epoch :  50  Time:  1.539  Rel. Train L2 Loss :  0.14209477292166817  Rel. Test L2 Loss :  0.14146252751350402  Test L2 Loss :  0.20491756200790406  inv_L_scale:  [1.0, 1.0]
Epoch :  51  Time:  1.536  Rel. Train L2 Loss :  0.14270446234279208  Rel. Test L2 Loss :  0.141066358089447  Test L2 Loss :  0.20412096083164216  inv_L_scale:  [1.0, 1.0]
Epoch :  52  Time:  1.536  Rel. Train L2 Loss :  0.14372033241722318  Rel. Test L2 Loss :  0.1380644279718399  Test L2 Loss :  0.20094732344150543  inv_L_scale:  [1.0, 1.0]
Epoch :  53  Time:  1.532  Rel. Train L2 Loss :  0.1418798079755571  Rel. Test L2 Loss :  0.13937794387340546  Test L2 Loss :  0.20212771594524384  inv_L_scale:  [1.0, 1.0]
Epoch :  54  Time:  1.592  Rel. Train L2 Loss :  0.1429177553123898  Rel. Test L2 Loss :  0.14454322278499604  Test L2 Loss :  0.20877129673957825  inv_L_scale:  [1.0, 1.0]