x1 = speconv(fn, bases_c, bases_s, bases_0, wbases_c, wbases_s, wbases_0)
x2 = w(f)
geo_weight1 = self.softsign(geow1(geo))
x = x1 + geo_weight1*x2




(1000,) (1000, 1000, 1) (1000, 1000, 2)
use normalized raw measures
Casting to tensor
x_train shape torch.Size([900, 1000, 8]), y_train shape torch.Size([900, 1000, 1])
length of each dim:  tensor([6.5573987960815430, 6.1420288085937500])
kmax = 16
L = 10
geo_dims = [1, 2, 3, 4]
In PCNO_train, ndims =  2
Epoch :  0  Time:  1.454  Rel. Train L2 Loss :  0.5160444492763944  Rel. Test L2 Loss :  0.316374214887619  Test L2 Loss :  0.4525326728820801  inv_L_scale:  [1.0, 1.0]
Epoch :  1  Time:  1.11  Rel. Train L2 Loss :  0.25163931237326725  Rel. Test L2 Loss :  0.20062114238739015  Test L2 Loss :  0.28793219089508054  inv_L_scale:  [1.0, 1.0]
Epoch :  2  Time:  1.101  Rel. Train L2 Loss :  0.19545953883065117  Rel. Test L2 Loss :  0.17346299350261687  Test L2 Loss :  0.24908486127853394  inv_L_scale:  [1.0, 1.0]
Epoch :  3  Time:  1.12  Rel. Train L2 Loss :  0.16808781464894612  Rel. Test L2 Loss :  0.16995202422142028  Test L2 Loss :  0.24652865290641784  inv_L_scale:  [1.0, 1.0]
Epoch :  4  Time:  1.144  Rel. Train L2 Loss :  0.15901774797174667  Rel. Test L2 Loss :  0.1522308224439621  Test L2 Loss :  0.218166543841362  inv_L_scale:  [1.0, 1.0]
Epoch :  5  Time:  1.124  Rel. Train L2 Loss :  0.14855965104368  Rel. Test L2 Loss :  0.14677402436733245  Test L2 Loss :  0.2101460713148117  inv_L_scale:  [1.0, 1.0]
Epoch :  6  Time:  1.112  Rel. Train L2 Loss :  0.142998082836469  Rel. Test L2 Loss :  0.14133668601512908  Test L2 Loss :  0.20191660583019255  inv_L_scale:  [1.0, 1.0]
Epoch :  7  Time:  1.131  Rel. Train L2 Loss :  0.13814711113770803  Rel. Test L2 Loss :  0.13511616885662078  Test L2 Loss :  0.19470060348510743  inv_L_scale:  [1.0, 1.0]
Epoch :  8  Time:  1.135  Rel. Train L2 Loss :  0.13415356192323896  Rel. Test L2 Loss :  0.13759808421134948  Test L2 Loss :  0.19746772766113282  inv_L_scale:  [1.0, 1.0]
Epoch :  9  Time:  1.169  Rel. Train L2 Loss :  0.1320698059929742  Rel. Test L2 Loss :  0.13304097652435304  Test L2 Loss :  0.19138923823833465  inv_L_scale:  [1.0, 1.0]
Epoch :  10  Time:  1.126  Rel. Train L2 Loss :  0.12981630007425943  Rel. Test L2 Loss :  0.12387106895446777  Test L2 Loss :  0.17904150128364563  inv_L_scale:  [1.0, 1.0]
Epoch :  11  Time:  1.114  Rel. Train L2 Loss :  0.12486081937948863  Rel. Test L2 Loss :  0.1234942126274109  Test L2 Loss :  0.1774633812904358  inv_L_scale:  [1.0, 1.0]
Epoch :  12  Time:  1.146  Rel. Train L2 Loss :  0.1224571501215299  Rel. Test L2 Loss :  0.12993965566158294  Test L2 Loss :  0.18572901606559752  inv_L_scale:  [1.0, 1.0]
Epoch :  13  Time:  1.119  Rel. Train L2 Loss :  0.1215300209654702  Rel. Test L2 Loss :  0.12443000674247742  Test L2 Loss :  0.17892251074314117  inv_L_scale:  [1.0, 1.0]
Epoch :  14  Time:  1.137  Rel. Train L2 Loss :  0.11914244476291869  Rel. Test L2 Loss :  0.11971212327480316  Test L2 Loss :  0.17134767711162568  inv_L_scale:  [1.0, 1.0]
Epoch :  15  Time:  1.121  Rel. Train L2 Loss :  0.11748159153593911  Rel. Test L2 Loss :  0.11880532383918763  Test L2 Loss :  0.17033491611480714  inv_L_scale:  [1.0, 1.0]
Epoch :  16  Time:  1.117  Rel. Train L2 Loss :  0.11637793156835768  Rel. Test L2 Loss :  0.10973744362592697  Test L2 Loss :  0.15810930967330933  inv_L_scale:  [1.0, 1.0]
Epoch :  17  Time:  1.133  Rel. Train L2 Loss :  0.11375889546341367  Rel. Test L2 Loss :  0.11593303561210633  Test L2 Loss :  0.16677304685115815  inv_L_scale:  [1.0, 1.0]
Epoch :  18  Time:  1.125  Rel. Train L2 Loss :  0.11116370720995797  Rel. Test L2 Loss :  0.12025517523288727  Test L2 Loss :  0.17209599435329437  inv_L_scale:  [1.0, 1.0]
Epoch :  19  Time:  1.119  Rel. Train L2 Loss :  0.11138680623637305  Rel. Test L2 Loss :  0.1102151209115982  Test L2 Loss :  0.15791260182857514  inv_L_scale:  [1.0, 1.0]
Epoch :  20  Time:  1.127  Rel. Train L2 Loss :  0.10926799303955502  Rel. Test L2 Loss :  0.11034028381109237  Test L2 Loss :  0.15841100513935089  inv_L_scale:  [1.0, 1.0]
Epoch :  21  Time:  1.149  Rel. Train L2 Loss :  0.10813157776991526  Rel. Test L2 Loss :  0.1066856026649475  Test L2 Loss :  0.1526709473133087  inv_L_scale:  [1.0, 1.0]
Epoch :  22  Time:  1.135  Rel. Train L2 Loss :  0.10627413180139329  Rel. Test L2 Loss :  0.10468818366527557  Test L2 Loss :  0.150895072221756  inv_L_scale:  [1.0, 1.0]
Epoch :  23  Time:  1.122  Rel. Train L2 Loss :  0.1051602155301306  Rel. Test L2 Loss :  0.10688571631908417  Test L2 Loss :  0.15354708790779115  inv_L_scale:  [1.0, 1.0]
Epoch :  24  Time:  1.148  Rel. Train L2 Loss :  0.10654667701986101  Rel. Test L2 Loss :  0.11129365444183349  Test L2 Loss :  0.16006521701812745  inv_L_scale:  [1.0, 1.0]
Epoch :  25  Time:  1.122  Rel. Train L2 Loss :  0.10571684569120407  Rel. Test L2 Loss :  0.10046554267406464  Test L2 Loss :  0.14405646443367004  inv_L_scale:  [1.0, 1.0]
Epoch :  26  Time:  1.126  Rel. Train L2 Loss :  0.10250275876786974  Rel. Test L2 Loss :  0.10223511517047883  Test L2 Loss :  0.14706927120685578  inv_L_scale:  [1.0, 1.0]
Epoch :  27  Time:  1.113  Rel. Train L2 Loss :  0.10092489040560193  Rel. Test L2 Loss :  0.09810814529657363  Test L2 Loss :  0.14176978707313537  inv_L_scale:  [1.0, 1.0]
Epoch :  28  Time:  1.113  Rel. Train L2 Loss :  0.10055815984805425  Rel. Test L2 Loss :  0.10191477119922637  Test L2 Loss :  0.14690769612789153  inv_L_scale:  [1.0, 1.0]
Epoch :  29  Time:  1.137  Rel. Train L2 Loss :  0.0993014266424709  Rel. Test L2 Loss :  0.10307377576828003  Test L2 Loss :  0.14770556449890138  inv_L_scale:  [1.0, 1.0]
Epoch :  30  Time:  1.117  Rel. Train L2 Loss :  0.09830767197741402  Rel. Test L2 Loss :  0.1003817355632782  Test L2 Loss :  0.14384984374046325  inv_L_scale:  [1.0, 1.0]
Epoch :  31  Time:  1.108  Rel. Train L2 Loss :  0.09645072970125411  Rel. Test L2 Loss :  0.10118060380220413  Test L2 Loss :  0.14572884202003478  inv_L_scale:  [1.0, 1.0]
Epoch :  32  Time:  1.11  Rel. Train L2 Loss :  0.0964794232779079  Rel. Test L2 Loss :  0.1003733092546463  Test L2 Loss :  0.14471681654453278  inv_L_scale:  [1.0, 1.0]
Epoch :  33  Time:  1.107  Rel. Train L2 Loss :  0.09641633914576636  Rel. Test L2 Loss :  0.09977303981781006  Test L2 Loss :  0.14404011011123657  inv_L_scale:  [1.0, 1.0]
Epoch :  34  Time:  1.11  Rel. Train L2 Loss :  0.09599390533235339  Rel. Test L2 Loss :  0.09837186485528945  Test L2 Loss :  0.14201534748077393  inv_L_scale:  [1.0, 1.0]
Epoch :  35  Time:  1.106  Rel. Train L2 Loss :  0.09512357983324263  Rel. Test L2 Loss :  0.09628206968307496  Test L2 Loss :  0.1383420443534851  inv_L_scale:  [1.0, 1.0]
Epoch :  36  Time:  1.119  Rel. Train L2 Loss :  0.09584476732545429  Rel. Test L2 Loss :  0.09604277819395066  Test L2 Loss :  0.1376251184940338  inv_L_scale:  [1.0, 1.0]
Epoch :  37  Time:  1.113  Rel. Train L2 Loss :  0.09308510078324211  Rel. Test L2 Loss :  0.09507501900196075  Test L2 Loss :  0.1371067088842392  inv_L_scale:  [1.0, 1.0]
Epoch :  38  Time:  1.106  Rel. Train L2 Loss :  0.0929226424296697  Rel. Test L2 Loss :  0.0941068622469902  Test L2 Loss :  0.13594013571739197  inv_L_scale:  [1.0, 1.0]
Epoch :  39  Time:  1.108  Rel. Train L2 Loss :  0.09255339364210764  Rel. Test L2 Loss :  0.09532437801361084  Test L2 Loss :  0.13685727655887603  inv_L_scale:  [1.0, 1.0]
Epoch :  40  Time:  1.108  Rel. Train L2 Loss :  0.09088603830999799  Rel. Test L2 Loss :  0.09720888435840606  Test L2 Loss :  0.14096396386623383  inv_L_scale:  [1.0, 1.0]
Epoch :  41  Time:  1.11  Rel. Train L2 Loss :  0.0922594033016099  Rel. Test L2 Loss :  0.0942482328414917  Test L2 Loss :  0.13565948903560637  inv_L_scale:  [1.0, 1.0]
Epoch :  42  Time:  1.116  Rel. Train L2 Loss :  0.0910379390584098  Rel. Test L2 Loss :  0.09155415654182435  Test L2 Loss :  0.13171701192855834  inv_L_scale:  [1.0, 1.0]
Epoch :  43  Time:  1.122  Rel. Train L2 Loss :  0.09271455460124546  Rel. Test L2 Loss :  0.09503882944583893  Test L2 Loss :  0.13752657949924468  inv_L_scale:  [1.0, 1.0]
Epoch :  44  Time:  1.146  Rel. Train L2 Loss :  0.08929671284225252  Rel. Test L2 Loss :  0.09133154392242432  Test L2 Loss :  0.13138441979885102  inv_L_scale:  [1.0, 1.0]
Epoch :  45  Time:  1.141  Rel. Train L2 Loss :  0.08956162449386385  Rel. Test L2 Loss :  0.08971532762050628  Test L2 Loss :  0.1294029572606087  inv_L_scale:  [1.0, 1.0]
Epoch :  46  Time:  1.14  Rel. Train L2 Loss :  0.08939247770441903  Rel. Test L2 Loss :  0.09195617079734802  Test L2 Loss :  0.1319769138097763  inv_L_scale:  [1.0, 1.0]
Epoch :  47  Time:  1.112  Rel. Train L2 Loss :  0.08896935588783687  Rel. Test L2 Loss :  0.09233183622360229  Test L2 Loss :  0.13270217418670655  inv_L_scale:  [1.0, 1.0]
Epoch :  48  Time:  1.112  Rel. Train L2 Loss :  0.08818699840042327  Rel. Test L2 Loss :  0.0872806105017662  Test L2 Loss :  0.12499855637550354  inv_L_scale:  [1.0, 1.0]
Epoch :  49  Time:  1.113  Rel. Train L2 Loss :  0.08846936225891114  Rel. Test L2 Loss :  0.09101531863212585  Test L2 Loss :  0.13061480700969696  inv_L_scale:  [1.0, 1.0]
Epoch :  50  Time:  1.114  Rel. Train L2 Loss :  0.08629461076524522  Rel. Test L2 Loss :  0.08936410069465638  Test L2 Loss :  0.12861238032579422  inv_L_scale:  [1.0, 1.0]
Epoch :  51  Time:  1.11  Rel. Train L2 Loss :  0.08690696133507622  Rel. Test L2 Loss :  0.08650404334068298  Test L2 Loss :  0.1245436680316925  inv_L_scale:  [1.0, 1.0]
Epoch :  52  Time:  1.111  Rel. Train L2 Loss :  0.08605370359288321  Rel. Test L2 Loss :  0.0863801258802414  Test L2 Loss :  0.12414402544498443  inv_L_scale:  [1.0, 1.0]
Epoch :  53  Time:  1.131  Rel. Train L2 Loss :  0.08577897641393874  Rel. Test L2 Loss :  0.08525724411010742  Test L2 Loss :  0.12260483145713806  inv_L_scale:  [1.0, 1.0]
Epoch :  54  Time:  1.112  Rel. Train L2 Loss :  0.08539678709374533  Rel. Test L2 Loss :  0.08603597491979599  Test L2 Loss :  0.12392871916294097  inv_L_scale:  [1.0, 1.0]
Epoch :  55  Time:  1.11  Rel. Train L2 Loss :  0.0862791218691402  Rel. Test L2 Loss :  0.08924976587295533  Test L2 Loss :  0.12795746088027954  inv_L_scale:  [1.0, 1.0]
Epoch :  56  Time:  1.109  Rel. Train L2 Loss :  0.08633766882949405  Rel. Test L2 Loss :  0.08563954591751098  Test L2 Loss :  0.12296751767396927  inv_L_scale:  [1.0, 1.0]
Epoch :  57  Time:  1.113  Rel. Train L2 Loss :  0.08552863226996528  Rel. Test L2 Loss :  0.08821049809455872  Test L2 Loss :  0.12709762871265412  inv_L_scale:  [1.0, 1.0]
Epoch :  58  Time:  1.112  Rel. Train L2 Loss :  0.08444349331988228  Rel. Test L2 Loss :  0.08329381227493286  Test L2 Loss :  0.12016517221927643  inv_L_scale:  [1.0, 1.0]
Epoch :  59  Time:  1.135  Rel. Train L2 Loss :  0.08212830341524548  Rel. Test L2 Loss :  0.08094060510396957  Test L2 Loss :  0.11704708039760589  inv_L_scale:  [1.0, 1.0]
Epoch :  60  Time:  1.127  Rel. Train L2 Loss :  0.08252035193973117  Rel. Test L2 Loss :  0.08585961163043976  Test L2 Loss :  0.12359674632549286  inv_L_scale:  [1.0, 1.0]
Epoch :  61  Time:  1.119  Rel. Train L2 Loss :  0.0821462266643842  Rel. Test L2 Loss :  0.0815843665599823  Test L2 Loss :  0.11817426174879074  inv_L_scale:  [1.0, 1.0]
Epoch :  62  Time:  1.115  Rel. Train L2 Loss :  0.08196475764115652  Rel. Test L2 Loss :  0.08432152390480041  Test L2 Loss :  0.12068609714508056  inv_L_scale:  [1.0, 1.0]
Epoch :  63  Time:  1.126  Rel. Train L2 Loss :  0.0824761888384819  Rel. Test L2 Loss :  0.08370320558547974  Test L2 Loss :  0.12083935976028443  inv_L_scale:  [1.0, 1.0]
Epoch :  64  Time:  1.136  Rel. Train L2 Loss :  0.082052793569035  Rel. Test L2 Loss :  0.08572099387645721  Test L2 Loss :  0.12434821009635925  inv_L_scale:  [1.0, 1.0]
Epoch :  65  Time:  1.146  Rel. Train L2 Loss :  0.08220456351836522  Rel. Test L2 Loss :  0.08171368062496186  Test L2 Loss :  0.11707271099090576  inv_L_scale:  [1.0, 1.0]
Epoch :  66  Time:  1.129  Rel. Train L2 Loss :  0.08032538996802437  Rel. Test L2 Loss :  0.08604962646961212  Test L2 Loss :  0.12351722598075866  inv_L_scale:  [1.0, 1.0]
Epoch :  67  Time:  1.156  Rel. Train L2 Loss :  0.08062193075815836  Rel. Test L2 Loss :  0.085872563123703  Test L2 Loss :  0.12339246898889542  inv_L_scale:  [1.0, 1.0]
Epoch :  68  Time:  1.123  Rel. Train L2 Loss :  0.0797784291042222  Rel. Test L2 Loss :  0.08095638424158097  Test L2 Loss :  0.11670319706201554  inv_L_scale:  [1.0, 1.0]
Epoch :  69  Time:  1.129  Rel. Train L2 Loss :  0.07997450331846873  Rel. Test L2 Loss :  0.08412811785936355  Test L2 Loss :  0.12167726904153824  inv_L_scale:  [1.0, 1.0]
Epoch :  70  Time:  1.126  Rel. Train L2 Loss :  0.07976357122262319  Rel. Test L2 Loss :  0.08106828570365905  Test L2 Loss :  0.11732081234455109  inv_L_scale:  [1.0, 1.0]
Epoch :  71  Time:  1.114  Rel. Train L2 Loss :  0.07955901275078456  Rel. Test L2 Loss :  0.08366615384817123  Test L2 Loss :  0.12084611743688584  inv_L_scale:  [1.0, 1.0]
Epoch :  72  Time:  1.144  Rel. Train L2 Loss :  0.07981815142763986  Rel. Test L2 Loss :  0.08539935857057572  Test L2 Loss :  0.12326166450977326  inv_L_scale:  [1.0, 1.0]
Epoch :  73  Time:  1.122  Rel. Train L2 Loss :  0.07869057830837038  Rel. Test L2 Loss :  0.08066076785326004  Test L2 Loss :  0.1157642948627472  inv_L_scale:  [1.0, 1.0]
Epoch :  74  Time:  1.111  Rel. Train L2 Loss :  0.07873581575022803  Rel. Test L2 Loss :  0.0797715985774994  Test L2 Loss :  0.1154910197854042  inv_L_scale:  [1.0, 1.0]
Epoch :  75  Time:  1.126  Rel. Train L2 Loss :  0.07904837465948529  Rel. Test L2 Loss :  0.07800068914890289  Test L2 Loss :  0.11190039157867432  inv_L_scale:  [1.0, 1.0]
Epoch :  76  Time:  1.144  Rel. Train L2 Loss :  0.07651759376128514  Rel. Test L2 Loss :  0.07825298696756362  Test L2 Loss :  0.11257436275482177  inv_L_scale:  [1.0, 1.0]
Epoch :  77  Time:  1.116  Rel. Train L2 Loss :  0.07801648606856663  Rel. Test L2 Loss :  0.07680859357118607  Test L2 Loss :  0.11065219968557358  inv_L_scale:  [1.0, 1.0]
Epoch :  78  Time:  1.14  Rel. Train L2 Loss :  0.07855275430613094  Rel. Test L2 Loss :  0.07976541191339492  Test L2 Loss :  0.11452606707811355  inv_L_scale:  [1.0, 1.0]
Epoch :  79  Time:  1.115  Rel. Train L2 Loss :  0.07662753025690715  Rel. Test L2 Loss :  0.07774758070707322  Test L2 Loss :  0.1122638687491417  inv_L_scale:  [1.0, 1.0]
Epoch :  80  Time:  1.115  Rel. Train L2 Loss :  0.07680035150713391  Rel. Test L2 Loss :  0.07617004305124282  Test L2 Loss :  0.10979201138019562  inv_L_scale:  [1.0, 1.0]
Epoch :  81  Time:  1.107  Rel. Train L2 Loss :  0.07926528496874703  Rel. Test L2 Loss :  0.08144288897514343  Test L2 Loss :  0.11639159977436066  inv_L_scale:  [1.0, 1.0]
Epoch :  82  Time:  1.11  Rel. Train L2 Loss :  0.07890180812941658  Rel. Test L2 Loss :  0.07597293376922608  Test L2 Loss :  0.10903153151273727  inv_L_scale:  [1.0, 1.0]
Epoch :  83  Time:  1.108  Rel. Train L2 Loss :  0.07737263722552193  Rel. Test L2 Loss :  0.07915515244007111  Test L2 Loss :  0.1136740717291832  inv_L_scale:  [1.0, 1.0]
Epoch :  84  Time:  1.111  Rel. Train L2 Loss :  0.07655302835835351  Rel. Test L2 Loss :  0.07827627718448639  Test L2 Loss :  0.11367099493741989  inv_L_scale:  [1.0, 1.0]
Epoch :  85  Time:  1.121  Rel. Train L2 Loss :  0.0755936203069157  Rel. Test L2 Loss :  0.07703950762748718  Test L2 Loss :  0.11077723354101181  inv_L_scale:  [1.0, 1.0]
Epoch :  86  Time:  1.11  Rel. Train L2 Loss :  0.07655020091268751  Rel. Test L2 Loss :  0.07916179895401002  Test L2 Loss :  0.11357140988111496  inv_L_scale:  [1.0, 1.0]
Epoch :  87  Time:  1.105  Rel. Train L2 Loss :  0.07906184789207246  Rel. Test L2 Loss :  0.0775598081946373  Test L2 Loss :  0.11090549051761628  inv_L_scale:  [1.0, 1.0]
Epoch :  88  Time:  1.107  Rel. Train L2 Loss :  0.07476089235809114  Rel. Test L2 Loss :  0.07583000034093856  Test L2 Loss :  0.1089670205116272  inv_L_scale:  [1.0, 1.0]
Epoch :  89  Time:  1.106  Rel. Train L2 Loss :  0.07461092952224943  Rel. Test L2 Loss :  0.07582851201295852  Test L2 Loss :  0.10915996730327607  inv_L_scale:  [1.0, 1.0]
Epoch :  90  Time:  1.106  Rel. Train L2 Loss :  0.0748570054438379  Rel. Test L2 Loss :  0.07740855902433395  Test L2 Loss :  0.11158237636089324  inv_L_scale:  [1.0, 1.0]
Epoch :  91  Time:  1.106  Rel. Train L2 Loss :  0.07399079743358825  Rel. Test L2 Loss :  0.07164430171251297  Test L2 Loss :  0.10288238376379014  inv_L_scale:  [1.0, 1.0]
Epoch :  92  Time:  1.106  Rel. Train L2 Loss :  0.07309010237455368  Rel. Test L2 Loss :  0.07532760798931122  Test L2 Loss :  0.10762051731348038  inv_L_scale:  [1.0, 1.0]
Epoch :  93  Time:  1.11  Rel. Train L2 Loss :  0.07452743358082241  Rel. Test L2 Loss :  0.0770141214132309  Test L2 Loss :  0.11112177968025208  inv_L_scale:  [1.0, 1.0]
Epoch :  94  Time:  1.108  Rel. Train L2 Loss :  0.0734515169594023  Rel. Test L2 Loss :  0.07789284437894821  Test L2 Loss :  0.11210489869117737  inv_L_scale:  [1.0, 1.0]
Epoch :  95  Time:  1.108  Rel. Train L2 Loss :  0.07418754789564344  Rel. Test L2 Loss :  0.0754593962430954  Test L2 Loss :  0.10845359623432159  inv_L_scale:  [1.0, 1.0]
Epoch :  96  Time:  1.107  Rel. Train L2 Loss :  0.07265097447567516  Rel. Test L2 Loss :  0.07436859935522079  Test L2 Loss :  0.10683894664049148  inv_L_scale:  [1.0, 1.0]
Epoch :  97  Time:  1.104  Rel. Train L2 Loss :  0.07340649714072546  Rel. Test L2 Loss :  0.07100031942129136  Test L2 Loss :  0.10247484803199768  inv_L_scale:  [1.0, 1.0]
Epoch :  98  Time:  1.106  Rel. Train L2 Loss :  0.0732220701707734  Rel. Test L2 Loss :  0.07663349241018295  Test L2 Loss :  0.10996322572231293  inv_L_scale:  [1.0, 1.0]
Epoch :  99  Time:  1.104  Rel. Train L2 Loss :  0.07208048827118343  Rel. Test L2 Loss :  0.07365927815437318  Test L2 Loss :  0.10534104228019714  inv_L_scale:  [1.0, 1.0]
Epoch :  100  Time:  1.105  Rel. Train L2 Loss :  0.072216700580385  Rel. Test L2 Loss :  0.07362530410289764  Test L2 Loss :  0.10593212574720383  inv_L_scale:  [1.0, 1.0]
Epoch :  101  Time:  1.107  Rel. Train L2 Loss :  0.07271238485972087  Rel. Test L2 Loss :  0.07639141649007797  Test L2 Loss :  0.1103257992863655  inv_L_scale:  [1.0, 1.0]
Epoch :  102  Time:  1.105  Rel. Train L2 Loss :  0.07178509208891126  Rel. Test L2 Loss :  0.07640163540840149  Test L2 Loss :  0.11013417422771454  inv_L_scale:  [1.0, 1.0]
Epoch :  103  Time:  1.105  Rel. Train L2 Loss :  0.07286261697610219  Rel. Test L2 Loss :  0.07545633584260941  Test L2 Loss :  0.108669553399086  inv_L_scale:  [1.0, 1.0]
Epoch :  104  Time:  1.106  Rel. Train L2 Loss :  0.07166319260994593  Rel. Test L2 Loss :  0.0723386937379837  Test L2 Loss :  0.10384217977523803  inv_L_scale:  [1.0, 1.0]
Epoch :  105  Time:  1.107  Rel. Train L2 Loss :  0.07091200947761536  Rel. Test L2 Loss :  0.0745375970005989  Test L2 Loss :  0.10789482057094574  inv_L_scale:  [1.0, 1.0]
Epoch :  106  Time:  1.104  Rel. Train L2 Loss :  0.07080462475617727  Rel. Test L2 Loss :  0.07497931778430938  Test L2 Loss :  0.10759676456451416  inv_L_scale:  [1.0, 1.0]
Epoch :  107  Time:  1.105  Rel. Train L2 Loss :  0.07225198573536343  Rel. Test L2 Loss :  0.07793326407670975  Test L2 Loss :  0.1125086310505867  inv_L_scale:  [1.0, 1.0]
Epoch :  108  Time:  1.108  Rel. Train L2 Loss :  0.07442558106448915  Rel. Test L2 Loss :  0.07261620283126831  Test L2 Loss :  0.10506650418043137  inv_L_scale:  [1.0, 1.0]
Epoch :  109  Time:  1.107  Rel. Train L2 Loss :  0.07133456114265654  Rel. Test L2 Loss :  0.07414961099624634  Test L2 Loss :  0.1074135160446167  inv_L_scale:  [1.0, 1.0]
Epoch :  110  Time:  1.107  Rel. Train L2 Loss :  0.07066875278949737  Rel. Test L2 Loss :  0.07326497435569763  Test L2 Loss :  0.10557735860347747  inv_L_scale:  [1.0, 1.0]
Epoch :  111  Time:  1.106  Rel. Train L2 Loss :  0.06991072459353341  Rel. Test L2 Loss :  0.07405644416809082  Test L2 Loss :  0.1071041464805603  inv_L_scale:  [1.0, 1.0]
Epoch :  112  Time:  1.107  Rel. Train L2 Loss :  0.06992050369580587  Rel. Test L2 Loss :  0.07037758409976959  Test L2 Loss :  0.10125732421875  inv_L_scale:  [1.0, 1.0]
Epoch :  113  Time:  1.108  Rel. Train L2 Loss :  0.07025431957509783  Rel. Test L2 Loss :  0.06982611447572708  Test L2 Loss :  0.10074502170085907  inv_L_scale:  [1.0, 1.0]
Epoch :  114  Time:  1.107  Rel. Train L2 Loss :  0.0694345666633712  Rel. Test L2 Loss :  0.07321835845708848  Test L2 Loss :  0.10488603115081788  inv_L_scale:  [1.0, 1.0]
Epoch :  115  Time:  1.106  Rel. Train L2 Loss :  0.06914046310716206  Rel. Test L2 Loss :  0.07027777224779129  Test L2 Loss :  0.1012951022386551  inv_L_scale:  [1.0, 1.0]
Epoch :  116  Time:  1.104  Rel. Train L2 Loss :  0.06911664846870634  Rel. Test L2 Loss :  0.07111585795879365  Test L2 Loss :  0.10243653029203414  inv_L_scale:  [1.0, 1.0]
Epoch :  117  Time:  1.106  Rel. Train L2 Loss :  0.06930336722069316  Rel. Test L2 Loss :  0.07073999226093292  Test L2 Loss :  0.10177778661251068  inv_L_scale:  [1.0, 1.0]
Epoch :  118  Time:  1.115  Rel. Train L2 Loss :  0.06960953960816066  Rel. Test L2 Loss :  0.07148159086704255  Test L2 Loss :  0.1027456396818161  inv_L_scale:  [1.0, 1.0]
Epoch :  119  Time:  1.104  Rel. Train L2 Loss :  0.07048996224999428  Rel. Test L2 Loss :  0.07507273316383362  Test L2 Loss :  0.10753721356391907  inv_L_scale:  [1.0, 1.0]
Epoch :  120  Time:  1.106  Rel. Train L2 Loss :  0.06821604642603132  Rel. Test L2 Loss :  0.07028221756219864  Test L2 Loss :  0.10128767251968383  inv_L_scale:  [1.0, 1.0]
Epoch :  121  Time:  1.106  Rel. Train L2 Loss :  0.0691159161594179  Rel. Test L2 Loss :  0.06977016001939773  Test L2 Loss :  0.10036438345909118  inv_L_scale:  [1.0, 1.0]
Epoch :  122  Time:  1.104  Rel. Train L2 Loss :  0.06843358500136269  Rel. Test L2 Loss :  0.06976632326841355  Test L2 Loss :  0.10036499381065368  inv_L_scale:  [1.0, 1.0]
Epoch :  123  Time:  1.106  Rel. Train L2 Loss :  0.07150089845061303  Rel. Test L2 Loss :  0.0707376554608345  Test L2 Loss :  0.10185163855552673  inv_L_scale:  [1.0, 1.0]
Epoch :  124  Time:  1.107  Rel. Train L2 Loss :  0.06845060557126999  Rel. Test L2 Loss :  0.07088869124650955  Test L2 Loss :  0.10227371394634246  inv_L_scale:  [1.0, 1.0]
Epoch :  125  Time:  1.107  Rel. Train L2 Loss :  0.06845028435190519  Rel. Test L2 Loss :  0.0685324051976204  Test L2 Loss :  0.09889938354492188  inv_L_scale:  [1.0, 1.0]
Epoch :  126  Time:  1.107  Rel. Train L2 Loss :  0.06806749572356542  Rel. Test L2 Loss :  0.06768081545829772  Test L2 Loss :  0.09714705765247345  inv_L_scale:  [1.0, 1.0]
Epoch :  127  Time:  1.108  Rel. Train L2 Loss :  0.06817309359709421  Rel. Test L2 Loss :  0.07042881667613983  Test L2 Loss :  0.10148319035768509  inv_L_scale:  [1.0, 1.0]
Epoch :  128  Time:  1.106  Rel. Train L2 Loss :  0.06712728238768048  Rel. Test L2 Loss :  0.07278210759162902  Test L2 Loss :  0.10395187884569168  inv_L_scale:  [1.0, 1.0]
Epoch :  129  Time:  1.106  Rel. Train L2 Loss :  0.06850849095318053  Rel. Test L2 Loss :  0.07014355808496475  Test L2 Loss :  0.10108328640460967  inv_L_scale:  [1.0, 1.0]
Epoch :  130  Time:  1.106  Rel. Train L2 Loss :  0.06755081832408905  Rel. Test L2 Loss :  0.07022204637527465  Test L2 Loss :  0.10133126020431518  inv_L_scale:  [1.0, 1.0]
Epoch :  131  Time:  1.106  Rel. Train L2 Loss :  0.06807929855253961  Rel. Test L2 Loss :  0.06987264305353165  Test L2 Loss :  0.10042042553424835  inv_L_scale:  [1.0, 1.0]
Epoch :  132  Time:  1.107  Rel. Train L2 Loss :  0.06818316479523977  Rel. Test L2 Loss :  0.06865490794181824  Test L2 Loss :  0.09928557515144348  inv_L_scale:  [1.0, 1.0]
Epoch :  133  Time:  1.106  Rel. Train L2 Loss :  0.06755598316589992  Rel. Test L2 Loss :  0.07427762866020203  Test L2 Loss :  0.10654072850942611  inv_L_scale:  [1.0, 1.0]
Epoch :  134  Time:  1.106  Rel. Train L2 Loss :  0.06763690678609742  Rel. Test L2 Loss :  0.06901073038578033  Test L2 Loss :  0.0996198159456253  inv_L_scale:  [1.0, 1.0]
Epoch :  135  Time:  1.106  Rel. Train L2 Loss :  0.06744729767243067  Rel. Test L2 Loss :  0.06822719097137452  Test L2 Loss :  0.09877623975276947  inv_L_scale:  [1.0, 1.0]
Epoch :  136  Time:  1.106  Rel. Train L2 Loss :  0.06743895964490043  Rel. Test L2 Loss :  0.07279027074575424  Test L2 Loss :  0.10442675590515137  inv_L_scale:  [1.0, 1.0]
Epoch :  137  Time:  1.105  Rel. Train L2 Loss :  0.06672923121187423  Rel. Test L2 Loss :  0.06969511359930039  Test L2 Loss :  0.10092211127281189  inv_L_scale:  [1.0, 1.0]
Epoch :  138  Time:  1.105  Rel. Train L2 Loss :  0.06604220393631194  Rel. Test L2 Loss :  0.07060734510421753  Test L2 Loss :  0.10135683566331863  inv_L_scale:  [1.0, 1.0]
Epoch :  139  Time:  1.106  Rel. Train L2 Loss :  0.0662226735552152  Rel. Test L2 Loss :  0.06523005664348602  Test L2 Loss :  0.09405019283294677  inv_L_scale:  [1.0, 1.0]
Epoch :  140  Time:  1.105  Rel. Train L2 Loss :  0.06722825646400452  Rel. Test L2 Loss :  0.06913603872060775  Test L2 Loss :  0.09927584886550904  inv_L_scale:  [1.0, 1.0]
Epoch :  141  Time:  1.105  Rel. Train L2 Loss :  0.06590362234248055  Rel. Test L2 Loss :  0.06729007691144943  Test L2 Loss :  0.09699449479579926  inv_L_scale:  [1.0, 1.0]
Epoch :  142  Time:  1.107  Rel. Train L2 Loss :  0.06571200122435887  Rel. Test L2 Loss :  0.07010050177574158  Test L2 Loss :  0.10085588932037354  inv_L_scale:  [1.0, 1.0]
Epoch :  143  Time:  1.11  Rel. Train L2 Loss :  0.06596783101558686  Rel. Test L2 Loss :  0.06514551192522049  Test L2 Loss :  0.09406375080347061  inv_L_scale:  [1.0, 1.0]
Epoch :  144  Time:  1.11  Rel. Train L2 Loss :  0.0658273035287857  Rel. Test L2 Loss :  0.06792052268981934  Test L2 Loss :  0.09763616025447845  inv_L_scale:  [1.0, 1.0]
Epoch :  145  Time:  1.108  Rel. Train L2 Loss :  0.06497863408592013  Rel. Test L2 Loss :  0.0633951821923256  Test L2 Loss :  0.091521834731102  inv_L_scale:  [1.0, 1.0]
Epoch :  146  Time:  1.107  Rel. Train L2 Loss :  0.06541113823652267  Rel. Test L2 Loss :  0.0702848082780838  Test L2 Loss :  0.10140270322561264  inv_L_scale:  [1.0, 1.0]
Epoch :  147  Time:  1.108  Rel. Train L2 Loss :  0.06506516095664766  Rel. Test L2 Loss :  0.06754102438688278  Test L2 Loss :  0.0969790405035019  inv_L_scale:  [1.0, 1.0]
Epoch :  148  Time:  1.136  Rel. Train L2 Loss :  0.0642996736201975  Rel. Test L2 Loss :  0.06750197023153305  Test L2 Loss :  0.09746615558862687  inv_L_scale:  [1.0, 1.0]
Epoch :  149  Time:  1.144  Rel. Train L2 Loss :  0.06463697065909703  Rel. Test L2 Loss :  0.06641696363687516  Test L2 Loss :  0.09579577147960663  inv_L_scale:  [1.0, 1.0]
Epoch :  150  Time:  1.113  Rel. Train L2 Loss :  0.06489757284522056  Rel. Test L2 Loss :  0.06489893317222595  Test L2 Loss :  0.09343254864215851  inv_L_scale:  [1.0, 1.0]
Epoch :  151  Time:  1.143  Rel. Train L2 Loss :  0.06402892771694395  Rel. Test L2 Loss :  0.06558786392211914  Test L2 Loss :  0.09433874547481537  inv_L_scale:  [1.0, 1.0]
Epoch :  152  Time:  1.17  Rel. Train L2 Loss :  0.06457359264294306  Rel. Test L2 Loss :  0.06888629794120789  Test L2 Loss :  0.09902410686016083  inv_L_scale:  [1.0, 1.0]
Epoch :  153  Time:  1.123  Rel. Train L2 Loss :  0.06448746916320588  Rel. Test L2 Loss :  0.06714315474033355  Test L2 Loss :  0.09672335416078567  inv_L_scale:  [1.0, 1.0]
Epoch :  154  Time:  1.114  Rel. Train L2 Loss :  0.06461898431181907  Rel. Test L2 Loss :  0.06642511069774627  Test L2 Loss :  0.09521189570426941  inv_L_scale:  [1.0, 1.0]
Epoch :  155  Time:  1.117  Rel. Train L2 Loss :  0.06650374882751041  Rel. Test L2 Loss :  0.06436978340148926  Test L2 Loss :  0.09280427485704422  inv_L_scale:  [1.0, 1.0]
Epoch :  156  Time:  1.11  Rel. Train L2 Loss :  0.06387462139129639  Rel. Test L2 Loss :  0.06555087953805923  Test L2 Loss :  0.09470040798187256  inv_L_scale:  [1.0, 1.0]
Epoch :  157  Time:  1.113  Rel. Train L2 Loss :  0.06430971857574251  Rel. Test L2 Loss :  0.0651829594373703  Test L2 Loss :  0.09383092284202575  inv_L_scale:  [1.0, 1.0]
Epoch :  158  Time:  1.123  Rel. Train L2 Loss :  0.06410375561979081  Rel. Test L2 Loss :  0.06610025256872178  Test L2 Loss :  0.09551901400089263  inv_L_scale:  [1.0, 1.0]
Epoch :  159  Time:  1.111  Rel. Train L2 Loss :  0.0645578873819775  Rel. Test L2 Loss :  0.06511001855134964  Test L2 Loss :  0.09375409543514251  inv_L_scale:  [1.0, 1.0]
Epoch :  160  Time:  1.111  Rel. Train L2 Loss :  0.06670957876576318  Rel. Test L2 Loss :  0.0699267840385437  Test L2 Loss :  0.10019619107246398  inv_L_scale:  [1.0, 1.0]
Epoch :  161  Time:  1.111  Rel. Train L2 Loss :  0.06476519405841827  Rel. Test L2 Loss :  0.06541651427745819  Test L2 Loss :  0.0941469720005989  inv_L_scale:  [1.0, 1.0]
Epoch :  162  Time:  1.11  Rel. Train L2 Loss :  0.06411552392774159  Rel. Test L2 Loss :  0.06527580171823502  Test L2 Loss :  0.09421421110630035  inv_L_scale:  [1.0, 1.0]
Epoch :  163  Time:  1.11  Rel. Train L2 Loss :  0.06316716574960285  Rel. Test L2 Loss :  0.06653096348047256  Test L2 Loss :  0.09579712778329849  inv_L_scale:  [1.0, 1.0]
Epoch :  164  Time:  1.11  Rel. Train L2 Loss :  0.06345817471543948  Rel. Test L2 Loss :  0.06743968963623047  Test L2 Loss :  0.09784405201673507  inv_L_scale:  [1.0, 1.0]
Epoch :  165  Time:  1.109  Rel. Train L2 Loss :  0.06472060140636232  Rel. Test L2 Loss :  0.06477265119552612  Test L2 Loss :  0.09336390376091003  inv_L_scale:  [1.0, 1.0]
Epoch :  166  Time:  1.111  Rel. Train L2 Loss :  0.06375456737147438  Rel. Test L2 Loss :  0.069326691031456  Test L2 Loss :  0.10087228566408157  inv_L_scale:  [1.0, 1.0]
Epoch :  167  Time:  1.11  Rel. Train L2 Loss :  0.06373203876945707  Rel. Test L2 Loss :  0.06345038086175919  Test L2 Loss :  0.09156359821557998  inv_L_scale:  [1.0, 1.0]
Epoch :  168  Time:  1.113  Rel. Train L2 Loss :  0.06368929366270701  Rel. Test L2 Loss :  0.07012093305587769  Test L2 Loss :  0.10085068583488464  inv_L_scale:  [1.0, 1.0]
Epoch :  169  Time:  1.112  Rel. Train L2 Loss :  0.06397117184268104  Rel. Test L2 Loss :  0.06567517310380935  Test L2 Loss :  0.09454975366592407  inv_L_scale:  [1.0, 1.0]
Epoch :  170  Time:  1.109  Rel. Train L2 Loss :  0.06302004373735852  Rel. Test L2 Loss :  0.06513631284236908  Test L2 Loss :  0.09391270637512207  inv_L_scale:  [1.0, 1.0]
Epoch :  171  Time:  1.111  Rel. Train L2 Loss :  0.06470594119694498  Rel. Test L2 Loss :  0.06648438066244125  Test L2 Loss :  0.09636756360530853  inv_L_scale:  [1.0, 1.0]
Epoch :  172  Time:  1.111  Rel. Train L2 Loss :  0.06286878852380647  Rel. Test L2 Loss :  0.06489578604698182  Test L2 Loss :  0.09373496472835541  inv_L_scale:  [1.0, 1.0]
Epoch :  173  Time:  1.11  Rel. Train L2 Loss :  0.06241415075129933  Rel. Test L2 Loss :  0.06627219140529633  Test L2 Loss :  0.09563835233449935  inv_L_scale:  [1.0, 1.0]
Epoch :  174  Time:  1.111  Rel. Train L2 Loss :  0.06476040654712253  Rel. Test L2 Loss :  0.06677868753671647  Test L2 Loss :  0.09640898138284683  inv_L_scale:  [1.0, 1.0]
Epoch :  175  Time:  1.111  Rel. Train L2 Loss :  0.06344960861735874  Rel. Test L2 Loss :  0.06563303768634796  Test L2 Loss :  0.09474900901317597  inv_L_scale:  [1.0, 1.0]
Epoch :  176  Time:  1.111  Rel. Train L2 Loss :  0.06290758391221364  Rel. Test L2 Loss :  0.06373638629913331  Test L2 Loss :  0.09172478139400482  inv_L_scale:  [1.0, 1.0]
Epoch :  177  Time:  1.121  Rel. Train L2 Loss :  0.061337913109196555  Rel. Test L2 Loss :  0.06439177304506302  Test L2 Loss :  0.09280824661254883  inv_L_scale:  [1.0, 1.0]
Epoch :  178  Time:  1.136  Rel. Train L2 Loss :  0.061543580856588155  Rel. Test L2 Loss :  0.06403386294841766  Test L2 Loss :  0.09258471488952637  inv_L_scale:  [1.0, 1.0]
Epoch :  179  Time:  1.118  Rel. Train L2 Loss :  0.0625155567129453  Rel. Test L2 Loss :  0.06555035859346389  Test L2 Loss :  0.0942688912153244  inv_L_scale:  [1.0, 1.0]
Epoch :  180  Time:  1.111  Rel. Train L2 Loss :  0.061906565527121225  Rel. Test L2 Loss :  0.06675761848688126  Test L2 Loss :  0.09575946599245072  inv_L_scale:  [1.0, 1.0]
Epoch :  181  Time:  1.119  Rel. Train L2 Loss :  0.061895380119482674  Rel. Test L2 Loss :  0.06280230462551117  Test L2 Loss :  0.09052195221185684  inv_L_scale:  [1.0, 1.0]
Epoch :  182  Time:  1.141  Rel. Train L2 Loss :  0.06294574668010076  Rel. Test L2 Loss :  0.06371113687753677  Test L2 Loss :  0.09234789550304413  inv_L_scale:  [1.0, 1.0]
Epoch :  183  Time:  1.135  Rel. Train L2 Loss :  0.06212497062153286  Rel. Test L2 Loss :  0.06569587737321854  Test L2 Loss :  0.09486189424991608  inv_L_scale:  [1.0, 1.0]
Epoch :  184  Time:  1.116  Rel. Train L2 Loss :  0.06177036626471413  Rel. Test L2 Loss :  0.061518227756023405  Test L2 Loss :  0.08866283535957337  inv_L_scale:  [1.0, 1.0]
Epoch :  185  Time:  1.126  Rel. Train L2 Loss :  0.06105857686864005  Rel. Test L2 Loss :  0.06495482206344605  Test L2 Loss :  0.09379076540470123  inv_L_scale:  [1.0, 1.0]
Epoch :  186  Time:  1.121  Rel. Train L2 Loss :  0.06181564473443561  Rel. Test L2 Loss :  0.06261339038610458  Test L2 Loss :  0.09041074484586716  inv_L_scale:  [1.0, 1.0]
Epoch :  187  Time:  1.137  Rel. Train L2 Loss :  0.0611501168873575  Rel. Test L2 Loss :  0.06316345065832138  Test L2 Loss :  0.090877146422863  inv_L_scale:  [1.0, 1.0]
Epoch :  188  Time:  1.131  Rel. Train L2 Loss :  0.06247607681486342  Rel. Test L2 Loss :  0.06356612324714661  Test L2 Loss :  0.09171111702919006  inv_L_scale:  [1.0, 1.0]
Epoch :  189  Time:  1.143  Rel. Train L2 Loss :  0.06076832370625602  Rel. Test L2 Loss :  0.06264910072088242  Test L2 Loss :  0.09048656970262528  inv_L_scale:  [1.0, 1.0]
Epoch :  190  Time:  1.17  Rel. Train L2 Loss :  0.062436184386412304  Rel. Test L2 Loss :  0.06587612122297287  Test L2 Loss :  0.0947161489725113  inv_L_scale:  [1.0, 1.0]
Epoch :  191  Time:  1.149  Rel. Train L2 Loss :  0.062328541808658176  Rel. Test L2 Loss :  0.06483620792627334  Test L2 Loss :  0.09365895509719849  inv_L_scale:  [1.0, 1.0]
Epoch :  192  Time:  1.122  Rel. Train L2 Loss :  0.06058482789331012  Rel. Test L2 Loss :  0.06243699699640274  Test L2 Loss :  0.08990304529666901  inv_L_scale:  [1.0, 1.0]
Epoch :  193  Time:  1.119  Rel. Train L2 Loss :  0.06036841773324542  Rel. Test L2 Loss :  0.06206203401088715  Test L2 Loss :  0.08890621840953827  inv_L_scale:  [1.0, 1.0]
Epoch :  194  Time:  1.116  Rel. Train L2 Loss :  0.059810837606589  Rel. Test L2 Loss :  0.06370034575462341  Test L2 Loss :  0.09139881312847137  inv_L_scale:  [1.0, 1.0]
Epoch :  195  Time:  1.115  Rel. Train L2 Loss :  0.06036810666322708  Rel. Test L2 Loss :  0.06696725934743882  Test L2 Loss :  0.09606460601091385  inv_L_scale:  [1.0, 1.0]
Epoch :  196  Time:  1.12  Rel. Train L2 Loss :  0.062348387373818294  Rel. Test L2 Loss :  0.06572859823703765  Test L2 Loss :  0.09451647460460663  inv_L_scale:  [1.0, 1.0]
Epoch :  197  Time:  1.118  Rel. Train L2 Loss :  0.06099837675690651  Rel. Test L2 Loss :  0.06266752988100052  Test L2 Loss :  0.09008727252483367  inv_L_scale:  [1.0, 1.0]
Epoch :  198  Time:  1.113  Rel. Train L2 Loss :  0.06051547740896543  Rel. Test L2 Loss :  0.06375271618366242  Test L2 Loss :  0.09204947084188461  inv_L_scale:  [1.0, 1.0]
Epoch :  199  Time:  1.113  Rel. Train L2 Loss :  0.06098776078886456  Rel. Test L2 Loss :  0.06221909403800965  Test L2 Loss :  0.08956448793411255  inv_L_scale:  [1.0, 1.0]
Epoch :  200  Time:  1.108  Rel. Train L2 Loss :  0.060358163648181494  Rel. Test L2 Loss :  0.06297419458627701  Test L2 Loss :  0.0908339911699295  inv_L_scale:  [1.0, 1.0]
Epoch :  201  Time:  1.113  Rel. Train L2 Loss :  0.06021697355641259  Rel. Test L2 Loss :  0.06247374355792999  Test L2 Loss :  0.09002151429653167  inv_L_scale:  [1.0, 1.0]
Epoch :  202  Time:  1.118  Rel. Train L2 Loss :  0.06045523030890359  Rel. Test L2 Loss :  0.06053554803133011  Test L2 Loss :  0.08713460385799408  inv_L_scale:  [1.0, 1.0]
Epoch :  203  Time:  1.113  Rel. Train L2 Loss :  0.060115508569611446  Rel. Test L2 Loss :  0.06285194844007493  Test L2 Loss :  0.09085461765527725  inv_L_scale:  [1.0, 1.0]
Epoch :  204  Time:  1.116  Rel. Train L2 Loss :  0.059339177707831064  Rel. Test L2 Loss :  0.06068365097045898  Test L2 Loss :  0.08735253304243087  inv_L_scale:  [1.0, 1.0]
Epoch :  205  Time:  1.116  Rel. Train L2 Loss :  0.05926524245076709  Rel. Test L2 Loss :  0.05969841957092285  Test L2 Loss :  0.08626279175281525  inv_L_scale:  [1.0, 1.0]
Epoch :  206  Time:  1.114  Rel. Train L2 Loss :  0.06002585079934862  Rel. Test L2 Loss :  0.06218240588903427  Test L2 Loss :  0.08936159640550613  inv_L_scale:  [1.0, 1.0]
Epoch :  207  Time:  1.114  Rel. Train L2 Loss :  0.05976538373364343  Rel. Test L2 Loss :  0.06389024823904038  Test L2 Loss :  0.0924833768606186  inv_L_scale:  [1.0, 1.0]
Epoch :  208  Time:  1.114  Rel. Train L2 Loss :  0.06099779112471475  Rel. Test L2 Loss :  0.06271685689687728  Test L2 Loss :  0.09016219824552536  inv_L_scale:  [1.0, 1.0]
Epoch :  209  Time:  1.111  Rel. Train L2 Loss :  0.05918454905351003  Rel. Test L2 Loss :  0.06092175483703613  Test L2 Loss :  0.08779194712638855  inv_L_scale:  [1.0, 1.0]
Epoch :  210  Time:  1.115  Rel. Train L2 Loss :  0.05883462390965886  Rel. Test L2 Loss :  0.06362237989902496  Test L2 Loss :  0.09159761339426041  inv_L_scale:  [1.0, 1.0]
Epoch :  211  Time:  1.115  Rel. Train L2 Loss :  0.059407663411564296  Rel. Test L2 Loss :  0.05978535085916519  Test L2 Loss :  0.08610633432865143  inv_L_scale:  [1.0, 1.0]
Epoch :  212  Time:  1.115  Rel. Train L2 Loss :  0.05960594670640098  Rel. Test L2 Loss :  0.061979055404663086  Test L2 Loss :  0.0891733205318451  inv_L_scale:  [1.0, 1.0]
Epoch :  213  Time:  1.116  Rel. Train L2 Loss :  0.05908014138539632  Rel. Test L2 Loss :  0.061554582715034487  Test L2 Loss :  0.08878129661083221  inv_L_scale:  [1.0, 1.0]
Epoch :  214  Time:  1.112  Rel. Train L2 Loss :  0.058561200300852455  Rel. Test L2 Loss :  0.05921366959810257  Test L2 Loss :  0.08568525969982148  inv_L_scale:  [1.0, 1.0]
Epoch :  215  Time:  1.126  Rel. Train L2 Loss :  0.05917950507667329  Rel. Test L2 Loss :  0.0641507664322853  Test L2 Loss :  0.09229975402355194  inv_L_scale:  [1.0, 1.0]
Epoch :  216  Time:  1.113  Rel. Train L2 Loss :  0.05939502716064453  Rel. Test L2 Loss :  0.06256264835596084  Test L2 Loss :  0.08988447278738022  inv_L_scale:  [1.0, 1.0]
Epoch :  217  Time:  1.114  Rel. Train L2 Loss :  0.05890836608078745  Rel. Test L2 Loss :  0.06102144300937653  Test L2 Loss :  0.08795123338699341  inv_L_scale:  [1.0, 1.0]
Epoch :  218  Time:  1.115  Rel. Train L2 Loss :  0.061745162374443475  Rel. Test L2 Loss :  0.06116531163454056  Test L2 Loss :  0.08813161373138428  inv_L_scale:  [1.0, 1.0]
Epoch :  219  Time:  1.112  Rel. Train L2 Loss :  0.05949088364839554  Rel. Test L2 Loss :  0.06281984061002731  Test L2 Loss :  0.09016639083623885  inv_L_scale:  [1.0, 1.0]
Epoch :  220  Time:  1.112  Rel. Train L2 Loss :  0.05932945685254203  Rel. Test L2 Loss :  0.06108278453350067  Test L2 Loss :  0.0878179743885994  inv_L_scale:  [1.0, 1.0]
Epoch :  221  Time:  1.117  Rel. Train L2 Loss :  0.058318930483526654  Rel. Test L2 Loss :  0.06103849738836289  Test L2 Loss :  0.08788022935390473  inv_L_scale:  [1.0, 1.0]
Epoch :  222  Time:  1.116  Rel. Train L2 Loss :  0.058356249580780666  Rel. Test L2 Loss :  0.061403168141841886  Test L2 Loss :  0.08859312415122986  inv_L_scale:  [1.0, 1.0]
Epoch :  223  Time:  1.113  Rel. Train L2 Loss :  0.05828355679909388  Rel. Test L2 Loss :  0.060178628265857695  Test L2 Loss :  0.08691605806350708  inv_L_scale:  [1.0, 1.0]
Epoch :  224  Time:  1.112  Rel. Train L2 Loss :  0.057698004709349736  Rel. Test L2 Loss :  0.06118705838918686  Test L2 Loss :  0.08829503625631333  inv_L_scale:  [1.0, 1.0]
Epoch :  225  Time:  1.134  Rel. Train L2 Loss :  0.058491835792859395  Rel. Test L2 Loss :  0.059990813732147215  Test L2 Loss :  0.08631929874420166  inv_L_scale:  [1.0, 1.0]
Epoch :  226  Time:  1.115  Rel. Train L2 Loss :  0.05850580953889423  Rel. Test L2 Loss :  0.06072338461875915  Test L2 Loss :  0.08757892727851868  inv_L_scale:  [1.0, 1.0]
Epoch :  227  Time:  1.11  Rel. Train L2 Loss :  0.05806987022360166  Rel. Test L2 Loss :  0.05929131537675857  Test L2 Loss :  0.08569302588701248  inv_L_scale:  [1.0, 1.0]
Epoch :  228  Time:  1.11  Rel. Train L2 Loss :  0.0579404307074017  Rel. Test L2 Loss :  0.06222179293632507  Test L2 Loss :  0.0893467503786087  inv_L_scale:  [1.0, 1.0]
Epoch :  229  Time:  1.113  Rel. Train L2 Loss :  0.0581345542271932  Rel. Test L2 Loss :  0.06071507781744003  Test L2 Loss :  0.08801542520523072  inv_L_scale:  [1.0, 1.0]
Epoch :  230  Time:  1.125  Rel. Train L2 Loss :  0.05776952077945074  Rel. Test L2 Loss :  0.05940593391656876  Test L2 Loss :  0.08553144872188569  inv_L_scale:  [1.0, 1.0]
Epoch :  231  Time:  1.128  Rel. Train L2 Loss :  0.058258930146694185  Rel. Test L2 Loss :  0.06160325050354004  Test L2 Loss :  0.08822264075279236  inv_L_scale:  [1.0, 1.0]
Epoch :  232  Time:  1.116  Rel. Train L2 Loss :  0.057616568969355686  Rel. Test L2 Loss :  0.06008840262889862  Test L2 Loss :  0.08659914076328278  inv_L_scale:  [1.0, 1.0]
Epoch :  233  Time:  1.127  Rel. Train L2 Loss :  0.05807807789908515  Rel. Test L2 Loss :  0.061850455105304715  Test L2 Loss :  0.08913765579462052  inv_L_scale:  [1.0, 1.0]
Epoch :  234  Time:  1.138  Rel. Train L2 Loss :  0.057601975169446734  Rel. Test L2 Loss :  0.05898608326911926  Test L2 Loss :  0.08519629746675492  inv_L_scale:  [1.0, 1.0]
Epoch :  235  Time:  1.14  Rel. Train L2 Loss :  0.057271719111336605  Rel. Test L2 Loss :  0.0593781578540802  Test L2 Loss :  0.08548361897468566  inv_L_scale:  [1.0, 1.0]
Epoch :  236  Time:  1.122  Rel. Train L2 Loss :  0.058205711940924325  Rel. Test L2 Loss :  0.061047205924987795  Test L2 Loss :  0.08791409194469452  inv_L_scale:  [1.0, 1.0]
Epoch :  237  Time:  1.116  Rel. Train L2 Loss :  0.05769780438807275  Rel. Test L2 Loss :  0.05876477122306824  Test L2 Loss :  0.08485743135213852  inv_L_scale:  [1.0, 1.0]
Epoch :  238  Time:  1.126  Rel. Train L2 Loss :  0.05793584629893303  Rel. Test L2 Loss :  0.05964178800582886  Test L2 Loss :  0.08605554431676865  inv_L_scale:  [1.0, 1.0]
Epoch :  239  Time:  1.13  Rel. Train L2 Loss :  0.05714504389299287  Rel. Test L2 Loss :  0.060005147159099576  Test L2 Loss :  0.08656399875879288  inv_L_scale:  [1.0, 1.0]
Epoch :  240  Time:  1.106  Rel. Train L2 Loss :  0.057799780633714465  Rel. Test L2 Loss :  0.0618056321144104  Test L2 Loss :  0.08877493381500244  inv_L_scale:  [1.0, 1.0]
Epoch :  241  Time:  1.107  Rel. Train L2 Loss :  0.0573430801431338  Rel. Test L2 Loss :  0.05963428765535354  Test L2 Loss :  0.08566516548395157  inv_L_scale:  [1.0, 1.0]
Epoch :  242  Time:  1.107  Rel. Train L2 Loss :  0.05663860427008735  Rel. Test L2 Loss :  0.061205448508262636  Test L2 Loss :  0.08813703000545502  inv_L_scale:  [1.0, 1.0]
Epoch :  243  Time:  1.105  Rel. Train L2 Loss :  0.057138764295313095  Rel. Test L2 Loss :  0.059718569219112394  Test L2 Loss :  0.08598654866218566  inv_L_scale:  [1.0, 1.0]
Epoch :  244  Time:  1.107  Rel. Train L2 Loss :  0.057348914841810865  Rel. Test L2 Loss :  0.06147069096565247  Test L2 Loss :  0.08866815656423568  inv_L_scale:  [1.0, 1.0]
Epoch :  245  Time:  1.106  Rel. Train L2 Loss :  0.056588148706489136  Rel. Test L2 Loss :  0.05895248979330063  Test L2 Loss :  0.08484567493200303  inv_L_scale:  [1.0, 1.0]
Epoch :  246  Time:  1.106  Rel. Train L2 Loss :  0.05689751305513912  Rel. Test L2 Loss :  0.05964058935642243  Test L2 Loss :  0.08590629696846008  inv_L_scale:  [1.0, 1.0]
Epoch :  247  Time:  1.107  Rel. Train L2 Loss :  0.05693858080440097  Rel. Test L2 Loss :  0.05769295454025269  Test L2 Loss :  0.08318448156118392  inv_L_scale:  [1.0, 1.0]
Epoch :  248  Time:  1.104  Rel. Train L2 Loss :  0.057546128067705364  Rel. Test L2 Loss :  0.06025512307882309  Test L2 Loss :  0.08676487118005753  inv_L_scale:  [1.0, 1.0]
Epoch :  249  Time:  1.104  Rel. Train L2 Loss :  0.05744553380542331  Rel. Test L2 Loss :  0.060644852817058566  Test L2 Loss :  0.08721856355667114  inv_L_scale:  [1.0, 1.0]
Epoch :  250  Time:  1.105  Rel. Train L2 Loss :  0.0575137873325083  Rel. Test L2 Loss :  0.05888138353824615  Test L2 Loss :  0.0848335599899292  inv_L_scale:  [1.0, 1.0]
Epoch :  251  Time:  1.103  Rel. Train L2 Loss :  0.055543612755007216  Rel. Test L2 Loss :  0.05925461202859879  Test L2 Loss :  0.08563662171363831  inv_L_scale:  [1.0, 1.0]
Epoch :  252  Time:  1.103  Rel. Train L2 Loss :  0.05680276614096429  Rel. Test L2 Loss :  0.05814971089363098  Test L2 Loss :  0.08422236919403076  inv_L_scale:  [1.0, 1.0]
Epoch :  253  Time:  1.103  Rel. Train L2 Loss :  0.05597555092639393  Rel. Test L2 Loss :  0.059464510977268216  Test L2 Loss :  0.08561317563056946  inv_L_scale:  [1.0, 1.0]
Epoch :  254  Time:  1.104  Rel. Train L2 Loss :  0.05723664734098646  Rel. Test L2 Loss :  0.059226384460926054  Test L2 Loss :  0.08560141682624817  inv_L_scale:  [1.0, 1.0]
Epoch :  255  Time:  1.103  Rel. Train L2 Loss :  0.05668882272309727  Rel. Test L2 Loss :  0.05892689675092697  Test L2 Loss :  0.08489821076393128  inv_L_scale:  [1.0, 1.0]
Epoch :  256  Time:  1.107  Rel. Train L2 Loss :  0.05537212688061926  Rel. Test L2 Loss :  0.05917611926794052  Test L2 Loss :  0.08524095445871353  inv_L_scale:  [1.0, 1.0]
Epoch :  257  Time:  1.105  Rel. Train L2 Loss :  0.05712474985255135  Rel. Test L2 Loss :  0.05956065207719803  Test L2 Loss :  0.08590218424797058  inv_L_scale:  [1.0, 1.0]
Epoch :  258  Time:  1.104  Rel. Train L2 Loss :  0.05547487258911133  Rel. Test L2 Loss :  0.057883503139019014  Test L2 Loss :  0.0833922803401947  inv_L_scale:  [1.0, 1.0]
Epoch :  259  Time:  1.107  Rel. Train L2 Loss :  0.055906975004408097  Rel. Test L2 Loss :  0.05924637943506241  Test L2 Loss :  0.08559669315814972  inv_L_scale:  [1.0, 1.0]
Epoch :  260  Time:  1.104  Rel. Train L2 Loss :  0.05582781371143129  Rel. Test L2 Loss :  0.05976542890071869  Test L2 Loss :  0.0860643869638443  inv_L_scale:  [1.0, 1.0]
Epoch :  261  Time:  1.105  Rel. Train L2 Loss :  0.0558111499912209  Rel. Test L2 Loss :  0.059079168438911436  Test L2 Loss :  0.08571014881134033  inv_L_scale:  [1.0, 1.0]
Epoch :  262  Time:  1.104  Rel. Train L2 Loss :  0.0557240304019716  Rel. Test L2 Loss :  0.05879995346069336  Test L2 Loss :  0.08488427937030792  inv_L_scale:  [1.0, 1.0]
Epoch :  263  Time:  1.105  Rel. Train L2 Loss :  0.05709626247485479  Rel. Test L2 Loss :  0.058481787145137784  Test L2 Loss :  0.08411840915679931  inv_L_scale:  [1.0, 1.0]
Epoch :  264  Time:  1.104  Rel. Train L2 Loss :  0.05610982262425952  Rel. Test L2 Loss :  0.058882393538951874  Test L2 Loss :  0.08489448428153992  inv_L_scale:  [1.0, 1.0]
Epoch :  265  Time:  1.104  Rel. Train L2 Loss :  0.05521446453200446  Rel. Test L2 Loss :  0.0573327699303627  Test L2 Loss :  0.08271927297115327  inv_L_scale:  [1.0, 1.0]
Epoch :  266  Time:  1.104  Rel. Train L2 Loss :  0.05448831386036343  Rel. Test L2 Loss :  0.057099360525608066  Test L2 Loss :  0.08232910722494126  inv_L_scale:  [1.0, 1.0]
Epoch :  267  Time:  1.105  Rel. Train L2 Loss :  0.05508405466874441  Rel. Test L2 Loss :  0.058004278242588046  Test L2 Loss :  0.08369661629199981  inv_L_scale:  [1.0, 1.0]
Epoch :  268  Time:  1.104  Rel. Train L2 Loss :  0.055751502215862274  Rel. Test L2 Loss :  0.057745455503463744  Test L2 Loss :  0.08322865635156632  inv_L_scale:  [1.0, 1.0]
Epoch :  269  Time:  1.104  Rel. Train L2 Loss :  0.05461868829197354  Rel. Test L2 Loss :  0.05766331523656845  Test L2 Loss :  0.08284063637256622  inv_L_scale:  [1.0, 1.0]
Epoch :  270  Time:  1.105  Rel. Train L2 Loss :  0.054241224676370624  Rel. Test L2 Loss :  0.057873467803001406  Test L2 Loss :  0.0832180154323578  inv_L_scale:  [1.0, 1.0]
Epoch :  271  Time:  1.105  Rel. Train L2 Loss :  0.05585715944568316  Rel. Test L2 Loss :  0.05806203842163086  Test L2 Loss :  0.08322350412607193  inv_L_scale:  [1.0, 1.0]
Epoch :  272  Time:  1.105  Rel. Train L2 Loss :  0.05516568928956986  Rel. Test L2 Loss :  0.06061817497014999  Test L2 Loss :  0.0874972540140152  inv_L_scale:  [1.0, 1.0]
Epoch :  273  Time:  1.105  Rel. Train L2 Loss :  0.05718602238429917  Rel. Test L2 Loss :  0.059065485894680025  Test L2 Loss :  0.08526890277862549  inv_L_scale:  [1.0, 1.0]
Epoch :  274  Time:  1.103  Rel. Train L2 Loss :  0.05521495193243027  Rel. Test L2 Loss :  0.05771787017583847  Test L2 Loss :  0.08344116926193237  inv_L_scale:  [1.0, 1.0]
Epoch :  275  Time:  1.104  Rel. Train L2 Loss :  0.054518775675031876  Rel. Test L2 Loss :  0.05758053600788116  Test L2 Loss :  0.0831570166349411  inv_L_scale:  [1.0, 1.0]
Epoch :  276  Time:  1.106  Rel. Train L2 Loss :  0.05459529459476471  Rel. Test L2 Loss :  0.057007239162921906  Test L2 Loss :  0.08213350772857667  inv_L_scale:  [1.0, 1.0]
Epoch :  277  Time:  1.116  Rel. Train L2 Loss :  0.05504202019837168  Rel. Test L2 Loss :  0.05744807422161102  Test L2 Loss :  0.08313469767570496  inv_L_scale:  [1.0, 1.0]
Epoch :  278  Time:  1.105  Rel. Train L2 Loss :  0.05425355527136061  Rel. Test L2 Loss :  0.05713223278522492  Test L2 Loss :  0.08221894145011902  inv_L_scale:  [1.0, 1.0]
Epoch :  279  Time:  1.105  Rel. Train L2 Loss :  0.05445278141233656  Rel. Test L2 Loss :  0.05744450211524963  Test L2 Loss :  0.08298762172460555  inv_L_scale:  [1.0, 1.0]
Epoch :  280  Time:  1.105  Rel. Train L2 Loss :  0.05415231630206108  Rel. Test L2 Loss :  0.057165997922420504  Test L2 Loss :  0.08230900377035141  inv_L_scale:  [1.0, 1.0]
Epoch :  281  Time:  1.104  Rel. Train L2 Loss :  0.05411106682486004  Rel. Test L2 Loss :  0.05610734522342682  Test L2 Loss :  0.08074183732271195  inv_L_scale:  [1.0, 1.0]
Epoch :  282  Time:  1.104  Rel. Train L2 Loss :  0.05451149312986268  Rel. Test L2 Loss :  0.057395626604557035  Test L2 Loss :  0.08264732539653778  inv_L_scale:  [1.0, 1.0]
Epoch :  283  Time:  1.106  Rel. Train L2 Loss :  0.053932019505235886  Rel. Test L2 Loss :  0.05723846048116684  Test L2 Loss :  0.08250230729579926  inv_L_scale:  [1.0, 1.0]
Epoch :  284  Time:  1.104  Rel. Train L2 Loss :  0.05387248526016871  Rel. Test L2 Loss :  0.057990984320640565  Test L2 Loss :  0.08357179909944534  inv_L_scale:  [1.0, 1.0]
Epoch :  285  Time:  1.107  Rel. Train L2 Loss :  0.05475260408388244  Rel. Test L2 Loss :  0.05897568225860596  Test L2 Loss :  0.08476587831974029  inv_L_scale:  [1.0, 1.0]
Epoch :  286  Time:  1.107  Rel. Train L2 Loss :  0.05405640032556322  Rel. Test L2 Loss :  0.05715575873851776  Test L2 Loss :  0.08234794050455094  inv_L_scale:  [1.0, 1.0]
Epoch :  287  Time:  1.105  Rel. Train L2 Loss :  0.055069663061036  Rel. Test L2 Loss :  0.05875416204333305  Test L2 Loss :  0.08460122972726822  inv_L_scale:  [1.0, 1.0]
Epoch :  288  Time:  1.105  Rel. Train L2 Loss :  0.05536471906635496  Rel. Test L2 Loss :  0.058743123710155484  Test L2 Loss :  0.08437384188175201  inv_L_scale:  [1.0, 1.0]
Epoch :  289  Time:  1.106  Rel. Train L2 Loss :  0.05373600375321176  Rel. Test L2 Loss :  0.05694308519363403  Test L2 Loss :  0.0817430293560028  inv_L_scale:  [1.0, 1.0]
Epoch :  290  Time:  1.104  Rel. Train L2 Loss :  0.054301486959060036  Rel. Test L2 Loss :  0.057534186244010924  Test L2 Loss :  0.08285383641719818  inv_L_scale:  [1.0, 1.0]
Epoch :  291  Time:  1.103  Rel. Train L2 Loss :  0.0554966147740682  Rel. Test L2 Loss :  0.05764441251754761  Test L2 Loss :  0.0830436959862709  inv_L_scale:  [1.0, 1.0]
Epoch :  292  Time:  1.106  Rel. Train L2 Loss :  0.05390972692105505  Rel. Test L2 Loss :  0.05679468899965286  Test L2 Loss :  0.08217018336057663  inv_L_scale:  [1.0, 1.0]
Epoch :  293  Time:  1.105  Rel. Train L2 Loss :  0.05338518291711807  Rel. Test L2 Loss :  0.0564892503619194  Test L2 Loss :  0.08146102994680404  inv_L_scale:  [1.0, 1.0]
Epoch :  294  Time:  1.105  Rel. Train L2 Loss :  0.053364469839466945  Rel. Test L2 Loss :  0.05675004333257675  Test L2 Loss :  0.08173351407051087  inv_L_scale:  [1.0, 1.0]
Epoch :  295  Time:  1.107  Rel. Train L2 Loss :  0.05351471193962627  Rel. Test L2 Loss :  0.05605235904455185  Test L2 Loss :  0.08063756704330444  inv_L_scale:  [1.0, 1.0]
Epoch :  296  Time:  1.104  Rel. Train L2 Loss :  0.05463823575112555  Rel. Test L2 Loss :  0.05649562194943428  Test L2 Loss :  0.08137852519750595  inv_L_scale:  [1.0, 1.0]
Epoch :  297  Time:  1.104  Rel. Train L2 Loss :  0.053145801309082245  Rel. Test L2 Loss :  0.05578439652919769  Test L2 Loss :  0.08059455633163452  inv_L_scale:  [1.0, 1.0]
Epoch :  298  Time:  1.105  Rel. Train L2 Loss :  0.05293781611654493  Rel. Test L2 Loss :  0.05560375690460205  Test L2 Loss :  0.08008989334106445  inv_L_scale:  [1.0, 1.0]
Epoch :  299  Time:  1.104  Rel. Train L2 Loss :  0.053219347463713755  Rel. Test L2 Loss :  0.056738220155239105  Test L2 Loss :  0.08171110510826111  inv_L_scale:  [1.0, 1.0]
Epoch :  300  Time:  1.105  Rel. Train L2 Loss :  0.053008817202515074  Rel. Test L2 Loss :  0.05531096428632736  Test L2 Loss :  0.07981634527444839  inv_L_scale:  [1.0, 1.0]
Epoch :  301  Time:  1.106  Rel. Train L2 Loss :  0.053416680263148414  Rel. Test L2 Loss :  0.057223578095436094  Test L2 Loss :  0.08267161548137665  inv_L_scale:  [1.0, 1.0]
Epoch :  302  Time:  1.105  Rel. Train L2 Loss :  0.05337525675694148  Rel. Test L2 Loss :  0.05624890998005867  Test L2 Loss :  0.08100890457630157  inv_L_scale:  [1.0, 1.0]
Epoch :  303  Time:  1.106  Rel. Train L2 Loss :  0.053134597573015425  Rel. Test L2 Loss :  0.05775916218757629  Test L2 Loss :  0.08326833307743073  inv_L_scale:  [1.0, 1.0]
Epoch :  304  Time:  1.106  Rel. Train L2 Loss :  0.05285468127992418  Rel. Test L2 Loss :  0.05636735811829567  Test L2 Loss :  0.0812937581539154  inv_L_scale:  [1.0, 1.0]
Epoch :  305  Time:  1.107  Rel. Train L2 Loss :  0.05263952861229579  Rel. Test L2 Loss :  0.05554385334253311  Test L2 Loss :  0.07999097257852554  inv_L_scale:  [1.0, 1.0]
Epoch :  306  Time:  1.105  Rel. Train L2 Loss :  0.05251077416870329  Rel. Test L2 Loss :  0.056538532674312594  Test L2 Loss :  0.08129505574703216  inv_L_scale:  [1.0, 1.0]
Epoch :  307  Time:  1.105  Rel. Train L2 Loss :  0.05221330844693714  Rel. Test L2 Loss :  0.05589495658874512  Test L2 Loss :  0.08051293611526489  inv_L_scale:  [1.0, 1.0]
Epoch :  308  Time:  1.107  Rel. Train L2 Loss :  0.053859329654110805  Rel. Test L2 Loss :  0.05660499483346939  Test L2 Loss :  0.08144147992134095  inv_L_scale:  [1.0, 1.0]
Epoch :  309  Time:  1.104  Rel. Train L2 Loss :  0.05260878402325842  Rel. Test L2 Loss :  0.05563269823789597  Test L2 Loss :  0.08022545903921127  inv_L_scale:  [1.0, 1.0]
Epoch :  310  Time:  1.106  Rel. Train L2 Loss :  0.05222309718529383  Rel. Test L2 Loss :  0.05703722536563873  Test L2 Loss :  0.08227540761232376  inv_L_scale:  [1.0, 1.0]
Epoch :  311  Time:  1.105  Rel. Train L2 Loss :  0.05326496720314026  Rel. Test L2 Loss :  0.05647989362478256  Test L2 Loss :  0.0814142769575119  inv_L_scale:  [1.0, 1.0]
Epoch :  312  Time:  1.111  Rel. Train L2 Loss :  0.052637774215804206  Rel. Test L2 Loss :  0.056792586743831634  Test L2 Loss :  0.08176757663488388  inv_L_scale:  [1.0, 1.0]
Epoch :  313  Time:  1.109  Rel. Train L2 Loss :  0.05220948820312818  Rel. Test L2 Loss :  0.054764865934848785  Test L2 Loss :  0.07907949507236481  inv_L_scale:  [1.0, 1.0]
Epoch :  314  Time:  1.11  Rel. Train L2 Loss :  0.05198715204993884  Rel. Test L2 Loss :  0.05577924013137817  Test L2 Loss :  0.08024943917989731  inv_L_scale:  [1.0, 1.0]
Epoch :  315  Time:  1.115  Rel. Train L2 Loss :  0.05150234253870117  Rel. Test L2 Loss :  0.055786845982074736  Test L2 Loss :  0.08007985651493073  inv_L_scale:  [1.0, 1.0]
Epoch :  316  Time:  1.154  Rel. Train L2 Loss :  0.05200386964612537  Rel. Test L2 Loss :  0.0555126941204071  Test L2 Loss :  0.08003082126379013  inv_L_scale:  [1.0, 1.0]
Epoch :  317  Time:  1.127  Rel. Train L2 Loss :  0.052098133100403676  Rel. Test L2 Loss :  0.05558725267648697  Test L2 Loss :  0.07997977286577225  inv_L_scale:  [1.0, 1.0]
Epoch :  318  Time:  1.147  Rel. Train L2 Loss :  0.05193467459744877  Rel. Test L2 Loss :  0.05518646001815796  Test L2 Loss :  0.07944124668836594  inv_L_scale:  [1.0, 1.0]
Epoch :  319  Time:  1.121  Rel. Train L2 Loss :  0.05174639132287767  Rel. Test L2 Loss :  0.05633959263563156  Test L2 Loss :  0.08136177450418472  inv_L_scale:  [1.0, 1.0]
Epoch :  320  Time:  1.11  Rel. Train L2 Loss :  0.05165186560816235  Rel. Test L2 Loss :  0.05476738184690475  Test L2 Loss :  0.07909693896770477  inv_L_scale:  [1.0, 1.0]
Epoch :  321  Time:  1.113  Rel. Train L2 Loss :  0.051618505683210164  Rel. Test L2 Loss :  0.054831470847129825  Test L2 Loss :  0.07891118228435516  inv_L_scale:  [1.0, 1.0]
Epoch :  322  Time:  1.135  Rel. Train L2 Loss :  0.052085685084263485  Rel. Test L2 Loss :  0.055183148980140685  Test L2 Loss :  0.07943498015403748  inv_L_scale:  [1.0, 1.0]
Epoch :  323  Time:  1.128  Rel. Train L2 Loss :  0.051253310292959216  Rel. Test L2 Loss :  0.0549441185593605  Test L2 Loss :  0.07907629579305649  inv_L_scale:  [1.0, 1.0]
Epoch :  324  Time:  1.131  Rel. Train L2 Loss :  0.05162968824307124  Rel. Test L2 Loss :  0.05638819888234139  Test L2 Loss :  0.08132255673408509  inv_L_scale:  [1.0, 1.0]
Epoch :  325  Time:  1.142  Rel. Train L2 Loss :  0.05102983759509193  Rel. Test L2 Loss :  0.05399903923273087  Test L2 Loss :  0.07781253695487976  inv_L_scale:  [1.0, 1.0]
Epoch :  326  Time:  1.121  Rel. Train L2 Loss :  0.05124305834372838  Rel. Test L2 Loss :  0.053968198001384735  Test L2 Loss :  0.07769168436527252  inv_L_scale:  [1.0, 1.0]
Epoch :  327  Time:  1.136  Rel. Train L2 Loss :  0.0506811165312926  Rel. Test L2 Loss :  0.05479146867990494  Test L2 Loss :  0.0788078510761261  inv_L_scale:  [1.0, 1.0]
Epoch :  328  Time:  1.145  Rel. Train L2 Loss :  0.05109381053182814  Rel. Test L2 Loss :  0.05575690940022469  Test L2 Loss :  0.08008446276187897  inv_L_scale:  [1.0, 1.0]
Epoch :  329  Time:  1.123  Rel. Train L2 Loss :  0.05173447022835414  Rel. Test L2 Loss :  0.05414565116167069  Test L2 Loss :  0.0781108021736145  inv_L_scale:  [1.0, 1.0]
Epoch :  330  Time:  1.108  Rel. Train L2 Loss :  0.05093261841270659  Rel. Test L2 Loss :  0.053930853009223935  Test L2 Loss :  0.07754666328430176  inv_L_scale:  [1.0, 1.0]
Epoch :  331  Time:  1.107  Rel. Train L2 Loss :  0.05100400646527608  Rel. Test L2 Loss :  0.0556808403134346  Test L2 Loss :  0.0800995409488678  inv_L_scale:  [1.0, 1.0]
Epoch :  332  Time:  1.106  Rel. Train L2 Loss :  0.051220586995283764  Rel. Test L2 Loss :  0.05433406919240952  Test L2 Loss :  0.07823699295520782  inv_L_scale:  [1.0, 1.0]
Epoch :  333  Time:  1.107  Rel. Train L2 Loss :  0.050716636901100474  Rel. Test L2 Loss :  0.055211304426193236  Test L2 Loss :  0.07956288039684295  inv_L_scale:  [1.0, 1.0]
Epoch :  334  Time:  1.105  Rel. Train L2 Loss :  0.05091882175869412  Rel. Test L2 Loss :  0.054414641857147214  Test L2 Loss :  0.07834304153919219  inv_L_scale:  [1.0, 1.0]
Epoch :  335  Time:  1.106  Rel. Train L2 Loss :  0.05057375692658954  Rel. Test L2 Loss :  0.05461121946573257  Test L2 Loss :  0.07847629189491272  inv_L_scale:  [1.0, 1.0]
Epoch :  336  Time:  1.119  Rel. Train L2 Loss :  0.050069337205754384  Rel. Test L2 Loss :  0.054156832695007324  Test L2 Loss :  0.07796733438968659  inv_L_scale:  [1.0, 1.0]
Epoch :  337  Time:  1.149  Rel. Train L2 Loss :  0.050438287357489266  Rel. Test L2 Loss :  0.05422013953328133  Test L2 Loss :  0.07806755691766738  inv_L_scale:  [1.0, 1.0]
Epoch :  338  Time:  1.123  Rel. Train L2 Loss :  0.050968352953592935  Rel. Test L2 Loss :  0.05514851927757263  Test L2 Loss :  0.07959705173969268  inv_L_scale:  [1.0, 1.0]
Epoch :  339  Time:  1.126  Rel. Train L2 Loss :  0.0508143460088306  Rel. Test L2 Loss :  0.055346693694591526  Test L2 Loss :  0.0797327145934105  inv_L_scale:  [1.0, 1.0]
Epoch :  340  Time:  1.133  Rel. Train L2 Loss :  0.05065983666314019  Rel. Test L2 Loss :  0.054194446355104446  Test L2 Loss :  0.07809932231903076  inv_L_scale:  [1.0, 1.0]
Epoch :  341  Time:  1.14  Rel. Train L2 Loss :  0.050710684458414715  Rel. Test L2 Loss :  0.053977233916521074  Test L2 Loss :  0.07772894859313965  inv_L_scale:  [1.0, 1.0]
Epoch :  342  Time:  1.11  Rel. Train L2 Loss :  0.04985861505071322  Rel. Test L2 Loss :  0.05384423315525055  Test L2 Loss :  0.0777249750494957  inv_L_scale:  [1.0, 1.0]
Epoch :  343  Time:  1.107  Rel. Train L2 Loss :  0.05046590619617038  Rel. Test L2 Loss :  0.05396215230226517  Test L2 Loss :  0.07780177533626556  inv_L_scale:  [1.0, 1.0]
Epoch :  344  Time:  1.108  Rel. Train L2 Loss :  0.05043109705050786  Rel. Test L2 Loss :  0.053518377244472504  Test L2 Loss :  0.07704278618097306  inv_L_scale:  [1.0, 1.0]
Epoch :  345  Time:  1.106  Rel. Train L2 Loss :  0.04976494805680381  Rel. Test L2 Loss :  0.05454479277133942  Test L2 Loss :  0.07862082123756409  inv_L_scale:  [1.0, 1.0]
Epoch :  346  Time:  1.106  Rel. Train L2 Loss :  0.05003233866559135  Rel. Test L2 Loss :  0.053822585344314576  Test L2 Loss :  0.0775149244070053  inv_L_scale:  [1.0, 1.0]
Epoch :  347  Time:  1.107  Rel. Train L2 Loss :  0.05030197500354714  Rel. Test L2 Loss :  0.05472629845142365  Test L2 Loss :  0.07872336834669114  inv_L_scale:  [1.0, 1.0]
Epoch :  348  Time:  1.103  Rel. Train L2 Loss :  0.05038360786934694  Rel. Test L2 Loss :  0.05353165477514267  Test L2 Loss :  0.07721912175416946  inv_L_scale:  [1.0, 1.0]
Epoch :  349  Time:  1.104  Rel. Train L2 Loss :  0.050203447275691565  Rel. Test L2 Loss :  0.05387965515255928  Test L2 Loss :  0.07791368335485459  inv_L_scale:  [1.0, 1.0]
Epoch :  350  Time:  1.108  Rel. Train L2 Loss :  0.04985615311397446  Rel. Test L2 Loss :  0.053735679239034655  Test L2 Loss :  0.0773585468530655  inv_L_scale:  [1.0, 1.0]
Epoch :  351  Time:  1.105  Rel. Train L2 Loss :  0.049858355654610526  Rel. Test L2 Loss :  0.05327646300196648  Test L2 Loss :  0.07668558329343796  inv_L_scale:  [1.0, 1.0]
Epoch :  352  Time:  1.106  Rel. Train L2 Loss :  0.049875954174333145  Rel. Test L2 Loss :  0.05345947995781899  Test L2 Loss :  0.07715010285377502  inv_L_scale:  [1.0, 1.0]
Epoch :  353  Time:  1.106  Rel. Train L2 Loss :  0.049234993606805805  Rel. Test L2 Loss :  0.053312265276908875  Test L2 Loss :  0.07682767748832703  inv_L_scale:  [1.0, 1.0]
Epoch :  354  Time:  1.108  Rel. Train L2 Loss :  0.04984425178832478  Rel. Test L2 Loss :  0.05402801588177681  Test L2 Loss :  0.07803041070699691  inv_L_scale:  [1.0, 1.0]
Epoch :  355  Time:  1.107  Rel. Train L2 Loss :  0.04930197374688255  Rel. Test L2 Loss :  0.053552261739969256  Test L2 Loss :  0.07737874269485473  inv_L_scale:  [1.0, 1.0]
Epoch :  356  Time:  1.107  Rel. Train L2 Loss :  0.049570505056116314  Rel. Test L2 Loss :  0.052336382418870925  Test L2 Loss :  0.07540529042482376  inv_L_scale:  [1.0, 1.0]
Epoch :  357  Time:  1.106  Rel. Train L2 Loss :  0.04965795578228103  Rel. Test L2 Loss :  0.05350601553916931  Test L2 Loss :  0.07690082430839539  inv_L_scale:  [1.0, 1.0]
Epoch :  358  Time:  1.107  Rel. Train L2 Loss :  0.049382140023840795  Rel. Test L2 Loss :  0.053125655353069304  Test L2 Loss :  0.07646156787872314  inv_L_scale:  [1.0, 1.0]
Epoch :  359  Time:  1.107  Rel. Train L2 Loss :  0.04901629772451189  Rel. Test L2 Loss :  0.053235624134540555  Test L2 Loss :  0.07654333621263504  inv_L_scale:  [1.0, 1.0]
Epoch :  360  Time:  1.107  Rel. Train L2 Loss :  0.04975470486614439  Rel. Test L2 Loss :  0.05344425827264786  Test L2 Loss :  0.07698114275932312  inv_L_scale:  [1.0, 1.0]
Epoch :  361  Time:  1.106  Rel. Train L2 Loss :  0.049343682063950435  Rel. Test L2 Loss :  0.053885726034641264  Test L2 Loss :  0.0777188640832901  inv_L_scale:  [1.0, 1.0]
Epoch :  362  Time:  1.105  Rel. Train L2 Loss :  0.04920700894461738  Rel. Test L2 Loss :  0.052844794392585756  Test L2 Loss :  0.0762280848622322  inv_L_scale:  [1.0, 1.0]
Epoch :  363  Time:  1.108  Rel. Train L2 Loss :  0.04914907650815116  Rel. Test L2 Loss :  0.05335005789995193  Test L2 Loss :  0.07682390928268433  inv_L_scale:  [1.0, 1.0]
Epoch :  364  Time:  1.107  Rel. Train L2 Loss :  0.04932402226659987  Rel. Test L2 Loss :  0.05300272226333618  Test L2 Loss :  0.07640229493379593  inv_L_scale:  [1.0, 1.0]
Epoch :  365  Time:  1.106  Rel. Train L2 Loss :  0.04929679036140442  Rel. Test L2 Loss :  0.052892527729272845  Test L2 Loss :  0.07626833438873291  inv_L_scale:  [1.0, 1.0]
Epoch :  366  Time:  1.106  Rel. Train L2 Loss :  0.048787569486432605  Rel. Test L2 Loss :  0.0536964276432991  Test L2 Loss :  0.07740152478218079  inv_L_scale:  [1.0, 1.0]
Epoch :  367  Time:  1.105  Rel. Train L2 Loss :  0.04905081517166562  Rel. Test L2 Loss :  0.05323779791593552  Test L2 Loss :  0.0765914797782898  inv_L_scale:  [1.0, 1.0]
Epoch :  368  Time:  1.105  Rel. Train L2 Loss :  0.04880362262328466  Rel. Test L2 Loss :  0.05329248160123825  Test L2 Loss :  0.07678513079881669  inv_L_scale:  [1.0, 1.0]
Epoch :  369  Time:  1.107  Rel. Train L2 Loss :  0.048896161764860155  Rel. Test L2 Loss :  0.0525908213853836  Test L2 Loss :  0.0757585620880127  inv_L_scale:  [1.0, 1.0]
Epoch :  370  Time:  1.105  Rel. Train L2 Loss :  0.04883861165907648  Rel. Test L2 Loss :  0.054893955141305927  Test L2 Loss :  0.07895806431770325  inv_L_scale:  [1.0, 1.0]
Epoch :  371  Time:  1.108  Rel. Train L2 Loss :  0.04899098818500837  Rel. Test L2 Loss :  0.05314078152179718  Test L2 Loss :  0.07651180744171143  inv_L_scale:  [1.0, 1.0]
Epoch :  372  Time:  1.106  Rel. Train L2 Loss :  0.048570716083049775  Rel. Test L2 Loss :  0.05302461117506027  Test L2 Loss :  0.07644309997558593  inv_L_scale:  [1.0, 1.0]
Epoch :  373  Time:  1.107  Rel. Train L2 Loss :  0.048838419997029835  Rel. Test L2 Loss :  0.05316053420305252  Test L2 Loss :  0.07667972981929778  inv_L_scale:  [1.0, 1.0]
Epoch :  374  Time:  1.105  Rel. Train L2 Loss :  0.048628042853540845  Rel. Test L2 Loss :  0.052717655152082446  Test L2 Loss :  0.07589179337024689  inv_L_scale:  [1.0, 1.0]
Epoch :  375  Time:  1.105  Rel. Train L2 Loss :  0.048322136203447975  Rel. Test L2 Loss :  0.05276074439287186  Test L2 Loss :  0.07586587280035019  inv_L_scale:  [1.0, 1.0]
Epoch :  376  Time:  1.107  Rel. Train L2 Loss :  0.048227621499035096  Rel. Test L2 Loss :  0.05269623696804047  Test L2 Loss :  0.07598731964826584  inv_L_scale:  [1.0, 1.0]
Epoch :  377  Time:  1.119  Rel. Train L2 Loss :  0.04829591421617402  Rel. Test L2 Loss :  0.05316185936331749  Test L2 Loss :  0.07660549700260162  inv_L_scale:  [1.0, 1.0]
Epoch :  378  Time:  1.145  Rel. Train L2 Loss :  0.04924104298154513  Rel. Test L2 Loss :  0.05237860023975372  Test L2 Loss :  0.0754279261827469  inv_L_scale:  [1.0, 1.0]
Epoch :  379  Time:  1.128  Rel. Train L2 Loss :  0.04829622839887937  Rel. Test L2 Loss :  0.052843679189682004  Test L2 Loss :  0.07608868271112441  inv_L_scale:  [1.0, 1.0]
Epoch :  380  Time:  1.137  Rel. Train L2 Loss :  0.047978863964478174  Rel. Test L2 Loss :  0.05265395998954773  Test L2 Loss :  0.07577195286750793  inv_L_scale:  [1.0, 1.0]
Epoch :  381  Time:  1.136  Rel. Train L2 Loss :  0.04801419107450379  Rel. Test L2 Loss :  0.052388362288475036  Test L2 Loss :  0.07542662501335144  inv_L_scale:  [1.0, 1.0]
Epoch :  382  Time:  1.132  Rel. Train L2 Loss :  0.04812568366527557  Rel. Test L2 Loss :  0.052895854860544204  Test L2 Loss :  0.07618945956230164  inv_L_scale:  [1.0, 1.0]
Epoch :  383  Time:  1.144  Rel. Train L2 Loss :  0.04808407639463742  Rel. Test L2 Loss :  0.05221555382013321  Test L2 Loss :  0.07514317244291306  inv_L_scale:  [1.0, 1.0]
Epoch :  384  Time:  1.115  Rel. Train L2 Loss :  0.04800592073135906  Rel. Test L2 Loss :  0.05251338660717011  Test L2 Loss :  0.07555850327014924  inv_L_scale:  [1.0, 1.0]
Epoch :  385  Time:  1.117  Rel. Train L2 Loss :  0.047730251020855374  Rel. Test L2 Loss :  0.05268051341176033  Test L2 Loss :  0.07591590464115143  inv_L_scale:  [1.0, 1.0]
Epoch :  386  Time:  1.129  Rel. Train L2 Loss :  0.047985842873652776  Rel. Test L2 Loss :  0.05264251470565796  Test L2 Loss :  0.07582233786582947  inv_L_scale:  [1.0, 1.0]
Epoch :  387  Time:  1.131  Rel. Train L2 Loss :  0.04770831498834822  Rel. Test L2 Loss :  0.05269219264388084  Test L2 Loss :  0.07581406891345978  inv_L_scale:  [1.0, 1.0]
Epoch :  388  Time:  1.137  Rel. Train L2 Loss :  0.0480136323803001  Rel. Test L2 Loss :  0.051944364458322526  Test L2 Loss :  0.07474328190088272  inv_L_scale:  [1.0, 1.0]
Epoch :  389  Time:  1.14  Rel. Train L2 Loss :  0.047629314702418116  Rel. Test L2 Loss :  0.05174061864614487  Test L2 Loss :  0.07450774878263473  inv_L_scale:  [1.0, 1.0]
Epoch :  390  Time:  1.136  Rel. Train L2 Loss :  0.04761566379004055  Rel. Test L2 Loss :  0.052405433356761934  Test L2 Loss :  0.07552901357412338  inv_L_scale:  [1.0, 1.0]
Epoch :  391  Time:  1.12  Rel. Train L2 Loss :  0.04761380496952269  Rel. Test L2 Loss :  0.05266071170568466  Test L2 Loss :  0.07580494850873948  inv_L_scale:  [1.0, 1.0]
Epoch :  392  Time:  1.134  Rel. Train L2 Loss :  0.04776348652111159  Rel. Test L2 Loss :  0.05260499507188797  Test L2 Loss :  0.07579785048961639  inv_L_scale:  [1.0, 1.0]
Epoch :  393  Time:  1.124  Rel. Train L2 Loss :  0.047603291538026594  Rel. Test L2 Loss :  0.05209083184599876  Test L2 Loss :  0.07509885013103484  inv_L_scale:  [1.0, 1.0]
Epoch :  394  Time:  1.125  Rel. Train L2 Loss :  0.047555766602357226  Rel. Test L2 Loss :  0.05220413476228714  Test L2 Loss :  0.0751736569404602  inv_L_scale:  [1.0, 1.0]
Epoch :  395  Time:  1.127  Rel. Train L2 Loss :  0.04786956068542268  Rel. Test L2 Loss :  0.05256971523165703  Test L2 Loss :  0.0757058709859848  inv_L_scale:  [1.0, 1.0]
Epoch :  396  Time:  1.126  Rel. Train L2 Loss :  0.0473269504474269  Rel. Test L2 Loss :  0.05205117166042328  Test L2 Loss :  0.07492013603448867  inv_L_scale:  [1.0, 1.0]
Epoch :  397  Time:  1.132  Rel. Train L2 Loss :  0.04760644210709466  Rel. Test L2 Loss :  0.0519292376935482  Test L2 Loss :  0.07478835791349411  inv_L_scale:  [1.0, 1.0]
Epoch :  398  Time:  1.148  Rel. Train L2 Loss :  0.04739393769039048  Rel. Test L2 Loss :  0.05159847900271416  Test L2 Loss :  0.07433047652244568  inv_L_scale:  [1.0, 1.0]
Epoch :  399  Time:  1.109  Rel. Train L2 Loss :  0.04718565733896361  Rel. Test L2 Loss :  0.05169709026813507  Test L2 Loss :  0.07437534898519516  inv_L_scale:  [1.0, 1.0]
Epoch :  400  Time:  1.109  Rel. Train L2 Loss :  0.0471581968665123  Rel. Test L2 Loss :  0.05178198277950287  Test L2 Loss :  0.0746426272392273  inv_L_scale:  [1.0, 1.0]
Epoch :  401  Time:  1.109  Rel. Train L2 Loss :  0.04767384154929055  Rel. Test L2 Loss :  0.05210262104868889  Test L2 Loss :  0.07506710857152939  inv_L_scale:  [1.0, 1.0]
Epoch :  402  Time:  1.111  Rel. Train L2 Loss :  0.047155742247899375  Rel. Test L2 Loss :  0.05188652336597443  Test L2 Loss :  0.07467167854309081  inv_L_scale:  [1.0, 1.0]
Epoch :  403  Time:  1.109  Rel. Train L2 Loss :  0.047077683872646756  Rel. Test L2 Loss :  0.051883476078510286  Test L2 Loss :  0.07464124947786331  inv_L_scale:  [1.0, 1.0]
Epoch :  404  Time:  1.109  Rel. Train L2 Loss :  0.04692949323190583  Rel. Test L2 Loss :  0.05174122542142868  Test L2 Loss :  0.0746058040857315  inv_L_scale:  [1.0, 1.0]
Epoch :  405  Time:  1.109  Rel. Train L2 Loss :  0.04695127328236898  Rel. Test L2 Loss :  0.05168043181300163  Test L2 Loss :  0.07456439316272735  inv_L_scale:  [1.0, 1.0]
Epoch :  406  Time:  1.109  Rel. Train L2 Loss :  0.046864917394187716  Rel. Test L2 Loss :  0.051915358603000644  Test L2 Loss :  0.07471454054117203  inv_L_scale:  [1.0, 1.0]
Epoch :  407  Time:  1.109  Rel. Train L2 Loss :  0.046907312323649725  Rel. Test L2 Loss :  0.0518145053088665  Test L2 Loss :  0.07469038426876068  inv_L_scale:  [1.0, 1.0]
Epoch :  408  Time:  1.11  Rel. Train L2 Loss :  0.04691681800617112  Rel. Test L2 Loss :  0.051477498710155487  Test L2 Loss :  0.0742598557472229  inv_L_scale:  [1.0, 1.0]
Epoch :  409  Time:  1.107  Rel. Train L2 Loss :  0.04683811095025804  Rel. Test L2 Loss :  0.051527912318706515  Test L2 Loss :  0.07422131568193435  inv_L_scale:  [1.0, 1.0]
Epoch :  410  Time:  1.107  Rel. Train L2 Loss :  0.04675263416435983  Rel. Test L2 Loss :  0.05157202124595642  Test L2 Loss :  0.07422833174467086  inv_L_scale:  [1.0, 1.0]
Epoch :  411  Time:  1.107  Rel. Train L2 Loss :  0.046709001660346985  Rel. Test L2 Loss :  0.051572062969207765  Test L2 Loss :  0.07424680680036545  inv_L_scale:  [1.0, 1.0]
Epoch :  412  Time:  1.108  Rel. Train L2 Loss :  0.04685709430111779  Rel. Test L2 Loss :  0.051433271169662474  Test L2 Loss :  0.0740358430147171  inv_L_scale:  [1.0, 1.0]
Epoch :  413  Time:  1.108  Rel. Train L2 Loss :  0.04668760513265928  Rel. Test L2 Loss :  0.0515245695412159  Test L2 Loss :  0.07426087468862534  inv_L_scale:  [1.0, 1.0]
Epoch :  414  Time:  1.108  Rel. Train L2 Loss :  0.04693475138809946  Rel. Test L2 Loss :  0.05140705659985542  Test L2 Loss :  0.07415819644927979  inv_L_scale:  [1.0, 1.0]
Epoch :  415  Time:  1.109  Rel. Train L2 Loss :  0.046599468241135276  Rel. Test L2 Loss :  0.05165669396519661  Test L2 Loss :  0.07438939660787583  inv_L_scale:  [1.0, 1.0]
Epoch :  416  Time:  1.108  Rel. Train L2 Loss :  0.046524120519558586  Rel. Test L2 Loss :  0.051770739704370496  Test L2 Loss :  0.0746002659201622  inv_L_scale:  [1.0, 1.0]
Epoch :  417  Time:  1.11  Rel. Train L2 Loss :  0.046635123673412535  Rel. Test L2 Loss :  0.05154627293348312  Test L2 Loss :  0.07433205097913742  inv_L_scale:  [1.0, 1.0]
Epoch :  418  Time:  1.109  Rel. Train L2 Loss :  0.046424401683939825  Rel. Test L2 Loss :  0.05141378551721573  Test L2 Loss :  0.07407025426626206  inv_L_scale:  [1.0, 1.0]
Epoch :  419  Time:  1.109  Rel. Train L2 Loss :  0.046407552493943106  Rel. Test L2 Loss :  0.051768434941768644  Test L2 Loss :  0.07448538422584533  inv_L_scale:  [1.0, 1.0]
Epoch :  420  Time:  1.108  Rel. Train L2 Loss :  0.04661858295400938  Rel. Test L2 Loss :  0.051464121341705325  Test L2 Loss :  0.07406091898679733  inv_L_scale:  [1.0, 1.0]
Epoch :  421  Time:  1.108  Rel. Train L2 Loss :  0.04648597670925988  Rel. Test L2 Loss :  0.05138231724500656  Test L2 Loss :  0.07399713724851609  inv_L_scale:  [1.0, 1.0]
Epoch :  422  Time:  1.107  Rel. Train L2 Loss :  0.04647988667090734  Rel. Test L2 Loss :  0.051500563472509385  Test L2 Loss :  0.07414469808340073  inv_L_scale:  [1.0, 1.0]
Epoch :  423  Time:  1.108  Rel. Train L2 Loss :  0.046337852345572576  Rel. Test L2 Loss :  0.051173763871192934  Test L2 Loss :  0.073752022087574  inv_L_scale:  [1.0, 1.0]
Epoch :  424  Time:  1.11  Rel. Train L2 Loss :  0.046205831087297866  Rel. Test L2 Loss :  0.05159790083765983  Test L2 Loss :  0.0743299213051796  inv_L_scale:  [1.0, 1.0]
Epoch :  425  Time:  1.11  Rel. Train L2 Loss :  0.04625107400947147  Rel. Test L2 Loss :  0.05163529098033905  Test L2 Loss :  0.07434198707342148  inv_L_scale:  [1.0, 1.0]
Epoch :  426  Time:  1.109  Rel. Train L2 Loss :  0.04626054985655679  Rel. Test L2 Loss :  0.05141470700502396  Test L2 Loss :  0.07403298288583755  inv_L_scale:  [1.0, 1.0]
Epoch :  427  Time:  1.109  Rel. Train L2 Loss :  0.046337741298807994  Rel. Test L2 Loss :  0.0514906045794487  Test L2 Loss :  0.07415693461894989  inv_L_scale:  [1.0, 1.0]
Epoch :  428  Time:  1.11  Rel. Train L2 Loss :  0.04615013430515925  Rel. Test L2 Loss :  0.05120095461606979  Test L2 Loss :  0.07371909528970719  inv_L_scale:  [1.0, 1.0]
Epoch :  429  Time:  1.11  Rel. Train L2 Loss :  0.04610283467504713  Rel. Test L2 Loss :  0.0512773372232914  Test L2 Loss :  0.07378123730421066  inv_L_scale:  [1.0, 1.0]
Epoch :  430  Time:  1.109  Rel. Train L2 Loss :  0.04613778407375018  Rel. Test L2 Loss :  0.05141632750630379  Test L2 Loss :  0.07401160448789597  inv_L_scale:  [1.0, 1.0]
Epoch :  431  Time:  1.11  Rel. Train L2 Loss :  0.04605857121447722  Rel. Test L2 Loss :  0.051138394474983216  Test L2 Loss :  0.07357151806354523  inv_L_scale:  [1.0, 1.0]
Epoch :  432  Time:  1.112  Rel. Train L2 Loss :  0.046070842411783004  Rel. Test L2 Loss :  0.05118989646434784  Test L2 Loss :  0.07373128265142441  inv_L_scale:  [1.0, 1.0]
Epoch :  433  Time:  1.111  Rel. Train L2 Loss :  0.04601900514629152  Rel. Test L2 Loss :  0.050938527435064315  Test L2 Loss :  0.07329503625631333  inv_L_scale:  [1.0, 1.0]
Epoch :  434  Time:  1.109  Rel. Train L2 Loss :  0.04596128801504771  Rel. Test L2 Loss :  0.05106584295630455  Test L2 Loss :  0.07352559834718704  inv_L_scale:  [1.0, 1.0]
Epoch :  435  Time:  1.111  Rel. Train L2 Loss :  0.04591049480769369  Rel. Test L2 Loss :  0.05122023195028305  Test L2 Loss :  0.0737788999080658  inv_L_scale:  [1.0, 1.0]
Epoch :  436  Time:  1.111  Rel. Train L2 Loss :  0.04596945876876513  Rel. Test L2 Loss :  0.051324166804552075  Test L2 Loss :  0.07390089184045792  inv_L_scale:  [1.0, 1.0]
Epoch :  437  Time:  1.111  Rel. Train L2 Loss :  0.04592000603675842  Rel. Test L2 Loss :  0.051030344665050506  Test L2 Loss :  0.0734189012646675  inv_L_scale:  [1.0, 1.0]
Epoch :  438  Time:  1.111  Rel. Train L2 Loss :  0.04587233051657677  Rel. Test L2 Loss :  0.05134788244962692  Test L2 Loss :  0.0738563272356987  inv_L_scale:  [1.0, 1.0]
Epoch :  439  Time:  1.11  Rel. Train L2 Loss :  0.04601090658042166  Rel. Test L2 Loss :  0.051220822781324386  Test L2 Loss :  0.07376314252614975  inv_L_scale:  [1.0, 1.0]
Epoch :  440  Time:  1.109  Rel. Train L2 Loss :  0.045805253816975484  Rel. Test L2 Loss :  0.05096554934978485  Test L2 Loss :  0.07339604496955872  inv_L_scale:  [1.0, 1.0]
Epoch :  441  Time:  1.109  Rel. Train L2 Loss :  0.04576364147994253  Rel. Test L2 Loss :  0.05115968123078346  Test L2 Loss :  0.07365574538707734  inv_L_scale:  [1.0, 1.0]
Epoch :  442  Time:  1.112  Rel. Train L2 Loss :  0.04571706626150343  Rel. Test L2 Loss :  0.05110068276524544  Test L2 Loss :  0.07357667446136475  inv_L_scale:  [1.0, 1.0]
Epoch :  443  Time:  1.109  Rel. Train L2 Loss :  0.04570810120966699  Rel. Test L2 Loss :  0.05106511354446411  Test L2 Loss :  0.0735098248720169  inv_L_scale:  [1.0, 1.0]
Epoch :  444  Time:  1.11  Rel. Train L2 Loss :  0.04567278691464  Rel. Test L2 Loss :  0.05089888453483581  Test L2 Loss :  0.07324403673410415  inv_L_scale:  [1.0, 1.0]
Epoch :  445  Time:  1.11  Rel. Train L2 Loss :  0.04565362254778544  Rel. Test L2 Loss :  0.05094121843576431  Test L2 Loss :  0.07332996666431427  inv_L_scale:  [1.0, 1.0]
Epoch :  446  Time:  1.112  Rel. Train L2 Loss :  0.045706928471724195  Rel. Test L2 Loss :  0.05093483030796051  Test L2 Loss :  0.07335461914539337  inv_L_scale:  [1.0, 1.0]
Epoch :  447  Time:  1.112  Rel. Train L2 Loss :  0.04563009830812613  Rel. Test L2 Loss :  0.050945978164672855  Test L2 Loss :  0.07332084327936172  inv_L_scale:  [1.0, 1.0]
Epoch :  448  Time:  1.11  Rel. Train L2 Loss :  0.04558026995923784  Rel. Test L2 Loss :  0.05092618659138679  Test L2 Loss :  0.07328600764274597  inv_L_scale:  [1.0, 1.0]
Epoch :  449  Time:  1.111  Rel. Train L2 Loss :  0.04559857610199187  Rel. Test L2 Loss :  0.050846369564533235  Test L2 Loss :  0.07318006187677384  inv_L_scale:  [1.0, 1.0]
Epoch :  450  Time:  1.112  Rel. Train L2 Loss :  0.045559398722317485  Rel. Test L2 Loss :  0.05110942751169205  Test L2 Loss :  0.07353493750095368  inv_L_scale:  [1.0, 1.0]
Epoch :  451  Time:  1.113  Rel. Train L2 Loss :  0.04558721250957913  Rel. Test L2 Loss :  0.05074896305799484  Test L2 Loss :  0.07310677379369736  inv_L_scale:  [1.0, 1.0]
Epoch :  452  Time:  1.11  Rel. Train L2 Loss :  0.0455033712916904  Rel. Test L2 Loss :  0.05089873164892197  Test L2 Loss :  0.07328015238046647  inv_L_scale:  [1.0, 1.0]
Epoch :  453  Time:  1.11  Rel. Train L2 Loss :  0.04548526811930868  Rel. Test L2 Loss :  0.05080130755901337  Test L2 Loss :  0.07311910599470138  inv_L_scale:  [1.0, 1.0]
Epoch :  454  Time:  1.114  Rel. Train L2 Loss :  0.04548500178588761  Rel. Test L2 Loss :  0.051059515178203584  Test L2 Loss :  0.07344261586666107  inv_L_scale:  [1.0, 1.0]
Epoch :  455  Time:  1.113  Rel. Train L2 Loss :  0.045444587734010486  Rel. Test L2 Loss :  0.05077628493309021  Test L2 Loss :  0.07310719281435013  inv_L_scale:  [1.0, 1.0]
Epoch :  456  Time:  1.11  Rel. Train L2 Loss :  0.04542864422003428  Rel. Test L2 Loss :  0.050839353650808335  Test L2 Loss :  0.07315575420856475  inv_L_scale:  [1.0, 1.0]
Epoch :  457  Time:  1.111  Rel. Train L2 Loss :  0.04537217280930943  Rel. Test L2 Loss :  0.05098931759595871  Test L2 Loss :  0.07335451662540436  inv_L_scale:  [1.0, 1.0]
Epoch :  458  Time:  1.11  Rel. Train L2 Loss :  0.04540083310670323  Rel. Test L2 Loss :  0.05076957255601883  Test L2 Loss :  0.07304423689842224  inv_L_scale:  [1.0, 1.0]
Epoch :  459  Time:  1.111  Rel. Train L2 Loss :  0.04537077875600921  Rel. Test L2 Loss :  0.05082127898931503  Test L2 Loss :  0.07315790891647339  inv_L_scale:  [1.0, 1.0]
Epoch :  460  Time:  1.111  Rel. Train L2 Loss :  0.04534997304280599  Rel. Test L2 Loss :  0.05112403452396393  Test L2 Loss :  0.07358358979225159  inv_L_scale:  [1.0, 1.0]
Epoch :  461  Time:  1.111  Rel. Train L2 Loss :  0.045328575157456925  Rel. Test L2 Loss :  0.050959397256374356  Test L2 Loss :  0.0733241781592369  inv_L_scale:  [1.0, 1.0]
Epoch :  462  Time:  1.113  Rel. Train L2 Loss :  0.04528532363474369  Rel. Test L2 Loss :  0.05094924256205559  Test L2 Loss :  0.07334078460931778  inv_L_scale:  [1.0, 1.0]
Epoch :  463  Time:  1.112  Rel. Train L2 Loss :  0.045286301887697646  Rel. Test L2 Loss :  0.05089118927717209  Test L2 Loss :  0.0732146868109703  inv_L_scale:  [1.0, 1.0]
Epoch :  464  Time:  1.112  Rel. Train L2 Loss :  0.04525464735097355  Rel. Test L2 Loss :  0.050912986993789676  Test L2 Loss :  0.07326929062604905  inv_L_scale:  [1.0, 1.0]
Epoch :  465  Time:  1.115  Rel. Train L2 Loss :  0.04524600204494265  Rel. Test L2 Loss :  0.050838725566864015  Test L2 Loss :  0.073177892267704  inv_L_scale:  [1.0, 1.0]
Epoch :  466  Time:  1.112  Rel. Train L2 Loss :  0.045228447483645545  Rel. Test L2 Loss :  0.05093787506222725  Test L2 Loss :  0.07330845683813095  inv_L_scale:  [1.0, 1.0]
Epoch :  467  Time:  1.112  Rel. Train L2 Loss :  0.04524260027541055  Rel. Test L2 Loss :  0.05089263364672661  Test L2 Loss :  0.07321911960840226  inv_L_scale:  [1.0, 1.0]
Epoch :  468  Time:  1.111  Rel. Train L2 Loss :  0.04520798593759537  Rel. Test L2 Loss :  0.050878569185733795  Test L2 Loss :  0.07323913276195526  inv_L_scale:  [1.0, 1.0]
Epoch :  469  Time:  1.112  Rel. Train L2 Loss :  0.04518411033683353  Rel. Test L2 Loss :  0.05085533916950226  Test L2 Loss :  0.07319300144910812  inv_L_scale:  [1.0, 1.0]
Epoch :  470  Time:  1.112  Rel. Train L2 Loss :  0.04518628751238187  Rel. Test L2 Loss :  0.050908371657133106  Test L2 Loss :  0.07325497329235077  inv_L_scale:  [1.0, 1.0]
Epoch :  471  Time:  1.112  Rel. Train L2 Loss :  0.045160437855455614  Rel. Test L2 Loss :  0.05091996029019356  Test L2 Loss :  0.0732804724574089  inv_L_scale:  [1.0, 1.0]
Epoch :  472  Time:  1.112  Rel. Train L2 Loss :  0.04514989412493176  Rel. Test L2 Loss :  0.0509072944521904  Test L2 Loss :  0.07324447691440582  inv_L_scale:  [1.0, 1.0]
Epoch :  473  Time:  1.111  Rel. Train L2 Loss :  0.04513252311282688  Rel. Test L2 Loss :  0.05081464990973473  Test L2 Loss :  0.0731337708234787  inv_L_scale:  [1.0, 1.0]
Epoch :  474  Time:  1.113  Rel. Train L2 Loss :  0.045119901680284076  Rel. Test L2 Loss :  0.050893501937389375  Test L2 Loss :  0.07324167847633362  inv_L_scale:  [1.0, 1.0]
Epoch :  475  Time:  1.113  Rel. Train L2 Loss :  0.04511196580198076  Rel. Test L2 Loss :  0.05086334645748138  Test L2 Loss :  0.07319177508354187  inv_L_scale:  [1.0, 1.0]
Epoch :  476  Time:  1.113  Rel. Train L2 Loss :  0.04510563792453872  Rel. Test L2 Loss :  0.05085509270429611  Test L2 Loss :  0.0731796544790268  inv_L_scale:  [1.0, 1.0]
Epoch :  477  Time:  1.112  Rel. Train L2 Loss :  0.04510068881842825  Rel. Test L2 Loss :  0.05078120768070221  Test L2 Loss :  0.07307406932115555  inv_L_scale:  [1.0, 1.0]
Epoch :  478  Time:  1.112  Rel. Train L2 Loss :  0.04508006797896491  Rel. Test L2 Loss :  0.05087608873844147  Test L2 Loss :  0.07321395635604859  inv_L_scale:  [1.0, 1.0]
Epoch :  479  Time:  1.113  Rel. Train L2 Loss :  0.04507416134079297  Rel. Test L2 Loss :  0.05081900015473366  Test L2 Loss :  0.07312613636255265  inv_L_scale:  [1.0, 1.0]
Epoch :  480  Time:  1.113  Rel. Train L2 Loss :  0.04506276276376512  Rel. Test L2 Loss :  0.05087166547775269  Test L2 Loss :  0.07320667088031768  inv_L_scale:  [1.0, 1.0]
Epoch :  481  Time:  1.112  Rel. Train L2 Loss :  0.04505046389169163  Rel. Test L2 Loss :  0.050826386064291  Test L2 Loss :  0.07314718931913376  inv_L_scale:  [1.0, 1.0]
Epoch :  482  Time:  1.113  Rel. Train L2 Loss :  0.045039374811781774  Rel. Test L2 Loss :  0.050827566683292386  Test L2 Loss :  0.07313305377960205  inv_L_scale:  [1.0, 1.0]
Epoch :  483  Time:  1.113  Rel. Train L2 Loss :  0.04503284297055668  Rel. Test L2 Loss :  0.05082409560680389  Test L2 Loss :  0.07313538789749145  inv_L_scale:  [1.0, 1.0]
Epoch :  484  Time:  1.112  Rel. Train L2 Loss :  0.04502192169427872  Rel. Test L2 Loss :  0.05082627758383751  Test L2 Loss :  0.0731356680393219  inv_L_scale:  [1.0, 1.0]
Epoch :  485  Time:  1.112  Rel. Train L2 Loss :  0.04501731269889408  Rel. Test L2 Loss :  0.050877503752708435  Test L2 Loss :  0.07322573095560074  inv_L_scale:  [1.0, 1.0]
Epoch :  486  Time:  1.113  Rel. Train L2 Loss :  0.045013470335139166  Rel. Test L2 Loss :  0.05083484590053558  Test L2 Loss :  0.0731506660580635  inv_L_scale:  [1.0, 1.0]
Epoch :  487  Time:  1.113  Rel. Train L2 Loss :  0.045009500251875986  Rel. Test L2 Loss :  0.050838924497365955  Test L2 Loss :  0.07315369933843613  inv_L_scale:  [1.0, 1.0]
Epoch :  488  Time:  1.113  Rel. Train L2 Loss :  0.04499893120593495  Rel. Test L2 Loss :  0.05079943060874939  Test L2 Loss :  0.07309642732143402  inv_L_scale:  [1.0, 1.0]
Epoch :  489  Time:  1.112  Rel. Train L2 Loss :  0.04499341266022788  Rel. Test L2 Loss :  0.05082154080271721  Test L2 Loss :  0.07312977850437165  inv_L_scale:  [1.0, 1.0]
Epoch :  490  Time:  1.114  Rel. Train L2 Loss :  0.04499625090095732  Rel. Test L2 Loss :  0.05081442251801491  Test L2 Loss :  0.07311558514833451  inv_L_scale:  [1.0, 1.0]
Epoch :  491  Time:  1.113  Rel. Train L2 Loss :  0.04498374318910969  Rel. Test L2 Loss :  0.05082633584737778  Test L2 Loss :  0.07313116252422333  inv_L_scale:  [1.0, 1.0]
Epoch :  492  Time:  1.114  Rel. Train L2 Loss :  0.044979144980510075  Rel. Test L2 Loss :  0.0508482164144516  Test L2 Loss :  0.07316782921552659  inv_L_scale:  [1.0, 1.0]
Epoch :  493  Time:  1.114  Rel. Train L2 Loss :  0.04497557264235284  Rel. Test L2 Loss :  0.0508501124382019  Test L2 Loss :  0.07316669493913651  inv_L_scale:  [1.0, 1.0]
Epoch :  494  Time:  1.115  Rel. Train L2 Loss :  0.04497642300195164  Rel. Test L2 Loss :  0.05086352437734604  Test L2 Loss :  0.07319832414388656  inv_L_scale:  [1.0, 1.0]
Epoch :  495  Time:  1.113  Rel. Train L2 Loss :  0.044972266091240776  Rel. Test L2 Loss :  0.0508115853369236  Test L2 Loss :  0.07312117338180542  inv_L_scale:  [1.0, 1.0]
Epoch :  496  Time:  1.113  Rel. Train L2 Loss :  0.044970611449744964  Rel. Test L2 Loss :  0.05085264682769775  Test L2 Loss :  0.07317212134599686  inv_L_scale:  [1.0, 1.0]
Epoch :  497  Time:  1.114  Rel. Train L2 Loss :  0.04496910681327184  Rel. Test L2 Loss :  0.05083026230335236  Test L2 Loss :  0.07314853996038437  inv_L_scale:  [1.0, 1.0]
Epoch :  498  Time:  1.113  Rel. Train L2 Loss :  0.04496446323063639  Rel. Test L2 Loss :  0.050859941244125365  Test L2 Loss :  0.07318810403347015  inv_L_scale:  [1.0, 1.0]
Epoch :  499  Time:  1.113  Rel. Train L2 Loss :  0.044966943545473946  Rel. Test L2 Loss :  0.050839172899723055  Test L2 Loss :  0.07316343039274216  inv_L_scale:  [1.0, 1.0]