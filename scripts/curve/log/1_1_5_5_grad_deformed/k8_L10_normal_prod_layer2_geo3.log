(1000,) (1000, 1000, 1) (1000, 1000, 2)
use normalized raw measures
Casting to tensor
x_train shape torch.Size([900, 1000, 8]), y_train shape torch.Size([900, 1000, 1])
length of each dim:  tensor([6.5573987960815430, 6.1420288085937500])
kmax = 8
L = 10
use cube modes, scale = 0 (144, 2, 1)
geo_dims = [1, 2, 3, 4]
In PCNO_train, ndims =  2
Epoch :  0  Time:  1.121  Rel. Train L2 Loss :  0.5009807031684451  Rel. Test L2 Loss :  0.3680689167976379  Test L2 Loss :  0.5273442912101746  inv_L_scale:  [1.0, 1.0]
Epoch :  1  Time:  0.771  Rel. Train L2 Loss :  0.27951095283031463  Rel. Test L2 Loss :  0.25374382853507993  Test L2 Loss :  0.36862011671066286  inv_L_scale:  [1.0, 1.0]
Epoch :  2  Time:  0.768  Rel. Train L2 Loss :  0.19739551146825154  Rel. Test L2 Loss :  0.1919955551624298  Test L2 Loss :  0.2712979757785797  inv_L_scale:  [1.0, 1.0]
Epoch :  3  Time:  0.769  Rel. Train L2 Loss :  0.16401271495554182  Rel. Test L2 Loss :  0.16656837821006776  Test L2 Loss :  0.23675499081611634  inv_L_scale:  [1.0, 1.0]
Epoch :  4  Time:  0.773  Rel. Train L2 Loss :  0.14086207846800486  Rel. Test L2 Loss :  0.15494009613990783  Test L2 Loss :  0.2191353714466095  inv_L_scale:  [1.0, 1.0]
Epoch :  5  Time:  0.774  Rel. Train L2 Loss :  0.12470705025725895  Rel. Test L2 Loss :  0.14707502007484435  Test L2 Loss :  0.2101627743244171  inv_L_scale:  [1.0, 1.0]
Epoch :  6  Time:  0.768  Rel. Train L2 Loss :  0.11764654371473525  Rel. Test L2 Loss :  0.1406747007369995  Test L2 Loss :  0.1994137978553772  inv_L_scale:  [1.0, 1.0]
Epoch :  7  Time:  0.797  Rel. Train L2 Loss :  0.11079078528616164  Rel. Test L2 Loss :  0.13560938596725464  Test L2 Loss :  0.19132513523101807  inv_L_scale:  [1.0, 1.0]
Epoch :  8  Time:  0.798  Rel. Train L2 Loss :  0.10564606342050764  Rel. Test L2 Loss :  0.12899345338344573  Test L2 Loss :  0.18398521184921265  inv_L_scale:  [1.0, 1.0]
Epoch :  9  Time:  0.83  Rel. Train L2 Loss :  0.10076975312497881  Rel. Test L2 Loss :  0.12872177600860596  Test L2 Loss :  0.18261046171188355  inv_L_scale:  [1.0, 1.0]
Epoch :  10  Time:  0.783  Rel. Train L2 Loss :  0.09604412224557665  Rel. Test L2 Loss :  0.12694122552871703  Test L2 Loss :  0.17973316192626954  inv_L_scale:  [1.0, 1.0]
Epoch :  11  Time:  0.802  Rel. Train L2 Loss :  0.09348370638158586  Rel. Test L2 Loss :  0.1231977903842926  Test L2 Loss :  0.17640371918678283  inv_L_scale:  [1.0, 1.0]
Epoch :  12  Time:  0.801  Rel. Train L2 Loss :  0.08770915091037751  Rel. Test L2 Loss :  0.11794251501560211  Test L2 Loss :  0.1679960310459137  inv_L_scale:  [1.0, 1.0]
Epoch :  13  Time:  0.774  Rel. Train L2 Loss :  0.08565473781691657  Rel. Test L2 Loss :  0.11425653278827667  Test L2 Loss :  0.16250945031642913  inv_L_scale:  [1.0, 1.0]
Epoch :  14  Time:  0.774  Rel. Train L2 Loss :  0.0868037309911516  Rel. Test L2 Loss :  0.11664923131465912  Test L2 Loss :  0.16612491488456727  inv_L_scale:  [1.0, 1.0]
Epoch :  15  Time:  0.865  Rel. Train L2 Loss :  0.08367008136378394  Rel. Test L2 Loss :  0.11459236860275268  Test L2 Loss :  0.16314493834972382  inv_L_scale:  [1.0, 1.0]
Epoch :  16  Time:  0.783  Rel. Train L2 Loss :  0.08151028994056914  Rel. Test L2 Loss :  0.11531168282032013  Test L2 Loss :  0.16401620626449584  inv_L_scale:  [1.0, 1.0]
Epoch :  17  Time:  0.783  Rel. Train L2 Loss :  0.07824705723259184  Rel. Test L2 Loss :  0.11147934675216675  Test L2 Loss :  0.15913734316825867  inv_L_scale:  [1.0, 1.0]
Epoch :  18  Time:  0.769  Rel. Train L2 Loss :  0.07709747463464738  Rel. Test L2 Loss :  0.11245148658752441  Test L2 Loss :  0.16050963759422301  inv_L_scale:  [1.0, 1.0]
Epoch :  19  Time:  0.826  Rel. Train L2 Loss :  0.0742828361524476  Rel. Test L2 Loss :  0.10822417914867401  Test L2 Loss :  0.15474781692028045  inv_L_scale:  [1.0, 1.0]
Epoch :  20  Time:  0.791  Rel. Train L2 Loss :  0.0772209040986167  Rel. Test L2 Loss :  0.10829711496829987  Test L2 Loss :  0.15365876793861388  inv_L_scale:  [1.0, 1.0]
Epoch :  21  Time:  0.777  Rel. Train L2 Loss :  0.07415522664785384  Rel. Test L2 Loss :  0.11145023643970489  Test L2 Loss :  0.1574867331981659  inv_L_scale:  [1.0, 1.0]
Epoch :  22  Time:  0.791  Rel. Train L2 Loss :  0.07370368672741784  Rel. Test L2 Loss :  0.10834703952074051  Test L2 Loss :  0.15391198992729188  inv_L_scale:  [1.0, 1.0]
Epoch :  23  Time:  0.81  Rel. Train L2 Loss :  0.07123656786150402  Rel. Test L2 Loss :  0.10602004379034043  Test L2 Loss :  0.15119588136672973  inv_L_scale:  [1.0, 1.0]
Epoch :  24  Time:  0.791  Rel. Train L2 Loss :  0.0718223872449663  Rel. Test L2 Loss :  0.10839219957590103  Test L2 Loss :  0.1538496893644333  inv_L_scale:  [1.0, 1.0]
Epoch :  25  Time:  0.772  Rel. Train L2 Loss :  0.07136146684487661  Rel. Test L2 Loss :  0.10681580662727357  Test L2 Loss :  0.15235527515411376  inv_L_scale:  [1.0, 1.0]
Epoch :  26  Time:  0.806  Rel. Train L2 Loss :  0.0684367768963178  Rel. Test L2 Loss :  0.10475491940975189  Test L2 Loss :  0.14937698245048522  inv_L_scale:  [1.0, 1.0]
Epoch :  27  Time:  0.836  Rel. Train L2 Loss :  0.07115413784980774  Rel. Test L2 Loss :  0.10708310306072236  Test L2 Loss :  0.1534319281578064  inv_L_scale:  [1.0, 1.0]
Epoch :  28  Time:  0.831  Rel. Train L2 Loss :  0.07045370363526875  Rel. Test L2 Loss :  0.10449876844882965  Test L2 Loss :  0.1483351045846939  inv_L_scale:  [1.0, 1.0]
Epoch :  29  Time:  0.776  Rel. Train L2 Loss :  0.06887720164325502  Rel. Test L2 Loss :  0.10272442042827606  Test L2 Loss :  0.14663100779056548  inv_L_scale:  [1.0, 1.0]
Epoch :  30  Time:  0.786  Rel. Train L2 Loss :  0.06511192904578315  Rel. Test L2 Loss :  0.10343227863311767  Test L2 Loss :  0.1468339341878891  inv_L_scale:  [1.0, 1.0]
Epoch :  31  Time:  0.789  Rel. Train L2 Loss :  0.06509836167097091  Rel. Test L2 Loss :  0.1039743885397911  Test L2 Loss :  0.14777750611305238  inv_L_scale:  [1.0, 1.0]
Epoch :  32  Time:  0.769  Rel. Train L2 Loss :  0.06425000285108884  Rel. Test L2 Loss :  0.10197366297245025  Test L2 Loss :  0.1458754914999008  inv_L_scale:  [1.0, 1.0]
Epoch :  33  Time:  0.77  Rel. Train L2 Loss :  0.06439226975043615  Rel. Test L2 Loss :  0.10387411206960678  Test L2 Loss :  0.14759607076644898  inv_L_scale:  [1.0, 1.0]
Epoch :  34  Time:  0.784  Rel. Train L2 Loss :  0.06461994840039147  Rel. Test L2 Loss :  0.10209883570671081  Test L2 Loss :  0.145844606757164  inv_L_scale:  [1.0, 1.0]
Epoch :  35  Time:  0.892  Rel. Train L2 Loss :  0.06368922879298528  Rel. Test L2 Loss :  0.10084998786449433  Test L2 Loss :  0.14421107470989228  inv_L_scale:  [1.0, 1.0]
Epoch :  36  Time:  0.776  Rel. Train L2 Loss :  0.0627391474114524  Rel. Test L2 Loss :  0.10165409356355667  Test L2 Loss :  0.14570602476596833  inv_L_scale:  [1.0, 1.0]
Epoch :  37  Time:  0.79  Rel. Train L2 Loss :  0.06431707655390104  Rel. Test L2 Loss :  0.1035110479593277  Test L2 Loss :  0.14761938989162446  inv_L_scale:  [1.0, 1.0]
Epoch :  38  Time:  0.837  Rel. Train L2 Loss :  0.06344162046909332  Rel. Test L2 Loss :  0.10582550019025802  Test L2 Loss :  0.15117830514907837  inv_L_scale:  [1.0, 1.0]
Epoch :  39  Time:  0.865  Rel. Train L2 Loss :  0.06333326316542096  Rel. Test L2 Loss :  0.10078026354312897  Test L2 Loss :  0.14379177033901214  inv_L_scale:  [1.0, 1.0]
Epoch :  40  Time:  0.82  Rel. Train L2 Loss :  0.062435097363260056  Rel. Test L2 Loss :  0.10006621778011322  Test L2 Loss :  0.1435895848274231  inv_L_scale:  [1.0, 1.0]
Epoch :  41  Time:  0.778  Rel. Train L2 Loss :  0.06303568538692263  Rel. Test L2 Loss :  0.1038312903046608  Test L2 Loss :  0.1495041847229004  inv_L_scale:  [1.0, 1.0]
Epoch :  42  Time:  0.774  Rel. Train L2 Loss :  0.06329842165112495  Rel. Test L2 Loss :  0.10039465576410293  Test L2 Loss :  0.14346927642822266  inv_L_scale:  [1.0, 1.0]
Epoch :  43  Time:  0.772  Rel. Train L2 Loss :  0.06219966193040212  Rel. Test L2 Loss :  0.10376100957393647  Test L2 Loss :  0.14791352033615113  inv_L_scale:  [1.0, 1.0]
Epoch :  44  Time:  0.769  Rel. Train L2 Loss :  0.06216226478417714  Rel. Test L2 Loss :  0.10257701069116593  Test L2 Loss :  0.14630048274993895  inv_L_scale:  [1.0, 1.0]
Epoch :  45  Time:  0.768  Rel. Train L2 Loss :  0.06264542748530706  Rel. Test L2 Loss :  0.10281425505876542  Test L2 Loss :  0.1462513929605484  inv_L_scale:  [1.0, 1.0]
Epoch :  46  Time:  0.798  Rel. Train L2 Loss :  0.06254741369022264  Rel. Test L2 Loss :  0.09949990391731262  Test L2 Loss :  0.14229409635066986  inv_L_scale:  [1.0, 1.0]
Epoch :  47  Time:  0.773  Rel. Train L2 Loss :  0.059801502757602265  Rel. Test L2 Loss :  0.10499752789735795  Test L2 Loss :  0.15089507162570953  inv_L_scale:  [1.0, 1.0]
Epoch :  48  Time:  0.769  Rel. Train L2 Loss :  0.06164822989039951  Rel. Test L2 Loss :  0.09962206959724426  Test L2 Loss :  0.14329223871231078  inv_L_scale:  [1.0, 1.0]
Epoch :  49  Time:  0.786  Rel. Train L2 Loss :  0.06053641951746411  Rel. Test L2 Loss :  0.10016279190778732  Test L2 Loss :  0.14261384427547455  inv_L_scale:  [1.0, 1.0]
Epoch :  50  Time:  0.791  Rel. Train L2 Loss :  0.06252930177582634  Rel. Test L2 Loss :  0.10371815681457519  Test L2 Loss :  0.14756822407245637  inv_L_scale:  [1.0, 1.0]
Epoch :  51  Time:  0.776  Rel. Train L2 Loss :  0.05874550104141235  Rel. Test L2 Loss :  0.09915721744298935  Test L2 Loss :  0.14166998744010925  inv_L_scale:  [1.0, 1.0]
Epoch :  52  Time:  0.779  Rel. Train L2 Loss :  0.058043136480781764  Rel. Test L2 Loss :  0.09975178271532059  Test L2 Loss :  0.1428995269536972  inv_L_scale:  [1.0, 1.0]
Epoch :  53  Time:  0.773  Rel. Train L2 Loss :  0.06006760767764515  Rel. Test L2 Loss :  0.10448104977607726  Test L2 Loss :  0.14926427125930786  inv_L_scale:  [1.0, 1.0]
Epoch :  54  Time:  0.769  Rel. Train L2 Loss :  0.06027423317233722  Rel. Test L2 Loss :  0.0969878649711609  Test L2 Loss :  0.13867423415184021  inv_L_scale:  [1.0, 1.0]
Epoch :  55  Time:  0.777  Rel. Train L2 Loss :  0.057687757975525326  Rel. Test L2 Loss :  0.09656575292348862  Test L2 Loss :  0.13842147529125215  inv_L_scale:  [1.0, 1.0]
Epoch :  56  Time:  0.774  Rel. Train L2 Loss :  0.0585437565545241  Rel. Test L2 Loss :  0.10104736804962158  Test L2 Loss :  0.1453724879026413  inv_L_scale:  [1.0, 1.0]
Epoch :  57  Time:  0.768  Rel. Train L2 Loss :  0.058299907578362356  Rel. Test L2 Loss :  0.10060113668441772  Test L2 Loss :  0.1434805351495743  inv_L_scale:  [1.0, 1.0]
Epoch :  58  Time:  0.876  Rel. Train L2 Loss :  0.05700247062577141  Rel. Test L2 Loss :  0.10218252897262574  Test L2 Loss :  0.14547851622104646  inv_L_scale:  [1.0, 1.0]
Epoch :  59  Time:  0.802  Rel. Train L2 Loss :  0.05872084528207779  Rel. Test L2 Loss :  0.09526630312204361  Test L2 Loss :  0.13750206410884858  inv_L_scale:  [1.0, 1.0]
Epoch :  60  Time:  0.805  Rel. Train L2 Loss :  0.06041032691796621  Rel. Test L2 Loss :  0.09849397778511047  Test L2 Loss :  0.14065200805664063  inv_L_scale:  [1.0, 1.0]
Epoch :  61  Time:  0.804  Rel. Train L2 Loss :  0.05838782396581438  Rel. Test L2 Loss :  0.0976864755153656  Test L2 Loss :  0.1389528226852417  inv_L_scale:  [1.0, 1.0]
Epoch :  62  Time:  0.782  Rel. Train L2 Loss :  0.056970282097657525  Rel. Test L2 Loss :  0.09954986453056336  Test L2 Loss :  0.14214503586292268  inv_L_scale:  [1.0, 1.0]
Epoch :  63  Time:  0.778  Rel. Train L2 Loss :  0.057842887938022614  Rel. Test L2 Loss :  0.10268555492162705  Test L2 Loss :  0.1476334661245346  inv_L_scale:  [1.0, 1.0]
Epoch :  64  Time:  0.783  Rel. Train L2 Loss :  0.0591400146484375  Rel. Test L2 Loss :  0.09829895734786988  Test L2 Loss :  0.14040781199932098  inv_L_scale:  [1.0, 1.0]
Epoch :  65  Time:  0.773  Rel. Train L2 Loss :  0.05883829772472381  Rel. Test L2 Loss :  0.09617006242275238  Test L2 Loss :  0.13758543372154236  inv_L_scale:  [1.0, 1.0]
Epoch :  66  Time:  0.789  Rel. Train L2 Loss :  0.05707134707106484  Rel. Test L2 Loss :  0.0981406381726265  Test L2 Loss :  0.14046307444572448  inv_L_scale:  [1.0, 1.0]
Epoch :  67  Time:  0.783  Rel. Train L2 Loss :  0.05672657536135779  Rel. Test L2 Loss :  0.09617064565420151  Test L2 Loss :  0.13597225725650788  inv_L_scale:  [1.0, 1.0]
Epoch :  68  Time:  0.779  Rel. Train L2 Loss :  0.05759378413359324  Rel. Test L2 Loss :  0.10192621082067489  Test L2 Loss :  0.14657116830348968  inv_L_scale:  [1.0, 1.0]
Epoch :  69  Time:  0.785  Rel. Train L2 Loss :  0.0594748639398151  Rel. Test L2 Loss :  0.10127389281988144  Test L2 Loss :  0.1452672803401947  inv_L_scale:  [1.0, 1.0]
Epoch :  70  Time:  0.79  Rel. Train L2 Loss :  0.056213943974839316  Rel. Test L2 Loss :  0.09682081907987594  Test L2 Loss :  0.1394305294752121  inv_L_scale:  [1.0, 1.0]
Epoch :  71  Time:  0.779  Rel. Train L2 Loss :  0.05601259811056985  Rel. Test L2 Loss :  0.09994551479816437  Test L2 Loss :  0.14287274897098542  inv_L_scale:  [1.0, 1.0]
Epoch :  72  Time:  0.842  Rel. Train L2 Loss :  0.05748466725150744  Rel. Test L2 Loss :  0.09696084409952163  Test L2 Loss :  0.13918609380722047  inv_L_scale:  [1.0, 1.0]
Epoch :  73  Time:  0.803  Rel. Train L2 Loss :  0.05626976879106627  Rel. Test L2 Loss :  0.0947974306344986  Test L2 Loss :  0.13506827294826507  inv_L_scale:  [1.0, 1.0]
Epoch :  74  Time:  0.8  Rel. Train L2 Loss :  0.05543960177236133  Rel. Test L2 Loss :  0.09865164756774902  Test L2 Loss :  0.1401786971092224  inv_L_scale:  [1.0, 1.0]
Epoch :  75  Time:  0.783  Rel. Train L2 Loss :  0.05695743466416995  Rel. Test L2 Loss :  0.09686149597167969  Test L2 Loss :  0.13862196624279022  inv_L_scale:  [1.0, 1.0]
Epoch :  76  Time:  0.779  Rel. Train L2 Loss :  0.057458731267187334  Rel. Test L2 Loss :  0.09852787613868713  Test L2 Loss :  0.14042104363441468  inv_L_scale:  [1.0, 1.0]
Epoch :  77  Time:  0.767  Rel. Train L2 Loss :  0.05805738980571429  Rel. Test L2 Loss :  0.09769168376922607  Test L2 Loss :  0.13950108647346496  inv_L_scale:  [1.0, 1.0]
Epoch :  78  Time:  0.766  Rel. Train L2 Loss :  0.055555757549073964  Rel. Test L2 Loss :  0.09390002936124801  Test L2 Loss :  0.1345793664455414  inv_L_scale:  [1.0, 1.0]
Epoch :  79  Time:  0.769  Rel. Train L2 Loss :  0.05668622960646947  Rel. Test L2 Loss :  0.09755129814147949  Test L2 Loss :  0.13891322433948516  inv_L_scale:  [1.0, 1.0]
Epoch :  80  Time:  0.766  Rel. Train L2 Loss :  0.054909401999579534  Rel. Test L2 Loss :  0.09391137361526489  Test L2 Loss :  0.13544822573661805  inv_L_scale:  [1.0, 1.0]
Epoch :  81  Time:  0.77  Rel. Train L2 Loss :  0.0546715588039822  Rel. Test L2 Loss :  0.09720668584108352  Test L2 Loss :  0.13984801948070527  inv_L_scale:  [1.0, 1.0]
Epoch :  82  Time:  0.767  Rel. Train L2 Loss :  0.05521774507231182  Rel. Test L2 Loss :  0.09775793075561523  Test L2 Loss :  0.13999198853969574  inv_L_scale:  [1.0, 1.0]
Epoch :  83  Time:  0.766  Rel. Train L2 Loss :  0.055041141427225534  Rel. Test L2 Loss :  0.09668359369039535  Test L2 Loss :  0.13840608477592467  inv_L_scale:  [1.0, 1.0]
Epoch :  84  Time:  0.769  Rel. Train L2 Loss :  0.05378211044602924  Rel. Test L2 Loss :  0.09415313929319381  Test L2 Loss :  0.13553805112838746  inv_L_scale:  [1.0, 1.0]
Epoch :  85  Time:  0.768  Rel. Train L2 Loss :  0.05326268540488349  Rel. Test L2 Loss :  0.09440718472003937  Test L2 Loss :  0.13480041027069092  inv_L_scale:  [1.0, 1.0]
Epoch :  86  Time:  0.769  Rel. Train L2 Loss :  0.05516879508892695  Rel. Test L2 Loss :  0.0948025643825531  Test L2 Loss :  0.1360795521736145  inv_L_scale:  [1.0, 1.0]
Epoch :  87  Time:  0.768  Rel. Train L2 Loss :  0.05676311155160268  Rel. Test L2 Loss :  0.09356474965810775  Test L2 Loss :  0.13492751240730286  inv_L_scale:  [1.0, 1.0]
Epoch :  88  Time:  0.766  Rel. Train L2 Loss :  0.05388684721456634  Rel. Test L2 Loss :  0.09313349574804305  Test L2 Loss :  0.13392613470554351  inv_L_scale:  [1.0, 1.0]
Epoch :  89  Time:  0.767  Rel. Train L2 Loss :  0.05542740821838379  Rel. Test L2 Loss :  0.09779994189739227  Test L2 Loss :  0.1390884917974472  inv_L_scale:  [1.0, 1.0]
Epoch :  90  Time:  0.766  Rel. Train L2 Loss :  0.054752498865127563  Rel. Test L2 Loss :  0.09662798970937729  Test L2 Loss :  0.13908543586730956  inv_L_scale:  [1.0, 1.0]
Epoch :  91  Time:  0.766  Rel. Train L2 Loss :  0.05376439210441378  Rel. Test L2 Loss :  0.09478640615940094  Test L2 Loss :  0.13508422374725343  inv_L_scale:  [1.0, 1.0]
Epoch :  92  Time:  0.767  Rel. Train L2 Loss :  0.05434935758511225  Rel. Test L2 Loss :  0.09475808560848237  Test L2 Loss :  0.1350569224357605  inv_L_scale:  [1.0, 1.0]
Epoch :  93  Time:  0.784  Rel. Train L2 Loss :  0.05383128816882769  Rel. Test L2 Loss :  0.09127466082572937  Test L2 Loss :  0.13071541607379913  inv_L_scale:  [1.0, 1.0]
Epoch :  94  Time:  0.885  Rel. Train L2 Loss :  0.053054100258482825  Rel. Test L2 Loss :  0.08972708433866501  Test L2 Loss :  0.12868110090494156  inv_L_scale:  [1.0, 1.0]
Epoch :  95  Time:  0.819  Rel. Train L2 Loss :  0.05324788487619824  Rel. Test L2 Loss :  0.09430300563573837  Test L2 Loss :  0.13522705674171448  inv_L_scale:  [1.0, 1.0]
Epoch :  96  Time:  0.781  Rel. Train L2 Loss :  0.05192394720183478  Rel. Test L2 Loss :  0.09480402708053588  Test L2 Loss :  0.135974001288414  inv_L_scale:  [1.0, 1.0]
Epoch :  97  Time:  0.772  Rel. Train L2 Loss :  0.05463043873508771  Rel. Test L2 Loss :  0.0947620502114296  Test L2 Loss :  0.13500994801521302  inv_L_scale:  [1.0, 1.0]
Epoch :  98  Time:  0.804  Rel. Train L2 Loss :  0.05606998551223013  Rel. Test L2 Loss :  0.09269028902053833  Test L2 Loss :  0.13291878938674928  inv_L_scale:  [1.0, 1.0]
Epoch :  99  Time:  0.844  Rel. Train L2 Loss :  0.053313042951954735  Rel. Test L2 Loss :  0.09287643015384674  Test L2 Loss :  0.13271607607603073  inv_L_scale:  [1.0, 1.0]
Epoch :  100  Time:  0.78  Rel. Train L2 Loss :  0.05159022996822993  Rel. Test L2 Loss :  0.09510657966136932  Test L2 Loss :  0.13551380813121797  inv_L_scale:  [1.0, 1.0]
Epoch :  101  Time:  0.77  Rel. Train L2 Loss :  0.05180053260591295  Rel. Test L2 Loss :  0.09379693001508713  Test L2 Loss :  0.1337583240866661  inv_L_scale:  [1.0, 1.0]