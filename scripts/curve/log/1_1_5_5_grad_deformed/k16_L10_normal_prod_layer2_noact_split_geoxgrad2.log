x1 = speconv(fn, bases_c, bases_s, bases_0, wbases_c, wbases_s, wbases_0)
x2 = w(f)

geo_weight1 = self.softsign(geow1(geo))
x3 = gw(self.softsign(compute_gradient(geo_weight1*fn, directed_edges, edge_gradient_weights)))

x = x1 + x2 + x3

(1000,) (1000, 1000, 1) (1000, 1000, 2)
use normalized raw measures
Casting to tensor
x_train shape torch.Size([900, 1000, 8]), y_train shape torch.Size([900, 1000, 1])
length of each dim:  tensor([6.5573987960815430, 6.1420288085937500])
kmax = 16
L = 10
geo_dims = [1, 2, 5, 6]
In PCNO_train, ndims =  2
Epoch :  0  Time:  1.685  Rel. Train L2 Loss :  0.5140815756056044  Rel. Test L2 Loss :  0.31484886646270754  Test L2 Loss :  0.4505479955673218  inv_L_scale:  [1.0, 1.0]
Epoch :  1  Time:  1.32  Rel. Train L2 Loss :  0.2574389611350165  Rel. Test L2 Loss :  0.21641814947128296  Test L2 Loss :  0.3131206321716309  inv_L_scale:  [1.0, 1.0]
Epoch :  2  Time:  1.312  Rel. Train L2 Loss :  0.20780716896057128  Rel. Test L2 Loss :  0.18420228242874145  Test L2 Loss :  0.2630044734477997  inv_L_scale:  [1.0, 1.0]
Epoch :  3  Time:  1.337  Rel. Train L2 Loss :  0.17735412425465055  Rel. Test L2 Loss :  0.17338616728782655  Test L2 Loss :  0.2516422462463379  inv_L_scale:  [1.0, 1.0]
Epoch :  4  Time:  1.322  Rel. Train L2 Loss :  0.16587198396523795  Rel. Test L2 Loss :  0.15818407356739045  Test L2 Loss :  0.22813309609889984  inv_L_scale:  [1.0, 1.0]
Epoch :  5  Time:  1.324  Rel. Train L2 Loss :  0.15243558208147684  Rel. Test L2 Loss :  0.14882929027080535  Test L2 Loss :  0.21509195506572723  inv_L_scale:  [1.0, 1.0]
Epoch :  6  Time:  1.365  Rel. Train L2 Loss :  0.1439481786886851  Rel. Test L2 Loss :  0.14258487284183502  Test L2 Loss :  0.20432113647460937  inv_L_scale:  [1.0, 1.0]
Epoch :  7  Time:  1.348  Rel. Train L2 Loss :  0.13702504681216346  Rel. Test L2 Loss :  0.13181447446346284  Test L2 Loss :  0.19012912154197692  inv_L_scale:  [1.0, 1.0]
Epoch :  8  Time:  1.313  Rel. Train L2 Loss :  0.132477728260888  Rel. Test L2 Loss :  0.13259114503860472  Test L2 Loss :  0.19045817494392395  inv_L_scale:  [1.0, 1.0]
Epoch :  9  Time:  1.314  Rel. Train L2 Loss :  0.12966408318943448  Rel. Test L2 Loss :  0.12899763584136964  Test L2 Loss :  0.18594360172748567  inv_L_scale:  [1.0, 1.0]
Epoch :  10  Time:  1.333  Rel. Train L2 Loss :  0.1251399768061108  Rel. Test L2 Loss :  0.12037755131721496  Test L2 Loss :  0.17359303832054138  inv_L_scale:  [1.0, 1.0]
Epoch :  11  Time:  1.335  Rel. Train L2 Loss :  0.12017749051253  Rel. Test L2 Loss :  0.12185687959194183  Test L2 Loss :  0.17515764951705934  inv_L_scale:  [1.0, 1.0]
Epoch :  12  Time:  1.314  Rel. Train L2 Loss :  0.11951886475086212  Rel. Test L2 Loss :  0.12134317517280578  Test L2 Loss :  0.17427109003067018  inv_L_scale:  [1.0, 1.0]
Epoch :  13  Time:  1.322  Rel. Train L2 Loss :  0.11776711020204755  Rel. Test L2 Loss :  0.12064160645008087  Test L2 Loss :  0.1735483592748642  inv_L_scale:  [1.0, 1.0]
Epoch :  14  Time:  1.312  Rel. Train L2 Loss :  0.11468886997964647  Rel. Test L2 Loss :  0.11330350130796432  Test L2 Loss :  0.16284377694129945  inv_L_scale:  [1.0, 1.0]
Epoch :  15  Time:  1.31  Rel. Train L2 Loss :  0.11277721881866455  Rel. Test L2 Loss :  0.11585034936666488  Test L2 Loss :  0.16651127576828004  inv_L_scale:  [1.0, 1.0]
Epoch :  16  Time:  1.31  Rel. Train L2 Loss :  0.11320668253633712  Rel. Test L2 Loss :  0.1081220555305481  Test L2 Loss :  0.15626278698444365  inv_L_scale:  [1.0, 1.0]
Epoch :  17  Time:  1.306  Rel. Train L2 Loss :  0.1103287097480562  Rel. Test L2 Loss :  0.10956616014242172  Test L2 Loss :  0.1576880371570587  inv_L_scale:  [1.0, 1.0]
Epoch :  18  Time:  1.372  Rel. Train L2 Loss :  0.110471454527643  Rel. Test L2 Loss :  0.11429962038993835  Test L2 Loss :  0.16393531799316408  inv_L_scale:  [1.0, 1.0]
Epoch :  19  Time:  1.34  Rel. Train L2 Loss :  0.1064135421315829  Rel. Test L2 Loss :  0.10493536412715912  Test L2 Loss :  0.15115781366825104  inv_L_scale:  [1.0, 1.0]
Epoch :  20  Time:  1.311  Rel. Train L2 Loss :  0.10548219939072927  Rel. Test L2 Loss :  0.10525827676057815  Test L2 Loss :  0.15176313519477844  inv_L_scale:  [1.0, 1.0]
Epoch :  21  Time:  1.311  Rel. Train L2 Loss :  0.10451473368538751  Rel. Test L2 Loss :  0.10605201989412308  Test L2 Loss :  0.15287722945213317  inv_L_scale:  [1.0, 1.0]
Epoch :  22  Time:  1.312  Rel. Train L2 Loss :  0.10342060572571225  Rel. Test L2 Loss :  0.10022898912429809  Test L2 Loss :  0.14372588694095612  inv_L_scale:  [1.0, 1.0]
Epoch :  23  Time:  1.311  Rel. Train L2 Loss :  0.10149043311675389  Rel. Test L2 Loss :  0.10646819025278091  Test L2 Loss :  0.15345601737499237  inv_L_scale:  [1.0, 1.0]
Epoch :  24  Time:  1.307  Rel. Train L2 Loss :  0.1027470123105579  Rel. Test L2 Loss :  0.10699671298265458  Test L2 Loss :  0.15414371192455292  inv_L_scale:  [1.0, 1.0]
Epoch :  25  Time:  1.308  Rel. Train L2 Loss :  0.10155797726578182  Rel. Test L2 Loss :  0.09666606217622757  Test L2 Loss :  0.1388712304830551  inv_L_scale:  [1.0, 1.0]
Epoch :  26  Time:  1.31  Rel. Train L2 Loss :  0.09917518960105048  Rel. Test L2 Loss :  0.0991261300444603  Test L2 Loss :  0.14251135647296906  inv_L_scale:  [1.0, 1.0]
Epoch :  27  Time:  1.308  Rel. Train L2 Loss :  0.0992601121796502  Rel. Test L2 Loss :  0.09741694033145905  Test L2 Loss :  0.14080415666103363  inv_L_scale:  [1.0, 1.0]
Epoch :  28  Time:  1.31  Rel. Train L2 Loss :  0.09895030435588625  Rel. Test L2 Loss :  0.10161619156599044  Test L2 Loss :  0.14667111307382583  inv_L_scale:  [1.0, 1.0]
Epoch :  29  Time:  1.335  Rel. Train L2 Loss :  0.09814556118514803  Rel. Test L2 Loss :  0.1015775066614151  Test L2 Loss :  0.14562216758728028  inv_L_scale:  [1.0, 1.0]
Epoch :  30  Time:  1.307  Rel. Train L2 Loss :  0.09880740738577314  Rel. Test L2 Loss :  0.0992784109711647  Test L2 Loss :  0.14260001838207245  inv_L_scale:  [1.0, 1.0]
Epoch :  31  Time:  1.308  Rel. Train L2 Loss :  0.09592349410057067  Rel. Test L2 Loss :  0.09738690257072449  Test L2 Loss :  0.13975590616464614  inv_L_scale:  [1.0, 1.0]
Epoch :  32  Time:  1.308  Rel. Train L2 Loss :  0.09652632531192568  Rel. Test L2 Loss :  0.09627672076225281  Test L2 Loss :  0.13824135303497315  inv_L_scale:  [1.0, 1.0]




