FFT_2D:

  data:
    L: 1.0
    downsample_ratio: 14
    n_train: 800
    n_test: 200

  model:
    layer_types: ['HGalerkinConv_pca','HGalerkinConv_pca','HGalerkinConv_pca','HGalerkinConv_pca']  # HGalerkinConv_fourier ， HGalerkinConv_pca ， FourierConv2d ，Attention
    double_bases: False
    FNO_modes: [16,16,16,16]   # modes for FourierConv2d
    GkNN_modes: [96,96,96,96]  # modes for GkNN
    kernel_modes: [64,64,64,64]
    num_heads: [1,1,1,1]
    attention_types: ["galerkin","galerkin","galerkin","galerkin"]
    fc_dim: 128
    in_dim: 3  #default
    out_dim: 1  #default
    pca_include_input: False
    pca_include_grid: False
    layers_dim: [128,128,128,128,128]     # len(layers_dim) == len(..modes)+1 
    act: 'gelu'
    get_H : 'learn_real'     #'compute' or 'learn_complex' or 'learn_real' or 'trained' 
    dropout: [False,False,False,False]
    H_init: 'random'  # 'Galerkin' or 'random'




  train:
    device: 'cuda'   #cpu or cuda
    base_lr: 0.001
    weight_decay: 0.0001
    epochs: 500
    scheduler: 'OneCycleLR'
    milestones: [200,300,400,500,800,900]
    scheduler_gamma: 0.5
    batch_size: 8
    normalization_x: True
    normalization_y: True
    normalization_dim: []
    L1regularization_lambda: 0.0001
    hard_pruning: 0.0001
    grad_clip: 1
    L2regularization_alpha: 0.0005
    L2regularization_beta: 0.001
    

