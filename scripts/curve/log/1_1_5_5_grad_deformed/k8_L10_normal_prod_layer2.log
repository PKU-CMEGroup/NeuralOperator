(1000,) (1000, 1000, 1) (1000, 1000, 2)
use normalized raw measures
Computing normal vector
Casting to tensor
x_train shape torch.Size([900, 1000, 8]), y_train shape torch.Size([900, 1000, 1])
length of each dim:  tensor([6.5573987960815430, 6.1420288085937500])
kmax = 8
L = 10
use cube modes, scale = 0 (144, 2, 1)
In PCNO_train, ndims =  2
Epoch :  0  Time:  14.257  Rel. Train L2 Loss :  0.5122639332877265  Rel. Test L2 Loss :  0.37266069650650024  Test L2 Loss :  0.5373352491855621  inv_L_scale:  [1.0, 1.0]
Epoch :  1  Time:  0.668  Rel. Train L2 Loss :  0.3086387228965759  Rel. Test L2 Loss :  0.2643111979961395  Test L2 Loss :  0.37828477382659914  inv_L_scale:  [1.0, 1.0]
Epoch :  2  Time:  0.671  Rel. Train L2 Loss :  0.21594690567917293  Rel. Test L2 Loss :  0.20543429434299468  Test L2 Loss :  0.29406028509140014  inv_L_scale:  [1.0, 1.0]
Epoch :  3  Time:  0.667  Rel. Train L2 Loss :  0.1745872668425242  Rel. Test L2 Loss :  0.1834633594751358  Test L2 Loss :  0.25979702234268187  inv_L_scale:  [1.0, 1.0]
Epoch :  4  Time:  0.666  Rel. Train L2 Loss :  0.1529240745306015  Rel. Test L2 Loss :  0.16829654514789583  Test L2 Loss :  0.2397962498664856  inv_L_scale:  [1.0, 1.0]
Epoch :  5  Time:  0.667  Rel. Train L2 Loss :  0.1364451175265842  Rel. Test L2 Loss :  0.1569777512550354  Test L2 Loss :  0.22377570748329162  inv_L_scale:  [1.0, 1.0]
Epoch :  6  Time:  0.668  Rel. Train L2 Loss :  0.12878762033250596  Rel. Test L2 Loss :  0.14932066559791565  Test L2 Loss :  0.21290797829627991  inv_L_scale:  [1.0, 1.0]
Epoch :  7  Time:  0.666  Rel. Train L2 Loss :  0.12110716700553895  Rel. Test L2 Loss :  0.1504859721660614  Test L2 Loss :  0.213444082736969  inv_L_scale:  [1.0, 1.0]
Epoch :  8  Time:  0.666  Rel. Train L2 Loss :  0.11251177443398369  Rel. Test L2 Loss :  0.1480143642425537  Test L2 Loss :  0.2092401033639908  inv_L_scale:  [1.0, 1.0]
Epoch :  9  Time:  0.666  Rel. Train L2 Loss :  0.11030564076370664  Rel. Test L2 Loss :  0.13092264413833618  Test L2 Loss :  0.18612374722957611  inv_L_scale:  [1.0, 1.0]
Epoch :  10  Time:  0.668  Rel. Train L2 Loss :  0.10209465930859248  Rel. Test L2 Loss :  0.1337306660413742  Test L2 Loss :  0.19188012421131134  inv_L_scale:  [1.0, 1.0]
Epoch :  11  Time:  0.666  Rel. Train L2 Loss :  0.09969084865517086  Rel. Test L2 Loss :  0.13047043681144715  Test L2 Loss :  0.18651483416557313  inv_L_scale:  [1.0, 1.0]
Epoch :  12  Time:  0.666  Rel. Train L2 Loss :  0.09634372419781155  Rel. Test L2 Loss :  0.13283370256423951  Test L2 Loss :  0.1902024781703949  inv_L_scale:  [1.0, 1.0]
Epoch :  13  Time:  0.666  Rel. Train L2 Loss :  0.09289991567532221  Rel. Test L2 Loss :  0.12258083581924438  Test L2 Loss :  0.17404931426048278  inv_L_scale:  [1.0, 1.0]
Epoch :  14  Time:  0.669  Rel. Train L2 Loss :  0.08863328158855438  Rel. Test L2 Loss :  0.12574806094169616  Test L2 Loss :  0.1792047452926636  inv_L_scale:  [1.0, 1.0]
Epoch :  15  Time:  0.667  Rel. Train L2 Loss :  0.08644787106249067  Rel. Test L2 Loss :  0.11892124056816102  Test L2 Loss :  0.1689842814207077  inv_L_scale:  [1.0, 1.0]
Epoch :  16  Time:  0.666  Rel. Train L2 Loss :  0.08621135135491689  Rel. Test L2 Loss :  0.1194695383310318  Test L2 Loss :  0.17073187470436096  inv_L_scale:  [1.0, 1.0]
Epoch :  17  Time:  0.667  Rel. Train L2 Loss :  0.08644807779126697  Rel. Test L2 Loss :  0.12428922295570373  Test L2 Loss :  0.17652176260948182  inv_L_scale:  [1.0, 1.0]
Epoch :  18  Time:  0.668  Rel. Train L2 Loss :  0.08271476844946543  Rel. Test L2 Loss :  0.1181795984506607  Test L2 Loss :  0.17050532698631288  inv_L_scale:  [1.0, 1.0]
Epoch :  19  Time:  0.667  Rel. Train L2 Loss :  0.08279932455884086  Rel. Test L2 Loss :  0.1266237312555313  Test L2 Loss :  0.1790565937757492  inv_L_scale:  [1.0, 1.0]
Epoch :  20  Time:  0.667  Rel. Train L2 Loss :  0.08062527841991848  Rel. Test L2 Loss :  0.11823969900608063  Test L2 Loss :  0.16927743554115296  inv_L_scale:  [1.0, 1.0]
Epoch :  21  Time:  0.666  Rel. Train L2 Loss :  0.07934889872868855  Rel. Test L2 Loss :  0.1232218611240387  Test L2 Loss :  0.17560475170612336  inv_L_scale:  [1.0, 1.0]
Epoch :  22  Time:  0.667  Rel. Train L2 Loss :  0.07488640149434407  Rel. Test L2 Loss :  0.11389196038246155  Test L2 Loss :  0.16310396313667297  inv_L_scale:  [1.0, 1.0]
Epoch :  23  Time:  0.668  Rel. Train L2 Loss :  0.0750221441189448  Rel. Test L2 Loss :  0.11386043429374695  Test L2 Loss :  0.16261789679527283  inv_L_scale:  [1.0, 1.0]
Epoch :  24  Time:  0.668  Rel. Train L2 Loss :  0.07487586226728227  Rel. Test L2 Loss :  0.11689739823341369  Test L2 Loss :  0.16643477499485015  inv_L_scale:  [1.0, 1.0]
Epoch :  25  Time:  0.666  Rel. Train L2 Loss :  0.07336460133393606  Rel. Test L2 Loss :  0.11313812732696533  Test L2 Loss :  0.1616437828540802  inv_L_scale:  [1.0, 1.0]
Epoch :  26  Time:  0.666  Rel. Train L2 Loss :  0.07181385782029893  Rel. Test L2 Loss :  0.11560412526130676  Test L2 Loss :  0.16484241366386412  inv_L_scale:  [1.0, 1.0]
Epoch :  27  Time:  0.666  Rel. Train L2 Loss :  0.07138475285636055  Rel. Test L2 Loss :  0.11032223641872406  Test L2 Loss :  0.15767398834228516  inv_L_scale:  [1.0, 1.0]
Epoch :  28  Time:  0.666  Rel. Train L2 Loss :  0.07174312445852492  Rel. Test L2 Loss :  0.11333003163337707  Test L2 Loss :  0.1608480167388916  inv_L_scale:  [1.0, 1.0]
Epoch :  29  Time:  0.667  Rel. Train L2 Loss :  0.0711780396103859  Rel. Test L2 Loss :  0.11463311314582825  Test L2 Loss :  0.16351254284381866  inv_L_scale:  [1.0, 1.0]
Epoch :  30  Time:  0.666  Rel. Train L2 Loss :  0.06966253237591849  Rel. Test L2 Loss :  0.11585736334323883  Test L2 Loss :  0.16446640253067016  inv_L_scale:  [1.0, 1.0]
Epoch :  31  Time:  0.666  Rel. Train L2 Loss :  0.07338934974537956  Rel. Test L2 Loss :  0.11176875293254852  Test L2 Loss :  0.1596789127588272  inv_L_scale:  [1.0, 1.0]
Epoch :  32  Time:  0.666  Rel. Train L2 Loss :  0.06922020812829335  Rel. Test L2 Loss :  0.11325774252414704  Test L2 Loss :  0.16118162631988525  inv_L_scale:  [1.0, 1.0]
Epoch :  33  Time:  0.666  Rel. Train L2 Loss :  0.06637858831220203  Rel. Test L2 Loss :  0.11305773317813873  Test L2 Loss :  0.16102663934230804  inv_L_scale:  [1.0, 1.0]
Epoch :  34  Time:  0.667  Rel. Train L2 Loss :  0.06638151473469205  Rel. Test L2 Loss :  0.1140670657157898  Test L2 Loss :  0.16191171884536742  inv_L_scale:  [1.0, 1.0]
Epoch :  35  Time:  0.666  Rel. Train L2 Loss :  0.06923013279835383  Rel. Test L2 Loss :  0.11389112770557404  Test L2 Loss :  0.16146390080451967  inv_L_scale:  [1.0, 1.0]
Epoch :  36  Time:  0.666  Rel. Train L2 Loss :  0.0681132721569803  Rel. Test L2 Loss :  0.11020459175109863  Test L2 Loss :  0.1569826817512512  inv_L_scale:  [1.0, 1.0]
Epoch :  37  Time:  0.666  Rel. Train L2 Loss :  0.06420437686973147  Rel. Test L2 Loss :  0.10791528761386872  Test L2 Loss :  0.15429676532745362  inv_L_scale:  [1.0, 1.0]
Epoch :  38  Time:  0.666  Rel. Train L2 Loss :  0.06356290509303411  Rel. Test L2 Loss :  0.11024774074554443  Test L2 Loss :  0.15717114567756651  inv_L_scale:  [1.0, 1.0]
Epoch :  39  Time:  0.668  Rel. Train L2 Loss :  0.06344569798972871  Rel. Test L2 Loss :  0.10754229307174683  Test L2 Loss :  0.15341147899627686  inv_L_scale:  [1.0, 1.0]
Epoch :  40  Time:  0.667  Rel. Train L2 Loss :  0.06389267676406436  Rel. Test L2 Loss :  0.11496689796447754  Test L2 Loss :  0.16218383312225343  inv_L_scale:  [1.0, 1.0]
Epoch :  41  Time:  0.666  Rel. Train L2 Loss :  0.06570761538214154  Rel. Test L2 Loss :  0.10882890939712525  Test L2 Loss :  0.15506348133087158  inv_L_scale:  [1.0, 1.0]
Epoch :  42  Time:  0.666  Rel. Train L2 Loss :  0.06297310511271159  Rel. Test L2 Loss :  0.1122256177663803  Test L2 Loss :  0.16023893415927887  inv_L_scale:  [1.0, 1.0]
Epoch :  43  Time:  0.666  Rel. Train L2 Loss :  0.0658988552292188  Rel. Test L2 Loss :  0.10818329751491547  Test L2 Loss :  0.15441870093345642  inv_L_scale:  [1.0, 1.0]
Epoch :  44  Time:  0.667  Rel. Train L2 Loss :  0.06483327358961105  Rel. Test L2 Loss :  0.1114952164888382  Test L2 Loss :  0.15958451747894287  inv_L_scale:  [1.0, 1.0]
Epoch :  45  Time:  0.666  Rel. Train L2 Loss :  0.06490941613912582  Rel. Test L2 Loss :  0.1037958186864853  Test L2 Loss :  0.14773656368255617  inv_L_scale:  [1.0, 1.0]
Epoch :  46  Time:  0.67  Rel. Train L2 Loss :  0.06346810211737951  Rel. Test L2 Loss :  0.10829536139965057  Test L2 Loss :  0.15399460077285768  inv_L_scale:  [1.0, 1.0]
Epoch :  47  Time:  0.667  Rel. Train L2 Loss :  0.06377570503287845  Rel. Test L2 Loss :  0.10987326443195343  Test L2 Loss :  0.15680231809616088  inv_L_scale:  [1.0, 1.0]
Epoch :  48  Time:  0.667  Rel. Train L2 Loss :  0.06140757636891471  Rel. Test L2 Loss :  0.10661469876766205  Test L2 Loss :  0.15194600224494934  inv_L_scale:  [1.0, 1.0]
Epoch :  49  Time:  0.666  Rel. Train L2 Loss :  0.061100556734535426  Rel. Test L2 Loss :  0.10937553256750107  Test L2 Loss :  0.15626472353935242  inv_L_scale:  [1.0, 1.0]
Epoch :  50  Time:  0.665  Rel. Train L2 Loss :  0.06294337484571669  Rel. Test L2 Loss :  0.10886244535446167  Test L2 Loss :  0.15617223024368287  inv_L_scale:  [1.0, 1.0]
Epoch :  51  Time:  0.664  Rel. Train L2 Loss :  0.0615005044804679  Rel. Test L2 Loss :  0.10801738739013672  Test L2 Loss :  0.15407081663608552  inv_L_scale:  [1.0, 1.0]
Epoch :  52  Time:  0.665  Rel. Train L2 Loss :  0.06313068124983046  Rel. Test L2 Loss :  0.11031091630458832  Test L2 Loss :  0.15806565821170807  inv_L_scale:  [1.0, 1.0]
Epoch :  53  Time:  0.665  Rel. Train L2 Loss :  0.06494412052962516  Rel. Test L2 Loss :  0.11044627487659454  Test L2 Loss :  0.15664196908473968  inv_L_scale:  [1.0, 1.0]
Epoch :  54  Time:  0.665  Rel. Train L2 Loss :  0.06153265641795264  Rel. Test L2 Loss :  0.11052431046962738  Test L2 Loss :  0.15678561151027678  inv_L_scale:  [1.0, 1.0]
Epoch :  55  Time:  0.665  Rel. Train L2 Loss :  0.06232368495729235  Rel. Test L2 Loss :  0.10527299046516418  Test L2 Loss :  0.14959368526935576  inv_L_scale:  [1.0, 1.0]
Epoch :  56  Time:  0.665  Rel. Train L2 Loss :  0.06234601769182417  Rel. Test L2 Loss :  0.10697041690349579  Test L2 Loss :  0.1525791448354721  inv_L_scale:  [1.0, 1.0]
Epoch :  57  Time:  0.665  Rel. Train L2 Loss :  0.0629485653506385  Rel. Test L2 Loss :  0.10936694145202637  Test L2 Loss :  0.15580870628356933  inv_L_scale:  [1.0, 1.0]
Epoch :  58  Time:  0.666  Rel. Train L2 Loss :  0.059312754124403  Rel. Test L2 Loss :  0.10507714807987213  Test L2 Loss :  0.14920087277889252  inv_L_scale:  [1.0, 1.0]
Epoch :  59  Time:  0.666  Rel. Train L2 Loss :  0.0606977610455619  Rel. Test L2 Loss :  0.10902443706989288  Test L2 Loss :  0.1555407440662384  inv_L_scale:  [1.0, 1.0]
Epoch :  60  Time:  0.665  Rel. Train L2 Loss :  0.05936304605669446  Rel. Test L2 Loss :  0.1110565984249115  Test L2 Loss :  0.15849677801132203  inv_L_scale:  [1.0, 1.0]
Epoch :  61  Time:  0.666  Rel. Train L2 Loss :  0.06302845001220703  Rel. Test L2 Loss :  0.10611209154129028  Test L2 Loss :  0.15058037757873535  inv_L_scale:  [1.0, 1.0]
Epoch :  62  Time:  0.665  Rel. Train L2 Loss :  0.059127245081795586  Rel. Test L2 Loss :  0.10675783693790436  Test L2 Loss :  0.15282233774662018  inv_L_scale:  [1.0, 1.0]
Epoch :  63  Time:  0.666  Rel. Train L2 Loss :  0.06167721680468983  Rel. Test L2 Loss :  0.11249467194080352  Test L2 Loss :  0.16007568955421447  inv_L_scale:  [1.0, 1.0]
Epoch :  64  Time:  0.665  Rel. Train L2 Loss :  0.06200295226441489  Rel. Test L2 Loss :  0.10928067088127136  Test L2 Loss :  0.15668131709098815  inv_L_scale:  [1.0, 1.0]
Epoch :  65  Time:  0.667  Rel. Train L2 Loss :  0.06071185410022736  Rel. Test L2 Loss :  0.10601097404956818  Test L2 Loss :  0.15078323423862458  inv_L_scale:  [1.0, 1.0]
Epoch :  66  Time:  0.666  Rel. Train L2 Loss :  0.0603095022506184  Rel. Test L2 Loss :  0.10615757882595062  Test L2 Loss :  0.1522159308195114  inv_L_scale:  [1.0, 1.0]
Epoch :  67  Time:  0.666  Rel. Train L2 Loss :  0.0600139061609904  Rel. Test L2 Loss :  0.10820199310779571  Test L2 Loss :  0.1539126616716385  inv_L_scale:  [1.0, 1.0]
Epoch :  68  Time:  0.665  Rel. Train L2 Loss :  0.05770266395476129  Rel. Test L2 Loss :  0.10683144986629486  Test L2 Loss :  0.15238540530204772  inv_L_scale:  [1.0, 1.0]
Epoch :  69  Time:  0.666  Rel. Train L2 Loss :  0.05655771023697323  Rel. Test L2 Loss :  0.10583144187927246  Test L2 Loss :  0.15165245175361633  inv_L_scale:  [1.0, 1.0]
Epoch :  70  Time:  0.666  Rel. Train L2 Loss :  0.05930855777528551  Rel. Test L2 Loss :  0.10486796140670776  Test L2 Loss :  0.14929655194282532  inv_L_scale:  [1.0, 1.0]
Epoch :  71  Time:  0.667  Rel. Train L2 Loss :  0.05833571543296178  Rel. Test L2 Loss :  0.10430223405361176  Test L2 Loss :  0.14916681945323945  inv_L_scale:  [1.0, 1.0]
Epoch :  72  Time:  0.666  Rel. Train L2 Loss :  0.05733368247747421  Rel. Test L2 Loss :  0.10465713500976563  Test L2 Loss :  0.1496596199274063  inv_L_scale:  [1.0, 1.0]
Epoch :  73  Time:  0.666  Rel. Train L2 Loss :  0.05988298396269481  Rel. Test L2 Loss :  0.1055686628818512  Test L2 Loss :  0.1507776212692261  inv_L_scale:  [1.0, 1.0]
Epoch :  74  Time:  0.665  Rel. Train L2 Loss :  0.05861203309562471  Rel. Test L2 Loss :  0.10568822562694549  Test L2 Loss :  0.1506929039955139  inv_L_scale:  [1.0, 1.0]
Epoch :  75  Time:  0.666  Rel. Train L2 Loss :  0.057854500280486214  Rel. Test L2 Loss :  0.10546434968709946  Test L2 Loss :  0.15176496386528016  inv_L_scale:  [1.0, 1.0]
Epoch :  76  Time:  0.665  Rel. Train L2 Loss :  0.058612261116504666  Rel. Test L2 Loss :  0.105352823138237  Test L2 Loss :  0.15047566831111908  inv_L_scale:  [1.0, 1.0]
Epoch :  77  Time:  0.665  Rel. Train L2 Loss :  0.057212831146187255  Rel. Test L2 Loss :  0.10580013960599899  Test L2 Loss :  0.15193476319313048  inv_L_scale:  [1.0, 1.0]
Epoch :  78  Time:  0.666  Rel. Train L2 Loss :  0.05845478544632594  Rel. Test L2 Loss :  0.10455373764038085  Test L2 Loss :  0.14937151372432708  inv_L_scale:  [1.0, 1.0]
Epoch :  79  Time:  0.668  Rel. Train L2 Loss :  0.05892635815673404  Rel. Test L2 Loss :  0.10882940173149108  Test L2 Loss :  0.15513671994209288  inv_L_scale:  [1.0, 1.0]
Epoch :  80  Time:  0.667  Rel. Train L2 Loss :  0.05824489126602809  Rel. Test L2 Loss :  0.1031314080953598  Test L2 Loss :  0.14691909313201904  inv_L_scale:  [1.0, 1.0]
Epoch :  81  Time:  0.666  Rel. Train L2 Loss :  0.0587769633366002  Rel. Test L2 Loss :  0.10570481240749359  Test L2 Loss :  0.15001715064048768  inv_L_scale:  [1.0, 1.0]
Epoch :  82  Time:  0.666  Rel. Train L2 Loss :  0.0578472804526488  Rel. Test L2 Loss :  0.10127288490533828  Test L2 Loss :  0.1451123720407486  inv_L_scale:  [1.0, 1.0]
Epoch :  83  Time:  0.666  Rel. Train L2 Loss :  0.055262708564599354  Rel. Test L2 Loss :  0.1111902904510498  Test L2 Loss :  0.16167484045028688  inv_L_scale:  [1.0, 1.0]
Epoch :  84  Time:  0.665  Rel. Train L2 Loss :  0.05744230518738429  Rel. Test L2 Loss :  0.10753383338451386  Test L2 Loss :  0.15345435738563537  inv_L_scale:  [1.0, 1.0]
Epoch :  85  Time:  0.665  Rel. Train L2 Loss :  0.05641599378652043  Rel. Test L2 Loss :  0.10499450862407685  Test L2 Loss :  0.14931428372859956  inv_L_scale:  [1.0, 1.0]
Epoch :  86  Time:  0.666  Rel. Train L2 Loss :  0.056725561105542714  Rel. Test L2 Loss :  0.1068361085653305  Test L2 Loss :  0.15383971571922303  inv_L_scale:  [1.0, 1.0]
Epoch :  87  Time:  0.666  Rel. Train L2 Loss :  0.057043439745903014  Rel. Test L2 Loss :  0.10578948557376862  Test L2 Loss :  0.1517234879732132  inv_L_scale:  [1.0, 1.0]
Epoch :  88  Time:  0.666  Rel. Train L2 Loss :  0.059239130351278514  Rel. Test L2 Loss :  0.1020549887418747  Test L2 Loss :  0.1464512801170349  inv_L_scale:  [1.0, 1.0]
Epoch :  89  Time:  0.666  Rel. Train L2 Loss :  0.0596577536728647  Rel. Test L2 Loss :  0.11110437333583832  Test L2 Loss :  0.15968689143657686  inv_L_scale:  [1.0, 1.0]
Epoch :  90  Time:  0.666  Rel. Train L2 Loss :  0.05667834637893571  Rel. Test L2 Loss :  0.10386160403490066  Test L2 Loss :  0.14823752641677856  inv_L_scale:  [1.0, 1.0]
Epoch :  91  Time:  0.666  Rel. Train L2 Loss :  0.055897198932038414  Rel. Test L2 Loss :  0.1026054298877716  Test L2 Loss :  0.14622459292411805  inv_L_scale:  [1.0, 1.0]
Epoch :  92  Time:  0.665  Rel. Train L2 Loss :  0.055143948545058566  Rel. Test L2 Loss :  0.10358250677585602  Test L2 Loss :  0.14754008889198303  inv_L_scale:  [1.0, 1.0]
Epoch :  93  Time:  0.665  Rel. Train L2 Loss :  0.05557031565242344  Rel. Test L2 Loss :  0.10391319990158081  Test L2 Loss :  0.14827944159507753  inv_L_scale:  [1.0, 1.0]
Epoch :  94  Time:  0.667  Rel. Train L2 Loss :  0.05743592331806819  Rel. Test L2 Loss :  0.10310391962528229  Test L2 Loss :  0.1480775624513626  inv_L_scale:  [1.0, 1.0]
Epoch :  95  Time:  0.666  Rel. Train L2 Loss :  0.05657664590411716  Rel. Test L2 Loss :  0.10122903913259507  Test L2 Loss :  0.1450222659111023  inv_L_scale:  [1.0, 1.0]
Epoch :  96  Time:  0.665  Rel. Train L2 Loss :  0.05527293711900711  Rel. Test L2 Loss :  0.10197317481040954  Test L2 Loss :  0.14632228016853333  inv_L_scale:  [1.0, 1.0]
Epoch :  97  Time:  0.666  Rel. Train L2 Loss :  0.05562743041250441  Rel. Test L2 Loss :  0.10137798249721527  Test L2 Loss :  0.14451249837875366  inv_L_scale:  [1.0, 1.0]
Epoch :  98  Time:  0.666  Rel. Train L2 Loss :  0.05497591757112079  Rel. Test L2 Loss :  0.10102075427770614  Test L2 Loss :  0.144840025305748  inv_L_scale:  [1.0, 1.0]
Epoch :  99  Time:  0.665  Rel. Train L2 Loss :  0.05413160466485553  Rel. Test L2 Loss :  0.10274478524923325  Test L2 Loss :  0.14672522246837616  inv_L_scale:  [1.0, 1.0]
Epoch :  100  Time:  0.668  Rel. Train L2 Loss :  0.056370868020587495  Rel. Test L2 Loss :  0.100498628616333  Test L2 Loss :  0.14432759284973146  inv_L_scale:  [1.0, 1.0]
Epoch :  101  Time:  0.666  Rel. Train L2 Loss :  0.05364296964473195  Rel. Test L2 Loss :  0.10408367455005646  Test L2 Loss :  0.14871292769908906  inv_L_scale:  [1.0, 1.0]
Epoch :  102  Time:  0.668  Rel. Train L2 Loss :  0.0542664247751236  Rel. Test L2 Loss :  0.10055007725954056  Test L2 Loss :  0.14400015115737916  inv_L_scale:  [1.0, 1.0]
Epoch :  103  Time:  0.666  Rel. Train L2 Loss :  0.055162446896235146  Rel. Test L2 Loss :  0.1022010686993599  Test L2 Loss :  0.14620303750038147  inv_L_scale:  [1.0, 1.0]
Epoch :  104  Time:  0.666  Rel. Train L2 Loss :  0.05422852214839723  Rel. Test L2 Loss :  0.10319251120090485  Test L2 Loss :  0.14610734701156616  inv_L_scale:  [1.0, 1.0]
Epoch :  105  Time:  0.666  Rel. Train L2 Loss :  0.05327486349476708  Rel. Test L2 Loss :  0.10076598882675171  Test L2 Loss :  0.1436408966779709  inv_L_scale:  [1.0, 1.0]
Epoch :  106  Time:  0.666  Rel. Train L2 Loss :  0.05234604628549682  Rel. Test L2 Loss :  0.09959985136985779  Test L2 Loss :  0.14210901498794556  inv_L_scale:  [1.0, 1.0]
Epoch :  107  Time:  0.666  Rel. Train L2 Loss :  0.05169933762815263  Rel. Test L2 Loss :  0.1012417858839035  Test L2 Loss :  0.14503171145915986  inv_L_scale:  [1.0, 1.0]
Epoch :  108  Time:  0.666  Rel. Train L2 Loss :  0.052267183330323964  Rel. Test L2 Loss :  0.1016701352596283  Test L2 Loss :  0.14616066753864287  inv_L_scale:  [1.0, 1.0]
Epoch :  109  Time:  0.667  Rel. Train L2 Loss :  0.05394035028086768  Rel. Test L2 Loss :  0.09952377021312714  Test L2 Loss :  0.14201762080192565  inv_L_scale:  [1.0, 1.0]
Epoch :  110  Time:  0.666  Rel. Train L2 Loss :  0.05184546944167879  Rel. Test L2 Loss :  0.1027575534582138  Test L2 Loss :  0.14665595710277557  inv_L_scale:  [1.0, 1.0]
Epoch :  111  Time:  0.666  Rel. Train L2 Loss :  0.05218441767825021  Rel. Test L2 Loss :  0.09760794818401336  Test L2 Loss :  0.13942635476589202  inv_L_scale:  [1.0, 1.0]
Epoch :  112  Time:  0.666  Rel. Train L2 Loss :  0.05104943878120846  Rel. Test L2 Loss :  0.09924836099147796  Test L2 Loss :  0.14203992307186128  inv_L_scale:  [1.0, 1.0]
Epoch :  113  Time:  0.666  Rel. Train L2 Loss :  0.05236092295911577  Rel. Test L2 Loss :  0.10359945982694625  Test L2 Loss :  0.1488684755563736  inv_L_scale:  [1.0, 1.0]
Epoch :  114  Time:  0.666  Rel. Train L2 Loss :  0.05461142669121424  Rel. Test L2 Loss :  0.0984779217839241  Test L2 Loss :  0.14142899572849274  inv_L_scale:  [1.0, 1.0]
Epoch :  115  Time:  0.666  Rel. Train L2 Loss :  0.051342355575826434  Rel. Test L2 Loss :  0.09905236005783082  Test L2 Loss :  0.14115210354328156  inv_L_scale:  [1.0, 1.0]
Epoch :  116  Time:  0.666  Rel. Train L2 Loss :  0.052303240067429015  Rel. Test L2 Loss :  0.0984668990969658  Test L2 Loss :  0.1407739692926407  inv_L_scale:  [1.0, 1.0]
Epoch :  117  Time:  0.667  Rel. Train L2 Loss :  0.05138600534862942  Rel. Test L2 Loss :  0.09697330266237258  Test L2 Loss :  0.1375759392976761  inv_L_scale:  [1.0, 1.0]
Epoch :  118  Time:  0.666  Rel. Train L2 Loss :  0.052315059006214144  Rel. Test L2 Loss :  0.09548863619565964  Test L2 Loss :  0.13613487720489503  inv_L_scale:  [1.0, 1.0]
Epoch :  119  Time:  0.668  Rel. Train L2 Loss :  0.050652558472421436  Rel. Test L2 Loss :  0.09951200425624847  Test L2 Loss :  0.1417369830608368  inv_L_scale:  [1.0, 1.0]
Epoch :  120  Time:  0.665  Rel. Train L2 Loss :  0.05086118507716391  Rel. Test L2 Loss :  0.09779836297035217  Test L2 Loss :  0.1397065180540085  inv_L_scale:  [1.0, 1.0]
Epoch :  121  Time:  0.665  Rel. Train L2 Loss :  0.051687376101811726  Rel. Test L2 Loss :  0.10488791465759277  Test L2 Loss :  0.15035364985466004  inv_L_scale:  [1.0, 1.0]
Epoch :  122  Time:  0.664  Rel. Train L2 Loss :  0.050175072219636706  Rel. Test L2 Loss :  0.10266988188028335  Test L2 Loss :  0.1478278124332428  inv_L_scale:  [1.0, 1.0]
Epoch :  123  Time:  0.664  Rel. Train L2 Loss :  0.05100753363635805  Rel. Test L2 Loss :  0.09932416409254075  Test L2 Loss :  0.14197876691818237  inv_L_scale:  [1.0, 1.0]
Epoch :  124  Time:  0.664  Rel. Train L2 Loss :  0.05107174654801687  Rel. Test L2 Loss :  0.09877047061920166  Test L2 Loss :  0.14203714907169343  inv_L_scale:  [1.0, 1.0]
Epoch :  125  Time:  0.664  Rel. Train L2 Loss :  0.050089595086044734  Rel. Test L2 Loss :  0.09530485838651657  Test L2 Loss :  0.13621444404125213  inv_L_scale:  [1.0, 1.0]
Epoch :  126  Time:  0.664  Rel. Train L2 Loss :  0.04945525626341502  Rel. Test L2 Loss :  0.09775549113750458  Test L2 Loss :  0.13930390715599061  inv_L_scale:  [1.0, 1.0]
Epoch :  127  Time:  0.664  Rel. Train L2 Loss :  0.051142684866984686  Rel. Test L2 Loss :  0.09618589520454407  Test L2 Loss :  0.13769245028495788  inv_L_scale:  [1.0, 1.0]
Epoch :  128  Time:  0.665  Rel. Train L2 Loss :  0.05015776268310017  Rel. Test L2 Loss :  0.09851506680250167  Test L2 Loss :  0.14116024672985078  inv_L_scale:  [1.0, 1.0]
Epoch :  129  Time:  0.664  Rel. Train L2 Loss :  0.0488595293296708  Rel. Test L2 Loss :  0.0954957601428032  Test L2 Loss :  0.1365830796957016  inv_L_scale:  [1.0, 1.0]
Epoch :  130  Time:  0.664  Rel. Train L2 Loss :  0.04941870450973511  Rel. Test L2 Loss :  0.09591850012540817  Test L2 Loss :  0.1370842844247818  inv_L_scale:  [1.0, 1.0]
Epoch :  131  Time:  0.664  Rel. Train L2 Loss :  0.050840146508481766  Rel. Test L2 Loss :  0.0976921272277832  Test L2 Loss :  0.14024887681007386  inv_L_scale:  [1.0, 1.0]
Epoch :  132  Time:  0.664  Rel. Train L2 Loss :  0.050454189909829035  Rel. Test L2 Loss :  0.09559070885181427  Test L2 Loss :  0.1372662627696991  inv_L_scale:  [1.0, 1.0]
Epoch :  133  Time:  0.664  Rel. Train L2 Loss :  0.0488312718934483  Rel. Test L2 Loss :  0.09546660453081131  Test L2 Loss :  0.1368435662984848  inv_L_scale:  [1.0, 1.0]
Epoch :  134  Time:  0.664  Rel. Train L2 Loss :  0.04862120078669654  Rel. Test L2 Loss :  0.0972801399230957  Test L2 Loss :  0.13917925894260408  inv_L_scale:  [1.0, 1.0]
Epoch :  135  Time:  0.665  Rel. Train L2 Loss :  0.05113987919357088  Rel. Test L2 Loss :  0.09494834959506988  Test L2 Loss :  0.13569725930690765  inv_L_scale:  [1.0, 1.0]
Epoch :  136  Time:  0.664  Rel. Train L2 Loss :  0.04840725392103195  Rel. Test L2 Loss :  0.0980649983882904  Test L2 Loss :  0.1401144504547119  inv_L_scale:  [1.0, 1.0]
Epoch :  137  Time:  0.666  Rel. Train L2 Loss :  0.04903591367933485  Rel. Test L2 Loss :  0.09508928775787354  Test L2 Loss :  0.13631984770298003  inv_L_scale:  [1.0, 1.0]
Epoch :  138  Time:  0.665  Rel. Train L2 Loss :  0.047771186232566834  Rel. Test L2 Loss :  0.09755139470100403  Test L2 Loss :  0.1408399200439453  inv_L_scale:  [1.0, 1.0]
Epoch :  139  Time:  0.665  Rel. Train L2 Loss :  0.04944090073307355  Rel. Test L2 Loss :  0.09751764088869094  Test L2 Loss :  0.13891587078571319  inv_L_scale:  [1.0, 1.0]
Epoch :  140  Time:  0.665  Rel. Train L2 Loss :  0.04821111275090112  Rel. Test L2 Loss :  0.09446125209331513  Test L2 Loss :  0.13448764741420746  inv_L_scale:  [1.0, 1.0]
Epoch :  141  Time:  0.665  Rel. Train L2 Loss :  0.04663676483763589  Rel. Test L2 Loss :  0.09236993163824081  Test L2 Loss :  0.1313907539844513  inv_L_scale:  [1.0, 1.0]
Epoch :  142  Time:  0.665  Rel. Train L2 Loss :  0.04631933275196287  Rel. Test L2 Loss :  0.09586004078388215  Test L2 Loss :  0.137436483502388  inv_L_scale:  [1.0, 1.0]
Epoch :  143  Time:  0.665  Rel. Train L2 Loss :  0.04776505794790056  Rel. Test L2 Loss :  0.09581153064966202  Test L2 Loss :  0.13691449761390687  inv_L_scale:  [1.0, 1.0]
Epoch :  144  Time:  0.665  Rel. Train L2 Loss :  0.0482699430319998  Rel. Test L2 Loss :  0.0932532024383545  Test L2 Loss :  0.1334476900100708  inv_L_scale:  [1.0, 1.0]
Epoch :  145  Time:  0.665  Rel. Train L2 Loss :  0.04711780170599619  Rel. Test L2 Loss :  0.09497873067855835  Test L2 Loss :  0.1367996448278427  inv_L_scale:  [1.0, 1.0]
Epoch :  146  Time:  0.667  Rel. Train L2 Loss :  0.047072615308894054  Rel. Test L2 Loss :  0.0985754069685936  Test L2 Loss :  0.141693811416626  inv_L_scale:  [1.0, 1.0]
Epoch :  147  Time:  0.665  Rel. Train L2 Loss :  0.04918235065208541  Rel. Test L2 Loss :  0.09854975700378418  Test L2 Loss :  0.14044203102588654  inv_L_scale:  [1.0, 1.0]
Epoch :  148  Time:  0.664  Rel. Train L2 Loss :  0.047368395494090186  Rel. Test L2 Loss :  0.09512863218784333  Test L2 Loss :  0.13610455572605132  inv_L_scale:  [1.0, 1.0]
Epoch :  149  Time:  0.664  Rel. Train L2 Loss :  0.04490654225150744  Rel. Test L2 Loss :  0.09408280581235885  Test L2 Loss :  0.13464620172977448  inv_L_scale:  [1.0, 1.0]
Epoch :  150  Time:  0.664  Rel. Train L2 Loss :  0.0474358905851841  Rel. Test L2 Loss :  0.09423614621162414  Test L2 Loss :  0.13405118763446808  inv_L_scale:  [1.0, 1.0]
Epoch :  151  Time:  0.664  Rel. Train L2 Loss :  0.045685660855637654  Rel. Test L2 Loss :  0.09243135452270508  Test L2 Loss :  0.1326490408182144  inv_L_scale:  [1.0, 1.0]
Epoch :  152  Time:  0.664  Rel. Train L2 Loss :  0.04566782085431947  Rel. Test L2 Loss :  0.09184774547815323  Test L2 Loss :  0.13124115347862245  inv_L_scale:  [1.0, 1.0]
Epoch :  153  Time:  0.664  Rel. Train L2 Loss :  0.04500194698572159  Rel. Test L2 Loss :  0.09678784668445588  Test L2 Loss :  0.1374602061510086  inv_L_scale:  [1.0, 1.0]
Epoch :  154  Time:  0.664  Rel. Train L2 Loss :  0.04584111630916596  Rel. Test L2 Loss :  0.09261028200387955  Test L2 Loss :  0.13238462626934053  inv_L_scale:  [1.0, 1.0]
Epoch :  155  Time:  0.665  Rel. Train L2 Loss :  0.045785008668899535  Rel. Test L2 Loss :  0.09444459676742553  Test L2 Loss :  0.13523009598255156  inv_L_scale:  [1.0, 1.0]
Epoch :  156  Time:  0.665  Rel. Train L2 Loss :  0.045798937612109715  Rel. Test L2 Loss :  0.09350143671035767  Test L2 Loss :  0.13409206449985503  inv_L_scale:  [1.0, 1.0]
Epoch :  157  Time:  0.664  Rel. Train L2 Loss :  0.04524470584260093  Rel. Test L2 Loss :  0.09096740603446961  Test L2 Loss :  0.13047850251197815  inv_L_scale:  [1.0, 1.0]
Epoch :  158  Time:  0.665  Rel. Train L2 Loss :  0.045775063302781846  Rel. Test L2 Loss :  0.09200065314769745  Test L2 Loss :  0.13227282345294952  inv_L_scale:  [1.0, 1.0]
Epoch :  159  Time:  0.665  Rel. Train L2 Loss :  0.04525097045633528  Rel. Test L2 Loss :  0.09304048508405685  Test L2 Loss :  0.1338582181930542  inv_L_scale:  [1.0, 1.0]
Epoch :  160  Time:  0.664  Rel. Train L2 Loss :  0.045758307526508966  Rel. Test L2 Loss :  0.09553838610649108  Test L2 Loss :  0.1366396290063858  inv_L_scale:  [1.0, 1.0]
Epoch :  161  Time:  0.667  Rel. Train L2 Loss :  0.04760422751307487  Rel. Test L2 Loss :  0.09286788880825042  Test L2 Loss :  0.1328887039422989  inv_L_scale:  [1.0, 1.0]
Epoch :  162  Time:  0.667  Rel. Train L2 Loss :  0.04438751028643714  Rel. Test L2 Loss :  0.09351535677909852  Test L2 Loss :  0.13389605462551116  inv_L_scale:  [1.0, 1.0]
Epoch :  163  Time:  0.666  Rel. Train L2 Loss :  0.044421543214056225  Rel. Test L2 Loss :  0.0944125109910965  Test L2 Loss :  0.13474654376506806  inv_L_scale:  [1.0, 1.0]
Epoch :  164  Time:  0.666  Rel. Train L2 Loss :  0.04399604575501548  Rel. Test L2 Loss :  0.09304511189460754  Test L2 Loss :  0.13245410680770875  inv_L_scale:  [1.0, 1.0]
Epoch :  165  Time:  0.666  Rel. Train L2 Loss :  0.04397340696718958  Rel. Test L2 Loss :  0.09270266801118851  Test L2 Loss :  0.1332613307237625  inv_L_scale:  [1.0, 1.0]
Epoch :  166  Time:  0.667  Rel. Train L2 Loss :  0.04349487218591902  Rel. Test L2 Loss :  0.09115135490894317  Test L2 Loss :  0.1307675963640213  inv_L_scale:  [1.0, 1.0]
Epoch :  167  Time:  0.667  Rel. Train L2 Loss :  0.044023428675201204  Rel. Test L2 Loss :  0.0945825269818306  Test L2 Loss :  0.1352192533016205  inv_L_scale:  [1.0, 1.0]
Epoch :  168  Time:  0.666  Rel. Train L2 Loss :  0.04385935687356525  Rel. Test L2 Loss :  0.09222171068191529  Test L2 Loss :  0.13147231698036194  inv_L_scale:  [1.0, 1.0]
Epoch :  169  Time:  0.666  Rel. Train L2 Loss :  0.042657584663894445  Rel. Test L2 Loss :  0.0926466578245163  Test L2 Loss :  0.13242903411388396  inv_L_scale:  [1.0, 1.0]
Epoch :  170  Time:  0.666  Rel. Train L2 Loss :  0.04461214274168015  Rel. Test L2 Loss :  0.08998115301132202  Test L2 Loss :  0.1286593696475029  inv_L_scale:  [1.0, 1.0]
Epoch :  171  Time:  0.666  Rel. Train L2 Loss :  0.04213319352931447  Rel. Test L2 Loss :  0.0925269776582718  Test L2 Loss :  0.1321931278705597  inv_L_scale:  [1.0, 1.0]
Epoch :  172  Time:  0.666  Rel. Train L2 Loss :  0.043129472360014916  Rel. Test L2 Loss :  0.09037101298570632  Test L2 Loss :  0.1296236237883568  inv_L_scale:  [1.0, 1.0]
Epoch :  173  Time:  0.666  Rel. Train L2 Loss :  0.043503398365444604  Rel. Test L2 Loss :  0.09303426861763  Test L2 Loss :  0.13305119931697845  inv_L_scale:  [1.0, 1.0]
Epoch :  174  Time:  0.665  Rel. Train L2 Loss :  0.043735427425967324  Rel. Test L2 Loss :  0.09119411826133728  Test L2 Loss :  0.13011141300201415  inv_L_scale:  [1.0, 1.0]
Epoch :  175  Time:  0.666  Rel. Train L2 Loss :  0.04201339215040207  Rel. Test L2 Loss :  0.09082877397537231  Test L2 Loss :  0.13017829596996308  inv_L_scale:  [1.0, 1.0]
Epoch :  176  Time:  0.666  Rel. Train L2 Loss :  0.042331873410277894  Rel. Test L2 Loss :  0.09133114099502564  Test L2 Loss :  0.13059526741504668  inv_L_scale:  [1.0, 1.0]
Epoch :  177  Time:  0.667  Rel. Train L2 Loss :  0.04141794603731897  Rel. Test L2 Loss :  0.09206954151391983  Test L2 Loss :  0.13170982599258424  inv_L_scale:  [1.0, 1.0]
Epoch :  178  Time:  0.666  Rel. Train L2 Loss :  0.042797761327690545  Rel. Test L2 Loss :  0.08871156811714172  Test L2 Loss :  0.1273808640241623  inv_L_scale:  [1.0, 1.0]
Epoch :  179  Time:  0.667  Rel. Train L2 Loss :  0.04221457143624623  Rel. Test L2 Loss :  0.09341580659151077  Test L2 Loss :  0.13334059119224548  inv_L_scale:  [1.0, 1.0]
Epoch :  180  Time:  0.666  Rel. Train L2 Loss :  0.04352352266510328  Rel. Test L2 Loss :  0.08965747058391571  Test L2 Loss :  0.12891196578741074  inv_L_scale:  [1.0, 1.0]
Epoch :  181  Time:  0.667  Rel. Train L2 Loss :  0.04329075359635883  Rel. Test L2 Loss :  0.09273993551731109  Test L2 Loss :  0.13282292425632478  inv_L_scale:  [1.0, 1.0]
Epoch :  182  Time:  0.666  Rel. Train L2 Loss :  0.04200429188708464  Rel. Test L2 Loss :  0.09230198472738266  Test L2 Loss :  0.13246314346790314  inv_L_scale:  [1.0, 1.0]
Epoch :  183  Time:  0.666  Rel. Train L2 Loss :  0.04079076621267531  Rel. Test L2 Loss :  0.09037121176719666  Test L2 Loss :  0.12942793428897859  inv_L_scale:  [1.0, 1.0]
Epoch :  184  Time:  0.667  Rel. Train L2 Loss :  0.041321078406439886  Rel. Test L2 Loss :  0.09048065304756164  Test L2 Loss :  0.12928149223327637  inv_L_scale:  [1.0, 1.0]
Epoch :  185  Time:  0.669  Rel. Train L2 Loss :  0.040713798221614625  Rel. Test L2 Loss :  0.09083663940429687  Test L2 Loss :  0.13002481997013093  inv_L_scale:  [1.0, 1.0]
Epoch :  186  Time:  0.666  Rel. Train L2 Loss :  0.04066891132129563  Rel. Test L2 Loss :  0.09185600340366364  Test L2 Loss :  0.13100286066532135  inv_L_scale:  [1.0, 1.0]
Epoch :  187  Time:  0.666  Rel. Train L2 Loss :  0.04159456862343682  Rel. Test L2 Loss :  0.08964899301528931  Test L2 Loss :  0.127934290766716  inv_L_scale:  [1.0, 1.0]
Epoch :  188  Time:  0.666  Rel. Train L2 Loss :  0.04101763543155458  Rel. Test L2 Loss :  0.08849208772182465  Test L2 Loss :  0.12685117721557618  inv_L_scale:  [1.0, 1.0]
Epoch :  189  Time:  0.667  Rel. Train L2 Loss :  0.04131573801239331  Rel. Test L2 Loss :  0.09225694060325623  Test L2 Loss :  0.1313098692893982  inv_L_scale:  [1.0, 1.0]
Epoch :  190  Time:  0.666  Rel. Train L2 Loss :  0.04085704012049569  Rel. Test L2 Loss :  0.09088769197463989  Test L2 Loss :  0.13009189069271088  inv_L_scale:  [1.0, 1.0]
Epoch :  191  Time:  0.667  Rel. Train L2 Loss :  0.03918053362104628  Rel. Test L2 Loss :  0.08957943379878998  Test L2 Loss :  0.12853598177433015  inv_L_scale:  [1.0, 1.0]
Epoch :  192  Time:  0.666  Rel. Train L2 Loss :  0.04024627268314362  Rel. Test L2 Loss :  0.08805272817611694  Test L2 Loss :  0.12641938388347626  inv_L_scale:  [1.0, 1.0]
Epoch :  193  Time:  0.667  Rel. Train L2 Loss :  0.03962664329343372  Rel. Test L2 Loss :  0.08996292650699615  Test L2 Loss :  0.12875297248363496  inv_L_scale:  [1.0, 1.0]
Epoch :  194  Time:  0.667  Rel. Train L2 Loss :  0.04106491337219874  Rel. Test L2 Loss :  0.08867377519607544  Test L2 Loss :  0.12692172586917877  inv_L_scale:  [1.0, 1.0]
Epoch :  195  Time:  0.666  Rel. Train L2 Loss :  0.03984411016106606  Rel. Test L2 Loss :  0.08882669687271118  Test L2 Loss :  0.12670397281646728  inv_L_scale:  [1.0, 1.0]
Epoch :  196  Time:  0.667  Rel. Train L2 Loss :  0.03897302806377411  Rel. Test L2 Loss :  0.08751511514186859  Test L2 Loss :  0.1260658472776413  inv_L_scale:  [1.0, 1.0]
Epoch :  197  Time:  0.666  Rel. Train L2 Loss :  0.03879716960920228  Rel. Test L2 Loss :  0.09017991095781326  Test L2 Loss :  0.12893241584300996  inv_L_scale:  [1.0, 1.0]
Epoch :  198  Time:  0.667  Rel. Train L2 Loss :  0.03958632253938251  Rel. Test L2 Loss :  0.08879408001899719  Test L2 Loss :  0.12685031831264496  inv_L_scale:  [1.0, 1.0]
Epoch :  199  Time:  0.667  Rel. Train L2 Loss :  0.038548255720072325  Rel. Test L2 Loss :  0.08818243503570557  Test L2 Loss :  0.12582698315382004  inv_L_scale:  [1.0, 1.0]
Epoch :  200  Time:  0.668  Rel. Train L2 Loss :  0.03984420685304536  Rel. Test L2 Loss :  0.08958291202783585  Test L2 Loss :  0.12824322938919067  inv_L_scale:  [1.0, 1.0]
Epoch :  201  Time:  0.668  Rel. Train L2 Loss :  0.04046046227216721  Rel. Test L2 Loss :  0.08737447738647461  Test L2 Loss :  0.12495607256889343  inv_L_scale:  [1.0, 1.0]
Epoch :  202  Time:  0.668  Rel. Train L2 Loss :  0.038840798752175436  Rel. Test L2 Loss :  0.08897850006818771  Test L2 Loss :  0.12724715530872344  inv_L_scale:  [1.0, 1.0]
Epoch :  203  Time:  0.667  Rel. Train L2 Loss :  0.03804601920975579  Rel. Test L2 Loss :  0.08970159441232681  Test L2 Loss :  0.12893904566764833  inv_L_scale:  [1.0, 1.0]
Epoch :  204  Time:  0.666  Rel. Train L2 Loss :  0.03933158824841181  Rel. Test L2 Loss :  0.08904080033302307  Test L2 Loss :  0.12759337902069093  inv_L_scale:  [1.0, 1.0]
Epoch :  205  Time:  0.667  Rel. Train L2 Loss :  0.03760801711016231  Rel. Test L2 Loss :  0.08764429599046707  Test L2 Loss :  0.12580846905708312  inv_L_scale:  [1.0, 1.0]
Epoch :  206  Time:  0.667  Rel. Train L2 Loss :  0.03848380042446984  Rel. Test L2 Loss :  0.08925040483474732  Test L2 Loss :  0.1276664388179779  inv_L_scale:  [1.0, 1.0]
Epoch :  207  Time:  0.668  Rel. Train L2 Loss :  0.03846240490674972  Rel. Test L2 Loss :  0.08669448643922806  Test L2 Loss :  0.12432526856660843  inv_L_scale:  [1.0, 1.0]
Epoch :  208  Time:  0.666  Rel. Train L2 Loss :  0.038006321407026714  Rel. Test L2 Loss :  0.08709513902664184  Test L2 Loss :  0.12464294999837876  inv_L_scale:  [1.0, 1.0]
Epoch :  209  Time:  0.666  Rel. Train L2 Loss :  0.038006063832177056  Rel. Test L2 Loss :  0.089593226313591  Test L2 Loss :  0.12830638110637665  inv_L_scale:  [1.0, 1.0]
Epoch :  210  Time:  0.666  Rel. Train L2 Loss :  0.03941531951228778  Rel. Test L2 Loss :  0.08681528508663178  Test L2 Loss :  0.12352766245603561  inv_L_scale:  [1.0, 1.0]
Epoch :  211  Time:  0.667  Rel. Train L2 Loss :  0.03834993329313066  Rel. Test L2 Loss :  0.08688508868217468  Test L2 Loss :  0.12408975422382355  inv_L_scale:  [1.0, 1.0]
Epoch :  212  Time:  0.666  Rel. Train L2 Loss :  0.03832805507712894  Rel. Test L2 Loss :  0.0877380394935608  Test L2 Loss :  0.12597494810819626  inv_L_scale:  [1.0, 1.0]
Epoch :  213  Time:  0.667  Rel. Train L2 Loss :  0.037199636962678695  Rel. Test L2 Loss :  0.08949147403240204  Test L2 Loss :  0.12788874864578248  inv_L_scale:  [1.0, 1.0]
Epoch :  214  Time:  0.667  Rel. Train L2 Loss :  0.03617449323336283  Rel. Test L2 Loss :  0.08623115181922912  Test L2 Loss :  0.1238649183511734  inv_L_scale:  [1.0, 1.0]
Epoch :  215  Time:  0.667  Rel. Train L2 Loss :  0.037063441707028286  Rel. Test L2 Loss :  0.0871558141708374  Test L2 Loss :  0.12429938673973083  inv_L_scale:  [1.0, 1.0]
Epoch :  216  Time:  0.666  Rel. Train L2 Loss :  0.03780762066443761  Rel. Test L2 Loss :  0.08708326160907745  Test L2 Loss :  0.12505930811166763  inv_L_scale:  [1.0, 1.0]
Epoch :  217  Time:  0.666  Rel. Train L2 Loss :  0.036789433625009325  Rel. Test L2 Loss :  0.0900141116976738  Test L2 Loss :  0.12878409206867217  inv_L_scale:  [1.0, 1.0]
Epoch :  218  Time:  0.667  Rel. Train L2 Loss :  0.03770230359501309  Rel. Test L2 Loss :  0.08782400190830231  Test L2 Loss :  0.12565158069133758  inv_L_scale:  [1.0, 1.0]
Epoch :  219  Time:  0.667  Rel. Train L2 Loss :  0.03608586124247975  Rel. Test L2 Loss :  0.0872113686800003  Test L2 Loss :  0.12470231920480729  inv_L_scale:  [1.0, 1.0]
Epoch :  220  Time:  0.666  Rel. Train L2 Loss :  0.03539344982968436  Rel. Test L2 Loss :  0.08692418336868286  Test L2 Loss :  0.12414848029613496  inv_L_scale:  [1.0, 1.0]
Epoch :  221  Time:  0.666  Rel. Train L2 Loss :  0.035767213106155396  Rel. Test L2 Loss :  0.08856022775173188  Test L2 Loss :  0.1264281278848648  inv_L_scale:  [1.0, 1.0]
Epoch :  222  Time:  0.667  Rel. Train L2 Loss :  0.0361463093592061  Rel. Test L2 Loss :  0.08764738559722901  Test L2 Loss :  0.12593773066997527  inv_L_scale:  [1.0, 1.0]
Epoch :  223  Time:  0.667  Rel. Train L2 Loss :  0.0347801160481241  Rel. Test L2 Loss :  0.0855207884311676  Test L2 Loss :  0.12233571141958237  inv_L_scale:  [1.0, 1.0]
Epoch :  224  Time:  0.667  Rel. Train L2 Loss :  0.035817989392413034  Rel. Test L2 Loss :  0.08675409466028214  Test L2 Loss :  0.12392154455184937  inv_L_scale:  [1.0, 1.0]
Epoch :  225  Time:  0.666  Rel. Train L2 Loss :  0.03496076539986663  Rel. Test L2 Loss :  0.08581150680780411  Test L2 Loss :  0.12297248989343643  inv_L_scale:  [1.0, 1.0]
Epoch :  226  Time:  0.666  Rel. Train L2 Loss :  0.03561029780242178  Rel. Test L2 Loss :  0.08815809190273285  Test L2 Loss :  0.1260538589954376  inv_L_scale:  [1.0, 1.0]
Epoch :  227  Time:  0.668  Rel. Train L2 Loss :  0.0358216453757551  Rel. Test L2 Loss :  0.08553359031677246  Test L2 Loss :  0.12271284550428391  inv_L_scale:  [1.0, 1.0]
Epoch :  228  Time:  0.667  Rel. Train L2 Loss :  0.03737152841356065  Rel. Test L2 Loss :  0.08711849570274353  Test L2 Loss :  0.1246490854024887  inv_L_scale:  [1.0, 1.0]
Epoch :  229  Time:  0.667  Rel. Train L2 Loss :  0.03596820346183247  Rel. Test L2 Loss :  0.0856400579214096  Test L2 Loss :  0.12258819848299027  inv_L_scale:  [1.0, 1.0]
Epoch :  230  Time:  0.666  Rel. Train L2 Loss :  0.034838577293687396  Rel. Test L2 Loss :  0.08519621461629867  Test L2 Loss :  0.12148568361997604  inv_L_scale:  [1.0, 1.0]
Epoch :  231  Time:  0.667  Rel. Train L2 Loss :  0.03411000303096241  Rel. Test L2 Loss :  0.08710954517126084  Test L2 Loss :  0.12514369189739227  inv_L_scale:  [1.0, 1.0]
Epoch :  232  Time:  0.667  Rel. Train L2 Loss :  0.034637327823374  Rel. Test L2 Loss :  0.08497470736503601  Test L2 Loss :  0.1218023145198822  inv_L_scale:  [1.0, 1.0]
Epoch :  233  Time:  0.667  Rel. Train L2 Loss :  0.0342974741756916  Rel. Test L2 Loss :  0.08579046308994293  Test L2 Loss :  0.12305630087852477  inv_L_scale:  [1.0, 1.0]
Epoch :  234  Time:  0.666  Rel. Train L2 Loss :  0.034386941376659604  Rel. Test L2 Loss :  0.08628192394971848  Test L2 Loss :  0.12370710372924805  inv_L_scale:  [1.0, 1.0]
Epoch :  235  Time:  0.667  Rel. Train L2 Loss :  0.033751315143373276  Rel. Test L2 Loss :  0.08514291167259216  Test L2 Loss :  0.12264548629522323  inv_L_scale:  [1.0, 1.0]
Epoch :  236  Time:  0.667  Rel. Train L2 Loss :  0.033709820326831605  Rel. Test L2 Loss :  0.08420552104711533  Test L2 Loss :  0.12085228711366654  inv_L_scale:  [1.0, 1.0]
Epoch :  237  Time:  0.667  Rel. Train L2 Loss :  0.0332716028061178  Rel. Test L2 Loss :  0.08503137826919556  Test L2 Loss :  0.12233154326677323  inv_L_scale:  [1.0, 1.0]
Epoch :  238  Time:  0.667  Rel. Train L2 Loss :  0.03241303655008475  Rel. Test L2 Loss :  0.0853065311908722  Test L2 Loss :  0.12271094560623169  inv_L_scale:  [1.0, 1.0]
Epoch :  239  Time:  0.667  Rel. Train L2 Loss :  0.033129760159386526  Rel. Test L2 Loss :  0.08529529631137849  Test L2 Loss :  0.12195934534072876  inv_L_scale:  [1.0, 1.0]
Epoch :  240  Time:  0.666  Rel. Train L2 Loss :  0.033381922956970005  Rel. Test L2 Loss :  0.08541292697191238  Test L2 Loss :  0.12218735218048096  inv_L_scale:  [1.0, 1.0]
Epoch :  241  Time:  0.668  Rel. Train L2 Loss :  0.03333103251126077  Rel. Test L2 Loss :  0.08533547520637512  Test L2 Loss :  0.12181338667869568  inv_L_scale:  [1.0, 1.0]
Epoch :  242  Time:  0.667  Rel. Train L2 Loss :  0.03262253007955021  Rel. Test L2 Loss :  0.08530023992061615  Test L2 Loss :  0.12217741906642914  inv_L_scale:  [1.0, 1.0]
Epoch :  243  Time:  0.667  Rel. Train L2 Loss :  0.03343005670441521  Rel. Test L2 Loss :  0.08495042949914933  Test L2 Loss :  0.12195092022418975  inv_L_scale:  [1.0, 1.0]
Epoch :  244  Time:  0.667  Rel. Train L2 Loss :  0.03314273224936591  Rel. Test L2 Loss :  0.08667878806591034  Test L2 Loss :  0.1237103796005249  inv_L_scale:  [1.0, 1.0]
Epoch :  245  Time:  0.667  Rel. Train L2 Loss :  0.03325910478830338  Rel. Test L2 Loss :  0.08509043037891388  Test L2 Loss :  0.12227231413125991  inv_L_scale:  [1.0, 1.0]
Epoch :  246  Time:  0.667  Rel. Train L2 Loss :  0.03207330939670404  Rel. Test L2 Loss :  0.08492152810096741  Test L2 Loss :  0.12145119607448578  inv_L_scale:  [1.0, 1.0]
Epoch :  247  Time:  0.667  Rel. Train L2 Loss :  0.032759931435187656  Rel. Test L2 Loss :  0.0859160476922989  Test L2 Loss :  0.12283914744853973  inv_L_scale:  [1.0, 1.0]
Epoch :  248  Time:  0.667  Rel. Train L2 Loss :  0.032384605722294915  Rel. Test L2 Loss :  0.08582950681447983  Test L2 Loss :  0.12277415335178375  inv_L_scale:  [1.0, 1.0]
Epoch :  249  Time:  0.667  Rel. Train L2 Loss :  0.032066515593065156  Rel. Test L2 Loss :  0.08499720633029938  Test L2 Loss :  0.12176537215709686  inv_L_scale:  [1.0, 1.0]
Epoch :  250  Time:  0.667  Rel. Train L2 Loss :  0.03174759571750959  Rel. Test L2 Loss :  0.08549895972013473  Test L2 Loss :  0.12236996471881867  inv_L_scale:  [1.0, 1.0]
Epoch :  251  Time:  0.667  Rel. Train L2 Loss :  0.031555371201700634  Rel. Test L2 Loss :  0.0852134370803833  Test L2 Loss :  0.12219249844551086  inv_L_scale:  [1.0, 1.0]
Epoch :  252  Time:  0.667  Rel. Train L2 Loss :  0.03180622204310364  Rel. Test L2 Loss :  0.08419670879840851  Test L2 Loss :  0.12084980726242066  inv_L_scale:  [1.0, 1.0]
Epoch :  253  Time:  0.667  Rel. Train L2 Loss :  0.031633439362049105  Rel. Test L2 Loss :  0.08525830626487732  Test L2 Loss :  0.12186106503009796  inv_L_scale:  [1.0, 1.0]
Epoch :  254  Time:  0.667  Rel. Train L2 Loss :  0.0320792833632893  Rel. Test L2 Loss :  0.08502088516950607  Test L2 Loss :  0.12197470307350158  inv_L_scale:  [1.0, 1.0]
Epoch :  255  Time:  0.667  Rel. Train L2 Loss :  0.030356565763552983  Rel. Test L2 Loss :  0.08569695144891738  Test L2 Loss :  0.12280270159244537  inv_L_scale:  [1.0, 1.0]
Epoch :  256  Time:  0.667  Rel. Train L2 Loss :  0.030577863719728256  Rel. Test L2 Loss :  0.08519364356994628  Test L2 Loss :  0.12222421646118165  inv_L_scale:  [1.0, 1.0]
Epoch :  257  Time:  0.667  Rel. Train L2 Loss :  0.030952985121144187  Rel. Test L2 Loss :  0.08385191649198533  Test L2 Loss :  0.12000315725803375  inv_L_scale:  [1.0, 1.0]
Epoch :  258  Time:  0.667  Rel. Train L2 Loss :  0.030068501225776142  Rel. Test L2 Loss :  0.0849148041009903  Test L2 Loss :  0.12118831783533096  inv_L_scale:  [1.0, 1.0]
Epoch :  259  Time:  0.667  Rel. Train L2 Loss :  0.03055442257059945  Rel. Test L2 Loss :  0.08537402033805847  Test L2 Loss :  0.12259651988744735  inv_L_scale:  [1.0, 1.0]
Epoch :  260  Time:  0.667  Rel. Train L2 Loss :  0.03064228309525384  Rel. Test L2 Loss :  0.08449923038482667  Test L2 Loss :  0.120748271048069  inv_L_scale:  [1.0, 1.0]
Epoch :  261  Time:  0.667  Rel. Train L2 Loss :  0.029601003461413915  Rel. Test L2 Loss :  0.08547938644886016  Test L2 Loss :  0.12243939429521561  inv_L_scale:  [1.0, 1.0]
Epoch :  262  Time:  0.667  Rel. Train L2 Loss :  0.0295816441377004  Rel. Test L2 Loss :  0.08420546531677246  Test L2 Loss :  0.12090021282434464  inv_L_scale:  [1.0, 1.0]
Epoch :  263  Time:  0.667  Rel. Train L2 Loss :  0.029566457304689618  Rel. Test L2 Loss :  0.0833912044763565  Test L2 Loss :  0.11944000631570816  inv_L_scale:  [1.0, 1.0]
Epoch :  264  Time:  0.667  Rel. Train L2 Loss :  0.02944027809633149  Rel. Test L2 Loss :  0.08481182456016541  Test L2 Loss :  0.12152039706707  inv_L_scale:  [1.0, 1.0]
Epoch :  265  Time:  0.667  Rel. Train L2 Loss :  0.029678367442554896  Rel. Test L2 Loss :  0.08407530754804611  Test L2 Loss :  0.1201905643939972  inv_L_scale:  [1.0, 1.0]
Epoch :  266  Time:  0.667  Rel. Train L2 Loss :  0.029731019718779457  Rel. Test L2 Loss :  0.08493001401424408  Test L2 Loss :  0.12120736986398697  inv_L_scale:  [1.0, 1.0]
Epoch :  267  Time:  0.666  Rel. Train L2 Loss :  0.03006836184197002  Rel. Test L2 Loss :  0.08367430120706558  Test L2 Loss :  0.11945701837539673  inv_L_scale:  [1.0, 1.0]
Epoch :  268  Time:  0.667  Rel. Train L2 Loss :  0.029058919697999955  Rel. Test L2 Loss :  0.0840310126543045  Test L2 Loss :  0.12042589545249939  inv_L_scale:  [1.0, 1.0]
Epoch :  269  Time:  0.67  Rel. Train L2 Loss :  0.02954216274122397  Rel. Test L2 Loss :  0.08288163900375366  Test L2 Loss :  0.1187474364042282  inv_L_scale:  [1.0, 1.0]
Epoch :  270  Time:  0.667  Rel. Train L2 Loss :  0.028204723505510225  Rel. Test L2 Loss :  0.08401734054088593  Test L2 Loss :  0.12022275865077972  inv_L_scale:  [1.0, 1.0]
Epoch :  271  Time:  0.666  Rel. Train L2 Loss :  0.028495606887671682  Rel. Test L2 Loss :  0.08388976454734802  Test L2 Loss :  0.12008521050214767  inv_L_scale:  [1.0, 1.0]
Epoch :  272  Time:  0.666  Rel. Train L2 Loss :  0.028744668008552656  Rel. Test L2 Loss :  0.0836810314655304  Test L2 Loss :  0.1198409616947174  inv_L_scale:  [1.0, 1.0]
Epoch :  273  Time:  0.666  Rel. Train L2 Loss :  0.028056813296344546  Rel. Test L2 Loss :  0.08412712275981903  Test L2 Loss :  0.12066514998674392  inv_L_scale:  [1.0, 1.0]
Epoch :  274  Time:  0.666  Rel. Train L2 Loss :  0.027839323091838095  Rel. Test L2 Loss :  0.08407216101884842  Test L2 Loss :  0.11992214024066924  inv_L_scale:  [1.0, 1.0]
Epoch :  275  Time:  0.667  Rel. Train L2 Loss :  0.027513746155632866  Rel. Test L2 Loss :  0.0838796329498291  Test L2 Loss :  0.12027402311563491  inv_L_scale:  [1.0, 1.0]
Epoch :  276  Time:  0.666  Rel. Train L2 Loss :  0.028366477986176808  Rel. Test L2 Loss :  0.08343989610671997  Test L2 Loss :  0.11976155251264572  inv_L_scale:  [1.0, 1.0]
Epoch :  277  Time:  0.666  Rel. Train L2 Loss :  0.028078515860769485  Rel. Test L2 Loss :  0.08344808459281922  Test L2 Loss :  0.11938057482242584  inv_L_scale:  [1.0, 1.0]
Epoch :  278  Time:  0.666  Rel. Train L2 Loss :  0.02772214060028394  Rel. Test L2 Loss :  0.08321059077978134  Test L2 Loss :  0.11923781603574753  inv_L_scale:  [1.0, 1.0]
Epoch :  279  Time:  0.667  Rel. Train L2 Loss :  0.027731940928432678  Rel. Test L2 Loss :  0.08321482867002487  Test L2 Loss :  0.11891382992267609  inv_L_scale:  [1.0, 1.0]
Epoch :  280  Time:  0.666  Rel. Train L2 Loss :  0.027086611191431683  Rel. Test L2 Loss :  0.0830584278702736  Test L2 Loss :  0.11870677769184113  inv_L_scale:  [1.0, 1.0]
Epoch :  281  Time:  0.667  Rel. Train L2 Loss :  0.026865677941176627  Rel. Test L2 Loss :  0.0829868695139885  Test L2 Loss :  0.11845863342285157  inv_L_scale:  [1.0, 1.0]
Epoch :  282  Time:  0.667  Rel. Train L2 Loss :  0.026490872899691265  Rel. Test L2 Loss :  0.08277467250823975  Test L2 Loss :  0.11882014095783233  inv_L_scale:  [1.0, 1.0]
Epoch :  283  Time:  0.667  Rel. Train L2 Loss :  0.02671332830356227  Rel. Test L2 Loss :  0.08394839435815811  Test L2 Loss :  0.11997133016586303  inv_L_scale:  [1.0, 1.0]
Epoch :  284  Time:  0.667  Rel. Train L2 Loss :  0.0267235770324866  Rel. Test L2 Loss :  0.0850770828127861  Test L2 Loss :  0.12174118399620056  inv_L_scale:  [1.0, 1.0]
Epoch :  285  Time:  0.666  Rel. Train L2 Loss :  0.027036159419351155  Rel. Test L2 Loss :  0.08276943802833557  Test L2 Loss :  0.11845849871635437  inv_L_scale:  [1.0, 1.0]
Epoch :  286  Time:  0.666  Rel. Train L2 Loss :  0.026335182785987853  Rel. Test L2 Loss :  0.08367537140846253  Test L2 Loss :  0.11995412528514862  inv_L_scale:  [1.0, 1.0]
Epoch :  287  Time:  0.667  Rel. Train L2 Loss :  0.026128233497341474  Rel. Test L2 Loss :  0.08344106793403626  Test L2 Loss :  0.11931270897388459  inv_L_scale:  [1.0, 1.0]
Epoch :  288  Time:  0.666  Rel. Train L2 Loss :  0.026340219784114095  Rel. Test L2 Loss :  0.08376332253217697  Test L2 Loss :  0.12025131374597549  inv_L_scale:  [1.0, 1.0]
Epoch :  289  Time:  0.666  Rel. Train L2 Loss :  0.02603375993669033  Rel. Test L2 Loss :  0.08348080605268478  Test L2 Loss :  0.11968761801719666  inv_L_scale:  [1.0, 1.0]
Epoch :  290  Time:  0.667  Rel. Train L2 Loss :  0.025518164758880933  Rel. Test L2 Loss :  0.08291351616382599  Test L2 Loss :  0.11900482714176178  inv_L_scale:  [1.0, 1.0]
Epoch :  291  Time:  0.666  Rel. Train L2 Loss :  0.025170331969857216  Rel. Test L2 Loss :  0.08344432532787323  Test L2 Loss :  0.11960452347993851  inv_L_scale:  [1.0, 1.0]
Epoch :  292  Time:  0.667  Rel. Train L2 Loss :  0.026410507783293725  Rel. Test L2 Loss :  0.08403191477060318  Test L2 Loss :  0.12026245713233948  inv_L_scale:  [1.0, 1.0]
Epoch :  293  Time:  0.666  Rel. Train L2 Loss :  0.026135989725589753  Rel. Test L2 Loss :  0.08290955543518067  Test L2 Loss :  0.11862463057041168  inv_L_scale:  [1.0, 1.0]
Epoch :  294  Time:  0.666  Rel. Train L2 Loss :  0.026079510417249468  Rel. Test L2 Loss :  0.08319553315639495  Test L2 Loss :  0.11928166925907135  inv_L_scale:  [1.0, 1.0]
Epoch :  295  Time:  0.666  Rel. Train L2 Loss :  0.025784116395645672  Rel. Test L2 Loss :  0.08411841243505477  Test L2 Loss :  0.12039594411849976  inv_L_scale:  [1.0, 1.0]
Epoch :  296  Time:  0.667  Rel. Train L2 Loss :  0.024771413165662025  Rel. Test L2 Loss :  0.08262019485235214  Test L2 Loss :  0.11849254250526428  inv_L_scale:  [1.0, 1.0]
Epoch :  297  Time:  0.667  Rel. Train L2 Loss :  0.024782561461130777  Rel. Test L2 Loss :  0.08272962629795075  Test L2 Loss :  0.11842339038848877  inv_L_scale:  [1.0, 1.0]
Epoch :  298  Time:  0.667  Rel. Train L2 Loss :  0.024403402854998906  Rel. Test L2 Loss :  0.08288870751857758  Test L2 Loss :  0.11862858057022095  inv_L_scale:  [1.0, 1.0]
Epoch :  299  Time:  0.667  Rel. Train L2 Loss :  0.024023379865619872  Rel. Test L2 Loss :  0.08330388486385346  Test L2 Loss :  0.11937773793935776  inv_L_scale:  [1.0, 1.0]
Epoch :  300  Time:  0.669  Rel. Train L2 Loss :  0.02460677987999386  Rel. Test L2 Loss :  0.08182093918323517  Test L2 Loss :  0.11762797355651855  inv_L_scale:  [1.0, 1.0]
Epoch :  301  Time:  0.667  Rel. Train L2 Loss :  0.024251089874241086  Rel. Test L2 Loss :  0.08253717511892318  Test L2 Loss :  0.11827792197465897  inv_L_scale:  [1.0, 1.0]
Epoch :  302  Time:  0.666  Rel. Train L2 Loss :  0.023842694958051046  Rel. Test L2 Loss :  0.08222877144813538  Test L2 Loss :  0.11734184414148331  inv_L_scale:  [1.0, 1.0]
Epoch :  303  Time:  0.667  Rel. Train L2 Loss :  0.02377990879946285  Rel. Test L2 Loss :  0.08274957865476608  Test L2 Loss :  0.11861123561859131  inv_L_scale:  [1.0, 1.0]
Epoch :  304  Time:  0.666  Rel. Train L2 Loss :  0.02388210804098182  Rel. Test L2 Loss :  0.08255681574344635  Test L2 Loss :  0.11816231667995453  inv_L_scale:  [1.0, 1.0]
Epoch :  305  Time:  0.667  Rel. Train L2 Loss :  0.023493597060441972  Rel. Test L2 Loss :  0.08283731579780579  Test L2 Loss :  0.11869100123643875  inv_L_scale:  [1.0, 1.0]
Epoch :  306  Time:  0.667  Rel. Train L2 Loss :  0.02349739291601711  Rel. Test L2 Loss :  0.08199801534414292  Test L2 Loss :  0.11750028520822525  inv_L_scale:  [1.0, 1.0]
Epoch :  307  Time:  0.666  Rel. Train L2 Loss :  0.023581858227650323  Rel. Test L2 Loss :  0.08258423507213593  Test L2 Loss :  0.118068245947361  inv_L_scale:  [1.0, 1.0]
Epoch :  308  Time:  0.667  Rel. Train L2 Loss :  0.02300038860903846  Rel. Test L2 Loss :  0.08200083792209625  Test L2 Loss :  0.11803046733140946  inv_L_scale:  [1.0, 1.0]
Epoch :  309  Time:  0.666  Rel. Train L2 Loss :  0.02245385035044617  Rel. Test L2 Loss :  0.08242596119642258  Test L2 Loss :  0.11817886412143708  inv_L_scale:  [1.0, 1.0]
Epoch :  310  Time:  0.666  Rel. Train L2 Loss :  0.0231168705638912  Rel. Test L2 Loss :  0.08243182092905045  Test L2 Loss :  0.11803539305925369  inv_L_scale:  [1.0, 1.0]
Epoch :  311  Time:  0.666  Rel. Train L2 Loss :  0.023327845533688864  Rel. Test L2 Loss :  0.0819542071223259  Test L2 Loss :  0.11772878766059876  inv_L_scale:  [1.0, 1.0]
Epoch :  312  Time:  0.668  Rel. Train L2 Loss :  0.021378625647889244  Rel. Test L2 Loss :  0.08201684534549714  Test L2 Loss :  0.11769885808229447  inv_L_scale:  [1.0, 1.0]
Epoch :  313  Time:  0.667  Rel. Train L2 Loss :  0.022673872460921604  Rel. Test L2 Loss :  0.0827341240644455  Test L2 Loss :  0.1186821585893631  inv_L_scale:  [1.0, 1.0]
Epoch :  314  Time:  0.666  Rel. Train L2 Loss :  0.022304473121960957  Rel. Test L2 Loss :  0.08231930315494537  Test L2 Loss :  0.11783262580633164  inv_L_scale:  [1.0, 1.0]
Epoch :  315  Time:  0.667  Rel. Train L2 Loss :  0.02300118845370081  Rel. Test L2 Loss :  0.08169042021036148  Test L2 Loss :  0.11683347642421722  inv_L_scale:  [1.0, 1.0]
Epoch :  316  Time:  0.666  Rel. Train L2 Loss :  0.021348756576577824  Rel. Test L2 Loss :  0.08223927468061447  Test L2 Loss :  0.11764462411403656  inv_L_scale:  [1.0, 1.0]
Epoch :  317  Time:  0.666  Rel. Train L2 Loss :  0.021346558100647395  Rel. Test L2 Loss :  0.08227805733680725  Test L2 Loss :  0.11778372406959534  inv_L_scale:  [1.0, 1.0]
Epoch :  318  Time:  0.666  Rel. Train L2 Loss :  0.021680179660518963  Rel. Test L2 Loss :  0.08262347251176834  Test L2 Loss :  0.1182251912355423  inv_L_scale:  [1.0, 1.0]
Epoch :  319  Time:  0.667  Rel. Train L2 Loss :  0.02146712960468398  Rel. Test L2 Loss :  0.08201602518558503  Test L2 Loss :  0.11784112095832824  inv_L_scale:  [1.0, 1.0]
Epoch :  320  Time:  0.666  Rel. Train L2 Loss :  0.02089657348063257  Rel. Test L2 Loss :  0.081527079641819  Test L2 Loss :  0.11706631869077683  inv_L_scale:  [1.0, 1.0]
Epoch :  321  Time:  0.666  Rel. Train L2 Loss :  0.0205299748852849  Rel. Test L2 Loss :  0.08217550575733185  Test L2 Loss :  0.11769672572612762  inv_L_scale:  [1.0, 1.0]
Epoch :  322  Time:  0.666  Rel. Train L2 Loss :  0.020837230011820793  Rel. Test L2 Loss :  0.08178194314241409  Test L2 Loss :  0.11734482288360595  inv_L_scale:  [1.0, 1.0]
Epoch :  323  Time:  0.667  Rel. Train L2 Loss :  0.020196513599819606  Rel. Test L2 Loss :  0.08237477421760558  Test L2 Loss :  0.11795107007026673  inv_L_scale:  [1.0, 1.0]
Epoch :  324  Time:  0.666  Rel. Train L2 Loss :  0.020916763262616263  Rel. Test L2 Loss :  0.08172980785369872  Test L2 Loss :  0.11716028988361359  inv_L_scale:  [1.0, 1.0]
Epoch :  325  Time:  0.667  Rel. Train L2 Loss :  0.020486958134505483  Rel. Test L2 Loss :  0.08118786603212357  Test L2 Loss :  0.1166477432847023  inv_L_scale:  [1.0, 1.0]
Epoch :  326  Time:  0.666  Rel. Train L2 Loss :  0.02021406229171488  Rel. Test L2 Loss :  0.08171427667140961  Test L2 Loss :  0.11738035887479782  inv_L_scale:  [1.0, 1.0]
Epoch :  327  Time:  0.665  Rel. Train L2 Loss :  0.020172331482172012  Rel. Test L2 Loss :  0.08174765050411224  Test L2 Loss :  0.11735047191381455  inv_L_scale:  [1.0, 1.0]
Epoch :  328  Time:  0.664  Rel. Train L2 Loss :  0.020249173641204835  Rel. Test L2 Loss :  0.08122913300991058  Test L2 Loss :  0.11657141715288162  inv_L_scale:  [1.0, 1.0]
Epoch :  329  Time:  0.664  Rel. Train L2 Loss :  0.01967355853981442  Rel. Test L2 Loss :  0.08239317744970322  Test L2 Loss :  0.11841344892978668  inv_L_scale:  [1.0, 1.0]
Epoch :  330  Time:  0.664  Rel. Train L2 Loss :  0.019731805879208777  Rel. Test L2 Loss :  0.0818003299832344  Test L2 Loss :  0.11721567183732987  inv_L_scale:  [1.0, 1.0]
Epoch :  331  Time:  0.664  Rel. Train L2 Loss :  0.019571162031756507  Rel. Test L2 Loss :  0.08106167912483216  Test L2 Loss :  0.11634148567914963  inv_L_scale:  [1.0, 1.0]
Epoch :  332  Time:  0.664  Rel. Train L2 Loss :  0.020179601940843794  Rel. Test L2 Loss :  0.08174962162971497  Test L2 Loss :  0.11716987580060959  inv_L_scale:  [1.0, 1.0]
Epoch :  333  Time:  0.664  Rel. Train L2 Loss :  0.0193798914220598  Rel. Test L2 Loss :  0.08072776615619659  Test L2 Loss :  0.11559995323419571  inv_L_scale:  [1.0, 1.0]
Epoch :  334  Time:  0.664  Rel. Train L2 Loss :  0.019383606099420123  Rel. Test L2 Loss :  0.08146223545074463  Test L2 Loss :  0.11666350603103638  inv_L_scale:  [1.0, 1.0]
Epoch :  335  Time:  0.664  Rel. Train L2 Loss :  0.018846521452069283  Rel. Test L2 Loss :  0.08133216381072998  Test L2 Loss :  0.1163694417476654  inv_L_scale:  [1.0, 1.0]
Epoch :  336  Time:  0.664  Rel. Train L2 Loss :  0.01874830310543378  Rel. Test L2 Loss :  0.0811829036474228  Test L2 Loss :  0.11642065942287445  inv_L_scale:  [1.0, 1.0]
Epoch :  337  Time:  0.664  Rel. Train L2 Loss :  0.018403553374939496  Rel. Test L2 Loss :  0.08115103989839553  Test L2 Loss :  0.11642690986394882  inv_L_scale:  [1.0, 1.0]
Epoch :  338  Time:  0.664  Rel. Train L2 Loss :  0.01882598429918289  Rel. Test L2 Loss :  0.08174826264381409  Test L2 Loss :  0.11725929975509644  inv_L_scale:  [1.0, 1.0]
Epoch :  339  Time:  0.664  Rel. Train L2 Loss :  0.018660884491271443  Rel. Test L2 Loss :  0.08102144807577133  Test L2 Loss :  0.11624581724405289  inv_L_scale:  [1.0, 1.0]
Epoch :  340  Time:  0.664  Rel. Train L2 Loss :  0.018054072136680286  Rel. Test L2 Loss :  0.08081648111343384  Test L2 Loss :  0.11577436625957489  inv_L_scale:  [1.0, 1.0]
Epoch :  341  Time:  0.664  Rel. Train L2 Loss :  0.0179503326697482  Rel. Test L2 Loss :  0.08097797036170959  Test L2 Loss :  0.11610178083181381  inv_L_scale:  [1.0, 1.0]
Epoch :  342  Time:  0.664  Rel. Train L2 Loss :  0.018572420246071284  Rel. Test L2 Loss :  0.08159008413553238  Test L2 Loss :  0.1167982691526413  inv_L_scale:  [1.0, 1.0]
Epoch :  343  Time:  0.664  Rel. Train L2 Loss :  0.01829406206806501  Rel. Test L2 Loss :  0.08176433473825455  Test L2 Loss :  0.11719272196292878  inv_L_scale:  [1.0, 1.0]
Epoch :  344  Time:  0.666  Rel. Train L2 Loss :  0.01786399472090933  Rel. Test L2 Loss :  0.08110268980264664  Test L2 Loss :  0.1163604474067688  inv_L_scale:  [1.0, 1.0]
Epoch :  345  Time:  0.667  Rel. Train L2 Loss :  0.017924798197216457  Rel. Test L2 Loss :  0.08162018269300461  Test L2 Loss :  0.11683352828025818  inv_L_scale:  [1.0, 1.0]
Epoch :  346  Time:  0.665  Rel. Train L2 Loss :  0.01770148776471615  Rel. Test L2 Loss :  0.08144119143486023  Test L2 Loss :  0.1167548456788063  inv_L_scale:  [1.0, 1.0]
Epoch :  347  Time:  0.665  Rel. Train L2 Loss :  0.01763870157301426  Rel. Test L2 Loss :  0.0811225986480713  Test L2 Loss :  0.11619346082210541  inv_L_scale:  [1.0, 1.0]
Epoch :  348  Time:  0.665  Rel. Train L2 Loss :  0.017173769109778934  Rel. Test L2 Loss :  0.08158067584037781  Test L2 Loss :  0.11705648332834244  inv_L_scale:  [1.0, 1.0]
Epoch :  349  Time:  0.665  Rel. Train L2 Loss :  0.01721769828763273  Rel. Test L2 Loss :  0.08080921858549119  Test L2 Loss :  0.11610833376646042  inv_L_scale:  [1.0, 1.0]
Epoch :  350  Time:  0.665  Rel. Train L2 Loss :  0.01674001610527436  Rel. Test L2 Loss :  0.08171147584915162  Test L2 Loss :  0.11725961565971374  inv_L_scale:  [1.0, 1.0]
Epoch :  351  Time:  0.666  Rel. Train L2 Loss :  0.016687806364562775  Rel. Test L2 Loss :  0.0810905534029007  Test L2 Loss :  0.11613713175058366  inv_L_scale:  [1.0, 1.0]
Epoch :  352  Time:  0.664  Rel. Train L2 Loss :  0.016528838127851487  Rel. Test L2 Loss :  0.08194062680006027  Test L2 Loss :  0.11738184869289398  inv_L_scale:  [1.0, 1.0]
Epoch :  353  Time:  0.662  Rel. Train L2 Loss :  0.016662419330742625  Rel. Test L2 Loss :  0.08159682631492615  Test L2 Loss :  0.11710770159959794  inv_L_scale:  [1.0, 1.0]
Epoch :  354  Time:  0.663  Rel. Train L2 Loss :  0.016450879780782593  Rel. Test L2 Loss :  0.08142288118600845  Test L2 Loss :  0.11672241806983948  inv_L_scale:  [1.0, 1.0]
Epoch :  355  Time:  0.662  Rel. Train L2 Loss :  0.016050552729931142  Rel. Test L2 Loss :  0.08138660728931427  Test L2 Loss :  0.1166598403453827  inv_L_scale:  [1.0, 1.0]
Epoch :  356  Time:  0.663  Rel. Train L2 Loss :  0.016285852301451895  Rel. Test L2 Loss :  0.08121108651161194  Test L2 Loss :  0.11648699074983597  inv_L_scale:  [1.0, 1.0]
Epoch :  357  Time:  0.662  Rel. Train L2 Loss :  0.016047605470650726  Rel. Test L2 Loss :  0.08116822540760041  Test L2 Loss :  0.11628288984298706  inv_L_scale:  [1.0, 1.0]
Epoch :  358  Time:  0.662  Rel. Train L2 Loss :  0.015687542607386907  Rel. Test L2 Loss :  0.08142004549503326  Test L2 Loss :  0.11660173535346985  inv_L_scale:  [1.0, 1.0]
Epoch :  359  Time:  0.662  Rel. Train L2 Loss :  0.015541804217629962  Rel. Test L2 Loss :  0.08091094225645065  Test L2 Loss :  0.11586714714765549  inv_L_scale:  [1.0, 1.0]
Epoch :  360  Time:  0.662  Rel. Train L2 Loss :  0.015663211767872175  Rel. Test L2 Loss :  0.08132712811231613  Test L2 Loss :  0.11643288969993591  inv_L_scale:  [1.0, 1.0]
Epoch :  361  Time:  0.662  Rel. Train L2 Loss :  0.01511859784523646  Rel. Test L2 Loss :  0.08093755304813385  Test L2 Loss :  0.11593068957328796  inv_L_scale:  [1.0, 1.0]
Epoch :  362  Time:  0.663  Rel. Train L2 Loss :  0.015062068270312414  Rel. Test L2 Loss :  0.08091836869716644  Test L2 Loss :  0.11602866053581237  inv_L_scale:  [1.0, 1.0]
Epoch :  363  Time:  0.663  Rel. Train L2 Loss :  0.014755392306380802  Rel. Test L2 Loss :  0.08091622531414032  Test L2 Loss :  0.11610076189041138  inv_L_scale:  [1.0, 1.0]
Epoch :  364  Time:  0.662  Rel. Train L2 Loss :  0.0148181055403418  Rel. Test L2 Loss :  0.08101192355155945  Test L2 Loss :  0.11625106275081634  inv_L_scale:  [1.0, 1.0]
Epoch :  365  Time:  0.662  Rel. Train L2 Loss :  0.014757400469647514  Rel. Test L2 Loss :  0.08114544987678528  Test L2 Loss :  0.1164434888958931  inv_L_scale:  [1.0, 1.0]
Epoch :  366  Time:  0.662  Rel. Train L2 Loss :  0.014610124594635433  Rel. Test L2 Loss :  0.08151920318603516  Test L2 Loss :  0.11677366018295288  inv_L_scale:  [1.0, 1.0]
Epoch :  367  Time:  0.662  Rel. Train L2 Loss :  0.014339956761234337  Rel. Test L2 Loss :  0.08106834471225738  Test L2 Loss :  0.11598153173923492  inv_L_scale:  [1.0, 1.0]
Epoch :  368  Time:  0.663  Rel. Train L2 Loss :  0.014680109032326274  Rel. Test L2 Loss :  0.08122648864984512  Test L2 Loss :  0.11654929757118225  inv_L_scale:  [1.0, 1.0]
Epoch :  369  Time:  0.662  Rel. Train L2 Loss :  0.013950681860248247  Rel. Test L2 Loss :  0.0809868910908699  Test L2 Loss :  0.1161039012670517  inv_L_scale:  [1.0, 1.0]
Epoch :  370  Time:  0.663  Rel. Train L2 Loss :  0.014133737666739359  Rel. Test L2 Loss :  0.08114501684904099  Test L2 Loss :  0.11629264235496521  inv_L_scale:  [1.0, 1.0]
Epoch :  371  Time:  0.663  Rel. Train L2 Loss :  0.013754789912038379  Rel. Test L2 Loss :  0.08093641817569733  Test L2 Loss :  0.11620509386062622  inv_L_scale:  [1.0, 1.0]
Epoch :  372  Time:  0.662  Rel. Train L2 Loss :  0.013623694802323977  Rel. Test L2 Loss :  0.08142257034778595  Test L2 Loss :  0.11673776507377624  inv_L_scale:  [1.0, 1.0]
Epoch :  373  Time:  0.664  Rel. Train L2 Loss :  0.01379626513355308  Rel. Test L2 Loss :  0.08126835137605667  Test L2 Loss :  0.1164750224351883  inv_L_scale:  [1.0, 1.0]
Epoch :  374  Time:  0.663  Rel. Train L2 Loss :  0.01372281539771292  Rel. Test L2 Loss :  0.08070986032485962  Test L2 Loss :  0.11576394975185395  inv_L_scale:  [1.0, 1.0]
Epoch :  375  Time:  0.663  Rel. Train L2 Loss :  0.013546577650639746  Rel. Test L2 Loss :  0.081031534075737  Test L2 Loss :  0.11645685404539108  inv_L_scale:  [1.0, 1.0]
Epoch :  376  Time:  0.663  Rel. Train L2 Loss :  0.01316318071550793  Rel. Test L2 Loss :  0.08141803741455078  Test L2 Loss :  0.11684850454330445  inv_L_scale:  [1.0, 1.0]
Epoch :  377  Time:  0.663  Rel. Train L2 Loss :  0.013197246516744296  Rel. Test L2 Loss :  0.08092383682727813  Test L2 Loss :  0.11612129837274551  inv_L_scale:  [1.0, 1.0]
Epoch :  378  Time:  0.663  Rel. Train L2 Loss :  0.013108270996146731  Rel. Test L2 Loss :  0.08095656722784042  Test L2 Loss :  0.11616344124078751  inv_L_scale:  [1.0, 1.0]
Epoch :  379  Time:  0.663  Rel. Train L2 Loss :  0.012571678062280019  Rel. Test L2 Loss :  0.0806572061777115  Test L2 Loss :  0.11554171919822692  inv_L_scale:  [1.0, 1.0]
Epoch :  380  Time:  0.663  Rel. Train L2 Loss :  0.012342537310388353  Rel. Test L2 Loss :  0.08135786563158036  Test L2 Loss :  0.11661072939634323  inv_L_scale:  [1.0, 1.0]
Epoch :  381  Time:  0.663  Rel. Train L2 Loss :  0.012228662334382533  Rel. Test L2 Loss :  0.08098207503557205  Test L2 Loss :  0.11614533603191375  inv_L_scale:  [1.0, 1.0]
Epoch :  382  Time:  0.663  Rel. Train L2 Loss :  0.012715132559339206  Rel. Test L2 Loss :  0.0808146345615387  Test L2 Loss :  0.11591776221990585  inv_L_scale:  [1.0, 1.0]
Epoch :  383  Time:  0.664  Rel. Train L2 Loss :  0.012287717391219404  Rel. Test L2 Loss :  0.081219043135643  Test L2 Loss :  0.11636051535606384  inv_L_scale:  [1.0, 1.0]
Epoch :  384  Time:  0.663  Rel. Train L2 Loss :  0.012240147131184737  Rel. Test L2 Loss :  0.08130829572677613  Test L2 Loss :  0.11697358846664428  inv_L_scale:  [1.0, 1.0]
Epoch :  385  Time:  0.663  Rel. Train L2 Loss :  0.012198823690414428  Rel. Test L2 Loss :  0.0811645558476448  Test L2 Loss :  0.11633526116609573  inv_L_scale:  [1.0, 1.0]
Epoch :  386  Time:  0.663  Rel. Train L2 Loss :  0.011990661240286297  Rel. Test L2 Loss :  0.080861556828022  Test L2 Loss :  0.11597754895687103  inv_L_scale:  [1.0, 1.0]
Epoch :  387  Time:  0.663  Rel. Train L2 Loss :  0.011823253271480401  Rel. Test L2 Loss :  0.08103811264038085  Test L2 Loss :  0.11626290440559388  inv_L_scale:  [1.0, 1.0]
Epoch :  388  Time:  0.664  Rel. Train L2 Loss :  0.011633186489343644  Rel. Test L2 Loss :  0.08086512058973312  Test L2 Loss :  0.11603843867778778  inv_L_scale:  [1.0, 1.0]
Epoch :  389  Time:  0.663  Rel. Train L2 Loss :  0.011686817444860935  Rel. Test L2 Loss :  0.08099854916334152  Test L2 Loss :  0.11636599898338318  inv_L_scale:  [1.0, 1.0]
Epoch :  390  Time:  0.663  Rel. Train L2 Loss :  0.011596093136403295  Rel. Test L2 Loss :  0.08086324125528335  Test L2 Loss :  0.11627616703510285  inv_L_scale:  [1.0, 1.0]
Epoch :  391  Time:  0.663  Rel. Train L2 Loss :  0.011212226272457175  Rel. Test L2 Loss :  0.08118226766586303  Test L2 Loss :  0.11638674914836883  inv_L_scale:  [1.0, 1.0]
Epoch :  392  Time:  0.663  Rel. Train L2 Loss :  0.011245994774831666  Rel. Test L2 Loss :  0.0812738835811615  Test L2 Loss :  0.11668167054653168  inv_L_scale:  [1.0, 1.0]
Epoch :  393  Time:  0.663  Rel. Train L2 Loss :  0.011742436070409087  Rel. Test L2 Loss :  0.08117065817117691  Test L2 Loss :  0.11659091293811798  inv_L_scale:  [1.0, 1.0]
Epoch :  394  Time:  0.663  Rel. Train L2 Loss :  0.011604503244161606  Rel. Test L2 Loss :  0.08126694411039352  Test L2 Loss :  0.11654045194387436  inv_L_scale:  [1.0, 1.0]
Epoch :  395  Time:  0.663  Rel. Train L2 Loss :  0.011013643973403507  Rel. Test L2 Loss :  0.08105978965759278  Test L2 Loss :  0.11619769811630248  inv_L_scale:  [1.0, 1.0]
Epoch :  396  Time:  0.663  Rel. Train L2 Loss :  0.010882058234678374  Rel. Test L2 Loss :  0.08080343902111053  Test L2 Loss :  0.1159425449371338  inv_L_scale:  [1.0, 1.0]
Epoch :  397  Time:  0.665  Rel. Train L2 Loss :  0.010618815571069718  Rel. Test L2 Loss :  0.08092582702636719  Test L2 Loss :  0.1161971652507782  inv_L_scale:  [1.0, 1.0]
Epoch :  398  Time:  0.664  Rel. Train L2 Loss :  0.010415138490498067  Rel. Test L2 Loss :  0.08111948549747466  Test L2 Loss :  0.11626398861408234  inv_L_scale:  [1.0, 1.0]
Epoch :  399  Time:  0.663  Rel. Train L2 Loss :  0.01031103319591946  Rel. Test L2 Loss :  0.08098379135131836  Test L2 Loss :  0.116178337931633  inv_L_scale:  [1.0, 1.0]
Epoch :  400  Time:  0.667  Rel. Train L2 Loss :  0.010135022062394354  Rel. Test L2 Loss :  0.08089406698942185  Test L2 Loss :  0.11610922008752823  inv_L_scale:  [1.0, 1.0]
Epoch :  401  Time:  0.664  Rel. Train L2 Loss :  0.010002649964557754  Rel. Test L2 Loss :  0.08109821170568467  Test L2 Loss :  0.11626524239778518  inv_L_scale:  [1.0, 1.0]
Epoch :  402  Time:  0.663  Rel. Train L2 Loss :  0.009998502110441525  Rel. Test L2 Loss :  0.08133852541446686  Test L2 Loss :  0.11663101017475128  inv_L_scale:  [1.0, 1.0]
Epoch :  403  Time:  0.664  Rel. Train L2 Loss :  0.009877571488420169  Rel. Test L2 Loss :  0.08101494073867797  Test L2 Loss :  0.11619101375341416  inv_L_scale:  [1.0, 1.0]
Epoch :  404  Time:  0.664  Rel. Train L2 Loss :  0.009685626522534423  Rel. Test L2 Loss :  0.08109196484088897  Test L2 Loss :  0.11632089763879776  inv_L_scale:  [1.0, 1.0]
Epoch :  405  Time:  0.665  Rel. Train L2 Loss :  0.009531621970236302  Rel. Test L2 Loss :  0.08093684256076812  Test L2 Loss :  0.11610201269388198  inv_L_scale:  [1.0, 1.0]
Epoch :  406  Time:  0.664  Rel. Train L2 Loss :  0.009537255528072516  Rel. Test L2 Loss :  0.08105497747659683  Test L2 Loss :  0.11628341197967529  inv_L_scale:  [1.0, 1.0]
Epoch :  407  Time:  0.664  Rel. Train L2 Loss :  0.009710587287942569  Rel. Test L2 Loss :  0.08139905959367752  Test L2 Loss :  0.11671709299087524  inv_L_scale:  [1.0, 1.0]
Epoch :  408  Time:  0.664  Rel. Train L2 Loss :  0.009481677719288402  Rel. Test L2 Loss :  0.08116107672452927  Test L2 Loss :  0.11643270373344422  inv_L_scale:  [1.0, 1.0]
Epoch :  409  Time:  0.664  Rel. Train L2 Loss :  0.009277584254741669  Rel. Test L2 Loss :  0.08095293700695037  Test L2 Loss :  0.11610818654298782  inv_L_scale:  [1.0, 1.0]
Epoch :  410  Time:  0.664  Rel. Train L2 Loss :  0.009166702301137978  Rel. Test L2 Loss :  0.0811586818099022  Test L2 Loss :  0.11636113375425339  inv_L_scale:  [1.0, 1.0]
Epoch :  411  Time:  0.664  Rel. Train L2 Loss :  0.009291505184438494  Rel. Test L2 Loss :  0.08106034517288208  Test L2 Loss :  0.11623412787914277  inv_L_scale:  [1.0, 1.0]
Epoch :  412  Time:  0.664  Rel. Train L2 Loss :  0.009158904428283373  Rel. Test L2 Loss :  0.08116248548030854  Test L2 Loss :  0.11643405050039292  inv_L_scale:  [1.0, 1.0]
Epoch :  413  Time:  0.665  Rel. Train L2 Loss :  0.009185582374533017  Rel. Test L2 Loss :  0.08119132697582244  Test L2 Loss :  0.11652824580669403  inv_L_scale:  [1.0, 1.0]
Epoch :  414  Time:  0.665  Rel. Train L2 Loss :  0.0091294692001409  Rel. Test L2 Loss :  0.08104312598705292  Test L2 Loss :  0.11636875808238983  inv_L_scale:  [1.0, 1.0]
Epoch :  415  Time:  0.664  Rel. Train L2 Loss :  0.008758980085452398  Rel. Test L2 Loss :  0.08124884456396103  Test L2 Loss :  0.11657515555620193  inv_L_scale:  [1.0, 1.0]
Epoch :  416  Time:  0.664  Rel. Train L2 Loss :  0.008528394392795033  Rel. Test L2 Loss :  0.08107279628515243  Test L2 Loss :  0.11632760435342789  inv_L_scale:  [1.0, 1.0]
Epoch :  417  Time:  0.665  Rel. Train L2 Loss :  0.008470221751679977  Rel. Test L2 Loss :  0.08114653378725052  Test L2 Loss :  0.11633677452802658  inv_L_scale:  [1.0, 1.0]
Epoch :  418  Time:  0.664  Rel. Train L2 Loss :  0.008423497494724062  Rel. Test L2 Loss :  0.08111949235200883  Test L2 Loss :  0.11645555198192596  inv_L_scale:  [1.0, 1.0]
Epoch :  419  Time:  0.664  Rel. Train L2 Loss :  0.008263830877840519  Rel. Test L2 Loss :  0.08115351468324661  Test L2 Loss :  0.11637531638145447  inv_L_scale:  [1.0, 1.0]
Epoch :  420  Time:  0.664  Rel. Train L2 Loss :  0.00822731088846922  Rel. Test L2 Loss :  0.08112690985202789  Test L2 Loss :  0.11634514480829239  inv_L_scale:  [1.0, 1.0]
Epoch :  421  Time:  0.664  Rel. Train L2 Loss :  0.00815445056806008  Rel. Test L2 Loss :  0.08125445306301117  Test L2 Loss :  0.1166505116224289  inv_L_scale:  [1.0, 1.0]
Epoch :  422  Time:  0.664  Rel. Train L2 Loss :  0.00819061345110337  Rel. Test L2 Loss :  0.0810495749115944  Test L2 Loss :  0.11621669858694077  inv_L_scale:  [1.0, 1.0]
Epoch :  423  Time:  0.664  Rel. Train L2 Loss :  0.008074571349554591  Rel. Test L2 Loss :  0.08111213862895966  Test L2 Loss :  0.11631424337625504  inv_L_scale:  [1.0, 1.0]
Epoch :  424  Time:  0.664  Rel. Train L2 Loss :  0.007932948656380176  Rel. Test L2 Loss :  0.08126647233963012  Test L2 Loss :  0.11657409608364105  inv_L_scale:  [1.0, 1.0]
Epoch :  425  Time:  0.664  Rel. Train L2 Loss :  0.007845898808704482  Rel. Test L2 Loss :  0.08135655850172042  Test L2 Loss :  0.11665795922279358  inv_L_scale:  [1.0, 1.0]
Epoch :  426  Time:  0.664  Rel. Train L2 Loss :  0.00781941693276167  Rel. Test L2 Loss :  0.08135559767484665  Test L2 Loss :  0.11672540068626404  inv_L_scale:  [1.0, 1.0]
Epoch :  427  Time:  0.664  Rel. Train L2 Loss :  0.007730963372935851  Rel. Test L2 Loss :  0.08118479281663894  Test L2 Loss :  0.11641497761011124  inv_L_scale:  [1.0, 1.0]
Epoch :  428  Time:  0.664  Rel. Train L2 Loss :  0.0076304141742487746  Rel. Test L2 Loss :  0.08122493505477905  Test L2 Loss :  0.116486357152462  inv_L_scale:  [1.0, 1.0]
Epoch :  429  Time:  0.664  Rel. Train L2 Loss :  0.007557904790672991  Rel. Test L2 Loss :  0.08104062646627426  Test L2 Loss :  0.1163188135623932  inv_L_scale:  [1.0, 1.0]
Epoch :  430  Time:  0.664  Rel. Train L2 Loss :  0.007413501573933496  Rel. Test L2 Loss :  0.08132832109928131  Test L2 Loss :  0.1166915100812912  inv_L_scale:  [1.0, 1.0]
Epoch :  431  Time:  0.664  Rel. Train L2 Loss :  0.00744935817602608  Rel. Test L2 Loss :  0.08119527101516724  Test L2 Loss :  0.11653300553560257  inv_L_scale:  [1.0, 1.0]
Epoch :  432  Time:  0.667  Rel. Train L2 Loss :  0.007437082725680537  Rel. Test L2 Loss :  0.08138612687587737  Test L2 Loss :  0.1166980293393135  inv_L_scale:  [1.0, 1.0]
Epoch :  433  Time:  0.665  Rel. Train L2 Loss :  0.007190342947012848  Rel. Test L2 Loss :  0.08116786986589432  Test L2 Loss :  0.11642516076564789  inv_L_scale:  [1.0, 1.0]
Epoch :  434  Time:  0.664  Rel. Train L2 Loss :  0.007140073614815871  Rel. Test L2 Loss :  0.08131853610277176  Test L2 Loss :  0.11665804535150529  inv_L_scale:  [1.0, 1.0]
Epoch :  435  Time:  0.665  Rel. Train L2 Loss :  0.007077965972324213  Rel. Test L2 Loss :  0.0812798872590065  Test L2 Loss :  0.11656726121902466  inv_L_scale:  [1.0, 1.0]
Epoch :  436  Time:  0.664  Rel. Train L2 Loss :  0.007015909337335162  Rel. Test L2 Loss :  0.08120221465826034  Test L2 Loss :  0.11648088812828064  inv_L_scale:  [1.0, 1.0]
Epoch :  437  Time:  0.664  Rel. Train L2 Loss :  0.007009294196549389  Rel. Test L2 Loss :  0.08121991991996765  Test L2 Loss :  0.11654216706752778  inv_L_scale:  [1.0, 1.0]
Epoch :  438  Time:  0.664  Rel. Train L2 Loss :  0.006920962743461132  Rel. Test L2 Loss :  0.08130229026079178  Test L2 Loss :  0.11663355469703675  inv_L_scale:  [1.0, 1.0]
Epoch :  439  Time:  0.665  Rel. Train L2 Loss :  0.006897046998557118  Rel. Test L2 Loss :  0.08126822650432587  Test L2 Loss :  0.11654656529426574  inv_L_scale:  [1.0, 1.0]
Epoch :  440  Time:  0.664  Rel. Train L2 Loss :  0.006803200095891953  Rel. Test L2 Loss :  0.08120651453733445  Test L2 Loss :  0.11648486852645874  inv_L_scale:  [1.0, 1.0]
Epoch :  441  Time:  0.664  Rel. Train L2 Loss :  0.006784893009397719  Rel. Test L2 Loss :  0.0813068687915802  Test L2 Loss :  0.11661255419254303  inv_L_scale:  [1.0, 1.0]
Epoch :  442  Time:  0.664  Rel. Train L2 Loss :  0.006710456651118067  Rel. Test L2 Loss :  0.08133303701877594  Test L2 Loss :  0.11670792162418366  inv_L_scale:  [1.0, 1.0]
Epoch :  443  Time:  0.664  Rel. Train L2 Loss :  0.006631521265953779  Rel. Test L2 Loss :  0.08138111561536789  Test L2 Loss :  0.1167131358385086  inv_L_scale:  [1.0, 1.0]
Epoch :  444  Time:  0.664  Rel. Train L2 Loss :  0.006574401598837641  Rel. Test L2 Loss :  0.08132945448160171  Test L2 Loss :  0.11666024476289749  inv_L_scale:  [1.0, 1.0]
Epoch :  445  Time:  0.664  Rel. Train L2 Loss :  0.006494361004895634  Rel. Test L2 Loss :  0.08136097937822342  Test L2 Loss :  0.11668671667575836  inv_L_scale:  [1.0, 1.0]
Epoch :  446  Time:  0.664  Rel. Train L2 Loss :  0.0064917190704080795  Rel. Test L2 Loss :  0.0813593539595604  Test L2 Loss :  0.11672936290502549  inv_L_scale:  [1.0, 1.0]
Epoch :  447  Time:  0.664  Rel. Train L2 Loss :  0.006478374443120427  Rel. Test L2 Loss :  0.0813720628619194  Test L2 Loss :  0.11672165870666504  inv_L_scale:  [1.0, 1.0]
Epoch :  448  Time:  0.664  Rel. Train L2 Loss :  0.006467842463817861  Rel. Test L2 Loss :  0.08133118659257889  Test L2 Loss :  0.11667736083269119  inv_L_scale:  [1.0, 1.0]
Epoch :  449  Time:  0.664  Rel. Train L2 Loss :  0.0063992848371466  Rel. Test L2 Loss :  0.08138103514909745  Test L2 Loss :  0.11672193676233292  inv_L_scale:  [1.0, 1.0]
Epoch :  450  Time:  0.665  Rel. Train L2 Loss :  0.0063183583650324076  Rel. Test L2 Loss :  0.08134509325027466  Test L2 Loss :  0.11671112596988678  inv_L_scale:  [1.0, 1.0]
Epoch :  451  Time:  0.664  Rel. Train L2 Loss :  0.006252296653886636  Rel. Test L2 Loss :  0.08141251146793366  Test L2 Loss :  0.11674338757991791  inv_L_scale:  [1.0, 1.0]
Epoch :  452  Time:  0.664  Rel. Train L2 Loss :  0.006227171673542924  Rel. Test L2 Loss :  0.08133512645959855  Test L2 Loss :  0.11667047828435897  inv_L_scale:  [1.0, 1.0]
Epoch :  453  Time:  0.664  Rel. Train L2 Loss :  0.0061930976166493365  Rel. Test L2 Loss :  0.08140933841466903  Test L2 Loss :  0.1167725196480751  inv_L_scale:  [1.0, 1.0]
Epoch :  454  Time:  0.664  Rel. Train L2 Loss :  0.006198168450759517  Rel. Test L2 Loss :  0.08134163558483123  Test L2 Loss :  0.11668495535850525  inv_L_scale:  [1.0, 1.0]
Epoch :  455  Time:  0.664  Rel. Train L2 Loss :  0.006118715647608042  Rel. Test L2 Loss :  0.08139020770788193  Test L2 Loss :  0.11674951612949372  inv_L_scale:  [1.0, 1.0]
Epoch :  456  Time:  0.665  Rel. Train L2 Loss :  0.006113129982517825  Rel. Test L2 Loss :  0.0814861962199211  Test L2 Loss :  0.11688904285430908  inv_L_scale:  [1.0, 1.0]
Epoch :  457  Time:  0.664  Rel. Train L2 Loss :  0.006068821692218383  Rel. Test L2 Loss :  0.08137590199708938  Test L2 Loss :  0.11676615983247757  inv_L_scale:  [1.0, 1.0]
Epoch :  458  Time:  0.665  Rel. Train L2 Loss :  0.006045589341471593  Rel. Test L2 Loss :  0.08141250193119048  Test L2 Loss :  0.11679933071136475  inv_L_scale:  [1.0, 1.0]
Epoch :  459  Time:  0.664  Rel. Train L2 Loss :  0.006006162634326352  Rel. Test L2 Loss :  0.0814510440826416  Test L2 Loss :  0.11686685413122178  inv_L_scale:  [1.0, 1.0]
Epoch :  460  Time:  0.664  Rel. Train L2 Loss :  0.005947868497007423  Rel. Test L2 Loss :  0.08147962123155594  Test L2 Loss :  0.11690250039100647  inv_L_scale:  [1.0, 1.0]
Epoch :  461  Time:  0.664  Rel. Train L2 Loss :  0.005936407169534101  Rel. Test L2 Loss :  0.08139273911714553  Test L2 Loss :  0.11677903801202774  inv_L_scale:  [1.0, 1.0]
Epoch :  462  Time:  0.664  Rel. Train L2 Loss :  0.005904295165091753  Rel. Test L2 Loss :  0.0814194431900978  Test L2 Loss :  0.11679049670696258  inv_L_scale:  [1.0, 1.0]
Epoch :  463  Time:  0.664  Rel. Train L2 Loss :  0.005859211184498336  Rel. Test L2 Loss :  0.08137909710407257  Test L2 Loss :  0.11675280183553696  inv_L_scale:  [1.0, 1.0]
Epoch :  464  Time:  0.664  Rel. Train L2 Loss :  0.0058341676824622685  Rel. Test L2 Loss :  0.08143365174531937  Test L2 Loss :  0.11681553274393082  inv_L_scale:  [1.0, 1.0]
Epoch :  465  Time:  0.665  Rel. Train L2 Loss :  0.00581701796501875  Rel. Test L2 Loss :  0.08144474655389786  Test L2 Loss :  0.11682296603918076  inv_L_scale:  [1.0, 1.0]
Epoch :  466  Time:  0.664  Rel. Train L2 Loss :  0.005804754955073197  Rel. Test L2 Loss :  0.08147052347660065  Test L2 Loss :  0.11686870992183686  inv_L_scale:  [1.0, 1.0]
Epoch :  467  Time:  0.665  Rel. Train L2 Loss :  0.005776605885475874  Rel. Test L2 Loss :  0.08147392511367797  Test L2 Loss :  0.11687005132436752  inv_L_scale:  [1.0, 1.0]
Epoch :  468  Time:  0.666  Rel. Train L2 Loss :  0.005760201475479536  Rel. Test L2 Loss :  0.0814662778377533  Test L2 Loss :  0.1168697053194046  inv_L_scale:  [1.0, 1.0]
Epoch :  469  Time:  0.665  Rel. Train L2 Loss :  0.00574774733848042  Rel. Test L2 Loss :  0.08148161143064499  Test L2 Loss :  0.11688119113445282  inv_L_scale:  [1.0, 1.0]
Epoch :  470  Time:  0.665  Rel. Train L2 Loss :  0.0057385488309794  Rel. Test L2 Loss :  0.08147029340267181  Test L2 Loss :  0.11688012838363647  inv_L_scale:  [1.0, 1.0]
Epoch :  471  Time:  0.664  Rel. Train L2 Loss :  0.005726302709016535  Rel. Test L2 Loss :  0.08148322939872742  Test L2 Loss :  0.11688391923904419  inv_L_scale:  [1.0, 1.0]
Epoch :  472  Time:  0.664  Rel. Train L2 Loss :  0.005698393206629488  Rel. Test L2 Loss :  0.08150157392024994  Test L2 Loss :  0.11691701173782348  inv_L_scale:  [1.0, 1.0]
Epoch :  473  Time:  0.665  Rel. Train L2 Loss :  0.0056825816941758  Rel. Test L2 Loss :  0.08150623857975006  Test L2 Loss :  0.11692008674144745  inv_L_scale:  [1.0, 1.0]
Epoch :  474  Time:  0.666  Rel. Train L2 Loss :  0.005660671461373568  Rel. Test L2 Loss :  0.08153473764657974  Test L2 Loss :  0.11696279793977737  inv_L_scale:  [1.0, 1.0]
Epoch :  475  Time:  0.665  Rel. Train L2 Loss :  0.005652203874455558  Rel. Test L2 Loss :  0.08152883559465408  Test L2 Loss :  0.11694560229778289  inv_L_scale:  [1.0, 1.0]
Epoch :  476  Time:  0.664  Rel. Train L2 Loss :  0.0056407057928542295  Rel. Test L2 Loss :  0.0815264880657196  Test L2 Loss :  0.11695842027664184  inv_L_scale:  [1.0, 1.0]
Epoch :  477  Time:  0.665  Rel. Train L2 Loss :  0.00562446052622464  Rel. Test L2 Loss :  0.08152412176132202  Test L2 Loss :  0.11694319278001786  inv_L_scale:  [1.0, 1.0]
Epoch :  478  Time:  0.665  Rel. Train L2 Loss :  0.005619266864119304  Rel. Test L2 Loss :  0.08149939090013504  Test L2 Loss :  0.11692085564136505  inv_L_scale:  [1.0, 1.0]
Epoch :  479  Time:  0.664  Rel. Train L2 Loss :  0.005608087838109997  Rel. Test L2 Loss :  0.08151706635951995  Test L2 Loss :  0.11693237721920013  inv_L_scale:  [1.0, 1.0]
Epoch :  480  Time:  0.665  Rel. Train L2 Loss :  0.005593341717289554  Rel. Test L2 Loss :  0.08154264271259308  Test L2 Loss :  0.11698234975337982  inv_L_scale:  [1.0, 1.0]
Epoch :  481  Time:  0.665  Rel. Train L2 Loss :  0.005583607270899746  Rel. Test L2 Loss :  0.08152143031358719  Test L2 Loss :  0.11695777773857116  inv_L_scale:  [1.0, 1.0]
Epoch :  482  Time:  0.664  Rel. Train L2 Loss :  0.005568787145117919  Rel. Test L2 Loss :  0.0815135470032692  Test L2 Loss :  0.11693449586629867  inv_L_scale:  [1.0, 1.0]
Epoch :  483  Time:  0.664  Rel. Train L2 Loss :  0.005564645261814197  Rel. Test L2 Loss :  0.08152796924114228  Test L2 Loss :  0.11695316702127456  inv_L_scale:  [1.0, 1.0]
Epoch :  484  Time:  0.664  Rel. Train L2 Loss :  0.005556001400368081  Rel. Test L2 Loss :  0.08152663707733154  Test L2 Loss :  0.11695326775312424  inv_L_scale:  [1.0, 1.0]
Epoch :  485  Time:  0.665  Rel. Train L2 Loss :  0.0055479707693060236  Rel. Test L2 Loss :  0.08154738932847977  Test L2 Loss :  0.11698277860879898  inv_L_scale:  [1.0, 1.0]
Epoch :  486  Time:  0.664  Rel. Train L2 Loss :  0.005541925471689966  Rel. Test L2 Loss :  0.08153309404850007  Test L2 Loss :  0.11696555018424988  inv_L_scale:  [1.0, 1.0]
Epoch :  487  Time:  0.665  Rel. Train L2 Loss :  0.005533492712097035  Rel. Test L2 Loss :  0.08154020607471466  Test L2 Loss :  0.11697256803512573  inv_L_scale:  [1.0, 1.0]
Epoch :  488  Time:  0.664  Rel. Train L2 Loss :  0.005527058645255036  Rel. Test L2 Loss :  0.08155963659286498  Test L2 Loss :  0.11700312614440918  inv_L_scale:  [1.0, 1.0]
Epoch :  489  Time:  0.664  Rel. Train L2 Loss :  0.0055216118279430605  Rel. Test L2 Loss :  0.08153548836708069  Test L2 Loss :  0.1169639691710472  inv_L_scale:  [1.0, 1.0]
Epoch :  490  Time:  0.664  Rel. Train L2 Loss :  0.005516921977202097  Rel. Test L2 Loss :  0.08154576539993286  Test L2 Loss :  0.116979700922966  inv_L_scale:  [1.0, 1.0]
Epoch :  491  Time:  0.664  Rel. Train L2 Loss :  0.005512036422474517  Rel. Test L2 Loss :  0.08155041545629502  Test L2 Loss :  0.11699065297842026  inv_L_scale:  [1.0, 1.0]
Epoch :  492  Time:  0.665  Rel. Train L2 Loss :  0.005506537842253844  Rel. Test L2 Loss :  0.08155575007200241  Test L2 Loss :  0.11699395954608917  inv_L_scale:  [1.0, 1.0]
Epoch :  493  Time:  0.665  Rel. Train L2 Loss :  0.005502343471679423  Rel. Test L2 Loss :  0.08156969666481018  Test L2 Loss :  0.11701335906982421  inv_L_scale:  [1.0, 1.0]
Epoch :  494  Time:  0.665  Rel. Train L2 Loss :  0.0054994091267387074  Rel. Test L2 Loss :  0.0815581014752388  Test L2 Loss :  0.11699477136135102  inv_L_scale:  [1.0, 1.0]
Epoch :  495  Time:  0.665  Rel. Train L2 Loss :  0.00549522559882866  Rel. Test L2 Loss :  0.08156916975975037  Test L2 Loss :  0.11701261341571807  inv_L_scale:  [1.0, 1.0]
Epoch :  496  Time:  0.665  Rel. Train L2 Loss :  0.005490276678982708  Rel. Test L2 Loss :  0.08156629621982575  Test L2 Loss :  0.11701000571250915  inv_L_scale:  [1.0, 1.0]
Epoch :  497  Time:  0.665  Rel. Train L2 Loss :  0.005485909775727325  Rel. Test L2 Loss :  0.08158187121152878  Test L2 Loss :  0.11703208208084107  inv_L_scale:  [1.0, 1.0]
Epoch :  498  Time:  0.666  Rel. Train L2 Loss :  0.00548377523612645  Rel. Test L2 Loss :  0.0815720146894455  Test L2 Loss :  0.11701329052448273  inv_L_scale:  [1.0, 1.0]
Epoch :  499  Time:  0.665  Rel. Train L2 Loss :  0.0054812539513740275  Rel. Test L2 Loss :  0.08157374024391174  Test L2 Loss :  0.11701862007379532  inv_L_scale:  [1.0, 1.0]
