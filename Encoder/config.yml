FFT_2D:

  data:
    L: 1.0
    downsample_ratio: 15
    n_train: 1000
    n_test: 200

  model:
    layer_types: ['DoubleAttention','GalerkinConv_fourier','GalerkinConv_fourier','DoubleAttention']  # GalerkinConv_fourier ， GalerkinConv_pca ， FourierConv2d ，Attention
    # layer_types: ['FourierConv2d','FourierConv2d','FourierConv2d','FourierConv2d']  # GalerkinConv_fourier ， GalerkinConv_pca ， FourierConv2d ，Attention
    FNO_modes: [16,16,16,16]   # modes for FourierConv2d
    GkNN_modes: [128,128,128,128]  # modes for GkNN
    num_heads: [1,1,1,1]
    attention_types: ["galerkin","galerkin","galerkin","galerkin"]
    fc_dim: 128
    in_dim: 3  #default
    out_dim: 1  #default
    pca_include_input: False
    pca_include_grid: False
    layers_dim: [128,128,128,128,128]     # len(layers_dim) == len(..modes)+1 
    act: 'gelu'
    pad_ratio: 0.05
    residual : [False,False,False,False]
    test_types : ["encoder", 0, 0, "decoder"]


  train:
    device: 'cpu'   #cpu or cuda
    base_lr: 0.001
    weight_decay: 0.0001
    epochs: 500
    scheduler: 'OneCycleLR'
    milestones: [200,300,400,500,800,900]
    scheduler_gamma: 0.5
    batch_size: 8
    normalization_x: True
    normalization_y: True
    normalization_dim: []

