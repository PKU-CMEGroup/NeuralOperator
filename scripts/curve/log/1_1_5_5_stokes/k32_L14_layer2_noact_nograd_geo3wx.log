Loading data from  ../../data/curve//pcno_curve_data_1_1_5_5_stokes.npz
(1000,) (1000, 1000, 1) (1000, 1000, 2)
use normalized raw measures
Casting to tensor
x_train shape torch.Size([900, 1000, 6]), y_train shape torch.Size([900, 1000, 1])
length of each dim:  tensor([6.6455335617065430, 6.6654777526855469])
kmax = 32
L = 14
geo_dims = [1, 2, 3, 4], num_grad = 3
In PCNO_train, ndims =  2
Epoch :  0  Time:  3.091  Rel. Train L2 Loss :  0.5562793596585591  Rel. Test L2 Loss :  0.2962349891662598  Test L2 Loss :  0.5530226802825928  inv_L_scale:  [1.0, 1.0]
Epoch :  1  Time:  2.594  Rel. Train L2 Loss :  0.253761283159256  Rel. Test L2 Loss :  0.2213482677936554  Test L2 Loss :  0.41236374258995057  inv_L_scale:  [1.0, 1.0]
Epoch :  2  Time:  2.587  Rel. Train L2 Loss :  0.18981487803988986  Rel. Test L2 Loss :  0.16464304208755492  Test L2 Loss :  0.30794501543045044  inv_L_scale:  [1.0, 1.0]
Epoch :  3  Time:  2.578  Rel. Train L2 Loss :  0.1520734210146798  Rel. Test L2 Loss :  0.1369481062889099  Test L2 Loss :  0.25944456696510315  inv_L_scale:  [1.0, 1.0]
Epoch :  4  Time:  2.593  Rel. Train L2 Loss :  0.13522101521492005  Rel. Test L2 Loss :  0.12819311022758484  Test L2 Loss :  0.23980051159858704  inv_L_scale:  [1.0, 1.0]
Epoch :  5  Time:  2.584  Rel. Train L2 Loss :  0.11766407476531135  Rel. Test L2 Loss :  0.11694936245679856  Test L2 Loss :  0.21887792766094208  inv_L_scale:  [1.0, 1.0]
Epoch :  6  Time:  2.57  Rel. Train L2 Loss :  0.10827818344036738  Rel. Test L2 Loss :  0.10391292989253997  Test L2 Loss :  0.1940963888168335  inv_L_scale:  [1.0, 1.0]
Epoch :  7  Time:  2.591  Rel. Train L2 Loss :  0.10304404854774475  Rel. Test L2 Loss :  0.10542201399803161  Test L2 Loss :  0.195643390417099  inv_L_scale:  [1.0, 1.0]
Epoch :  8  Time:  2.605  Rel. Train L2 Loss :  0.09341797391573588  Rel. Test L2 Loss :  0.09593119114637375  Test L2 Loss :  0.1764421993494034  inv_L_scale:  [1.0, 1.0]
Epoch :  9  Time:  2.586  Rel. Train L2 Loss :  0.08932308521535662  Rel. Test L2 Loss :  0.09106066524982452  Test L2 Loss :  0.1689901065826416  inv_L_scale:  [1.0, 1.0]
Epoch :  10  Time:  2.589  Rel. Train L2 Loss :  0.08098221573564741  Rel. Test L2 Loss :  0.09891520977020264  Test L2 Loss :  0.18522046327590944  inv_L_scale:  [1.0, 1.0]
Epoch :  11  Time:  2.569  Rel. Train L2 Loss :  0.07865009099245071  Rel. Test L2 Loss :  0.07966149002313613  Test L2 Loss :  0.14759576797485352  inv_L_scale:  [1.0, 1.0]
Epoch :  12  Time:  2.573  Rel. Train L2 Loss :  0.07350766037901242  Rel. Test L2 Loss :  0.07767379581928253  Test L2 Loss :  0.1438612675666809  inv_L_scale:  [1.0, 1.0]
Epoch :  13  Time:  2.581  Rel. Train L2 Loss :  0.07043545974625481  Rel. Test L2 Loss :  0.08426503956317902  Test L2 Loss :  0.1582016772031784  inv_L_scale:  [1.0, 1.0]
Epoch :  14  Time:  2.597  Rel. Train L2 Loss :  0.06833476550049251  Rel. Test L2 Loss :  0.07214954972267151  Test L2 Loss :  0.13285035490989686  inv_L_scale:  [1.0, 1.0]
Epoch :  15  Time:  2.586  Rel. Train L2 Loss :  0.06756295422712962  Rel. Test L2 Loss :  0.0695334443449974  Test L2 Loss :  0.12842071831226348  inv_L_scale:  [1.0, 1.0]
Epoch :  16  Time:  2.588  Rel. Train L2 Loss :  0.06493099942803383  Rel. Test L2 Loss :  0.07005408972501755  Test L2 Loss :  0.13138796031475067  inv_L_scale:  [1.0, 1.0]
Epoch :  17  Time:  2.581  Rel. Train L2 Loss :  0.06327724777989917  Rel. Test L2 Loss :  0.08110806792974472  Test L2 Loss :  0.14597095906734467  inv_L_scale:  [1.0, 1.0]
Epoch :  18  Time:  2.582  Rel. Train L2 Loss :  0.062314450525575216  Rel. Test L2 Loss :  0.07238448858261108  Test L2 Loss :  0.1347508955001831  inv_L_scale:  [1.0, 1.0]
Epoch :  19  Time:  2.578  Rel. Train L2 Loss :  0.058646231326791975  Rel. Test L2 Loss :  0.06378073558211327  Test L2 Loss :  0.11598284959793091  inv_L_scale:  [1.0, 1.0]
Epoch :  20  Time:  2.584  Rel. Train L2 Loss :  0.05749235742621952  Rel. Test L2 Loss :  0.0714211742579937  Test L2 Loss :  0.13083318531513213  inv_L_scale:  [1.0, 1.0]
Epoch :  21  Time:  2.583  Rel. Train L2 Loss :  0.059927681850062475  Rel. Test L2 Loss :  0.06473170861601829  Test L2 Loss :  0.1168187528848648  inv_L_scale:  [1.0, 1.0]
Epoch :  22  Time:  2.579  Rel. Train L2 Loss :  0.0559857944978608  Rel. Test L2 Loss :  0.06397785961627961  Test L2 Loss :  0.11669301927089691  inv_L_scale:  [1.0, 1.0]
Epoch :  23  Time:  2.586  Rel. Train L2 Loss :  0.05413507372140884  Rel. Test L2 Loss :  0.06290939807891846  Test L2 Loss :  0.11652770757675171  inv_L_scale:  [1.0, 1.0]
Epoch :  24  Time:  2.593  Rel. Train L2 Loss :  0.05188858785563045  Rel. Test L2 Loss :  0.058369638323783876  Test L2 Loss :  0.10608303248882293  inv_L_scale:  [1.0, 1.0]
Epoch :  25  Time:  2.592  Rel. Train L2 Loss :  0.05203292851646741  Rel. Test L2 Loss :  0.05556067377328873  Test L2 Loss :  0.10149765402078628  inv_L_scale:  [1.0, 1.0]
Epoch :  26  Time:  2.587  Rel. Train L2 Loss :  0.04972093997730149  Rel. Test L2 Loss :  0.05304827272891998  Test L2 Loss :  0.0962669438123703  inv_L_scale:  [1.0, 1.0]
Epoch :  27  Time:  2.565  Rel. Train L2 Loss :  0.05293388879961437  Rel. Test L2 Loss :  0.062348714619874956  Test L2 Loss :  0.11530497670173645  inv_L_scale:  [1.0, 1.0]
Epoch :  28  Time:  2.566  Rel. Train L2 Loss :  0.05387713521718979  Rel. Test L2 Loss :  0.059152445644140246  Test L2 Loss :  0.1077815705537796  inv_L_scale:  [1.0, 1.0]
Epoch :  29  Time:  2.557  Rel. Train L2 Loss :  0.04813496732049518  Rel. Test L2 Loss :  0.05308544635772705  Test L2 Loss :  0.09607636451721191  inv_L_scale:  [1.0, 1.0]
Epoch :  30  Time:  2.53  Rel. Train L2 Loss :  0.05067609500553873  Rel. Test L2 Loss :  0.06463700234889984  Test L2 Loss :  0.1174943795800209  inv_L_scale:  [1.0, 1.0]
Epoch :  31  Time:  2.595  Rel. Train L2 Loss :  0.047949024852779173  Rel. Test L2 Loss :  0.05144278571009636  Test L2 Loss :  0.09324460804462432  inv_L_scale:  [1.0, 1.0]
Epoch :  32  Time:  2.597  Rel. Train L2 Loss :  0.04493268945150905  Rel. Test L2 Loss :  0.04925788149237633  Test L2 Loss :  0.0891747960448265  inv_L_scale:  [1.0, 1.0]
Epoch :  33  Time:  2.603  Rel. Train L2 Loss :  0.04692757785320282  Rel. Test L2 Loss :  0.04934192061424256  Test L2 Loss :  0.08930102944374084  inv_L_scale:  [1.0, 1.0]
Epoch :  34  Time:  2.608  Rel. Train L2 Loss :  0.04538502617014779  Rel. Test L2 Loss :  0.05231103539466858  Test L2 Loss :  0.09402333974838256  inv_L_scale:  [1.0, 1.0]
Epoch :  35  Time:  2.601  Rel. Train L2 Loss :  0.04619877507289251  Rel. Test L2 Loss :  0.05257718488574028  Test L2 Loss :  0.09548293501138687  inv_L_scale:  [1.0, 1.0]
Epoch :  36  Time:  2.61  Rel. Train L2 Loss :  0.04633263369401296  Rel. Test L2 Loss :  0.04981722369790077  Test L2 Loss :  0.08974424451589584  inv_L_scale:  [1.0, 1.0]
Epoch :  37  Time:  2.618  Rel. Train L2 Loss :  0.044812373121579485  Rel. Test L2 Loss :  0.048167811632156374  Test L2 Loss :  0.08694992363452911  inv_L_scale:  [1.0, 1.0]
Epoch :  38  Time:  2.613  Rel. Train L2 Loss :  0.04417541932728555  Rel. Test L2 Loss :  0.046041394472122195  Test L2 Loss :  0.08351780295372009  inv_L_scale:  [1.0, 1.0]
Epoch :  39  Time:  2.608  Rel. Train L2 Loss :  0.04446273704369863  Rel. Test L2 Loss :  0.04615863531827927  Test L2 Loss :  0.08345957070589066  inv_L_scale:  [1.0, 1.0]
Epoch :  40  Time:  2.605  Rel. Train L2 Loss :  0.04233816749519772  Rel. Test L2 Loss :  0.046044999659061434  Test L2 Loss :  0.08305057436227799  inv_L_scale:  [1.0, 1.0]
Epoch :  41  Time:  2.565  Rel. Train L2 Loss :  0.04186812867720922  Rel. Test L2 Loss :  0.04552676230669021  Test L2 Loss :  0.08293542206287384  inv_L_scale:  [1.0, 1.0]
Epoch :  42  Time:  2.598  Rel. Train L2 Loss :  0.042563395831320024  Rel. Test L2 Loss :  0.051764295399188996  Test L2 Loss :  0.0957533660531044  inv_L_scale:  [1.0, 1.0]
Epoch :  43  Time:  2.588  Rel. Train L2 Loss :  0.042668113029665417  Rel. Test L2 Loss :  0.04278314024209976  Test L2 Loss :  0.07739102482795715  inv_L_scale:  [1.0, 1.0]
Epoch :  44  Time:  2.596  Rel. Train L2 Loss :  0.04206059801909658  Rel. Test L2 Loss :  0.046423175185918805  Test L2 Loss :  0.08378098636865616  inv_L_scale:  [1.0, 1.0]
Epoch :  45  Time:  2.595  Rel. Train L2 Loss :  0.04266066961818271  Rel. Test L2 Loss :  0.04770134136080742  Test L2 Loss :  0.08665710180997849  inv_L_scale:  [1.0, 1.0]
Epoch :  46  Time:  2.597  Rel. Train L2 Loss :  0.042440579997168645  Rel. Test L2 Loss :  0.0481427638232708  Test L2 Loss :  0.08900073409080506  inv_L_scale:  [1.0, 1.0]
Epoch :  47  Time:  2.599  Rel. Train L2 Loss :  0.04199939464529356  Rel. Test L2 Loss :  0.04148172587156296  Test L2 Loss :  0.07642133235931396  inv_L_scale:  [1.0, 1.0]
Epoch :  48  Time:  2.605  Rel. Train L2 Loss :  0.04287806262572606  Rel. Test L2 Loss :  0.04283800780773163  Test L2 Loss :  0.07751333087682724  inv_L_scale:  [1.0, 1.0]
Epoch :  49  Time:  2.594  Rel. Train L2 Loss :  0.040931877262062495  Rel. Test L2 Loss :  0.0403111320734024  Test L2 Loss :  0.07295545697212219  inv_L_scale:  [1.0, 1.0]
Epoch :  50  Time:  2.574  Rel. Train L2 Loss :  0.040058216204245885  Rel. Test L2 Loss :  0.049114200174808505  Test L2 Loss :  0.0913807624578476  inv_L_scale:  [1.0, 1.0]
Epoch :  51  Time:  2.585  Rel. Train L2 Loss :  0.03859008472826746  Rel. Test L2 Loss :  0.04384522378444672  Test L2 Loss :  0.07882247388362884  inv_L_scale:  [1.0, 1.0]
Epoch :  52  Time:  2.585  Rel. Train L2 Loss :  0.04015391346481111  Rel. Test L2 Loss :  0.0448419851064682  Test L2 Loss :  0.08134078532457352  inv_L_scale:  [1.0, 1.0]
Epoch :  53  Time:  2.603  Rel. Train L2 Loss :  0.03968587790926297  Rel. Test L2 Loss :  0.04274164453148842  Test L2 Loss :  0.07717143654823304  inv_L_scale:  [1.0, 1.0]
Epoch :  54  Time:  2.594  Rel. Train L2 Loss :  0.03908508524298668  Rel. Test L2 Loss :  0.041031737625598905  Test L2 Loss :  0.07546396374702453  inv_L_scale:  [1.0, 1.0]
Epoch :  55  Time:  2.598  Rel. Train L2 Loss :  0.035117698841624786  Rel. Test L2 Loss :  0.04036200672388077  Test L2 Loss :  0.0734757199883461  inv_L_scale:  [1.0, 1.0]
Epoch :  56  Time:  2.596  Rel. Train L2 Loss :  0.03536545839574602  Rel. Test L2 Loss :  0.03893997088074684  Test L2 Loss :  0.07074947148561478  inv_L_scale:  [1.0, 1.0]
Epoch :  57  Time:  2.608  Rel. Train L2 Loss :  0.037681246134969926  Rel. Test L2 Loss :  0.04216318592429161  Test L2 Loss :  0.07574586391448974  inv_L_scale:  [1.0, 1.0]
Epoch :  58  Time:  2.593  Rel. Train L2 Loss :  0.03617581845985519  Rel. Test L2 Loss :  0.040393915325403214  Test L2 Loss :  0.07263663351535797  inv_L_scale:  [1.0, 1.0]
Epoch :  59  Time:  2.579  Rel. Train L2 Loss :  0.03761593974298901  Rel. Test L2 Loss :  0.03846176236867905  Test L2 Loss :  0.06928484693169594  inv_L_scale:  [1.0, 1.0]
Epoch :  60  Time:  2.586  Rel. Train L2 Loss :  0.03535628688004282  Rel. Test L2 Loss :  0.039919352531433104  Test L2 Loss :  0.07226395517587662  inv_L_scale:  [1.0, 1.0]
Epoch :  61  Time:  2.591  Rel. Train L2 Loss :  0.03595247450802061  Rel. Test L2 Loss :  0.03588313601911068  Test L2 Loss :  0.06528101772069932  inv_L_scale:  [1.0, 1.0]
Epoch :  62  Time:  2.594  Rel. Train L2 Loss :  0.033667821221881444  Rel. Test L2 Loss :  0.03517413854598999  Test L2 Loss :  0.06516814887523652  inv_L_scale:  [1.0, 1.0]
Epoch :  63  Time:  2.589  Rel. Train L2 Loss :  0.03464000244935354  Rel. Test L2 Loss :  0.04684959232807159  Test L2 Loss :  0.08422991693019867  inv_L_scale:  [1.0, 1.0]
Epoch :  64  Time:  2.589  Rel. Train L2 Loss :  0.036152962976031836  Rel. Test L2 Loss :  0.04264159888029098  Test L2 Loss :  0.07905995100736618  inv_L_scale:  [1.0, 1.0]
Epoch :  65  Time:  2.594  Rel. Train L2 Loss :  0.03603987781537904  Rel. Test L2 Loss :  0.03675132095813751  Test L2 Loss :  0.06632416725158691  inv_L_scale:  [1.0, 1.0]
Epoch :  66  Time:  2.584  Rel. Train L2 Loss :  0.032658544447686934  Rel. Test L2 Loss :  0.033909225985407826  Test L2 Loss :  0.06173052817583084  inv_L_scale:  [1.0, 1.0]
Epoch :  67  Time:  2.578  Rel. Train L2 Loss :  0.03244931686255667  Rel. Test L2 Loss :  0.036245064437389375  Test L2 Loss :  0.06542815715074539  inv_L_scale:  [1.0, 1.0]
Epoch :  68  Time:  2.575  Rel. Train L2 Loss :  0.03248507604002952  Rel. Test L2 Loss :  0.03864465296268463  Test L2 Loss :  0.06954314768314361  inv_L_scale:  [1.0, 1.0]
Epoch :  69  Time:  2.587  Rel. Train L2 Loss :  0.03357008738650216  Rel. Test L2 Loss :  0.03600877076387406  Test L2 Loss :  0.06543921366333962  inv_L_scale:  [1.0, 1.0]
Epoch :  70  Time:  2.583  Rel. Train L2 Loss :  0.03423537240260177  Rel. Test L2 Loss :  0.03531519189476967  Test L2 Loss :  0.06397555679082871  inv_L_scale:  [1.0, 1.0]
Epoch :  71  Time:  2.579  Rel. Train L2 Loss :  0.03213633043070634  Rel. Test L2 Loss :  0.03879295706748962  Test L2 Loss :  0.06990874826908111  inv_L_scale:  [1.0, 1.0]
Epoch :  72  Time:  2.592  Rel. Train L2 Loss :  0.03303967825240559  Rel. Test L2 Loss :  0.037987469136714934  Test L2 Loss :  0.06759963780641556  inv_L_scale:  [1.0, 1.0]
Epoch :  73  Time:  2.588  Rel. Train L2 Loss :  0.033397263007031545  Rel. Test L2 Loss :  0.03611131563782692  Test L2 Loss :  0.06680333256721496  inv_L_scale:  [1.0, 1.0]
Epoch :  74  Time:  2.567  Rel. Train L2 Loss :  0.030752878934144974  Rel. Test L2 Loss :  0.036493574678897855  Test L2 Loss :  0.06517894595861434  inv_L_scale:  [1.0, 1.0]
Epoch :  75  Time:  2.579  Rel. Train L2 Loss :  0.03234175342652533  Rel. Test L2 Loss :  0.035639994740486146  Test L2 Loss :  0.06396391585469247  inv_L_scale:  [1.0, 1.0]
Epoch :  76  Time:  2.588  Rel. Train L2 Loss :  0.032014822214841844  Rel. Test L2 Loss :  0.03492412030696869  Test L2 Loss :  0.06296993851661682  inv_L_scale:  [1.0, 1.0]
Epoch :  77  Time:  2.583  Rel. Train L2 Loss :  0.030403126610649957  Rel. Test L2 Loss :  0.03300653845071792  Test L2 Loss :  0.06038082480430603  inv_L_scale:  [1.0, 1.0]
Epoch :  78  Time:  2.587  Rel. Train L2 Loss :  0.029804512725936042  Rel. Test L2 Loss :  0.030267251506447792  Test L2 Loss :  0.05497068151831627  inv_L_scale:  [1.0, 1.0]
Epoch :  79  Time:  2.582  Rel. Train L2 Loss :  0.02975373511513074  Rel. Test L2 Loss :  0.03487875483930111  Test L2 Loss :  0.06297271683812142  inv_L_scale:  [1.0, 1.0]
Epoch :  80  Time:  2.573  Rel. Train L2 Loss :  0.02926038321521547  Rel. Test L2 Loss :  0.03239307336509228  Test L2 Loss :  0.05941113606095314  inv_L_scale:  [1.0, 1.0]
Epoch :  81  Time:  2.58  Rel. Train L2 Loss :  0.029357502543263966  Rel. Test L2 Loss :  0.03397749647498131  Test L2 Loss :  0.06150265991687775  inv_L_scale:  [1.0, 1.0]
Epoch :  82  Time:  2.597  Rel. Train L2 Loss :  0.029689423789580664  Rel. Test L2 Loss :  0.03220428347587585  Test L2 Loss :  0.05880009204149246  inv_L_scale:  [1.0, 1.0]
Epoch :  83  Time:  2.586  Rel. Train L2 Loss :  0.028085272527403303  Rel. Test L2 Loss :  0.03521504819393158  Test L2 Loss :  0.06334545060992242  inv_L_scale:  [1.0, 1.0]
Epoch :  84  Time:  2.589  Rel. Train L2 Loss :  0.028129231681426368  Rel. Test L2 Loss :  0.03513576798141003  Test L2 Loss :  0.06389137238264084  inv_L_scale:  [1.0, 1.0]
Epoch :  85  Time:  2.591  Rel. Train L2 Loss :  0.02955712935162915  Rel. Test L2 Loss :  0.026353337168693543  Test L2 Loss :  0.04812634110450745  inv_L_scale:  [1.0, 1.0]
Epoch :  86  Time:  2.582  Rel. Train L2 Loss :  0.02840546061595281  Rel. Test L2 Loss :  0.033674736618995664  Test L2 Loss :  0.06068299889564514  inv_L_scale:  [1.0, 1.0]
Epoch :  87  Time:  2.583  Rel. Train L2 Loss :  0.027937572598457337  Rel. Test L2 Loss :  0.02938946321606636  Test L2 Loss :  0.0533831587433815  inv_L_scale:  [1.0, 1.0]
Epoch :  88  Time:  2.592  Rel. Train L2 Loss :  0.026537786225477856  Rel. Test L2 Loss :  0.029337586611509325  Test L2 Loss :  0.05222932904958725  inv_L_scale:  [1.0, 1.0]
Epoch :  89  Time:  2.586  Rel. Train L2 Loss :  0.027562715096606148  Rel. Test L2 Loss :  0.027527937740087507  Test L2 Loss :  0.05040094628930092  inv_L_scale:  [1.0, 1.0]
Epoch :  90  Time:  2.563  Rel. Train L2 Loss :  0.02868397303753429  Rel. Test L2 Loss :  0.03333001360297203  Test L2 Loss :  0.0604670000076294  inv_L_scale:  [1.0, 1.0]
Epoch :  91  Time:  2.571  Rel. Train L2 Loss :  0.027150543282429378  Rel. Test L2 Loss :  0.0280310295522213  Test L2 Loss :  0.05087620824575424  inv_L_scale:  [1.0, 1.0]
Epoch :  92  Time:  2.57  Rel. Train L2 Loss :  0.027164026606414052  Rel. Test L2 Loss :  0.027495154589414598  Test L2 Loss :  0.04970221444964409  inv_L_scale:  [1.0, 1.0]
Epoch :  93  Time:  2.576  Rel. Train L2 Loss :  0.02688185448447863  Rel. Test L2 Loss :  0.028102095574140548  Test L2 Loss :  0.05152297914028168  inv_L_scale:  [1.0, 1.0]
Epoch :  94  Time:  2.586  Rel. Train L2 Loss :  0.02596357567442788  Rel. Test L2 Loss :  0.02813649408519268  Test L2 Loss :  0.05080596283078194  inv_L_scale:  [1.0, 1.0]
Epoch :  95  Time:  2.585  Rel. Train L2 Loss :  0.025276120867994096  Rel. Test L2 Loss :  0.028341205418109895  Test L2 Loss :  0.05184016600251198  inv_L_scale:  [1.0, 1.0]
Epoch :  96  Time:  2.586  Rel. Train L2 Loss :  0.024180778347783618  Rel. Test L2 Loss :  0.029978446513414383  Test L2 Loss :  0.05396498441696167  inv_L_scale:  [1.0, 1.0]
Epoch :  97  Time:  2.574  Rel. Train L2 Loss :  0.026003554463386536  Rel. Test L2 Loss :  0.033386782258749005  Test L2 Loss :  0.060933684706687925  inv_L_scale:  [1.0, 1.0]
Epoch :  98  Time:  2.571  Rel. Train L2 Loss :  0.02496764212846756  Rel. Test L2 Loss :  0.029306341409683228  Test L2 Loss :  0.053291754871606825  inv_L_scale:  [1.0, 1.0]
Epoch :  99  Time:  2.584  Rel. Train L2 Loss :  0.025072716606987847  Rel. Test L2 Loss :  0.03160576499998569  Test L2 Loss :  0.05779461830854416  inv_L_scale:  [1.0, 1.0]
Epoch :  100  Time:  2.588  Rel. Train L2 Loss :  0.026496943831443787  Rel. Test L2 Loss :  0.029063905626535415  Test L2 Loss :  0.0525332710146904  inv_L_scale:  [1.0, 1.0]
Epoch :  101  Time:  2.578  Rel. Train L2 Loss :  0.024678915449314647  Rel. Test L2 Loss :  0.026821397766470908  Test L2 Loss :  0.048663032352924344  inv_L_scale:  [1.0, 1.0]
Epoch :  102  Time:  2.577  Rel. Train L2 Loss :  0.024084410236941443  Rel. Test L2 Loss :  0.02744208723306656  Test L2 Loss :  0.05021738424897194  inv_L_scale:  [1.0, 1.0]
Epoch :  103  Time:  2.583  Rel. Train L2 Loss :  0.02418289817869663  Rel. Test L2 Loss :  0.024990706890821456  Test L2 Loss :  0.04545451045036316  inv_L_scale:  [1.0, 1.0]
Epoch :  104  Time:  2.579  Rel. Train L2 Loss :  0.023563983895712428  Rel. Test L2 Loss :  0.026733534559607506  Test L2 Loss :  0.0484162974357605  inv_L_scale:  [1.0, 1.0]
Epoch :  105  Time:  2.585  Rel. Train L2 Loss :  0.023226168586148156  Rel. Test L2 Loss :  0.02725752368569374  Test L2 Loss :  0.05061306595802307  inv_L_scale:  [1.0, 1.0]
Epoch :  106  Time:  2.586  Rel. Train L2 Loss :  0.023304251945681042  Rel. Test L2 Loss :  0.02651761256158352  Test L2 Loss :  0.04744240283966064  inv_L_scale:  [1.0, 1.0]
Epoch :  107  Time:  2.582  Rel. Train L2 Loss :  0.02261235799226496  Rel. Test L2 Loss :  0.028484960645437242  Test L2 Loss :  0.05071827054023743  inv_L_scale:  [1.0, 1.0]
Epoch :  108  Time:  2.582  Rel. Train L2 Loss :  0.023152458286947675  Rel. Test L2 Loss :  0.028043141067028047  Test L2 Loss :  0.051038242727518085  inv_L_scale:  [1.0, 1.0]
Epoch :  109  Time:  2.584  Rel. Train L2 Loss :  0.022775112556086646  Rel. Test L2 Loss :  0.025156789273023606  Test L2 Loss :  0.04525065466761589  inv_L_scale:  [1.0, 1.0]
Epoch :  110  Time:  2.59  Rel. Train L2 Loss :  0.02380820683307118  Rel. Test L2 Loss :  0.025830321460962296  Test L2 Loss :  0.04681519016623497  inv_L_scale:  [1.0, 1.0]
Epoch :  111  Time:  2.592  Rel. Train L2 Loss :  0.021408339821630054  Rel. Test L2 Loss :  0.026825380101799964  Test L2 Loss :  0.048221849501132966  inv_L_scale:  [1.0, 1.0]
Epoch :  112  Time:  2.589  Rel. Train L2 Loss :  0.02346308568285571  Rel. Test L2 Loss :  0.02636541560292244  Test L2 Loss :  0.04746473595499992  inv_L_scale:  [1.0, 1.0]
Epoch :  113  Time:  2.582  Rel. Train L2 Loss :  0.02226200916700893  Rel. Test L2 Loss :  0.02604031629860401  Test L2 Loss :  0.047496632635593415  inv_L_scale:  [1.0, 1.0]
Epoch :  114  Time:  2.578  Rel. Train L2 Loss :  0.02185849459634887  Rel. Test L2 Loss :  0.022762583792209624  Test L2 Loss :  0.04166717872023582  inv_L_scale:  [1.0, 1.0]
Epoch :  115  Time:  2.594  Rel. Train L2 Loss :  0.02197473469707701  Rel. Test L2 Loss :  0.023724740520119667  Test L2 Loss :  0.04310548812150955  inv_L_scale:  [1.0, 1.0]
Epoch :  116  Time:  2.596  Rel. Train L2 Loss :  0.021379409200615353  Rel. Test L2 Loss :  0.02768647901713848  Test L2 Loss :  0.05071738615632057  inv_L_scale:  [1.0, 1.0]
Epoch :  117  Time:  2.587  Rel. Train L2 Loss :  0.020964732749594584  Rel. Test L2 Loss :  0.025802141800522805  Test L2 Loss :  0.04719767421483993  inv_L_scale:  [1.0, 1.0]
Epoch :  118  Time:  2.582  Rel. Train L2 Loss :  0.023457132594452965  Rel. Test L2 Loss :  0.02317797675728798  Test L2 Loss :  0.041816858053207395  inv_L_scale:  [1.0, 1.0]
Epoch :  119  Time:  2.577  Rel. Train L2 Loss :  0.022033581071429782  Rel. Test L2 Loss :  0.0300120709836483  Test L2 Loss :  0.05430553361773491  inv_L_scale:  [1.0, 1.0]
Epoch :  120  Time:  2.584  Rel. Train L2 Loss :  0.02274036521712939  Rel. Test L2 Loss :  0.02512187846004963  Test L2 Loss :  0.046034565418958666  inv_L_scale:  [1.0, 1.0]
Epoch :  121  Time:  2.594  Rel. Train L2 Loss :  0.022437406703829765  Rel. Test L2 Loss :  0.02607442989945412  Test L2 Loss :  0.0490519343316555  inv_L_scale:  [1.0, 1.0]
Epoch :  122  Time:  2.589  Rel. Train L2 Loss :  0.02016070001655155  Rel. Test L2 Loss :  0.027166033685207366  Test L2 Loss :  0.050913243889808654  inv_L_scale:  [1.0, 1.0]
Epoch :  123  Time:  2.584  Rel. Train L2 Loss :  0.02032804804129733  Rel. Test L2 Loss :  0.019446200355887414  Test L2 Loss :  0.035275108069181445  inv_L_scale:  [1.0, 1.0]
Epoch :  124  Time:  2.593  Rel. Train L2 Loss :  0.019113224637177257  Rel. Test L2 Loss :  0.022341969907283783  Test L2 Loss :  0.040465215742588045  inv_L_scale:  [1.0, 1.0]
Epoch :  125  Time:  2.581  Rel. Train L2 Loss :  0.020415741610858174  Rel. Test L2 Loss :  0.022478576004505157  Test L2 Loss :  0.04122054859995842  inv_L_scale:  [1.0, 1.0]
Epoch :  126  Time:  2.579  Rel. Train L2 Loss :  0.019456792920827866  Rel. Test L2 Loss :  0.021225676983594895  Test L2 Loss :  0.039220689833164214  inv_L_scale:  [1.0, 1.0]
Epoch :  127  Time:  2.589  Rel. Train L2 Loss :  0.019665422257449893  Rel. Test L2 Loss :  0.020563080534338952  Test L2 Loss :  0.03742404699325561  inv_L_scale:  [1.0, 1.0]
Epoch :  128  Time:  2.576  Rel. Train L2 Loss :  0.019774230842789012  Rel. Test L2 Loss :  0.02140791967511177  Test L2 Loss :  0.038304538577795026  inv_L_scale:  [1.0, 1.0]
Epoch :  129  Time:  2.581  Rel. Train L2 Loss :  0.01902298454609182  Rel. Test L2 Loss :  0.021024227812886237  Test L2 Loss :  0.03794875100255012  inv_L_scale:  [1.0, 1.0]
Epoch :  130  Time:  2.594  Rel. Train L2 Loss :  0.01929369721147749  Rel. Test L2 Loss :  0.021571298614144325  Test L2 Loss :  0.03957412391901016  inv_L_scale:  [1.0, 1.0]
Epoch :  131  Time:  2.588  Rel. Train L2 Loss :  0.019153446786933474  Rel. Test L2 Loss :  0.02232215240597725  Test L2 Loss :  0.04070056185126305  inv_L_scale:  [1.0, 1.0]
Epoch :  132  Time:  2.58  Rel. Train L2 Loss :  0.019980803098943498  Rel. Test L2 Loss :  0.022484171092510222  Test L2 Loss :  0.04064746603369713  inv_L_scale:  [1.0, 1.0]
Epoch :  133  Time:  2.58  Rel. Train L2 Loss :  0.01885590380264653  Rel. Test L2 Loss :  0.02182508647441864  Test L2 Loss :  0.03933717638254166  inv_L_scale:  [1.0, 1.0]
Epoch :  134  Time:  2.585  Rel. Train L2 Loss :  0.01887658500009113  Rel. Test L2 Loss :  0.02112986072897911  Test L2 Loss :  0.03830611556768417  inv_L_scale:  [1.0, 1.0]
Epoch :  135  Time:  2.595  Rel. Train L2 Loss :  0.019256273118986023  Rel. Test L2 Loss :  0.02220246762037277  Test L2 Loss :  0.04059486925601959  inv_L_scale:  [1.0, 1.0]
Epoch :  136  Time:  2.584  Rel. Train L2 Loss :  0.01851062516371409  Rel. Test L2 Loss :  0.019349722266197203  Test L2 Loss :  0.03521896332502365  inv_L_scale:  [1.0, 1.0]
Epoch :  137  Time:  2.571  Rel. Train L2 Loss :  0.01827172809176975  Rel. Test L2 Loss :  0.020711436569690704  Test L2 Loss :  0.03771056249737739  inv_L_scale:  [1.0, 1.0]
Epoch :  138  Time:  2.59  Rel. Train L2 Loss :  0.01918918791744444  Rel. Test L2 Loss :  0.022052887678146362  Test L2 Loss :  0.04002399370074272  inv_L_scale:  [1.0, 1.0]
Epoch :  139  Time:  2.588  Rel. Train L2 Loss :  0.01877809688448906  Rel. Test L2 Loss :  0.022843411862850188  Test L2 Loss :  0.041428108364343644  inv_L_scale:  [1.0, 1.0]
Epoch :  140  Time:  2.589  Rel. Train L2 Loss :  0.018430373602443272  Rel. Test L2 Loss :  0.023770536333322524  Test L2 Loss :  0.042631387412548065  inv_L_scale:  [1.0, 1.0]
Epoch :  141  Time:  2.594  Rel. Train L2 Loss :  0.01799552769296699  Rel. Test L2 Loss :  0.019065128788352013  Test L2 Loss :  0.0345650877058506  inv_L_scale:  [1.0, 1.0]
Epoch :  142  Time:  2.587  Rel. Train L2 Loss :  0.0179542700946331  Rel. Test L2 Loss :  0.021211052387952803  Test L2 Loss :  0.0388925564289093  inv_L_scale:  [1.0, 1.0]
Epoch :  143  Time:  2.59  Rel. Train L2 Loss :  0.018388007486032115  Rel. Test L2 Loss :  0.022810315266251564  Test L2 Loss :  0.04116789013147354  inv_L_scale:  [1.0, 1.0]
Epoch :  144  Time:  2.59  Rel. Train L2 Loss :  0.01795518154071437  Rel. Test L2 Loss :  0.02033903233706951  Test L2 Loss :  0.036729469895362854  inv_L_scale:  [1.0, 1.0]
Epoch :  145  Time:  2.587  Rel. Train L2 Loss :  0.0177727018089758  Rel. Test L2 Loss :  0.0202849218249321  Test L2 Loss :  0.03720837578177452  inv_L_scale:  [1.0, 1.0]
Epoch :  146  Time:  2.55  Rel. Train L2 Loss :  0.01733086361653275  Rel. Test L2 Loss :  0.020018719732761384  Test L2 Loss :  0.036665847599506377  inv_L_scale:  [1.0, 1.0]
Epoch :  147  Time:  2.535  Rel. Train L2 Loss :  0.017590235124031704  Rel. Test L2 Loss :  0.02225785732269287  Test L2 Loss :  0.03993178382515907  inv_L_scale:  [1.0, 1.0]
Epoch :  148  Time:  2.569  Rel. Train L2 Loss :  0.018427467023332915  Rel. Test L2 Loss :  0.018308521285653113  Test L2 Loss :  0.033266617804765704  inv_L_scale:  [1.0, 1.0]
Epoch :  149  Time:  2.586  Rel. Train L2 Loss :  0.018185306212140453  Rel. Test L2 Loss :  0.019882556796073914  Test L2 Loss :  0.036711439043283466  inv_L_scale:  [1.0, 1.0]
Epoch :  150  Time:  2.596  Rel. Train L2 Loss :  0.017055988336602847  Rel. Test L2 Loss :  0.018358279094099997  Test L2 Loss :  0.033490376472473146  inv_L_scale:  [1.0, 1.0]
Epoch :  151  Time:  2.598  Rel. Train L2 Loss :  0.016920249172382884  Rel. Test L2 Loss :  0.021308792829513548  Test L2 Loss :  0.03902616113424301  inv_L_scale:  [1.0, 1.0]
Epoch :  152  Time:  2.594  Rel. Train L2 Loss :  0.01825763785176807  Rel. Test L2 Loss :  0.024019199311733245  Test L2 Loss :  0.04383495569229126  inv_L_scale:  [1.0, 1.0]
Epoch :  153  Time:  2.596  Rel. Train L2 Loss :  0.018545693432291347  Rel. Test L2 Loss :  0.021392234414815903  Test L2 Loss :  0.03855212360620499  inv_L_scale:  [1.0, 1.0]
Epoch :  154  Time:  2.601  Rel. Train L2 Loss :  0.017595117580559518  Rel. Test L2 Loss :  0.02257588803768158  Test L2 Loss :  0.0408871790766716  inv_L_scale:  [1.0, 1.0]
Epoch :  155  Time:  2.595  Rel. Train L2 Loss :  0.016798038143250676  Rel. Test L2 Loss :  0.019448673203587532  Test L2 Loss :  0.03500266075134277  inv_L_scale:  [1.0, 1.0]
Epoch :  156  Time:  2.587  Rel. Train L2 Loss :  0.017515136069721646  Rel. Test L2 Loss :  0.021012910157442093  Test L2 Loss :  0.0386896239221096  inv_L_scale:  [1.0, 1.0]
Epoch :  157  Time:  2.565  Rel. Train L2 Loss :  0.016366571121745638  Rel. Test L2 Loss :  0.01826621387153864  Test L2 Loss :  0.03333747804164886  inv_L_scale:  [1.0, 1.0]
Epoch :  158  Time:  2.595  Rel. Train L2 Loss :  0.01735567546553082  Rel. Test L2 Loss :  0.02147117257118225  Test L2 Loss :  0.03902068018913269  inv_L_scale:  [1.0, 1.0]
Epoch :  159  Time:  2.589  Rel. Train L2 Loss :  0.017042770832777023  Rel. Test L2 Loss :  0.020291637703776358  Test L2 Loss :  0.037695406079292296  inv_L_scale:  [1.0, 1.0]
Epoch :  160  Time:  2.596  Rel. Train L2 Loss :  0.01617451103197204  Rel. Test L2 Loss :  0.026451566889882087  Test L2 Loss :  0.04790837347507477  inv_L_scale:  [1.0, 1.0]
Epoch :  161  Time:  2.597  Rel. Train L2 Loss :  0.016678854847947757  Rel. Test L2 Loss :  0.01939813181757927  Test L2 Loss :  0.035424089282751085  inv_L_scale:  [1.0, 1.0]
Epoch :  162  Time:  2.599  Rel. Train L2 Loss :  0.01633265948130025  Rel. Test L2 Loss :  0.017883661910891534  Test L2 Loss :  0.032531936466693875  inv_L_scale:  [1.0, 1.0]
Epoch :  163  Time:  2.598  Rel. Train L2 Loss :  0.015985156090723145  Rel. Test L2 Loss :  0.020604662075638772  Test L2 Loss :  0.03782247722148895  inv_L_scale:  [1.0, 1.0]
Epoch :  164  Time:  2.603  Rel. Train L2 Loss :  0.016864473447203637  Rel. Test L2 Loss :  0.018454006761312484  Test L2 Loss :  0.033689229786396026  inv_L_scale:  [1.0, 1.0]
Epoch :  165  Time:  2.586  Rel. Train L2 Loss :  0.017327258520656162  Rel. Test L2 Loss :  0.018607656359672545  Test L2 Loss :  0.03371227100491524  inv_L_scale:  [1.0, 1.0]
Epoch :  166  Time:  2.557  Rel. Train L2 Loss :  0.016974919587373734  Rel. Test L2 Loss :  0.01753208301961422  Test L2 Loss :  0.03158251568675041  inv_L_scale:  [1.0, 1.0]
Epoch :  167  Time:  2.585  Rel. Train L2 Loss :  0.016142375328474574  Rel. Test L2 Loss :  0.018379618525505067  Test L2 Loss :  0.03389929011464119  inv_L_scale:  [1.0, 1.0]
Epoch :  168  Time:  2.578  Rel. Train L2 Loss :  0.016619844088951747  Rel. Test L2 Loss :  0.017986266650259496  Test L2 Loss :  0.032570291757583615  inv_L_scale:  [1.0, 1.0]
Epoch :  169  Time:  2.588  Rel. Train L2 Loss :  0.01642639478047689  Rel. Test L2 Loss :  0.01721785742789507  Test L2 Loss :  0.03175380259752274  inv_L_scale:  [1.0, 1.0]
Epoch :  170  Time:  2.588  Rel. Train L2 Loss :  0.01686182657463683  Rel. Test L2 Loss :  0.018355908095836638  Test L2 Loss :  0.03295053005218506  inv_L_scale:  [1.0, 1.0]
Epoch :  171  Time:  2.59  Rel. Train L2 Loss :  0.016768763036363654  Rel. Test L2 Loss :  0.018754678778350353  Test L2 Loss :  0.03404539734125137  inv_L_scale:  [1.0, 1.0]
Epoch :  172  Time:  2.592  Rel. Train L2 Loss :  0.016121909924679333  Rel. Test L2 Loss :  0.019684933722019196  Test L2 Loss :  0.03571211948990822  inv_L_scale:  [1.0, 1.0]
Epoch :  173  Time:  2.596  Rel. Train L2 Loss :  0.016320786459578407  Rel. Test L2 Loss :  0.01995833180844784  Test L2 Loss :  0.037142811119556425  inv_L_scale:  [1.0, 1.0]
Epoch :  174  Time:  2.587  Rel. Train L2 Loss :  0.01639989800751209  Rel. Test L2 Loss :  0.018053132370114328  Test L2 Loss :  0.03362509950995445  inv_L_scale:  [1.0, 1.0]
Epoch :  175  Time:  2.559  Rel. Train L2 Loss :  0.016315041705965996  Rel. Test L2 Loss :  0.016790343299508095  Test L2 Loss :  0.03039989896118641  inv_L_scale:  [1.0, 1.0]
Epoch :  176  Time:  2.593  Rel. Train L2 Loss :  0.01509373314678669  Rel. Test L2 Loss :  0.019463623985648156  Test L2 Loss :  0.03661331489682198  inv_L_scale:  [1.0, 1.0]
Epoch :  177  Time:  2.565  Rel. Train L2 Loss :  0.01523662355211046  Rel. Test L2 Loss :  0.018008197844028472  Test L2 Loss :  0.03277402445673942  inv_L_scale:  [1.0, 1.0]
Epoch :  178  Time:  2.569  Rel. Train L2 Loss :  0.015314623283015357  Rel. Test L2 Loss :  0.018014510422945024  Test L2 Loss :  0.03251656547188759  inv_L_scale:  [1.0, 1.0]
Epoch :  179  Time:  2.576  Rel. Train L2 Loss :  0.01505489959485001  Rel. Test L2 Loss :  0.01748982086777687  Test L2 Loss :  0.03191055953502655  inv_L_scale:  [1.0, 1.0]
Epoch :  180  Time:  2.583  Rel. Train L2 Loss :  0.015930368879603016  Rel. Test L2 Loss :  0.02150654137134552  Test L2 Loss :  0.03954406589269638  inv_L_scale:  [1.0, 1.0]
Epoch :  181  Time:  2.585  Rel. Train L2 Loss :  0.0151539962242047  Rel. Test L2 Loss :  0.01744900655001402  Test L2 Loss :  0.032167649269104  inv_L_scale:  [1.0, 1.0]
Epoch :  182  Time:  2.569  Rel. Train L2 Loss :  0.016204134246541393  Rel. Test L2 Loss :  0.018627694994211196  Test L2 Loss :  0.033645305633544925  inv_L_scale:  [1.0, 1.0]
Epoch :  183  Time:  2.571  Rel. Train L2 Loss :  0.015326689589354727  Rel. Test L2 Loss :  0.017527431920170783  Test L2 Loss :  0.03183502972126007  inv_L_scale:  [1.0, 1.0]
Epoch :  184  Time:  2.581  Rel. Train L2 Loss :  0.014774644068545765  Rel. Test L2 Loss :  0.01778727985918522  Test L2 Loss :  0.032157096266746524  inv_L_scale:  [1.0, 1.0]
Epoch :  185  Time:  2.58  Rel. Train L2 Loss :  0.015583631288674142  Rel. Test L2 Loss :  0.01784667506814003  Test L2 Loss :  0.0321686215698719  inv_L_scale:  [1.0, 1.0]
Epoch :  186  Time:  2.591  Rel. Train L2 Loss :  0.015624471058448155  Rel. Test L2 Loss :  0.016963460966944694  Test L2 Loss :  0.030890055298805237  inv_L_scale:  [1.0, 1.0]
Epoch :  187  Time:  2.582  Rel. Train L2 Loss :  0.014563123567236795  Rel. Test L2 Loss :  0.016483475640416145  Test L2 Loss :  0.03000025898218155  inv_L_scale:  [1.0, 1.0]
Epoch :  188  Time:  2.58  Rel. Train L2 Loss :  0.014829919329947896  Rel. Test L2 Loss :  0.016910995170474053  Test L2 Loss :  0.030528004318475722  inv_L_scale:  [1.0, 1.0]
Epoch :  189  Time:  2.568  Rel. Train L2 Loss :  0.014375129756000306  Rel. Test L2 Loss :  0.016384654119610785  Test L2 Loss :  0.029692936092615127  inv_L_scale:  [1.0, 1.0]
Epoch :  190  Time:  2.574  Rel. Train L2 Loss :  0.014122466035187244  Rel. Test L2 Loss :  0.01521476324647665  Test L2 Loss :  0.027622341960668564  inv_L_scale:  [1.0, 1.0]
Epoch :  191  Time:  2.584  Rel. Train L2 Loss :  0.014102669366531902  Rel. Test L2 Loss :  0.015888402946293356  Test L2 Loss :  0.02898093268275261  inv_L_scale:  [1.0, 1.0]
Epoch :  192  Time:  2.587  Rel. Train L2 Loss :  0.01393061138689518  Rel. Test L2 Loss :  0.015139430090785026  Test L2 Loss :  0.027551860213279725  inv_L_scale:  [1.0, 1.0]
Epoch :  193  Time:  2.584  Rel. Train L2 Loss :  0.014041668872038523  Rel. Test L2 Loss :  0.019942785874009133  Test L2 Loss :  0.03713017821311951  inv_L_scale:  [1.0, 1.0]
Epoch :  194  Time:  2.577  Rel. Train L2 Loss :  0.015177691529194515  Rel. Test L2 Loss :  0.017155188098549844  Test L2 Loss :  0.031615661829710005  inv_L_scale:  [1.0, 1.0]
Epoch :  195  Time:  2.57  Rel. Train L2 Loss :  0.014695214335289267  Rel. Test L2 Loss :  0.014920358099043369  Test L2 Loss :  0.027293179631233216  inv_L_scale:  [1.0, 1.0]
Epoch :  196  Time:  2.579  Rel. Train L2 Loss :  0.0134724104238881  Rel. Test L2 Loss :  0.017665562257170676  Test L2 Loss :  0.03233229801058769  inv_L_scale:  [1.0, 1.0]
Epoch :  197  Time:  2.581  Rel. Train L2 Loss :  0.0138468294011222  Rel. Test L2 Loss :  0.015607838109135628  Test L2 Loss :  0.02862376794219017  inv_L_scale:  [1.0, 1.0]
Epoch :  198  Time:  2.577  Rel. Train L2 Loss :  0.013653156277206209  Rel. Test L2 Loss :  0.01628611724823713  Test L2 Loss :  0.029868281334638595  inv_L_scale:  [1.0, 1.0]
Epoch :  199  Time:  2.575  Rel. Train L2 Loss :  0.013791249096393586  Rel. Test L2 Loss :  0.014801471456885339  Test L2 Loss :  0.02701861098408699  inv_L_scale:  [1.0, 1.0]
Epoch :  200  Time:  2.576  Rel. Train L2 Loss :  0.014110937275820308  Rel. Test L2 Loss :  0.013800073191523552  Test L2 Loss :  0.025085742622613906  inv_L_scale:  [1.0, 1.0]
Epoch :  201  Time:  2.586  Rel. Train L2 Loss :  0.013368207150035434  Rel. Test L2 Loss :  0.015170162804424762  Test L2 Loss :  0.027535256221890448  inv_L_scale:  [1.0, 1.0]
Epoch :  202  Time:  2.586  Rel. Train L2 Loss :  0.013591827667421764  Rel. Test L2 Loss :  0.015153090059757233  Test L2 Loss :  0.027447560578584673  inv_L_scale:  [1.0, 1.0]
Epoch :  203  Time:  2.576  Rel. Train L2 Loss :  0.013490303779641787  Rel. Test L2 Loss :  0.015911757051944732  Test L2 Loss :  0.029010084569454194  inv_L_scale:  [1.0, 1.0]
Epoch :  204  Time:  2.583  Rel. Train L2 Loss :  0.013196438666847016  Rel. Test L2 Loss :  0.01624382209032774  Test L2 Loss :  0.029604417011141776  inv_L_scale:  [1.0, 1.0]
Epoch :  205  Time:  2.586  Rel. Train L2 Loss :  0.013252245912121402  Rel. Test L2 Loss :  0.01538599692285061  Test L2 Loss :  0.028252306431531905  inv_L_scale:  [1.0, 1.0]
Epoch :  206  Time:  2.58  Rel. Train L2 Loss :  0.01422709747734997  Rel. Test L2 Loss :  0.015485625602304936  Test L2 Loss :  0.028273537456989288  inv_L_scale:  [1.0, 1.0]
Epoch :  207  Time:  2.578  Rel. Train L2 Loss :  0.013582786950800153  Rel. Test L2 Loss :  0.014593161270022392  Test L2 Loss :  0.026592659801244735  inv_L_scale:  [1.0, 1.0]
Epoch :  208  Time:  2.582  Rel. Train L2 Loss :  0.01331248101260927  Rel. Test L2 Loss :  0.017049237564206125  Test L2 Loss :  0.03154274880886078  inv_L_scale:  [1.0, 1.0]
Epoch :  209  Time:  2.571  Rel. Train L2 Loss :  0.013270318764779302  Rel. Test L2 Loss :  0.018251400515437124  Test L2 Loss :  0.034087096750736234  inv_L_scale:  [1.0, 1.0]
Epoch :  210  Time:  2.582  Rel. Train L2 Loss :  0.014357427805662156  Rel. Test L2 Loss :  0.016000166535377502  Test L2 Loss :  0.0290298805385828  inv_L_scale:  [1.0, 1.0]
Epoch :  211  Time:  2.573  Rel. Train L2 Loss :  0.013024683751993709  Rel. Test L2 Loss :  0.015330180078744888  Test L2 Loss :  0.028098470345139504  inv_L_scale:  [1.0, 1.0]
Epoch :  212  Time:  2.558  Rel. Train L2 Loss :  0.013331252125402291  Rel. Test L2 Loss :  0.015340377725660801  Test L2 Loss :  0.027858918383717537  inv_L_scale:  [1.0, 1.0]
Epoch :  213  Time:  2.578  Rel. Train L2 Loss :  0.013170501531826126  Rel. Test L2 Loss :  0.014343623295426369  Test L2 Loss :  0.025929691419005394  inv_L_scale:  [1.0, 1.0]
Epoch :  214  Time:  2.59  Rel. Train L2 Loss :  0.012691265576415593  Rel. Test L2 Loss :  0.013335065245628356  Test L2 Loss :  0.024359258636832238  inv_L_scale:  [1.0, 1.0]
Epoch :  215  Time:  2.574  Rel. Train L2 Loss :  0.013186142548090881  Rel. Test L2 Loss :  0.01611635524779558  Test L2 Loss :  0.02919467717409134  inv_L_scale:  [1.0, 1.0]
Epoch :  216  Time:  2.569  Rel. Train L2 Loss :  0.013634639109174411  Rel. Test L2 Loss :  0.01651870720088482  Test L2 Loss :  0.030077804774045945  inv_L_scale:  [1.0, 1.0]
Epoch :  217  Time:  2.588  Rel. Train L2 Loss :  0.0127375338309341  Rel. Test L2 Loss :  0.014361640214920044  Test L2 Loss :  0.026246409118175506  inv_L_scale:  [1.0, 1.0]
Epoch :  218  Time:  2.579  Rel. Train L2 Loss :  0.012604382559657097  Rel. Test L2 Loss :  0.015958103016018868  Test L2 Loss :  0.028953781947493554  inv_L_scale:  [1.0, 1.0]
Epoch :  219  Time:  2.585  Rel. Train L2 Loss :  0.013341561431686083  Rel. Test L2 Loss :  0.019659634828567505  Test L2 Loss :  0.036618140786886216  inv_L_scale:  [1.0, 1.0]
Epoch :  220  Time:  2.569  Rel. Train L2 Loss :  0.013092140071094036  Rel. Test L2 Loss :  0.016390425525605677  Test L2 Loss :  0.02998011454939842  inv_L_scale:  [1.0, 1.0]
Epoch :  221  Time:  2.577  Rel. Train L2 Loss :  0.012571636421812905  Rel. Test L2 Loss :  0.01547736518085003  Test L2 Loss :  0.02893874503672123  inv_L_scale:  [1.0, 1.0]
Epoch :  222  Time:  2.586  Rel. Train L2 Loss :  0.012022344470024109  Rel. Test L2 Loss :  0.013713715672492981  Test L2 Loss :  0.025239190459251402  inv_L_scale:  [1.0, 1.0]
Epoch :  223  Time:  2.58  Rel. Train L2 Loss :  0.012279371950361464  Rel. Test L2 Loss :  0.013963036090135574  Test L2 Loss :  0.025531736835837364  inv_L_scale:  [1.0, 1.0]
Epoch :  224  Time:  2.58  Rel. Train L2 Loss :  0.012218501443664233  Rel. Test L2 Loss :  0.014073770456016065  Test L2 Loss :  0.02571853846311569  inv_L_scale:  [1.0, 1.0]
Epoch :  225  Time:  2.589  Rel. Train L2 Loss :  0.012373130751980675  Rel. Test L2 Loss :  0.017836637496948242  Test L2 Loss :  0.0336482247710228  inv_L_scale:  [1.0, 1.0]
Epoch :  226  Time:  2.574  Rel. Train L2 Loss :  0.012271691386898358  Rel. Test L2 Loss :  0.013153091222047806  Test L2 Loss :  0.02397263005375862  inv_L_scale:  [1.0, 1.0]
Epoch :  227  Time:  2.569  Rel. Train L2 Loss :  0.01270642485883501  Rel. Test L2 Loss :  0.013818424008786679  Test L2 Loss :  0.02539775714278221  inv_L_scale:  [1.0, 1.0]
Epoch :  228  Time:  2.579  Rel. Train L2 Loss :  0.01239905478225814  Rel. Test L2 Loss :  0.01408596396446228  Test L2 Loss :  0.025864415690302848  inv_L_scale:  [1.0, 1.0]
Epoch :  229  Time:  2.581  Rel. Train L2 Loss :  0.012689179956085152  Rel. Test L2 Loss :  0.014899838455021382  Test L2 Loss :  0.027114983648061752  inv_L_scale:  [1.0, 1.0]
Epoch :  230  Time:  2.585  Rel. Train L2 Loss :  0.012683224756684569  Rel. Test L2 Loss :  0.013228663839399815  Test L2 Loss :  0.02418215438723564  inv_L_scale:  [1.0, 1.0]
Epoch :  231  Time:  2.586  Rel. Train L2 Loss :  0.012011628295812342  Rel. Test L2 Loss :  0.016113098673522473  Test L2 Loss :  0.029953333288431166  inv_L_scale:  [1.0, 1.0]
Epoch :  232  Time:  2.582  Rel. Train L2 Loss :  0.01237331808441215  Rel. Test L2 Loss :  0.014158920347690583  Test L2 Loss :  0.0258367907255888  inv_L_scale:  [1.0, 1.0]
Epoch :  233  Time:  2.58  Rel. Train L2 Loss :  0.013026615257064502  Rel. Test L2 Loss :  0.013819748535752296  Test L2 Loss :  0.025551443845033647  inv_L_scale:  [1.0, 1.0]
Epoch :  234  Time:  2.577  Rel. Train L2 Loss :  0.012272486256228553  Rel. Test L2 Loss :  0.014191076755523682  Test L2 Loss :  0.02573809154331684  inv_L_scale:  [1.0, 1.0]
Epoch :  235  Time:  2.577  Rel. Train L2 Loss :  0.012209299008051554  Rel. Test L2 Loss :  0.01349122941493988  Test L2 Loss :  0.024852424189448358  inv_L_scale:  [1.0, 1.0]
Epoch :  236  Time:  2.572  Rel. Train L2 Loss :  0.011969368209441503  Rel. Test L2 Loss :  0.014131378754973412  Test L2 Loss :  0.0255146424472332  inv_L_scale:  [1.0, 1.0]
Epoch :  237  Time:  2.581  Rel. Train L2 Loss :  0.01151400906758176  Rel. Test L2 Loss :  0.013884654194116592  Test L2 Loss :  0.025396339148283004  inv_L_scale:  [1.0, 1.0]
Epoch :  238  Time:  2.589  Rel. Train L2 Loss :  0.01210946399304602  Rel. Test L2 Loss :  0.014049180150032044  Test L2 Loss :  0.02572476163506508  inv_L_scale:  [1.0, 1.0]
Epoch :  239  Time:  2.575  Rel. Train L2 Loss :  0.012189977309770055  Rel. Test L2 Loss :  0.013624197393655777  Test L2 Loss :  0.024795670360326767  inv_L_scale:  [1.0, 1.0]
Epoch :  240  Time:  2.574  Rel. Train L2 Loss :  0.011574126473731464  Rel. Test L2 Loss :  0.017507811188697816  Test L2 Loss :  0.032101796120405195  inv_L_scale:  [1.0, 1.0]
Epoch :  241  Time:  2.584  Rel. Train L2 Loss :  0.011878893102208772  Rel. Test L2 Loss :  0.013105937652289868  Test L2 Loss :  0.023951546996831895  inv_L_scale:  [1.0, 1.0]
Epoch :  242  Time:  2.589  Rel. Train L2 Loss :  0.011411202107038762  Rel. Test L2 Loss :  0.012992577962577342  Test L2 Loss :  0.02380075566470623  inv_L_scale:  [1.0, 1.0]
Epoch :  243  Time:  2.576  Rel. Train L2 Loss :  0.01179393455800083  Rel. Test L2 Loss :  0.012921955212950706  Test L2 Loss :  0.023639524281024935  inv_L_scale:  [1.0, 1.0]
Epoch :  244  Time:  2.572  Rel. Train L2 Loss :  0.012273884688814482  Rel. Test L2 Loss :  0.01306237068027258  Test L2 Loss :  0.023870131000876427  inv_L_scale:  [1.0, 1.0]
Epoch :  245  Time:  2.574  Rel. Train L2 Loss :  0.01136669191221396  Rel. Test L2 Loss :  0.01261816743761301  Test L2 Loss :  0.023177176937460898  inv_L_scale:  [1.0, 1.0]
Epoch :  246  Time:  2.577  Rel. Train L2 Loss :  0.011149971104330487  Rel. Test L2 Loss :  0.013759623356163502  Test L2 Loss :  0.024957279115915297  inv_L_scale:  [1.0, 1.0]
Epoch :  247  Time:  2.582  Rel. Train L2 Loss :  0.011567014124658373  Rel. Test L2 Loss :  0.013522562645375729  Test L2 Loss :  0.024722312092781067  inv_L_scale:  [1.0, 1.0]
Epoch :  248  Time:  2.579  Rel. Train L2 Loss :  0.01145876574019591  Rel. Test L2 Loss :  0.012367318645119666  Test L2 Loss :  0.02268195554614067  inv_L_scale:  [1.0, 1.0]
Epoch :  249  Time:  2.582  Rel. Train L2 Loss :  0.011340931745039091  Rel. Test L2 Loss :  0.012411837056279183  Test L2 Loss :  0.02255514442920685  inv_L_scale:  [1.0, 1.0]
Epoch :  250  Time:  2.568  Rel. Train L2 Loss :  0.01129916081411971  Rel. Test L2 Loss :  0.013859976641833782  Test L2 Loss :  0.025390997454524042  inv_L_scale:  [1.0, 1.0]
Epoch :  251  Time:  2.587  Rel. Train L2 Loss :  0.011645198203623294  Rel. Test L2 Loss :  0.012806895524263381  Test L2 Loss :  0.02335429348051548  inv_L_scale:  [1.0, 1.0]
Epoch :  252  Time:  2.591  Rel. Train L2 Loss :  0.011451884541246626  Rel. Test L2 Loss :  0.014458558224141597  Test L2 Loss :  0.026246147826313973  inv_L_scale:  [1.0, 1.0]
Epoch :  253  Time:  2.57  Rel. Train L2 Loss :  0.012087053039835559  Rel. Test L2 Loss :  0.014199251718819141  Test L2 Loss :  0.02577580139040947  inv_L_scale:  [1.0, 1.0]
Epoch :  254  Time:  2.571  Rel. Train L2 Loss :  0.011237884047958585  Rel. Test L2 Loss :  0.01260549396276474  Test L2 Loss :  0.023133342117071153  inv_L_scale:  [1.0, 1.0]
Epoch :  255  Time:  2.585  Rel. Train L2 Loss :  0.011783570866617892  Rel. Test L2 Loss :  0.012686633765697479  Test L2 Loss :  0.023425035700201987  inv_L_scale:  [1.0, 1.0]
Epoch :  256  Time:  2.58  Rel. Train L2 Loss :  0.011209592657784621  Rel. Test L2 Loss :  0.012708375081419945  Test L2 Loss :  0.02319949269294739  inv_L_scale:  [1.0, 1.0]
Epoch :  257  Time:  2.575  Rel. Train L2 Loss :  0.010834906047417058  Rel. Test L2 Loss :  0.01603645842522383  Test L2 Loss :  0.030000646486878394  inv_L_scale:  [1.0, 1.0]
Epoch :  258  Time:  2.586  Rel. Train L2 Loss :  0.011456458556155364  Rel. Test L2 Loss :  0.012230055704712868  Test L2 Loss :  0.022195567637681962  inv_L_scale:  [1.0, 1.0]
Epoch :  259  Time:  2.583  Rel. Train L2 Loss :  0.010781342320972019  Rel. Test L2 Loss :  0.013268383368849754  Test L2 Loss :  0.02457151547074318  inv_L_scale:  [1.0, 1.0]
Epoch :  260  Time:  2.576  Rel. Train L2 Loss :  0.010865704864263534  Rel. Test L2 Loss :  0.012218096330761909  Test L2 Loss :  0.022372806295752525  inv_L_scale:  [1.0, 1.0]
Epoch :  261  Time:  2.574  Rel. Train L2 Loss :  0.010703384549253517  Rel. Test L2 Loss :  0.012445469535887242  Test L2 Loss :  0.022816573530435563  inv_L_scale:  [1.0, 1.0]
Epoch :  262  Time:  2.561  Rel. Train L2 Loss :  0.010677472117046515  Rel. Test L2 Loss :  0.012776023894548415  Test L2 Loss :  0.023439594879746437  inv_L_scale:  [1.0, 1.0]
Epoch :  263  Time:  2.53  Rel. Train L2 Loss :  0.010640966097513834  Rel. Test L2 Loss :  0.012678642347455025  Test L2 Loss :  0.023006915003061294  inv_L_scale:  [1.0, 1.0]
Epoch :  264  Time:  2.552  Rel. Train L2 Loss :  0.010717594561477502  Rel. Test L2 Loss :  0.013524432554841042  Test L2 Loss :  0.024683820083737373  inv_L_scale:  [1.0, 1.0]
Epoch :  265  Time:  2.584  Rel. Train L2 Loss :  0.010390061380134688  Rel. Test L2 Loss :  0.011994289457798004  Test L2 Loss :  0.02192829743027687  inv_L_scale:  [1.0, 1.0]
Epoch :  266  Time:  2.589  Rel. Train L2 Loss :  0.010311235292918152  Rel. Test L2 Loss :  0.01146908313035965  Test L2 Loss :  0.02113448292016983  inv_L_scale:  [1.0, 1.0]
Epoch :  267  Time:  2.586  Rel. Train L2 Loss :  0.010578904214004675  Rel. Test L2 Loss :  0.011290836818516255  Test L2 Loss :  0.020546735227108003  inv_L_scale:  [1.0, 1.0]
Epoch :  268  Time:  2.588  Rel. Train L2 Loss :  0.009845678148170313  Rel. Test L2 Loss :  0.012593271061778068  Test L2 Loss :  0.023027075976133345  inv_L_scale:  [1.0, 1.0]
Epoch :  269  Time:  2.586  Rel. Train L2 Loss :  0.01030027234305938  Rel. Test L2 Loss :  0.012132739424705505  Test L2 Loss :  0.02196062035858631  inv_L_scale:  [1.0, 1.0]
Epoch :  270  Time:  2.593  Rel. Train L2 Loss :  0.01033121530794435  Rel. Test L2 Loss :  0.010990710482001304  Test L2 Loss :  0.019964130371809007  inv_L_scale:  [1.0, 1.0]
Epoch :  271  Time:  2.589  Rel. Train L2 Loss :  0.010259248225225342  Rel. Test L2 Loss :  0.012346420474350452  Test L2 Loss :  0.02244210258126259  inv_L_scale:  [1.0, 1.0]
Epoch :  272  Time:  2.58  Rel. Train L2 Loss :  0.01060986403375864  Rel. Test L2 Loss :  0.01155959889292717  Test L2 Loss :  0.021104695200920107  inv_L_scale:  [1.0, 1.0]
Epoch :  273  Time:  2.558  Rel. Train L2 Loss :  0.010361378586126698  Rel. Test L2 Loss :  0.01170763947069645  Test L2 Loss :  0.02151213467121124  inv_L_scale:  [1.0, 1.0]
Epoch :  274  Time:  2.576  Rel. Train L2 Loss :  0.010179770593014028  Rel. Test L2 Loss :  0.010894332155585289  Test L2 Loss :  0.020032676011323927  inv_L_scale:  [1.0, 1.0]
Epoch :  275  Time:  2.576  Rel. Train L2 Loss :  0.010081054266128275  Rel. Test L2 Loss :  0.011559942662715912  Test L2 Loss :  0.02098066620528698  inv_L_scale:  [1.0, 1.0]
Epoch :  276  Time:  2.59  Rel. Train L2 Loss :  0.010185235912601153  Rel. Test L2 Loss :  0.012124727964401245  Test L2 Loss :  0.022380040064454078  inv_L_scale:  [1.0, 1.0]
Epoch :  277  Time:  2.588  Rel. Train L2 Loss :  0.01016042227960295  Rel. Test L2 Loss :  0.012923683151602744  Test L2 Loss :  0.023915207237005232  inv_L_scale:  [1.0, 1.0]
Epoch :  278  Time:  2.586  Rel. Train L2 Loss :  0.010355462386376328  Rel. Test L2 Loss :  0.011344506107270717  Test L2 Loss :  0.020829145461320878  inv_L_scale:  [1.0, 1.0]
Epoch :  279  Time:  2.59  Rel. Train L2 Loss :  0.010402119002408452  Rel. Test L2 Loss :  0.012978943064808846  Test L2 Loss :  0.02366986244916916  inv_L_scale:  [1.0, 1.0]
Epoch :  280  Time:  2.598  Rel. Train L2 Loss :  0.009961077024539312  Rel. Test L2 Loss :  0.011028225608170033  Test L2 Loss :  0.020249994546175  inv_L_scale:  [1.0, 1.0]
Epoch :  281  Time:  2.588  Rel. Train L2 Loss :  0.009891254198220041  Rel. Test L2 Loss :  0.01082651399075985  Test L2 Loss :  0.019870760440826415  inv_L_scale:  [1.0, 1.0]
Epoch :  282  Time:  2.568  Rel. Train L2 Loss :  0.009944867090218598  Rel. Test L2 Loss :  0.012115340977907181  Test L2 Loss :  0.02215589389204979  inv_L_scale:  [1.0, 1.0]
Epoch :  283  Time:  2.581  Rel. Train L2 Loss :  0.00965330617295371  Rel. Test L2 Loss :  0.011732321195304395  Test L2 Loss :  0.021657602190971376  inv_L_scale:  [1.0, 1.0]
Epoch :  284  Time:  2.575  Rel. Train L2 Loss :  0.009587071186138524  Rel. Test L2 Loss :  0.01084012508392334  Test L2 Loss :  0.019943626448512077  inv_L_scale:  [1.0, 1.0]
Epoch :  285  Time:  2.592  Rel. Train L2 Loss :  0.009534900983174641  Rel. Test L2 Loss :  0.011034837290644646  Test L2 Loss :  0.020306982174515723  inv_L_scale:  [1.0, 1.0]
Epoch :  286  Time:  2.589  Rel. Train L2 Loss :  0.009607780964838135  Rel. Test L2 Loss :  0.01173705417662859  Test L2 Loss :  0.021433276757597923  inv_L_scale:  [1.0, 1.0]
Epoch :  287  Time:  2.585  Rel. Train L2 Loss :  0.009745311182406213  Rel. Test L2 Loss :  0.011920790299773215  Test L2 Loss :  0.022369998693466186  inv_L_scale:  [1.0, 1.0]
Epoch :  288  Time:  2.592  Rel. Train L2 Loss :  0.009797998501194848  Rel. Test L2 Loss :  0.011890388280153274  Test L2 Loss :  0.021925819143652915  inv_L_scale:  [1.0, 1.0]
Epoch :  289  Time:  2.598  Rel. Train L2 Loss :  0.010082698812087378  Rel. Test L2 Loss :  0.011254005953669549  Test L2 Loss :  0.020639926567673682  inv_L_scale:  [1.0, 1.0]
Epoch :  290  Time:  2.584  Rel. Train L2 Loss :  0.009486555709607072  Rel. Test L2 Loss :  0.01093080386519432  Test L2 Loss :  0.02012219458818436  inv_L_scale:  [1.0, 1.0]
Epoch :  291  Time:  2.578  Rel. Train L2 Loss :  0.010024864847461382  Rel. Test L2 Loss :  0.01142275206744671  Test L2 Loss :  0.0208539779484272  inv_L_scale:  [1.0, 1.0]
Epoch :  292  Time:  2.555  Rel. Train L2 Loss :  0.009250679835677147  Rel. Test L2 Loss :  0.010856171734631062  Test L2 Loss :  0.01990603655576706  inv_L_scale:  [1.0, 1.0]
Epoch :  293  Time:  2.6  Rel. Train L2 Loss :  0.009299013821615113  Rel. Test L2 Loss :  0.010907031893730164  Test L2 Loss :  0.019968293085694314  inv_L_scale:  [1.0, 1.0]
Epoch :  294  Time:  2.584  Rel. Train L2 Loss :  0.009447595613698165  Rel. Test L2 Loss :  0.010366135835647583  Test L2 Loss :  0.01906077042222023  inv_L_scale:  [1.0, 1.0]
Epoch :  295  Time:  2.575  Rel. Train L2 Loss :  0.00934149700941311  Rel. Test L2 Loss :  0.01181337408721447  Test L2 Loss :  0.021505449414253235  inv_L_scale:  [1.0, 1.0]
Epoch :  296  Time:  2.568  Rel. Train L2 Loss :  0.00943634001745118  Rel. Test L2 Loss :  0.010622926950454713  Test L2 Loss :  0.019291542917490006  inv_L_scale:  [1.0, 1.0]
Epoch :  297  Time:  2.577  Rel. Train L2 Loss :  0.008965321030053828  Rel. Test L2 Loss :  0.010444748327136039  Test L2 Loss :  0.019381540343165398  inv_L_scale:  [1.0, 1.0]
Epoch :  298  Time:  2.583  Rel. Train L2 Loss :  0.00893608343684011  Rel. Test L2 Loss :  0.010321990065276622  Test L2 Loss :  0.018948967084288598  inv_L_scale:  [1.0, 1.0]
Epoch :  299  Time:  2.588  Rel. Train L2 Loss :  0.009833015431132582  Rel. Test L2 Loss :  0.012038812190294266  Test L2 Loss :  0.022194764912128448  inv_L_scale:  [1.0, 1.0]
Epoch :  300  Time:  2.587  Rel. Train L2 Loss :  0.00948138831390275  Rel. Test L2 Loss :  0.010433202013373374  Test L2 Loss :  0.019301308840513228  inv_L_scale:  [1.0, 1.0]
Epoch :  301  Time:  2.573  Rel. Train L2 Loss :  0.008886457292570009  Rel. Test L2 Loss :  0.010947915501892566  Test L2 Loss :  0.020214565694332123  inv_L_scale:  [1.0, 1.0]
Epoch :  302  Time:  2.577  Rel. Train L2 Loss :  0.008879908008707894  Rel. Test L2 Loss :  0.010175319835543633  Test L2 Loss :  0.01876478858292103  inv_L_scale:  [1.0, 1.0]
Epoch :  303  Time:  2.59  Rel. Train L2 Loss :  0.008766488565338983  Rel. Test L2 Loss :  0.010076361671090127  Test L2 Loss :  0.018547743260860443  inv_L_scale:  [1.0, 1.0]
Epoch :  304  Time:  2.588  Rel. Train L2 Loss :  0.008740723443528017  Rel. Test L2 Loss :  0.010133259296417237  Test L2 Loss :  0.018608934432268142  inv_L_scale:  [1.0, 1.0]
Epoch :  305  Time:  2.576  Rel. Train L2 Loss :  0.008895502839651372  Rel. Test L2 Loss :  0.010460975840687751  Test L2 Loss :  0.019213672950863837  inv_L_scale:  [1.0, 1.0]
Epoch :  306  Time:  2.579  Rel. Train L2 Loss :  0.008918395176943806  Rel. Test L2 Loss :  0.01018865656107664  Test L2 Loss :  0.01858442597091198  inv_L_scale:  [1.0, 1.0]
Epoch :  307  Time:  2.576  Rel. Train L2 Loss :  0.008931556257108847  Rel. Test L2 Loss :  0.01057229433208704  Test L2 Loss :  0.019563348218798637  inv_L_scale:  [1.0, 1.0]
Epoch :  308  Time:  2.588  Rel. Train L2 Loss :  0.009035945923791991  Rel. Test L2 Loss :  0.011058907508850097  Test L2 Loss :  0.02026181183755398  inv_L_scale:  [1.0, 1.0]
Epoch :  309  Time:  2.59  Rel. Train L2 Loss :  0.009038697572218047  Rel. Test L2 Loss :  0.01135096862912178  Test L2 Loss :  0.020729242339730263  inv_L_scale:  [1.0, 1.0]
Epoch :  310  Time:  2.583  Rel. Train L2 Loss :  0.0088267324016326  Rel. Test L2 Loss :  0.010306344106793404  Test L2 Loss :  0.018914149701595308  inv_L_scale:  [1.0, 1.0]
Epoch :  311  Time:  2.584  Rel. Train L2 Loss :  0.008836379829380247  Rel. Test L2 Loss :  0.009802013039588928  Test L2 Loss :  0.017986849397420884  inv_L_scale:  [1.0, 1.0]
Epoch :  312  Time:  2.569  Rel. Train L2 Loss :  0.0087655373952455  Rel. Test L2 Loss :  0.010394812747836112  Test L2 Loss :  0.018905121386051178  inv_L_scale:  [1.0, 1.0]
Epoch :  313  Time:  2.574  Rel. Train L2 Loss :  0.008591741865707768  Rel. Test L2 Loss :  0.010631111077964306  Test L2 Loss :  0.019692752733826636  inv_L_scale:  [1.0, 1.0]
Epoch :  314  Time:  2.586  Rel. Train L2 Loss :  0.008547928300168778  Rel. Test L2 Loss :  0.010149289667606354  Test L2 Loss :  0.01863517940044403  inv_L_scale:  [1.0, 1.0]
Epoch :  315  Time:  2.582  Rel. Train L2 Loss :  0.008504020938028892  Rel. Test L2 Loss :  0.009762040860950947  Test L2 Loss :  0.017889264523983  inv_L_scale:  [1.0, 1.0]
Epoch :  316  Time:  2.579  Rel. Train L2 Loss :  0.008607442250682247  Rel. Test L2 Loss :  0.009507495947182178  Test L2 Loss :  0.017383384481072427  inv_L_scale:  [1.0, 1.0]
Epoch :  317  Time:  2.591  Rel. Train L2 Loss :  0.008383072146938907  Rel. Test L2 Loss :  0.01017917674034834  Test L2 Loss :  0.01867175064980984  inv_L_scale:  [1.0, 1.0]
Epoch :  318  Time:  2.582  Rel. Train L2 Loss :  0.008761559054255486  Rel. Test L2 Loss :  0.010508977174758911  Test L2 Loss :  0.019314298555254936  inv_L_scale:  [1.0, 1.0]
Epoch :  319  Time:  2.577  Rel. Train L2 Loss :  0.008375144919587506  Rel. Test L2 Loss :  0.009398545809090138  Test L2 Loss :  0.017193196713924407  inv_L_scale:  [1.0, 1.0]
Epoch :  320  Time:  2.574  Rel. Train L2 Loss :  0.008220688826921913  Rel. Test L2 Loss :  0.00984103135764599  Test L2 Loss :  0.018072599172592164  inv_L_scale:  [1.0, 1.0]
Epoch :  321  Time:  2.578  Rel. Train L2 Loss :  0.008345843301051193  Rel. Test L2 Loss :  0.010330815352499485  Test L2 Loss :  0.01910914808511734  inv_L_scale:  [1.0, 1.0]
Epoch :  322  Time:  2.586  Rel. Train L2 Loss :  0.008400180095599757  Rel. Test L2 Loss :  0.010025463812053204  Test L2 Loss :  0.018291736990213393  inv_L_scale:  [1.0, 1.0]
Epoch :  323  Time:  2.59  Rel. Train L2 Loss :  0.00839218310183949  Rel. Test L2 Loss :  0.009534670896828175  Test L2 Loss :  0.01739553190767765  inv_L_scale:  [1.0, 1.0]
Epoch :  324  Time:  2.583  Rel. Train L2 Loss :  0.008178249624454313  Rel. Test L2 Loss :  0.009719937108457088  Test L2 Loss :  0.017674794420599937  inv_L_scale:  [1.0, 1.0]
Epoch :  325  Time:  2.569  Rel. Train L2 Loss :  0.00818889741268423  Rel. Test L2 Loss :  0.010611146315932274  Test L2 Loss :  0.01934556759893894  inv_L_scale:  [1.0, 1.0]
Epoch :  326  Time:  2.591  Rel. Train L2 Loss :  0.008216131985601451  Rel. Test L2 Loss :  0.009105713590979576  Test L2 Loss :  0.01679677113890648  inv_L_scale:  [1.0, 1.0]
Epoch :  327  Time:  2.589  Rel. Train L2 Loss :  0.008102654694683022  Rel. Test L2 Loss :  0.009570019729435443  Test L2 Loss :  0.01770547553896904  inv_L_scale:  [1.0, 1.0]
Epoch :  328  Time:  2.58  Rel. Train L2 Loss :  0.0082278881346186  Rel. Test L2 Loss :  0.009030238650739193  Test L2 Loss :  0.016514578498899937  inv_L_scale:  [1.0, 1.0]
Epoch :  329  Time:  2.57  Rel. Train L2 Loss :  0.0079001484811306  Rel. Test L2 Loss :  0.009604239352047444  Test L2 Loss :  0.01752751909196377  inv_L_scale:  [1.0, 1.0]
Epoch :  330  Time:  2.574  Rel. Train L2 Loss :  0.008299478499425783  Rel. Test L2 Loss :  0.00948509119451046  Test L2 Loss :  0.017314766719937324  inv_L_scale:  [1.0, 1.0]
Epoch :  331  Time:  2.58  Rel. Train L2 Loss :  0.008062238705654938  Rel. Test L2 Loss :  0.009458513930439949  Test L2 Loss :  0.017380514144897462  inv_L_scale:  [1.0, 1.0]
Epoch :  332  Time:  2.584  Rel. Train L2 Loss :  0.007915821957091491  Rel. Test L2 Loss :  0.009589331708848476  Test L2 Loss :  0.017581196427345278  inv_L_scale:  [1.0, 1.0]
Epoch :  333  Time:  2.582  Rel. Train L2 Loss :  0.007998926242192587  Rel. Test L2 Loss :  0.00970521591603756  Test L2 Loss :  0.01785850666463375  inv_L_scale:  [1.0, 1.0]
Epoch :  334  Time:  2.571  Rel. Train L2 Loss :  0.008161825022349755  Rel. Test L2 Loss :  0.009296864978969097  Test L2 Loss :  0.017115090042352676  inv_L_scale:  [1.0, 1.0]
Epoch :  335  Time:  2.577  Rel. Train L2 Loss :  0.007903448254283931  Rel. Test L2 Loss :  0.009269473180174827  Test L2 Loss :  0.01702868416905403  inv_L_scale:  [1.0, 1.0]
Epoch :  336  Time:  2.59  Rel. Train L2 Loss :  0.007742033397985829  Rel. Test L2 Loss :  0.00869142472743988  Test L2 Loss :  0.015921516716480254  inv_L_scale:  [1.0, 1.0]
Epoch :  337  Time:  2.582  Rel. Train L2 Loss :  0.00790881097730663  Rel. Test L2 Loss :  0.00917153935879469  Test L2 Loss :  0.016890617609024047  inv_L_scale:  [1.0, 1.0]
Epoch :  338  Time:  2.582  Rel. Train L2 Loss :  0.007632089244822661  Rel. Test L2 Loss :  0.00948120091110468  Test L2 Loss :  0.017589830681681632  inv_L_scale:  [1.0, 1.0]
Epoch :  339  Time:  2.58  Rel. Train L2 Loss :  0.007942715674224827  Rel. Test L2 Loss :  0.008909048587083817  Test L2 Loss :  0.016354759186506272  inv_L_scale:  [1.0, 1.0]
Epoch :  340  Time:  2.572  Rel. Train L2 Loss :  0.007791501242253515  Rel. Test L2 Loss :  0.008911645412445069  Test L2 Loss :  0.016290245465934276  inv_L_scale:  [1.0, 1.0]
Epoch :  341  Time:  2.577  Rel. Train L2 Loss :  0.007746717077162531  Rel. Test L2 Loss :  0.008429356738924981  Test L2 Loss :  0.015522326938807965  inv_L_scale:  [1.0, 1.0]
Epoch :  342  Time:  2.575  Rel. Train L2 Loss :  0.007536638155579567  Rel. Test L2 Loss :  0.008894907459616661  Test L2 Loss :  0.0162665119767189  inv_L_scale:  [1.0, 1.0]
Epoch :  343  Time:  2.595  Rel. Train L2 Loss :  0.007638308753569921  Rel. Test L2 Loss :  0.008951292037963868  Test L2 Loss :  0.016413336358964442  inv_L_scale:  [1.0, 1.0]
Epoch :  344  Time:  2.588  Rel. Train L2 Loss :  0.007527176655001111  Rel. Test L2 Loss :  0.009309954158961773  Test L2 Loss :  0.01702284637838602  inv_L_scale:  [1.0, 1.0]
Epoch :  345  Time:  2.578  Rel. Train L2 Loss :  0.0076765249793728195  Rel. Test L2 Loss :  0.01020987894386053  Test L2 Loss :  0.01897974170744419  inv_L_scale:  [1.0, 1.0]
Epoch :  346  Time:  2.574  Rel. Train L2 Loss :  0.007796060761643781  Rel. Test L2 Loss :  0.009555431045591832  Test L2 Loss :  0.017598937153816222  inv_L_scale:  [1.0, 1.0]
Epoch :  347  Time:  2.574  Rel. Train L2 Loss :  0.007756512761116028  Rel. Test L2 Loss :  0.008588708080351353  Test L2 Loss :  0.015824250318109988  inv_L_scale:  [1.0, 1.0]
Epoch :  348  Time:  2.582  Rel. Train L2 Loss :  0.007609512503776285  Rel. Test L2 Loss :  0.009292842335999012  Test L2 Loss :  0.01702140711247921  inv_L_scale:  [1.0, 1.0]
Epoch :  349  Time:  2.578  Rel. Train L2 Loss :  0.007686694636940956  Rel. Test L2 Loss :  0.008793429676443339  Test L2 Loss :  0.016088031493127347  inv_L_scale:  [1.0, 1.0]
Epoch :  350  Time:  2.578  Rel. Train L2 Loss :  0.007581151883221335  Rel. Test L2 Loss :  0.008845323845744133  Test L2 Loss :  0.016192665286362172  inv_L_scale:  [1.0, 1.0]
Epoch :  351  Time:  2.583  Rel. Train L2 Loss :  0.007838105360666911  Rel. Test L2 Loss :  0.009436191320419311  Test L2 Loss :  0.017246602922677993  inv_L_scale:  [1.0, 1.0]
Epoch :  352  Time:  2.577  Rel. Train L2 Loss :  0.0077782365679740905  Rel. Test L2 Loss :  0.009399308450520038  Test L2 Loss :  0.017123342379927634  inv_L_scale:  [1.0, 1.0]
Epoch :  353  Time:  2.58  Rel. Train L2 Loss :  0.007653574293686284  Rel. Test L2 Loss :  0.008978073727339506  Test L2 Loss :  0.016488995328545572  inv_L_scale:  [1.0, 1.0]
Epoch :  354  Time:  2.583  Rel. Train L2 Loss :  0.007477243766188622  Rel. Test L2 Loss :  0.008522246852517129  Test L2 Loss :  0.015620120242238045  inv_L_scale:  [1.0, 1.0]
Epoch :  355  Time:  2.582  Rel. Train L2 Loss :  0.007526041786703798  Rel. Test L2 Loss :  0.008834633342921734  Test L2 Loss :  0.01621291197836399  inv_L_scale:  [1.0, 1.0]
Epoch :  356  Time:  2.584  Rel. Train L2 Loss :  0.0075946276096834076  Rel. Test L2 Loss :  0.008949303403496742  Test L2 Loss :  0.01643777847290039  inv_L_scale:  [1.0, 1.0]
Epoch :  357  Time:  2.582  Rel. Train L2 Loss :  0.007494519472950035  Rel. Test L2 Loss :  0.008992533236742019  Test L2 Loss :  0.016356815844774247  inv_L_scale:  [1.0, 1.0]
Epoch :  358  Time:  2.574  Rel. Train L2 Loss :  0.007372379584444894  Rel. Test L2 Loss :  0.008740738295018672  Test L2 Loss :  0.015978159047663212  inv_L_scale:  [1.0, 1.0]
Epoch :  359  Time:  2.58  Rel. Train L2 Loss :  0.0072927414460314645  Rel. Test L2 Loss :  0.008747518509626389  Test L2 Loss :  0.015976171270012857  inv_L_scale:  [1.0, 1.0]
Epoch :  360  Time:  2.578  Rel. Train L2 Loss :  0.007411587472177214  Rel. Test L2 Loss :  0.008542997650802136  Test L2 Loss :  0.015614289715886116  inv_L_scale:  [1.0, 1.0]
Epoch :  361  Time:  2.588  Rel. Train L2 Loss :  0.007356050167646673  Rel. Test L2 Loss :  0.008800663724541665  Test L2 Loss :  0.016042666658759117  inv_L_scale:  [1.0, 1.0]
Epoch :  362  Time:  2.585  Rel. Train L2 Loss :  0.007154245869153076  Rel. Test L2 Loss :  0.008491860311478376  Test L2 Loss :  0.015560022592544555  inv_L_scale:  [1.0, 1.0]
Epoch :  363  Time:  2.559  Rel. Train L2 Loss :  0.007194087579846382  Rel. Test L2 Loss :  0.008302614036947488  Test L2 Loss :  0.015231300294399262  inv_L_scale:  [1.0, 1.0]
Epoch :  364  Time:  2.569  Rel. Train L2 Loss :  0.007138539275361432  Rel. Test L2 Loss :  0.008498410768806934  Test L2 Loss :  0.015502737686038017  inv_L_scale:  [1.0, 1.0]
Epoch :  365  Time:  2.583  Rel. Train L2 Loss :  0.007166268494394091  Rel. Test L2 Loss :  0.008501990288496018  Test L2 Loss :  0.01566378928720951  inv_L_scale:  [1.0, 1.0]
Epoch :  366  Time:  2.574  Rel. Train L2 Loss :  0.007123814363860422  Rel. Test L2 Loss :  0.008632479123771191  Test L2 Loss :  0.015860201865434645  inv_L_scale:  [1.0, 1.0]
Epoch :  367  Time:  2.575  Rel. Train L2 Loss :  0.007054605007999473  Rel. Test L2 Loss :  0.008137665744870902  Test L2 Loss :  0.01490607760846615  inv_L_scale:  [1.0, 1.0]
Epoch :  368  Time:  2.576  Rel. Train L2 Loss :  0.006907214601006773  Rel. Test L2 Loss :  0.008018803112208843  Test L2 Loss :  0.014741051681339741  inv_L_scale:  [1.0, 1.0]
Epoch :  369  Time:  2.582  Rel. Train L2 Loss :  0.006875520820418994  Rel. Test L2 Loss :  0.008119081817567349  Test L2 Loss :  0.01489985264837742  inv_L_scale:  [1.0, 1.0]
Epoch :  370  Time:  2.585  Rel. Train L2 Loss :  0.006847230220834414  Rel. Test L2 Loss :  0.008518414832651615  Test L2 Loss :  0.015700418092310427  inv_L_scale:  [1.0, 1.0]
Epoch :  371  Time:  2.581  Rel. Train L2 Loss :  0.00683945881202817  Rel. Test L2 Loss :  0.008264061845839023  Test L2 Loss :  0.015209661349654197  inv_L_scale:  [1.0, 1.0]
Epoch :  372  Time:  2.574  Rel. Train L2 Loss :  0.0068221560948424865  Rel. Test L2 Loss :  0.008377217911183834  Test L2 Loss :  0.015300033502280713  inv_L_scale:  [1.0, 1.0]
Epoch :  373  Time:  2.574  Rel. Train L2 Loss :  0.0070506930061512525  Rel. Test L2 Loss :  0.008118960745632649  Test L2 Loss :  0.014853805676102639  inv_L_scale:  [1.0, 1.0]
Epoch :  374  Time:  2.578  Rel. Train L2 Loss :  0.0069084504308799905  Rel. Test L2 Loss :  0.008286405485123396  Test L2 Loss :  0.015228776969015598  inv_L_scale:  [1.0, 1.0]
Epoch :  375  Time:  2.581  Rel. Train L2 Loss :  0.006878147638506359  Rel. Test L2 Loss :  0.007999630905687808  Test L2 Loss :  0.01467039242386818  inv_L_scale:  [1.0, 1.0]
Epoch :  376  Time:  2.588  Rel. Train L2 Loss :  0.006766933910548687  Rel. Test L2 Loss :  0.008211801573634148  Test L2 Loss :  0.015139488093554974  inv_L_scale:  [1.0, 1.0]
Epoch :  377  Time:  2.575  Rel. Train L2 Loss :  0.006786679277817408  Rel. Test L2 Loss :  0.007822646964341403  Test L2 Loss :  0.014383249469101429  inv_L_scale:  [1.0, 1.0]
Epoch :  378  Time:  2.565  Rel. Train L2 Loss :  0.006700075392921765  Rel. Test L2 Loss :  0.007787996158003807  Test L2 Loss :  0.014297204241156578  inv_L_scale:  [1.0, 1.0]
Epoch :  379  Time:  2.552  Rel. Train L2 Loss :  0.0065799505139390625  Rel. Test L2 Loss :  0.007670648656785488  Test L2 Loss :  0.014103631563484669  inv_L_scale:  [1.0, 1.0]
Epoch :  380  Time:  2.529  Rel. Train L2 Loss :  0.006629696064111259  Rel. Test L2 Loss :  0.007997947558760644  Test L2 Loss :  0.014656824804842473  inv_L_scale:  [1.0, 1.0]
Epoch :  381  Time:  2.588  Rel. Train L2 Loss :  0.006767255100939009  Rel. Test L2 Loss :  0.008112334869801998  Test L2 Loss :  0.014894619397819043  inv_L_scale:  [1.0, 1.0]
Epoch :  382  Time:  2.579  Rel. Train L2 Loss :  0.006665026880800724  Rel. Test L2 Loss :  0.00788371842354536  Test L2 Loss :  0.014479116015136241  inv_L_scale:  [1.0, 1.0]
Epoch :  383  Time:  2.593  Rel. Train L2 Loss :  0.006641298066824675  Rel. Test L2 Loss :  0.007917662896215916  Test L2 Loss :  0.014489685520529746  inv_L_scale:  [1.0, 1.0]
Epoch :  384  Time:  2.593  Rel. Train L2 Loss :  0.006541828769776556  Rel. Test L2 Loss :  0.0076661908999085425  Test L2 Loss :  0.014060809090733529  inv_L_scale:  [1.0, 1.0]
Epoch :  385  Time:  2.588  Rel. Train L2 Loss :  0.00647320746547646  Rel. Test L2 Loss :  0.007851698882877827  Test L2 Loss :  0.014406741857528686  inv_L_scale:  [1.0, 1.0]
Epoch :  386  Time:  2.593  Rel. Train L2 Loss :  0.006587635220752822  Rel. Test L2 Loss :  0.007699372619390488  Test L2 Loss :  0.014146134182810783  inv_L_scale:  [1.0, 1.0]
Epoch :  387  Time:  2.598  Rel. Train L2 Loss :  0.0065397223954399425  Rel. Test L2 Loss :  0.008083149790763855  Test L2 Loss :  0.014893344715237617  inv_L_scale:  [1.0, 1.0]
Epoch :  388  Time:  2.583  Rel. Train L2 Loss :  0.006464234151773982  Rel. Test L2 Loss :  0.007748001478612423  Test L2 Loss :  0.014228095449507237  inv_L_scale:  [1.0, 1.0]
Epoch :  389  Time:  2.577  Rel. Train L2 Loss :  0.006406718157231808  Rel. Test L2 Loss :  0.007549476176500321  Test L2 Loss :  0.013794495388865471  inv_L_scale:  [1.0, 1.0]
Epoch :  390  Time:  2.556  Rel. Train L2 Loss :  0.006579111268122991  Rel. Test L2 Loss :  0.007992026954889297  Test L2 Loss :  0.014686798378825187  inv_L_scale:  [1.0, 1.0]
Epoch :  391  Time:  2.602  Rel. Train L2 Loss :  0.0064399322722521095  Rel. Test L2 Loss :  0.0077448121085762975  Test L2 Loss :  0.014249939434230328  inv_L_scale:  [1.0, 1.0]
Epoch :  392  Time:  2.574  Rel. Train L2 Loss :  0.006347890107168091  Rel. Test L2 Loss :  0.0076615124195814135  Test L2 Loss :  0.014131343215703964  inv_L_scale:  [1.0, 1.0]
Epoch :  393  Time:  2.589  Rel. Train L2 Loss :  0.006330923694703314  Rel. Test L2 Loss :  0.007472087107598782  Test L2 Loss :  0.013658332973718643  inv_L_scale:  [1.0, 1.0]
Epoch :  394  Time:  2.586  Rel. Train L2 Loss :  0.0063433663878175945  Rel. Test L2 Loss :  0.0073901694267988205  Test L2 Loss :  0.013551018945872784  inv_L_scale:  [1.0, 1.0]
Epoch :  395  Time:  2.577  Rel. Train L2 Loss :  0.006331254359748628  Rel. Test L2 Loss :  0.0075928885862231255  Test L2 Loss :  0.013868987634778023  inv_L_scale:  [1.0, 1.0]
Epoch :  396  Time:  2.578  Rel. Train L2 Loss :  0.006306049037310813  Rel. Test L2 Loss :  0.007527128793299198  Test L2 Loss :  0.013788476511836052  inv_L_scale:  [1.0, 1.0]
Epoch :  397  Time:  2.574  Rel. Train L2 Loss :  0.006205748379644421  Rel. Test L2 Loss :  0.007486793082207442  Test L2 Loss :  0.013765130639076233  inv_L_scale:  [1.0, 1.0]
Epoch :  398  Time:  2.575  Rel. Train L2 Loss :  0.00623393971266018  Rel. Test L2 Loss :  0.007710683532059193  Test L2 Loss :  0.01402854423969984  inv_L_scale:  [1.0, 1.0]
Epoch :  399  Time:  2.585  Rel. Train L2 Loss :  0.006188019348515404  Rel. Test L2 Loss :  0.007522901184856891  Test L2 Loss :  0.013808422349393367  inv_L_scale:  [1.0, 1.0]
Epoch :  400  Time:  2.582  Rel. Train L2 Loss :  0.006312979002379709  Rel. Test L2 Loss :  0.0073782592266798015  Test L2 Loss :  0.013532191589474678  inv_L_scale:  [1.0, 1.0]
Epoch :  401  Time:  2.568  Rel. Train L2 Loss :  0.006145948537935813  Rel. Test L2 Loss :  0.007374553866684437  Test L2 Loss :  0.013539798893034458  inv_L_scale:  [1.0, 1.0]
Epoch :  402  Time:  2.58  Rel. Train L2 Loss :  0.006162766615549723  Rel. Test L2 Loss :  0.007312836237251759  Test L2 Loss :  0.013388546407222748  inv_L_scale:  [1.0, 1.0]
Epoch :  403  Time:  2.582  Rel. Train L2 Loss :  0.0061669662812103825  Rel. Test L2 Loss :  0.007425579335540533  Test L2 Loss :  0.013631587475538253  inv_L_scale:  [1.0, 1.0]
Epoch :  404  Time:  2.588  Rel. Train L2 Loss :  0.006164393462240696  Rel. Test L2 Loss :  0.007313489057123661  Test L2 Loss :  0.01338429294526577  inv_L_scale:  [1.0, 1.0]
Epoch :  405  Time:  2.581  Rel. Train L2 Loss :  0.006087712537911203  Rel. Test L2 Loss :  0.007643376737833023  Test L2 Loss :  0.014010952785611153  inv_L_scale:  [1.0, 1.0]
Epoch :  406  Time:  2.58  Rel. Train L2 Loss :  0.006155908664481507  Rel. Test L2 Loss :  0.007232153564691543  Test L2 Loss :  0.013283938206732272  inv_L_scale:  [1.0, 1.0]
Epoch :  407  Time:  2.578  Rel. Train L2 Loss :  0.006165593943248193  Rel. Test L2 Loss :  0.0072376222535967824  Test L2 Loss :  0.013253776282072067  inv_L_scale:  [1.0, 1.0]
Epoch :  408  Time:  2.58  Rel. Train L2 Loss :  0.006167019059260686  Rel. Test L2 Loss :  0.007520158402621746  Test L2 Loss :  0.013741845414042473  inv_L_scale:  [1.0, 1.0]
Epoch :  409  Time:  2.579  Rel. Train L2 Loss :  0.006160765516882142  Rel. Test L2 Loss :  0.007338877152651548  Test L2 Loss :  0.013474164046347142  inv_L_scale:  [1.0, 1.0]
Epoch :  410  Time:  2.581  Rel. Train L2 Loss :  0.006176424301746819  Rel. Test L2 Loss :  0.0075495681539177895  Test L2 Loss :  0.013831740356981754  inv_L_scale:  [1.0, 1.0]
Epoch :  411  Time:  2.574  Rel. Train L2 Loss :  0.006142388681570689  Rel. Test L2 Loss :  0.007363622728735209  Test L2 Loss :  0.013518731743097305  inv_L_scale:  [1.0, 1.0]
Epoch :  412  Time:  2.581  Rel. Train L2 Loss :  0.00608714762247271  Rel. Test L2 Loss :  0.007410054951906204  Test L2 Loss :  0.01355753656476736  inv_L_scale:  [1.0, 1.0]
Epoch :  413  Time:  2.571  Rel. Train L2 Loss :  0.006034057606011629  Rel. Test L2 Loss :  0.007187387961894273  Test L2 Loss :  0.013229092620313167  inv_L_scale:  [1.0, 1.0]
Epoch :  414  Time:  2.575  Rel. Train L2 Loss :  0.006061606800390615  Rel. Test L2 Loss :  0.007305923588573932  Test L2 Loss :  0.013411760851740838  inv_L_scale:  [1.0, 1.0]
Epoch :  415  Time:  2.581  Rel. Train L2 Loss :  0.006056154072284698  Rel. Test L2 Loss :  0.007296817153692245  Test L2 Loss :  0.013328156247735024  inv_L_scale:  [1.0, 1.0]
Epoch :  416  Time:  2.581  Rel. Train L2 Loss :  0.00598133220233851  Rel. Test L2 Loss :  0.007406421527266502  Test L2 Loss :  0.013625144474208355  inv_L_scale:  [1.0, 1.0]
Epoch :  417  Time:  2.59  Rel. Train L2 Loss :  0.006091050472524431  Rel. Test L2 Loss :  0.007289447896182537  Test L2 Loss :  0.01333928931504488  inv_L_scale:  [1.0, 1.0]
Epoch :  418  Time:  2.576  Rel. Train L2 Loss :  0.005993088425861465  Rel. Test L2 Loss :  0.0072145402058959  Test L2 Loss :  0.013262804225087165  inv_L_scale:  [1.0, 1.0]
Epoch :  419  Time:  2.575  Rel. Train L2 Loss :  0.0059444023213452764  Rel. Test L2 Loss :  0.007205889299511909  Test L2 Loss :  0.013220212161540986  inv_L_scale:  [1.0, 1.0]
Epoch :  420  Time:  2.58  Rel. Train L2 Loss :  0.005944485306325886  Rel. Test L2 Loss :  0.0072235757112503055  Test L2 Loss :  0.013296703770756722  inv_L_scale:  [1.0, 1.0]
Epoch :  421  Time:  2.576  Rel. Train L2 Loss :  0.005906147498430477  Rel. Test L2 Loss :  0.00707310188561678  Test L2 Loss :  0.013002562448382377  inv_L_scale:  [1.0, 1.0]
Epoch :  422  Time:  2.57  Rel. Train L2 Loss :  0.00592953863243262  Rel. Test L2 Loss :  0.007244240026921034  Test L2 Loss :  0.013400330692529678  inv_L_scale:  [1.0, 1.0]
Epoch :  423  Time:  2.582  Rel. Train L2 Loss :  0.005859477180573675  Rel. Test L2 Loss :  0.007117240987718106  Test L2 Loss :  0.013067481517791748  inv_L_scale:  [1.0, 1.0]
Epoch :  424  Time:  2.581  Rel. Train L2 Loss :  0.005854698961807622  Rel. Test L2 Loss :  0.007159631196409464  Test L2 Loss :  0.013142468929290772  inv_L_scale:  [1.0, 1.0]
Epoch :  425  Time:  2.579  Rel. Train L2 Loss :  0.005819269342141019  Rel. Test L2 Loss :  0.007085498180240393  Test L2 Loss :  0.01301458328962326  inv_L_scale:  [1.0, 1.0]
Epoch :  426  Time:  2.584  Rel. Train L2 Loss :  0.005826632525357935  Rel. Test L2 Loss :  0.007097721360623837  Test L2 Loss :  0.012978907823562622  inv_L_scale:  [1.0, 1.0]
Epoch :  427  Time:  2.581  Rel. Train L2 Loss :  0.005826174536099037  Rel. Test L2 Loss :  0.007078637480735779  Test L2 Loss :  0.013012285828590393  inv_L_scale:  [1.0, 1.0]
Epoch :  428  Time:  2.58  Rel. Train L2 Loss :  0.005848356400512986  Rel. Test L2 Loss :  0.007011284958571196  Test L2 Loss :  0.012865182161331177  inv_L_scale:  [1.0, 1.0]
Epoch :  429  Time:  2.584  Rel. Train L2 Loss :  0.005813067820337084  Rel. Test L2 Loss :  0.0070812788233160975  Test L2 Loss :  0.01297527812421322  inv_L_scale:  [1.0, 1.0]
Epoch :  430  Time:  2.579  Rel. Train L2 Loss :  0.005790701415389776  Rel. Test L2 Loss :  0.006998360324651003  Test L2 Loss :  0.012826672606170177  inv_L_scale:  [1.0, 1.0]
Epoch :  431  Time:  2.58  Rel. Train L2 Loss :  0.0057253447423378625  Rel. Test L2 Loss :  0.007028050385415554  Test L2 Loss :  0.012867910452187062  inv_L_scale:  [1.0, 1.0]
Epoch :  432  Time:  2.595  Rel. Train L2 Loss :  0.005757243302133348  Rel. Test L2 Loss :  0.007088757157325745  Test L2 Loss :  0.012997707836329937  inv_L_scale:  [1.0, 1.0]
Epoch :  433  Time:  2.587  Rel. Train L2 Loss :  0.005731007272584571  Rel. Test L2 Loss :  0.00694276062771678  Test L2 Loss :  0.012719012163579464  inv_L_scale:  [1.0, 1.0]
Epoch :  434  Time:  2.572  Rel. Train L2 Loss :  0.005669035721156332  Rel. Test L2 Loss :  0.006978089436888695  Test L2 Loss :  0.012795386873185634  inv_L_scale:  [1.0, 1.0]
Epoch :  435  Time:  2.58  Rel. Train L2 Loss :  0.0056727310456335545  Rel. Test L2 Loss :  0.006926479749381542  Test L2 Loss :  0.012693060152232647  inv_L_scale:  [1.0, 1.0]
Epoch :  436  Time:  2.586  Rel. Train L2 Loss :  0.005665326979425218  Rel. Test L2 Loss :  0.007024459950625897  Test L2 Loss :  0.012867456562817096  inv_L_scale:  [1.0, 1.0]
Epoch :  437  Time:  2.589  Rel. Train L2 Loss :  0.005713982350296444  Rel. Test L2 Loss :  0.006995164062827825  Test L2 Loss :  0.01283972978591919  inv_L_scale:  [1.0, 1.0]
Epoch :  438  Time:  2.586  Rel. Train L2 Loss :  0.005663927106393708  Rel. Test L2 Loss :  0.006916799619793892  Test L2 Loss :  0.012682318948209285  inv_L_scale:  [1.0, 1.0]
Epoch :  439  Time:  2.594  Rel. Train L2 Loss :  0.005638170534123977  Rel. Test L2 Loss :  0.0069425304606556895  Test L2 Loss :  0.01271444670855999  inv_L_scale:  [1.0, 1.0]
Epoch :  440  Time:  2.595  Rel. Train L2 Loss :  0.005633802639527453  Rel. Test L2 Loss :  0.006908861957490444  Test L2 Loss :  0.012651691697537899  inv_L_scale:  [1.0, 1.0]
Epoch :  441  Time:  2.59  Rel. Train L2 Loss :  0.005644952998393112  Rel. Test L2 Loss :  0.006879138462245464  Test L2 Loss :  0.012586451694369316  inv_L_scale:  [1.0, 1.0]
Epoch :  442  Time:  2.583  Rel. Train L2 Loss :  0.005610038119678696  Rel. Test L2 Loss :  0.006913489606231451  Test L2 Loss :  0.01265535555779934  inv_L_scale:  [1.0, 1.0]
Epoch :  443  Time:  2.577  Rel. Train L2 Loss :  0.00562885298497147  Rel. Test L2 Loss :  0.006907922588288784  Test L2 Loss :  0.012649137824773789  inv_L_scale:  [1.0, 1.0]
Epoch :  444  Time:  2.591  Rel. Train L2 Loss :  0.005582224625266261  Rel. Test L2 Loss :  0.006850049756467342  Test L2 Loss :  0.01252722404897213  inv_L_scale:  [1.0, 1.0]
Epoch :  445  Time:  2.6  Rel. Train L2 Loss :  0.005573006766951746  Rel. Test L2 Loss :  0.0069038189575076105  Test L2 Loss :  0.01261992633342743  inv_L_scale:  [1.0, 1.0]
Epoch :  446  Time:  2.585  Rel. Train L2 Loss :  0.005581282528324259  Rel. Test L2 Loss :  0.006823883578181267  Test L2 Loss :  0.012502327561378479  inv_L_scale:  [1.0, 1.0]
Epoch :  447  Time:  2.596  Rel. Train L2 Loss :  0.005535460654646158  Rel. Test L2 Loss :  0.006820591203868389  Test L2 Loss :  0.01247921697795391  inv_L_scale:  [1.0, 1.0]
Epoch :  448  Time:  2.596  Rel. Train L2 Loss :  0.005538528113522463  Rel. Test L2 Loss :  0.006863506715744734  Test L2 Loss :  0.012544699609279633  inv_L_scale:  [1.0, 1.0]
Epoch :  449  Time:  2.587  Rel. Train L2 Loss :  0.005534214520206054  Rel. Test L2 Loss :  0.006808123849332333  Test L2 Loss :  0.012472989782691003  inv_L_scale:  [1.0, 1.0]
Epoch :  450  Time:  2.604  Rel. Train L2 Loss :  0.005525232667310371  Rel. Test L2 Loss :  0.006824855506420135  Test L2 Loss :  0.0124937404692173  inv_L_scale:  [1.0, 1.0]
Epoch :  451  Time:  2.601  Rel. Train L2 Loss :  0.0055293645440704295  Rel. Test L2 Loss :  0.006831847056746483  Test L2 Loss :  0.012533691301941872  inv_L_scale:  [1.0, 1.0]
Epoch :  452  Time:  2.598  Rel. Train L2 Loss :  0.0055462555752860175  Rel. Test L2 Loss :  0.0068251252919435505  Test L2 Loss :  0.012537949755787849  inv_L_scale:  [1.0, 1.0]
Epoch :  453  Time:  2.605  Rel. Train L2 Loss :  0.005508628306496475  Rel. Test L2 Loss :  0.006821359135210514  Test L2 Loss :  0.012496927045285702  inv_L_scale:  [1.0, 1.0]
Epoch :  454  Time:  2.603  Rel. Train L2 Loss :  0.005501276568199197  Rel. Test L2 Loss :  0.006782148890197277  Test L2 Loss :  0.012422176077961922  inv_L_scale:  [1.0, 1.0]
Epoch :  455  Time:  2.606  Rel. Train L2 Loss :  0.005506699917217096  Rel. Test L2 Loss :  0.006757011897861958  Test L2 Loss :  0.012383588962256909  inv_L_scale:  [1.0, 1.0]
Epoch :  456  Time:  2.603  Rel. Train L2 Loss :  0.005474307216289971  Rel. Test L2 Loss :  0.006728918813169002  Test L2 Loss :  0.01234947882592678  inv_L_scale:  [1.0, 1.0]
Epoch :  457  Time:  2.597  Rel. Train L2 Loss :  0.005456820935424832  Rel. Test L2 Loss :  0.006722549572587013  Test L2 Loss :  0.012325216457247734  inv_L_scale:  [1.0, 1.0]
Epoch :  458  Time:  2.586  Rel. Train L2 Loss :  0.005457298648026254  Rel. Test L2 Loss :  0.006720054168254137  Test L2 Loss :  0.012308212332427501  inv_L_scale:  [1.0, 1.0]
Epoch :  459  Time:  2.584  Rel. Train L2 Loss :  0.005448347344580624  Rel. Test L2 Loss :  0.00670791782438755  Test L2 Loss :  0.012295260801911354  inv_L_scale:  [1.0, 1.0]
Epoch :  460  Time:  2.585  Rel. Train L2 Loss :  0.005435506275130643  Rel. Test L2 Loss :  0.006741562783718109  Test L2 Loss :  0.01234590496867895  inv_L_scale:  [1.0, 1.0]
Epoch :  461  Time:  2.572  Rel. Train L2 Loss :  0.00543851051479578  Rel. Test L2 Loss :  0.006734417024999857  Test L2 Loss :  0.012348299361765385  inv_L_scale:  [1.0, 1.0]
Epoch :  462  Time:  2.59  Rel. Train L2 Loss :  0.0054257233461572065  Rel. Test L2 Loss :  0.006737889051437378  Test L2 Loss :  0.01234718520194292  inv_L_scale:  [1.0, 1.0]
Epoch :  463  Time:  2.578  Rel. Train L2 Loss :  0.005414353617363506  Rel. Test L2 Loss :  0.006710279788821935  Test L2 Loss :  0.012289198078215123  inv_L_scale:  [1.0, 1.0]
Epoch :  464  Time:  2.579  Rel. Train L2 Loss :  0.005412285329980983  Rel. Test L2 Loss :  0.006693835817277432  Test L2 Loss :  0.012255781926214696  inv_L_scale:  [1.0, 1.0]
Epoch :  465  Time:  2.584  Rel. Train L2 Loss :  0.005397824193868373  Rel. Test L2 Loss :  0.006680890619754791  Test L2 Loss :  0.012243696376681329  inv_L_scale:  [1.0, 1.0]
Epoch :  466  Time:  2.591  Rel. Train L2 Loss :  0.005401027782095803  Rel. Test L2 Loss :  0.006693405713886023  Test L2 Loss :  0.012251072376966477  inv_L_scale:  [1.0, 1.0]
Epoch :  467  Time:  2.578  Rel. Train L2 Loss :  0.005390550296546684  Rel. Test L2 Loss :  0.006727460399270057  Test L2 Loss :  0.012335621081292629  inv_L_scale:  [1.0, 1.0]
Epoch :  468  Time:  2.588  Rel. Train L2 Loss :  0.005393181679149469  Rel. Test L2 Loss :  0.006668130084872246  Test L2 Loss :  0.012221749983727931  inv_L_scale:  [1.0, 1.0]
Epoch :  469  Time:  2.586  Rel. Train L2 Loss :  0.00537326393648982  Rel. Test L2 Loss :  0.006665486879646778  Test L2 Loss :  0.012214984819293022  inv_L_scale:  [1.0, 1.0]
Epoch :  470  Time:  2.575  Rel. Train L2 Loss :  0.005377947804000642  Rel. Test L2 Loss :  0.006684433184564114  Test L2 Loss :  0.012255112379789353  inv_L_scale:  [1.0, 1.0]
Epoch :  471  Time:  2.593  Rel. Train L2 Loss :  0.0053642114645077125  Rel. Test L2 Loss :  0.006640381682664156  Test L2 Loss :  0.012171872779726983  inv_L_scale:  [1.0, 1.0]
Epoch :  472  Time:  2.594  Rel. Train L2 Loss :  0.00536298266508513  Rel. Test L2 Loss :  0.006666410695761443  Test L2 Loss :  0.012212259583175183  inv_L_scale:  [1.0, 1.0]
Epoch :  473  Time:  2.58  Rel. Train L2 Loss :  0.005356612642192178  Rel. Test L2 Loss :  0.006668011844158173  Test L2 Loss :  0.012232553921639919  inv_L_scale:  [1.0, 1.0]
Epoch :  474  Time:  2.581  Rel. Train L2 Loss :  0.005352715549783574  Rel. Test L2 Loss :  0.006633059065788985  Test L2 Loss :  0.012155072465538978  inv_L_scale:  [1.0, 1.0]
Epoch :  475  Time:  2.584  Rel. Train L2 Loss :  0.005347282773711615  Rel. Test L2 Loss :  0.006659068036824465  Test L2 Loss :  0.012200495973229409  inv_L_scale:  [1.0, 1.0]
Epoch :  476  Time:  2.589  Rel. Train L2 Loss :  0.005342034678906202  Rel. Test L2 Loss :  0.006655507516115904  Test L2 Loss :  0.012195325568318366  inv_L_scale:  [1.0, 1.0]
Epoch :  477  Time:  2.529  Rel. Train L2 Loss :  0.005338182176152865  Rel. Test L2 Loss :  0.006658135373145342  Test L2 Loss :  0.012197846621274948  inv_L_scale:  [1.0, 1.0]
Epoch :  478  Time:  2.526  Rel. Train L2 Loss :  0.005336164896272951  Rel. Test L2 Loss :  0.006647375486791134  Test L2 Loss :  0.0121840787678957  inv_L_scale:  [1.0, 1.0]
Epoch :  479  Time:  2.606  Rel. Train L2 Loss :  0.005332339213540157  Rel. Test L2 Loss :  0.00663852846249938  Test L2 Loss :  0.01216790933161974  inv_L_scale:  [1.0, 1.0]
Epoch :  480  Time:  2.585  Rel. Train L2 Loss :  0.005326955356738634  Rel. Test L2 Loss :  0.006644101329147816  Test L2 Loss :  0.012174688503146172  inv_L_scale:  [1.0, 1.0]
Epoch :  481  Time:  2.598  Rel. Train L2 Loss :  0.005321062643908792  Rel. Test L2 Loss :  0.006652553901076317  Test L2 Loss :  0.01217989906668663  inv_L_scale:  [1.0, 1.0]
Epoch :  482  Time:  2.597  Rel. Train L2 Loss :  0.005317931661589278  Rel. Test L2 Loss :  0.006643763668835163  Test L2 Loss :  0.012175338752567768  inv_L_scale:  [1.0, 1.0]
Epoch :  483  Time:  2.594  Rel. Train L2 Loss :  0.005312858869632085  Rel. Test L2 Loss :  0.006635794267058372  Test L2 Loss :  0.012165386863052845  inv_L_scale:  [1.0, 1.0]
Epoch :  484  Time:  2.597  Rel. Train L2 Loss :  0.005312924095326  Rel. Test L2 Loss :  0.006634575873613357  Test L2 Loss :  0.012161935903131962  inv_L_scale:  [1.0, 1.0]
Epoch :  485  Time:  2.613  Rel. Train L2 Loss :  0.005308505499528514  Rel. Test L2 Loss :  0.006627296693623066  Test L2 Loss :  0.012147761546075345  inv_L_scale:  [1.0, 1.0]
Epoch :  486  Time:  2.599  Rel. Train L2 Loss :  0.005308982947220405  Rel. Test L2 Loss :  0.006632340587675572  Test L2 Loss :  0.012148780934512615  inv_L_scale:  [1.0, 1.0]
Epoch :  487  Time:  2.579  Rel. Train L2 Loss :  0.0053035949067109164  Rel. Test L2 Loss :  0.0066258198581635955  Test L2 Loss :  0.012138496786355972  inv_L_scale:  [1.0, 1.0]
Epoch :  488  Time:  2.571  Rel. Train L2 Loss :  0.005300396413852771  Rel. Test L2 Loss :  0.0066287627816200255  Test L2 Loss :  0.01215079601854086  inv_L_scale:  [1.0, 1.0]
Epoch :  489  Time:  2.603  Rel. Train L2 Loss :  0.005300972786628538  Rel. Test L2 Loss :  0.006624688953161239  Test L2 Loss :  0.012142051085829735  inv_L_scale:  [1.0, 1.0]
Epoch :  490  Time:  2.585  Rel. Train L2 Loss :  0.005297453585598204  Rel. Test L2 Loss :  0.00662441922351718  Test L2 Loss :  0.012139717675745487  inv_L_scale:  [1.0, 1.0]
Epoch :  491  Time:  2.599  Rel. Train L2 Loss :  0.005293930023908615  Rel. Test L2 Loss :  0.006626716554164886  Test L2 Loss :  0.01213613286614418  inv_L_scale:  [1.0, 1.0]
Epoch :  492  Time:  2.588  Rel. Train L2 Loss :  0.005289837705592314  Rel. Test L2 Loss :  0.006614228375256061  Test L2 Loss :  0.012115464806556701  inv_L_scale:  [1.0, 1.0]
Epoch :  493  Time:  2.563  Rel. Train L2 Loss :  0.005290868247134818  Rel. Test L2 Loss :  0.00661650525406003  Test L2 Loss :  0.012130362316966056  inv_L_scale:  [1.0, 1.0]
Epoch :  494  Time:  2.568  Rel. Train L2 Loss :  0.005286271344456407  Rel. Test L2 Loss :  0.00661260612308979  Test L2 Loss :  0.012117542885243892  inv_L_scale:  [1.0, 1.0]
Epoch :  495  Time:  2.6  Rel. Train L2 Loss :  0.0052844298941393695  Rel. Test L2 Loss :  0.006624403987079859  Test L2 Loss :  0.012135199531912803  inv_L_scale:  [1.0, 1.0]
Epoch :  496  Time:  2.587  Rel. Train L2 Loss :  0.005288219586428669  Rel. Test L2 Loss :  0.00663404781371355  Test L2 Loss :  0.012144891396164894  inv_L_scale:  [1.0, 1.0]
Epoch :  497  Time:  2.582  Rel. Train L2 Loss :  0.00528531115502119  Rel. Test L2 Loss :  0.006617669276893139  Test L2 Loss :  0.012126730345189572  inv_L_scale:  [1.0, 1.0]
Epoch :  498  Time:  2.582  Rel. Train L2 Loss :  0.005285265162173244  Rel. Test L2 Loss :  0.006616161409765482  Test L2 Loss :  0.012124980688095094  inv_L_scale:  [1.0, 1.0]
Epoch :  499  Time:  2.589  Rel. Train L2 Loss :  0.0052857470595174365  Rel. Test L2 Loss :  0.006618723385035992  Test L2 Loss :  0.012127136550843716  inv_L_scale:  [1.0, 1.0]
