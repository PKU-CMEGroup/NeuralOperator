x1 = speconv(fn, bases_c, bases_s, bases_0, wbases_c, wbases_s, wbases_0)
x2 = w(f)
x3 = gw(self.softsign(compute_gradient(x, directed_edges, edge_gradient_weights)))

(1000,) (1000, 1000, 1) (1000, 1000, 2)
use normalized raw measures
Casting to tensor
x_train shape torch.Size([900, 1000, 8]), y_train shape torch.Size([900, 1000, 1])
length of each dim:  tensor([6.5573987960815430, 6.1420288085937500])
kmax = 16
L = 10
geo_dims = [1, 2, 3, 4]
In PCNO_train, ndims =  2
Epoch :  0  Time:  1.634  Rel. Train L2 Loss :  0.48311753816074793  Rel. Test L2 Loss :  0.26884896159172056  Test L2 Loss :  0.3803399813175201  inv_L_scale:  [1.0, 1.0]
Epoch :  1  Time:  1.269  Rel. Train L2 Loss :  0.21668930768966674  Rel. Test L2 Loss :  0.16212763786315917  Test L2 Loss :  0.22816917777061463  inv_L_scale:  [1.0, 1.0]
Epoch :  2  Time:  1.291  Rel. Train L2 Loss :  0.14803322911262512  Rel. Test L2 Loss :  0.13155632793903352  Test L2 Loss :  0.18703231811523438  inv_L_scale:  [1.0, 1.0]
Epoch :  3  Time:  1.267  Rel. Train L2 Loss :  0.13102376447783576  Rel. Test L2 Loss :  0.12312703669071197  Test L2 Loss :  0.177098987698555  inv_L_scale:  [1.0, 1.0]
Epoch :  4  Time:  1.268  Rel. Train L2 Loss :  0.12215367356936137  Rel. Test L2 Loss :  0.12194821357727051  Test L2 Loss :  0.17471258401870726  inv_L_scale:  [1.0, 1.0]
Epoch :  5  Time:  1.294  Rel. Train L2 Loss :  0.11679805530442132  Rel. Test L2 Loss :  0.10876126527786255  Test L2 Loss :  0.15550581812858583  inv_L_scale:  [1.0, 1.0]
Epoch :  6  Time:  1.317  Rel. Train L2 Loss :  0.11334917075104184  Rel. Test L2 Loss :  0.10794117510318756  Test L2 Loss :  0.15516702175140382  inv_L_scale:  [1.0, 1.0]
Epoch :  7  Time:  1.282  Rel. Train L2 Loss :  0.11034531768825319  Rel. Test L2 Loss :  0.10636471271514893  Test L2 Loss :  0.1523108959197998  inv_L_scale:  [1.0, 1.0]
Epoch :  8  Time:  1.281  Rel. Train L2 Loss :  0.10495032757520675  Rel. Test L2 Loss :  0.1023818951845169  Test L2 Loss :  0.14706348657608032  inv_L_scale:  [1.0, 1.0]
Epoch :  9  Time:  1.272  Rel. Train L2 Loss :  0.10275194101863437  Rel. Test L2 Loss :  0.10286446332931519  Test L2 Loss :  0.1476893252134323  inv_L_scale:  [1.0, 1.0]
Epoch :  10  Time:  1.273  Rel. Train L2 Loss :  0.10200945132308537  Rel. Test L2 Loss :  0.10095544219017029  Test L2 Loss :  0.1446869069337845  inv_L_scale:  [1.0, 1.0]
Epoch :  11  Time:  1.272  Rel. Train L2 Loss :  0.10180701024002499  Rel. Test L2 Loss :  0.10614972412586213  Test L2 Loss :  0.15243639171123505  inv_L_scale:  [1.0, 1.0]
Epoch :  12  Time:  1.278  Rel. Train L2 Loss :  0.09876949634816912  Rel. Test L2 Loss :  0.1002867865562439  Test L2 Loss :  0.14295272707939147  inv_L_scale:  [1.0, 1.0]
Epoch :  13  Time:  1.275  Rel. Train L2 Loss :  0.0993658149904675  Rel. Test L2 Loss :  0.09933242112398148  Test L2 Loss :  0.14298530280590058  inv_L_scale:  [1.0, 1.0]
Epoch :  14  Time:  1.273  Rel. Train L2 Loss :  0.09706099102894465  Rel. Test L2 Loss :  0.09443721204996108  Test L2 Loss :  0.13473336160182953  inv_L_scale:  [1.0, 1.0]
Epoch :  15  Time:  1.27  Rel. Train L2 Loss :  0.09580352524916332  Rel. Test L2 Loss :  0.1004338675737381  Test L2 Loss :  0.1422071325778961  inv_L_scale:  [1.0, 1.0]
Epoch :  16  Time:  1.27  Rel. Train L2 Loss :  0.09412413232856327  Rel. Test L2 Loss :  0.09463706374168396  Test L2 Loss :  0.13550453305244445  inv_L_scale:  [1.0, 1.0]
Epoch :  17  Time:  1.296  Rel. Train L2 Loss :  0.09493145806921853  Rel. Test L2 Loss :  0.09400230139493942  Test L2 Loss :  0.1345391571521759  inv_L_scale:  [1.0, 1.0]
Epoch :  18  Time:  1.278  Rel. Train L2 Loss :  0.09274408330519994  Rel. Test L2 Loss :  0.09178773373365402  Test L2 Loss :  0.13163708209991454  inv_L_scale:  [1.0, 1.0]
Epoch :  19  Time:  1.293  Rel. Train L2 Loss :  0.09189777731895447  Rel. Test L2 Loss :  0.08972424864768982  Test L2 Loss :  0.1285812649130821  inv_L_scale:  [1.0, 1.0]
Epoch :  20  Time:  1.3  Rel. Train L2 Loss :  0.09226870132817162  Rel. Test L2 Loss :  0.09245988100767136  Test L2 Loss :  0.13249516665935515  inv_L_scale:  [1.0, 1.0]
Epoch :  21  Time:  1.281  Rel. Train L2 Loss :  0.0903776968187756  Rel. Test L2 Loss :  0.09097082078456879  Test L2 Loss :  0.1311410313844681  inv_L_scale:  [1.0, 1.0]
Epoch :  22  Time:  1.276  Rel. Train L2 Loss :  0.09205438782771429  Rel. Test L2 Loss :  0.08950563788414001  Test L2 Loss :  0.12853300392627717  inv_L_scale:  [1.0, 1.0]
Epoch :  23  Time:  1.273  Rel. Train L2 Loss :  0.08930991990698708  Rel. Test L2 Loss :  0.0896617141366005  Test L2 Loss :  0.12890528351068498  inv_L_scale:  [1.0, 1.0]
Epoch :  24  Time:  1.31  Rel. Train L2 Loss :  0.08903969052765104  Rel. Test L2 Loss :  0.0891387265920639  Test L2 Loss :  0.1277223601937294  inv_L_scale:  [1.0, 1.0]
Epoch :  25  Time:  1.296  Rel. Train L2 Loss :  0.08777352962228988  Rel. Test L2 Loss :  0.08715141087770462  Test L2 Loss :  0.12513868480920792  inv_L_scale:  [1.0, 1.0]
Epoch :  26  Time:  1.318  Rel. Train L2 Loss :  0.08918327632877562  Rel. Test L2 Loss :  0.08937563717365266  Test L2 Loss :  0.12774450421333314  inv_L_scale:  [1.0, 1.0]
Epoch :  27  Time:  1.295  Rel. Train L2 Loss :  0.08865363829665714  Rel. Test L2 Loss :  0.0879759156703949  Test L2 Loss :  0.12615648716688155  inv_L_scale:  [1.0, 1.0]
Epoch :  28  Time:  1.291  Rel. Train L2 Loss :  0.08940833194388284  Rel. Test L2 Loss :  0.08647508323192596  Test L2 Loss :  0.12385929465293884  inv_L_scale:  [1.0, 1.0]
Epoch :  29  Time:  1.322  Rel. Train L2 Loss :  0.08654440330134498  Rel. Test L2 Loss :  0.08740512549877166  Test L2 Loss :  0.12507169872522353  inv_L_scale:  [1.0, 1.0]
Epoch :  30  Time:  1.299  Rel. Train L2 Loss :  0.08709662917587492  Rel. Test L2 Loss :  0.08640499591827393  Test L2 Loss :  0.12432540535926818  inv_L_scale:  [1.0, 1.0]
Epoch :  31  Time:  1.285  Rel. Train L2 Loss :  0.08793362730079227  Rel. Test L2 Loss :  0.08885280668735504  Test L2 Loss :  0.1279434096813202  inv_L_scale:  [1.0, 1.0]
Epoch :  32  Time:  1.286  Rel. Train L2 Loss :  0.08708310418658786  Rel. Test L2 Loss :  0.08873949944972992  Test L2 Loss :  0.1274123215675354  inv_L_scale:  [1.0, 1.0]
Epoch :  33  Time:  1.294  Rel. Train L2 Loss :  0.0858753052022722  Rel. Test L2 Loss :  0.08695449739694595  Test L2 Loss :  0.1253034567832947  inv_L_scale:  [1.0, 1.0]
Epoch :  34  Time:  1.288  Rel. Train L2 Loss :  0.08772415591610802  Rel. Test L2 Loss :  0.08857337355613709  Test L2 Loss :  0.12745563328266143  inv_L_scale:  [1.0, 1.0]
Epoch :  35  Time:  1.288  Rel. Train L2 Loss :  0.08590016331937578  Rel. Test L2 Loss :  0.08651978105306625  Test L2 Loss :  0.12423835217952728  inv_L_scale:  [1.0, 1.0]
Epoch :  36  Time:  1.322  Rel. Train L2 Loss :  0.08560386114650302  Rel. Test L2 Loss :  0.08794853329658509  Test L2 Loss :  0.12627009063959121  inv_L_scale:  [1.0, 1.0]
Epoch :  37  Time:  1.34  Rel. Train L2 Loss :  0.08966951840453678  Rel. Test L2 Loss :  0.10197149336338043  Test L2 Loss :  0.1493491107225418  inv_L_scale:  [1.0, 1.0]
Epoch :  38  Time:  1.289  Rel. Train L2 Loss :  0.08868318385548062  Rel. Test L2 Loss :  0.08735698103904724  Test L2 Loss :  0.12646127462387086  inv_L_scale:  [1.0, 1.0]
Epoch :  39  Time:  1.292  Rel. Train L2 Loss :  0.08552489972776837  Rel. Test L2 Loss :  0.08671558290719986  Test L2 Loss :  0.12444686859846116  inv_L_scale:  [1.0, 1.0]
Epoch :  40  Time:  1.322  Rel. Train L2 Loss :  0.08527707053555382  Rel. Test L2 Loss :  0.08535431534051895  Test L2 Loss :  0.12207828640937805  inv_L_scale:  [1.0, 1.0]
Epoch :  41  Time:  1.265  Rel. Train L2 Loss :  0.08382311178578271  Rel. Test L2 Loss :  0.08234458744525909  Test L2 Loss :  0.118555566072464  inv_L_scale:  [1.0, 1.0]
Epoch :  42  Time:  1.261  Rel. Train L2 Loss :  0.08524849699603186  Rel. Test L2 Loss :  0.08847034990787506  Test L2 Loss :  0.12663258850574494  inv_L_scale:  [1.0, 1.0]
Epoch :  43  Time:  1.265  Rel. Train L2 Loss :  0.08478996369573805  Rel. Test L2 Loss :  0.08675462454557419  Test L2 Loss :  0.12510520845651626  inv_L_scale:  [1.0, 1.0]
Epoch :  44  Time:  1.264  Rel. Train L2 Loss :  0.08691012902392281  Rel. Test L2 Loss :  0.08964028179645539  Test L2 Loss :  0.12975900053977965  inv_L_scale:  [1.0, 1.0]
Epoch :  45  Time:  1.262  Rel. Train L2 Loss :  0.08486813174353705  Rel. Test L2 Loss :  0.08472432076931  Test L2 Loss :  0.12160509884357452  inv_L_scale:  [1.0, 1.0]
Epoch :  46  Time:  1.264  Rel. Train L2 Loss :  0.08467575993802812  Rel. Test L2 Loss :  0.08535113275051116  Test L2 Loss :  0.12205708980560302  inv_L_scale:  [1.0, 1.0]
Epoch :  47  Time:  1.263  Rel. Train L2 Loss :  0.08438839700486925  Rel. Test L2 Loss :  0.08297034204006196  Test L2 Loss :  0.11887075513601303  inv_L_scale:  [1.0, 1.0]
Epoch :  48  Time:  1.262  Rel. Train L2 Loss :  0.08484474543068143  Rel. Test L2 Loss :  0.08847426056861878  Test L2 Loss :  0.12656329095363616  inv_L_scale:  [1.0, 1.0]
Epoch :  49  Time:  1.262  Rel. Train L2 Loss :  0.08476928638087379  Rel. Test L2 Loss :  0.08704746365547181  Test L2 Loss :  0.12461927890777588  inv_L_scale:  [1.0, 1.0]
Epoch :  50  Time:  1.264  Rel. Train L2 Loss :  0.08395131169093979  Rel. Test L2 Loss :  0.08248399674892426  Test L2 Loss :  0.11857112497091293  inv_L_scale:  [1.0, 1.0]
