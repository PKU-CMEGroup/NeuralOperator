Loading data from  ../../data/curve//pcno_curve_data_1_1_5_5_stokes.npz
(1000,) (1000, 1000, 1) (1000, 1000, 2)
use normalized raw measures
Casting to tensor
x_train shape torch.Size([900, 1000, 6]), y_train shape torch.Size([900, 1000, 1])
length of each dim:  tensor([6.6455335617065430, 6.6654777526855469])
kmax = 16
L = 14
geo_dims = [1, 2, 3, 4], num_grad = 3
In PCNO_train, ndims =  2
Epoch :  0  Time:  1.562  Rel. Train L2 Loss :  0.4082574692699644  Rel. Test L2 Loss :  0.23544164538383483  Test L2 Loss :  0.44870553016662595  inv_L_scale:  [1.0, 1.0]
Epoch :  1  Time:  1.113  Rel. Train L2 Loss :  0.19443896949291228  Rel. Test L2 Loss :  0.1511497575044632  Test L2 Loss :  0.2812382364273071  inv_L_scale:  [1.0, 1.0]
Epoch :  2  Time:  1.111  Rel. Train L2 Loss :  0.13702849758995903  Rel. Test L2 Loss :  0.12561169862747193  Test L2 Loss :  0.23314206957817077  inv_L_scale:  [1.0, 1.0]
Epoch :  3  Time:  1.111  Rel. Train L2 Loss :  0.11689532399177552  Rel. Test L2 Loss :  0.10982534170150757  Test L2 Loss :  0.20510786771774292  inv_L_scale:  [1.0, 1.0]
Epoch :  4  Time:  1.109  Rel. Train L2 Loss :  0.10049754470586776  Rel. Test L2 Loss :  0.09793934166431427  Test L2 Loss :  0.17878913402557373  inv_L_scale:  [1.0, 1.0]
Epoch :  5  Time:  1.109  Rel. Train L2 Loss :  0.08831403017044068  Rel. Test L2 Loss :  0.09465113043785095  Test L2 Loss :  0.17233894109725953  inv_L_scale:  [1.0, 1.0]
Epoch :  6  Time:  1.106  Rel. Train L2 Loss :  0.08404922233687506  Rel. Test L2 Loss :  0.08404563009738922  Test L2 Loss :  0.1527470076084137  inv_L_scale:  [1.0, 1.0]
Epoch :  7  Time:  1.107  Rel. Train L2 Loss :  0.07795041501522064  Rel. Test L2 Loss :  0.07542585045099258  Test L2 Loss :  0.1367708534002304  inv_L_scale:  [1.0, 1.0]
Epoch :  8  Time:  1.11  Rel. Train L2 Loss :  0.07264473461442524  Rel. Test L2 Loss :  0.07809748381376266  Test L2 Loss :  0.14034691512584685  inv_L_scale:  [1.0, 1.0]
Epoch :  9  Time:  1.109  Rel. Train L2 Loss :  0.06844621519247691  Rel. Test L2 Loss :  0.07594252705574035  Test L2 Loss :  0.13684361517429353  inv_L_scale:  [1.0, 1.0]
Epoch :  10  Time:  1.109  Rel. Train L2 Loss :  0.06860170650813315  Rel. Test L2 Loss :  0.0712273146212101  Test L2 Loss :  0.1281012612581253  inv_L_scale:  [1.0, 1.0]
Epoch :  11  Time:  1.107  Rel. Train L2 Loss :  0.06309119476212395  Rel. Test L2 Loss :  0.06566729173064231  Test L2 Loss :  0.11982526987791062  inv_L_scale:  [1.0, 1.0]
Epoch :  12  Time:  1.108  Rel. Train L2 Loss :  0.06121164686150021  Rel. Test L2 Loss :  0.06477650582790374  Test L2 Loss :  0.11765403032302857  inv_L_scale:  [1.0, 1.0]
Epoch :  13  Time:  1.107  Rel. Train L2 Loss :  0.06126207169559267  Rel. Test L2 Loss :  0.06550829619169235  Test L2 Loss :  0.11863358527421951  inv_L_scale:  [1.0, 1.0]
Epoch :  14  Time:  1.11  Rel. Train L2 Loss :  0.05728897707329856  Rel. Test L2 Loss :  0.06691241055727006  Test L2 Loss :  0.11976123750209808  inv_L_scale:  [1.0, 1.0]
Epoch :  15  Time:  1.108  Rel. Train L2 Loss :  0.055814952585432266  Rel. Test L2 Loss :  0.06224594697356224  Test L2 Loss :  0.11315494447946549  inv_L_scale:  [1.0, 1.0]
Epoch :  16  Time:  1.105  Rel. Train L2 Loss :  0.05270905526147948  Rel. Test L2 Loss :  0.05581916704773903  Test L2 Loss :  0.09936188817024232  inv_L_scale:  [1.0, 1.0]
Epoch :  17  Time:  1.108  Rel. Train L2 Loss :  0.05278288644221094  Rel. Test L2 Loss :  0.059142800569534304  Test L2 Loss :  0.10552460253238678  inv_L_scale:  [1.0, 1.0]
Epoch :  18  Time:  1.109  Rel. Train L2 Loss :  0.049330034255981446  Rel. Test L2 Loss :  0.05647562101483345  Test L2 Loss :  0.10319900423288346  inv_L_scale:  [1.0, 1.0]
Epoch :  19  Time:  1.109  Rel. Train L2 Loss :  0.051457529266675316  Rel. Test L2 Loss :  0.0592691433429718  Test L2 Loss :  0.10915606498718261  inv_L_scale:  [1.0, 1.0]
Epoch :  20  Time:  1.109  Rel. Train L2 Loss :  0.04794196483161715  Rel. Test L2 Loss :  0.05484865128993988  Test L2 Loss :  0.09783040344715119  inv_L_scale:  [1.0, 1.0]
Epoch :  21  Time:  1.11  Rel. Train L2 Loss :  0.046688446948925655  Rel. Test L2 Loss :  0.05756373062729835  Test L2 Loss :  0.10192504525184631  inv_L_scale:  [1.0, 1.0]
Epoch :  22  Time:  1.108  Rel. Train L2 Loss :  0.04826022365027004  Rel. Test L2 Loss :  0.052875467240810395  Test L2 Loss :  0.0966618499159813  inv_L_scale:  [1.0, 1.0]
Epoch :  23  Time:  1.108  Rel. Train L2 Loss :  0.04537463974621561  Rel. Test L2 Loss :  0.04916620165109634  Test L2 Loss :  0.0883901470899582  inv_L_scale:  [1.0, 1.0]
Epoch :  24  Time:  1.109  Rel. Train L2 Loss :  0.045535133944617376  Rel. Test L2 Loss :  0.05236211240291595  Test L2 Loss :  0.0942590057849884  inv_L_scale:  [1.0, 1.0]
Epoch :  25  Time:  1.108  Rel. Train L2 Loss :  0.04580657919247945  Rel. Test L2 Loss :  0.05525179624557495  Test L2 Loss :  0.10108747422695159  inv_L_scale:  [1.0, 1.0]
Epoch :  26  Time:  1.109  Rel. Train L2 Loss :  0.04743290411101447  Rel. Test L2 Loss :  0.04640762358903885  Test L2 Loss :  0.08325258582830429  inv_L_scale:  [1.0, 1.0]
Epoch :  27  Time:  1.108  Rel. Train L2 Loss :  0.04507856531275643  Rel. Test L2 Loss :  0.05230997234582901  Test L2 Loss :  0.0961844739317894  inv_L_scale:  [1.0, 1.0]
Epoch :  28  Time:  1.108  Rel. Train L2 Loss :  0.04435229784912533  Rel. Test L2 Loss :  0.04949486643075943  Test L2 Loss :  0.08782485842704774  inv_L_scale:  [1.0, 1.0]
Epoch :  29  Time:  1.109  Rel. Train L2 Loss :  0.04358161012331645  Rel. Test L2 Loss :  0.04352203458547592  Test L2 Loss :  0.07915569126605987  inv_L_scale:  [1.0, 1.0]
Epoch :  30  Time:  1.107  Rel. Train L2 Loss :  0.041276505721939936  Rel. Test L2 Loss :  0.045322430729866026  Test L2 Loss :  0.08054792374372483  inv_L_scale:  [1.0, 1.0]
Epoch :  31  Time:  1.109  Rel. Train L2 Loss :  0.045392227503988476  Rel. Test L2 Loss :  0.05321389064192772  Test L2 Loss :  0.09467500537633895  inv_L_scale:  [1.0, 1.0]
Epoch :  32  Time:  1.109  Rel. Train L2 Loss :  0.04373130715555615  Rel. Test L2 Loss :  0.04894595950841904  Test L2 Loss :  0.08936085641384124  inv_L_scale:  [1.0, 1.0]
Epoch :  33  Time:  1.108  Rel. Train L2 Loss :  0.044555511905087365  Rel. Test L2 Loss :  0.05162262737751007  Test L2 Loss :  0.0926638013124466  inv_L_scale:  [1.0, 1.0]
Epoch :  34  Time:  1.109  Rel. Train L2 Loss :  0.04198118610514535  Rel. Test L2 Loss :  0.04488715603947639  Test L2 Loss :  0.0802366515994072  inv_L_scale:  [1.0, 1.0]
Epoch :  35  Time:  1.109  Rel. Train L2 Loss :  0.03987936149040858  Rel. Test L2 Loss :  0.04367981925606727  Test L2 Loss :  0.07767376512289047  inv_L_scale:  [1.0, 1.0]
Epoch :  36  Time:  1.108  Rel. Train L2 Loss :  0.04164865911006928  Rel. Test L2 Loss :  0.04490927129983902  Test L2 Loss :  0.07933745384216309  inv_L_scale:  [1.0, 1.0]
Epoch :  37  Time:  1.11  Rel. Train L2 Loss :  0.039086003369755214  Rel. Test L2 Loss :  0.04163106754422188  Test L2 Loss :  0.07533047556877136  inv_L_scale:  [1.0, 1.0]
Epoch :  38  Time:  1.109  Rel. Train L2 Loss :  0.03772673464483685  Rel. Test L2 Loss :  0.045123508274555205  Test L2 Loss :  0.07944216430187226  inv_L_scale:  [1.0, 1.0]
Epoch :  39  Time:  1.109  Rel. Train L2 Loss :  0.04156587145394749  Rel. Test L2 Loss :  0.04883951798081398  Test L2 Loss :  0.090125070810318  inv_L_scale:  [1.0, 1.0]
Epoch :  40  Time:  1.108  Rel. Train L2 Loss :  0.03775000640087658  Rel. Test L2 Loss :  0.0416298471391201  Test L2 Loss :  0.0737649405002594  inv_L_scale:  [1.0, 1.0]
Epoch :  41  Time:  1.108  Rel. Train L2 Loss :  0.0411572980052895  Rel. Test L2 Loss :  0.04322782695293426  Test L2 Loss :  0.07702613234519959  inv_L_scale:  [1.0, 1.0]
Epoch :  42  Time:  1.11  Rel. Train L2 Loss :  0.03952918734815385  Rel. Test L2 Loss :  0.0462197870016098  Test L2 Loss :  0.08418783009052276  inv_L_scale:  [1.0, 1.0]
Epoch :  43  Time:  1.108  Rel. Train L2 Loss :  0.03940932586789131  Rel. Test L2 Loss :  0.04200863674283028  Test L2 Loss :  0.07549668312072753  inv_L_scale:  [1.0, 1.0]
Epoch :  44  Time:  1.108  Rel. Train L2 Loss :  0.03941169967254003  Rel. Test L2 Loss :  0.04311538636684418  Test L2 Loss :  0.07801944494247437  inv_L_scale:  [1.0, 1.0]
Epoch :  45  Time:  1.107  Rel. Train L2 Loss :  0.037693830099370745  Rel. Test L2 Loss :  0.043667080700397494  Test L2 Loss :  0.07969928681850433  inv_L_scale:  [1.0, 1.0]
Epoch :  46  Time:  1.109  Rel. Train L2 Loss :  0.04155215207073423  Rel. Test L2 Loss :  0.041610785722732545  Test L2 Loss :  0.07484139531850814  inv_L_scale:  [1.0, 1.0]
Epoch :  47  Time:  1.108  Rel. Train L2 Loss :  0.038590985470347935  Rel. Test L2 Loss :  0.04137713253498077  Test L2 Loss :  0.07392733097076416  inv_L_scale:  [1.0, 1.0]
Epoch :  48  Time:  1.108  Rel. Train L2 Loss :  0.038461909261014726  Rel. Test L2 Loss :  0.04256729558110237  Test L2 Loss :  0.07702560484409332  inv_L_scale:  [1.0, 1.0]
Epoch :  49  Time:  1.109  Rel. Train L2 Loss :  0.03641802358958456  Rel. Test L2 Loss :  0.03692030213773251  Test L2 Loss :  0.065867710262537  inv_L_scale:  [1.0, 1.0]
Epoch :  50  Time:  1.107  Rel. Train L2 Loss :  0.03879657079776128  Rel. Test L2 Loss :  0.044274495840072634  Test L2 Loss :  0.07916390508413315  inv_L_scale:  [1.0, 1.0]
Epoch :  51  Time:  1.109  Rel. Train L2 Loss :  0.03748934058679475  Rel. Test L2 Loss :  0.039318894445896146  Test L2 Loss :  0.07132310718297959  inv_L_scale:  [1.0, 1.0]
Epoch :  52  Time:  1.109  Rel. Train L2 Loss :  0.038662467234664495  Rel. Test L2 Loss :  0.055564665496349336  Test L2 Loss :  0.10178094059228897  inv_L_scale:  [1.0, 1.0]
Epoch :  53  Time:  1.107  Rel. Train L2 Loss :  0.03892600678735309  Rel. Test L2 Loss :  0.039848311245441435  Test L2 Loss :  0.07061059415340423  inv_L_scale:  [1.0, 1.0]
Epoch :  54  Time:  1.111  Rel. Train L2 Loss :  0.03711913858850797  Rel. Test L2 Loss :  0.041280897557735445  Test L2 Loss :  0.07353226035833359  inv_L_scale:  [1.0, 1.0]
Epoch :  55  Time:  1.109  Rel. Train L2 Loss :  0.03607931849029329  Rel. Test L2 Loss :  0.0395300729572773  Test L2 Loss :  0.07019557237625122  inv_L_scale:  [1.0, 1.0]
Epoch :  56  Time:  1.108  Rel. Train L2 Loss :  0.035860683768987656  Rel. Test L2 Loss :  0.047475776374340056  Test L2 Loss :  0.08648496210575103  inv_L_scale:  [1.0, 1.0]
Epoch :  57  Time:  1.109  Rel. Train L2 Loss :  0.03751512130929364  Rel. Test L2 Loss :  0.04355562925338745  Test L2 Loss :  0.07843506187200547  inv_L_scale:  [1.0, 1.0]
Epoch :  58  Time:  1.108  Rel. Train L2 Loss :  0.035799593693680236  Rel. Test L2 Loss :  0.038571872562170026  Test L2 Loss :  0.06930823981761933  inv_L_scale:  [1.0, 1.0]
Epoch :  59  Time:  1.109  Rel. Train L2 Loss :  0.035349806000789005  Rel. Test L2 Loss :  0.03680706024169922  Test L2 Loss :  0.06623583674430847  inv_L_scale:  [1.0, 1.0]
Epoch :  60  Time:  1.108  Rel. Train L2 Loss :  0.035083158678478665  Rel. Test L2 Loss :  0.038288876861333844  Test L2 Loss :  0.06793537586927414  inv_L_scale:  [1.0, 1.0]
Epoch :  61  Time:  1.108  Rel. Train L2 Loss :  0.03606494463152356  Rel. Test L2 Loss :  0.03796066701412201  Test L2 Loss :  0.06806972295045853  inv_L_scale:  [1.0, 1.0]
Epoch :  62  Time:  1.109  Rel. Train L2 Loss :  0.03778311116827859  Rel. Test L2 Loss :  0.03598438441753388  Test L2 Loss :  0.06418419793248177  inv_L_scale:  [1.0, 1.0]
Epoch :  63  Time:  1.108  Rel. Train L2 Loss :  0.03342844135231442  Rel. Test L2 Loss :  0.03631896659731865  Test L2 Loss :  0.06510258942842484  inv_L_scale:  [1.0, 1.0]
Epoch :  64  Time:  1.108  Rel. Train L2 Loss :  0.03417935788631439  Rel. Test L2 Loss :  0.03784295991063118  Test L2 Loss :  0.06827495902776719  inv_L_scale:  [1.0, 1.0]
Epoch :  65  Time:  1.109  Rel. Train L2 Loss :  0.03473552647564146  Rel. Test L2 Loss :  0.03592568680644035  Test L2 Loss :  0.06418098539113998  inv_L_scale:  [1.0, 1.0]
Epoch :  66  Time:  1.108  Rel. Train L2 Loss :  0.0357863013446331  Rel. Test L2 Loss :  0.043272905945777894  Test L2 Loss :  0.07873090773820877  inv_L_scale:  [1.0, 1.0]
Epoch :  67  Time:  1.108  Rel. Train L2 Loss :  0.033994095772504805  Rel. Test L2 Loss :  0.03447084821760654  Test L2 Loss :  0.061158245503902434  inv_L_scale:  [1.0, 1.0]
Epoch :  68  Time:  1.107  Rel. Train L2 Loss :  0.03326755003796683  Rel. Test L2 Loss :  0.03901004031300545  Test L2 Loss :  0.0695591589808464  inv_L_scale:  [1.0, 1.0]
Epoch :  69  Time:  1.106  Rel. Train L2 Loss :  0.033449625737137265  Rel. Test L2 Loss :  0.03739082396030426  Test L2 Loss :  0.06797796547412872  inv_L_scale:  [1.0, 1.0]
Epoch :  70  Time:  1.104  Rel. Train L2 Loss :  0.034292978710598415  Rel. Test L2 Loss :  0.03553780362010002  Test L2 Loss :  0.0631526356935501  inv_L_scale:  [1.0, 1.0]
Epoch :  71  Time:  1.105  Rel. Train L2 Loss :  0.03350972397459878  Rel. Test L2 Loss :  0.035223020091652874  Test L2 Loss :  0.06324783235788345  inv_L_scale:  [1.0, 1.0]
Epoch :  72  Time:  1.105  Rel. Train L2 Loss :  0.03342381707496113  Rel. Test L2 Loss :  0.03532820537686348  Test L2 Loss :  0.06274325951933861  inv_L_scale:  [1.0, 1.0]
Epoch :  73  Time:  1.104  Rel. Train L2 Loss :  0.0336786887049675  Rel. Test L2 Loss :  0.04153130456805229  Test L2 Loss :  0.07684950828552246  inv_L_scale:  [1.0, 1.0]
Epoch :  74  Time:  1.103  Rel. Train L2 Loss :  0.034068545285198426  Rel. Test L2 Loss :  0.03503275692462921  Test L2 Loss :  0.06181274846196175  inv_L_scale:  [1.0, 1.0]
Epoch :  75  Time:  1.105  Rel. Train L2 Loss :  0.03265115083919631  Rel. Test L2 Loss :  0.03531709000468254  Test L2 Loss :  0.06270108491182327  inv_L_scale:  [1.0, 1.0]
Epoch :  76  Time:  1.104  Rel. Train L2 Loss :  0.031646081275410125  Rel. Test L2 Loss :  0.0345488003641367  Test L2 Loss :  0.061285192370414736  inv_L_scale:  [1.0, 1.0]
Epoch :  77  Time:  1.104  Rel. Train L2 Loss :  0.03126670948333211  Rel. Test L2 Loss :  0.03431918568909168  Test L2 Loss :  0.06193793997168541  inv_L_scale:  [1.0, 1.0]
Epoch :  78  Time:  1.104  Rel. Train L2 Loss :  0.031707898187968465  Rel. Test L2 Loss :  0.0367699322104454  Test L2 Loss :  0.06472134917974472  inv_L_scale:  [1.0, 1.0]
Epoch :  79  Time:  1.105  Rel. Train L2 Loss :  0.031984894399841625  Rel. Test L2 Loss :  0.032634654492139814  Test L2 Loss :  0.05744270518422127  inv_L_scale:  [1.0, 1.0]
Epoch :  80  Time:  1.104  Rel. Train L2 Loss :  0.031353820429907905  Rel. Test L2 Loss :  0.031257735714316365  Test L2 Loss :  0.05583771839737892  inv_L_scale:  [1.0, 1.0]
Epoch :  81  Time:  1.103  Rel. Train L2 Loss :  0.030943521675136355  Rel. Test L2 Loss :  0.04201935559511185  Test L2 Loss :  0.07592283338308334  inv_L_scale:  [1.0, 1.0]
Epoch :  82  Time:  1.104  Rel. Train L2 Loss :  0.032967610889010956  Rel. Test L2 Loss :  0.031529664024710656  Test L2 Loss :  0.05634861350059509  inv_L_scale:  [1.0, 1.0]
Epoch :  83  Time:  1.103  Rel. Train L2 Loss :  0.03163402719630135  Rel. Test L2 Loss :  0.03242297649383545  Test L2 Loss :  0.05781772255897522  inv_L_scale:  [1.0, 1.0]
Epoch :  84  Time:  1.103  Rel. Train L2 Loss :  0.0320742296675841  Rel. Test L2 Loss :  0.03165735319256782  Test L2 Loss :  0.05653976827859879  inv_L_scale:  [1.0, 1.0]
Epoch :  85  Time:  1.103  Rel. Train L2 Loss :  0.03262837911645571  Rel. Test L2 Loss :  0.040422512888908385  Test L2 Loss :  0.07598959654569626  inv_L_scale:  [1.0, 1.0]
Epoch :  86  Time:  1.105  Rel. Train L2 Loss :  0.03103627703256077  Rel. Test L2 Loss :  0.033143311887979504  Test L2 Loss :  0.058918419480323794  inv_L_scale:  [1.0, 1.0]
Epoch :  87  Time:  1.105  Rel. Train L2 Loss :  0.029319842722680834  Rel. Test L2 Loss :  0.03437783397734165  Test L2 Loss :  0.06111193016171455  inv_L_scale:  [1.0, 1.0]
Epoch :  88  Time:  1.104  Rel. Train L2 Loss :  0.030480541653103297  Rel. Test L2 Loss :  0.031786602288484574  Test L2 Loss :  0.05649339437484741  inv_L_scale:  [1.0, 1.0]
Epoch :  89  Time:  1.103  Rel. Train L2 Loss :  0.028450312895907295  Rel. Test L2 Loss :  0.03234683156013489  Test L2 Loss :  0.05743202805519104  inv_L_scale:  [1.0, 1.0]
Epoch :  90  Time:  1.104  Rel. Train L2 Loss :  0.029867098563247256  Rel. Test L2 Loss :  0.03091011554002762  Test L2 Loss :  0.05580601900815964  inv_L_scale:  [1.0, 1.0]
Epoch :  91  Time:  1.103  Rel. Train L2 Loss :  0.02954711145824856  Rel. Test L2 Loss :  0.0313777806609869  Test L2 Loss :  0.05475408986210823  inv_L_scale:  [1.0, 1.0]
Epoch :  92  Time:  1.104  Rel. Train L2 Loss :  0.03032609338561694  Rel. Test L2 Loss :  0.03462011396884918  Test L2 Loss :  0.061996091604232785  inv_L_scale:  [1.0, 1.0]
Epoch :  93  Time:  1.103  Rel. Train L2 Loss :  0.029918157450026937  Rel. Test L2 Loss :  0.031403742134571075  Test L2 Loss :  0.05569663807749748  inv_L_scale:  [1.0, 1.0]
Epoch :  94  Time:  1.104  Rel. Train L2 Loss :  0.02881333496835497  Rel. Test L2 Loss :  0.030331991165876388  Test L2 Loss :  0.054086101204156876  inv_L_scale:  [1.0, 1.0]
Epoch :  95  Time:  1.104  Rel. Train L2 Loss :  0.02832242591513528  Rel. Test L2 Loss :  0.03772295668721199  Test L2 Loss :  0.06967202365398407  inv_L_scale:  [1.0, 1.0]
Epoch :  96  Time:  1.104  Rel. Train L2 Loss :  0.029512283164593908  Rel. Test L2 Loss :  0.03143215082585812  Test L2 Loss :  0.05675141021609306  inv_L_scale:  [1.0, 1.0]
Epoch :  97  Time:  1.103  Rel. Train L2 Loss :  0.029154602570666207  Rel. Test L2 Loss :  0.03002642631530762  Test L2 Loss :  0.05348888874053955  inv_L_scale:  [1.0, 1.0]
Epoch :  98  Time:  1.103  Rel. Train L2 Loss :  0.027831670227977966  Rel. Test L2 Loss :  0.031316604986786845  Test L2 Loss :  0.055097227543592454  inv_L_scale:  [1.0, 1.0]
Epoch :  99  Time:  1.105  Rel. Train L2 Loss :  0.029236738665236368  Rel. Test L2 Loss :  0.03048685349524021  Test L2 Loss :  0.05494495913386345  inv_L_scale:  [1.0, 1.0]
Epoch :  100  Time:  1.103  Rel. Train L2 Loss :  0.02968744304445055  Rel. Test L2 Loss :  0.030227033868432045  Test L2 Loss :  0.053724761903285984  inv_L_scale:  [1.0, 1.0]
Epoch :  101  Time:  1.103  Rel. Train L2 Loss :  0.028271879951159158  Rel. Test L2 Loss :  0.03341032475233078  Test L2 Loss :  0.06012324869632721  inv_L_scale:  [1.0, 1.0]
Epoch :  102  Time:  1.103  Rel. Train L2 Loss :  0.028626903204454317  Rel. Test L2 Loss :  0.038465262055397034  Test L2 Loss :  0.07014648169279099  inv_L_scale:  [1.0, 1.0]
Epoch :  103  Time:  1.104  Rel. Train L2 Loss :  0.029306880169444615  Rel. Test L2 Loss :  0.031111275926232338  Test L2 Loss :  0.05510076954960823  inv_L_scale:  [1.0, 1.0]
Epoch :  104  Time:  1.104  Rel. Train L2 Loss :  0.028480972597996392  Rel. Test L2 Loss :  0.02999732106924057  Test L2 Loss :  0.053345486521720886  inv_L_scale:  [1.0, 1.0]
Epoch :  105  Time:  1.104  Rel. Train L2 Loss :  0.027086693611409928  Rel. Test L2 Loss :  0.029749249666929246  Test L2 Loss :  0.05292197585105896  inv_L_scale:  [1.0, 1.0]
Epoch :  106  Time:  1.104  Rel. Train L2 Loss :  0.026701135734717052  Rel. Test L2 Loss :  0.032492409944534305  Test L2 Loss :  0.058678396344184876  inv_L_scale:  [1.0, 1.0]
Epoch :  107  Time:  1.104  Rel. Train L2 Loss :  0.02816077909535832  Rel. Test L2 Loss :  0.028975069522857666  Test L2 Loss :  0.051765705198049544  inv_L_scale:  [1.0, 1.0]
Epoch :  108  Time:  1.107  Rel. Train L2 Loss :  0.027214773669838904  Rel. Test L2 Loss :  0.02923158511519432  Test L2 Loss :  0.05248316019773483  inv_L_scale:  [1.0, 1.0]
Epoch :  109  Time:  1.103  Rel. Train L2 Loss :  0.026986233956283995  Rel. Test L2 Loss :  0.028625683188438417  Test L2 Loss :  0.05071281313896179  inv_L_scale:  [1.0, 1.0]
Epoch :  110  Time:  1.104  Rel. Train L2 Loss :  0.02852850533194012  Rel. Test L2 Loss :  0.027880869656801224  Test L2 Loss :  0.0493133693933487  inv_L_scale:  [1.0, 1.0]
Epoch :  111  Time:  1.103  Rel. Train L2 Loss :  0.026776539103852377  Rel. Test L2 Loss :  0.030296513438224794  Test L2 Loss :  0.05343362718820572  inv_L_scale:  [1.0, 1.0]
Epoch :  112  Time:  1.104  Rel. Train L2 Loss :  0.028074120779832203  Rel. Test L2 Loss :  0.028385899364948272  Test L2 Loss :  0.05044906497001648  inv_L_scale:  [1.0, 1.0]
Epoch :  113  Time:  1.104  Rel. Train L2 Loss :  0.026982484890355003  Rel. Test L2 Loss :  0.030770299658179283  Test L2 Loss :  0.053558984100818635  inv_L_scale:  [1.0, 1.0]
Epoch :  114  Time:  1.103  Rel. Train L2 Loss :  0.02579595733847883  Rel. Test L2 Loss :  0.027853625267744063  Test L2 Loss :  0.04991636276245117  inv_L_scale:  [1.0, 1.0]
Epoch :  115  Time:  1.103  Rel. Train L2 Loss :  0.027039319508605532  Rel. Test L2 Loss :  0.027974600344896315  Test L2 Loss :  0.04949022501707077  inv_L_scale:  [1.0, 1.0]
Epoch :  116  Time:  1.103  Rel. Train L2 Loss :  0.02601865217089653  Rel. Test L2 Loss :  0.026373917758464812  Test L2 Loss :  0.046807324588298796  inv_L_scale:  [1.0, 1.0]
Epoch :  117  Time:  1.104  Rel. Train L2 Loss :  0.026183697630961737  Rel. Test L2 Loss :  0.03040699616074562  Test L2 Loss :  0.05473154857754707  inv_L_scale:  [1.0, 1.0]
Epoch :  118  Time:  1.104  Rel. Train L2 Loss :  0.026268564032183753  Rel. Test L2 Loss :  0.025847649872303008  Test L2 Loss :  0.04595757931470871  inv_L_scale:  [1.0, 1.0]
Epoch :  119  Time:  1.103  Rel. Train L2 Loss :  0.025351204027732215  Rel. Test L2 Loss :  0.02670020878314972  Test L2 Loss :  0.04713149920105934  inv_L_scale:  [1.0, 1.0]
Epoch :  120  Time:  1.101  Rel. Train L2 Loss :  0.026534547209739686  Rel. Test L2 Loss :  0.030454158782958984  Test L2 Loss :  0.055262686610221864  inv_L_scale:  [1.0, 1.0]
Epoch :  121  Time:  1.101  Rel. Train L2 Loss :  0.026061194323831135  Rel. Test L2 Loss :  0.026658427640795707  Test L2 Loss :  0.047164153456687924  inv_L_scale:  [1.0, 1.0]
Epoch :  122  Time:  1.102  Rel. Train L2 Loss :  0.025679545725385347  Rel. Test L2 Loss :  0.03109182506799698  Test L2 Loss :  0.05569735437631607  inv_L_scale:  [1.0, 1.0]
Epoch :  123  Time:  1.102  Rel. Train L2 Loss :  0.025399932339787483  Rel. Test L2 Loss :  0.026192369163036345  Test L2 Loss :  0.04607789188623428  inv_L_scale:  [1.0, 1.0]
Epoch :  124  Time:  1.102  Rel. Train L2 Loss :  0.02517802897426817  Rel. Test L2 Loss :  0.026875585988163947  Test L2 Loss :  0.04737208843231201  inv_L_scale:  [1.0, 1.0]
Epoch :  125  Time:  1.103  Rel. Train L2 Loss :  0.025368345768915283  Rel. Test L2 Loss :  0.027369689121842386  Test L2 Loss :  0.04844479113817215  inv_L_scale:  [1.0, 1.0]
Epoch :  126  Time:  1.1  Rel. Train L2 Loss :  0.024640885475609036  Rel. Test L2 Loss :  0.025475128889083862  Test L2 Loss :  0.04526387721300125  inv_L_scale:  [1.0, 1.0]
Epoch :  127  Time:  1.102  Rel. Train L2 Loss :  0.025362343134151564  Rel. Test L2 Loss :  0.027711858898401262  Test L2 Loss :  0.049491718560457226  inv_L_scale:  [1.0, 1.0]
Epoch :  128  Time:  1.102  Rel. Train L2 Loss :  0.025453157789177366  Rel. Test L2 Loss :  0.02487125352025032  Test L2 Loss :  0.04378606021404266  inv_L_scale:  [1.0, 1.0]
Epoch :  129  Time:  1.103  Rel. Train L2 Loss :  0.02567980104850398  Rel. Test L2 Loss :  0.028634003326296807  Test L2 Loss :  0.0514944264292717  inv_L_scale:  [1.0, 1.0]
Epoch :  130  Time:  1.103  Rel. Train L2 Loss :  0.02505798446635405  Rel. Test L2 Loss :  0.029549528881907462  Test L2 Loss :  0.05218155026435852  inv_L_scale:  [1.0, 1.0]
Epoch :  131  Time:  1.102  Rel. Train L2 Loss :  0.024967589005827902  Rel. Test L2 Loss :  0.028033503592014314  Test L2 Loss :  0.04944247424602508  inv_L_scale:  [1.0, 1.0]
Epoch :  132  Time:  1.103  Rel. Train L2 Loss :  0.025101228952407836  Rel. Test L2 Loss :  0.030387869626283644  Test L2 Loss :  0.0554784594476223  inv_L_scale:  [1.0, 1.0]
Epoch :  133  Time:  1.104  Rel. Train L2 Loss :  0.025805745157930587  Rel. Test L2 Loss :  0.026353726536035536  Test L2 Loss :  0.04701954200863838  inv_L_scale:  [1.0, 1.0]
Epoch :  134  Time:  1.104  Rel. Train L2 Loss :  0.024845574556125533  Rel. Test L2 Loss :  0.025751882269978522  Test L2 Loss :  0.045355122983455655  inv_L_scale:  [1.0, 1.0]
Epoch :  135  Time:  1.103  Rel. Train L2 Loss :  0.02419059249262015  Rel. Test L2 Loss :  0.024517945498228073  Test L2 Loss :  0.043415713608264926  inv_L_scale:  [1.0, 1.0]
Epoch :  136  Time:  1.103  Rel. Train L2 Loss :  0.024328663672010104  Rel. Test L2 Loss :  0.026445513665676115  Test L2 Loss :  0.046931836605072025  inv_L_scale:  [1.0, 1.0]
Epoch :  137  Time:  1.103  Rel. Train L2 Loss :  0.024886216811007923  Rel. Test L2 Loss :  0.025991897881031036  Test L2 Loss :  0.0457539002597332  inv_L_scale:  [1.0, 1.0]
Epoch :  138  Time:  1.103  Rel. Train L2 Loss :  0.024234377708699968  Rel. Test L2 Loss :  0.02958049677312374  Test L2 Loss :  0.054299558252096175  inv_L_scale:  [1.0, 1.0]
Epoch :  139  Time:  1.104  Rel. Train L2 Loss :  0.024555349167850283  Rel. Test L2 Loss :  0.02668404333293438  Test L2 Loss :  0.0472090420126915  inv_L_scale:  [1.0, 1.0]
Epoch :  140  Time:  1.103  Rel. Train L2 Loss :  0.02491838703552882  Rel. Test L2 Loss :  0.026597095131874086  Test L2 Loss :  0.0469417279958725  inv_L_scale:  [1.0, 1.0]
Epoch :  141  Time:  1.103  Rel. Train L2 Loss :  0.024012629373206033  Rel. Test L2 Loss :  0.03291064463555813  Test L2 Loss :  0.059084970057010654  inv_L_scale:  [1.0, 1.0]
Epoch :  142  Time:  1.103  Rel. Train L2 Loss :  0.025028888947433894  Rel. Test L2 Loss :  0.029815721958875656  Test L2 Loss :  0.05346344172954559  inv_L_scale:  [1.0, 1.0]
Epoch :  143  Time:  1.103  Rel. Train L2 Loss :  0.024817548973692788  Rel. Test L2 Loss :  0.027187521979212762  Test L2 Loss :  0.04864540904760361  inv_L_scale:  [1.0, 1.0]
Epoch :  144  Time:  1.103  Rel. Train L2 Loss :  0.023838322824902003  Rel. Test L2 Loss :  0.025054313242435455  Test L2 Loss :  0.04417805105447769  inv_L_scale:  [1.0, 1.0]
Epoch :  145  Time:  1.103  Rel. Train L2 Loss :  0.02446521113316218  Rel. Test L2 Loss :  0.025913063809275626  Test L2 Loss :  0.04563361912965774  inv_L_scale:  [1.0, 1.0]
Epoch :  146  Time:  1.103  Rel. Train L2 Loss :  0.023882068925433687  Rel. Test L2 Loss :  0.027348889485001564  Test L2 Loss :  0.048626136779785153  inv_L_scale:  [1.0, 1.0]
Epoch :  147  Time:  1.103  Rel. Train L2 Loss :  0.023709938526153565  Rel. Test L2 Loss :  0.02473682478070259  Test L2 Loss :  0.04440323919057846  inv_L_scale:  [1.0, 1.0]
Epoch :  148  Time:  1.103  Rel. Train L2 Loss :  0.023513746311267215  Rel. Test L2 Loss :  0.025418972000479698  Test L2 Loss :  0.04538273125886917  inv_L_scale:  [1.0, 1.0]
Epoch :  149  Time:  1.103  Rel. Train L2 Loss :  0.024072151333093643  Rel. Test L2 Loss :  0.025045867264270782  Test L2 Loss :  0.04439902797341347  inv_L_scale:  [1.0, 1.0]
Epoch :  150  Time:  1.103  Rel. Train L2 Loss :  0.02360475939181116  Rel. Test L2 Loss :  0.027460930049419404  Test L2 Loss :  0.04790202468633652  inv_L_scale:  [1.0, 1.0]
Epoch :  151  Time:  1.104  Rel. Train L2 Loss :  0.023332972576220832  Rel. Test L2 Loss :  0.024742034375667573  Test L2 Loss :  0.04317776039242745  inv_L_scale:  [1.0, 1.0]
Epoch :  152  Time:  1.103  Rel. Train L2 Loss :  0.023618252989318637  Rel. Test L2 Loss :  0.025050776079297066  Test L2 Loss :  0.04495376318693161  inv_L_scale:  [1.0, 1.0]
Epoch :  153  Time:  1.103  Rel. Train L2 Loss :  0.022563366293907164  Rel. Test L2 Loss :  0.025187582671642304  Test L2 Loss :  0.044815642684698107  inv_L_scale:  [1.0, 1.0]
Epoch :  154  Time:  1.103  Rel. Train L2 Loss :  0.022986323750681346  Rel. Test L2 Loss :  0.02323558561503887  Test L2 Loss :  0.04087038844823837  inv_L_scale:  [1.0, 1.0]
Epoch :  155  Time:  1.103  Rel. Train L2 Loss :  0.023508665644460254  Rel. Test L2 Loss :  0.024685217291116713  Test L2 Loss :  0.043707242906093596  inv_L_scale:  [1.0, 1.0]
Epoch :  156  Time:  1.103  Rel. Train L2 Loss :  0.023046820221675767  Rel. Test L2 Loss :  0.02356399044394493  Test L2 Loss :  0.04140965148806572  inv_L_scale:  [1.0, 1.0]
Epoch :  157  Time:  1.103  Rel. Train L2 Loss :  0.02259843639201588  Rel. Test L2 Loss :  0.023303689435124397  Test L2 Loss :  0.04090024739503861  inv_L_scale:  [1.0, 1.0]
Epoch :  158  Time:  1.103  Rel. Train L2 Loss :  0.022851436105039386  Rel. Test L2 Loss :  0.02426868222653866  Test L2 Loss :  0.04288618743419647  inv_L_scale:  [1.0, 1.0]
Epoch :  159  Time:  1.103  Rel. Train L2 Loss :  0.023247227080994182  Rel. Test L2 Loss :  0.024034611731767654  Test L2 Loss :  0.04198231220245361  inv_L_scale:  [1.0, 1.0]
Epoch :  160  Time:  1.103  Rel. Train L2 Loss :  0.02311386939552095  Rel. Test L2 Loss :  0.02495614007115364  Test L2 Loss :  0.04410650461912155  inv_L_scale:  [1.0, 1.0]
Epoch :  161  Time:  1.103  Rel. Train L2 Loss :  0.022795136471589407  Rel. Test L2 Loss :  0.024075152277946474  Test L2 Loss :  0.04239112645387649  inv_L_scale:  [1.0, 1.0]
Epoch :  162  Time:  1.103  Rel. Train L2 Loss :  0.022172847522629633  Rel. Test L2 Loss :  0.025041633546352388  Test L2 Loss :  0.04427341237664223  inv_L_scale:  [1.0, 1.0]
Epoch :  163  Time:  1.102  Rel. Train L2 Loss :  0.022843483620219762  Rel. Test L2 Loss :  0.02336910903453827  Test L2 Loss :  0.04121180683374405  inv_L_scale:  [1.0, 1.0]
Epoch :  164  Time:  1.105  Rel. Train L2 Loss :  0.023495529691378275  Rel. Test L2 Loss :  0.025456944555044173  Test L2 Loss :  0.04519551008939743  inv_L_scale:  [1.0, 1.0]
Epoch :  165  Time:  1.104  Rel. Train L2 Loss :  0.023268946790032916  Rel. Test L2 Loss :  0.024075605645775794  Test L2 Loss :  0.042435000389814376  inv_L_scale:  [1.0, 1.0]
Epoch :  166  Time:  1.103  Rel. Train L2 Loss :  0.022346509430143567  Rel. Test L2 Loss :  0.025207320526242256  Test L2 Loss :  0.04438925340771675  inv_L_scale:  [1.0, 1.0]
Epoch :  167  Time:  1.103  Rel. Train L2 Loss :  0.0224722870066762  Rel. Test L2 Loss :  0.024094704687595368  Test L2 Loss :  0.04225177496671677  inv_L_scale:  [1.0, 1.0]
Epoch :  168  Time:  1.103  Rel. Train L2 Loss :  0.022149396075142755  Rel. Test L2 Loss :  0.02292675830423832  Test L2 Loss :  0.04041667103767395  inv_L_scale:  [1.0, 1.0]
Epoch :  169  Time:  1.103  Rel. Train L2 Loss :  0.02256180098487271  Rel. Test L2 Loss :  0.024632133170962335  Test L2 Loss :  0.04375742495059967  inv_L_scale:  [1.0, 1.0]
Epoch :  170  Time:  1.103  Rel. Train L2 Loss :  0.022514271686474484  Rel. Test L2 Loss :  0.025430279225111006  Test L2 Loss :  0.045351266860961914  inv_L_scale:  [1.0, 1.0]
Epoch :  171  Time:  1.103  Rel. Train L2 Loss :  0.023074414407213528  Rel. Test L2 Loss :  0.02428390383720398  Test L2 Loss :  0.043166647851467135  inv_L_scale:  [1.0, 1.0]
Epoch :  172  Time:  1.102  Rel. Train L2 Loss :  0.022650153661767643  Rel. Test L2 Loss :  0.02323212429881096  Test L2 Loss :  0.04097109049558639  inv_L_scale:  [1.0, 1.0]
Epoch :  173  Time:  1.103  Rel. Train L2 Loss :  0.022522068810131815  Rel. Test L2 Loss :  0.023577489703893662  Test L2 Loss :  0.04165253609418869  inv_L_scale:  [1.0, 1.0]
Epoch :  174  Time:  1.103  Rel. Train L2 Loss :  0.023127392563554977  Rel. Test L2 Loss :  0.02407245010137558  Test L2 Loss :  0.04240695744752884  inv_L_scale:  [1.0, 1.0]
Epoch :  175  Time:  1.103  Rel. Train L2 Loss :  0.022422657857338588  Rel. Test L2 Loss :  0.02379590943455696  Test L2 Loss :  0.04216037586331368  inv_L_scale:  [1.0, 1.0]
Epoch :  176  Time:  1.103  Rel. Train L2 Loss :  0.02232645084046655  Rel. Test L2 Loss :  0.02373860329389572  Test L2 Loss :  0.04210801988840103  inv_L_scale:  [1.0, 1.0]
Epoch :  177  Time:  1.103  Rel. Train L2 Loss :  0.021938455328345298  Rel. Test L2 Loss :  0.023101065754890442  Test L2 Loss :  0.04067201256752014  inv_L_scale:  [1.0, 1.0]
Epoch :  178  Time:  1.104  Rel. Train L2 Loss :  0.02209765796446138  Rel. Test L2 Loss :  0.022190173864364626  Test L2 Loss :  0.03912153393030167  inv_L_scale:  [1.0, 1.0]
Epoch :  179  Time:  1.103  Rel. Train L2 Loss :  0.021988233286473487  Rel. Test L2 Loss :  0.02279833197593689  Test L2 Loss :  0.04018368110060692  inv_L_scale:  [1.0, 1.0]
Epoch :  180  Time:  1.102  Rel. Train L2 Loss :  0.021448511746194627  Rel. Test L2 Loss :  0.02840314246714115  Test L2 Loss :  0.05068659573793411  inv_L_scale:  [1.0, 1.0]
Epoch :  181  Time:  1.102  Rel. Train L2 Loss :  0.022093715377979807  Rel. Test L2 Loss :  0.02364611729979515  Test L2 Loss :  0.04156816214323044  inv_L_scale:  [1.0, 1.0]
Epoch :  182  Time:  1.103  Rel. Train L2 Loss :  0.02180524669587612  Rel. Test L2 Loss :  0.024744701087474823  Test L2 Loss :  0.044036995768547055  inv_L_scale:  [1.0, 1.0]
Epoch :  183  Time:  1.103  Rel. Train L2 Loss :  0.02193015542295244  Rel. Test L2 Loss :  0.023602546975016594  Test L2 Loss :  0.0412603023648262  inv_L_scale:  [1.0, 1.0]
Epoch :  184  Time:  1.103  Rel. Train L2 Loss :  0.022307332646515635  Rel. Test L2 Loss :  0.02183035038411617  Test L2 Loss :  0.03851127967238426  inv_L_scale:  [1.0, 1.0]
Epoch :  185  Time:  1.103  Rel. Train L2 Loss :  0.021444628338019054  Rel. Test L2 Loss :  0.023416008353233337  Test L2 Loss :  0.0411958447098732  inv_L_scale:  [1.0, 1.0]
Epoch :  186  Time:  1.103  Rel. Train L2 Loss :  0.02125281718042162  Rel. Test L2 Loss :  0.023268027007579805  Test L2 Loss :  0.04104441732168198  inv_L_scale:  [1.0, 1.0]
Epoch :  187  Time:  1.103  Rel. Train L2 Loss :  0.02167777809003989  Rel. Test L2 Loss :  0.02272834338247776  Test L2 Loss :  0.04014679372310639  inv_L_scale:  [1.0, 1.0]
Epoch :  188  Time:  1.103  Rel. Train L2 Loss :  0.021617225938373143  Rel. Test L2 Loss :  0.023333377987146377  Test L2 Loss :  0.04095372229814529  inv_L_scale:  [1.0, 1.0]
Epoch :  189  Time:  1.103  Rel. Train L2 Loss :  0.021906130702959166  Rel. Test L2 Loss :  0.02341433972120285  Test L2 Loss :  0.041281045526266096  inv_L_scale:  [1.0, 1.0]
Epoch :  190  Time:  1.102  Rel. Train L2 Loss :  0.02147110414173868  Rel. Test L2 Loss :  0.022702833563089372  Test L2 Loss :  0.04016304701566696  inv_L_scale:  [1.0, 1.0]
Epoch :  191  Time:  1.102  Rel. Train L2 Loss :  0.021722910271750558  Rel. Test L2 Loss :  0.02627468019723892  Test L2 Loss :  0.04794182538986206  inv_L_scale:  [1.0, 1.0]
Epoch :  192  Time:  1.103  Rel. Train L2 Loss :  0.02227663981417815  Rel. Test L2 Loss :  0.0233800607919693  Test L2 Loss :  0.04104469329118729  inv_L_scale:  [1.0, 1.0]
Epoch :  193  Time:  1.103  Rel. Train L2 Loss :  0.02248870544963413  Rel. Test L2 Loss :  0.024815312922000884  Test L2 Loss :  0.04416057467460632  inv_L_scale:  [1.0, 1.0]
Epoch :  194  Time:  1.103  Rel. Train L2 Loss :  0.022061048241125213  Rel. Test L2 Loss :  0.023036283254623414  Test L2 Loss :  0.04030915796756744  inv_L_scale:  [1.0, 1.0]
Epoch :  195  Time:  1.103  Rel. Train L2 Loss :  0.022482673128445943  Rel. Test L2 Loss :  0.023351062089204788  Test L2 Loss :  0.04134746998548508  inv_L_scale:  [1.0, 1.0]
Epoch :  196  Time:  1.103  Rel. Train L2 Loss :  0.0220663248664803  Rel. Test L2 Loss :  0.02280208095908165  Test L2 Loss :  0.04028079897165299  inv_L_scale:  [1.0, 1.0]
Epoch :  197  Time:  1.102  Rel. Train L2 Loss :  0.02187006801366806  Rel. Test L2 Loss :  0.0235262930393219  Test L2 Loss :  0.04199297457933426  inv_L_scale:  [1.0, 1.0]
Epoch :  198  Time:  1.104  Rel. Train L2 Loss :  0.021596561819314956  Rel. Test L2 Loss :  0.023669484332203866  Test L2 Loss :  0.0424025958776474  inv_L_scale:  [1.0, 1.0]
Epoch :  199  Time:  1.104  Rel. Train L2 Loss :  0.021675927564501762  Rel. Test L2 Loss :  0.022432103604078293  Test L2 Loss :  0.039940435737371445  inv_L_scale:  [1.0, 1.0]
Epoch :  200  Time:  1.103  Rel. Train L2 Loss :  0.020847173271079857  Rel. Test L2 Loss :  0.02123200997710228  Test L2 Loss :  0.03736795634031296  inv_L_scale:  [1.0, 1.0]
Epoch :  201  Time:  1.103  Rel. Train L2 Loss :  0.0210292070855697  Rel. Test L2 Loss :  0.0218560066819191  Test L2 Loss :  0.03840947568416595  inv_L_scale:  [1.0, 1.0]
Epoch :  202  Time:  1.104  Rel. Train L2 Loss :  0.021026285282439657  Rel. Test L2 Loss :  0.023406364172697067  Test L2 Loss :  0.04129621043801308  inv_L_scale:  [1.0, 1.0]
Epoch :  203  Time:  1.102  Rel. Train L2 Loss :  0.021769503673745527  Rel. Test L2 Loss :  0.022725978642702104  Test L2 Loss :  0.039714471101760865  inv_L_scale:  [1.0, 1.0]
Epoch :  204  Time:  1.103  Rel. Train L2 Loss :  0.021838487171464496  Rel. Test L2 Loss :  0.025681238025426864  Test L2 Loss :  0.04552803307771683  inv_L_scale:  [1.0, 1.0]
Epoch :  205  Time:  1.103  Rel. Train L2 Loss :  0.021552145489388042  Rel. Test L2 Loss :  0.021328499466180803  Test L2 Loss :  0.037667197436094285  inv_L_scale:  [1.0, 1.0]
Epoch :  206  Time:  1.103  Rel. Train L2 Loss :  0.021067541191975275  Rel. Test L2 Loss :  0.021820441633462907  Test L2 Loss :  0.03836079493165016  inv_L_scale:  [1.0, 1.0]
Epoch :  207  Time:  1.103  Rel. Train L2 Loss :  0.020549965186251535  Rel. Test L2 Loss :  0.02179811358451843  Test L2 Loss :  0.038311183899641034  inv_L_scale:  [1.0, 1.0]
Epoch :  208  Time:  1.104  Rel. Train L2 Loss :  0.02051521004901992  Rel. Test L2 Loss :  0.021382135152816773  Test L2 Loss :  0.0376694729924202  inv_L_scale:  [1.0, 1.0]
Epoch :  209  Time:  1.104  Rel. Train L2 Loss :  0.020724791996181012  Rel. Test L2 Loss :  0.025512928813695906  Test L2 Loss :  0.04506928116083145  inv_L_scale:  [1.0, 1.0]
Epoch :  210  Time:  1.104  Rel. Train L2 Loss :  0.02074570174846384  Rel. Test L2 Loss :  0.021145613566040992  Test L2 Loss :  0.03723794370889664  inv_L_scale:  [1.0, 1.0]
Epoch :  211  Time:  1.104  Rel. Train L2 Loss :  0.02084595090813107  Rel. Test L2 Loss :  0.021699165850877764  Test L2 Loss :  0.03818470418453217  inv_L_scale:  [1.0, 1.0]
Epoch :  212  Time:  1.104  Rel. Train L2 Loss :  0.02025193716916773  Rel. Test L2 Loss :  0.021511239111423493  Test L2 Loss :  0.03759646475315094  inv_L_scale:  [1.0, 1.0]
Epoch :  213  Time:  1.103  Rel. Train L2 Loss :  0.02043342641658253  Rel. Test L2 Loss :  0.021804506555199624  Test L2 Loss :  0.038532434701919555  inv_L_scale:  [1.0, 1.0]
Epoch :  214  Time:  1.104  Rel. Train L2 Loss :  0.020787877672248416  Rel. Test L2 Loss :  0.022405443638563158  Test L2 Loss :  0.03949660927057266  inv_L_scale:  [1.0, 1.0]
Epoch :  215  Time:  1.103  Rel. Train L2 Loss :  0.021028597023752  Rel. Test L2 Loss :  0.021491501480340958  Test L2 Loss :  0.03769757091999054  inv_L_scale:  [1.0, 1.0]
Epoch :  216  Time:  1.103  Rel. Train L2 Loss :  0.020471469172173077  Rel. Test L2 Loss :  0.02119695082306862  Test L2 Loss :  0.03724205553531647  inv_L_scale:  [1.0, 1.0]
Epoch :  217  Time:  1.103  Rel. Train L2 Loss :  0.020794684953159757  Rel. Test L2 Loss :  0.02249525710940361  Test L2 Loss :  0.040197070538997653  inv_L_scale:  [1.0, 1.0]
Epoch :  218  Time:  1.105  Rel. Train L2 Loss :  0.020634874494539365  Rel. Test L2 Loss :  0.024336241483688355  Test L2 Loss :  0.04298397794365883  inv_L_scale:  [1.0, 1.0]
Epoch :  219  Time:  1.104  Rel. Train L2 Loss :  0.020791222337219452  Rel. Test L2 Loss :  0.024210464507341385  Test L2 Loss :  0.04302403286099434  inv_L_scale:  [1.0, 1.0]
Epoch :  220  Time:  1.103  Rel. Train L2 Loss :  0.020569794095224803  Rel. Test L2 Loss :  0.02172937259078026  Test L2 Loss :  0.038107164800167084  inv_L_scale:  [1.0, 1.0]
Epoch :  221  Time:  1.103  Rel. Train L2 Loss :  0.020564225332604515  Rel. Test L2 Loss :  0.022846186906099318  Test L2 Loss :  0.040156220495700834  inv_L_scale:  [1.0, 1.0]
Epoch :  222  Time:  1.103  Rel. Train L2 Loss :  0.02078517376548714  Rel. Test L2 Loss :  0.022261799201369285  Test L2 Loss :  0.038990836143493655  inv_L_scale:  [1.0, 1.0]
Epoch :  223  Time:  1.104  Rel. Train L2 Loss :  0.020791623799337283  Rel. Test L2 Loss :  0.021913552582263948  Test L2 Loss :  0.03845348998904228  inv_L_scale:  [1.0, 1.0]
Epoch :  224  Time:  1.103  Rel. Train L2 Loss :  0.020436550494697357  Rel. Test L2 Loss :  0.02088836006820202  Test L2 Loss :  0.03659079387784004  inv_L_scale:  [1.0, 1.0]
Epoch :  225  Time:  1.102  Rel. Train L2 Loss :  0.02030962517691983  Rel. Test L2 Loss :  0.021853285431861876  Test L2 Loss :  0.038208848536014556  inv_L_scale:  [1.0, 1.0]
Epoch :  226  Time:  1.102  Rel. Train L2 Loss :  0.02062932906051477  Rel. Test L2 Loss :  0.021083013713359834  Test L2 Loss :  0.03722996532917023  inv_L_scale:  [1.0, 1.0]
Epoch :  227  Time:  1.104  Rel. Train L2 Loss :  0.0201466204226017  Rel. Test L2 Loss :  0.02050777703523636  Test L2 Loss :  0.035938781052827835  inv_L_scale:  [1.0, 1.0]
Epoch :  228  Time:  1.103  Rel. Train L2 Loss :  0.019998034694128565  Rel. Test L2 Loss :  0.02076795756816864  Test L2 Loss :  0.0363606022298336  inv_L_scale:  [1.0, 1.0]
Epoch :  229  Time:  1.102  Rel. Train L2 Loss :  0.020482858576708368  Rel. Test L2 Loss :  0.020809885933995246  Test L2 Loss :  0.036659713685512546  inv_L_scale:  [1.0, 1.0]
Epoch :  230  Time:  1.101  Rel. Train L2 Loss :  0.020451206962267557  Rel. Test L2 Loss :  0.019959941580891608  Test L2 Loss :  0.034841190725564956  inv_L_scale:  [1.0, 1.0]
Epoch :  231  Time:  1.101  Rel. Train L2 Loss :  0.02034860072036584  Rel. Test L2 Loss :  0.020777261927723886  Test L2 Loss :  0.03635301142930984  inv_L_scale:  [1.0, 1.0]
Epoch :  232  Time:  1.101  Rel. Train L2 Loss :  0.01956485316157341  Rel. Test L2 Loss :  0.02122525133192539  Test L2 Loss :  0.037519200444221495  inv_L_scale:  [1.0, 1.0]
Epoch :  233  Time:  1.1  Rel. Train L2 Loss :  0.01999084846013122  Rel. Test L2 Loss :  0.021135368645191194  Test L2 Loss :  0.03694318264722824  inv_L_scale:  [1.0, 1.0]
Epoch :  234  Time:  1.101  Rel. Train L2 Loss :  0.019956749197509553  Rel. Test L2 Loss :  0.020002366900444032  Test L2 Loss :  0.03501572608947754  inv_L_scale:  [1.0, 1.0]
Epoch :  235  Time:  1.102  Rel. Train L2 Loss :  0.020062124985787605  Rel. Test L2 Loss :  0.021921956390142442  Test L2 Loss :  0.03848818331956863  inv_L_scale:  [1.0, 1.0]
Epoch :  236  Time:  1.102  Rel. Train L2 Loss :  0.020264422715538077  Rel. Test L2 Loss :  0.021566300243139266  Test L2 Loss :  0.0380657884478569  inv_L_scale:  [1.0, 1.0]
Epoch :  237  Time:  1.102  Rel. Train L2 Loss :  0.01998945880267355  Rel. Test L2 Loss :  0.02281376376748085  Test L2 Loss :  0.04001985177397728  inv_L_scale:  [1.0, 1.0]
Epoch :  238  Time:  1.102  Rel. Train L2 Loss :  0.020045514677961666  Rel. Test L2 Loss :  0.021517404243350028  Test L2 Loss :  0.03775960609316826  inv_L_scale:  [1.0, 1.0]
Epoch :  239  Time:  1.103  Rel. Train L2 Loss :  0.019779529091384675  Rel. Test L2 Loss :  0.01966643750667572  Test L2 Loss :  0.03446465015411377  inv_L_scale:  [1.0, 1.0]
Epoch :  240  Time:  1.103  Rel. Train L2 Loss :  0.019854823822776476  Rel. Test L2 Loss :  0.021243684217333792  Test L2 Loss :  0.037299912869930264  inv_L_scale:  [1.0, 1.0]
Epoch :  241  Time:  1.102  Rel. Train L2 Loss :  0.02031413744721148  Rel. Test L2 Loss :  0.023058436512947082  Test L2 Loss :  0.04110125571489334  inv_L_scale:  [1.0, 1.0]
Epoch :  242  Time:  1.102  Rel. Train L2 Loss :  0.020203274803029168  Rel. Test L2 Loss :  0.021177781373262407  Test L2 Loss :  0.03707156479358673  inv_L_scale:  [1.0, 1.0]
Epoch :  243  Time:  1.102  Rel. Train L2 Loss :  0.02011776107880804  Rel. Test L2 Loss :  0.021094873398542404  Test L2 Loss :  0.03682851195335388  inv_L_scale:  [1.0, 1.0]
Epoch :  244  Time:  1.103  Rel. Train L2 Loss :  0.019970248945885234  Rel. Test L2 Loss :  0.020110406056046484  Test L2 Loss :  0.035219937711954113  inv_L_scale:  [1.0, 1.0]
Epoch :  245  Time:  1.104  Rel. Train L2 Loss :  0.01971613746550348  Rel. Test L2 Loss :  0.020763773545622824  Test L2 Loss :  0.03634228065609932  inv_L_scale:  [1.0, 1.0]
Epoch :  246  Time:  1.104  Rel. Train L2 Loss :  0.019586713338891667  Rel. Test L2 Loss :  0.02076360985636711  Test L2 Loss :  0.03641362950205803  inv_L_scale:  [1.0, 1.0]
Epoch :  247  Time:  1.103  Rel. Train L2 Loss :  0.019788334626290534  Rel. Test L2 Loss :  0.021646199077367784  Test L2 Loss :  0.038058527410030366  inv_L_scale:  [1.0, 1.0]
Epoch :  248  Time:  1.102  Rel. Train L2 Loss :  0.020851422631078295  Rel. Test L2 Loss :  0.02149095982313156  Test L2 Loss :  0.037428090274333956  inv_L_scale:  [1.0, 1.0]
Epoch :  249  Time:  1.103  Rel. Train L2 Loss :  0.019739973677529228  Rel. Test L2 Loss :  0.02011500157415867  Test L2 Loss :  0.03506799399852753  inv_L_scale:  [1.0, 1.0]
Epoch :  250  Time:  1.102  Rel. Train L2 Loss :  0.019556152290768094  Rel. Test L2 Loss :  0.021661035120487213  Test L2 Loss :  0.0381097187101841  inv_L_scale:  [1.0, 1.0]
Epoch :  251  Time:  1.102  Rel. Train L2 Loss :  0.019535497509770922  Rel. Test L2 Loss :  0.021378119364380836  Test L2 Loss :  0.0375185814499855  inv_L_scale:  [1.0, 1.0]
Epoch :  252  Time:  1.103  Rel. Train L2 Loss :  0.019601890366110538  Rel. Test L2 Loss :  0.01990566000342369  Test L2 Loss :  0.03479104921221733  inv_L_scale:  [1.0, 1.0]
Epoch :  253  Time:  1.103  Rel. Train L2 Loss :  0.019891284679373105  Rel. Test L2 Loss :  0.022015119343996047  Test L2 Loss :  0.03855622559785843  inv_L_scale:  [1.0, 1.0]
Epoch :  254  Time:  1.103  Rel. Train L2 Loss :  0.01941978389190303  Rel. Test L2 Loss :  0.019980920031666755  Test L2 Loss :  0.03486028805375099  inv_L_scale:  [1.0, 1.0]
Epoch :  255  Time:  1.102  Rel. Train L2 Loss :  0.0194624702549643  Rel. Test L2 Loss :  0.0214842776209116  Test L2 Loss :  0.03789577007293701  inv_L_scale:  [1.0, 1.0]
Epoch :  256  Time:  1.103  Rel. Train L2 Loss :  0.019388767778873443  Rel. Test L2 Loss :  0.02173425108194351  Test L2 Loss :  0.038127217590808865  inv_L_scale:  [1.0, 1.0]
Epoch :  257  Time:  1.103  Rel. Train L2 Loss :  0.019433160680863593  Rel. Test L2 Loss :  0.02037870794534683  Test L2 Loss :  0.035883173048496246  inv_L_scale:  [1.0, 1.0]
Epoch :  258  Time:  1.102  Rel. Train L2 Loss :  0.01913359929704004  Rel. Test L2 Loss :  0.01986842170357704  Test L2 Loss :  0.03489613145589829  inv_L_scale:  [1.0, 1.0]
Epoch :  259  Time:  1.103  Rel. Train L2 Loss :  0.018992258600062793  Rel. Test L2 Loss :  0.020080317705869676  Test L2 Loss :  0.03482672914862633  inv_L_scale:  [1.0, 1.0]
Epoch :  260  Time:  1.102  Rel. Train L2 Loss :  0.01906401687198215  Rel. Test L2 Loss :  0.02102639988064766  Test L2 Loss :  0.03700861021876335  inv_L_scale:  [1.0, 1.0]
Epoch :  261  Time:  1.102  Rel. Train L2 Loss :  0.019392175608211094  Rel. Test L2 Loss :  0.019785194993019103  Test L2 Loss :  0.03450829148292542  inv_L_scale:  [1.0, 1.0]
Epoch :  262  Time:  1.104  Rel. Train L2 Loss :  0.019204522048433623  Rel. Test L2 Loss :  0.020012919828295707  Test L2 Loss :  0.03491157308220863  inv_L_scale:  [1.0, 1.0]
Epoch :  263  Time:  1.103  Rel. Train L2 Loss :  0.019513439527816243  Rel. Test L2 Loss :  0.020202643126249312  Test L2 Loss :  0.03530777648091316  inv_L_scale:  [1.0, 1.0]
Epoch :  264  Time:  1.101  Rel. Train L2 Loss :  0.019403784150878588  Rel. Test L2 Loss :  0.019457419738173484  Test L2 Loss :  0.0340643709897995  inv_L_scale:  [1.0, 1.0]
Epoch :  265  Time:  1.105  Rel. Train L2 Loss :  0.019460123653213184  Rel. Test L2 Loss :  0.01965666241943836  Test L2 Loss :  0.03431186497211456  inv_L_scale:  [1.0, 1.0]
Epoch :  266  Time:  1.106  Rel. Train L2 Loss :  0.01900429651969009  Rel. Test L2 Loss :  0.022222287952899933  Test L2 Loss :  0.03918084979057312  inv_L_scale:  [1.0, 1.0]
Epoch :  267  Time:  1.102  Rel. Train L2 Loss :  0.01897638503048155  Rel. Test L2 Loss :  0.019811135604977607  Test L2 Loss :  0.03474041670560837  inv_L_scale:  [1.0, 1.0]
Epoch :  268  Time:  1.102  Rel. Train L2 Loss :  0.018962613667050997  Rel. Test L2 Loss :  0.02004765912890434  Test L2 Loss :  0.03502420216798782  inv_L_scale:  [1.0, 1.0]
Epoch :  269  Time:  1.102  Rel. Train L2 Loss :  0.018966518491506577  Rel. Test L2 Loss :  0.020846863985061647  Test L2 Loss :  0.036859233677387235  inv_L_scale:  [1.0, 1.0]
Epoch :  270  Time:  1.102  Rel. Train L2 Loss :  0.019041286955277126  Rel. Test L2 Loss :  0.019786984026432038  Test L2 Loss :  0.034566189348697665  inv_L_scale:  [1.0, 1.0]
Epoch :  271  Time:  1.102  Rel. Train L2 Loss :  0.019037468313342996  Rel. Test L2 Loss :  0.02128323294222355  Test L2 Loss :  0.03748185932636261  inv_L_scale:  [1.0, 1.0]
Epoch :  272  Time:  1.102  Rel. Train L2 Loss :  0.01929885452820195  Rel. Test L2 Loss :  0.019253534078598023  Test L2 Loss :  0.033410037010908125  inv_L_scale:  [1.0, 1.0]
Epoch :  273  Time:  1.102  Rel. Train L2 Loss :  0.018803919297125604  Rel. Test L2 Loss :  0.020052608624100684  Test L2 Loss :  0.03495355576276779  inv_L_scale:  [1.0, 1.0]
Epoch :  274  Time:  1.102  Rel. Train L2 Loss :  0.018845963089002504  Rel. Test L2 Loss :  0.01979839228093624  Test L2 Loss :  0.03465366825461388  inv_L_scale:  [1.0, 1.0]
Epoch :  275  Time:  1.102  Rel. Train L2 Loss :  0.019108379905422527  Rel. Test L2 Loss :  0.01958417899906635  Test L2 Loss :  0.034205672293901444  inv_L_scale:  [1.0, 1.0]
Epoch :  276  Time:  1.104  Rel. Train L2 Loss :  0.01878350194957521  Rel. Test L2 Loss :  0.02066360376775265  Test L2 Loss :  0.035993615835905074  inv_L_scale:  [1.0, 1.0]
Epoch :  277  Time:  1.103  Rel. Train L2 Loss :  0.019533220074243015  Rel. Test L2 Loss :  0.020030734837055208  Test L2 Loss :  0.034750030785799024  inv_L_scale:  [1.0, 1.0]
Epoch :  278  Time:  1.103  Rel. Train L2 Loss :  0.018940496486094263  Rel. Test L2 Loss :  0.01993934988975525  Test L2 Loss :  0.034922716617584226  inv_L_scale:  [1.0, 1.0]
Epoch :  279  Time:  1.104  Rel. Train L2 Loss :  0.019060503815611203  Rel. Test L2 Loss :  0.020243173241615297  Test L2 Loss :  0.03556352257728577  inv_L_scale:  [1.0, 1.0]
Epoch :  280  Time:  1.103  Rel. Train L2 Loss :  0.018738173039423094  Rel. Test L2 Loss :  0.02011714205145836  Test L2 Loss :  0.035319900810718535  inv_L_scale:  [1.0, 1.0]
Epoch :  281  Time:  1.103  Rel. Train L2 Loss :  0.018837688114080164  Rel. Test L2 Loss :  0.019663889557123185  Test L2 Loss :  0.03450996816158294  inv_L_scale:  [1.0, 1.0]
Epoch :  282  Time:  1.103  Rel. Train L2 Loss :  0.01936645576937331  Rel. Test L2 Loss :  0.021744156926870345  Test L2 Loss :  0.038340243846178054  inv_L_scale:  [1.0, 1.0]
Epoch :  283  Time:  1.103  Rel. Train L2 Loss :  0.019490313256780308  Rel. Test L2 Loss :  0.020075276046991348  Test L2 Loss :  0.035133866667747496  inv_L_scale:  [1.0, 1.0]
Epoch :  284  Time:  1.103  Rel. Train L2 Loss :  0.019017844510575137  Rel. Test L2 Loss :  0.020322532057762147  Test L2 Loss :  0.03565543249249458  inv_L_scale:  [1.0, 1.0]
Epoch :  285  Time:  1.103  Rel. Train L2 Loss :  0.018971115938491292  Rel. Test L2 Loss :  0.01992000885307789  Test L2 Loss :  0.034525990784168244  inv_L_scale:  [1.0, 1.0]
Epoch :  286  Time:  1.104  Rel. Train L2 Loss :  0.019027584551109207  Rel. Test L2 Loss :  0.02010501816868782  Test L2 Loss :  0.035490933954715725  inv_L_scale:  [1.0, 1.0]
Epoch :  287  Time:  1.103  Rel. Train L2 Loss :  0.019031088277697564  Rel. Test L2 Loss :  0.019092372953891754  Test L2 Loss :  0.03327101543545723  inv_L_scale:  [1.0, 1.0]
Epoch :  288  Time:  1.104  Rel. Train L2 Loss :  0.018714665940238368  Rel. Test L2 Loss :  0.01922030232846737  Test L2 Loss :  0.033399351984262464  inv_L_scale:  [1.0, 1.0]
Epoch :  289  Time:  1.104  Rel. Train L2 Loss :  0.018563274749451214  Rel. Test L2 Loss :  0.019473693072795867  Test L2 Loss :  0.033955033719539646  inv_L_scale:  [1.0, 1.0]
Epoch :  290  Time:  1.104  Rel. Train L2 Loss :  0.01883092054890262  Rel. Test L2 Loss :  0.018882555291056632  Test L2 Loss :  0.03295391127467155  inv_L_scale:  [1.0, 1.0]
Epoch :  291  Time:  1.104  Rel. Train L2 Loss :  0.018361689531140857  Rel. Test L2 Loss :  0.020375161468982696  Test L2 Loss :  0.03563049763441086  inv_L_scale:  [1.0, 1.0]
Epoch :  292  Time:  1.104  Rel. Train L2 Loss :  0.01841569497353501  Rel. Test L2 Loss :  0.018753181621432306  Test L2 Loss :  0.03268649771809578  inv_L_scale:  [1.0, 1.0]
Epoch :  293  Time:  1.104  Rel. Train L2 Loss :  0.018685350633329816  Rel. Test L2 Loss :  0.01857965536415577  Test L2 Loss :  0.03242148205637932  inv_L_scale:  [1.0, 1.0]
Epoch :  294  Time:  1.104  Rel. Train L2 Loss :  0.018520467686984274  Rel. Test L2 Loss :  0.019034840166568756  Test L2 Loss :  0.03302776828408241  inv_L_scale:  [1.0, 1.0]
Epoch :  295  Time:  1.104  Rel. Train L2 Loss :  0.018456629812717437  Rel. Test L2 Loss :  0.020180025473237037  Test L2 Loss :  0.035375989824533466  inv_L_scale:  [1.0, 1.0]
Epoch :  296  Time:  1.104  Rel. Train L2 Loss :  0.018407138304577932  Rel. Test L2 Loss :  0.01909264110028744  Test L2 Loss :  0.03338736474514008  inv_L_scale:  [1.0, 1.0]
Epoch :  297  Time:  1.104  Rel. Train L2 Loss :  0.018307645718256632  Rel. Test L2 Loss :  0.019063149467110633  Test L2 Loss :  0.03322395920753479  inv_L_scale:  [1.0, 1.0]
Epoch :  298  Time:  1.105  Rel. Train L2 Loss :  0.018224211111664772  Rel. Test L2 Loss :  0.01951692298054695  Test L2 Loss :  0.0339724263548851  inv_L_scale:  [1.0, 1.0]
Epoch :  299  Time:  1.106  Rel. Train L2 Loss :  0.018135759863588546  Rel. Test L2 Loss :  0.019375913739204408  Test L2 Loss :  0.03380701065063477  inv_L_scale:  [1.0, 1.0]
Epoch :  300  Time:  1.105  Rel. Train L2 Loss :  0.018307497849067052  Rel. Test L2 Loss :  0.019000960364937782  Test L2 Loss :  0.033121750503778455  inv_L_scale:  [1.0, 1.0]
Epoch :  301  Time:  1.104  Rel. Train L2 Loss :  0.01872933010260264  Rel. Test L2 Loss :  0.021295099407434463  Test L2 Loss :  0.03787799835205078  inv_L_scale:  [1.0, 1.0]
Epoch :  302  Time:  1.104  Rel. Train L2 Loss :  0.018464558025201163  Rel. Test L2 Loss :  0.019095544442534446  Test L2 Loss :  0.033213692754507064  inv_L_scale:  [1.0, 1.0]
Epoch :  303  Time:  1.103  Rel. Train L2 Loss :  0.01803027951055103  Rel. Test L2 Loss :  0.019398399218916892  Test L2 Loss :  0.03410223379731178  inv_L_scale:  [1.0, 1.0]
Epoch :  304  Time:  1.103  Rel. Train L2 Loss :  0.01798313674827417  Rel. Test L2 Loss :  0.018840161710977556  Test L2 Loss :  0.03271407127380371  inv_L_scale:  [1.0, 1.0]
Epoch :  305  Time:  1.103  Rel. Train L2 Loss :  0.01797715052962303  Rel. Test L2 Loss :  0.019981395602226257  Test L2 Loss :  0.03487960249185562  inv_L_scale:  [1.0, 1.0]
Epoch :  306  Time:  1.103  Rel. Train L2 Loss :  0.018133056230015224  Rel. Test L2 Loss :  0.019138773009181022  Test L2 Loss :  0.03349476411938667  inv_L_scale:  [1.0, 1.0]
Epoch :  307  Time:  1.104  Rel. Train L2 Loss :  0.018017688708172903  Rel. Test L2 Loss :  0.018682373836636543  Test L2 Loss :  0.03243294209241867  inv_L_scale:  [1.0, 1.0]
Epoch :  308  Time:  1.102  Rel. Train L2 Loss :  0.018128549423482684  Rel. Test L2 Loss :  0.018503676801919937  Test L2 Loss :  0.03219817161560059  inv_L_scale:  [1.0, 1.0]
Epoch :  309  Time:  1.102  Rel. Train L2 Loss :  0.01792201976809237  Rel. Test L2 Loss :  0.019204117357730865  Test L2 Loss :  0.03352093696594238  inv_L_scale:  [1.0, 1.0]
Epoch :  310  Time:  1.102  Rel. Train L2 Loss :  0.017835303843021393  Rel. Test L2 Loss :  0.018777207881212236  Test L2 Loss :  0.03276959881186485  inv_L_scale:  [1.0, 1.0]
Epoch :  311  Time:  1.102  Rel. Train L2 Loss :  0.018022121745679114  Rel. Test L2 Loss :  0.019018234759569166  Test L2 Loss :  0.033402033150196075  inv_L_scale:  [1.0, 1.0]
Epoch :  312  Time:  1.102  Rel. Train L2 Loss :  0.01801317012558381  Rel. Test L2 Loss :  0.018570305854082106  Test L2 Loss :  0.03236010208725929  inv_L_scale:  [1.0, 1.0]
Epoch :  313  Time:  1.102  Rel. Train L2 Loss :  0.017704540722899967  Rel. Test L2 Loss :  0.0183185363560915  Test L2 Loss :  0.03190465614199638  inv_L_scale:  [1.0, 1.0]
Epoch :  314  Time:  1.103  Rel. Train L2 Loss :  0.017653021381960975  Rel. Test L2 Loss :  0.018823511451482772  Test L2 Loss :  0.03276598252356053  inv_L_scale:  [1.0, 1.0]
Epoch :  315  Time:  1.102  Rel. Train L2 Loss :  0.017877363173498046  Rel. Test L2 Loss :  0.01895102173089981  Test L2 Loss :  0.03310165882110596  inv_L_scale:  [1.0, 1.0]
Epoch :  316  Time:  1.104  Rel. Train L2 Loss :  0.018031297557883793  Rel. Test L2 Loss :  0.019259413033723832  Test L2 Loss :  0.03360301479697227  inv_L_scale:  [1.0, 1.0]
Epoch :  317  Time:  1.102  Rel. Train L2 Loss :  0.017805600646469327  Rel. Test L2 Loss :  0.018647067472338675  Test L2 Loss :  0.03250684715807438  inv_L_scale:  [1.0, 1.0]
Epoch :  318  Time:  1.102  Rel. Train L2 Loss :  0.01785257928073406  Rel. Test L2 Loss :  0.01848767414689064  Test L2 Loss :  0.03208947978913784  inv_L_scale:  [1.0, 1.0]
Epoch :  319  Time:  1.102  Rel. Train L2 Loss :  0.017656866469317013  Rel. Test L2 Loss :  0.01892596110701561  Test L2 Loss :  0.03303324207663536  inv_L_scale:  [1.0, 1.0]
Epoch :  320  Time:  1.102  Rel. Train L2 Loss :  0.01777291473415163  Rel. Test L2 Loss :  0.018643342703580857  Test L2 Loss :  0.03254363879561424  inv_L_scale:  [1.0, 1.0]
Epoch :  321  Time:  1.102  Rel. Train L2 Loss :  0.017849222678277227  Rel. Test L2 Loss :  0.01835868626832962  Test L2 Loss :  0.03192238360643387  inv_L_scale:  [1.0, 1.0]
Epoch :  322  Time:  1.1  Rel. Train L2 Loss :  0.017872412643498845  Rel. Test L2 Loss :  0.018774289190769195  Test L2 Loss :  0.03253532387316227  inv_L_scale:  [1.0, 1.0]
Epoch :  323  Time:  1.1  Rel. Train L2 Loss :  0.018017408152421314  Rel. Test L2 Loss :  0.019014931097626687  Test L2 Loss :  0.033204779773950574  inv_L_scale:  [1.0, 1.0]
Epoch :  324  Time:  1.1  Rel. Train L2 Loss :  0.017827326613995765  Rel. Test L2 Loss :  0.01896710440516472  Test L2 Loss :  0.033034557849168776  inv_L_scale:  [1.0, 1.0]
Epoch :  325  Time:  1.1  Rel. Train L2 Loss :  0.017796543538570405  Rel. Test L2 Loss :  0.018495132923126222  Test L2 Loss :  0.03214972972869873  inv_L_scale:  [1.0, 1.0]
Epoch :  326  Time:  1.1  Rel. Train L2 Loss :  0.01770230896357033  Rel. Test L2 Loss :  0.018301117420196533  Test L2 Loss :  0.03192735493183136  inv_L_scale:  [1.0, 1.0]
Epoch :  327  Time:  1.1  Rel. Train L2 Loss :  0.01774141527298424  Rel. Test L2 Loss :  0.01935769997537136  Test L2 Loss :  0.033937023878097536  inv_L_scale:  [1.0, 1.0]
Epoch :  328  Time:  1.1  Rel. Train L2 Loss :  0.017456657518115308  Rel. Test L2 Loss :  0.01855506472289562  Test L2 Loss :  0.0324490787088871  inv_L_scale:  [1.0, 1.0]
Epoch :  329  Time:  1.1  Rel. Train L2 Loss :  0.017370963601602448  Rel. Test L2 Loss :  0.018037978559732437  Test L2 Loss :  0.03137468636035919  inv_L_scale:  [1.0, 1.0]
Epoch :  330  Time:  1.099  Rel. Train L2 Loss :  0.017610416693819894  Rel. Test L2 Loss :  0.01886229954659939  Test L2 Loss :  0.032840499728918074  inv_L_scale:  [1.0, 1.0]
Epoch :  331  Time:  1.1  Rel. Train L2 Loss :  0.01747872970170445  Rel. Test L2 Loss :  0.01840383969247341  Test L2 Loss :  0.03205636531114578  inv_L_scale:  [1.0, 1.0]
Epoch :  332  Time:  1.102  Rel. Train L2 Loss :  0.017436470554934608  Rel. Test L2 Loss :  0.01819211833178997  Test L2 Loss :  0.031645141541957855  inv_L_scale:  [1.0, 1.0]
Epoch :  333  Time:  1.101  Rel. Train L2 Loss :  0.017338713109493257  Rel. Test L2 Loss :  0.018347143232822417  Test L2 Loss :  0.032106868624687195  inv_L_scale:  [1.0, 1.0]
Epoch :  334  Time:  1.102  Rel. Train L2 Loss :  0.017423963422576585  Rel. Test L2 Loss :  0.019977740719914438  Test L2 Loss :  0.03509329497814179  inv_L_scale:  [1.0, 1.0]
Epoch :  335  Time:  1.101  Rel. Train L2 Loss :  0.017792400187916224  Rel. Test L2 Loss :  0.018673691749572754  Test L2 Loss :  0.03254874989390373  inv_L_scale:  [1.0, 1.0]
Epoch :  336  Time:  1.101  Rel. Train L2 Loss :  0.018356847912073135  Rel. Test L2 Loss :  0.0186402927339077  Test L2 Loss :  0.032343518435955045  inv_L_scale:  [1.0, 1.0]
Epoch :  337  Time:  1.101  Rel. Train L2 Loss :  0.017729257088568477  Rel. Test L2 Loss :  0.01831798329949379  Test L2 Loss :  0.031762527599930764  inv_L_scale:  [1.0, 1.0]
Epoch :  338  Time:  1.1  Rel. Train L2 Loss :  0.017762288914786446  Rel. Test L2 Loss :  0.018579417020082475  Test L2 Loss :  0.03217138260602951  inv_L_scale:  [1.0, 1.0]
Epoch :  339  Time:  1.1  Rel. Train L2 Loss :  0.01765957915948497  Rel. Test L2 Loss :  0.01864877760410309  Test L2 Loss :  0.032603718787431714  inv_L_scale:  [1.0, 1.0]
Epoch :  340  Time:  1.1  Rel. Train L2 Loss :  0.01749301773806413  Rel. Test L2 Loss :  0.018410928025841714  Test L2 Loss :  0.03190624989569187  inv_L_scale:  [1.0, 1.0]
Epoch :  341  Time:  1.1  Rel. Train L2 Loss :  0.017303495647178757  Rel. Test L2 Loss :  0.01843441091477871  Test L2 Loss :  0.03209431678056717  inv_L_scale:  [1.0, 1.0]
Epoch :  342  Time:  1.1  Rel. Train L2 Loss :  0.01736689324180285  Rel. Test L2 Loss :  0.018135906010866166  Test L2 Loss :  0.03142484866082668  inv_L_scale:  [1.0, 1.0]
Epoch :  343  Time:  1.1  Rel. Train L2 Loss :  0.017205594115787082  Rel. Test L2 Loss :  0.017941924929618835  Test L2 Loss :  0.031195966228842735  inv_L_scale:  [1.0, 1.0]
Epoch :  344  Time:  1.103  Rel. Train L2 Loss :  0.017302152787645658  Rel. Test L2 Loss :  0.01859858341515064  Test L2 Loss :  0.03246731862425804  inv_L_scale:  [1.0, 1.0]
Epoch :  345  Time:  1.1  Rel. Train L2 Loss :  0.01718930285423994  Rel. Test L2 Loss :  0.018297568559646607  Test L2 Loss :  0.03202338665723801  inv_L_scale:  [1.0, 1.0]
Epoch :  346  Time:  1.1  Rel. Train L2 Loss :  0.01743813728292783  Rel. Test L2 Loss :  0.018231877833604814  Test L2 Loss :  0.03174627110362053  inv_L_scale:  [1.0, 1.0]
Epoch :  347  Time:  1.1  Rel. Train L2 Loss :  0.017315740800566144  Rel. Test L2 Loss :  0.01794280156493187  Test L2 Loss :  0.031236613616347313  inv_L_scale:  [1.0, 1.0]
Epoch :  348  Time:  1.101  Rel. Train L2 Loss :  0.017048345249560143  Rel. Test L2 Loss :  0.017787465304136277  Test L2 Loss :  0.03083314873278141  inv_L_scale:  [1.0, 1.0]
Epoch :  349  Time:  1.101  Rel. Train L2 Loss :  0.01703461184269852  Rel. Test L2 Loss :  0.01764903225004673  Test L2 Loss :  0.030621344149112703  inv_L_scale:  [1.0, 1.0]
Epoch :  350  Time:  1.101  Rel. Train L2 Loss :  0.017019559269150098  Rel. Test L2 Loss :  0.01760861314833164  Test L2 Loss :  0.030579121708869936  inv_L_scale:  [1.0, 1.0]
Epoch :  351  Time:  1.101  Rel. Train L2 Loss :  0.016947861657374434  Rel. Test L2 Loss :  0.017697783410549162  Test L2 Loss :  0.03074765108525753  inv_L_scale:  [1.0, 1.0]
Epoch :  352  Time:  1.099  Rel. Train L2 Loss :  0.017082133491834003  Rel. Test L2 Loss :  0.017753945365548134  Test L2 Loss :  0.030818648487329483  inv_L_scale:  [1.0, 1.0]
Epoch :  353  Time:  1.101  Rel. Train L2 Loss :  0.017092652395367624  Rel. Test L2 Loss :  0.01801115073263645  Test L2 Loss :  0.031295986473560335  inv_L_scale:  [1.0, 1.0]
Epoch :  354  Time:  1.101  Rel. Train L2 Loss :  0.017007285348243185  Rel. Test L2 Loss :  0.017819491028785706  Test L2 Loss :  0.030879587531089783  inv_L_scale:  [1.0, 1.0]
Epoch :  355  Time:  1.1  Rel. Train L2 Loss :  0.017027478367090225  Rel. Test L2 Loss :  0.01878255099058151  Test L2 Loss :  0.03296478688716888  inv_L_scale:  [1.0, 1.0]
Epoch :  356  Time:  1.1  Rel. Train L2 Loss :  0.017021131242314975  Rel. Test L2 Loss :  0.01843024604022503  Test L2 Loss :  0.03210645839571953  inv_L_scale:  [1.0, 1.0]
Epoch :  357  Time:  1.102  Rel. Train L2 Loss :  0.016951875198218558  Rel. Test L2 Loss :  0.017822495475411416  Test L2 Loss :  0.0309604386985302  inv_L_scale:  [1.0, 1.0]
Epoch :  358  Time:  1.102  Rel. Train L2 Loss :  0.016832042353020774  Rel. Test L2 Loss :  0.01793018080294132  Test L2 Loss :  0.031009192392230035  inv_L_scale:  [1.0, 1.0]
Epoch :  359  Time:  1.101  Rel. Train L2 Loss :  0.016822447694010204  Rel. Test L2 Loss :  0.01750512294471264  Test L2 Loss :  0.030359664261341096  inv_L_scale:  [1.0, 1.0]
Epoch :  360  Time:  1.101  Rel. Train L2 Loss :  0.01689388403462039  Rel. Test L2 Loss :  0.017643071562051773  Test L2 Loss :  0.030728668719530106  inv_L_scale:  [1.0, 1.0]
Epoch :  361  Time:  1.1  Rel. Train L2 Loss :  0.016834204114145702  Rel. Test L2 Loss :  0.017843721583485603  Test L2 Loss :  0.03092760480940342  inv_L_scale:  [1.0, 1.0]
Epoch :  362  Time:  1.102  Rel. Train L2 Loss :  0.016774799091120562  Rel. Test L2 Loss :  0.017395509108901024  Test L2 Loss :  0.030181589871644973  inv_L_scale:  [1.0, 1.0]
Epoch :  363  Time:  1.099  Rel. Train L2 Loss :  0.016754404803117115  Rel. Test L2 Loss :  0.017675794214010238  Test L2 Loss :  0.030657958984375  inv_L_scale:  [1.0, 1.0]
Epoch :  364  Time:  1.1  Rel. Train L2 Loss :  0.016725157019164827  Rel. Test L2 Loss :  0.01724017083644867  Test L2 Loss :  0.02984423652291298  inv_L_scale:  [1.0, 1.0]
Epoch :  365  Time:  1.1  Rel. Train L2 Loss :  0.01669751637511783  Rel. Test L2 Loss :  0.017515356130898  Test L2 Loss :  0.03038161650300026  inv_L_scale:  [1.0, 1.0]
Epoch :  366  Time:  1.1  Rel. Train L2 Loss :  0.016694895111852223  Rel. Test L2 Loss :  0.01725108500570059  Test L2 Loss :  0.03000536859035492  inv_L_scale:  [1.0, 1.0]
Epoch :  367  Time:  1.1  Rel. Train L2 Loss :  0.01663857641319434  Rel. Test L2 Loss :  0.017285597771406175  Test L2 Loss :  0.029963891506195068  inv_L_scale:  [1.0, 1.0]
Epoch :  368  Time:  1.1  Rel. Train L2 Loss :  0.016729045427507826  Rel. Test L2 Loss :  0.01751877799630165  Test L2 Loss :  0.030431463420391082  inv_L_scale:  [1.0, 1.0]
Epoch :  369  Time:  1.1  Rel. Train L2 Loss :  0.016656634045971765  Rel. Test L2 Loss :  0.017386585026979446  Test L2 Loss :  0.030104971006512642  inv_L_scale:  [1.0, 1.0]
Epoch :  370  Time:  1.101  Rel. Train L2 Loss :  0.016647991082734532  Rel. Test L2 Loss :  0.017425698041915894  Test L2 Loss :  0.030228729397058486  inv_L_scale:  [1.0, 1.0]
Epoch :  371  Time:  1.101  Rel. Train L2 Loss :  0.016640754727025826  Rel. Test L2 Loss :  0.017662232890725136  Test L2 Loss :  0.030828883796930315  inv_L_scale:  [1.0, 1.0]
Epoch :  372  Time:  1.1  Rel. Train L2 Loss :  0.016685944952898556  Rel. Test L2 Loss :  0.01741708129644394  Test L2 Loss :  0.030224027186632155  inv_L_scale:  [1.0, 1.0]
Epoch :  373  Time:  1.1  Rel. Train L2 Loss :  0.016537128471665913  Rel. Test L2 Loss :  0.01723465733230114  Test L2 Loss :  0.02990291327238083  inv_L_scale:  [1.0, 1.0]
Epoch :  374  Time:  1.1  Rel. Train L2 Loss :  0.016641130099693934  Rel. Test L2 Loss :  0.017354045882821082  Test L2 Loss :  0.030089104399085045  inv_L_scale:  [1.0, 1.0]
Epoch :  375  Time:  1.101  Rel. Train L2 Loss :  0.01658077646460798  Rel. Test L2 Loss :  0.01750097781419754  Test L2 Loss :  0.030418710857629774  inv_L_scale:  [1.0, 1.0]
Epoch :  376  Time:  1.1  Rel. Train L2 Loss :  0.016523318100306723  Rel. Test L2 Loss :  0.01744181424379349  Test L2 Loss :  0.03019287794828415  inv_L_scale:  [1.0, 1.0]
Epoch :  377  Time:  1.1  Rel. Train L2 Loss :  0.016493826773431565  Rel. Test L2 Loss :  0.017038720697164535  Test L2 Loss :  0.0295344740152359  inv_L_scale:  [1.0, 1.0]
Epoch :  378  Time:  1.1  Rel. Train L2 Loss :  0.01643533734811677  Rel. Test L2 Loss :  0.017280596792697906  Test L2 Loss :  0.029881196543574334  inv_L_scale:  [1.0, 1.0]
Epoch :  379  Time:  1.1  Rel. Train L2 Loss :  0.01655547760013077  Rel. Test L2 Loss :  0.017221189588308334  Test L2 Loss :  0.029827260226011277  inv_L_scale:  [1.0, 1.0]
Epoch :  380  Time:  1.1  Rel. Train L2 Loss :  0.01645815372467041  Rel. Test L2 Loss :  0.017627240531146525  Test L2 Loss :  0.030577730163931848  inv_L_scale:  [1.0, 1.0]
Epoch :  381  Time:  1.1  Rel. Train L2 Loss :  0.016574885472655298  Rel. Test L2 Loss :  0.017482801154255868  Test L2 Loss :  0.030394508689641952  inv_L_scale:  [1.0, 1.0]
Epoch :  382  Time:  1.101  Rel. Train L2 Loss :  0.016501910092516076  Rel. Test L2 Loss :  0.017297169044613838  Test L2 Loss :  0.030009268075227736  inv_L_scale:  [1.0, 1.0]
Epoch :  383  Time:  1.101  Rel. Train L2 Loss :  0.01639211867418554  Rel. Test L2 Loss :  0.017175207287073134  Test L2 Loss :  0.02981575019657612  inv_L_scale:  [1.0, 1.0]
Epoch :  384  Time:  1.102  Rel. Train L2 Loss :  0.016287288582987256  Rel. Test L2 Loss :  0.01698668159544468  Test L2 Loss :  0.029496073573827743  inv_L_scale:  [1.0, 1.0]
Epoch :  385  Time:  1.101  Rel. Train L2 Loss :  0.01638634055438969  Rel. Test L2 Loss :  0.017177886590361596  Test L2 Loss :  0.02979588769376278  inv_L_scale:  [1.0, 1.0]
Epoch :  386  Time:  1.101  Rel. Train L2 Loss :  0.01643760352498955  Rel. Test L2 Loss :  0.01727715529501438  Test L2 Loss :  0.030022921711206435  inv_L_scale:  [1.0, 1.0]
Epoch :  387  Time:  1.101  Rel. Train L2 Loss :  0.016282699215743275  Rel. Test L2 Loss :  0.01715619757771492  Test L2 Loss :  0.029830078706145288  inv_L_scale:  [1.0, 1.0]
Epoch :  388  Time:  1.1  Rel. Train L2 Loss :  0.016224986074699296  Rel. Test L2 Loss :  0.017476346045732498  Test L2 Loss :  0.03055075965821743  inv_L_scale:  [1.0, 1.0]
Epoch :  389  Time:  1.101  Rel. Train L2 Loss :  0.01633197462807099  Rel. Test L2 Loss :  0.017203000634908677  Test L2 Loss :  0.02984390892088413  inv_L_scale:  [1.0, 1.0]
Epoch :  390  Time:  1.1  Rel. Train L2 Loss :  0.01625789879096879  Rel. Test L2 Loss :  0.01726779878139496  Test L2 Loss :  0.029867572784423826  inv_L_scale:  [1.0, 1.0]
Epoch :  391  Time:  1.1  Rel. Train L2 Loss :  0.01624511917018228  Rel. Test L2 Loss :  0.016884324327111244  Test L2 Loss :  0.029242030531167983  inv_L_scale:  [1.0, 1.0]
Epoch :  392  Time:  1.1  Rel. Train L2 Loss :  0.016167401928040715  Rel. Test L2 Loss :  0.01713989272713661  Test L2 Loss :  0.029685088098049164  inv_L_scale:  [1.0, 1.0]
Epoch :  393  Time:  1.101  Rel. Train L2 Loss :  0.016212195898923608  Rel. Test L2 Loss :  0.017173539623618127  Test L2 Loss :  0.02989003263413906  inv_L_scale:  [1.0, 1.0]
Epoch :  394  Time:  1.1  Rel. Train L2 Loss :  0.016148168991009394  Rel. Test L2 Loss :  0.017398910000920295  Test L2 Loss :  0.030317011252045632  inv_L_scale:  [1.0, 1.0]
Epoch :  395  Time:  1.1  Rel. Train L2 Loss :  0.016608950015571382  Rel. Test L2 Loss :  0.017721998766064645  Test L2 Loss :  0.030736354067921638  inv_L_scale:  [1.0, 1.0]
Epoch :  396  Time:  1.1  Rel. Train L2 Loss :  0.016807015790707536  Rel. Test L2 Loss :  0.0173735623806715  Test L2 Loss :  0.03009994126856327  inv_L_scale:  [1.0, 1.0]
Epoch :  397  Time:  1.1  Rel. Train L2 Loss :  0.01644736203054587  Rel. Test L2 Loss :  0.017096486762166022  Test L2 Loss :  0.029595113322138787  inv_L_scale:  [1.0, 1.0]
Epoch :  398  Time:  1.1  Rel. Train L2 Loss :  0.016414151423507266  Rel. Test L2 Loss :  0.01719322383403778  Test L2 Loss :  0.029783478826284408  inv_L_scale:  [1.0, 1.0]
Epoch :  399  Time:  1.1  Rel. Train L2 Loss :  0.01628616156677405  Rel. Test L2 Loss :  0.017144053652882577  Test L2 Loss :  0.029766326621174812  inv_L_scale:  [1.0, 1.0]
Epoch :  400  Time:  1.1  Rel. Train L2 Loss :  0.016272549513313507  Rel. Test L2 Loss :  0.01742180161178112  Test L2 Loss :  0.030209633186459542  inv_L_scale:  [1.0, 1.0]
Epoch :  401  Time:  1.1  Rel. Train L2 Loss :  0.016228874093956416  Rel. Test L2 Loss :  0.017054755166172983  Test L2 Loss :  0.029523125365376473  inv_L_scale:  [1.0, 1.0]
Epoch :  402  Time:  1.101  Rel. Train L2 Loss :  0.016191580320398014  Rel. Test L2 Loss :  0.017058139219880104  Test L2 Loss :  0.02955692008137703  inv_L_scale:  [1.0, 1.0]
Epoch :  403  Time:  1.101  Rel. Train L2 Loss :  0.01610912976993455  Rel. Test L2 Loss :  0.016845187693834304  Test L2 Loss :  0.02914286553859711  inv_L_scale:  [1.0, 1.0]
Epoch :  404  Time:  1.101  Rel. Train L2 Loss :  0.016060669173796973  Rel. Test L2 Loss :  0.016791485846042634  Test L2 Loss :  0.029060992300510406  inv_L_scale:  [1.0, 1.0]
Epoch :  405  Time:  1.101  Rel. Train L2 Loss :  0.016069425601098274  Rel. Test L2 Loss :  0.01664507795125246  Test L2 Loss :  0.028763664290308952  inv_L_scale:  [1.0, 1.0]
Epoch :  406  Time:  1.1  Rel. Train L2 Loss :  0.016060296421249707  Rel. Test L2 Loss :  0.016916834563016892  Test L2 Loss :  0.02928541511297226  inv_L_scale:  [1.0, 1.0]
Epoch :  407  Time:  1.1  Rel. Train L2 Loss :  0.016026468119687505  Rel. Test L2 Loss :  0.016984439119696618  Test L2 Loss :  0.02942091628909111  inv_L_scale:  [1.0, 1.0]
Epoch :  408  Time:  1.1  Rel. Train L2 Loss :  0.016034907975958454  Rel. Test L2 Loss :  0.01689383588731289  Test L2 Loss :  0.02921684369444847  inv_L_scale:  [1.0, 1.0]
Epoch :  409  Time:  1.098  Rel. Train L2 Loss :  0.015998234666056103  Rel. Test L2 Loss :  0.017084455713629723  Test L2 Loss :  0.029671344310045242  inv_L_scale:  [1.0, 1.0]
Epoch :  410  Time:  1.101  Rel. Train L2 Loss :  0.01596485926045312  Rel. Test L2 Loss :  0.016849651746451855  Test L2 Loss :  0.02917181059718132  inv_L_scale:  [1.0, 1.0]
Epoch :  411  Time:  1.1  Rel. Train L2 Loss :  0.015890159962905777  Rel. Test L2 Loss :  0.01680056896060705  Test L2 Loss :  0.02913013696670532  inv_L_scale:  [1.0, 1.0]
Epoch :  412  Time:  1.101  Rel. Train L2 Loss :  0.01585758450958464  Rel. Test L2 Loss :  0.016792073622345926  Test L2 Loss :  0.029104800447821617  inv_L_scale:  [1.0, 1.0]
Epoch :  413  Time:  1.1  Rel. Train L2 Loss :  0.015934984534978866  Rel. Test L2 Loss :  0.016984070762991906  Test L2 Loss :  0.029472509175539018  inv_L_scale:  [1.0, 1.0]
Epoch :  414  Time:  1.1  Rel. Train L2 Loss :  0.01591924121396409  Rel. Test L2 Loss :  0.016777083203196527  Test L2 Loss :  0.029041905924677848  inv_L_scale:  [1.0, 1.0]
Epoch :  415  Time:  1.1  Rel. Train L2 Loss :  0.015863265982932515  Rel. Test L2 Loss :  0.01666582841426134  Test L2 Loss :  0.028840628117322922  inv_L_scale:  [1.0, 1.0]
Epoch :  416  Time:  1.1  Rel. Train L2 Loss :  0.015851243891649776  Rel. Test L2 Loss :  0.01663326848298311  Test L2 Loss :  0.02880025677382946  inv_L_scale:  [1.0, 1.0]
Epoch :  417  Time:  1.1  Rel. Train L2 Loss :  0.015849333554506302  Rel. Test L2 Loss :  0.01657237406820059  Test L2 Loss :  0.028692819476127625  inv_L_scale:  [1.0, 1.0]
Epoch :  418  Time:  1.1  Rel. Train L2 Loss :  0.015802543610334396  Rel. Test L2 Loss :  0.016687940917909146  Test L2 Loss :  0.02889437958598137  inv_L_scale:  [1.0, 1.0]
Epoch :  419  Time:  1.1  Rel. Train L2 Loss :  0.01582911370529069  Rel. Test L2 Loss :  0.016592209227383137  Test L2 Loss :  0.02869017392396927  inv_L_scale:  [1.0, 1.0]
Epoch :  420  Time:  1.1  Rel. Train L2 Loss :  0.015818808289865652  Rel. Test L2 Loss :  0.016580995060503482  Test L2 Loss :  0.028701620697975157  inv_L_scale:  [1.0, 1.0]
Epoch :  421  Time:  1.101  Rel. Train L2 Loss :  0.015761526657475367  Rel. Test L2 Loss :  0.016664600521326064  Test L2 Loss :  0.028812010735273362  inv_L_scale:  [1.0, 1.0]
Epoch :  422  Time:  1.1  Rel. Train L2 Loss :  0.01575774744980865  Rel. Test L2 Loss :  0.01673413544893265  Test L2 Loss :  0.028941797092556953  inv_L_scale:  [1.0, 1.0]
Epoch :  423  Time:  1.1  Rel. Train L2 Loss :  0.015798870130545564  Rel. Test L2 Loss :  0.01675448805093765  Test L2 Loss :  0.028997949957847595  inv_L_scale:  [1.0, 1.0]
Epoch :  424  Time:  1.1  Rel. Train L2 Loss :  0.01573962576687336  Rel. Test L2 Loss :  0.01668953262269497  Test L2 Loss :  0.028885002806782724  inv_L_scale:  [1.0, 1.0]
Epoch :  425  Time:  1.1  Rel. Train L2 Loss :  0.01575541217294004  Rel. Test L2 Loss :  0.016711703538894652  Test L2 Loss :  0.028892821222543715  inv_L_scale:  [1.0, 1.0]
Epoch :  426  Time:  1.102  Rel. Train L2 Loss :  0.015728562656376097  Rel. Test L2 Loss :  0.016551965326070787  Test L2 Loss :  0.028701162189245222  inv_L_scale:  [1.0, 1.0]
Epoch :  427  Time:  1.101  Rel. Train L2 Loss :  0.01571277672217952  Rel. Test L2 Loss :  0.016629242300987244  Test L2 Loss :  0.028803696930408476  inv_L_scale:  [1.0, 1.0]
Epoch :  428  Time:  1.1  Rel. Train L2 Loss :  0.01569830748769972  Rel. Test L2 Loss :  0.016631563752889635  Test L2 Loss :  0.028753442615270616  inv_L_scale:  [1.0, 1.0]
Epoch :  429  Time:  1.1  Rel. Train L2 Loss :  0.01565623487863276  Rel. Test L2 Loss :  0.01656371437013149  Test L2 Loss :  0.02868695981800556  inv_L_scale:  [1.0, 1.0]
Epoch :  430  Time:  1.1  Rel. Train L2 Loss :  0.015660057274831666  Rel. Test L2 Loss :  0.01653896741569042  Test L2 Loss :  0.028677631244063376  inv_L_scale:  [1.0, 1.0]
Epoch :  431  Time:  1.1  Rel. Train L2 Loss :  0.015632730341619914  Rel. Test L2 Loss :  0.016573174372315407  Test L2 Loss :  0.028693517744541167  inv_L_scale:  [1.0, 1.0]
Epoch :  432  Time:  1.1  Rel. Train L2 Loss :  0.015620290525257588  Rel. Test L2 Loss :  0.016568130180239678  Test L2 Loss :  0.028676438331604003  inv_L_scale:  [1.0, 1.0]
Epoch :  433  Time:  1.1  Rel. Train L2 Loss :  0.0156529690987534  Rel. Test L2 Loss :  0.016511456444859504  Test L2 Loss :  0.028623239025473594  inv_L_scale:  [1.0, 1.0]
Epoch :  434  Time:  1.1  Rel. Train L2 Loss :  0.015605663545429707  Rel. Test L2 Loss :  0.01656556099653244  Test L2 Loss :  0.028653741553425788  inv_L_scale:  [1.0, 1.0]
Epoch :  435  Time:  1.1  Rel. Train L2 Loss :  0.015564825265771813  Rel. Test L2 Loss :  0.016604110337793826  Test L2 Loss :  0.02874079339206219  inv_L_scale:  [1.0, 1.0]
Epoch :  436  Time:  1.1  Rel. Train L2 Loss :  0.015564703866839408  Rel. Test L2 Loss :  0.0164388931915164  Test L2 Loss :  0.02842073805630207  inv_L_scale:  [1.0, 1.0]
Epoch :  437  Time:  1.101  Rel. Train L2 Loss :  0.015570944804284307  Rel. Test L2 Loss :  0.01654684081673622  Test L2 Loss :  0.02859834410250187  inv_L_scale:  [1.0, 1.0]
Epoch :  438  Time:  1.097  Rel. Train L2 Loss :  0.015564443121353785  Rel. Test L2 Loss :  0.01652667634189129  Test L2 Loss :  0.028596397638320923  inv_L_scale:  [1.0, 1.0]
Epoch :  439  Time:  1.1  Rel. Train L2 Loss :  0.015612592407398753  Rel. Test L2 Loss :  0.01652459930628538  Test L2 Loss :  0.028625686690211295  inv_L_scale:  [1.0, 1.0]
Epoch :  440  Time:  1.1  Rel. Train L2 Loss :  0.015551466734872925  Rel. Test L2 Loss :  0.016445915214717388  Test L2 Loss :  0.028445845395326616  inv_L_scale:  [1.0, 1.0]
Epoch :  441  Time:  1.1  Rel. Train L2 Loss :  0.01549902253266838  Rel. Test L2 Loss :  0.016445332504808903  Test L2 Loss :  0.028464896976947783  inv_L_scale:  [1.0, 1.0]
Epoch :  442  Time:  1.1  Rel. Train L2 Loss :  0.015512287211087016  Rel. Test L2 Loss :  0.01646294254809618  Test L2 Loss :  0.028508144915103912  inv_L_scale:  [1.0, 1.0]
Epoch :  443  Time:  1.099  Rel. Train L2 Loss :  0.015491954965723885  Rel. Test L2 Loss :  0.016596765853464604  Test L2 Loss :  0.028746189400553703  inv_L_scale:  [1.0, 1.0]
Epoch :  444  Time:  1.1  Rel. Train L2 Loss :  0.015502849254343245  Rel. Test L2 Loss :  0.016470175758004187  Test L2 Loss :  0.028472291529178618  inv_L_scale:  [1.0, 1.0]
Epoch :  445  Time:  1.1  Rel. Train L2 Loss :  0.015466215440796481  Rel. Test L2 Loss :  0.016433432400226593  Test L2 Loss :  0.02842633202672005  inv_L_scale:  [1.0, 1.0]
Epoch :  446  Time:  1.1  Rel. Train L2 Loss :  0.0154560635280278  Rel. Test L2 Loss :  0.01641558438539505  Test L2 Loss :  0.028358804881572722  inv_L_scale:  [1.0, 1.0]
Epoch :  447  Time:  1.098  Rel. Train L2 Loss :  0.015452933083805773  Rel. Test L2 Loss :  0.016427474543452263  Test L2 Loss :  0.028394339978694914  inv_L_scale:  [1.0, 1.0]
Epoch :  448  Time:  1.095  Rel. Train L2 Loss :  0.01547186648266183  Rel. Test L2 Loss :  0.016522896960377693  Test L2 Loss :  0.02859587922692299  inv_L_scale:  [1.0, 1.0]
Epoch :  449  Time:  1.098  Rel. Train L2 Loss :  0.015454150057501262  Rel. Test L2 Loss :  0.01648662082850933  Test L2 Loss :  0.028531490713357924  inv_L_scale:  [1.0, 1.0]
Epoch :  450  Time:  1.097  Rel. Train L2 Loss :  0.015455934413605266  Rel. Test L2 Loss :  0.01638832539319992  Test L2 Loss :  0.028307863622903825  inv_L_scale:  [1.0, 1.0]
Epoch :  451  Time:  1.097  Rel. Train L2 Loss :  0.015412869155406952  Rel. Test L2 Loss :  0.016422552838921547  Test L2 Loss :  0.02840428039431572  inv_L_scale:  [1.0, 1.0]
Epoch :  452  Time:  1.098  Rel. Train L2 Loss :  0.015415383179982504  Rel. Test L2 Loss :  0.016380925215780735  Test L2 Loss :  0.02832235164940357  inv_L_scale:  [1.0, 1.0]
Epoch :  453  Time:  1.098  Rel. Train L2 Loss :  0.01541571843955252  Rel. Test L2 Loss :  0.016401099637150765  Test L2 Loss :  0.028372054174542426  inv_L_scale:  [1.0, 1.0]
Epoch :  454  Time:  1.099  Rel. Train L2 Loss :  0.015405975605050722  Rel. Test L2 Loss :  0.016351291686296465  Test L2 Loss :  0.02829259179532528  inv_L_scale:  [1.0, 1.0]
Epoch :  455  Time:  1.099  Rel. Train L2 Loss :  0.01539469921340545  Rel. Test L2 Loss :  0.016393345035612582  Test L2 Loss :  0.02835936866700649  inv_L_scale:  [1.0, 1.0]
Epoch :  456  Time:  1.099  Rel. Train L2 Loss :  0.015389256181402338  Rel. Test L2 Loss :  0.016429375670850278  Test L2 Loss :  0.028440687954425812  inv_L_scale:  [1.0, 1.0]
Epoch :  457  Time:  1.099  Rel. Train L2 Loss :  0.01539555285539892  Rel. Test L2 Loss :  0.016379032768309116  Test L2 Loss :  0.02831155613064766  inv_L_scale:  [1.0, 1.0]
Epoch :  458  Time:  1.098  Rel. Train L2 Loss :  0.015379866531325712  Rel. Test L2 Loss :  0.016428971141576768  Test L2 Loss :  0.028402246981859208  inv_L_scale:  [1.0, 1.0]
Epoch :  459  Time:  1.098  Rel. Train L2 Loss :  0.015356358836094538  Rel. Test L2 Loss :  0.016315004378557204  Test L2 Loss :  0.02822796791791916  inv_L_scale:  [1.0, 1.0]
Epoch :  460  Time:  1.098  Rel. Train L2 Loss :  0.015362716478606065  Rel. Test L2 Loss :  0.016291487738490106  Test L2 Loss :  0.02815409131348133  inv_L_scale:  [1.0, 1.0]
Epoch :  461  Time:  1.098  Rel. Train L2 Loss :  0.015367466575569576  Rel. Test L2 Loss :  0.016355073265731334  Test L2 Loss :  0.028302019536495207  inv_L_scale:  [1.0, 1.0]
Epoch :  462  Time:  1.098  Rel. Train L2 Loss :  0.015341320807735126  Rel. Test L2 Loss :  0.016304859966039656  Test L2 Loss :  0.0281870499253273  inv_L_scale:  [1.0, 1.0]
Epoch :  463  Time:  1.099  Rel. Train L2 Loss :  0.015332804024219514  Rel. Test L2 Loss :  0.016340427100658417  Test L2 Loss :  0.028261213600635528  inv_L_scale:  [1.0, 1.0]
Epoch :  464  Time:  1.099  Rel. Train L2 Loss :  0.015334701480136978  Rel. Test L2 Loss :  0.016338296942412855  Test L2 Loss :  0.02824349418282509  inv_L_scale:  [1.0, 1.0]
Epoch :  465  Time:  1.098  Rel. Train L2 Loss :  0.015322796437475417  Rel. Test L2 Loss :  0.016355444826185703  Test L2 Loss :  0.02827255330979824  inv_L_scale:  [1.0, 1.0]
Epoch :  466  Time:  1.098  Rel. Train L2 Loss :  0.01531307787530952  Rel. Test L2 Loss :  0.016277559362351895  Test L2 Loss :  0.02812524527311325  inv_L_scale:  [1.0, 1.0]
Epoch :  467  Time:  1.099  Rel. Train L2 Loss :  0.015288870500193702  Rel. Test L2 Loss :  0.016327511072158813  Test L2 Loss :  0.028220037817955016  inv_L_scale:  [1.0, 1.0]
Epoch :  468  Time:  1.098  Rel. Train L2 Loss :  0.015292157183090845  Rel. Test L2 Loss :  0.01633710891008377  Test L2 Loss :  0.028250298053026198  inv_L_scale:  [1.0, 1.0]
Epoch :  469  Time:  1.098  Rel. Train L2 Loss :  0.015295049564705955  Rel. Test L2 Loss :  0.016283725388348103  Test L2 Loss :  0.028144398927688597  inv_L_scale:  [1.0, 1.0]
Epoch :  470  Time:  1.099  Rel. Train L2 Loss :  0.01528494260377354  Rel. Test L2 Loss :  0.016334961988031863  Test L2 Loss :  0.02822516903281212  inv_L_scale:  [1.0, 1.0]
Epoch :  471  Time:  1.099  Rel. Train L2 Loss :  0.015281455467144649  Rel. Test L2 Loss :  0.016338838674128057  Test L2 Loss :  0.02825235478579998  inv_L_scale:  [1.0, 1.0]
Epoch :  472  Time:  1.099  Rel. Train L2 Loss :  0.01527479528139035  Rel. Test L2 Loss :  0.016317706555128098  Test L2 Loss :  0.028196171522140503  inv_L_scale:  [1.0, 1.0]
Epoch :  473  Time:  1.099  Rel. Train L2 Loss :  0.01526313907156388  Rel. Test L2 Loss :  0.016276896819472312  Test L2 Loss :  0.028114761114120482  inv_L_scale:  [1.0, 1.0]
Epoch :  474  Time:  1.098  Rel. Train L2 Loss :  0.015260839085612031  Rel. Test L2 Loss :  0.016286781094968318  Test L2 Loss :  0.028151687532663346  inv_L_scale:  [1.0, 1.0]
Epoch :  475  Time:  1.099  Rel. Train L2 Loss :  0.01525845232937071  Rel. Test L2 Loss :  0.016308624632656574  Test L2 Loss :  0.028180049955844878  inv_L_scale:  [1.0, 1.0]
Epoch :  476  Time:  1.099  Rel. Train L2 Loss :  0.01524756259802315  Rel. Test L2 Loss :  0.01629387930035591  Test L2 Loss :  0.028163641691207886  inv_L_scale:  [1.0, 1.0]
Epoch :  477  Time:  1.098  Rel. Train L2 Loss :  0.015248686936166551  Rel. Test L2 Loss :  0.01628985084593296  Test L2 Loss :  0.02815562978386879  inv_L_scale:  [1.0, 1.0]
Epoch :  478  Time:  1.098  Rel. Train L2 Loss :  0.015241410351461834  Rel. Test L2 Loss :  0.016280053369700908  Test L2 Loss :  0.02813700556755066  inv_L_scale:  [1.0, 1.0]
Epoch :  479  Time:  1.098  Rel. Train L2 Loss :  0.01523988305694527  Rel. Test L2 Loss :  0.01628937926143408  Test L2 Loss :  0.028142320364713667  inv_L_scale:  [1.0, 1.0]
Epoch :  480  Time:  1.099  Rel. Train L2 Loss :  0.01523898565934764  Rel. Test L2 Loss :  0.016283678710460662  Test L2 Loss :  0.02815206527709961  inv_L_scale:  [1.0, 1.0]
Epoch :  481  Time:  1.098  Rel. Train L2 Loss :  0.015229296622176964  Rel. Test L2 Loss :  0.016278375312685965  Test L2 Loss :  0.02812428817152977  inv_L_scale:  [1.0, 1.0]
Epoch :  482  Time:  1.099  Rel. Train L2 Loss :  0.015228498772614531  Rel. Test L2 Loss :  0.01627915173768997  Test L2 Loss :  0.028135496526956558  inv_L_scale:  [1.0, 1.0]
Epoch :  483  Time:  1.099  Rel. Train L2 Loss :  0.01522006085763375  Rel. Test L2 Loss :  0.016286156699061395  Test L2 Loss :  0.028147071450948715  inv_L_scale:  [1.0, 1.0]
Epoch :  484  Time:  1.097  Rel. Train L2 Loss :  0.01521223867105113  Rel. Test L2 Loss :  0.016279577016830443  Test L2 Loss :  0.02814106419682503  inv_L_scale:  [1.0, 1.0]
Epoch :  485  Time:  1.099  Rel. Train L2 Loss :  0.01521334042151769  Rel. Test L2 Loss :  0.01628691654652357  Test L2 Loss :  0.02815839886665344  inv_L_scale:  [1.0, 1.0]
Epoch :  486  Time:  1.098  Rel. Train L2 Loss :  0.015212155058979987  Rel. Test L2 Loss :  0.016299856938421727  Test L2 Loss :  0.028173501640558242  inv_L_scale:  [1.0, 1.0]
Epoch :  487  Time:  1.099  Rel. Train L2 Loss :  0.015213346978028616  Rel. Test L2 Loss :  0.01628241267055273  Test L2 Loss :  0.02814129412174225  inv_L_scale:  [1.0, 1.0]
Epoch :  488  Time:  1.099  Rel. Train L2 Loss :  0.015209019738766882  Rel. Test L2 Loss :  0.016273810788989068  Test L2 Loss :  0.028130826279520987  inv_L_scale:  [1.0, 1.0]
Epoch :  489  Time:  1.099  Rel. Train L2 Loss :  0.015203516201840506  Rel. Test L2 Loss :  0.016284491494297983  Test L2 Loss :  0.02814766764640808  inv_L_scale:  [1.0, 1.0]
Epoch :  490  Time:  1.099  Rel. Train L2 Loss :  0.015202198492156135  Rel. Test L2 Loss :  0.016278312020003797  Test L2 Loss :  0.028133285194635392  inv_L_scale:  [1.0, 1.0]
Epoch :  491  Time:  1.099  Rel. Train L2 Loss :  0.01519664337237676  Rel. Test L2 Loss :  0.01629178136587143  Test L2 Loss :  0.02815473884344101  inv_L_scale:  [1.0, 1.0]
Epoch :  492  Time:  1.098  Rel. Train L2 Loss :  0.015198642739819156  Rel. Test L2 Loss :  0.016278209052979945  Test L2 Loss :  0.028133336007595062  inv_L_scale:  [1.0, 1.0]
Epoch :  493  Time:  1.099  Rel. Train L2 Loss :  0.015197068726023038  Rel. Test L2 Loss :  0.016283369474112987  Test L2 Loss :  0.02814742684364319  inv_L_scale:  [1.0, 1.0]
Epoch :  494  Time:  1.099  Rel. Train L2 Loss :  0.015189941831760936  Rel. Test L2 Loss :  0.016279999129474164  Test L2 Loss :  0.028140737414360045  inv_L_scale:  [1.0, 1.0]
Epoch :  495  Time:  1.098  Rel. Train L2 Loss :  0.015192619835337004  Rel. Test L2 Loss :  0.016270414851605894  Test L2 Loss :  0.028121704310178755  inv_L_scale:  [1.0, 1.0]
Epoch :  496  Time:  1.099  Rel. Train L2 Loss :  0.015189013824694687  Rel. Test L2 Loss :  0.01628019765019417  Test L2 Loss :  0.028136916607618332  inv_L_scale:  [1.0, 1.0]
Epoch :  497  Time:  1.099  Rel. Train L2 Loss :  0.015191484950482845  Rel. Test L2 Loss :  0.016262411773204803  Test L2 Loss :  0.028107054978609085  inv_L_scale:  [1.0, 1.0]
Epoch :  498  Time:  1.099  Rel. Train L2 Loss :  0.015188644859525893  Rel. Test L2 Loss :  0.01627463348209858  Test L2 Loss :  0.028127959370613097  inv_L_scale:  [1.0, 1.0]
Epoch :  499  Time:  1.099  Rel. Train L2 Loss :  0.015188516105214754  Rel. Test L2 Loss :  0.016281276121735574  Test L2 Loss :  0.02813532404601574  inv_L_scale:  [1.0, 1.0]
