(1000,) (1000, 1000, 1) (1000, 1000, 2)
use normalized raw measures
Casting to tensor
x_train shape torch.Size([900, 1000, 8]), y_train shape torch.Size([900, 1000, 1])
length of each dim:  tensor([6.5573987960815430, 6.1420288085937500])
kmax = 16
L = 10
geo_dims = [1, 2, 3, 4]
In PCNO_train, ndims =  2
Epoch :  0  Time:  1.148  Rel. Train L2 Loss :  0.5843664312362671  Rel. Test L2 Loss :  0.4830828905105591  Test L2 Loss :  0.6988453197479249  inv_L_scale:  [1.0, 1.0]
Epoch :  1  Time:  0.874  Rel. Train L2 Loss :  0.4010547724035051  Rel. Test L2 Loss :  0.3347637927532196  Test L2 Loss :  0.48159936904907225  inv_L_scale:  [1.0, 1.0]
Epoch :  2  Time:  0.872  Rel. Train L2 Loss :  0.2851601485411326  Rel. Test L2 Loss :  0.257922842502594  Test L2 Loss :  0.3647353291511536  inv_L_scale:  [1.0, 1.0]
Epoch :  3  Time:  0.873  Rel. Train L2 Loss :  0.22008140391773648  Rel. Test L2 Loss :  0.2033225929737091  Test L2 Loss :  0.2895718169212341  inv_L_scale:  [1.0, 1.0]
Epoch :  4  Time:  0.873  Rel. Train L2 Loss :  0.18516989847024282  Rel. Test L2 Loss :  0.17794020235538482  Test L2 Loss :  0.2536530208587646  inv_L_scale:  [1.0, 1.0]
Epoch :  5  Time:  0.872  Rel. Train L2 Loss :  0.17336934447288513  Rel. Test L2 Loss :  0.16555511713027954  Test L2 Loss :  0.23554985284805297  inv_L_scale:  [1.0, 1.0]
Epoch :  6  Time:  0.872  Rel. Train L2 Loss :  0.15855823675791422  Rel. Test L2 Loss :  0.15111880421638488  Test L2 Loss :  0.21636092722415923  inv_L_scale:  [1.0, 1.0]
Epoch :  7  Time:  0.872  Rel. Train L2 Loss :  0.14572672022713556  Rel. Test L2 Loss :  0.13921804070472718  Test L2 Loss :  0.1976667422056198  inv_L_scale:  [1.0, 1.0]
Epoch :  8  Time:  0.875  Rel. Train L2 Loss :  0.13692321413093142  Rel. Test L2 Loss :  0.13587444603443147  Test L2 Loss :  0.19415229320526123  inv_L_scale:  [1.0, 1.0]
Epoch :  9  Time:  0.872  Rel. Train L2 Loss :  0.13214715361595153  Rel. Test L2 Loss :  0.13095023691654206  Test L2 Loss :  0.18657276391983033  inv_L_scale:  [1.0, 1.0]
Epoch :  10  Time:  0.872  Rel. Train L2 Loss :  0.12639578441778818  Rel. Test L2 Loss :  0.12674094557762147  Test L2 Loss :  0.17986615896224975  inv_L_scale:  [1.0, 1.0]
Epoch :  11  Time:  0.872  Rel. Train L2 Loss :  0.12156827290852865  Rel. Test L2 Loss :  0.12430692791938781  Test L2 Loss :  0.17786837875843048  inv_L_scale:  [1.0, 1.0]
Epoch :  12  Time:  0.872  Rel. Train L2 Loss :  0.11771508011553022  Rel. Test L2 Loss :  0.11961383104324341  Test L2 Loss :  0.1709788727760315  inv_L_scale:  [1.0, 1.0]
Epoch :  13  Time:  0.873  Rel. Train L2 Loss :  0.11512602749798033  Rel. Test L2 Loss :  0.11416598558425903  Test L2 Loss :  0.16273502945899965  inv_L_scale:  [1.0, 1.0]
Epoch :  14  Time:  0.873  Rel. Train L2 Loss :  0.1114522037572331  Rel. Test L2 Loss :  0.11090791016817093  Test L2 Loss :  0.15803488492965698  inv_L_scale:  [1.0, 1.0]
Epoch :  15  Time:  0.87  Rel. Train L2 Loss :  0.11012299219767252  Rel. Test L2 Loss :  0.10944366693496704  Test L2 Loss :  0.15745692372322082  inv_L_scale:  [1.0, 1.0]
Epoch :  16  Time:  0.872  Rel. Train L2 Loss :  0.10679076774252785  Rel. Test L2 Loss :  0.1080942577123642  Test L2 Loss :  0.15491395711898803  inv_L_scale:  [1.0, 1.0]
Epoch :  17  Time:  0.87  Rel. Train L2 Loss :  0.10484346356656817  Rel. Test L2 Loss :  0.10428360223770142  Test L2 Loss :  0.14990644574165343  inv_L_scale:  [1.0, 1.0]
Epoch :  18  Time:  0.872  Rel. Train L2 Loss :  0.10224952088461982  Rel. Test L2 Loss :  0.10069611877202987  Test L2 Loss :  0.14401386559009552  inv_L_scale:  [1.0, 1.0]
Epoch :  19  Time:  0.873  Rel. Train L2 Loss :  0.10016312821043863  Rel. Test L2 Loss :  0.1103354662656784  Test L2 Loss :  0.1581656563282013  inv_L_scale:  [1.0, 1.0]
Epoch :  20  Time:  0.873  Rel. Train L2 Loss :  0.10262977911366357  Rel. Test L2 Loss :  0.10226796507835388  Test L2 Loss :  0.1467225569486618  inv_L_scale:  [1.0, 1.0]
Epoch :  21  Time:  0.871  Rel. Train L2 Loss :  0.09869057049353917  Rel. Test L2 Loss :  0.09918857365846634  Test L2 Loss :  0.14259579181671142  inv_L_scale:  [1.0, 1.0]
Epoch :  22  Time:  0.87  Rel. Train L2 Loss :  0.09669044868813621  Rel. Test L2 Loss :  0.09961132317781449  Test L2 Loss :  0.14314910292625427  inv_L_scale:  [1.0, 1.0]
Epoch :  23  Time:  0.872  Rel. Train L2 Loss :  0.09520336952474383  Rel. Test L2 Loss :  0.09890845388174058  Test L2 Loss :  0.14172719836235045  inv_L_scale:  [1.0, 1.0]
Epoch :  24  Time:  0.871  Rel. Train L2 Loss :  0.09320405787891811  Rel. Test L2 Loss :  0.09179293572902679  Test L2 Loss :  0.1321163910627365  inv_L_scale:  [1.0, 1.0]
Epoch :  25  Time:  0.873  Rel. Train L2 Loss :  0.09291360858413908  Rel. Test L2 Loss :  0.09278912335634232  Test L2 Loss :  0.13298870831727982  inv_L_scale:  [1.0, 1.0]
Epoch :  26  Time:  0.872  Rel. Train L2 Loss :  0.0904684794611401  Rel. Test L2 Loss :  0.08969375818967819  Test L2 Loss :  0.12895138204097747  inv_L_scale:  [1.0, 1.0]
Epoch :  27  Time:  0.872  Rel. Train L2 Loss :  0.0887788999080658  Rel. Test L2 Loss :  0.09151070952415466  Test L2 Loss :  0.1319843789935112  inv_L_scale:  [1.0, 1.0]
Epoch :  28  Time:  0.871  Rel. Train L2 Loss :  0.08909448676639133  Rel. Test L2 Loss :  0.09190272957086563  Test L2 Loss :  0.1321692457795143  inv_L_scale:  [1.0, 1.0]
Epoch :  29  Time:  0.872  Rel. Train L2 Loss :  0.08643164104885526  Rel. Test L2 Loss :  0.09109804958105087  Test L2 Loss :  0.13028059542179107  inv_L_scale:  [1.0, 1.0]
Epoch :  30  Time:  0.871  Rel. Train L2 Loss :  0.08803312069839901  Rel. Test L2 Loss :  0.09056257069110871  Test L2 Loss :  0.12956891775131227  inv_L_scale:  [1.0, 1.0]
Epoch :  31  Time:  0.871  Rel. Train L2 Loss :  0.0862069109413359  Rel. Test L2 Loss :  0.09001050114631653  Test L2 Loss :  0.12866829335689545  inv_L_scale:  [1.0, 1.0]
Epoch :  32  Time:  0.871  Rel. Train L2 Loss :  0.0860466773642434  Rel. Test L2 Loss :  0.09425672799348832  Test L2 Loss :  0.13518586814403533  inv_L_scale:  [1.0, 1.0]
Epoch :  33  Time:  0.872  Rel. Train L2 Loss :  0.08710808280441495  Rel. Test L2 Loss :  0.08798850208520889  Test L2 Loss :  0.12531309217214584  inv_L_scale:  [1.0, 1.0]
Epoch :  34  Time:  0.872  Rel. Train L2 Loss :  0.08493232180674871  Rel. Test L2 Loss :  0.08546840250492097  Test L2 Loss :  0.12214119493961334  inv_L_scale:  [1.0, 1.0]
Epoch :  35  Time:  0.871  Rel. Train L2 Loss :  0.08287224782837761  Rel. Test L2 Loss :  0.08656826108694077  Test L2 Loss :  0.12374657928943635  inv_L_scale:  [1.0, 1.0]
Epoch :  36  Time:  0.873  Rel. Train L2 Loss :  0.08516657451788584  Rel. Test L2 Loss :  0.0853689205646515  Test L2 Loss :  0.12277461409568786  inv_L_scale:  [1.0, 1.0]
Epoch :  37  Time:  0.872  Rel. Train L2 Loss :  0.08150293976068497  Rel. Test L2 Loss :  0.08371569961309433  Test L2 Loss :  0.12016020476818084  inv_L_scale:  [1.0, 1.0]
Epoch :  38  Time:  0.871  Rel. Train L2 Loss :  0.07982189363903469  Rel. Test L2 Loss :  0.08311176300048828  Test L2 Loss :  0.11914229094982147  inv_L_scale:  [1.0, 1.0]
Epoch :  39  Time:  0.871  Rel. Train L2 Loss :  0.08030118137598037  Rel. Test L2 Loss :  0.08254418075084687  Test L2 Loss :  0.11874915152788162  inv_L_scale:  [1.0, 1.0]
Epoch :  40  Time:  0.871  Rel. Train L2 Loss :  0.07953490760591295  Rel. Test L2 Loss :  0.07937258839607239  Test L2 Loss :  0.11438505202531815  inv_L_scale:  [1.0, 1.0]
Epoch :  41  Time:  0.872  Rel. Train L2 Loss :  0.08000184850560295  Rel. Test L2 Loss :  0.0797406455874443  Test L2 Loss :  0.11477128744125366  inv_L_scale:  [1.0, 1.0]
Epoch :  42  Time:  0.871  Rel. Train L2 Loss :  0.07916267649994956  Rel. Test L2 Loss :  0.07984791159629821  Test L2 Loss :  0.11459478557109833  inv_L_scale:  [1.0, 1.0]
Epoch :  43  Time:  0.87  Rel. Train L2 Loss :  0.07897475063800811  Rel. Test L2 Loss :  0.08356438279151916  Test L2 Loss :  0.11954827725887299  inv_L_scale:  [1.0, 1.0]
Epoch :  44  Time:  0.873  Rel. Train L2 Loss :  0.07920902384652032  Rel. Test L2 Loss :  0.0811813884973526  Test L2 Loss :  0.11704450368881225  inv_L_scale:  [1.0, 1.0]
Epoch :  45  Time:  0.871  Rel. Train L2 Loss :  0.07835478017727535  Rel. Test L2 Loss :  0.08031520783901215  Test L2 Loss :  0.1153313785791397  inv_L_scale:  [1.0, 1.0]
Epoch :  46  Time:  0.871  Rel. Train L2 Loss :  0.07734810842408074  Rel. Test L2 Loss :  0.07740480720996856  Test L2 Loss :  0.11142679393291473  inv_L_scale:  [1.0, 1.0]
Epoch :  47  Time:  0.873  Rel. Train L2 Loss :  0.07778238465388616  Rel. Test L2 Loss :  0.07675532281398773  Test L2 Loss :  0.11057326436042786  inv_L_scale:  [1.0, 1.0]
Epoch :  48  Time:  0.871  Rel. Train L2 Loss :  0.07786316550440259  Rel. Test L2 Loss :  0.08063015580177307  Test L2 Loss :  0.11487161457538604  inv_L_scale:  [1.0, 1.0]
Epoch :  49  Time:  0.87  Rel. Train L2 Loss :  0.07628236108356053  Rel. Test L2 Loss :  0.0765928715467453  Test L2 Loss :  0.10982889354228974  inv_L_scale:  [1.0, 1.0]
Epoch :  50  Time:  0.871  Rel. Train L2 Loss :  0.07687328328688939  Rel. Test L2 Loss :  0.0783368068933487  Test L2 Loss :  0.11244838774204254  inv_L_scale:  [1.0, 1.0]
Epoch :  51  Time:  0.87  Rel. Train L2 Loss :  0.076337847577201  Rel. Test L2 Loss :  0.07856628268957139  Test L2 Loss :  0.11321457535028458  inv_L_scale:  [1.0, 1.0]
Epoch :  52  Time:  0.87  Rel. Train L2 Loss :  0.07532921651999155  Rel. Test L2 Loss :  0.07289686620235443  Test L2 Loss :  0.10507903069257736  inv_L_scale:  [1.0, 1.0]
Epoch :  53  Time:  0.871  Rel. Train L2 Loss :  0.07462824791669846  Rel. Test L2 Loss :  0.07765488266944885  Test L2 Loss :  0.11160141229629517  inv_L_scale:  [1.0, 1.0]
Epoch :  54  Time:  0.87  Rel. Train L2 Loss :  0.07501024315754573  Rel. Test L2 Loss :  0.07505959987640382  Test L2 Loss :  0.10838068753480912  inv_L_scale:  [1.0, 1.0]
Epoch :  55  Time:  0.872  Rel. Train L2 Loss :  0.07431283649471071  Rel. Test L2 Loss :  0.07610765010118485  Test L2 Loss :  0.10883074820041656  inv_L_scale:  [1.0, 1.0]
Epoch :  56  Time:  0.872  Rel. Train L2 Loss :  0.0743587041232321  Rel. Test L2 Loss :  0.07554094076156616  Test L2 Loss :  0.10841801404953003  inv_L_scale:  [1.0, 1.0]
Epoch :  57  Time:  0.871  Rel. Train L2 Loss :  0.07283148970868852  Rel. Test L2 Loss :  0.07250953555107116  Test L2 Loss :  0.10448136270046234  inv_L_scale:  [1.0, 1.0]
Epoch :  58  Time:  0.871  Rel. Train L2 Loss :  0.07356999102565977  Rel. Test L2 Loss :  0.08020934939384461  Test L2 Loss :  0.11491630017757416  inv_L_scale:  [1.0, 1.0]
Epoch :  59  Time:  0.874  Rel. Train L2 Loss :  0.07439335349533294  Rel. Test L2 Loss :  0.07231169700622558  Test L2 Loss :  0.10390079259872437  inv_L_scale:  [1.0, 1.0]
Epoch :  60  Time:  0.872  Rel. Train L2 Loss :  0.07188314722643958  Rel. Test L2 Loss :  0.07488007158041  Test L2 Loss :  0.1080008402466774  inv_L_scale:  [1.0, 1.0]
Epoch :  61  Time:  0.871  Rel. Train L2 Loss :  0.07241338911983702  Rel. Test L2 Loss :  0.07082664877176285  Test L2 Loss :  0.1018405544757843  inv_L_scale:  [1.0, 1.0]
Epoch :  62  Time:  0.871  Rel. Train L2 Loss :  0.07205697072876824  Rel. Test L2 Loss :  0.07039092510938644  Test L2 Loss :  0.10111027121543885  inv_L_scale:  [1.0, 1.0]
Epoch :  63  Time:  0.871  Rel. Train L2 Loss :  0.0707928854227066  Rel. Test L2 Loss :  0.07286082088947296  Test L2 Loss :  0.10499797463417053  inv_L_scale:  [1.0, 1.0]
Epoch :  64  Time:  0.871  Rel. Train L2 Loss :  0.07126995725764168  Rel. Test L2 Loss :  0.07263720244169235  Test L2 Loss :  0.1043784722685814  inv_L_scale:  [1.0, 1.0]
Epoch :  65  Time:  0.872  Rel. Train L2 Loss :  0.07036495678954655  Rel. Test L2 Loss :  0.0696797451376915  Test L2 Loss :  0.10020470798015595  inv_L_scale:  [1.0, 1.0]
Epoch :  66  Time:  0.871  Rel. Train L2 Loss :  0.07123816081219249  Rel. Test L2 Loss :  0.07639545768499374  Test L2 Loss :  0.10912576794624329  inv_L_scale:  [1.0, 1.0]
Epoch :  67  Time:  0.871  Rel. Train L2 Loss :  0.07008108599318398  Rel. Test L2 Loss :  0.07020512133836747  Test L2 Loss :  0.1007122403383255  inv_L_scale:  [1.0, 1.0]
Epoch :  68  Time:  0.871  Rel. Train L2 Loss :  0.07029744356870651  Rel. Test L2 Loss :  0.07116778761148453  Test L2 Loss :  0.10237124681472778  inv_L_scale:  [1.0, 1.0]
Epoch :  69  Time:  0.871  Rel. Train L2 Loss :  0.06917281515068478  Rel. Test L2 Loss :  0.0742689660191536  Test L2 Loss :  0.10787422865629197  inv_L_scale:  [1.0, 1.0]
Epoch :  70  Time:  0.871  Rel. Train L2 Loss :  0.06998089217477374  Rel. Test L2 Loss :  0.0725775596499443  Test L2 Loss :  0.10459313094615937  inv_L_scale:  [1.0, 1.0]
Epoch :  71  Time:  0.871  Rel. Train L2 Loss :  0.07095163431432512  Rel. Test L2 Loss :  0.0738782051205635  Test L2 Loss :  0.10615271925926209  inv_L_scale:  [1.0, 1.0]
Epoch :  72  Time:  0.871  Rel. Train L2 Loss :  0.06949523902601666  Rel. Test L2 Loss :  0.06888981372117996  Test L2 Loss :  0.09913334518671035  inv_L_scale:  [1.0, 1.0]
Epoch :  73  Time:  0.873  Rel. Train L2 Loss :  0.06821294993162155  Rel. Test L2 Loss :  0.0725317895412445  Test L2 Loss :  0.10379636317491531  inv_L_scale:  [1.0, 1.0]
Epoch :  74  Time:  0.871  Rel. Train L2 Loss :  0.06880220237705442  Rel. Test L2 Loss :  0.07003900438547134  Test L2 Loss :  0.10103231072425842  inv_L_scale:  [1.0, 1.0]
Epoch :  75  Time:  0.871  Rel. Train L2 Loss :  0.06796279129054811  Rel. Test L2 Loss :  0.06902941972017289  Test L2 Loss :  0.09931926369667053  inv_L_scale:  [1.0, 1.0]
Epoch :  76  Time:  0.871  Rel. Train L2 Loss :  0.06849948258863556  Rel. Test L2 Loss :  0.06566314309835435  Test L2 Loss :  0.094339519739151  inv_L_scale:  [1.0, 1.0]
Epoch :  77  Time:  0.874  Rel. Train L2 Loss :  0.06787018660042021  Rel. Test L2 Loss :  0.06560611099004746  Test L2 Loss :  0.09425745964050293  inv_L_scale:  [1.0, 1.0]
Epoch :  78  Time:  0.871  Rel. Train L2 Loss :  0.06821926722923914  Rel. Test L2 Loss :  0.06613675504922867  Test L2 Loss :  0.0952508169412613  inv_L_scale:  [1.0, 1.0]
Epoch :  79  Time:  0.871  Rel. Train L2 Loss :  0.06718023826678594  Rel. Test L2 Loss :  0.06966535836458206  Test L2 Loss :  0.1005514207482338  inv_L_scale:  [1.0, 1.0]
Epoch :  80  Time:  0.871  Rel. Train L2 Loss :  0.06786149183909099  Rel. Test L2 Loss :  0.06710393100976944  Test L2 Loss :  0.09621703803539276  inv_L_scale:  [1.0, 1.0]
Epoch :  81  Time:  0.871  Rel. Train L2 Loss :  0.06580398261547088  Rel. Test L2 Loss :  0.06567256361246109  Test L2 Loss :  0.0945070168375969  inv_L_scale:  [1.0, 1.0]
Epoch :  82  Time:  0.871  Rel. Train L2 Loss :  0.06580359352959526  Rel. Test L2 Loss :  0.06885176539421081  Test L2 Loss :  0.09890053927898407  inv_L_scale:  [1.0, 1.0]
Epoch :  83  Time:  0.871  Rel. Train L2 Loss :  0.06675114221043058  Rel. Test L2 Loss :  0.07049131274223328  Test L2 Loss :  0.10235539764165878  inv_L_scale:  [1.0, 1.0]
Epoch :  84  Time:  0.871  Rel. Train L2 Loss :  0.06745925918221474  Rel. Test L2 Loss :  0.06827892899513245  Test L2 Loss :  0.09811858505010605  inv_L_scale:  [1.0, 1.0]
Epoch :  85  Time:  0.871  Rel. Train L2 Loss :  0.06756052792072297  Rel. Test L2 Loss :  0.06777786523103714  Test L2 Loss :  0.09710625827312469  inv_L_scale:  [1.0, 1.0]
Epoch :  86  Time:  0.871  Rel. Train L2 Loss :  0.06546563451488813  Rel. Test L2 Loss :  0.07112667590379715  Test L2 Loss :  0.10300851285457611  inv_L_scale:  [1.0, 1.0]
Epoch :  87  Time:  0.871  Rel. Train L2 Loss :  0.06505224522617128  Rel. Test L2 Loss :  0.06668987035751343  Test L2 Loss :  0.09553157985210418  inv_L_scale:  [1.0, 1.0]
Epoch :  88  Time:  0.871  Rel. Train L2 Loss :  0.0667999224199189  Rel. Test L2 Loss :  0.06750733643770218  Test L2 Loss :  0.09802977442741394  inv_L_scale:  [1.0, 1.0]
Epoch :  89  Time:  0.872  Rel. Train L2 Loss :  0.06596586717499626  Rel. Test L2 Loss :  0.06676148265600204  Test L2 Loss :  0.09583791613578796  inv_L_scale:  [1.0, 1.0]
Epoch :  90  Time:  0.872  Rel. Train L2 Loss :  0.06629310637712478  Rel. Test L2 Loss :  0.06754465699195862  Test L2 Loss :  0.09792917788028717  inv_L_scale:  [1.0, 1.0]
Epoch :  91  Time:  0.871  Rel. Train L2 Loss :  0.0657642920811971  Rel. Test L2 Loss :  0.06575152009725571  Test L2 Loss :  0.09495014548301697  inv_L_scale:  [1.0, 1.0]
Epoch :  92  Time:  0.871  Rel. Train L2 Loss :  0.06554778426885605  Rel. Test L2 Loss :  0.06427805334329605  Test L2 Loss :  0.09245385706424714  inv_L_scale:  [1.0, 1.0]
Epoch :  93  Time:  0.871  Rel. Train L2 Loss :  0.06475492950942781  Rel. Test L2 Loss :  0.06670705497264862  Test L2 Loss :  0.09621690809726716  inv_L_scale:  [1.0, 1.0]
Epoch :  94  Time:  0.873  Rel. Train L2 Loss :  0.06453574294845263  Rel. Test L2 Loss :  0.06632338404655456  Test L2 Loss :  0.09580981492996216  inv_L_scale:  [1.0, 1.0]
Epoch :  95  Time:  0.872  Rel. Train L2 Loss :  0.06402475078900655  Rel. Test L2 Loss :  0.06457099676132202  Test L2 Loss :  0.0928586894273758  inv_L_scale:  [1.0, 1.0]
Epoch :  96  Time:  0.871  Rel. Train L2 Loss :  0.06408540429340469  Rel. Test L2 Loss :  0.06511007398366928  Test L2 Loss :  0.09417477786540986  inv_L_scale:  [1.0, 1.0]
Epoch :  97  Time:  0.871  Rel. Train L2 Loss :  0.06388041956557168  Rel. Test L2 Loss :  0.06673809587955475  Test L2 Loss :  0.09616818755865097  inv_L_scale:  [1.0, 1.0]
Epoch :  98  Time:  0.871  Rel. Train L2 Loss :  0.0639607952038447  Rel. Test L2 Loss :  0.06442086845636368  Test L2 Loss :  0.09253710001707077  inv_L_scale:  [1.0, 1.0]
Epoch :  99  Time:  0.871  Rel. Train L2 Loss :  0.06482329335477617  Rel. Test L2 Loss :  0.06274613261222839  Test L2 Loss :  0.09078772902488709  inv_L_scale:  [1.0, 1.0]
Epoch :  100  Time:  0.871  Rel. Train L2 Loss :  0.0633255126244492  Rel. Test L2 Loss :  0.06317257255315781  Test L2 Loss :  0.09119212448596954  inv_L_scale:  [1.0, 1.0]
Epoch :  101  Time:  0.872  Rel. Train L2 Loss :  0.0630830509463946  Rel. Test L2 Loss :  0.06194071963429451  Test L2 Loss :  0.08980507254600525  inv_L_scale:  [1.0, 1.0]
Epoch :  102  Time:  0.88  Rel. Train L2 Loss :  0.06283473322788874  Rel. Test L2 Loss :  0.06639231234788895  Test L2 Loss :  0.09545872390270232  inv_L_scale:  [1.0, 1.0]
Epoch :  103  Time:  0.873  Rel. Train L2 Loss :  0.06399862873885366  Rel. Test L2 Loss :  0.06693511843681335  Test L2 Loss :  0.09683722376823425  inv_L_scale:  [1.0, 1.0]
Epoch :  104  Time:  0.872  Rel. Train L2 Loss :  0.06387748228179084  Rel. Test L2 Loss :  0.06377215147018432  Test L2 Loss :  0.09172154247760772  inv_L_scale:  [1.0, 1.0]
Epoch :  105  Time:  0.871  Rel. Train L2 Loss :  0.06370263127817048  Rel. Test L2 Loss :  0.0638012507557869  Test L2 Loss :  0.09256006598472595  inv_L_scale:  [1.0, 1.0]
Epoch :  106  Time:  0.871  Rel. Train L2 Loss :  0.06319165223174625  Rel. Test L2 Loss :  0.06848353773355484  Test L2 Loss :  0.09843084782361984  inv_L_scale:  [1.0, 1.0]
Epoch :  107  Time:  0.871  Rel. Train L2 Loss :  0.061886126581165525  Rel. Test L2 Loss :  0.06503711819648743  Test L2 Loss :  0.09367289245128632  inv_L_scale:  [1.0, 1.0]
Epoch :  108  Time:  0.871  Rel. Train L2 Loss :  0.061333388321929506  Rel. Test L2 Loss :  0.05969988882541657  Test L2 Loss :  0.08617624878883362  inv_L_scale:  [1.0, 1.0]
Epoch :  109  Time:  0.873  Rel. Train L2 Loss :  0.06096610466639201  Rel. Test L2 Loss :  0.06421132922172547  Test L2 Loss :  0.09283708214759827  inv_L_scale:  [1.0, 1.0]
Epoch :  110  Time:  0.871  Rel. Train L2 Loss :  0.06264115115006764  Rel. Test L2 Loss :  0.06287006735801696  Test L2 Loss :  0.08998464584350586  inv_L_scale:  [1.0, 1.0]
Epoch :  111  Time:  0.871  Rel. Train L2 Loss :  0.06163269675440258  Rel. Test L2 Loss :  0.0648781156539917  Test L2 Loss :  0.09411668181419372  inv_L_scale:  [1.0, 1.0]
Epoch :  112  Time:  0.871  Rel. Train L2 Loss :  0.061989969578054215  Rel. Test L2 Loss :  0.061419153809547426  Test L2 Loss :  0.08896416425704956  inv_L_scale:  [1.0, 1.0]
Epoch :  113  Time:  0.871  Rel. Train L2 Loss :  0.061068991985585956  Rel. Test L2 Loss :  0.06052001982927322  Test L2 Loss :  0.08725951045751572  inv_L_scale:  [1.0, 1.0]
Epoch :  114  Time:  0.871  Rel. Train L2 Loss :  0.06092905001507865  Rel. Test L2 Loss :  0.06353822827339173  Test L2 Loss :  0.09142108738422394  inv_L_scale:  [1.0, 1.0]
Epoch :  115  Time:  0.874  Rel. Train L2 Loss :  0.06215824067592621  Rel. Test L2 Loss :  0.06198881715536118  Test L2 Loss :  0.08914559870958329  inv_L_scale:  [1.0, 1.0]
Epoch :  116  Time:  0.872  Rel. Train L2 Loss :  0.06079526003864076  Rel. Test L2 Loss :  0.0627465483546257  Test L2 Loss :  0.09036139041185379  inv_L_scale:  [1.0, 1.0]
Epoch :  117  Time:  0.871  Rel. Train L2 Loss :  0.061404117859072155  Rel. Test L2 Loss :  0.05982251048088074  Test L2 Loss :  0.0863902622461319  inv_L_scale:  [1.0, 1.0]
Epoch :  118  Time:  0.871  Rel. Train L2 Loss :  0.06120792657136917  Rel. Test L2 Loss :  0.06600077599287033  Test L2 Loss :  0.09625797778367996  inv_L_scale:  [1.0, 1.0]
Epoch :  119  Time:  0.87  Rel. Train L2 Loss :  0.061266498035854766  Rel. Test L2 Loss :  0.059188595712184905  Test L2 Loss :  0.08516549378633499  inv_L_scale:  [1.0, 1.0]
Epoch :  120  Time:  0.871  Rel. Train L2 Loss :  0.06007726748784383  Rel. Test L2 Loss :  0.06470130458474159  Test L2 Loss :  0.09286303281784057  inv_L_scale:  [1.0, 1.0]
Epoch :  121  Time:  0.871  Rel. Train L2 Loss :  0.06087279548247655  Rel. Test L2 Loss :  0.0628962591290474  Test L2 Loss :  0.0909320679306984  inv_L_scale:  [1.0, 1.0]
Epoch :  122  Time:  0.871  Rel. Train L2 Loss :  0.060325096249580386  Rel. Test L2 Loss :  0.06103849619626999  Test L2 Loss :  0.08827589899301529  inv_L_scale:  [1.0, 1.0]
Epoch :  123  Time:  0.871  Rel. Train L2 Loss :  0.060240285959508685  Rel. Test L2 Loss :  0.06501098811626434  Test L2 Loss :  0.0934346643090248  inv_L_scale:  [1.0, 1.0]
Epoch :  124  Time:  0.87  Rel. Train L2 Loss :  0.06045160793595844  Rel. Test L2 Loss :  0.06259761452674865  Test L2 Loss :  0.08975636780261993  inv_L_scale:  [1.0, 1.0]
Epoch :  125  Time:  0.871  Rel. Train L2 Loss :  0.06042515678538216  Rel. Test L2 Loss :  0.061347483694553374  Test L2 Loss :  0.08866380900144577  inv_L_scale:  [1.0, 1.0]
Epoch :  126  Time:  0.871  Rel. Train L2 Loss :  0.06008803324566947  Rel. Test L2 Loss :  0.05978995755314827  Test L2 Loss :  0.08666747510433197  inv_L_scale:  [1.0, 1.0]
Epoch :  127  Time:  0.872  Rel. Train L2 Loss :  0.060661107036802504  Rel. Test L2 Loss :  0.062017787098884586  Test L2 Loss :  0.08996562987565994  inv_L_scale:  [1.0, 1.0]
Epoch :  128  Time:  0.871  Rel. Train L2 Loss :  0.05897132532464133  Rel. Test L2 Loss :  0.05785980373620987  Test L2 Loss :  0.08367725491523742  inv_L_scale:  [1.0, 1.0]
Epoch :  129  Time:  0.871  Rel. Train L2 Loss :  0.05929155439138412  Rel. Test L2 Loss :  0.06218867272138596  Test L2 Loss :  0.08991170674562454  inv_L_scale:  [1.0, 1.0]
Epoch :  130  Time:  0.871  Rel. Train L2 Loss :  0.059592511355876926  Rel. Test L2 Loss :  0.060168332159519194  Test L2 Loss :  0.08705671668052674  inv_L_scale:  [1.0, 1.0]
Epoch :  131  Time:  0.87  Rel. Train L2 Loss :  0.059537383649084306  Rel. Test L2 Loss :  0.05987418234348297  Test L2 Loss :  0.08620049148797988  inv_L_scale:  [1.0, 1.0]
Epoch :  132  Time:  0.87  Rel. Train L2 Loss :  0.059896658758322396  Rel. Test L2 Loss :  0.05985265910625458  Test L2 Loss :  0.08644829213619232  inv_L_scale:  [1.0, 1.0]
Epoch :  133  Time:  0.872  Rel. Train L2 Loss :  0.060225037733713786  Rel. Test L2 Loss :  0.058266475200653076  Test L2 Loss :  0.08377990484237671  inv_L_scale:  [1.0, 1.0]
Epoch :  134  Time:  0.871  Rel. Train L2 Loss :  0.058143802616331314  Rel. Test L2 Loss :  0.059216309040784836  Test L2 Loss :  0.08554551869630814  inv_L_scale:  [1.0, 1.0]
Epoch :  135  Time:  0.871  Rel. Train L2 Loss :  0.05849480676982138  Rel. Test L2 Loss :  0.05958905503153801  Test L2 Loss :  0.08603752702474594  inv_L_scale:  [1.0, 1.0]
Epoch :  136  Time:  0.87  Rel. Train L2 Loss :  0.059474383195241294  Rel. Test L2 Loss :  0.05803000286221504  Test L2 Loss :  0.08351199388504028  inv_L_scale:  [1.0, 1.0]
Epoch :  137  Time:  0.87  Rel. Train L2 Loss :  0.058544697595967185  Rel. Test L2 Loss :  0.05961483955383301  Test L2 Loss :  0.08617392659187317  inv_L_scale:  [1.0, 1.0]
Epoch :  138  Time:  0.87  Rel. Train L2 Loss :  0.058144510719511246  Rel. Test L2 Loss :  0.060458275079727175  Test L2 Loss :  0.08723548024892808  inv_L_scale:  [1.0, 1.0]
Epoch :  139  Time:  0.871  Rel. Train L2 Loss :  0.058397022154596114  Rel. Test L2 Loss :  0.060393081307411195  Test L2 Loss :  0.08688368082046509  inv_L_scale:  [1.0, 1.0]
Epoch :  140  Time:  0.873  Rel. Train L2 Loss :  0.05799036059114668  Rel. Test L2 Loss :  0.06058139979839325  Test L2 Loss :  0.08754957675933837  inv_L_scale:  [1.0, 1.0]
Epoch :  141  Time:  0.872  Rel. Train L2 Loss :  0.05860672791798909  Rel. Test L2 Loss :  0.0584726294875145  Test L2 Loss :  0.08450398147106171  inv_L_scale:  [1.0, 1.0]
Epoch :  142  Time:  0.87  Rel. Train L2 Loss :  0.05918095777432124  Rel. Test L2 Loss :  0.05998694986104965  Test L2 Loss :  0.08672219634056091  inv_L_scale:  [1.0, 1.0]
Epoch :  143  Time:  0.87  Rel. Train L2 Loss :  0.059013941056198546  Rel. Test L2 Loss :  0.060147262364625934  Test L2 Loss :  0.08696989953517914  inv_L_scale:  [1.0, 1.0]
Epoch :  144  Time:  0.87  Rel. Train L2 Loss :  0.058364311622248755  Rel. Test L2 Loss :  0.05874932050704956  Test L2 Loss :  0.08477921605110168  inv_L_scale:  [1.0, 1.0]
Epoch :  145  Time:  0.87  Rel. Train L2 Loss :  0.05805327733357747  Rel. Test L2 Loss :  0.05907337233424187  Test L2 Loss :  0.08518172204494476  inv_L_scale:  [1.0, 1.0]
Epoch :  146  Time:  0.871  Rel. Train L2 Loss :  0.05792863706747691  Rel. Test L2 Loss :  0.0620433509349823  Test L2 Loss :  0.09020059704780578  inv_L_scale:  [1.0, 1.0]
Epoch :  147  Time:  0.871  Rel. Train L2 Loss :  0.05819450027412838  Rel. Test L2 Loss :  0.06122675746679306  Test L2 Loss :  0.0885996875166893  inv_L_scale:  [1.0, 1.0]
Epoch :  148  Time:  0.871  Rel. Train L2 Loss :  0.05873352924982707  Rel. Test L2 Loss :  0.062096837460994724  Test L2 Loss :  0.08947771251201629  inv_L_scale:  [1.0, 1.0]
Epoch :  149  Time:  0.871  Rel. Train L2 Loss :  0.0573227075404591  Rel. Test L2 Loss :  0.058030972182750704  Test L2 Loss :  0.08417238056659698  inv_L_scale:  [1.0, 1.0]
Epoch :  150  Time:  0.871  Rel. Train L2 Loss :  0.05773092673884498  Rel. Test L2 Loss :  0.05722064286470413  Test L2 Loss :  0.08293495774269104  inv_L_scale:  [1.0, 1.0]
Epoch :  151  Time:  0.87  Rel. Train L2 Loss :  0.05736807571517097  Rel. Test L2 Loss :  0.05845377549529076  Test L2 Loss :  0.08467768371105194  inv_L_scale:  [1.0, 1.0]
Epoch :  152  Time:  0.87  Rel. Train L2 Loss :  0.05786493533187442  Rel. Test L2 Loss :  0.05755197808146477  Test L2 Loss :  0.0832885080575943  inv_L_scale:  [1.0, 1.0]
Epoch :  153  Time:  0.87  Rel. Train L2 Loss :  0.057399345139662425  Rel. Test L2 Loss :  0.06362415730953216  Test L2 Loss :  0.09165682792663574  inv_L_scale:  [1.0, 1.0]
Epoch :  154  Time:  0.871  Rel. Train L2 Loss :  0.05722941494650311  Rel. Test L2 Loss :  0.05964223891496658  Test L2 Loss :  0.08592173427343369  inv_L_scale:  [1.0, 1.0]
Epoch :  155  Time:  0.871  Rel. Train L2 Loss :  0.05690844221247567  Rel. Test L2 Loss :  0.05770497828722  Test L2 Loss :  0.08326647371053696  inv_L_scale:  [1.0, 1.0]
Epoch :  156  Time:  0.871  Rel. Train L2 Loss :  0.05688563562101788  Rel. Test L2 Loss :  0.05793646037578583  Test L2 Loss :  0.08401410520076752  inv_L_scale:  [1.0, 1.0]
Epoch :  157  Time:  0.87  Rel. Train L2 Loss :  0.05769671873913871  Rel. Test L2 Loss :  0.055261131674051285  Test L2 Loss :  0.08052794814109802  inv_L_scale:  [1.0, 1.0]
Epoch :  158  Time:  0.87  Rel. Train L2 Loss :  0.05698118006189664  Rel. Test L2 Loss :  0.05899197429418564  Test L2 Loss :  0.08552489757537841  inv_L_scale:  [1.0, 1.0]
Epoch :  159  Time:  0.871  Rel. Train L2 Loss :  0.058909907705254026  Rel. Test L2 Loss :  0.05899533241987229  Test L2 Loss :  0.08542821764945983  inv_L_scale:  [1.0, 1.0]
Epoch :  160  Time:  0.871  Rel. Train L2 Loss :  0.056355704896979865  Rel. Test L2 Loss :  0.05951192647218704  Test L2 Loss :  0.08621319711208343  inv_L_scale:  [1.0, 1.0]
Epoch :  161  Time:  0.871  Rel. Train L2 Loss :  0.056801757050885096  Rel. Test L2 Loss :  0.06387633949518204  Test L2 Loss :  0.09178531318902969  inv_L_scale:  [1.0, 1.0]
Epoch :  162  Time:  0.871  Rel. Train L2 Loss :  0.05953470988406075  Rel. Test L2 Loss :  0.05877603441476822  Test L2 Loss :  0.08487482845783234  inv_L_scale:  [1.0, 1.0]
Epoch :  163  Time:  0.871  Rel. Train L2 Loss :  0.056772209770149656  Rel. Test L2 Loss :  0.05605137184262276  Test L2 Loss :  0.08116742670536041  inv_L_scale:  [1.0, 1.0]
Epoch :  164  Time:  0.871  Rel. Train L2 Loss :  0.056536248723665875  Rel. Test L2 Loss :  0.05893771469593048  Test L2 Loss :  0.0852170205116272  inv_L_scale:  [1.0, 1.0]
Epoch :  165  Time:  0.871  Rel. Train L2 Loss :  0.0568227233323786  Rel. Test L2 Loss :  0.05696677207946777  Test L2 Loss :  0.08260677814483643  inv_L_scale:  [1.0, 1.0]
Epoch :  166  Time:  0.87  Rel. Train L2 Loss :  0.057936928669611615  Rel. Test L2 Loss :  0.05707027405500412  Test L2 Loss :  0.08249663919210434  inv_L_scale:  [1.0, 1.0]
Epoch :  167  Time:  0.871  Rel. Train L2 Loss :  0.05656137436628342  Rel. Test L2 Loss :  0.057607759684324265  Test L2 Loss :  0.08329718112945557  inv_L_scale:  [1.0, 1.0]
Epoch :  168  Time:  0.87  Rel. Train L2 Loss :  0.057320834481053885  Rel. Test L2 Loss :  0.059029701054096224  Test L2 Loss :  0.08572043895721436  inv_L_scale:  [1.0, 1.0]
Epoch :  169  Time:  0.87  Rel. Train L2 Loss :  0.056379404266675315  Rel. Test L2 Loss :  0.05535367831587792  Test L2 Loss :  0.0801278030872345  inv_L_scale:  [1.0, 1.0]
Epoch :  170  Time:  0.873  Rel. Train L2 Loss :  0.056450976861847774  Rel. Test L2 Loss :  0.06090076833963394  Test L2 Loss :  0.0887810754776001  inv_L_scale:  [1.0, 1.0]
Epoch :  171  Time:  0.872  Rel. Train L2 Loss :  0.05711846821837955  Rel. Test L2 Loss :  0.058469366431236264  Test L2 Loss :  0.08456549912691116  inv_L_scale:  [1.0, 1.0]
Epoch :  172  Time:  0.871  Rel. Train L2 Loss :  0.05577417259414991  Rel. Test L2 Loss :  0.05656454816460609  Test L2 Loss :  0.08206977784633636  inv_L_scale:  [1.0, 1.0]
Epoch :  173  Time:  0.87  Rel. Train L2 Loss :  0.05565754002994961  Rel. Test L2 Loss :  0.056350070238113406  Test L2 Loss :  0.08137142270803452  inv_L_scale:  [1.0, 1.0]
Epoch :  174  Time:  0.871  Rel. Train L2 Loss :  0.05621749053398768  Rel. Test L2 Loss :  0.05609124347567558  Test L2 Loss :  0.08136090219020843  inv_L_scale:  [1.0, 1.0]
Epoch :  175  Time:  0.87  Rel. Train L2 Loss :  0.0561123972468906  Rel. Test L2 Loss :  0.05602209120988846  Test L2 Loss :  0.08107295215129852  inv_L_scale:  [1.0, 1.0]
Epoch :  176  Time:  0.871  Rel. Train L2 Loss :  0.055718268818325464  Rel. Test L2 Loss :  0.05570977360010147  Test L2 Loss :  0.08042729556560517  inv_L_scale:  [1.0, 1.0]
Epoch :  177  Time:  0.871  Rel. Train L2 Loss :  0.05754117468992869  Rel. Test L2 Loss :  0.059184768199920655  Test L2 Loss :  0.08576077818870545  inv_L_scale:  [1.0, 1.0]
Epoch :  178  Time:  0.871  Rel. Train L2 Loss :  0.05761222172114584  Rel. Test L2 Loss :  0.05831368267536163  Test L2 Loss :  0.08431679010391235  inv_L_scale:  [1.0, 1.0]
Epoch :  179  Time:  0.871  Rel. Train L2 Loss :  0.05575228386455112  Rel. Test L2 Loss :  0.05840459287166595  Test L2 Loss :  0.08458655834197998  inv_L_scale:  [1.0, 1.0]
Epoch :  180  Time:  0.871  Rel. Train L2 Loss :  0.05538639770613776  Rel. Test L2 Loss :  0.0578936967253685  Test L2 Loss :  0.08351465821266174  inv_L_scale:  [1.0, 1.0]
Epoch :  181  Time:  0.871  Rel. Train L2 Loss :  0.05609448158078723  Rel. Test L2 Loss :  0.058581689298152925  Test L2 Loss :  0.08438030064105988  inv_L_scale:  [1.0, 1.0]
Epoch :  182  Time:  0.87  Rel. Train L2 Loss :  0.0559995894961887  Rel. Test L2 Loss :  0.05675061836838722  Test L2 Loss :  0.08189670085906982  inv_L_scale:  [1.0, 1.0]
Epoch :  183  Time:  0.871  Rel. Train L2 Loss :  0.05985407713386748  Rel. Test L2 Loss :  0.05827563643455505  Test L2 Loss :  0.08410750389099121  inv_L_scale:  [1.0, 1.0]
Epoch :  184  Time:  0.871  Rel. Train L2 Loss :  0.05683343794610765  Rel. Test L2 Loss :  0.05690492495894432  Test L2 Loss :  0.08217842042446137  inv_L_scale:  [1.0, 1.0]
Epoch :  185  Time:  0.87  Rel. Train L2 Loss :  0.05531897382603751  Rel. Test L2 Loss :  0.056381474733352664  Test L2 Loss :  0.08140827357769012  inv_L_scale:  [1.0, 1.0]
Epoch :  186  Time:  0.87  Rel. Train L2 Loss :  0.056496401031812034  Rel. Test L2 Loss :  0.05718413218855858  Test L2 Loss :  0.08290997803211213  inv_L_scale:  [1.0, 1.0]
Epoch :  187  Time:  0.87  Rel. Train L2 Loss :  0.055756996704472435  Rel. Test L2 Loss :  0.05448715075850487  Test L2 Loss :  0.07896256804466248  inv_L_scale:  [1.0, 1.0]
Epoch :  188  Time:  0.87  Rel. Train L2 Loss :  0.055071393549442293  Rel. Test L2 Loss :  0.05481761068105698  Test L2 Loss :  0.07932808637619018  inv_L_scale:  [1.0, 1.0]
Epoch :  189  Time:  0.87  Rel. Train L2 Loss :  0.05494031930963198  Rel. Test L2 Loss :  0.05464252144098282  Test L2 Loss :  0.07906105518341064  inv_L_scale:  [1.0, 1.0]
Epoch :  190  Time:  0.869  Rel. Train L2 Loss :  0.05472647471560372  Rel. Test L2 Loss :  0.05622340977191925  Test L2 Loss :  0.08138264894485474  inv_L_scale:  [1.0, 1.0]
Epoch :  191  Time:  0.87  Rel. Train L2 Loss :  0.054921910994582705  Rel. Test L2 Loss :  0.056363866329193116  Test L2 Loss :  0.08139567315578461  inv_L_scale:  [1.0, 1.0]
Epoch :  192  Time:  0.869  Rel. Train L2 Loss :  0.0544120525320371  Rel. Test L2 Loss :  0.05487232819199562  Test L2 Loss :  0.07964970529079438  inv_L_scale:  [1.0, 1.0]
Epoch :  193  Time:  0.87  Rel. Train L2 Loss :  0.055320448146926035  Rel. Test L2 Loss :  0.05687173575162888  Test L2 Loss :  0.0823748430609703  inv_L_scale:  [1.0, 1.0]
Epoch :  194  Time:  0.87  Rel. Train L2 Loss :  0.054361045277780955  Rel. Test L2 Loss :  0.055083479285240176  Test L2 Loss :  0.07948759198188782  inv_L_scale:  [1.0, 1.0]
Epoch :  195  Time:  0.87  Rel. Train L2 Loss :  0.054146798037820396  Rel. Test L2 Loss :  0.054303756952285766  Test L2 Loss :  0.0785519677400589  inv_L_scale:  [1.0, 1.0]
Epoch :  196  Time:  0.872  Rel. Train L2 Loss :  0.054306257797612084  Rel. Test L2 Loss :  0.0563609567284584  Test L2 Loss :  0.08122389435768128  inv_L_scale:  [1.0, 1.0]
Epoch :  197  Time:  0.871  Rel. Train L2 Loss :  0.055037153528796304  Rel. Test L2 Loss :  0.05678152337670326  Test L2 Loss :  0.08227325797080993  inv_L_scale:  [1.0, 1.0]
Epoch :  198  Time:  0.871  Rel. Train L2 Loss :  0.055749722586737736  Rel. Test L2 Loss :  0.05599491968750954  Test L2 Loss :  0.08108628451824189  inv_L_scale:  [1.0, 1.0]
Epoch :  199  Time:  0.871  Rel. Train L2 Loss :  0.055151997688743806  Rel. Test L2 Loss :  0.05409539043903351  Test L2 Loss :  0.07796923935413361  inv_L_scale:  [1.0, 1.0]
Epoch :  200  Time:  0.871  Rel. Train L2 Loss :  0.05430959767765469  Rel. Test L2 Loss :  0.05681330218911171  Test L2 Loss :  0.0822520238161087  inv_L_scale:  [1.0, 1.0]
Epoch :  201  Time:  0.871  Rel. Train L2 Loss :  0.05396546877092785  Rel. Test L2 Loss :  0.0549092772603035  Test L2 Loss :  0.07943494230508805  inv_L_scale:  [1.0, 1.0]
Epoch :  202  Time:  0.871  Rel. Train L2 Loss :  0.054858165234327315  Rel. Test L2 Loss :  0.05770660191774368  Test L2 Loss :  0.08356373190879822  inv_L_scale:  [1.0, 1.0]
Epoch :  203  Time:  0.871  Rel. Train L2 Loss :  0.055009362945954  Rel. Test L2 Loss :  0.055228279680013655  Test L2 Loss :  0.08032047390937805  inv_L_scale:  [1.0, 1.0]
Epoch :  204  Time:  0.87  Rel. Train L2 Loss :  0.054134865287277435  Rel. Test L2 Loss :  0.05720724761486053  Test L2 Loss :  0.08273045241832733  inv_L_scale:  [1.0, 1.0]
Epoch :  205  Time:  0.871  Rel. Train L2 Loss :  0.05487319959534539  Rel. Test L2 Loss :  0.053809145539999007  Test L2 Loss :  0.07827351033687592  inv_L_scale:  [1.0, 1.0]
Epoch :  206  Time:  0.873  Rel. Train L2 Loss :  0.05326584350731638  Rel. Test L2 Loss :  0.055819466859102246  Test L2 Loss :  0.08075204491615295  inv_L_scale:  [1.0, 1.0]
Epoch :  207  Time:  0.872  Rel. Train L2 Loss :  0.054736532999409566  Rel. Test L2 Loss :  0.05419283181428909  Test L2 Loss :  0.07884282439947128  inv_L_scale:  [1.0, 1.0]
Epoch :  208  Time:  0.871  Rel. Train L2 Loss :  0.05282794732186529  Rel. Test L2 Loss :  0.05410664662718773  Test L2 Loss :  0.07834331065416336  inv_L_scale:  [1.0, 1.0]
Epoch :  209  Time:  0.871  Rel. Train L2 Loss :  0.05315425806575351  Rel. Test L2 Loss :  0.054675346612930296  Test L2 Loss :  0.07889087557792664  inv_L_scale:  [1.0, 1.0]
Epoch :  210  Time:  0.871  Rel. Train L2 Loss :  0.05393404523531596  Rel. Test L2 Loss :  0.05543655812740326  Test L2 Loss :  0.08027857840061188  inv_L_scale:  [1.0, 1.0]
Epoch :  211  Time:  0.871  Rel. Train L2 Loss :  0.05354302095042335  Rel. Test L2 Loss :  0.05460405319929123  Test L2 Loss :  0.07906433016061783  inv_L_scale:  [1.0, 1.0]
Epoch :  212  Time:  0.871  Rel. Train L2 Loss :  0.05282830986711714  Rel. Test L2 Loss :  0.053550844341516496  Test L2 Loss :  0.0774382734298706  inv_L_scale:  [1.0, 1.0]
Epoch :  213  Time:  0.871  Rel. Train L2 Loss :  0.054264261060290864  Rel. Test L2 Loss :  0.05656319677829742  Test L2 Loss :  0.08193308115005493  inv_L_scale:  [1.0, 1.0]
Epoch :  214  Time:  0.871  Rel. Train L2 Loss :  0.05382444087002013  Rel. Test L2 Loss :  0.05395178854465485  Test L2 Loss :  0.0779983627796173  inv_L_scale:  [1.0, 1.0]
Epoch :  215  Time:  0.87  Rel. Train L2 Loss :  0.05322350733810001  Rel. Test L2 Loss :  0.05435259968042374  Test L2 Loss :  0.07890147745609283  inv_L_scale:  [1.0, 1.0]
Epoch :  216  Time:  0.871  Rel. Train L2 Loss :  0.053463962773482004  Rel. Test L2 Loss :  0.05641853585839272  Test L2 Loss :  0.08151292234659195  inv_L_scale:  [1.0, 1.0]
Epoch :  217  Time:  0.87  Rel. Train L2 Loss :  0.05459127737416161  Rel. Test L2 Loss :  0.0544536928832531  Test L2 Loss :  0.07851174026727677  inv_L_scale:  [1.0, 1.0]
Epoch :  218  Time:  0.871  Rel. Train L2 Loss :  0.05298285577032301  Rel. Test L2 Loss :  0.05383955761790275  Test L2 Loss :  0.07797137022018433  inv_L_scale:  [1.0, 1.0]
Epoch :  219  Time:  0.871  Rel. Train L2 Loss :  0.05311260054508845  Rel. Test L2 Loss :  0.05442432403564453  Test L2 Loss :  0.07901431828737258  inv_L_scale:  [1.0, 1.0]
Epoch :  220  Time:  0.871  Rel. Train L2 Loss :  0.05280311120880975  Rel. Test L2 Loss :  0.054360853731632235  Test L2 Loss :  0.07868223965167999  inv_L_scale:  [1.0, 1.0]
Epoch :  221  Time:  0.871  Rel. Train L2 Loss :  0.05267687165074878  Rel. Test L2 Loss :  0.05462714895606041  Test L2 Loss :  0.07909779131412506  inv_L_scale:  [1.0, 1.0]
Epoch :  222  Time:  0.87  Rel. Train L2 Loss :  0.05256430523263084  Rel. Test L2 Loss :  0.05434716686606407  Test L2 Loss :  0.07855264633893967  inv_L_scale:  [1.0, 1.0]
Epoch :  223  Time:  0.871  Rel. Train L2 Loss :  0.05354830672343572  Rel. Test L2 Loss :  0.0544935554265976  Test L2 Loss :  0.07940886378288269  inv_L_scale:  [1.0, 1.0]
Epoch :  224  Time:  0.871  Rel. Train L2 Loss :  0.05315395378404193  Rel. Test L2 Loss :  0.055672645717859265  Test L2 Loss :  0.08063072383403778  inv_L_scale:  [1.0, 1.0]
Epoch :  225  Time:  0.871  Rel. Train L2 Loss :  0.05367458053761058  Rel. Test L2 Loss :  0.054510478079319  Test L2 Loss :  0.07895047336816788  inv_L_scale:  [1.0, 1.0]
Epoch :  226  Time:  0.871  Rel. Train L2 Loss :  0.052417085021734235  Rel. Test L2 Loss :  0.05642330527305603  Test L2 Loss :  0.08165818333625793  inv_L_scale:  [1.0, 1.0]
Epoch :  227  Time:  0.872  Rel. Train L2 Loss :  0.052796164717939166  Rel. Test L2 Loss :  0.052312277257442474  Test L2 Loss :  0.07598228484392167  inv_L_scale:  [1.0, 1.0]
Epoch :  228  Time:  0.871  Rel. Train L2 Loss :  0.052304928137196435  Rel. Test L2 Loss :  0.05631706267595291  Test L2 Loss :  0.08105140149593354  inv_L_scale:  [1.0, 1.0]
Epoch :  229  Time:  0.871  Rel. Train L2 Loss :  0.05266469887561268  Rel. Test L2 Loss :  0.05394461378455162  Test L2 Loss :  0.07779738754034042  inv_L_scale:  [1.0, 1.0]
Epoch :  230  Time:  0.871  Rel. Train L2 Loss :  0.05229107999139362  Rel. Test L2 Loss :  0.05557700797915459  Test L2 Loss :  0.08041508644819259  inv_L_scale:  [1.0, 1.0]
Epoch :  231  Time:  0.871  Rel. Train L2 Loss :  0.052900823520289526  Rel. Test L2 Loss :  0.0523181639611721  Test L2 Loss :  0.07574173271656036  inv_L_scale:  [1.0, 1.0]
Epoch :  232  Time:  0.871  Rel. Train L2 Loss :  0.052285410828060576  Rel. Test L2 Loss :  0.05550985395908356  Test L2 Loss :  0.08053205728530884  inv_L_scale:  [1.0, 1.0]
Epoch :  233  Time:  0.871  Rel. Train L2 Loss :  0.052466171234846114  Rel. Test L2 Loss :  0.053265493214130405  Test L2 Loss :  0.07718369513750076  inv_L_scale:  [1.0, 1.0]
Epoch :  234  Time:  0.871  Rel. Train L2 Loss :  0.052128319061464735  Rel. Test L2 Loss :  0.05457070797681809  Test L2 Loss :  0.07888115763664245  inv_L_scale:  [1.0, 1.0]
Epoch :  235  Time:  0.871  Rel. Train L2 Loss :  0.052622038937277266  Rel. Test L2 Loss :  0.0536134484410286  Test L2 Loss :  0.0774834880232811  inv_L_scale:  [1.0, 1.0]
Epoch :  236  Time:  0.871  Rel. Train L2 Loss :  0.05196252663930257  Rel. Test L2 Loss :  0.05329548060894013  Test L2 Loss :  0.07707149684429168  inv_L_scale:  [1.0, 1.0]
Epoch :  237  Time:  0.872  Rel. Train L2 Loss :  0.053119665582974755  Rel. Test L2 Loss :  0.053611393570899966  Test L2 Loss :  0.07772981256246567  inv_L_scale:  [1.0, 1.0]
Epoch :  238  Time:  0.871  Rel. Train L2 Loss :  0.05280717939138412  Rel. Test L2 Loss :  0.053800606578588483  Test L2 Loss :  0.07795502036809922  inv_L_scale:  [1.0, 1.0]
Epoch :  239  Time:  0.871  Rel. Train L2 Loss :  0.05209091603755951  Rel. Test L2 Loss :  0.05159545376896858  Test L2 Loss :  0.07475979268550872  inv_L_scale:  [1.0, 1.0]
Epoch :  240  Time:  0.871  Rel. Train L2 Loss :  0.05209359773331218  Rel. Test L2 Loss :  0.05352817833423615  Test L2 Loss :  0.07742085158824921  inv_L_scale:  [1.0, 1.0]
Epoch :  241  Time:  0.871  Rel. Train L2 Loss :  0.051802048136790596  Rel. Test L2 Loss :  0.05236628279089928  Test L2 Loss :  0.0757115849852562  inv_L_scale:  [1.0, 1.0]
Epoch :  242  Time:  0.87  Rel. Train L2 Loss :  0.05180268103877703  Rel. Test L2 Loss :  0.05584977328777313  Test L2 Loss :  0.08067321687936783  inv_L_scale:  [1.0, 1.0]
Epoch :  243  Time:  0.87  Rel. Train L2 Loss :  0.0516637363533179  Rel. Test L2 Loss :  0.051753751039505004  Test L2 Loss :  0.07559668898582458  inv_L_scale:  [1.0, 1.0]
Epoch :  244  Time:  0.871  Rel. Train L2 Loss :  0.051079388078716065  Rel. Test L2 Loss :  0.05258248180150986  Test L2 Loss :  0.07643348634243012  inv_L_scale:  [1.0, 1.0]
Epoch :  245  Time:  0.871  Rel. Train L2 Loss :  0.05191718445883857  Rel. Test L2 Loss :  0.051925408840179446  Test L2 Loss :  0.07519231170415878  inv_L_scale:  [1.0, 1.0]
Epoch :  246  Time:  0.871  Rel. Train L2 Loss :  0.05116281512710783  Rel. Test L2 Loss :  0.05155690282583237  Test L2 Loss :  0.07472074031829834  inv_L_scale:  [1.0, 1.0]
Epoch :  247  Time:  0.87  Rel. Train L2 Loss :  0.050776925931374235  Rel. Test L2 Loss :  0.05356334865093231  Test L2 Loss :  0.07731993556022644  inv_L_scale:  [1.0, 1.0]
Epoch :  248  Time:  0.87  Rel. Train L2 Loss :  0.05077735929025544  Rel. Test L2 Loss :  0.05116324692964554  Test L2 Loss :  0.07404298186302186  inv_L_scale:  [1.0, 1.0]
Epoch :  249  Time:  0.872  Rel. Train L2 Loss :  0.05092861079507404  Rel. Test L2 Loss :  0.05153497710824013  Test L2 Loss :  0.0741216042637825  inv_L_scale:  [1.0, 1.0]
Epoch :  250  Time:  0.873  Rel. Train L2 Loss :  0.05034065220091078  Rel. Test L2 Loss :  0.05328415438532829  Test L2 Loss :  0.07714509546756744  inv_L_scale:  [1.0, 1.0]
Epoch :  251  Time:  0.871  Rel. Train L2 Loss :  0.051130035022894545  Rel. Test L2 Loss :  0.0515650837123394  Test L2 Loss :  0.07460592091083526  inv_L_scale:  [1.0, 1.0]
Epoch :  252  Time:  0.871  Rel. Train L2 Loss :  0.0517378192808893  Rel. Test L2 Loss :  0.053552835285663604  Test L2 Loss :  0.0774976858496666  inv_L_scale:  [1.0, 1.0]
Epoch :  253  Time:  0.871  Rel. Train L2 Loss :  0.05064003293712934  Rel. Test L2 Loss :  0.053723067939281464  Test L2 Loss :  0.07760314464569092  inv_L_scale:  [1.0, 1.0]
Epoch :  254  Time:  0.871  Rel. Train L2 Loss :  0.05102390229701996  Rel. Test L2 Loss :  0.05281773328781128  Test L2 Loss :  0.07619978785514832  inv_L_scale:  [1.0, 1.0]
Epoch :  255  Time:  0.871  Rel. Train L2 Loss :  0.050437119983964496  Rel. Test L2 Loss :  0.050079430788755416  Test L2 Loss :  0.07252440959215165  inv_L_scale:  [1.0, 1.0]
Epoch :  256  Time:  0.871  Rel. Train L2 Loss :  0.05051138430833817  Rel. Test L2 Loss :  0.05285927593708038  Test L2 Loss :  0.07626913547515869  inv_L_scale:  [1.0, 1.0]
Epoch :  257  Time:  0.871  Rel. Train L2 Loss :  0.05096645151575407  Rel. Test L2 Loss :  0.05420838758349419  Test L2 Loss :  0.07855448544025422  inv_L_scale:  [1.0, 1.0]
Epoch :  258  Time:  0.871  Rel. Train L2 Loss :  0.050939173880550595  Rel. Test L2 Loss :  0.05149570196866989  Test L2 Loss :  0.07461017400026321  inv_L_scale:  [1.0, 1.0]
Epoch :  259  Time:  0.871  Rel. Train L2 Loss :  0.050260416467984514  Rel. Test L2 Loss :  0.05334919050335884  Test L2 Loss :  0.07736069887876511  inv_L_scale:  [1.0, 1.0]
Epoch :  260  Time:  0.871  Rel. Train L2 Loss :  0.050958037078380584  Rel. Test L2 Loss :  0.05024740368127823  Test L2 Loss :  0.07307042330503463  inv_L_scale:  [1.0, 1.0]
Epoch :  261  Time:  0.87  Rel. Train L2 Loss :  0.050766564806302386  Rel. Test L2 Loss :  0.051712343096733095  Test L2 Loss :  0.07486729949712753  inv_L_scale:  [1.0, 1.0]
Epoch :  262  Time:  0.871  Rel. Train L2 Loss :  0.05022449274857839  Rel. Test L2 Loss :  0.05254028633236885  Test L2 Loss :  0.07604333162307739  inv_L_scale:  [1.0, 1.0]
Epoch :  263  Time:  0.871  Rel. Train L2 Loss :  0.05033986687660217  Rel. Test L2 Loss :  0.05012176275253296  Test L2 Loss :  0.07252939283847809  inv_L_scale:  [1.0, 1.0]
Epoch :  264  Time:  0.871  Rel. Train L2 Loss :  0.04988249583376778  Rel. Test L2 Loss :  0.05330677643418312  Test L2 Loss :  0.0773661470413208  inv_L_scale:  [1.0, 1.0]
Epoch :  265  Time:  0.871  Rel. Train L2 Loss :  0.050225612388716805  Rel. Test L2 Loss :  0.05278467506170273  Test L2 Loss :  0.07624100655317306  inv_L_scale:  [1.0, 1.0]
Epoch :  266  Time:  0.871  Rel. Train L2 Loss :  0.05003233507275581  Rel. Test L2 Loss :  0.051231869161129  Test L2 Loss :  0.0745317828655243  inv_L_scale:  [1.0, 1.0]
Epoch :  267  Time:  0.871  Rel. Train L2 Loss :  0.04903043649262852  Rel. Test L2 Loss :  0.050376083105802535  Test L2 Loss :  0.07294693320989609  inv_L_scale:  [1.0, 1.0]
Epoch :  268  Time:  0.871  Rel. Train L2 Loss :  0.05029524185591274  Rel. Test L2 Loss :  0.05240462988615036  Test L2 Loss :  0.07603678464889527  inv_L_scale:  [1.0, 1.0]
Epoch :  269  Time:  0.871  Rel. Train L2 Loss :  0.050006258454587726  Rel. Test L2 Loss :  0.05094326585531235  Test L2 Loss :  0.0739472509920597  inv_L_scale:  [1.0, 1.0]
Epoch :  270  Time:  0.871  Rel. Train L2 Loss :  0.049802792850467896  Rel. Test L2 Loss :  0.05158213213086128  Test L2 Loss :  0.07477668523788453  inv_L_scale:  [1.0, 1.0]
Epoch :  271  Time:  0.871  Rel. Train L2 Loss :  0.04959697453512086  Rel. Test L2 Loss :  0.050367810130119324  Test L2 Loss :  0.07301539838314057  inv_L_scale:  [1.0, 1.0]
Epoch :  272  Time:  0.871  Rel. Train L2 Loss :  0.04888288830717405  Rel. Test L2 Loss :  0.05247229158878326  Test L2 Loss :  0.07577907621860504  inv_L_scale:  [1.0, 1.0]
Epoch :  273  Time:  0.871  Rel. Train L2 Loss :  0.04958497216304143  Rel. Test L2 Loss :  0.049618805199861525  Test L2 Loss :  0.07184406265616416  inv_L_scale:  [1.0, 1.0]
Epoch :  274  Time:  0.872  Rel. Train L2 Loss :  0.04977189267675082  Rel. Test L2 Loss :  0.05071784108877182  Test L2 Loss :  0.07347625494003296  inv_L_scale:  [1.0, 1.0]
Epoch :  275  Time:  0.871  Rel. Train L2 Loss :  0.049393245677153266  Rel. Test L2 Loss :  0.05033723279833793  Test L2 Loss :  0.07301387071609497  inv_L_scale:  [1.0, 1.0]
Epoch :  276  Time:  0.87  Rel. Train L2 Loss :  0.04941640882028474  Rel. Test L2 Loss :  0.04989588290452957  Test L2 Loss :  0.07244480043649673  inv_L_scale:  [1.0, 1.0]
Epoch :  277  Time:  0.87  Rel. Train L2 Loss :  0.04885572297705544  Rel. Test L2 Loss :  0.04910169020295143  Test L2 Loss :  0.07123610854148865  inv_L_scale:  [1.0, 1.0]
Epoch :  278  Time:  0.87  Rel. Train L2 Loss :  0.048822451101409065  Rel. Test L2 Loss :  0.04859214872121811  Test L2 Loss :  0.07048133969306945  inv_L_scale:  [1.0, 1.0]
Epoch :  279  Time:  0.871  Rel. Train L2 Loss :  0.04848292403750949  Rel. Test L2 Loss :  0.04981967121362686  Test L2 Loss :  0.07223348528146743  inv_L_scale:  [1.0, 1.0]
Epoch :  280  Time:  0.871  Rel. Train L2 Loss :  0.04900071443782912  Rel. Test L2 Loss :  0.04994259566068649  Test L2 Loss :  0.07226685285568238  inv_L_scale:  [1.0, 1.0]
Epoch :  281  Time:  0.87  Rel. Train L2 Loss :  0.04868169304397371  Rel. Test L2 Loss :  0.04979474514722824  Test L2 Loss :  0.07250732243061066  inv_L_scale:  [1.0, 1.0]
Epoch :  282  Time:  0.871  Rel. Train L2 Loss :  0.04839544552895758  Rel. Test L2 Loss :  0.051055050790309905  Test L2 Loss :  0.07400263220071793  inv_L_scale:  [1.0, 1.0]
Epoch :  283  Time:  0.871  Rel. Train L2 Loss :  0.04895071221722497  Rel. Test L2 Loss :  0.04960812956094742  Test L2 Loss :  0.07177690237760544  inv_L_scale:  [1.0, 1.0]
Epoch :  284  Time:  0.871  Rel. Train L2 Loss :  0.04866071848405732  Rel. Test L2 Loss :  0.049744456708431244  Test L2 Loss :  0.07195237070322037  inv_L_scale:  [1.0, 1.0]
Epoch :  285  Time:  0.871  Rel. Train L2 Loss :  0.04799619982639949  Rel. Test L2 Loss :  0.04973016396164894  Test L2 Loss :  0.07229932606220245  inv_L_scale:  [1.0, 1.0]
Epoch :  286  Time:  0.872  Rel. Train L2 Loss :  0.04900888365175989  Rel. Test L2 Loss :  0.04956488862633705  Test L2 Loss :  0.07183077946305275  inv_L_scale:  [1.0, 1.0]
Epoch :  287  Time:  0.872  Rel. Train L2 Loss :  0.04805982145998213  Rel. Test L2 Loss :  0.04876065716147423  Test L2 Loss :  0.07093087792396545  inv_L_scale:  [1.0, 1.0]
Epoch :  288  Time:  0.87  Rel. Train L2 Loss :  0.04919532049033377  Rel. Test L2 Loss :  0.05115739420056343  Test L2 Loss :  0.07385353088378906  inv_L_scale:  [1.0, 1.0]
Epoch :  289  Time:  0.871  Rel. Train L2 Loss :  0.04856813175810708  Rel. Test L2 Loss :  0.0498043942451477  Test L2 Loss :  0.07223408952355385  inv_L_scale:  [1.0, 1.0]
Epoch :  290  Time:  0.87  Rel. Train L2 Loss :  0.04818650821844737  Rel. Test L2 Loss :  0.04938249468803406  Test L2 Loss :  0.07167004317045211  inv_L_scale:  [1.0, 1.0]
Epoch :  291  Time:  0.871  Rel. Train L2 Loss :  0.04844088680214352  Rel. Test L2 Loss :  0.05167100042104721  Test L2 Loss :  0.07516815841197967  inv_L_scale:  [1.0, 1.0]
Epoch :  292  Time:  0.871  Rel. Train L2 Loss :  0.04861564283569654  Rel. Test L2 Loss :  0.049933549612760544  Test L2 Loss :  0.072803093791008  inv_L_scale:  [1.0, 1.0]
Epoch :  293  Time:  0.881  Rel. Train L2 Loss :  0.048891343010796444  Rel. Test L2 Loss :  0.04881580352783203  Test L2 Loss :  0.07065693646669388  inv_L_scale:  [1.0, 1.0]
Epoch :  294  Time:  0.874  Rel. Train L2 Loss :  0.04828187323278851  Rel. Test L2 Loss :  0.04979591712355614  Test L2 Loss :  0.07226215124130249  inv_L_scale:  [1.0, 1.0]
Epoch :  295  Time:  0.871  Rel. Train L2 Loss :  0.04785223906238874  Rel. Test L2 Loss :  0.049176560044288636  Test L2 Loss :  0.07151262760162354  inv_L_scale:  [1.0, 1.0]
Epoch :  296  Time:  0.871  Rel. Train L2 Loss :  0.048009380400180816  Rel. Test L2 Loss :  0.050534492433071135  Test L2 Loss :  0.07334280520677566  inv_L_scale:  [1.0, 1.0]
Epoch :  297  Time:  0.87  Rel. Train L2 Loss :  0.04750298097729683  Rel. Test L2 Loss :  0.04794754922389984  Test L2 Loss :  0.06964729696512223  inv_L_scale:  [1.0, 1.0]
Epoch :  298  Time:  0.871  Rel. Train L2 Loss :  0.04841336747010549  Rel. Test L2 Loss :  0.048367577642202376  Test L2 Loss :  0.07040896028280258  inv_L_scale:  [1.0, 1.0]
Epoch :  299  Time:  0.871  Rel. Train L2 Loss :  0.04769085498319732  Rel. Test L2 Loss :  0.04911658525466919  Test L2 Loss :  0.07162821888923646  inv_L_scale:  [1.0, 1.0]
Epoch :  300  Time:  0.871  Rel. Train L2 Loss :  0.04745630265937911  Rel. Test L2 Loss :  0.048270704448223116  Test L2 Loss :  0.06997765243053436  inv_L_scale:  [1.0, 1.0]
Epoch :  301  Time:  0.873  Rel. Train L2 Loss :  0.04702161610126496  Rel. Test L2 Loss :  0.048238359689712525  Test L2 Loss :  0.06987942636013031  inv_L_scale:  [1.0, 1.0]
Epoch :  302  Time:  0.873  Rel. Train L2 Loss :  0.04734109318918652  Rel. Test L2 Loss :  0.04858562558889389  Test L2 Loss :  0.0703697843849659  inv_L_scale:  [1.0, 1.0]
Epoch :  303  Time:  0.87  Rel. Train L2 Loss :  0.047377699994378616  Rel. Test L2 Loss :  0.04747491791844368  Test L2 Loss :  0.06891126081347465  inv_L_scale:  [1.0, 1.0]
Epoch :  304  Time:  0.871  Rel. Train L2 Loss :  0.04694252027405633  Rel. Test L2 Loss :  0.048282290548086165  Test L2 Loss :  0.07032923236489295  inv_L_scale:  [1.0, 1.0]
Epoch :  305  Time:  0.871  Rel. Train L2 Loss :  0.046590291584531464  Rel. Test L2 Loss :  0.049018416404724124  Test L2 Loss :  0.07116033762693405  inv_L_scale:  [1.0, 1.0]
Epoch :  306  Time:  0.871  Rel. Train L2 Loss :  0.04738136758406957  Rel. Test L2 Loss :  0.048633134365081786  Test L2 Loss :  0.07025024175643921  inv_L_scale:  [1.0, 1.0]
Epoch :  307  Time:  0.87  Rel. Train L2 Loss :  0.04715169640050994  Rel. Test L2 Loss :  0.0483521893620491  Test L2 Loss :  0.07014495372772217  inv_L_scale:  [1.0, 1.0]
Epoch :  308  Time:  0.871  Rel. Train L2 Loss :  0.04728369091947873  Rel. Test L2 Loss :  0.04902486354112625  Test L2 Loss :  0.07101304531097412  inv_L_scale:  [1.0, 1.0]
Epoch :  309  Time:  0.87  Rel. Train L2 Loss :  0.047011823703845344  Rel. Test L2 Loss :  0.046990545690059664  Test L2 Loss :  0.06828360438346863  inv_L_scale:  [1.0, 1.0]
Epoch :  310  Time:  0.871  Rel. Train L2 Loss :  0.04632255103853014  Rel. Test L2 Loss :  0.048057388216257095  Test L2 Loss :  0.06969538182020188  inv_L_scale:  [1.0, 1.0]
Epoch :  311  Time:  0.871  Rel. Train L2 Loss :  0.04740045448144277  Rel. Test L2 Loss :  0.04859068274497986  Test L2 Loss :  0.0703762786090374  inv_L_scale:  [1.0, 1.0]
Epoch :  312  Time:  0.871  Rel. Train L2 Loss :  0.04641894463035796  Rel. Test L2 Loss :  0.04783037036657333  Test L2 Loss :  0.06929022938013077  inv_L_scale:  [1.0, 1.0]
Epoch :  313  Time:  0.871  Rel. Train L2 Loss :  0.04635675883955426  Rel. Test L2 Loss :  0.04859921038150787  Test L2 Loss :  0.07054365426301956  inv_L_scale:  [1.0, 1.0]
Epoch :  314  Time:  0.871  Rel. Train L2 Loss :  0.04706095900800493  Rel. Test L2 Loss :  0.048515216559171674  Test L2 Loss :  0.07041937857866287  inv_L_scale:  [1.0, 1.0]
Epoch :  315  Time:  0.87  Rel. Train L2 Loss :  0.04674350362684992  Rel. Test L2 Loss :  0.047336702942848204  Test L2 Loss :  0.06887934356927872  inv_L_scale:  [1.0, 1.0]
Epoch :  316  Time:  0.871  Rel. Train L2 Loss :  0.04596231445670128  Rel. Test L2 Loss :  0.04817951440811157  Test L2 Loss :  0.06989475399255753  inv_L_scale:  [1.0, 1.0]
Epoch :  317  Time:  0.871  Rel. Train L2 Loss :  0.0463218002849155  Rel. Test L2 Loss :  0.04826241090893745  Test L2 Loss :  0.07006433993577957  inv_L_scale:  [1.0, 1.0]
Epoch :  318  Time:  0.871  Rel. Train L2 Loss :  0.04670203215546078  Rel. Test L2 Loss :  0.04883276209235191  Test L2 Loss :  0.07076517224311829  inv_L_scale:  [1.0, 1.0]
Epoch :  319  Time:  0.871  Rel. Train L2 Loss :  0.04663778483867645  Rel. Test L2 Loss :  0.047846479266881944  Test L2 Loss :  0.06940506398677826  inv_L_scale:  [1.0, 1.0]
Epoch :  320  Time:  0.871  Rel. Train L2 Loss :  0.04607437501351039  Rel. Test L2 Loss :  0.04708275899291039  Test L2 Loss :  0.06855629533529281  inv_L_scale:  [1.0, 1.0]
Epoch :  321  Time:  0.87  Rel. Train L2 Loss :  0.046152460343307916  Rel. Test L2 Loss :  0.04845642328262329  Test L2 Loss :  0.07042690217494965  inv_L_scale:  [1.0, 1.0]
Epoch :  322  Time:  0.87  Rel. Train L2 Loss :  0.046160872247484  Rel. Test L2 Loss :  0.04822254747152328  Test L2 Loss :  0.07000868678092957  inv_L_scale:  [1.0, 1.0]
Epoch :  323  Time:  0.87  Rel. Train L2 Loss :  0.045899334632688096  Rel. Test L2 Loss :  0.04943027973175049  Test L2 Loss :  0.07146640256047249  inv_L_scale:  [1.0, 1.0]
Epoch :  324  Time:  0.869  Rel. Train L2 Loss :  0.04589527765909831  Rel. Test L2 Loss :  0.04783324867486954  Test L2 Loss :  0.06920710891485214  inv_L_scale:  [1.0, 1.0]
Epoch :  325  Time:  0.87  Rel. Train L2 Loss :  0.045438252372874154  Rel. Test L2 Loss :  0.04634591907262802  Test L2 Loss :  0.06750452145934105  inv_L_scale:  [1.0, 1.0]
Epoch :  326  Time:  0.87  Rel. Train L2 Loss :  0.04549518865015772  Rel. Test L2 Loss :  0.04669162079691887  Test L2 Loss :  0.06774176359176635  inv_L_scale:  [1.0, 1.0]
Epoch :  327  Time:  0.869  Rel. Train L2 Loss :  0.04639518674876955  Rel. Test L2 Loss :  0.04771046370267868  Test L2 Loss :  0.06923788398504258  inv_L_scale:  [1.0, 1.0]
Epoch :  328  Time:  0.87  Rel. Train L2 Loss :  0.045514169070455766  Rel. Test L2 Loss :  0.047806869596242904  Test L2 Loss :  0.06943940848112107  inv_L_scale:  [1.0, 1.0]
Epoch :  329  Time:  0.869  Rel. Train L2 Loss :  0.04591867478357421  Rel. Test L2 Loss :  0.04714128687977791  Test L2 Loss :  0.06832444339990616  inv_L_scale:  [1.0, 1.0]
Epoch :  330  Time:  0.869  Rel. Train L2 Loss :  0.04530759415692753  Rel. Test L2 Loss :  0.04669526994228363  Test L2 Loss :  0.06795307233929634  inv_L_scale:  [1.0, 1.0]
Epoch :  331  Time:  0.871  Rel. Train L2 Loss :  0.0457538297937976  Rel. Test L2 Loss :  0.046686616092920304  Test L2 Loss :  0.06774134665727616  inv_L_scale:  [1.0, 1.0]
Epoch :  332  Time:  0.87  Rel. Train L2 Loss :  0.04523293498489592  Rel. Test L2 Loss :  0.045861812382936476  Test L2 Loss :  0.06681222483515739  inv_L_scale:  [1.0, 1.0]
Epoch :  333  Time:  0.87  Rel. Train L2 Loss :  0.04478160043557485  Rel. Test L2 Loss :  0.04664614468812942  Test L2 Loss :  0.06766443192958832  inv_L_scale:  [1.0, 1.0]
Epoch :  334  Time:  0.87  Rel. Train L2 Loss :  0.04550857380032539  Rel. Test L2 Loss :  0.04746159642934799  Test L2 Loss :  0.06906552970409394  inv_L_scale:  [1.0, 1.0]
Epoch :  335  Time:  0.87  Rel. Train L2 Loss :  0.045227418326669266  Rel. Test L2 Loss :  0.04746797800064087  Test L2 Loss :  0.0688666957616806  inv_L_scale:  [1.0, 1.0]
Epoch :  336  Time:  0.87  Rel. Train L2 Loss :  0.04488349763883485  Rel. Test L2 Loss :  0.04721237808465958  Test L2 Loss :  0.06859293520450592  inv_L_scale:  [1.0, 1.0]
Epoch :  337  Time:  0.87  Rel. Train L2 Loss :  0.045676205572154786  Rel. Test L2 Loss :  0.046675426810979845  Test L2 Loss :  0.0677338981628418  inv_L_scale:  [1.0, 1.0]
Epoch :  338  Time:  0.87  Rel. Train L2 Loss :  0.04464909128016896  Rel. Test L2 Loss :  0.046853758096694946  Test L2 Loss :  0.0678129756450653  inv_L_scale:  [1.0, 1.0]
Epoch :  339  Time:  0.87  Rel. Train L2 Loss :  0.04479649995764096  Rel. Test L2 Loss :  0.04661256834864616  Test L2 Loss :  0.06784922480583191  inv_L_scale:  [1.0, 1.0]
Epoch :  340  Time:  0.869  Rel. Train L2 Loss :  0.04433248897393544  Rel. Test L2 Loss :  0.0462254174053669  Test L2 Loss :  0.06712346032261848  inv_L_scale:  [1.0, 1.0]
Epoch :  341  Time:  0.87  Rel. Train L2 Loss :  0.04450673033793767  Rel. Test L2 Loss :  0.046338737308979035  Test L2 Loss :  0.06722306862473487  inv_L_scale:  [1.0, 1.0]
Epoch :  342  Time:  0.87  Rel. Train L2 Loss :  0.04437829082210858  Rel. Test L2 Loss :  0.0462372063100338  Test L2 Loss :  0.06717064335942269  inv_L_scale:  [1.0, 1.0]
Epoch :  343  Time:  0.87  Rel. Train L2 Loss :  0.044194023311138156  Rel. Test L2 Loss :  0.04697603762149811  Test L2 Loss :  0.06817034751176834  inv_L_scale:  [1.0, 1.0]
Epoch :  344  Time:  0.87  Rel. Train L2 Loss :  0.044314074085818396  Rel. Test L2 Loss :  0.0462934273481369  Test L2 Loss :  0.06728599980473518  inv_L_scale:  [1.0, 1.0]
Epoch :  345  Time:  0.87  Rel. Train L2 Loss :  0.04466681222120921  Rel. Test L2 Loss :  0.04662039905786514  Test L2 Loss :  0.06780995547771454  inv_L_scale:  [1.0, 1.0]
Epoch :  346  Time:  0.872  Rel. Train L2 Loss :  0.044401865982347063  Rel. Test L2 Loss :  0.04815190687775612  Test L2 Loss :  0.06974381774663925  inv_L_scale:  [1.0, 1.0]
Epoch :  347  Time:  0.871  Rel. Train L2 Loss :  0.04475430942244  Rel. Test L2 Loss :  0.04665420055389404  Test L2 Loss :  0.06778083086013793  inv_L_scale:  [1.0, 1.0]
Epoch :  348  Time:  0.871  Rel. Train L2 Loss :  0.04437547162175179  Rel. Test L2 Loss :  0.04608895570039749  Test L2 Loss :  0.06703518509864807  inv_L_scale:  [1.0, 1.0]
Epoch :  349  Time:  0.871  Rel. Train L2 Loss :  0.043855098436276115  Rel. Test L2 Loss :  0.04659521862864494  Test L2 Loss :  0.06778835102915765  inv_L_scale:  [1.0, 1.0]
Epoch :  350  Time:  0.87  Rel. Train L2 Loss :  0.04408346891403198  Rel. Test L2 Loss :  0.04655648916959763  Test L2 Loss :  0.06754808932542801  inv_L_scale:  [1.0, 1.0]
Epoch :  351  Time:  0.869  Rel. Train L2 Loss :  0.04443812610374557  Rel. Test L2 Loss :  0.04737823635339737  Test L2 Loss :  0.06879192396998406  inv_L_scale:  [1.0, 1.0]
Epoch :  352  Time:  0.871  Rel. Train L2 Loss :  0.043864051327109334  Rel. Test L2 Loss :  0.045675762742757794  Test L2 Loss :  0.06645057916641235  inv_L_scale:  [1.0, 1.0]
Epoch :  353  Time:  0.87  Rel. Train L2 Loss :  0.043694261958201724  Rel. Test L2 Loss :  0.04597857072949409  Test L2 Loss :  0.0666718566417694  inv_L_scale:  [1.0, 1.0]
Epoch :  354  Time:  0.871  Rel. Train L2 Loss :  0.043775208244721094  Rel. Test L2 Loss :  0.04651799276471138  Test L2 Loss :  0.06728823632001876  inv_L_scale:  [1.0, 1.0]
Epoch :  355  Time:  0.87  Rel. Train L2 Loss :  0.044117194298240875  Rel. Test L2 Loss :  0.046191029250621796  Test L2 Loss :  0.06705776631832122  inv_L_scale:  [1.0, 1.0]
Epoch :  356  Time:  0.87  Rel. Train L2 Loss :  0.043563728796111215  Rel. Test L2 Loss :  0.045399143844842914  Test L2 Loss :  0.06585417687892914  inv_L_scale:  [1.0, 1.0]
Epoch :  357  Time:  0.87  Rel. Train L2 Loss :  0.04388044719894727  Rel. Test L2 Loss :  0.04577311336994171  Test L2 Loss :  0.06633316397666932  inv_L_scale:  [1.0, 1.0]
Epoch :  358  Time:  0.87  Rel. Train L2 Loss :  0.044083847088946235  Rel. Test L2 Loss :  0.04560162141919136  Test L2 Loss :  0.06627088218927384  inv_L_scale:  [1.0, 1.0]
Epoch :  359  Time:  0.871  Rel. Train L2 Loss :  0.04362343862652779  Rel. Test L2 Loss :  0.04563165962696075  Test L2 Loss :  0.06638898670673371  inv_L_scale:  [1.0, 1.0]
Epoch :  360  Time:  0.871  Rel. Train L2 Loss :  0.043811765495273804  Rel. Test L2 Loss :  0.04513189807534218  Test L2 Loss :  0.06555040240287781  inv_L_scale:  [1.0, 1.0]
Epoch :  361  Time:  0.871  Rel. Train L2 Loss :  0.04323290367921193  Rel. Test L2 Loss :  0.04594265669584274  Test L2 Loss :  0.06672538861632347  inv_L_scale:  [1.0, 1.0]
Epoch :  362  Time:  0.87  Rel. Train L2 Loss :  0.043409902701775235  Rel. Test L2 Loss :  0.045635835379362104  Test L2 Loss :  0.06619318306446076  inv_L_scale:  [1.0, 1.0]
Epoch :  363  Time:  0.872  Rel. Train L2 Loss :  0.04339176732632849  Rel. Test L2 Loss :  0.04526573196053505  Test L2 Loss :  0.06568274766206741  inv_L_scale:  [1.0, 1.0]
Epoch :  364  Time:  0.873  Rel. Train L2 Loss :  0.04327122787634532  Rel. Test L2 Loss :  0.04548428237438202  Test L2 Loss :  0.06597891420125962  inv_L_scale:  [1.0, 1.0]
Epoch :  365  Time:  0.871  Rel. Train L2 Loss :  0.043074998723136054  Rel. Test L2 Loss :  0.045501531660556795  Test L2 Loss :  0.06607166305184364  inv_L_scale:  [1.0, 1.0]
Epoch :  366  Time:  0.871  Rel. Train L2 Loss :  0.04341721961895625  Rel. Test L2 Loss :  0.04510967195034027  Test L2 Loss :  0.06554617166519165  inv_L_scale:  [1.0, 1.0]
Epoch :  367  Time:  0.871  Rel. Train L2 Loss :  0.04330446857545111  Rel. Test L2 Loss :  0.045050854831933974  Test L2 Loss :  0.06545188635587693  inv_L_scale:  [1.0, 1.0]
Epoch :  368  Time:  0.871  Rel. Train L2 Loss :  0.04280857647458712  Rel. Test L2 Loss :  0.04494121700525284  Test L2 Loss :  0.06538238883018493  inv_L_scale:  [1.0, 1.0]
Epoch :  369  Time:  0.871  Rel. Train L2 Loss :  0.043346845971213445  Rel. Test L2 Loss :  0.045788374245166776  Test L2 Loss :  0.06648158445954323  inv_L_scale:  [1.0, 1.0]
Epoch :  370  Time:  0.871  Rel. Train L2 Loss :  0.04286724737948842  Rel. Test L2 Loss :  0.04620337188243866  Test L2 Loss :  0.06695272564888001  inv_L_scale:  [1.0, 1.0]
Epoch :  371  Time:  0.871  Rel. Train L2 Loss :  0.043208306050962875  Rel. Test L2 Loss :  0.045536993741989135  Test L2 Loss :  0.0662027758359909  inv_L_scale:  [1.0, 1.0]
Epoch :  372  Time:  0.871  Rel. Train L2 Loss :  0.04272784367203712  Rel. Test L2 Loss :  0.04487268358469009  Test L2 Loss :  0.06502042233943939  inv_L_scale:  [1.0, 1.0]
Epoch :  373  Time:  0.871  Rel. Train L2 Loss :  0.04236741926934984  Rel. Test L2 Loss :  0.04478549584746361  Test L2 Loss :  0.06514677375555039  inv_L_scale:  [1.0, 1.0]
Epoch :  374  Time:  0.871  Rel. Train L2 Loss :  0.04245590443412463  Rel. Test L2 Loss :  0.04481550768017769  Test L2 Loss :  0.06515014678239822  inv_L_scale:  [1.0, 1.0]
Epoch :  375  Time:  0.871  Rel. Train L2 Loss :  0.04256605053941409  Rel. Test L2 Loss :  0.044851088672876356  Test L2 Loss :  0.06528757825493813  inv_L_scale:  [1.0, 1.0]
Epoch :  376  Time:  0.871  Rel. Train L2 Loss :  0.04280520632863045  Rel. Test L2 Loss :  0.04546996384859085  Test L2 Loss :  0.06607789993286133  inv_L_scale:  [1.0, 1.0]
Epoch :  377  Time:  0.871  Rel. Train L2 Loss :  0.042642197642061445  Rel. Test L2 Loss :  0.04452903464436531  Test L2 Loss :  0.06465046852827072  inv_L_scale:  [1.0, 1.0]
Epoch :  378  Time:  0.871  Rel. Train L2 Loss :  0.042335827598969145  Rel. Test L2 Loss :  0.04419108361005783  Test L2 Loss :  0.06421825438737869  inv_L_scale:  [1.0, 1.0]
Epoch :  379  Time:  0.87  Rel. Train L2 Loss :  0.042309258149729835  Rel. Test L2 Loss :  0.04388930350542068  Test L2 Loss :  0.06386913999915123  inv_L_scale:  [1.0, 1.0]
Epoch :  380  Time:  0.87  Rel. Train L2 Loss :  0.04223566124836604  Rel. Test L2 Loss :  0.04469228222966194  Test L2 Loss :  0.06497553646564484  inv_L_scale:  [1.0, 1.0]
Epoch :  381  Time:  0.871  Rel. Train L2 Loss :  0.04236023214956124  Rel. Test L2 Loss :  0.04512129619717598  Test L2 Loss :  0.0654977448284626  inv_L_scale:  [1.0, 1.0]
Epoch :  382  Time:  0.871  Rel. Train L2 Loss :  0.04202051872180568  Rel. Test L2 Loss :  0.04376265898346901  Test L2 Loss :  0.06365041881799698  inv_L_scale:  [1.0, 1.0]
Epoch :  383  Time:  0.871  Rel. Train L2 Loss :  0.042164662149217394  Rel. Test L2 Loss :  0.04452501654624939  Test L2 Loss :  0.06469485715031624  inv_L_scale:  [1.0, 1.0]
Epoch :  384  Time:  0.871  Rel. Train L2 Loss :  0.042304830766386456  Rel. Test L2 Loss :  0.04484206765890122  Test L2 Loss :  0.06516388714313508  inv_L_scale:  [1.0, 1.0]
Epoch :  385  Time:  0.87  Rel. Train L2 Loss :  0.04225358775920338  Rel. Test L2 Loss :  0.04463900998234749  Test L2 Loss :  0.06497550472617149  inv_L_scale:  [1.0, 1.0]
Epoch :  386  Time:  0.871  Rel. Train L2 Loss :  0.04219957888126373  Rel. Test L2 Loss :  0.04518746167421341  Test L2 Loss :  0.06562527507543564  inv_L_scale:  [1.0, 1.0]
Epoch :  387  Time:  0.871  Rel. Train L2 Loss :  0.04208769122759501  Rel. Test L2 Loss :  0.0438081394135952  Test L2 Loss :  0.06374849230051041  inv_L_scale:  [1.0, 1.0]
Epoch :  388  Time:  0.871  Rel. Train L2 Loss :  0.04169227282206218  Rel. Test L2 Loss :  0.04440497875213623  Test L2 Loss :  0.06461861535906792  inv_L_scale:  [1.0, 1.0]
Epoch :  389  Time:  0.871  Rel. Train L2 Loss :  0.04177691686484549  Rel. Test L2 Loss :  0.044101242274045944  Test L2 Loss :  0.0641785617172718  inv_L_scale:  [1.0, 1.0]
Epoch :  390  Time:  0.87  Rel. Train L2 Loss :  0.04184976864192221  Rel. Test L2 Loss :  0.04466000884771347  Test L2 Loss :  0.06490778222680092  inv_L_scale:  [1.0, 1.0]
Epoch :  391  Time:  0.871  Rel. Train L2 Loss :  0.04160873096850183  Rel. Test L2 Loss :  0.04373013973236084  Test L2 Loss :  0.06366735398769378  inv_L_scale:  [1.0, 1.0]
Epoch :  392  Time:  0.871  Rel. Train L2 Loss :  0.04156122366587321  Rel. Test L2 Loss :  0.043972627818584444  Test L2 Loss :  0.0638660454750061  inv_L_scale:  [1.0, 1.0]
Epoch :  393  Time:  0.87  Rel. Train L2 Loss :  0.041483635736836326  Rel. Test L2 Loss :  0.04414251193404198  Test L2 Loss :  0.06422900259494782  inv_L_scale:  [1.0, 1.0]
Epoch :  394  Time:  0.87  Rel. Train L2 Loss :  0.04162252061896854  Rel. Test L2 Loss :  0.04415259808301926  Test L2 Loss :  0.0641537457704544  inv_L_scale:  [1.0, 1.0]
Epoch :  395  Time:  0.87  Rel. Train L2 Loss :  0.041462682750489976  Rel. Test L2 Loss :  0.043925100713968275  Test L2 Loss :  0.06381874427199363  inv_L_scale:  [1.0, 1.0]
Epoch :  396  Time:  0.871  Rel. Train L2 Loss :  0.04150164066089524  Rel. Test L2 Loss :  0.044064726829528805  Test L2 Loss :  0.06408697247505188  inv_L_scale:  [1.0, 1.0]
Epoch :  397  Time:  0.871  Rel. Train L2 Loss :  0.04156327337026596  Rel. Test L2 Loss :  0.04431760460138321  Test L2 Loss :  0.06452582627534867  inv_L_scale:  [1.0, 1.0]
Epoch :  398  Time:  0.871  Rel. Train L2 Loss :  0.041391730705897016  Rel. Test L2 Loss :  0.04381126716732979  Test L2 Loss :  0.06363755077123642  inv_L_scale:  [1.0, 1.0]
Epoch :  399  Time:  0.871  Rel. Train L2 Loss :  0.041196505808167985  Rel. Test L2 Loss :  0.044695592522621154  Test L2 Loss :  0.0649538929760456  inv_L_scale:  [1.0, 1.0]
Epoch :  400  Time:  0.87  Rel. Train L2 Loss :  0.041239111175139745  Rel. Test L2 Loss :  0.04406687498092651  Test L2 Loss :  0.06388858139514923  inv_L_scale:  [1.0, 1.0]
Epoch :  401  Time:  0.87  Rel. Train L2 Loss :  0.04135557636618614  Rel. Test L2 Loss :  0.043840624839067456  Test L2 Loss :  0.06370308667421341  inv_L_scale:  [1.0, 1.0]
Epoch :  402  Time:  0.87  Rel. Train L2 Loss :  0.041183765762382085  Rel. Test L2 Loss :  0.04334812581539154  Test L2 Loss :  0.06318197786808014  inv_L_scale:  [1.0, 1.0]
Epoch :  403  Time:  0.871  Rel. Train L2 Loss :  0.041136043220758436  Rel. Test L2 Loss :  0.04411764025688172  Test L2 Loss :  0.06417257010936737  inv_L_scale:  [1.0, 1.0]
Epoch :  404  Time:  0.87  Rel. Train L2 Loss :  0.04111261568135685  Rel. Test L2 Loss :  0.04361792236566544  Test L2 Loss :  0.06355023756623268  inv_L_scale:  [1.0, 1.0]
Epoch :  405  Time:  0.871  Rel. Train L2 Loss :  0.04116387605667114  Rel. Test L2 Loss :  0.043800646364688875  Test L2 Loss :  0.0636818665266037  inv_L_scale:  [1.0, 1.0]
Epoch :  406  Time:  0.871  Rel. Train L2 Loss :  0.0411189783944024  Rel. Test L2 Loss :  0.043573160767555234  Test L2 Loss :  0.06337285429239273  inv_L_scale:  [1.0, 1.0]
Epoch :  407  Time:  0.871  Rel. Train L2 Loss :  0.04102208144134945  Rel. Test L2 Loss :  0.04354206770658493  Test L2 Loss :  0.0632841444015503  inv_L_scale:  [1.0, 1.0]
Epoch :  408  Time:  0.871  Rel. Train L2 Loss :  0.04096622292366293  Rel. Test L2 Loss :  0.043834258466959  Test L2 Loss :  0.06365646228194237  inv_L_scale:  [1.0, 1.0]
Epoch :  409  Time:  0.871  Rel. Train L2 Loss :  0.0409977593852414  Rel. Test L2 Loss :  0.04353427663445473  Test L2 Loss :  0.0632785964012146  inv_L_scale:  [1.0, 1.0]
Epoch :  410  Time:  0.871  Rel. Train L2 Loss :  0.040656810088290106  Rel. Test L2 Loss :  0.04355709344148636  Test L2 Loss :  0.06333188027143478  inv_L_scale:  [1.0, 1.0]
Epoch :  411  Time:  0.871  Rel. Train L2 Loss :  0.04063912837041749  Rel. Test L2 Loss :  0.043812564611434936  Test L2 Loss :  0.06368051528930664  inv_L_scale:  [1.0, 1.0]
Epoch :  412  Time:  0.87  Rel. Train L2 Loss :  0.040881501734256746  Rel. Test L2 Loss :  0.043894037902355194  Test L2 Loss :  0.06380553111433983  inv_L_scale:  [1.0, 1.0]
Epoch :  413  Time:  0.871  Rel. Train L2 Loss :  0.04070816328128179  Rel. Test L2 Loss :  0.04357039988040924  Test L2 Loss :  0.06341742351651192  inv_L_scale:  [1.0, 1.0]
Epoch :  414  Time:  0.871  Rel. Train L2 Loss :  0.04063988897535536  Rel. Test L2 Loss :  0.043677350729703905  Test L2 Loss :  0.06342297613620758  inv_L_scale:  [1.0, 1.0]
Epoch :  415  Time:  0.871  Rel. Train L2 Loss :  0.040791977130704454  Rel. Test L2 Loss :  0.04339910626411438  Test L2 Loss :  0.06304935202002525  inv_L_scale:  [1.0, 1.0]
Epoch :  416  Time:  0.873  Rel. Train L2 Loss :  0.04066705193784502  Rel. Test L2 Loss :  0.04376897156238556  Test L2 Loss :  0.06354997634887695  inv_L_scale:  [1.0, 1.0]
Epoch :  417  Time:  0.871  Rel. Train L2 Loss :  0.04051524715291129  Rel. Test L2 Loss :  0.04349255472421646  Test L2 Loss :  0.06326911255717277  inv_L_scale:  [1.0, 1.0]
Epoch :  418  Time:  0.871  Rel. Train L2 Loss :  0.04050076045923763  Rel. Test L2 Loss :  0.04333713755011558  Test L2 Loss :  0.06292912960052491  inv_L_scale:  [1.0, 1.0]
Epoch :  419  Time:  0.871  Rel. Train L2 Loss :  0.040323271486494276  Rel. Test L2 Loss :  0.04336995586752892  Test L2 Loss :  0.06307257369160651  inv_L_scale:  [1.0, 1.0]
Epoch :  420  Time:  0.871  Rel. Train L2 Loss :  0.04037629360953967  Rel. Test L2 Loss :  0.043175300061702726  Test L2 Loss :  0.06286524906754494  inv_L_scale:  [1.0, 1.0]
Epoch :  421  Time:  0.87  Rel. Train L2 Loss :  0.04032694993747605  Rel. Test L2 Loss :  0.04303423643112183  Test L2 Loss :  0.06258600577712059  inv_L_scale:  [1.0, 1.0]
Epoch :  422  Time:  0.871  Rel. Train L2 Loss :  0.04040656896101104  Rel. Test L2 Loss :  0.043037193566560744  Test L2 Loss :  0.06256983518600463  inv_L_scale:  [1.0, 1.0]
Epoch :  423  Time:  0.871  Rel. Train L2 Loss :  0.04027792152431276  Rel. Test L2 Loss :  0.0434202079474926  Test L2 Loss :  0.06310189425945283  inv_L_scale:  [1.0, 1.0]
Epoch :  424  Time:  0.871  Rel. Train L2 Loss :  0.040181007103787525  Rel. Test L2 Loss :  0.043070767819881436  Test L2 Loss :  0.06272837579250336  inv_L_scale:  [1.0, 1.0]
Epoch :  425  Time:  0.871  Rel. Train L2 Loss :  0.04018868742717637  Rel. Test L2 Loss :  0.04337748631834984  Test L2 Loss :  0.06299968540668488  inv_L_scale:  [1.0, 1.0]
Epoch :  426  Time:  0.871  Rel. Train L2 Loss :  0.04016661713520686  Rel. Test L2 Loss :  0.04314716964960098  Test L2 Loss :  0.06271776750683784  inv_L_scale:  [1.0, 1.0]
Epoch :  427  Time:  0.871  Rel. Train L2 Loss :  0.04003880085216628  Rel. Test L2 Loss :  0.04344577550888062  Test L2 Loss :  0.06311877608299256  inv_L_scale:  [1.0, 1.0]
Epoch :  428  Time:  0.871  Rel. Train L2 Loss :  0.03998127601212925  Rel. Test L2 Loss :  0.042804409265518185  Test L2 Loss :  0.0622720704972744  inv_L_scale:  [1.0, 1.0]
Epoch :  429  Time:  0.87  Rel. Train L2 Loss :  0.03993572197026676  Rel. Test L2 Loss :  0.04323623508214951  Test L2 Loss :  0.06284636199474335  inv_L_scale:  [1.0, 1.0]
Epoch :  430  Time:  0.87  Rel. Train L2 Loss :  0.03996014813582102  Rel. Test L2 Loss :  0.042998417019844054  Test L2 Loss :  0.062478773295879364  inv_L_scale:  [1.0, 1.0]
Epoch :  431  Time:  0.871  Rel. Train L2 Loss :  0.03996232090724839  Rel. Test L2 Loss :  0.04291637688875198  Test L2 Loss :  0.06245252251625061  inv_L_scale:  [1.0, 1.0]
Epoch :  432  Time:  0.871  Rel. Train L2 Loss :  0.039973282615343726  Rel. Test L2 Loss :  0.04278545930981636  Test L2 Loss :  0.06227935492992401  inv_L_scale:  [1.0, 1.0]
Epoch :  433  Time:  0.873  Rel. Train L2 Loss :  0.039859835257132846  Rel. Test L2 Loss :  0.04287768736481667  Test L2 Loss :  0.06239417463541031  inv_L_scale:  [1.0, 1.0]
Epoch :  434  Time:  0.872  Rel. Train L2 Loss :  0.03973443102505472  Rel. Test L2 Loss :  0.04314415946602821  Test L2 Loss :  0.06270549520850181  inv_L_scale:  [1.0, 1.0]
Epoch :  435  Time:  0.871  Rel. Train L2 Loss :  0.039869267576270635  Rel. Test L2 Loss :  0.04289873093366623  Test L2 Loss :  0.06241942897439003  inv_L_scale:  [1.0, 1.0]
Epoch :  436  Time:  0.871  Rel. Train L2 Loss :  0.039851574020253286  Rel. Test L2 Loss :  0.04285723239183426  Test L2 Loss :  0.062346926033496855  inv_L_scale:  [1.0, 1.0]
Epoch :  437  Time:  0.871  Rel. Train L2 Loss :  0.03975677682293786  Rel. Test L2 Loss :  0.04279327347874642  Test L2 Loss :  0.062201038002967834  inv_L_scale:  [1.0, 1.0]
Epoch :  438  Time:  0.87  Rel. Train L2 Loss :  0.039644077122211456  Rel. Test L2 Loss :  0.04278904169797897  Test L2 Loss :  0.06220718622207642  inv_L_scale:  [1.0, 1.0]
Epoch :  439  Time:  0.871  Rel. Train L2 Loss :  0.0395714190767871  Rel. Test L2 Loss :  0.04279864966869354  Test L2 Loss :  0.062226907908916475  inv_L_scale:  [1.0, 1.0]
Epoch :  440  Time:  0.87  Rel. Train L2 Loss :  0.03964341499739223  Rel. Test L2 Loss :  0.04270401552319527  Test L2 Loss :  0.06212445095181465  inv_L_scale:  [1.0, 1.0]
Epoch :  441  Time:  0.871  Rel. Train L2 Loss :  0.03962061416771677  Rel. Test L2 Loss :  0.04269405543804169  Test L2 Loss :  0.06216325893998146  inv_L_scale:  [1.0, 1.0]
Epoch :  442  Time:  0.871  Rel. Train L2 Loss :  0.03971421894927819  Rel. Test L2 Loss :  0.04293589860200882  Test L2 Loss :  0.06241095378994942  inv_L_scale:  [1.0, 1.0]
Epoch :  443  Time:  0.871  Rel. Train L2 Loss :  0.03950712609622214  Rel. Test L2 Loss :  0.04266847595572472  Test L2 Loss :  0.062098380476236344  inv_L_scale:  [1.0, 1.0]
Epoch :  444  Time:  0.871  Rel. Train L2 Loss :  0.039533635841475595  Rel. Test L2 Loss :  0.042625596225261686  Test L2 Loss :  0.061964193880558016  inv_L_scale:  [1.0, 1.0]
Epoch :  445  Time:  0.87  Rel. Train L2 Loss :  0.039584083143207764  Rel. Test L2 Loss :  0.04275345429778099  Test L2 Loss :  0.062180650532245633  inv_L_scale:  [1.0, 1.0]
Epoch :  446  Time:  0.871  Rel. Train L2 Loss :  0.03945082607368628  Rel. Test L2 Loss :  0.04270661637187004  Test L2 Loss :  0.06216650992631912  inv_L_scale:  [1.0, 1.0]
Epoch :  447  Time:  0.871  Rel. Train L2 Loss :  0.03943459812137816  Rel. Test L2 Loss :  0.04282377898693085  Test L2 Loss :  0.06229285955429077  inv_L_scale:  [1.0, 1.0]
Epoch :  448  Time:  0.871  Rel. Train L2 Loss :  0.03953126874234941  Rel. Test L2 Loss :  0.04252223610877991  Test L2 Loss :  0.06185613185167313  inv_L_scale:  [1.0, 1.0]
Epoch :  449  Time:  0.87  Rel. Train L2 Loss :  0.03935810645421346  Rel. Test L2 Loss :  0.04282948419451713  Test L2 Loss :  0.062254538536071775  inv_L_scale:  [1.0, 1.0]
Epoch :  450  Time:  0.871  Rel. Train L2 Loss :  0.0393494409819444  Rel. Test L2 Loss :  0.04246022492647171  Test L2 Loss :  0.061784391105175016  inv_L_scale:  [1.0, 1.0]
Epoch :  451  Time:  0.87  Rel. Train L2 Loss :  0.03938091023100747  Rel. Test L2 Loss :  0.04267006680369377  Test L2 Loss :  0.06211789458990097  inv_L_scale:  [1.0, 1.0]
Epoch :  452  Time:  0.871  Rel. Train L2 Loss :  0.039353402372863555  Rel. Test L2 Loss :  0.04255966886878013  Test L2 Loss :  0.061903903484344484  inv_L_scale:  [1.0, 1.0]
Epoch :  453  Time:  0.87  Rel. Train L2 Loss :  0.03933481588959694  Rel. Test L2 Loss :  0.042497365027666094  Test L2 Loss :  0.06184765785932541  inv_L_scale:  [1.0, 1.0]
Epoch :  454  Time:  0.871  Rel. Train L2 Loss :  0.039303035918209286  Rel. Test L2 Loss :  0.04246382623910904  Test L2 Loss :  0.06178601384162903  inv_L_scale:  [1.0, 1.0]
Epoch :  455  Time:  0.871  Rel. Train L2 Loss :  0.039302694524327914  Rel. Test L2 Loss :  0.04265283331274986  Test L2 Loss :  0.061996044665575026  inv_L_scale:  [1.0, 1.0]
Epoch :  456  Time:  0.87  Rel. Train L2 Loss :  0.03914363412393464  Rel. Test L2 Loss :  0.04265776678919792  Test L2 Loss :  0.062024712562561035  inv_L_scale:  [1.0, 1.0]
Epoch :  457  Time:  0.871  Rel. Train L2 Loss :  0.03923360682196087  Rel. Test L2 Loss :  0.04263281673192978  Test L2 Loss :  0.061966915875673295  inv_L_scale:  [1.0, 1.0]
Epoch :  458  Time:  0.871  Rel. Train L2 Loss :  0.03914703254070547  Rel. Test L2 Loss :  0.042698955237865446  Test L2 Loss :  0.06208941966295242  inv_L_scale:  [1.0, 1.0]
Epoch :  459  Time:  0.87  Rel. Train L2 Loss :  0.039148692074749206  Rel. Test L2 Loss :  0.04276524126529693  Test L2 Loss :  0.06217577442526817  inv_L_scale:  [1.0, 1.0]
Epoch :  460  Time:  0.869  Rel. Train L2 Loss :  0.03914727417131265  Rel. Test L2 Loss :  0.04255116015672684  Test L2 Loss :  0.06190995961427689  inv_L_scale:  [1.0, 1.0]
Epoch :  461  Time:  0.869  Rel. Train L2 Loss :  0.03906597314609422  Rel. Test L2 Loss :  0.04246584683656693  Test L2 Loss :  0.06171828016638756  inv_L_scale:  [1.0, 1.0]
Epoch :  462  Time:  0.869  Rel. Train L2 Loss :  0.03905718235505952  Rel. Test L2 Loss :  0.04250130996108055  Test L2 Loss :  0.06181106612086296  inv_L_scale:  [1.0, 1.0]
Epoch :  463  Time:  0.869  Rel. Train L2 Loss :  0.039060209492842356  Rel. Test L2 Loss :  0.04254771336913109  Test L2 Loss :  0.06185440927743912  inv_L_scale:  [1.0, 1.0]
Epoch :  464  Time:  0.869  Rel. Train L2 Loss :  0.03902871592177285  Rel. Test L2 Loss :  0.042546753883361814  Test L2 Loss :  0.0618838831782341  inv_L_scale:  [1.0, 1.0]
Epoch :  465  Time:  0.869  Rel. Train L2 Loss :  0.03899385391010179  Rel. Test L2 Loss :  0.042457483410835266  Test L2 Loss :  0.06175480797886848  inv_L_scale:  [1.0, 1.0]
Epoch :  466  Time:  0.869  Rel. Train L2 Loss :  0.03898952378167046  Rel. Test L2 Loss :  0.04251312762498856  Test L2 Loss :  0.061826460808515546  inv_L_scale:  [1.0, 1.0]
Epoch :  467  Time:  0.869  Rel. Train L2 Loss :  0.03900650966498587  Rel. Test L2 Loss :  0.04258100748062134  Test L2 Loss :  0.06191231638193131  inv_L_scale:  [1.0, 1.0]
Epoch :  468  Time:  0.87  Rel. Train L2 Loss :  0.03898378200001187  Rel. Test L2 Loss :  0.04246705740690231  Test L2 Loss :  0.061739113628864285  inv_L_scale:  [1.0, 1.0]
Epoch :  469  Time:  0.87  Rel. Train L2 Loss :  0.038943584602740076  Rel. Test L2 Loss :  0.042455410808324816  Test L2 Loss :  0.06174401611089706  inv_L_scale:  [1.0, 1.0]
Epoch :  470  Time:  0.87  Rel. Train L2 Loss :  0.03892474383115768  Rel. Test L2 Loss :  0.04245001628994942  Test L2 Loss :  0.06173130422830582  inv_L_scale:  [1.0, 1.0]
Epoch :  471  Time:  0.869  Rel. Train L2 Loss :  0.03891699180006981  Rel. Test L2 Loss :  0.0424303936958313  Test L2 Loss :  0.0617099142074585  inv_L_scale:  [1.0, 1.0]
Epoch :  472  Time:  0.869  Rel. Train L2 Loss :  0.038916683147350944  Rel. Test L2 Loss :  0.04245811626315117  Test L2 Loss :  0.06174863517284393  inv_L_scale:  [1.0, 1.0]
Epoch :  473  Time:  0.87  Rel. Train L2 Loss :  0.03887905698683527  Rel. Test L2 Loss :  0.042486162781715395  Test L2 Loss :  0.06178291648626327  inv_L_scale:  [1.0, 1.0]
Epoch :  474  Time:  0.87  Rel. Train L2 Loss :  0.03887683673865265  Rel. Test L2 Loss :  0.042485264986753465  Test L2 Loss :  0.06179902583360672  inv_L_scale:  [1.0, 1.0]
Epoch :  475  Time:  0.869  Rel. Train L2 Loss :  0.0388523789246877  Rel. Test L2 Loss :  0.04238757610321045  Test L2 Loss :  0.06166298180818558  inv_L_scale:  [1.0, 1.0]
Epoch :  476  Time:  0.869  Rel. Train L2 Loss :  0.03884045453535186  Rel. Test L2 Loss :  0.04243224874138832  Test L2 Loss :  0.06172172039747238  inv_L_scale:  [1.0, 1.0]
Epoch :  477  Time:  0.869  Rel. Train L2 Loss :  0.03884904886285464  Rel. Test L2 Loss :  0.042448677271604535  Test L2 Loss :  0.061731252968311306  inv_L_scale:  [1.0, 1.0]
Epoch :  478  Time:  0.865  Rel. Train L2 Loss :  0.038809518184926776  Rel. Test L2 Loss :  0.04248726069927215  Test L2 Loss :  0.0617831252515316  inv_L_scale:  [1.0, 1.0]
Epoch :  479  Time:  0.864  Rel. Train L2 Loss :  0.03880476593971252  Rel. Test L2 Loss :  0.04242431506514549  Test L2 Loss :  0.061698150932788846  inv_L_scale:  [1.0, 1.0]
Epoch :  480  Time:  0.864  Rel. Train L2 Loss :  0.03879310139351421  Rel. Test L2 Loss :  0.042495407462120056  Test L2 Loss :  0.06178283780813217  inv_L_scale:  [1.0, 1.0]
Epoch :  481  Time:  0.864  Rel. Train L2 Loss :  0.03878379576736026  Rel. Test L2 Loss :  0.042447875291109084  Test L2 Loss :  0.061715572327375415  inv_L_scale:  [1.0, 1.0]
Epoch :  482  Time:  0.864  Rel. Train L2 Loss :  0.03877009732855691  Rel. Test L2 Loss :  0.042447911649942396  Test L2 Loss :  0.06171877384185791  inv_L_scale:  [1.0, 1.0]
Epoch :  483  Time:  0.864  Rel. Train L2 Loss :  0.03876162050498856  Rel. Test L2 Loss :  0.04243587970733643  Test L2 Loss :  0.06171793431043625  inv_L_scale:  [1.0, 1.0]
Epoch :  484  Time:  0.864  Rel. Train L2 Loss :  0.03876123158468141  Rel. Test L2 Loss :  0.04243922024965286  Test L2 Loss :  0.06172655314207077  inv_L_scale:  [1.0, 1.0]
Epoch :  485  Time:  0.865  Rel. Train L2 Loss :  0.03875498263372315  Rel. Test L2 Loss :  0.042473154664039614  Test L2 Loss :  0.06176577627658844  inv_L_scale:  [1.0, 1.0]
Epoch :  486  Time:  0.865  Rel. Train L2 Loss :  0.03874281090166834  Rel. Test L2 Loss :  0.04244699537754059  Test L2 Loss :  0.06173370704054833  inv_L_scale:  [1.0, 1.0]
Epoch :  487  Time:  0.864  Rel. Train L2 Loss :  0.03873351217971908  Rel. Test L2 Loss :  0.042419603317976  Test L2 Loss :  0.061679042875766754  inv_L_scale:  [1.0, 1.0]
Epoch :  488  Time:  0.864  Rel. Train L2 Loss :  0.038738841033644146  Rel. Test L2 Loss :  0.04246368855237961  Test L2 Loss :  0.06173897132277489  inv_L_scale:  [1.0, 1.0]
Epoch :  489  Time:  0.864  Rel. Train L2 Loss :  0.038717052704758115  Rel. Test L2 Loss :  0.04246900945901871  Test L2 Loss :  0.06174635723233223  inv_L_scale:  [1.0, 1.0]
Epoch :  490  Time:  0.864  Rel. Train L2 Loss :  0.03871798755394088  Rel. Test L2 Loss :  0.04241813436150551  Test L2 Loss :  0.061688110530376435  inv_L_scale:  [1.0, 1.0]
Epoch :  491  Time:  0.873  Rel. Train L2 Loss :  0.0387129881978035  Rel. Test L2 Loss :  0.04243910610675812  Test L2 Loss :  0.061715122908353806  inv_L_scale:  [1.0, 1.0]
Epoch :  492  Time:  0.868  Rel. Train L2 Loss :  0.03870914459228516  Rel. Test L2 Loss :  0.04242763102054596  Test L2 Loss :  0.06169837296009064  inv_L_scale:  [1.0, 1.0]
Epoch :  493  Time:  0.865  Rel. Train L2 Loss :  0.038702437414063345  Rel. Test L2 Loss :  0.04246737539768219  Test L2 Loss :  0.06175800174474716  inv_L_scale:  [1.0, 1.0]
Epoch :  494  Time:  0.864  Rel. Train L2 Loss :  0.03870096974902683  Rel. Test L2 Loss :  0.04243018940091133  Test L2 Loss :  0.06171283096075058  inv_L_scale:  [1.0, 1.0]
Epoch :  495  Time:  0.864  Rel. Train L2 Loss :  0.03870372411277559  Rel. Test L2 Loss :  0.04245988547801972  Test L2 Loss :  0.06174026593565941  inv_L_scale:  [1.0, 1.0]
Epoch :  496  Time:  0.865  Rel. Train L2 Loss :  0.0387016954852475  Rel. Test L2 Loss :  0.04242687344551086  Test L2 Loss :  0.061695209741592406  inv_L_scale:  [1.0, 1.0]
Epoch :  497  Time:  0.865  Rel. Train L2 Loss :  0.038697912312216226  Rel. Test L2 Loss :  0.04246216267347336  Test L2 Loss :  0.06175330460071564  inv_L_scale:  [1.0, 1.0]
Epoch :  498  Time:  0.865  Rel. Train L2 Loss :  0.03869796575771438  Rel. Test L2 Loss :  0.04244622066617012  Test L2 Loss :  0.06171659678220749  inv_L_scale:  [1.0, 1.0]
Epoch :  499  Time:  0.865  Rel. Train L2 Loss :  0.03870357144210074  Rel. Test L2 Loss :  0.04245008334517479  Test L2 Loss :  0.06171984925866127  inv_L_scale:  [1.0, 1.0]
