Casting to tensor
k_max: 8
geo_dims: [0, 1, 2, 3, 4, 5]
Ls: [2.0, 2.0, 5.0]
In PCNO_train, ndims =  3
Epoch :  0  Time:  14.24  Rel. Train L2 Loss :  0.273299595952034  Rel. Test L2 Loss :  0.16541220851846644  Test L2 Loss :  10.208620844660578  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  1  Time:  11.698  Rel. Train L2 Loss :  0.1243646445274353  Rel. Test L2 Loss :  0.12794999711148375  Test L2 Loss :  7.877742973533836  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  2  Time:  10.491  Rel. Train L2 Loss :  0.09153594744205475  Rel. Test L2 Loss :  0.1092192031241752  Test L2 Loss :  6.723966203294359  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  3  Time:  10.505  Rel. Train L2 Loss :  0.07592411142587661  Rel. Test L2 Loss :  0.10112055035324784  Test L2 Loss :  6.2160514625343115  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  4  Time:  10.512  Rel. Train L2 Loss :  0.06864442884922027  Rel. Test L2 Loss :  0.09678376204258687  Test L2 Loss :  5.945474160684122  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  5  Time:  10.548  Rel. Train L2 Loss :  0.06938890326023102  Rel. Test L2 Loss :  0.10991724063684274  Test L2 Loss :  6.747576361303931  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  6  Time:  10.544  Rel. Train L2 Loss :  0.0674496061205864  Rel. Test L2 Loss :  0.09157472580402821  Test L2 Loss :  5.624906041600683  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  7  Time:  10.573  Rel. Train L2 Loss :  0.057549809873104096  Rel. Test L2 Loss :  0.08700791189262459  Test L2 Loss :  5.344841415817673  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  8  Time:  10.578  Rel. Train L2 Loss :  0.0546401641368866  Rel. Test L2 Loss :  0.08749427236952223  Test L2 Loss :  5.373746889131564  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  9  Time:  10.58  Rel. Train L2 Loss :  0.05206709808111191  Rel. Test L2 Loss :  0.08888337848422763  Test L2 Loss :  5.456935934118323  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  10  Time:  10.566  Rel. Train L2 Loss :  0.05261754477024078  Rel. Test L2 Loss :  0.08743307182380745  Test L2 Loss :  5.375097017030458  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  11  Time:  10.573  Rel. Train L2 Loss :  0.052673694133758546  Rel. Test L2 Loss :  0.08624421529941731  Test L2 Loss :  5.297676223892349  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  12  Time:  10.565  Rel. Train L2 Loss :  0.05072066110372543  Rel. Test L2 Loss :  0.08295130085300755  Test L2 Loss :  5.0941913020503415  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  13  Time:  10.566  Rel. Train L2 Loss :  0.05078389835357666  Rel. Test L2 Loss :  0.09061674652872859  Test L2 Loss :  5.5604795851149005  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  14  Time:  10.543  Rel. Train L2 Loss :  0.04857136940956116  Rel. Test L2 Loss :  0.08017907540003459  Test L2 Loss :  4.927258860957515  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  15  Time:  10.535  Rel. Train L2 Loss :  0.04724791437387466  Rel. Test L2 Loss :  0.08140911014230402  Test L2 Loss :  4.999653257765211  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  16  Time:  10.553  Rel. Train L2 Loss :  0.046838983595371246  Rel. Test L2 Loss :  0.08026932112805478  Test L2 Loss :  4.932456111048793  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  17  Time:  10.527  Rel. Train L2 Loss :  0.04593532061576843  Rel. Test L2 Loss :  0.08023742351446066  Test L2 Loss :  4.926613163303685  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  18  Time:  10.537  Rel. Train L2 Loss :  0.04802121499180794  Rel. Test L2 Loss :  0.08098028586791442  Test L2 Loss :  4.971905545071438  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  19  Time:  10.542  Rel. Train L2 Loss :  0.04742113614082336  Rel. Test L2 Loss :  0.08263024285032942  Test L2 Loss :  5.070850217664564  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  20  Time:  10.551  Rel. Train L2 Loss :  0.047707152009010316  Rel. Test L2 Loss :  0.07971489912754781  Test L2 Loss :  4.889189728745469  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  21  Time:  10.555  Rel. Train L2 Loss :  0.049791071474552154  Rel. Test L2 Loss :  0.08504385722650064  Test L2 Loss :  5.216946404259484  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  22  Time:  10.537  Rel. Train L2 Loss :  0.04633027797937393  Rel. Test L2 Loss :  0.07911453107455829  Test L2 Loss :  4.859688269125448  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  23  Time:  10.609  Rel. Train L2 Loss :  0.044042690455913545  Rel. Test L2 Loss :  0.078081634936032  Test L2 Loss :  4.7974916062913495  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  24  Time:  10.63  Rel. Train L2 Loss :  0.04528116431832314  Rel. Test L2 Loss :  0.07831940403929702  Test L2 Loss :  4.808114782109991  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  25  Time:  10.65  Rel. Train L2 Loss :  0.045017928183078766  Rel. Test L2 Loss :  0.0762627857762414  Test L2 Loss :  4.687830847662848  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  26  Time:  10.723  Rel. Train L2 Loss :  0.04308518055081367  Rel. Test L2 Loss :  0.07628838865606634  Test L2 Loss :  4.685207315393396  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  27  Time:  10.729  Rel. Train L2 Loss :  0.0428609484732151  Rel. Test L2 Loss :  0.07507431184923327  Test L2 Loss :  4.610768000284831  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  28  Time:  10.616  Rel. Train L2 Loss :  0.042321014046669006  Rel. Test L2 Loss :  0.07632518942291672  Test L2 Loss :  4.687364887546849  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  29  Time:  10.554  Rel. Train L2 Loss :  0.04283280822634697  Rel. Test L2 Loss :  0.08054001266891891  Test L2 Loss :  4.941195101351352  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  30  Time:  10.529  Rel. Train L2 Loss :  0.04497457951307297  Rel. Test L2 Loss :  0.07968793957083074  Test L2 Loss :  4.892254700531831  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  31  Time:  10.522  Rel. Train L2 Loss :  0.044764560669660565  Rel. Test L2 Loss :  0.0755126999842154  Test L2 Loss :  4.637279029365058  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  32  Time:  10.505  Rel. Train L2 Loss :  0.042944119572639466  Rel. Test L2 Loss :  0.07646386365632753  Test L2 Loss :  4.695106334514446  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  33  Time:  10.51  Rel. Train L2 Loss :  0.04470592573285103  Rel. Test L2 Loss :  0.07599472757932302  Test L2 Loss :  4.669663214468741  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  34  Time:  10.503  Rel. Train L2 Loss :  0.04366472882032395  Rel. Test L2 Loss :  0.07786343468202127  Test L2 Loss :  4.784573907250756  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  35  Time:  10.527  Rel. Train L2 Loss :  0.0435473889708519  Rel. Test L2 Loss :  0.075221155140851  Test L2 Loss :  4.619012162492082  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  36  Time:  10.525  Rel. Train L2 Loss :  0.04267148235440254  Rel. Test L2 Loss :  0.07551220166790593  Test L2 Loss :  4.637397078780441  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  37  Time:  10.547  Rel. Train L2 Loss :  0.04407347822189331  Rel. Test L2 Loss :  0.07954802652737042  Test L2 Loss :  4.886264148059192  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  38  Time:  10.564  Rel. Train L2 Loss :  0.043479111075401304  Rel. Test L2 Loss :  0.07537604318008767  Test L2 Loss :  4.6274052009926185  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  39  Time:  10.589  Rel. Train L2 Loss :  0.04584891754388809  Rel. Test L2 Loss :  0.07634999784263405  Test L2 Loss :  4.688834697276622  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  40  Time:  10.622  Rel. Train L2 Loss :  0.0451469960808754  Rel. Test L2 Loss :  0.07705683428961951  Test L2 Loss :  4.733703235248187  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  41  Time:  10.642  Rel. Train L2 Loss :  0.04419097307324409  Rel. Test L2 Loss :  0.07555020446175928  Test L2 Loss :  4.643605653230135  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  42  Time:  10.667  Rel. Train L2 Loss :  0.04458840847015381  Rel. Test L2 Loss :  0.0795678668193989  Test L2 Loss :  4.8844938192281635  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  43  Time:  10.649  Rel. Train L2 Loss :  0.04607105833292007  Rel. Test L2 Loss :  0.07739894964673498  Test L2 Loss :  4.748796188079559  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  44  Time:  10.594  Rel. Train L2 Loss :  0.04352956187725067  Rel. Test L2 Loss :  0.07698763490797163  Test L2 Loss :  4.728594737009959  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  45  Time:  10.549  Rel. Train L2 Loss :  0.04253384220600128  Rel. Test L2 Loss :  0.0751195157970394  Test L2 Loss :  4.6104154157208965  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  46  Time:  10.504  Rel. Train L2 Loss :  0.042899697750806806  Rel. Test L2 Loss :  0.07445940455874882  Test L2 Loss :  4.571699537672438  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  47  Time:  10.551  Rel. Train L2 Loss :  0.043730770617723465  Rel. Test L2 Loss :  0.07553394742914148  Test L2 Loss :  4.635655497645472  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  48  Time:  10.529  Rel. Train L2 Loss :  0.0450309527516365  Rel. Test L2 Loss :  0.07509768492466695  Test L2 Loss :  4.605138658403276  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  49  Time:  10.558  Rel. Train L2 Loss :  0.04470740151405334  Rel. Test L2 Loss :  0.07740767259855529  Test L2 Loss :  4.7550359846235395  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  50  Time:  10.537  Rel. Train L2 Loss :  0.04379529762268066  Rel. Test L2 Loss :  0.07585370835957227  Test L2 Loss :  4.656256203178887  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  51  Time:  10.556  Rel. Train L2 Loss :  0.044001764953136444  Rel. Test L2 Loss :  0.07399372501416249  Test L2 Loss :  4.544318860715574  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  52  Time:  10.592  Rel. Train L2 Loss :  0.0441206605732441  Rel. Test L2 Loss :  0.07441756048718014  Test L2 Loss :  4.570214331687033  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  53  Time:  10.604  Rel. Train L2 Loss :  0.04335804373025894  Rel. Test L2 Loss :  0.07942313278043592  Test L2 Loss :  4.88163490982743  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  54  Time:  10.6  Rel. Train L2 Loss :  0.045352632731199265  Rel. Test L2 Loss :  0.07790282663998303  Test L2 Loss :  4.780795483975797  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  55  Time:  10.612  Rel. Train L2 Loss :  0.044120288372039795  Rel. Test L2 Loss :  0.0778663630958076  Test L2 Loss :  4.772922378402573  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  56  Time:  10.626  Rel. Train L2 Loss :  0.04611562985181809  Rel. Test L2 Loss :  0.07709962344384408  Test L2 Loss :  4.736613849261859  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  57  Time:  10.614  Rel. Train L2 Loss :  0.045372258961200715  Rel. Test L2 Loss :  0.07654245909269866  Test L2 Loss :  4.6938543749285175  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  58  Time:  10.545  Rel. Train L2 Loss :  0.04283455118536949  Rel. Test L2 Loss :  0.07361312411926887  Test L2 Loss :  4.517706587507918  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  59  Time:  10.536  Rel. Train L2 Loss :  0.044571120470762254  Rel. Test L2 Loss :  0.07446416165377642  Test L2 Loss :  4.57045147870038  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  60  Time:  10.529  Rel. Train L2 Loss :  0.047239721447229384  Rel. Test L2 Loss :  0.07354705935125952  Test L2 Loss :  4.515686963055585  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  61  Time:  10.523  Rel. Train L2 Loss :  0.04349196991324425  Rel. Test L2 Loss :  0.07325654658111366  Test L2 Loss :  4.492583661466031  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  62  Time:  10.526  Rel. Train L2 Loss :  0.04312878596782684  Rel. Test L2 Loss :  0.07593383338000323  Test L2 Loss :  4.662182094814541  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  63  Time:  10.533  Rel. Train L2 Loss :  0.04294544991850853  Rel. Test L2 Loss :  0.0742166863905417  Test L2 Loss :  4.555559347341727  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  64  Time:  10.537  Rel. Train L2 Loss :  0.04349094957113266  Rel. Test L2 Loss :  0.07423623429762351  Test L2 Loss :  4.557774707003757  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  65  Time:  10.558  Rel. Train L2 Loss :  0.04246490260958671  Rel. Test L2 Loss :  0.07337078720599681  Test L2 Loss :  4.501322497118701  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  66  Time:  10.578  Rel. Train L2 Loss :  0.0440511366724968  Rel. Test L2 Loss :  0.0748417637906633  Test L2 Loss :  4.594361571578292  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  67  Time:  10.603  Rel. Train L2 Loss :  0.04369583427906036  Rel. Test L2 Loss :  0.07582712388253426  Test L2 Loss :  4.657156265533723  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  68  Time:  10.585  Rel. Train L2 Loss :  0.04315692803263664  Rel. Test L2 Loss :  0.07570136909012322  Test L2 Loss :  4.641879262150945  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  69  Time:  10.602  Rel. Train L2 Loss :  0.042759926438331604  Rel. Test L2 Loss :  0.07247470762278582  Test L2 Loss :  4.4465665044011295  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  70  Time:  10.598  Rel. Train L2 Loss :  0.04186828222870827  Rel. Test L2 Loss :  0.07623816046628866  Test L2 Loss :  4.67931553264996  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  71  Time:  10.611  Rel. Train L2 Loss :  0.04383867689967155  Rel. Test L2 Loss :  0.0744327379239572  Test L2 Loss :  4.5711805841944235  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  72  Time:  10.576  Rel. Train L2 Loss :  0.0433357997238636  Rel. Test L2 Loss :  0.07463718051308985  Test L2 Loss :  4.579842868151966  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  73  Time:  10.53  Rel. Train L2 Loss :  0.044419249355793  Rel. Test L2 Loss :  0.08308065850455482  Test L2 Loss :  5.093239758465741  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  74  Time:  10.524  Rel. Train L2 Loss :  0.047011502981185914  Rel. Test L2 Loss :  0.07311762184710116  Test L2 Loss :  4.487699027534004  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  75  Time:  10.523  Rel. Train L2 Loss :  0.0431998972594738  Rel. Test L2 Loss :  0.07391231392954921  Test L2 Loss :  4.537255038012256  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  76  Time:  10.511  Rel. Train L2 Loss :  0.04458104342222214  Rel. Test L2 Loss :  0.07445658783654908  Test L2 Loss :  4.56891071903813  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  77  Time:  10.512  Rel. Train L2 Loss :  0.044608059763908386  Rel. Test L2 Loss :  0.07352681901003863  Test L2 Loss :  4.511749112928236  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  78  Time:  10.521  Rel. Train L2 Loss :  0.0438955140709877  Rel. Test L2 Loss :  0.07392975124152931  Test L2 Loss :  4.538591161504522  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  79  Time:  10.537  Rel. Train L2 Loss :  0.0434989800453186  Rel. Test L2 Loss :  0.07516598808872807  Test L2 Loss :  4.615055393528294  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  80  Time:  10.567  Rel. Train L2 Loss :  0.04417121189832687  Rel. Test L2 Loss :  0.07370050882433986  Test L2 Loss :  4.525498072306315  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  81  Time:  10.603  Rel. Train L2 Loss :  0.041936668902635574  Rel. Test L2 Loss :  0.07229221806869851  Test L2 Loss :  4.43398853680035  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  82  Time:  10.601  Rel. Train L2 Loss :  0.042181692659854886  Rel. Test L2 Loss :  0.07624768727534526  Test L2 Loss :  4.678492039173573  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  83  Time:  10.616  Rel. Train L2 Loss :  0.04268719446659088  Rel. Test L2 Loss :  0.07636464930869438  Test L2 Loss :  4.686149322234832  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  84  Time:  10.629  Rel. Train L2 Loss :  0.04338846656680107  Rel. Test L2 Loss :  0.07493703644554894  Test L2 Loss :  4.5975979985417545  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  85  Time:  10.608  Rel. Train L2 Loss :  0.046438387036323546  Rel. Test L2 Loss :  0.07757464185491339  Test L2 Loss :  4.7620646674353795  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  86  Time:  10.564  Rel. Train L2 Loss :  0.04524929940700531  Rel. Test L2 Loss :  0.07303576480160963  Test L2 Loss :  4.482958475748698  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  87  Time:  10.544  Rel. Train L2 Loss :  0.04413836947083473  Rel. Test L2 Loss :  0.07568219760516742  Test L2 Loss :  4.6408658242440435  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  88  Time:  10.528  Rel. Train L2 Loss :  0.04361429446935654  Rel. Test L2 Loss :  0.07628638491974221  Test L2 Loss :  4.68373357068311  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  89  Time:  10.537  Rel. Train L2 Loss :  0.04248871272802353  Rel. Test L2 Loss :  0.07403421214034965  Test L2 Loss :  4.542639723769179  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  90  Time:  10.534  Rel. Train L2 Loss :  0.04320532876253128  Rel. Test L2 Loss :  0.07483354452494029  Test L2 Loss :  4.5939494639903575  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  91  Time:  10.546  Rel. Train L2 Loss :  0.0427479156255722  Rel. Test L2 Loss :  0.07477110302126086  Test L2 Loss :  4.58196143416671  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  92  Time:  10.546  Rel. Train L2 Loss :  0.04176309749484062  Rel. Test L2 Loss :  0.07192559553696229  Test L2 Loss :  4.414089615280564  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  93  Time:  10.559  Rel. Train L2 Loss :  0.04138337463140487  Rel. Test L2 Loss :  0.07275310239276371  Test L2 Loss :  4.464156623359199  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  94  Time:  10.569  Rel. Train L2 Loss :  0.040762790322303774  Rel. Test L2 Loss :  0.07329081415056109  Test L2 Loss :  4.498389304221213  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  95  Time:  10.619  Rel. Train L2 Loss :  0.04074107718467712  Rel. Test L2 Loss :  0.07518852884705002  Test L2 Loss :  4.619435370505393  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  96  Time:  10.612  Rel. Train L2 Loss :  0.0413099073767662  Rel. Test L2 Loss :  0.07420103641243668  Test L2 Loss :  4.554699476774748  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  97  Time:  10.666  Rel. Train L2 Loss :  0.0412483052611351  Rel. Test L2 Loss :  0.07663889054779534  Test L2 Loss :  4.7053917549751905  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  98  Time:  10.672  Rel. Train L2 Loss :  0.04397725328803062  Rel. Test L2 Loss :  0.0844675189739949  Test L2 Loss :  5.177773071838929  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  99  Time:  10.626  Rel. Train L2 Loss :  0.04287535238265991  Rel. Test L2 Loss :  0.07424764080090565  Test L2 Loss :  4.560908119957726  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  100  Time:  10.634  Rel. Train L2 Loss :  0.041445252269506454  Rel. Test L2 Loss :  0.07416248670569411  Test L2 Loss :  4.547842799006282  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  101  Time:  10.59  Rel. Train L2 Loss :  0.04101058578491211  Rel. Test L2 Loss :  0.0749089309761116  Test L2 Loss :  4.594668757808101  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  102  Time:  10.571  Rel. Train L2 Loss :  0.041638264268636704  Rel. Test L2 Loss :  0.07120603322982788  Test L2 Loss :  4.370934735547315  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  103  Time:  10.546  Rel. Train L2 Loss :  0.0410347353219986  Rel. Test L2 Loss :  0.07528703975247907  Test L2 Loss :  4.619251148120777  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  104  Time:  10.536  Rel. Train L2 Loss :  0.03965134760737419  Rel. Test L2 Loss :  0.07214765344654117  Test L2 Loss :  4.429254428760426  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  105  Time:  10.548  Rel. Train L2 Loss :  0.040318373769521715  Rel. Test L2 Loss :  0.07319210778485548  Test L2 Loss :  4.490941984159452  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  106  Time:  10.543  Rel. Train L2 Loss :  0.04029590314626694  Rel. Test L2 Loss :  0.07297157221012288  Test L2 Loss :  4.4794052742623  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  107  Time:  10.538  Rel. Train L2 Loss :  0.04006812047958374  Rel. Test L2 Loss :  0.07720911690780709  Test L2 Loss :  4.737491607666016  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  108  Time:  10.551  Rel. Train L2 Loss :  0.040832826048135755  Rel. Test L2 Loss :  0.07170218846819422  Test L2 Loss :  4.402509448764561  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  109  Time:  10.585  Rel. Train L2 Loss :  0.040143856287002566  Rel. Test L2 Loss :  0.07901902268598746  Test L2 Loss :  4.8503254383533925  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  110  Time:  10.584  Rel. Train L2 Loss :  0.041403885990381244  Rel. Test L2 Loss :  0.07307759518021936  Test L2 Loss :  4.486755577293602  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  111  Time:  10.59  Rel. Train L2 Loss :  0.03988004812598228  Rel. Test L2 Loss :  0.0713373500484604  Test L2 Loss :  4.377737938820779  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  112  Time:  10.585  Rel. Train L2 Loss :  0.03937554478645325  Rel. Test L2 Loss :  0.07204992384523959  Test L2 Loss :  4.420574583448805  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  113  Time:  10.592  Rel. Train L2 Loss :  0.04008898386359215  Rel. Test L2 Loss :  0.07230946582716864  Test L2 Loss :  4.435565226786846  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  114  Time:  10.593  Rel. Train L2 Loss :  0.03939507883787155  Rel. Test L2 Loss :  0.0714506560617739  Test L2 Loss :  4.384101420909435  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  115  Time:  10.597  Rel. Train L2 Loss :  0.03934908628463745  Rel. Test L2 Loss :  0.07093150282765294  Test L2 Loss :  4.3550664025384025  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  116  Time:  10.605  Rel. Train L2 Loss :  0.04003141534328461  Rel. Test L2 Loss :  0.0714024302658734  Test L2 Loss :  4.381774489944045  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  117  Time:  10.593  Rel. Train L2 Loss :  0.038357733994722365  Rel. Test L2 Loss :  0.07160967615273622  Test L2 Loss :  4.394935745376724  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  118  Time:  10.599  Rel. Train L2 Loss :  0.03813036769628525  Rel. Test L2 Loss :  0.07090050626445461  Test L2 Loss :  4.351072809717676  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  119  Time:  10.576  Rel. Train L2 Loss :  0.03739846283197403  Rel. Test L2 Loss :  0.07652940648096102  Test L2 Loss :  4.699797948201497  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  120  Time:  10.549  Rel. Train L2 Loss :  0.03906075203418732  Rel. Test L2 Loss :  0.06993894023938221  Test L2 Loss :  4.2899481283651815  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  121  Time:  10.637  Rel. Train L2 Loss :  0.03845183002948761  Rel. Test L2 Loss :  0.07228440663836024  Test L2 Loss :  4.434911315505569  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  122  Time:  10.618  Rel. Train L2 Loss :  0.03805115929245949  Rel. Test L2 Loss :  0.07277025671692582  Test L2 Loss :  4.467879802257091  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  123  Time:  10.622  Rel. Train L2 Loss :  0.03794744294881821  Rel. Test L2 Loss :  0.07169434347668209  Test L2 Loss :  4.399291837537611  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  124  Time:  10.649  Rel. Train L2 Loss :  0.03789566466212273  Rel. Test L2 Loss :  0.0713912608387234  Test L2 Loss :  4.383738096769865  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  125  Time:  10.654  Rel. Train L2 Loss :  0.03743858781456948  Rel. Test L2 Loss :  0.07427252144426913  Test L2 Loss :  4.569101728834547  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  126  Time:  10.6  Rel. Train L2 Loss :  0.03774270272254944  Rel. Test L2 Loss :  0.07159850538313926  Test L2 Loss :  4.394042985933321  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  127  Time:  10.597  Rel. Train L2 Loss :  0.03730982914566994  Rel. Test L2 Loss :  0.07112489546741452  Test L2 Loss :  4.366183014603348  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  128  Time:  10.6  Rel. Train L2 Loss :  0.0376190827190876  Rel. Test L2 Loss :  0.07113368231970985  Test L2 Loss :  4.362863179799673  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  129  Time:  10.584  Rel. Train L2 Loss :  0.036608429044485094  Rel. Test L2 Loss :  0.07063175858678045  Test L2 Loss :  4.336060360745266  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  130  Time:  10.583  Rel. Train L2 Loss :  0.03666380567848682  Rel. Test L2 Loss :  0.06984389177313796  Test L2 Loss :  4.285476736120276  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  131  Time:  10.577  Rel. Train L2 Loss :  0.037463811725378035  Rel. Test L2 Loss :  0.07111582643276937  Test L2 Loss :  4.367484273137273  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  132  Time:  10.596  Rel. Train L2 Loss :  0.03803402426838875  Rel. Test L2 Loss :  0.07185141916747566  Test L2 Loss :  4.413769335360141  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  133  Time:  10.554  Rel. Train L2 Loss :  0.03738674205541611  Rel. Test L2 Loss :  0.07102777184666814  Test L2 Loss :  4.359449661529816  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  134  Time:  10.566  Rel. Train L2 Loss :  0.03709272694587708  Rel. Test L2 Loss :  0.07019528370719773  Test L2 Loss :  4.309430302800359  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  135  Time:  10.582  Rel. Train L2 Loss :  0.03677343863248825  Rel. Test L2 Loss :  0.07231241088729722  Test L2 Loss :  4.435768986607457  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  136  Time:  10.583  Rel. Train L2 Loss :  0.03642031592130661  Rel. Test L2 Loss :  0.07119317419894107  Test L2 Loss :  4.368306735614398  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  137  Time:  10.585  Rel. Train L2 Loss :  0.03679547145962715  Rel. Test L2 Loss :  0.07078749397853473  Test L2 Loss :  4.346816432368648  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  138  Time:  10.593  Rel. Train L2 Loss :  0.035653655380010606  Rel. Test L2 Loss :  0.07180121406778558  Test L2 Loss :  4.4079265250816  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  139  Time:  10.585  Rel. Train L2 Loss :  0.03710363650321961  Rel. Test L2 Loss :  0.07102770284489468  Test L2 Loss :  4.35473514247585  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  140  Time:  10.584  Rel. Train L2 Loss :  0.035966116815805436  Rel. Test L2 Loss :  0.07113671678680557  Test L2 Loss :  4.368468860248187  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  141  Time:  10.563  Rel. Train L2 Loss :  0.03561583524942398  Rel. Test L2 Loss :  0.06913443164782482  Test L2 Loss :  4.241203737688494  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  142  Time:  10.563  Rel. Train L2 Loss :  0.03607941091060638  Rel. Test L2 Loss :  0.0703480931015702  Test L2 Loss :  4.313129734348607  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  143  Time:  10.581  Rel. Train L2 Loss :  0.035841681361198426  Rel. Test L2 Loss :  0.07214280587058884  Test L2 Loss :  4.427217311687298  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  144  Time:  10.575  Rel. Train L2 Loss :  0.036796348333358764  Rel. Test L2 Loss :  0.07702540250511856  Test L2 Loss :  4.724386868176159  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  145  Time:  10.582  Rel. Train L2 Loss :  0.036471471190452576  Rel. Test L2 Loss :  0.07258092336826497  Test L2 Loss :  4.461342528059676  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  146  Time:  10.57  Rel. Train L2 Loss :  0.036570775151252746  Rel. Test L2 Loss :  0.07136439498480376  Test L2 Loss :  4.378557050550306  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  147  Time:  10.57  Rel. Train L2 Loss :  0.03601701965928078  Rel. Test L2 Loss :  0.07218960679329194  Test L2 Loss :  4.426806097632056  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  148  Time:  10.576  Rel. Train L2 Loss :  0.03652763366699219  Rel. Test L2 Loss :  0.07176341129852845  Test L2 Loss :  4.405785964415954  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  149  Time:  10.566  Rel. Train L2 Loss :  0.034857356160879135  Rel. Test L2 Loss :  0.07013891623900817  Test L2 Loss :  4.3037323307346655  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  150  Time:  10.547  Rel. Train L2 Loss :  0.03441550061106682  Rel. Test L2 Loss :  0.0717207808215339  Test L2 Loss :  4.396558211730407  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  151  Time:  10.611  Rel. Train L2 Loss :  0.03518676197528839  Rel. Test L2 Loss :  0.0711823626681491  Test L2 Loss :  4.370921418473527  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  152  Time:  10.586  Rel. Train L2 Loss :  0.03406414133310318  Rel. Test L2 Loss :  0.07039581118403254  Test L2 Loss :  4.324082778380798  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  153  Time:  10.575  Rel. Train L2 Loss :  0.03423718959093094  Rel. Test L2 Loss :  0.06993406608298018  Test L2 Loss :  4.294185689977698  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  154  Time:  10.59  Rel. Train L2 Loss :  0.03430145201086998  Rel. Test L2 Loss :  0.07054026626251839  Test L2 Loss :  4.329263085717553  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  155  Time:  10.58  Rel. Train L2 Loss :  0.034291281282901764  Rel. Test L2 Loss :  0.07032327984904384  Test L2 Loss :  4.314388395429732  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  156  Time:  10.573  Rel. Train L2 Loss :  0.03480804693698883  Rel. Test L2 Loss :  0.07035497206825393  Test L2 Loss :  4.319066571759748  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  157  Time:  10.575  Rel. Train L2 Loss :  0.03482982477545738  Rel. Test L2 Loss :  0.07241168215468123  Test L2 Loss :  4.44363970369906  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  158  Time:  10.589  Rel. Train L2 Loss :  0.034501252979040144  Rel. Test L2 Loss :  0.07132546617104127  Test L2 Loss :  4.378140337832339  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  159  Time:  10.58  Rel. Train L2 Loss :  0.03362441152334213  Rel. Test L2 Loss :  0.06932050660923794  Test L2 Loss :  4.254134977186048  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  160  Time:  10.585  Rel. Train L2 Loss :  0.03330160772800445  Rel. Test L2 Loss :  0.07013290019722672  Test L2 Loss :  4.302407565417591  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  161  Time:  10.574  Rel. Train L2 Loss :  0.03512401576340198  Rel. Test L2 Loss :  0.07261118910334131  Test L2 Loss :  4.45283604527379  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  162  Time:  10.589  Rel. Train L2 Loss :  0.03366641440987587  Rel. Test L2 Loss :  0.07072903363554327  Test L2 Loss :  4.337153151228621  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  163  Time:  10.583  Rel. Train L2 Loss :  0.033710639089345934  Rel. Test L2 Loss :  0.07044447273821444  Test L2 Loss :  4.324859790973835  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  164  Time:  10.571  Rel. Train L2 Loss :  0.035796134650707245  Rel. Test L2 Loss :  0.06985826401023178  Test L2 Loss :  4.285806965183568  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  165  Time:  10.588  Rel. Train L2 Loss :  0.034890755653381345  Rel. Test L2 Loss :  0.0714983548130001  Test L2 Loss :  4.385119189013232  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  166  Time:  10.563  Rel. Train L2 Loss :  0.033447724759578704  Rel. Test L2 Loss :  0.07006548492758123  Test L2 Loss :  4.298145655039194  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  167  Time:  10.577  Rel. Train L2 Loss :  0.03277121371030808  Rel. Test L2 Loss :  0.07022288817543167  Test L2 Loss :  4.310438431061066  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  168  Time:  10.583  Rel. Train L2 Loss :  0.03291248805820942  Rel. Test L2 Loss :  0.0706165572544476  Test L2 Loss :  4.333759806177637  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  169  Time:  10.587  Rel. Train L2 Loss :  0.03314620468020439  Rel. Test L2 Loss :  0.07015803160968127  Test L2 Loss :  4.303547936516839  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  170  Time:  10.587  Rel. Train L2 Loss :  0.03304098266363144  Rel. Test L2 Loss :  0.07059148974246807  Test L2 Loss :  4.335062233177391  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  171  Time:  10.56  Rel. Train L2 Loss :  0.032664579451084134  Rel. Test L2 Loss :  0.07049637495934426  Test L2 Loss :  4.324180328094207  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  172  Time:  10.565  Rel. Train L2 Loss :  0.03349487775564194  Rel. Test L2 Loss :  0.072045342610763  Test L2 Loss :  4.421550407066001  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  173  Time:  10.56  Rel. Train L2 Loss :  0.03332640612125397  Rel. Test L2 Loss :  0.06988858263771813  Test L2 Loss :  4.291108088450389  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  174  Time:  10.526  Rel. Train L2 Loss :  0.03215124887228012  Rel. Test L2 Loss :  0.07015352098791448  Test L2 Loss :  4.305254188743797  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  175  Time:  10.602  Rel. Train L2 Loss :  0.03184101223945618  Rel. Test L2 Loss :  0.07216575204789101  Test L2 Loss :  4.431153580949113  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  176  Time:  10.587  Rel. Train L2 Loss :  0.03254797852039337  Rel. Test L2 Loss :  0.0733791750830573  Test L2 Loss :  4.504262013478322  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  177  Time:  10.566  Rel. Train L2 Loss :  0.03275357304513454  Rel. Test L2 Loss :  0.06961990449879621  Test L2 Loss :  4.273227399533933  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  178  Time:  10.556  Rel. Train L2 Loss :  0.031913439869880676  Rel. Test L2 Loss :  0.07062119836205835  Test L2 Loss :  4.332205042108759  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  179  Time:  10.557  Rel. Train L2 Loss :  0.03268789237737656  Rel. Test L2 Loss :  0.07081268204225076  Test L2 Loss :  4.344348615354246  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  180  Time:  10.584  Rel. Train L2 Loss :  0.032762095153331755  Rel. Test L2 Loss :  0.06987168230451979  Test L2 Loss :  4.288631800058726  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  181  Time:  10.575  Rel. Train L2 Loss :  0.031435168415307996  Rel. Test L2 Loss :  0.0695877738364108  Test L2 Loss :  4.269893285390493  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  182  Time:  10.564  Rel. Train L2 Loss :  0.03122116619348526  Rel. Test L2 Loss :  0.0709660697627712  Test L2 Loss :  4.3555326032208965  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  183  Time:  10.567  Rel. Train L2 Loss :  0.030918165504932402  Rel. Test L2 Loss :  0.06944498178121206  Test L2 Loss :  4.262215210510804  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  184  Time:  10.571  Rel. Train L2 Loss :  0.03109396994113922  Rel. Test L2 Loss :  0.06947642699018255  Test L2 Loss :  4.265030628926045  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  185  Time:  10.555  Rel. Train L2 Loss :  0.031989558428525924  Rel. Test L2 Loss :  0.06875825035679448  Test L2 Loss :  4.2183481164880705  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  186  Time:  10.564  Rel. Train L2 Loss :  0.032036963611841204  Rel. Test L2 Loss :  0.07070217019802816  Test L2 Loss :  4.337742934355864  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  187  Time:  10.552  Rel. Train L2 Loss :  0.032176006212830545  Rel. Test L2 Loss :  0.07034022018716142  Test L2 Loss :  4.31597376299334  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  188  Time:  10.589  Rel. Train L2 Loss :  0.03134027582406998  Rel. Test L2 Loss :  0.06882050391790029  Test L2 Loss :  4.224800694096196  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  189  Time:  10.587  Rel. Train L2 Loss :  0.03109144851565361  Rel. Test L2 Loss :  0.06933032365532608  Test L2 Loss :  4.256371970649238  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  190  Time:  10.573  Rel. Train L2 Loss :  0.030568562597036362  Rel. Test L2 Loss :  0.06964769556715682  Test L2 Loss :  4.27476692199707  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  191  Time:  10.56  Rel. Train L2 Loss :  0.030620752096176148  Rel. Test L2 Loss :  0.06871552778793885  Test L2 Loss :  4.2163831865465315  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  192  Time:  10.556  Rel. Train L2 Loss :  0.03007588320970535  Rel. Test L2 Loss :  0.06963461154216044  Test L2 Loss :  4.273742967897707  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  193  Time:  10.581  Rel. Train L2 Loss :  0.031169121012091638  Rel. Test L2 Loss :  0.06948899309914391  Test L2 Loss :  4.263645687618771  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  194  Time:  10.585  Rel. Train L2 Loss :  0.029974120646715164  Rel. Test L2 Loss :  0.06967495851688557  Test L2 Loss :  4.277006149291992  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  195  Time:  10.575  Rel. Train L2 Loss :  0.02978196993470192  Rel. Test L2 Loss :  0.06974529763599774  Test L2 Loss :  4.280571327553139  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  196  Time:  10.567  Rel. Train L2 Loss :  0.0300768583714962  Rel. Test L2 Loss :  0.07520077115780599  Test L2 Loss :  4.618903804469753  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  197  Time:  10.56  Rel. Train L2 Loss :  0.03026127605140209  Rel. Test L2 Loss :  0.0691241812598598  Test L2 Loss :  4.244321341987129  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  198  Time:  10.554  Rel. Train L2 Loss :  0.030108443692326545  Rel. Test L2 Loss :  0.0699784492587184  Test L2 Loss :  4.294187889442788  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  199  Time:  10.597  Rel. Train L2 Loss :  0.02979440777003765  Rel. Test L2 Loss :  0.06965725566889788  Test L2 Loss :  4.274033228556315  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  200  Time:  10.608  Rel. Train L2 Loss :  0.030306002289056777  Rel. Test L2 Loss :  0.07187312009098294  Test L2 Loss :  4.412872022336668  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  201  Time:  10.622  Rel. Train L2 Loss :  0.030332364082336426  Rel. Test L2 Loss :  0.07055948607556455  Test L2 Loss :  4.325454316697679  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  202  Time:  10.611  Rel. Train L2 Loss :  0.029911714643239974  Rel. Test L2 Loss :  0.07169906942694036  Test L2 Loss :  4.401224909601985  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  203  Time:  10.585  Rel. Train L2 Loss :  0.02977192521095276  Rel. Test L2 Loss :  0.06984736387794083  Test L2 Loss :  4.287226616799295  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  204  Time:  10.587  Rel. Train L2 Loss :  0.02947496283054352  Rel. Test L2 Loss :  0.07070069887616613  Test L2 Loss :  4.338017712842237  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  205  Time:  10.583  Rel. Train L2 Loss :  0.028572987973690032  Rel. Test L2 Loss :  0.07028754203169195  Test L2 Loss :  4.313884202424471  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  206  Time:  10.591  Rel. Train L2 Loss :  0.029339997738599778  Rel. Test L2 Loss :  0.06901954423199903  Test L2 Loss :  4.237178407273851  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  207  Time:  10.586  Rel. Train L2 Loss :  0.029378902941942214  Rel. Test L2 Loss :  0.06978217008951548  Test L2 Loss :  4.281932452777484  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  208  Time:  10.555  Rel. Train L2 Loss :  0.02907604095339775  Rel. Test L2 Loss :  0.06967059234241108  Test L2 Loss :  4.2760756037256735  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  209  Time:  10.558  Rel. Train L2 Loss :  0.027844267427921295  Rel. Test L2 Loss :  0.06844269772907635  Test L2 Loss :  4.19934843252371  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  210  Time:  10.569  Rel. Train L2 Loss :  0.0283876873254776  Rel. Test L2 Loss :  0.06865945538958988  Test L2 Loss :  4.213263520249376  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  211  Time:  10.557  Rel. Train L2 Loss :  0.029087710201740266  Rel. Test L2 Loss :  0.07112945683367618  Test L2 Loss :  4.363546904142912  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  212  Time:  10.553  Rel. Train L2 Loss :  0.028909712076187134  Rel. Test L2 Loss :  0.06843525869352324  Test L2 Loss :  4.1985440125336515  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  213  Time:  10.557  Rel. Train L2 Loss :  0.0279559123814106  Rel. Test L2 Loss :  0.06974339538866335  Test L2 Loss :  4.281507715448603  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  214  Time:  10.575  Rel. Train L2 Loss :  0.02956708814203739  Rel. Test L2 Loss :  0.06978346743025221  Test L2 Loss :  4.282358238288948  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  215  Time:  10.578  Rel. Train L2 Loss :  0.029282084107398985  Rel. Test L2 Loss :  0.07088038862288536  Test L2 Loss :  4.347301448787655  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  216  Time:  10.564  Rel. Train L2 Loss :  0.028935388654470443  Rel. Test L2 Loss :  0.07050462778624114  Test L2 Loss :  4.322520797317092  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  217  Time:  10.581  Rel. Train L2 Loss :  0.027530387580394746  Rel. Test L2 Loss :  0.07036351244728845  Test L2 Loss :  4.3207504684860645  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  218  Time:  10.586  Rel. Train L2 Loss :  0.027712314426898955  Rel. Test L2 Loss :  0.06877046179127048  Test L2 Loss :  4.221748970650338  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  219  Time:  10.595  Rel. Train L2 Loss :  0.027990916326642037  Rel. Test L2 Loss :  0.06902536320256757  Test L2 Loss :  4.238099845680031  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  220  Time:  10.603  Rel. Train L2 Loss :  0.028128892242908477  Rel. Test L2 Loss :  0.0691572835853508  Test L2 Loss :  4.244765908868463  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  221  Time:  10.589  Rel. Train L2 Loss :  0.027141459316015245  Rel. Test L2 Loss :  0.06889219165922285  Test L2 Loss :  4.227243234445383  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  222  Time:  10.576  Rel. Train L2 Loss :  0.026800094410777093  Rel. Test L2 Loss :  0.06908231812554437  Test L2 Loss :  4.239356049546251  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  223  Time:  10.583  Rel. Train L2 Loss :  0.027376590937376023  Rel. Test L2 Loss :  0.07047605407130611  Test L2 Loss :  4.326169228768563  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  224  Time:  10.577  Rel. Train L2 Loss :  0.027567840218544006  Rel. Test L2 Loss :  0.06930661899549467  Test L2 Loss :  4.252971013387044  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  225  Time:  10.594  Rel. Train L2 Loss :  0.027414025217294694  Rel. Test L2 Loss :  0.06906740541930671  Test L2 Loss :  4.2389136649466845  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  226  Time:  10.564  Rel. Train L2 Loss :  0.027122787684202194  Rel. Test L2 Loss :  0.06926607253315213  Test L2 Loss :  4.248953673216674  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  227  Time:  10.568  Rel. Train L2 Loss :  0.026368632644414903  Rel. Test L2 Loss :  0.0683005508538839  Test L2 Loss :  4.192100353069134  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  228  Time:  10.592  Rel. Train L2 Loss :  0.025937885835766793  Rel. Test L2 Loss :  0.06927030714782509  Test L2 Loss :  4.252640990523605  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  229  Time:  10.586  Rel. Train L2 Loss :  0.026906085550785063  Rel. Test L2 Loss :  0.06857783676267744  Test L2 Loss :  4.2081468427503435  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  230  Time:  10.585  Rel. Train L2 Loss :  0.026884909242391588  Rel. Test L2 Loss :  0.06866578771187379  Test L2 Loss :  4.214069125888584  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  231  Time:  10.569  Rel. Train L2 Loss :  0.02676788794994354  Rel. Test L2 Loss :  0.068967524412516  Test L2 Loss :  4.230777018779033  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  232  Time:  10.587  Rel. Train L2 Loss :  0.026778427138924598  Rel. Test L2 Loss :  0.07003440566965051  Test L2 Loss :  4.297933595674532  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  233  Time:  10.591  Rel. Train L2 Loss :  0.02652023258805275  Rel. Test L2 Loss :  0.06874951988727122  Test L2 Loss :  4.2177037763166  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  234  Time:  10.599  Rel. Train L2 Loss :  0.02627498872578144  Rel. Test L2 Loss :  0.06917720710909045  Test L2 Loss :  4.245961936744484  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  235  Time:  10.603  Rel. Train L2 Loss :  0.026220957458019258  Rel. Test L2 Loss :  0.06898903739344966  Test L2 Loss :  4.233784099956891  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  236  Time:  10.596  Rel. Train L2 Loss :  0.025840771853923798  Rel. Test L2 Loss :  0.06832495385462099  Test L2 Loss :  4.194546450365771  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  237  Time:  10.591  Rel. Train L2 Loss :  0.02584733133018017  Rel. Test L2 Loss :  0.07036428408579784  Test L2 Loss :  4.316337499532613  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  238  Time:  10.612  Rel. Train L2 Loss :  0.025660921275615693  Rel. Test L2 Loss :  0.06926516879786242  Test L2 Loss :  4.250074472513285  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  239  Time:  10.599  Rel. Train L2 Loss :  0.02622590896487236  Rel. Test L2 Loss :  0.0702433744529346  Test L2 Loss :  4.312704876736477  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  240  Time:  10.593  Rel. Train L2 Loss :  0.026179628789424897  Rel. Test L2 Loss :  0.06892089961885332  Test L2 Loss :  4.229400755048872  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  241  Time:  10.586  Rel. Train L2 Loss :  0.02514236781001091  Rel. Test L2 Loss :  0.06976306062560898  Test L2 Loss :  4.282656987508138  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  242  Time:  10.58  Rel. Train L2 Loss :  0.026195387959480284  Rel. Test L2 Loss :  0.07002837271303744  Test L2 Loss :  4.297176910950257  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  243  Time:  10.569  Rel. Train L2 Loss :  0.026797832250595094  Rel. Test L2 Loss :  0.06869989123430338  Test L2 Loss :  4.21841016546026  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  244  Time:  10.567  Rel. Train L2 Loss :  0.025529663920402526  Rel. Test L2 Loss :  0.0679692263538773  Test L2 Loss :  4.17136879654618  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  245  Time:  10.549  Rel. Train L2 Loss :  0.02488205699622631  Rel. Test L2 Loss :  0.06893971857723889  Test L2 Loss :  4.231907372002129  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  246  Time:  10.565  Rel. Train L2 Loss :  0.02492835721373558  Rel. Test L2 Loss :  0.06855536071029869  Test L2 Loss :  4.206268499563406  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  247  Time:  10.556  Rel. Train L2 Loss :  0.02409114736318588  Rel. Test L2 Loss :  0.06943223658982697  Test L2 Loss :  4.260573292637731  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  248  Time:  10.558  Rel. Train L2 Loss :  0.02462739723920822  Rel. Test L2 Loss :  0.06891306536691683  Test L2 Loss :  4.231326146168752  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  249  Time:  10.589  Rel. Train L2 Loss :  0.024540153115987777  Rel. Test L2 Loss :  0.06976720744425112  Test L2 Loss :  4.280389802949923  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  250  Time:  10.541  Rel. Train L2 Loss :  0.024612413883209228  Rel. Test L2 Loss :  0.0681399050596598  Test L2 Loss :  4.181182792594841  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  251  Time:  10.581  Rel. Train L2 Loss :  0.02463255375623703  Rel. Test L2 Loss :  0.06891722238815583  Test L2 Loss :  4.2318465258624105  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  252  Time:  10.605  Rel. Train L2 Loss :  0.024864429503679276  Rel. Test L2 Loss :  0.06917242262814496  Test L2 Loss :  4.244855880737305  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  253  Time:  10.587  Rel. Train L2 Loss :  0.024517101854085923  Rel. Test L2 Loss :  0.06825814053818986  Test L2 Loss :  4.19039368844247  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  254  Time:  10.578  Rel. Train L2 Loss :  0.024599769979715348  Rel. Test L2 Loss :  0.06930319038597313  Test L2 Loss :  4.253120370813318  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  255  Time:  10.588  Rel. Train L2 Loss :  0.024435815393924712  Rel. Test L2 Loss :  0.06917114864598524  Test L2 Loss :  4.245621208672051  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  256  Time:  10.691  Rel. Train L2 Loss :  0.024119078636169435  Rel. Test L2 Loss :  0.0684113515926911  Test L2 Loss :  4.199825527431728  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  257  Time:  10.579  Rel. Train L2 Loss :  0.023073340207338332  Rel. Test L2 Loss :  0.06809949176805513  Test L2 Loss :  4.178992520581494  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  258  Time:  10.577  Rel. Train L2 Loss :  0.022732874393463134  Rel. Test L2 Loss :  0.06865946693463368  Test L2 Loss :  4.2135054957759275  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  259  Time:  10.598  Rel. Train L2 Loss :  0.022902077704668046  Rel. Test L2 Loss :  0.06824144049807712  Test L2 Loss :  4.188949430311048  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  260  Time:  10.575  Rel. Train L2 Loss :  0.023981398671865464  Rel. Test L2 Loss :  0.06826180380743903  Test L2 Loss :  4.188708966916746  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  261  Time:  10.518  Rel. Train L2 Loss :  0.023667515888810157  Rel. Test L2 Loss :  0.06861773455465162  Test L2 Loss :  4.211540737667599  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  262  Time:  10.574  Rel. Train L2 Loss :  0.02430596709251404  Rel. Test L2 Loss :  0.06813364549800083  Test L2 Loss :  4.182595914548582  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  263  Time:  10.584  Rel. Train L2 Loss :  0.023136687949299812  Rel. Test L2 Loss :  0.06856897714975718  Test L2 Loss :  4.207731178214958  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  264  Time:  10.574  Rel. Train L2 Loss :  0.022241602033376693  Rel. Test L2 Loss :  0.06795009943816038  Test L2 Loss :  4.169707341237111  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  265  Time:  10.561  Rel. Train L2 Loss :  0.022364557892084122  Rel. Test L2 Loss :  0.06836066025871414  Test L2 Loss :  4.194002649805567  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  266  Time:  10.553  Rel. Train L2 Loss :  0.023359420835971832  Rel. Test L2 Loss :  0.06906543390170948  Test L2 Loss :  4.238441501651798  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  267  Time:  10.568  Rel. Train L2 Loss :  0.02316867010295391  Rel. Test L2 Loss :  0.06849842726647316  Test L2 Loss :  4.2039912799457175  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  268  Time:  10.567  Rel. Train L2 Loss :  0.023264240980148315  Rel. Test L2 Loss :  0.0691184224309148  Test L2 Loss :  4.24129901920353  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  269  Time:  10.597  Rel. Train L2 Loss :  0.022572858542203905  Rel. Test L2 Loss :  0.06903101463575621  Test L2 Loss :  4.236531816087328  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  270  Time:  10.582  Rel. Train L2 Loss :  0.022486899107694625  Rel. Test L2 Loss :  0.06916869196805868  Test L2 Loss :  4.244992591239311  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  271  Time:  10.592  Rel. Train L2 Loss :  0.022873791709542273  Rel. Test L2 Loss :  0.06831028896409112  Test L2 Loss :  4.192999367241387  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  272  Time:  10.583  Rel. Train L2 Loss :  0.021958061143755914  Rel. Test L2 Loss :  0.06858160850164052  Test L2 Loss :  4.210348765055339  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  273  Time:  10.573  Rel. Train L2 Loss :  0.022321720868349076  Rel. Test L2 Loss :  0.0681769348479606  Test L2 Loss :  4.183713431830879  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  274  Time:  10.587  Rel. Train L2 Loss :  0.02210291013121605  Rel. Test L2 Loss :  0.06814476498612412  Test L2 Loss :  4.182285893070805  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  275  Time:  10.557  Rel. Train L2 Loss :  0.021803624883294105  Rel. Test L2 Loss :  0.06870173092360969  Test L2 Loss :  4.216617515495232  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  276  Time:  10.628  Rel. Train L2 Loss :  0.021683510705828666  Rel. Test L2 Loss :  0.06812401881089082  Test L2 Loss :  4.180314828683664  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  277  Time:  10.611  Rel. Train L2 Loss :  0.021612940058112144  Rel. Test L2 Loss :  0.06841156718967197  Test L2 Loss :  4.199526950045749  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  278  Time:  10.606  Rel. Train L2 Loss :  0.021494793578982353  Rel. Test L2 Loss :  0.06881026561195785  Test L2 Loss :  4.222461442689638  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  279  Time:  10.611  Rel. Train L2 Loss :  0.021916465282440185  Rel. Test L2 Loss :  0.06830239269110533  Test L2 Loss :  4.193480998546153  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  280  Time:  10.559  Rel. Train L2 Loss :  0.0215057689845562  Rel. Test L2 Loss :  0.06804521959107201  Test L2 Loss :  4.176842680922499  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  281  Time:  10.565  Rel. Train L2 Loss :  0.02091527457535267  Rel. Test L2 Loss :  0.06777391884777997  Test L2 Loss :  4.159197970553562  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  282  Time:  10.564  Rel. Train L2 Loss :  0.020840975373983384  Rel. Test L2 Loss :  0.06814932742634335  Test L2 Loss :  4.182798901119748  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  283  Time:  10.564  Rel. Train L2 Loss :  0.020973984867334365  Rel. Test L2 Loss :  0.0682494809498658  Test L2 Loss :  4.188968435064092  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  284  Time:  10.577  Rel. Train L2 Loss :  0.02071809448301792  Rel. Test L2 Loss :  0.06850964367926658  Test L2 Loss :  4.205908508988114  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  285  Time:  10.572  Rel. Train L2 Loss :  0.020640721410512923  Rel. Test L2 Loss :  0.06789907974165839  Test L2 Loss :  4.165477649585621  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  286  Time:  11.299  Rel. Train L2 Loss :  0.020460527122020723  Rel. Test L2 Loss :  0.06827298182624954  Test L2 Loss :  4.190565195169535  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  287  Time:  10.56  Rel. Train L2 Loss :  0.019941608667373656  Rel. Test L2 Loss :  0.06811092324085063  Test L2 Loss :  4.182010066401851  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  288  Time:  10.578  Rel. Train L2 Loss :  0.020464855015277863  Rel. Test L2 Loss :  0.06809832008035334  Test L2 Loss :  4.178807731147285  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  289  Time:  10.596  Rel. Train L2 Loss :  0.02019083407521248  Rel. Test L2 Loss :  0.06816350232373487  Test L2 Loss :  4.183593732816679  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  290  Time:  10.63  Rel. Train L2 Loss :  0.02012020343542099  Rel. Test L2 Loss :  0.0683394764457737  Test L2 Loss :  4.193656955753361  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  291  Time:  11.322  Rel. Train L2 Loss :  0.020498775869607924  Rel. Test L2 Loss :  0.06808703466578647  Test L2 Loss :  4.178698651425473  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  292  Time:  10.68  Rel. Train L2 Loss :  0.020229774534702302  Rel. Test L2 Loss :  0.06891519878361677  Test L2 Loss :  4.228818326383023  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  293  Time:  10.619  Rel. Train L2 Loss :  0.019936559423804283  Rel. Test L2 Loss :  0.06786772044929298  Test L2 Loss :  4.165627024195215  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  294  Time:  11.403  Rel. Train L2 Loss :  0.020267206519842148  Rel. Test L2 Loss :  0.06787535897246352  Test L2 Loss :  4.166969075933233  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  295  Time:  10.547  Rel. Train L2 Loss :  0.019400427281856536  Rel. Test L2 Loss :  0.06850315670709352  Test L2 Loss :  4.204741297541438  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  296  Time:  10.548  Rel. Train L2 Loss :  0.019590736135840416  Rel. Test L2 Loss :  0.06774964203705659  Test L2 Loss :  4.158434996733794  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  297  Time:  10.537  Rel. Train L2 Loss :  0.019519646272063255  Rel. Test L2 Loss :  0.06811465390093692  Test L2 Loss :  4.181467966990428  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  298  Time:  10.546  Rel. Train L2 Loss :  0.019486816495656967  Rel. Test L2 Loss :  0.06796223274222365  Test L2 Loss :  4.1708409592912  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  299  Time:  10.537  Rel. Train L2 Loss :  0.01934259095788002  Rel. Test L2 Loss :  0.0679500285569612  Test L2 Loss :  4.172318742081925  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  300  Time:  10.559  Rel. Train L2 Loss :  0.019023545652627944  Rel. Test L2 Loss :  0.06815132391345394  Test L2 Loss :  4.181080947051177  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  301  Time:  10.565  Rel. Train L2 Loss :  0.018918277949094772  Rel. Test L2 Loss :  0.06786755747623271  Test L2 Loss :  4.165454125619149  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  302  Time:  10.567  Rel. Train L2 Loss :  0.018356454253196715  Rel. Test L2 Loss :  0.06827320950525301  Test L2 Loss :  4.190082120465803  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  303  Time:  10.654  Rel. Train L2 Loss :  0.01879106092453003  Rel. Test L2 Loss :  0.06795980506115132  Test L2 Loss :  4.169333088505375  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  304  Time:  10.643  Rel. Train L2 Loss :  0.018878146290779114  Rel. Test L2 Loss :  0.06783148431563163  Test L2 Loss :  4.16405963038539  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  305  Time:  10.679  Rel. Train L2 Loss :  0.018723691895604133  Rel. Test L2 Loss :  0.06764846046765645  Test L2 Loss :  4.152191522959116  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  306  Time:  10.704  Rel. Train L2 Loss :  0.01868306577205658  Rel. Test L2 Loss :  0.06809247023350484  Test L2 Loss :  4.178835052627701  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  307  Time:  10.629  Rel. Train L2 Loss :  0.01836177258193493  Rel. Test L2 Loss :  0.06797348754899996  Test L2 Loss :  4.171976828360343  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  308  Time:  10.686  Rel. Train L2 Loss :  0.018274294674396514  Rel. Test L2 Loss :  0.06852056958653906  Test L2 Loss :  4.20519581356564  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  309  Time:  10.704  Rel. Train L2 Loss :  0.018143238469958304  Rel. Test L2 Loss :  0.06776796053121756  Test L2 Loss :  4.158605455278276  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  310  Time:  10.643  Rel. Train L2 Loss :  0.01758245415985584  Rel. Test L2 Loss :  0.06818849170530164  Test L2 Loss :  4.185246613648561  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  311  Time:  10.635  Rel. Train L2 Loss :  0.017829471245408058  Rel. Test L2 Loss :  0.06815032459594109  Test L2 Loss :  4.183254413776569  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  312  Time:  10.646  Rel. Train L2 Loss :  0.01775068858265877  Rel. Test L2 Loss :  0.06806709315325762  Test L2 Loss :  4.177748259123381  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  313  Time:  10.625  Rel. Train L2 Loss :  0.01762627783417702  Rel. Test L2 Loss :  0.06798049377965497  Test L2 Loss :  4.172470384889895  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  314  Time:  10.628  Rel. Train L2 Loss :  0.017719581216573715  Rel. Test L2 Loss :  0.06774537788855063  Test L2 Loss :  4.158218400972384  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  315  Time:  10.632  Rel. Train L2 Loss :  0.017350114941596984  Rel. Test L2 Loss :  0.06810327773695593  Test L2 Loss :  4.180040548513602  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  316  Time:  10.651  Rel. Train L2 Loss :  0.01697627045959234  Rel. Test L2 Loss :  0.06724002178724822  Test L2 Loss :  4.124927280185459  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  317  Time:  10.668  Rel. Train L2 Loss :  0.017100938513875008  Rel. Test L2 Loss :  0.06806935947220605  Test L2 Loss :  4.177870209152634  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  318  Time:  10.671  Rel. Train L2 Loss :  0.017250436887145042  Rel. Test L2 Loss :  0.06790848868387239  Test L2 Loss :  4.167186857343794  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  319  Time:  10.672  Rel. Train L2 Loss :  0.016798493772745133  Rel. Test L2 Loss :  0.06760363562687023  Test L2 Loss :  4.149630950377868  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  320  Time:  10.659  Rel. Train L2 Loss :  0.016412527769804  Rel. Test L2 Loss :  0.06776619682440886  Test L2 Loss :  4.158715222332929  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  321  Time:  10.644  Rel. Train L2 Loss :  0.01660636595636606  Rel. Test L2 Loss :  0.06770269478763546  Test L2 Loss :  4.1553531337428735  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  322  Time:  10.651  Rel. Train L2 Loss :  0.016471936404705047  Rel. Test L2 Loss :  0.06792562448226654  Test L2 Loss :  4.168992016766523  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  323  Time:  10.646  Rel. Train L2 Loss :  0.01603761214017868  Rel. Test L2 Loss :  0.06781236813949035  Test L2 Loss :  4.162076468940254  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  324  Time:  10.645  Rel. Train L2 Loss :  0.01662545136362314  Rel. Test L2 Loss :  0.0677963452296214  Test L2 Loss :  4.161998645679371  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  325  Time:  10.641  Rel. Train L2 Loss :  0.016595612645149232  Rel. Test L2 Loss :  0.06792644605980264  Test L2 Loss :  4.169497773453996  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  326  Time:  10.642  Rel. Train L2 Loss :  0.016148829504847525  Rel. Test L2 Loss :  0.06777431111078004  Test L2 Loss :  4.161481238700248  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  327  Time:  10.622  Rel. Train L2 Loss :  0.015696863278746604  Rel. Test L2 Loss :  0.06829449400171503  Test L2 Loss :  4.190611744786168  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  328  Time:  10.63  Rel. Train L2 Loss :  0.01622336272895336  Rel. Test L2 Loss :  0.06828455694086917  Test L2 Loss :  4.1899447913642405  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  329  Time:  10.619  Rel. Train L2 Loss :  0.016130309268832205  Rel. Test L2 Loss :  0.0677710975612606  Test L2 Loss :  4.1606722651301205  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  330  Time:  10.622  Rel. Train L2 Loss :  0.015796852253377437  Rel. Test L2 Loss :  0.06786622872223726  Test L2 Loss :  4.166475983353348  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  331  Time:  10.574  Rel. Train L2 Loss :  0.01557719586789608  Rel. Test L2 Loss :  0.06776854476413212  Test L2 Loss :  4.159558218878669  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  332  Time:  10.644  Rel. Train L2 Loss :  0.015527624532580376  Rel. Test L2 Loss :  0.06769247285954587  Test L2 Loss :  4.156301240663271  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  333  Time:  10.642  Rel. Train L2 Loss :  0.015546143472194672  Rel. Test L2 Loss :  0.06779837742582098  Test L2 Loss :  4.161004367175403  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  334  Time:  10.625  Rel. Train L2 Loss :  0.015293816149234772  Rel. Test L2 Loss :  0.06767305704924437  Test L2 Loss :  4.15372692142521  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  335  Time:  10.627  Rel. Train L2 Loss :  0.015233651518821716  Rel. Test L2 Loss :  0.06767679039422456  Test L2 Loss :  4.1542866165573535  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  336  Time:  10.633  Rel. Train L2 Loss :  0.015145885489881038  Rel. Test L2 Loss :  0.06750088446849101  Test L2 Loss :  4.1428109761830925  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  337  Time:  10.639  Rel. Train L2 Loss :  0.015352321550250054  Rel. Test L2 Loss :  0.06789364283149307  Test L2 Loss :  4.16689310847102  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  338  Time:  10.643  Rel. Train L2 Loss :  0.015090585216879844  Rel. Test L2 Loss :  0.0682357299972225  Test L2 Loss :  4.188189893155484  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  339  Time:  10.654  Rel. Train L2 Loss :  0.014676184341311455  Rel. Test L2 Loss :  0.06770171560682692  Test L2 Loss :  4.155226149000563  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  340  Time:  10.64  Rel. Train L2 Loss :  0.014556564062833786  Rel. Test L2 Loss :  0.06749865090524829  Test L2 Loss :  4.142587524276596  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  341  Time:  10.629  Rel. Train L2 Loss :  0.014018283173441887  Rel. Test L2 Loss :  0.06739648693316691  Test L2 Loss :  4.136686376623206  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  342  Time:  10.637  Rel. Train L2 Loss :  0.013900723859667778  Rel. Test L2 Loss :  0.06766241144489597  Test L2 Loss :  4.153006545058242  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  343  Time:  10.642  Rel. Train L2 Loss :  0.013992421671748162  Rel. Test L2 Loss :  0.06760015734681138  Test L2 Loss :  4.149045548997484  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  344  Time:  10.628  Rel. Train L2 Loss :  0.013707885600626468  Rel. Test L2 Loss :  0.06750911017795941  Test L2 Loss :  4.143802230422561  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  345  Time:  10.633  Rel. Train L2 Loss :  0.01350049065798521  Rel. Test L2 Loss :  0.06773088483123092  Test L2 Loss :  4.157045398746525  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  346  Time:  10.63  Rel. Train L2 Loss :  0.013534529589116573  Rel. Test L2 Loss :  0.06762982435054607  Test L2 Loss :  4.150813661180101  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  347  Time:  10.606  Rel. Train L2 Loss :  0.013614271238446236  Rel. Test L2 Loss :  0.06741813657520053  Test L2 Loss :  4.137453268240164  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  348  Time:  10.634  Rel. Train L2 Loss :  0.013155510507524013  Rel. Test L2 Loss :  0.0679166934511683  Test L2 Loss :  4.168671719662778  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  349  Time:  10.623  Rel. Train L2 Loss :  0.013382916443049907  Rel. Test L2 Loss :  0.06755498185888067  Test L2 Loss :  4.145894849622572  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  350  Time:  10.625  Rel. Train L2 Loss :  0.013432582899928092  Rel. Test L2 Loss :  0.06750236357654538  Test L2 Loss :  4.141745472813512  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  351  Time:  10.638  Rel. Train L2 Loss :  0.013145123407244682  Rel. Test L2 Loss :  0.06726517333640708  Test L2 Loss :  4.129123120694547  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  352  Time:  10.629  Rel. Train L2 Loss :  0.013132973663508893  Rel. Test L2 Loss :  0.06751857013315768  Test L2 Loss :  4.14436201147131  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  353  Time:  10.628  Rel. Train L2 Loss :  0.012976418450474739  Rel. Test L2 Loss :  0.06788751644057196  Test L2 Loss :  4.166586317457594  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  354  Time:  10.639  Rel. Train L2 Loss :  0.013122548460960387  Rel. Test L2 Loss :  0.06739762049537522  Test L2 Loss :  4.136548257088876  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  355  Time:  10.602  Rel. Train L2 Loss :  0.012943261370062829  Rel. Test L2 Loss :  0.06780765856708493  Test L2 Loss :  4.162542807089316  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  356  Time:  10.68  Rel. Train L2 Loss :  0.012781109347939492  Rel. Test L2 Loss :  0.06758421552073848  Test L2 Loss :  4.1476846815229536  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  357  Time:  10.671  Rel. Train L2 Loss :  0.01257595580816269  Rel. Test L2 Loss :  0.06761730925456898  Test L2 Loss :  4.150047817745724  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  358  Time:  10.65  Rel. Train L2 Loss :  0.012704749926924705  Rel. Test L2 Loss :  0.06743828670398609  Test L2 Loss :  4.139602076899898  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  359  Time:  10.64  Rel. Train L2 Loss :  0.012172864124178886  Rel. Test L2 Loss :  0.06754266329713769  Test L2 Loss :  4.144911001394461  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  360  Time:  10.625  Rel. Train L2 Loss :  0.012399966970086098  Rel. Test L2 Loss :  0.06769301493962605  Test L2 Loss :  4.154925131582999  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  361  Time:  10.625  Rel. Train L2 Loss :  0.012019686952233315  Rel. Test L2 Loss :  0.06765027277104489  Test L2 Loss :  4.1524760100218625  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  362  Time:  10.626  Rel. Train L2 Loss :  0.012359305039048194  Rel. Test L2 Loss :  0.0675789421206122  Test L2 Loss :  4.14803831426947  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  363  Time:  10.642  Rel. Train L2 Loss :  0.012116522625088692  Rel. Test L2 Loss :  0.06760219464430937  Test L2 Loss :  4.149158512149845  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  364  Time:  10.629  Rel. Train L2 Loss :  0.011956907227635384  Rel. Test L2 Loss :  0.06780978366061374  Test L2 Loss :  4.162202491416587  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  365  Time:  10.622  Rel. Train L2 Loss :  0.01138029159605503  Rel. Test L2 Loss :  0.06755508791219007  Test L2 Loss :  4.1462453893713045  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  366  Time:  10.63  Rel. Train L2 Loss :  0.011387133285403252  Rel. Test L2 Loss :  0.06772269858970298  Test L2 Loss :  4.15606469506616  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  367  Time:  10.631  Rel. Train L2 Loss :  0.011134955748915673  Rel. Test L2 Loss :  0.06770095605034011  Test L2 Loss :  4.1551932773074585  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  368  Time:  10.638  Rel. Train L2 Loss :  0.01102341379225254  Rel. Test L2 Loss :  0.06771990817946356  Test L2 Loss :  4.156683294622748  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  369  Time:  10.636  Rel. Train L2 Loss :  0.01105612950026989  Rel. Test L2 Loss :  0.06730899241593508  Test L2 Loss :  4.13147563762493  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  370  Time:  10.639  Rel. Train L2 Loss :  0.010816493041813374  Rel. Test L2 Loss :  0.06767468570588946  Test L2 Loss :  4.154616794070682  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  371  Time:  10.638  Rel. Train L2 Loss :  0.010780982330441474  Rel. Test L2 Loss :  0.06741766403387259  Test L2 Loss :  4.137241827475058  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  372  Time:  10.638  Rel. Train L2 Loss :  0.01076893524825573  Rel. Test L2 Loss :  0.06750979831626823  Test L2 Loss :  4.143480369636604  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  373  Time:  10.627  Rel. Train L2 Loss :  0.010590657308697701  Rel. Test L2 Loss :  0.067489002738987  Test L2 Loss :  4.143439816999006  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  374  Time:  10.655  Rel. Train L2 Loss :  0.010546774566173554  Rel. Test L2 Loss :  0.0674940315452782  Test L2 Loss :  4.1420718528128955  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  375  Time:  10.638  Rel. Train L2 Loss :  0.010421692371368408  Rel. Test L2 Loss :  0.06751469395182154  Test L2 Loss :  4.144364674886067  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  376  Time:  10.634  Rel. Train L2 Loss :  0.010270762354135514  Rel. Test L2 Loss :  0.06729411058597737  Test L2 Loss :  4.130897504789335  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  377  Time:  10.633  Rel. Train L2 Loss :  0.009916358597576619  Rel. Test L2 Loss :  0.06744428072963748  Test L2 Loss :  4.139411771619642  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  378  Time:  10.621  Rel. Train L2 Loss :  0.009835527896881104  Rel. Test L2 Loss :  0.06747152032078924  Test L2 Loss :  4.140910792995143  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  379  Time:  10.58  Rel. Train L2 Loss :  0.0097070317491889  Rel. Test L2 Loss :  0.06738759912886061  Test L2 Loss :  4.136097968161643  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  380  Time:  10.655  Rel. Train L2 Loss :  0.009735567651689052  Rel. Test L2 Loss :  0.06738156187641728  Test L2 Loss :  4.136069701598571  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  381  Time:  10.65  Rel. Train L2 Loss :  0.009794326536357402  Rel. Test L2 Loss :  0.06748539155667967  Test L2 Loss :  4.142193940308717  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  382  Time:  10.63  Rel. Train L2 Loss :  0.00959379406273365  Rel. Test L2 Loss :  0.06742072105407715  Test L2 Loss :  4.138189934395455  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  383  Time:  10.658  Rel. Train L2 Loss :  0.00928433258831501  Rel. Test L2 Loss :  0.06749000823175585  Test L2 Loss :  4.142221244605812  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  384  Time:  10.645  Rel. Train L2 Loss :  0.009041270889341832  Rel. Test L2 Loss :  0.06735288398759859  Test L2 Loss :  4.133893485541816  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  385  Time:  10.638  Rel. Train L2 Loss :  0.009315269201993942  Rel. Test L2 Loss :  0.06744089105107763  Test L2 Loss :  4.1393014203320755  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  386  Time:  10.625  Rel. Train L2 Loss :  0.009140806615352631  Rel. Test L2 Loss :  0.06756750581500766  Test L2 Loss :  4.147324690947661  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  387  Time:  10.643  Rel. Train L2 Loss :  0.009121855258941651  Rel. Test L2 Loss :  0.0673544704914093  Test L2 Loss :  4.134046915415171  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  388  Time:  10.645  Rel. Train L2 Loss :  0.008958926133811473  Rel. Test L2 Loss :  0.06749625893326493  Test L2 Loss :  4.142615739289705  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  389  Time:  10.625  Rel. Train L2 Loss :  0.008757235579192639  Rel. Test L2 Loss :  0.06739128172934593  Test L2 Loss :  4.136819770744255  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  390  Time:  10.628  Rel. Train L2 Loss :  0.008624337986111641  Rel. Test L2 Loss :  0.06752113716022388  Test L2 Loss :  4.144176620620865  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  391  Time:  10.631  Rel. Train L2 Loss :  0.008529185779392719  Rel. Test L2 Loss :  0.0674033028048438  Test L2 Loss :  4.137176668321764  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  392  Time:  10.626  Rel. Train L2 Loss :  0.008569197058677673  Rel. Test L2 Loss :  0.06763999848752408  Test L2 Loss :  4.1512055096325575  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  393  Time:  10.631  Rel. Train L2 Loss :  0.008075627528131008  Rel. Test L2 Loss :  0.0674274053659525  Test L2 Loss :  4.138314272906329  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  394  Time:  10.638  Rel. Train L2 Loss :  0.00805949280038476  Rel. Test L2 Loss :  0.06741922798457446  Test L2 Loss :  4.138035078306456  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  395  Time:  10.644  Rel. Train L2 Loss :  0.008081984616816043  Rel. Test L2 Loss :  0.06757196381285384  Test L2 Loss :  4.147483275817321  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  396  Time:  10.994  Rel. Train L2 Loss :  0.00784223960340023  Rel. Test L2 Loss :  0.06744796359861219  Test L2 Loss :  4.139313534573391  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  397  Time:  15.144  Rel. Train L2 Loss :  0.007764241792261601  Rel. Test L2 Loss :  0.06749476613225164  Test L2 Loss :  4.1429715715013105  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  398  Time:  10.912  Rel. Train L2 Loss :  0.0077327446080744265  Rel. Test L2 Loss :  0.0674837859901222  Test L2 Loss :  4.1419451258204  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  399  Time:  10.589  Rel. Train L2 Loss :  0.0079304223023355  Rel. Test L2 Loss :  0.06745005566794593  Test L2 Loss :  4.140057847306535  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  400  Time:  10.584  Rel. Train L2 Loss :  0.008006418362259864  Rel. Test L2 Loss :  0.06752920204454714  Test L2 Loss :  4.1445527807012335  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  401  Time:  10.616  Rel. Train L2 Loss :  0.00772658783942461  Rel. Test L2 Loss :  0.06753250124218228  Test L2 Loss :  4.14498487249151  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  402  Time:  10.599  Rel. Train L2 Loss :  0.007724200833588838  Rel. Test L2 Loss :  0.06758823480691996  Test L2 Loss :  4.148333403441283  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  403  Time:  10.572  Rel. Train L2 Loss :  0.007388163428753615  Rel. Test L2 Loss :  0.06741811563302805  Test L2 Loss :  4.137914898159267  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  404  Time:  10.637  Rel. Train L2 Loss :  0.006993890017271042  Rel. Test L2 Loss :  0.06755818332637753  Test L2 Loss :  4.14649705629091  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  405  Time:  10.616  Rel. Train L2 Loss :  0.007272716857492924  Rel. Test L2 Loss :  0.06752300692034198  Test L2 Loss :  4.144163647213498  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  406  Time:  10.626  Rel. Train L2 Loss :  0.0071273427531123165  Rel. Test L2 Loss :  0.06754630857759768  Test L2 Loss :  4.14538895546853  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  407  Time:  10.619  Rel. Train L2 Loss :  0.0067432673275470735  Rel. Test L2 Loss :  0.06749847397073969  Test L2 Loss :  4.14233991262075  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  408  Time:  10.603  Rel. Train L2 Loss :  0.006693410255014897  Rel. Test L2 Loss :  0.06753884833138268  Test L2 Loss :  4.145114640931825  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  409  Time:  10.621  Rel. Train L2 Loss :  0.006554624289274216  Rel. Test L2 Loss :  0.06756673149160437  Test L2 Loss :  4.147113645398939  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  410  Time:  10.617  Rel. Train L2 Loss :  0.006332252852618694  Rel. Test L2 Loss :  0.06748695335946642  Test L2 Loss :  4.142032966957436  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  411  Time:  10.61  Rel. Train L2 Loss :  0.006228075131773949  Rel. Test L2 Loss :  0.06760253938468727  Test L2 Loss :  4.1493806237573025  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  412  Time:  10.596  Rel. Train L2 Loss :  0.006278823673725128  Rel. Test L2 Loss :  0.0674751191525846  Test L2 Loss :  4.141367336651227  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  413  Time:  10.582  Rel. Train L2 Loss :  0.006126729372888803  Rel. Test L2 Loss :  0.06755543399501492  Test L2 Loss :  4.146107699420001  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  414  Time:  10.589  Rel. Train L2 Loss :  0.006248071074485779  Rel. Test L2 Loss :  0.06747068907763507  Test L2 Loss :  4.141512518530494  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  415  Time:  10.588  Rel. Train L2 Loss :  0.0061139284037053584  Rel. Test L2 Loss :  0.06760164880537772  Test L2 Loss :  4.149228688832876  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  416  Time:  10.592  Rel. Train L2 Loss :  0.005907761972397566  Rel. Test L2 Loss :  0.0674739853218869  Test L2 Loss :  4.141131959519945  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  417  Time:  10.599  Rel. Train L2 Loss :  0.005767093457281589  Rel. Test L2 Loss :  0.06754464474884239  Test L2 Loss :  4.146226831384607  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  418  Time:  10.589  Rel. Train L2 Loss :  0.005750655010342598  Rel. Test L2 Loss :  0.06756410835025546  Test L2 Loss :  4.146951091182125  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  419  Time:  10.63  Rel. Train L2 Loss :  0.0056459449157118795  Rel. Test L2 Loss :  0.06755223977673161  Test L2 Loss :  4.1463409114528345  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  420  Time:  10.62  Rel. Train L2 Loss :  0.005510532688349485  Rel. Test L2 Loss :  0.06748596424455042  Test L2 Loss :  4.142192909309456  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  421  Time:  10.613  Rel. Train L2 Loss :  0.005278217237442732  Rel. Test L2 Loss :  0.06757871578405569  Test L2 Loss :  4.1479684468862175  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  422  Time:  10.6  Rel. Train L2 Loss :  0.0052365631610155105  Rel. Test L2 Loss :  0.06752603386973476  Test L2 Loss :  4.144638233356647  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  423  Time:  10.6  Rel. Train L2 Loss :  0.005268274281173944  Rel. Test L2 Loss :  0.06756474144823917  Test L2 Loss :  4.147108868435696  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  424  Time:  10.612  Rel. Train L2 Loss :  0.005124652795493603  Rel. Test L2 Loss :  0.06757295265928046  Test L2 Loss :  4.147446125477284  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  425  Time:  10.611  Rel. Train L2 Loss :  0.004956468552350998  Rel. Test L2 Loss :  0.06755971935418276  Test L2 Loss :  4.146566820574236  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  426  Time:  10.609  Rel. Train L2 Loss :  0.004877717439085245  Rel. Test L2 Loss :  0.06750606577675622  Test L2 Loss :  4.14331917290215  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  427  Time:  10.563  Rel. Train L2 Loss :  0.004741537559777498  Rel. Test L2 Loss :  0.06756143151102839  Test L2 Loss :  4.146802249255481  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  428  Time:  10.631  Rel. Train L2 Loss :  0.004638795897364616  Rel. Test L2 Loss :  0.06754860604131543  Test L2 Loss :  4.146136876699087  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  429  Time:  10.632  Rel. Train L2 Loss :  0.004608492724597454  Rel. Test L2 Loss :  0.06765414680446591  Test L2 Loss :  4.152388340718037  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  430  Time:  10.62  Rel. Train L2 Loss :  0.004580373946577311  Rel. Test L2 Loss :  0.06753254849631507  Test L2 Loss :  4.1449511416323555  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  431  Time:  10.592  Rel. Train L2 Loss :  0.004503275416791439  Rel. Test L2 Loss :  0.06762283342378633  Test L2 Loss :  4.1505754144342095  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  432  Time:  10.592  Rel. Train L2 Loss :  0.0043711731657385825  Rel. Test L2 Loss :  0.06764945414689211  Test L2 Loss :  4.152271459768484  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  433  Time:  10.591  Rel. Train L2 Loss :  0.004331587437540293  Rel. Test L2 Loss :  0.06756728028391933  Test L2 Loss :  4.14715576171875  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  434  Time:  10.598  Rel. Train L2 Loss :  0.0043156701065599915  Rel. Test L2 Loss :  0.06755103774972863  Test L2 Loss :  4.146146860208598  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  435  Time:  10.615  Rel. Train L2 Loss :  0.004275208139792085  Rel. Test L2 Loss :  0.06757065331613696  Test L2 Loss :  4.1471586485166805  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  436  Time:  10.59  Rel. Train L2 Loss :  0.0040958719179034235  Rel. Test L2 Loss :  0.06762885832571769  Test L2 Loss :  4.150941367621894  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  437  Time:  10.6  Rel. Train L2 Loss :  0.0040589595958590505  Rel. Test L2 Loss :  0.0676417200414984  Test L2 Loss :  4.151744498862876  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  438  Time:  10.603  Rel. Train L2 Loss :  0.003962933989241719  Rel. Test L2 Loss :  0.06760979155162433  Test L2 Loss :  4.149720269280511  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  439  Time:  10.601  Rel. Train L2 Loss :  0.0037858494240790605  Rel. Test L2 Loss :  0.06762722080892271  Test L2 Loss :  4.150710939287065  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  440  Time:  10.61  Rel. Train L2 Loss :  0.003794204119592905  Rel. Test L2 Loss :  0.06761239589871587  Test L2 Loss :  4.149869661073427  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  441  Time:  10.593  Rel. Train L2 Loss :  0.003660572713240981  Rel. Test L2 Loss :  0.06761466060672794  Test L2 Loss :  4.149968740102407  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  442  Time:  10.608  Rel. Train L2 Loss :  0.0035409212596714495  Rel. Test L2 Loss :  0.06761322606791247  Test L2 Loss :  4.149753347173467  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  443  Time:  10.609  Rel. Train L2 Loss :  0.003525456827133894  Rel. Test L2 Loss :  0.06763647295333244  Test L2 Loss :  4.151343766633455  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  444  Time:  10.623  Rel. Train L2 Loss :  0.003404646936804056  Rel. Test L2 Loss :  0.0676090091735393  Test L2 Loss :  4.149619557836035  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  445  Time:  10.605  Rel. Train L2 Loss :  0.003334212742745876  Rel. Test L2 Loss :  0.06762618551383147  Test L2 Loss :  4.150639645688169  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  446  Time:  10.591  Rel. Train L2 Loss :  0.003323272205889225  Rel. Test L2 Loss :  0.06766695186898515  Test L2 Loss :  4.153120418926617  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  447  Time:  10.592  Rel. Train L2 Loss :  0.003308263748884201  Rel. Test L2 Loss :  0.06767029402492282  Test L2 Loss :  4.1532236391359625  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  448  Time:  10.6  Rel. Train L2 Loss :  0.0032475597392767667  Rel. Test L2 Loss :  0.067667327485643  Test L2 Loss :  4.15326503375629  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  449  Time:  10.604  Rel. Train L2 Loss :  0.0031279374063014984  Rel. Test L2 Loss :  0.06768837463748348  Test L2 Loss :  4.15430347339527  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  450  Time:  10.603  Rel. Train L2 Loss :  0.0030721839983016254  Rel. Test L2 Loss :  0.0676969646870553  Test L2 Loss :  4.15508796073295  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  451  Time:  10.56  Rel. Train L2 Loss :  0.003086999196559191  Rel. Test L2 Loss :  0.06767545519648371  Test L2 Loss :  4.153631863293347  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  452  Time:  10.625  Rel. Train L2 Loss :  0.003013695914298296  Rel. Test L2 Loss :  0.06768915567312155  Test L2 Loss :  4.154562872809333  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  453  Time:  10.621  Rel. Train L2 Loss :  0.0028779236972332  Rel. Test L2 Loss :  0.06768813729286194  Test L2 Loss :  4.154461010082348  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  454  Time:  10.633  Rel. Train L2 Loss :  0.002788528487086296  Rel. Test L2 Loss :  0.0676843290393417  Test L2 Loss :  4.154145730508341  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  455  Time:  10.656  Rel. Train L2 Loss :  0.0027386773861944676  Rel. Test L2 Loss :  0.06769144105481671  Test L2 Loss :  4.154667398951075  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  456  Time:  10.596  Rel. Train L2 Loss :  0.0026664625741541384  Rel. Test L2 Loss :  0.06769449834351067  Test L2 Loss :  4.154830107817778  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  457  Time:  10.619  Rel. Train L2 Loss :  0.0026016080342233182  Rel. Test L2 Loss :  0.06769481086516166  Test L2 Loss :  4.154865642925641  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  458  Time:  10.629  Rel. Train L2 Loss :  0.0025660283882170914  Rel. Test L2 Loss :  0.06771098815643035  Test L2 Loss :  4.1559561480272995  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  459  Time:  10.604  Rel. Train L2 Loss :  0.0025050867963582277  Rel. Test L2 Loss :  0.06769508418736157  Test L2 Loss :  4.154841758109428  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  460  Time:  10.611  Rel. Train L2 Loss :  0.0024511820636689665  Rel. Test L2 Loss :  0.0677247178984118  Test L2 Loss :  4.156660389255833  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  461  Time:  10.613  Rel. Train L2 Loss :  0.002423908855766058  Rel. Test L2 Loss :  0.06771908069516087  Test L2 Loss :  4.15633672422117  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  462  Time:  10.596  Rel. Train L2 Loss :  0.0023732914663851263  Rel. Test L2 Loss :  0.06773712049733412  Test L2 Loss :  4.157388429383974  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  463  Time:  10.593  Rel. Train L2 Loss :  0.002328466223552823  Rel. Test L2 Loss :  0.06772621096791448  Test L2 Loss :  4.156779796153575  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  464  Time:  10.592  Rel. Train L2 Loss :  0.002282319063320756  Rel. Test L2 Loss :  0.06773293931204993  Test L2 Loss :  4.157177435385214  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  465  Time:  10.594  Rel. Train L2 Loss :  0.0022497305423021317  Rel. Test L2 Loss :  0.06772547772338798  Test L2 Loss :  4.156733933869783  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  466  Time:  10.58  Rel. Train L2 Loss :  0.0022135724276304246  Rel. Test L2 Loss :  0.06773902623503057  Test L2 Loss :  4.15756622520653  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  467  Time:  10.577  Rel. Train L2 Loss :  0.0021768537797033785  Rel. Test L2 Loss :  0.06774241296020714  Test L2 Loss :  4.157731683404596  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  468  Time:  10.59  Rel. Train L2 Loss :  0.0021322563532739877  Rel. Test L2 Loss :  0.06774040734445727  Test L2 Loss :  4.1576821438901055  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  469  Time:  10.585  Rel. Train L2 Loss :  0.002103117622435093  Rel. Test L2 Loss :  0.0677560331585171  Test L2 Loss :  4.158588082940729  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  470  Time:  10.579  Rel. Train L2 Loss :  0.002076963257044554  Rel. Test L2 Loss :  0.06774732712152842  Test L2 Loss :  4.158054197156751  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  471  Time:  10.601  Rel. Train L2 Loss :  0.0020443361029028892  Rel. Test L2 Loss :  0.06775477528572083  Test L2 Loss :  4.158490516043998  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  472  Time:  10.597  Rel. Train L2 Loss :  0.0020130518237128853  Rel. Test L2 Loss :  0.06775761348707182  Test L2 Loss :  4.158702025542388  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  473  Time:  10.605  Rel. Train L2 Loss :  0.0019904169011861084  Rel. Test L2 Loss :  0.06776519992330053  Test L2 Loss :  4.159112827197926  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  474  Time:  10.621  Rel. Train L2 Loss :  0.001971069924533367  Rel. Test L2 Loss :  0.06777107849851385  Test L2 Loss :  4.159525140985712  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  475  Time:  10.642  Rel. Train L2 Loss :  0.0019443707149475813  Rel. Test L2 Loss :  0.06777480056693962  Test L2 Loss :  4.1597346915855065  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  476  Time:  10.657  Rel. Train L2 Loss :  0.0019174612294882536  Rel. Test L2 Loss :  0.06778505900958637  Test L2 Loss :  4.16036336056821  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  477  Time:  10.649  Rel. Train L2 Loss :  0.0018948559882119298  Rel. Test L2 Loss :  0.06777501589543111  Test L2 Loss :  4.159745293694574  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  478  Time:  10.712  Rel. Train L2 Loss :  0.0018732487065717578  Rel. Test L2 Loss :  0.06777877071956256  Test L2 Loss :  4.159966941352363  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  479  Time:  10.703  Rel. Train L2 Loss :  0.0018554626647382974  Rel. Test L2 Loss :  0.06779028515557985  Test L2 Loss :  4.160668484799497  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  480  Time:  10.668  Rel. Train L2 Loss :  0.0018403276205062867  Rel. Test L2 Loss :  0.06778835256894429  Test L2 Loss :  4.1605563292632235  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  481  Time:  10.691  Rel. Train L2 Loss :  0.001826614730991423  Rel. Test L2 Loss :  0.06778837968637277  Test L2 Loss :  4.160551569483301  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  482  Time:  10.695  Rel. Train L2 Loss :  0.001809590045362711  Rel. Test L2 Loss :  0.06779175406103735  Test L2 Loss :  4.160778853270385  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  483  Time:  10.635  Rel. Train L2 Loss :  0.0017954888194799423  Rel. Test L2 Loss :  0.06779481000728435  Test L2 Loss :  4.1609490884316935  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  484  Time:  10.655  Rel. Train L2 Loss :  0.0017845772849395872  Rel. Test L2 Loss :  0.06780164547868676  Test L2 Loss :  4.161371918411942  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  485  Time:  10.667  Rel. Train L2 Loss :  0.0017740660384297372  Rel. Test L2 Loss :  0.06780081074517053  Test L2 Loss :  4.161317155167863  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  486  Time:  10.62  Rel. Train L2 Loss :  0.0017629874851554633  Rel. Test L2 Loss :  0.06780559388366905  Test L2 Loss :  4.161606195810679  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  487  Time:  10.622  Rel. Train L2 Loss :  0.0017519493009895085  Rel. Test L2 Loss :  0.06780842322487014  Test L2 Loss :  4.161786397298177  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  488  Time:  10.637  Rel. Train L2 Loss :  0.0017423894684761763  Rel. Test L2 Loss :  0.06780897550754719  Test L2 Loss :  4.161812361296232  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  489  Time:  10.625  Rel. Train L2 Loss :  0.0017331491950899362  Rel. Test L2 Loss :  0.06781232974550745  Test L2 Loss :  4.1620222383791265  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  490  Time:  10.626  Rel. Train L2 Loss :  0.001723655678331852  Rel. Test L2 Loss :  0.0678150959917017  Test L2 Loss :  4.162194483988994  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  491  Time:  10.617  Rel. Train L2 Loss :  0.0017142449282109738  Rel. Test L2 Loss :  0.06781506189354905  Test L2 Loss :  4.162186150078301  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  492  Time:  10.631  Rel. Train L2 Loss :  0.0017074866192415357  Rel. Test L2 Loss :  0.06781687500240567  Test L2 Loss :  4.162303151311101  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  493  Time:  10.626  Rel. Train L2 Loss :  0.001701080607250333  Rel. Test L2 Loss :  0.06782001337489567  Test L2 Loss :  4.162491033743094  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  494  Time:  10.629  Rel. Train L2 Loss :  0.0016955207213759423  Rel. Test L2 Loss :  0.06781887041555869  Test L2 Loss :  4.162420479027  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  495  Time:  10.629  Rel. Train L2 Loss :  0.0016884346231818199  Rel. Test L2 Loss :  0.06782744167087314  Test L2 Loss :  4.162933555809227  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  496  Time:  10.783  Rel. Train L2 Loss :  0.0016818788945674897  Rel. Test L2 Loss :  0.0678238159901387  Test L2 Loss :  4.162724469159101  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  497  Time:  10.628  Rel. Train L2 Loss :  0.0016771292826160788  Rel. Test L2 Loss :  0.06782732997928653  Test L2 Loss :  4.162934569625167  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  498  Time:  10.614  Rel. Train L2 Loss :  0.0016705467747524382  Rel. Test L2 Loss :  0.06783143061775344  Test L2 Loss :  4.163170410706116  inv_L_scale:  [1.0, 1.0, 1.0]
Epoch :  499  Time:  10.611  Rel. Train L2 Loss :  0.0016659113857895136  Rel. Test L2 Loss :  0.06783296181274964  Test L2 Loss :  4.1632746962813645  inv_L_scale:  [1.0, 1.0, 1.0]
