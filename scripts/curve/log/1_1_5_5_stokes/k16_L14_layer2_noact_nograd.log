Loading data from  ../../data/curve//pcno_curve_data_1_1_5_5_stokes.npz
(1000,) (1000, 1000, 1) (1000, 1000, 2)
use normalized raw measures
Casting to tensor
x_train shape torch.Size([900, 1000, 6]), y_train shape torch.Size([900, 1000, 1])
length of each dim:  tensor([6.6455335617065430, 6.6654777526855469])
kmax = 16
L =  14
In PCNO_train, ndims =  2
Epoch :  0  Time:  1.005  Rel. Train L2 Loss :  0.39640671173731484  Rel. Test L2 Loss :  0.22924378216266633  Test L2 Loss :  0.44146350145339963  inv_L_scale:  [1.0, 1.0]
Epoch :  1  Time:  0.746  Rel. Train L2 Loss :  0.18616369316975276  Rel. Test L2 Loss :  0.15486588597297668  Test L2 Loss :  0.2917732048034668  inv_L_scale:  [1.0, 1.0]
Epoch :  2  Time:  0.745  Rel. Train L2 Loss :  0.13831088499890434  Rel. Test L2 Loss :  0.11465386480093002  Test L2 Loss :  0.21130352318286896  inv_L_scale:  [1.0, 1.0]
Epoch :  3  Time:  0.743  Rel. Train L2 Loss :  0.1166272756126192  Rel. Test L2 Loss :  0.10959063887596131  Test L2 Loss :  0.2014884126186371  inv_L_scale:  [1.0, 1.0]
Epoch :  4  Time:  0.746  Rel. Train L2 Loss :  0.10169195148679945  Rel. Test L2 Loss :  0.10391894042491913  Test L2 Loss :  0.18976356506347655  inv_L_scale:  [1.0, 1.0]
Epoch :  5  Time:  0.743  Rel. Train L2 Loss :  0.09485435866647296  Rel. Test L2 Loss :  0.09961651980876923  Test L2 Loss :  0.17885929584503174  inv_L_scale:  [1.0, 1.0]
Epoch :  6  Time:  0.744  Rel. Train L2 Loss :  0.08797753827439414  Rel. Test L2 Loss :  0.09666878640651703  Test L2 Loss :  0.17356091976165772  inv_L_scale:  [1.0, 1.0]
Epoch :  7  Time:  0.743  Rel. Train L2 Loss :  0.0841185438964102  Rel. Test L2 Loss :  0.08821662485599518  Test L2 Loss :  0.158164142370224  inv_L_scale:  [1.0, 1.0]
Epoch :  8  Time:  0.743  Rel. Train L2 Loss :  0.08443987435764737  Rel. Test L2 Loss :  0.08673590183258056  Test L2 Loss :  0.15790109276771547  inv_L_scale:  [1.0, 1.0]
Epoch :  9  Time:  0.744  Rel. Train L2 Loss :  0.07758903053071764  Rel. Test L2 Loss :  0.07978473544120789  Test L2 Loss :  0.14500433564186097  inv_L_scale:  [1.0, 1.0]
Epoch :  10  Time:  0.744  Rel. Train L2 Loss :  0.07298237141635683  Rel. Test L2 Loss :  0.08020714044570923  Test L2 Loss :  0.1431840467453003  inv_L_scale:  [1.0, 1.0]
Epoch :  11  Time:  0.743  Rel. Train L2 Loss :  0.07315732040339046  Rel. Test L2 Loss :  0.07920504510402679  Test L2 Loss :  0.14221576750278472  inv_L_scale:  [1.0, 1.0]
Epoch :  12  Time:  0.743  Rel. Train L2 Loss :  0.0707448258664873  Rel. Test L2 Loss :  0.07687055170536042  Test L2 Loss :  0.13637115836143493  inv_L_scale:  [1.0, 1.0]
Epoch :  13  Time:  0.744  Rel. Train L2 Loss :  0.07031638873947992  Rel. Test L2 Loss :  0.07618335992097855  Test L2 Loss :  0.13575299263000487  inv_L_scale:  [1.0, 1.0]
Epoch :  14  Time:  0.744  Rel. Train L2 Loss :  0.0691628286573622  Rel. Test L2 Loss :  0.07632708668708801  Test L2 Loss :  0.1353079319000244  inv_L_scale:  [1.0, 1.0]
Epoch :  15  Time:  0.742  Rel. Train L2 Loss :  0.06982441905472014  Rel. Test L2 Loss :  0.07069274485111236  Test L2 Loss :  0.12519618213176728  inv_L_scale:  [1.0, 1.0]
Epoch :  16  Time:  0.745  Rel. Train L2 Loss :  0.06723122401369942  Rel. Test L2 Loss :  0.07514072433114052  Test L2 Loss :  0.13298424899578096  inv_L_scale:  [1.0, 1.0]
Epoch :  17  Time:  0.744  Rel. Train L2 Loss :  0.06913722525040308  Rel. Test L2 Loss :  0.07434410214424134  Test L2 Loss :  0.13091045886278152  inv_L_scale:  [1.0, 1.0]
Epoch :  18  Time:  0.743  Rel. Train L2 Loss :  0.06595244059960047  Rel. Test L2 Loss :  0.06996783137321472  Test L2 Loss :  0.12232158988714219  inv_L_scale:  [1.0, 1.0]
Epoch :  19  Time:  0.743  Rel. Train L2 Loss :  0.06541199035114713  Rel. Test L2 Loss :  0.0719474895298481  Test L2 Loss :  0.12611955404281616  inv_L_scale:  [1.0, 1.0]
Epoch :  20  Time:  0.742  Rel. Train L2 Loss :  0.06722538795736101  Rel. Test L2 Loss :  0.07301416367292404  Test L2 Loss :  0.1299811202287674  inv_L_scale:  [1.0, 1.0]
Epoch :  21  Time:  0.742  Rel. Train L2 Loss :  0.06645705742968454  Rel. Test L2 Loss :  0.06723078787326812  Test L2 Loss :  0.11922391504049301  inv_L_scale:  [1.0, 1.0]
Epoch :  22  Time:  0.743  Rel. Train L2 Loss :  0.06199016339249081  Rel. Test L2 Loss :  0.07295202016830445  Test L2 Loss :  0.1285365891456604  inv_L_scale:  [1.0, 1.0]
Epoch :  23  Time:  0.743  Rel. Train L2 Loss :  0.0642210719982783  Rel. Test L2 Loss :  0.07137185156345367  Test L2 Loss :  0.12578607380390167  inv_L_scale:  [1.0, 1.0]
Epoch :  24  Time:  0.743  Rel. Train L2 Loss :  0.06480840750866466  Rel. Test L2 Loss :  0.06871534630656242  Test L2 Loss :  0.12129379570484161  inv_L_scale:  [1.0, 1.0]
Epoch :  25  Time:  0.743  Rel. Train L2 Loss :  0.06471148143212001  Rel. Test L2 Loss :  0.0639754842221737  Test L2 Loss :  0.112121701836586  inv_L_scale:  [1.0, 1.0]
Epoch :  26  Time:  0.745  Rel. Train L2 Loss :  0.06094336092472077  Rel. Test L2 Loss :  0.06483840242028237  Test L2 Loss :  0.11383007526397705  inv_L_scale:  [1.0, 1.0]
Epoch :  27  Time:  0.745  Rel. Train L2 Loss :  0.06253591891792086  Rel. Test L2 Loss :  0.06258459478616714  Test L2 Loss :  0.11013544678688049  inv_L_scale:  [1.0, 1.0]
Epoch :  28  Time:  0.743  Rel. Train L2 Loss :  0.06249541663461261  Rel. Test L2 Loss :  0.0725665533542633  Test L2 Loss :  0.12835743218660356  inv_L_scale:  [1.0, 1.0]
Epoch :  29  Time:  0.743  Rel. Train L2 Loss :  0.06227736458182335  Rel. Test L2 Loss :  0.0676295256614685  Test L2 Loss :  0.11905838876962661  inv_L_scale:  [1.0, 1.0]
Epoch :  30  Time:  0.743  Rel. Train L2 Loss :  0.0625367753373252  Rel. Test L2 Loss :  0.06777228698134423  Test L2 Loss :  0.11867666482925415  inv_L_scale:  [1.0, 1.0]
Epoch :  31  Time:  0.744  Rel. Train L2 Loss :  0.06055979112784068  Rel. Test L2 Loss :  0.06433940440416336  Test L2 Loss :  0.11308722227811813  inv_L_scale:  [1.0, 1.0]
Epoch :  32  Time:  0.743  Rel. Train L2 Loss :  0.06090100662575828  Rel. Test L2 Loss :  0.06249395787715912  Test L2 Loss :  0.109533731341362  inv_L_scale:  [1.0, 1.0]
Epoch :  33  Time:  0.743  Rel. Train L2 Loss :  0.05942421784003576  Rel. Test L2 Loss :  0.06446479678153992  Test L2 Loss :  0.11322075366973877  inv_L_scale:  [1.0, 1.0]
Epoch :  34  Time:  0.743  Rel. Train L2 Loss :  0.06012095135119226  Rel. Test L2 Loss :  0.06268285989761352  Test L2 Loss :  0.10950663924217224  inv_L_scale:  [1.0, 1.0]
Epoch :  35  Time:  0.743  Rel. Train L2 Loss :  0.059018132156795924  Rel. Test L2 Loss :  0.06773343801498413  Test L2 Loss :  0.1206138402223587  inv_L_scale:  [1.0, 1.0]
Epoch :  36  Time:  0.745  Rel. Train L2 Loss :  0.0611181531018681  Rel. Test L2 Loss :  0.061813766062259676  Test L2 Loss :  0.10890242576599121  inv_L_scale:  [1.0, 1.0]
Epoch :  37  Time:  0.744  Rel. Train L2 Loss :  0.05893653195765283  Rel. Test L2 Loss :  0.06129579305648804  Test L2 Loss :  0.10665054142475128  inv_L_scale:  [1.0, 1.0]
Epoch :  38  Time:  0.743  Rel. Train L2 Loss :  0.059698231120904284  Rel. Test L2 Loss :  0.06425161629915238  Test L2 Loss :  0.1122695928812027  inv_L_scale:  [1.0, 1.0]
Epoch :  39  Time:  0.743  Rel. Train L2 Loss :  0.06002824008464813  Rel. Test L2 Loss :  0.06460138857364654  Test L2 Loss :  0.11424343824386597  inv_L_scale:  [1.0, 1.0]
Epoch :  40  Time:  0.742  Rel. Train L2 Loss :  0.06152057389418284  Rel. Test L2 Loss :  0.06450598105788231  Test L2 Loss :  0.11480580508708954  inv_L_scale:  [1.0, 1.0]
Epoch :  41  Time:  0.743  Rel. Train L2 Loss :  0.05910425148076481  Rel. Test L2 Loss :  0.06131997212767601  Test L2 Loss :  0.10638158559799195  inv_L_scale:  [1.0, 1.0]
Epoch :  42  Time:  0.744  Rel. Train L2 Loss :  0.05821958644522561  Rel. Test L2 Loss :  0.06059868827462196  Test L2 Loss :  0.10538602650165557  inv_L_scale:  [1.0, 1.0]
Epoch :  43  Time:  0.743  Rel. Train L2 Loss :  0.05950066453880734  Rel. Test L2 Loss :  0.06389094680547715  Test L2 Loss :  0.11150485694408417  inv_L_scale:  [1.0, 1.0]
Epoch :  44  Time:  0.742  Rel. Train L2 Loss :  0.058879602981938256  Rel. Test L2 Loss :  0.05976460307836533  Test L2 Loss :  0.10464553236961364  inv_L_scale:  [1.0, 1.0]
Epoch :  45  Time:  0.743  Rel. Train L2 Loss :  0.05925645391146342  Rel. Test L2 Loss :  0.06163573414087296  Test L2 Loss :  0.10691663146018981  inv_L_scale:  [1.0, 1.0]
Epoch :  46  Time:  0.743  Rel. Train L2 Loss :  0.05853418567114406  Rel. Test L2 Loss :  0.06099144548177719  Test L2 Loss :  0.10654139995574952  inv_L_scale:  [1.0, 1.0]
Epoch :  47  Time:  0.743  Rel. Train L2 Loss :  0.060042145897944765  Rel. Test L2 Loss :  0.06855944842100144  Test L2 Loss :  0.1197471222281456  inv_L_scale:  [1.0, 1.0]
Epoch :  48  Time:  0.745  Rel. Train L2 Loss :  0.05989565360877249  Rel. Test L2 Loss :  0.060030245929956434  Test L2 Loss :  0.10513733565807343  inv_L_scale:  [1.0, 1.0]
Epoch :  49  Time:  0.744  Rel. Train L2 Loss :  0.05820101160142157  Rel. Test L2 Loss :  0.05953052431344986  Test L2 Loss :  0.10480846017599106  inv_L_scale:  [1.0, 1.0]
Epoch :  50  Time:  0.743  Rel. Train L2 Loss :  0.058358646581570306  Rel. Test L2 Loss :  0.05927808701992035  Test L2 Loss :  0.10299726128578186  inv_L_scale:  [1.0, 1.0]
Epoch :  51  Time:  0.743  Rel. Train L2 Loss :  0.056684522231419884  Rel. Test L2 Loss :  0.060446370542049405  Test L2 Loss :  0.10501526057720184  inv_L_scale:  [1.0, 1.0]
Epoch :  52  Time:  0.742  Rel. Train L2 Loss :  0.05733931435479058  Rel. Test L2 Loss :  0.057973985373973844  Test L2 Loss :  0.10056359261274338  inv_L_scale:  [1.0, 1.0]
Epoch :  53  Time:  0.743  Rel. Train L2 Loss :  0.05704992413520813  Rel. Test L2 Loss :  0.06164440855383873  Test L2 Loss :  0.10823805153369903  inv_L_scale:  [1.0, 1.0]
Epoch :  54  Time:  0.743  Rel. Train L2 Loss :  0.056641610827710895  Rel. Test L2 Loss :  0.06172997429966927  Test L2 Loss :  0.10726383835077286  inv_L_scale:  [1.0, 1.0]
Epoch :  55  Time:  0.744  Rel. Train L2 Loss :  0.05729107038842307  Rel. Test L2 Loss :  0.06065920501947403  Test L2 Loss :  0.10739543318748473  inv_L_scale:  [1.0, 1.0]
Epoch :  56  Time:  0.743  Rel. Train L2 Loss :  0.0569626606338554  Rel. Test L2 Loss :  0.06046776920557022  Test L2 Loss :  0.1056449669599533  inv_L_scale:  [1.0, 1.0]
Epoch :  57  Time:  0.743  Rel. Train L2 Loss :  0.05752604651782248  Rel. Test L2 Loss :  0.05666905403137207  Test L2 Loss :  0.09831697702407836  inv_L_scale:  [1.0, 1.0]
Epoch :  58  Time:  0.743  Rel. Train L2 Loss :  0.05634494822886255  Rel. Test L2 Loss :  0.05717973798513412  Test L2 Loss :  0.09940653443336486  inv_L_scale:  [1.0, 1.0]
Epoch :  59  Time:  0.743  Rel. Train L2 Loss :  0.05557187851932314  Rel. Test L2 Loss :  0.06096514910459518  Test L2 Loss :  0.10684798508882523  inv_L_scale:  [1.0, 1.0]
Epoch :  60  Time:  0.743  Rel. Train L2 Loss :  0.056125498943858675  Rel. Test L2 Loss :  0.058048449754714966  Test L2 Loss :  0.10082276433706283  inv_L_scale:  [1.0, 1.0]
Epoch :  61  Time:  0.743  Rel. Train L2 Loss :  0.05568168408340878  Rel. Test L2 Loss :  0.058328937143087387  Test L2 Loss :  0.1023085618019104  inv_L_scale:  [1.0, 1.0]
Epoch :  62  Time:  0.745  Rel. Train L2 Loss :  0.05482937052845955  Rel. Test L2 Loss :  0.06049518883228302  Test L2 Loss :  0.10594184517860412  inv_L_scale:  [1.0, 1.0]
Epoch :  63  Time:  0.744  Rel. Train L2 Loss :  0.05603107863002353  Rel. Test L2 Loss :  0.05652657389640808  Test L2 Loss :  0.09936152070760727  inv_L_scale:  [1.0, 1.0]
Epoch :  64  Time:  0.743  Rel. Train L2 Loss :  0.054993676443894704  Rel. Test L2 Loss :  0.061365647315979  Test L2 Loss :  0.1069328373670578  inv_L_scale:  [1.0, 1.0]
Epoch :  65  Time:  0.743  Rel. Train L2 Loss :  0.05476027470495966  Rel. Test L2 Loss :  0.05753303736448288  Test L2 Loss :  0.10030888378620148  inv_L_scale:  [1.0, 1.0]
Epoch :  66  Time:  0.743  Rel. Train L2 Loss :  0.05511727636059125  Rel. Test L2 Loss :  0.059142680764198305  Test L2 Loss :  0.10275220155715942  inv_L_scale:  [1.0, 1.0]
Epoch :  67  Time:  0.743  Rel. Train L2 Loss :  0.054741010533438786  Rel. Test L2 Loss :  0.060094050765037536  Test L2 Loss :  0.10534451276063919  inv_L_scale:  [1.0, 1.0]
Epoch :  68  Time:  0.742  Rel. Train L2 Loss :  0.05597346486316787  Rel. Test L2 Loss :  0.06388051301240921  Test L2 Loss :  0.11474007815122604  inv_L_scale:  [1.0, 1.0]
Epoch :  69  Time:  0.743  Rel. Train L2 Loss :  0.05520616130696403  Rel. Test L2 Loss :  0.06388407051563263  Test L2 Loss :  0.10933790862560272  inv_L_scale:  [1.0, 1.0]
Epoch :  70  Time:  0.744  Rel. Train L2 Loss :  0.0564514886505074  Rel. Test L2 Loss :  0.05620258450508118  Test L2 Loss :  0.09802384376525879  inv_L_scale:  [1.0, 1.0]
Epoch :  71  Time:  0.743  Rel. Train L2 Loss :  0.05423682802253299  Rel. Test L2 Loss :  0.05999377027153969  Test L2 Loss :  0.10457019686698914  inv_L_scale:  [1.0, 1.0]
Epoch :  72  Time:  0.743  Rel. Train L2 Loss :  0.05381683246956931  Rel. Test L2 Loss :  0.05579241618514061  Test L2 Loss :  0.09741290450096131  inv_L_scale:  [1.0, 1.0]
Epoch :  73  Time:  0.743  Rel. Train L2 Loss :  0.05345659613609314  Rel. Test L2 Loss :  0.05875928103923798  Test L2 Loss :  0.10183010905981064  inv_L_scale:  [1.0, 1.0]
Epoch :  74  Time:  0.743  Rel. Train L2 Loss :  0.05376387806402312  Rel. Test L2 Loss :  0.05712014317512512  Test L2 Loss :  0.0984292009472847  inv_L_scale:  [1.0, 1.0]
Epoch :  75  Time:  0.743  Rel. Train L2 Loss :  0.054828726450602217  Rel. Test L2 Loss :  0.05847370788455009  Test L2 Loss :  0.10276101678609847  inv_L_scale:  [1.0, 1.0]
Epoch :  76  Time:  0.743  Rel. Train L2 Loss :  0.053858290612697604  Rel. Test L2 Loss :  0.05638769537210465  Test L2 Loss :  0.09978827238082885  inv_L_scale:  [1.0, 1.0]
Epoch :  77  Time:  0.743  Rel. Train L2 Loss :  0.054144332624144025  Rel. Test L2 Loss :  0.05766639441251755  Test L2 Loss :  0.10008192330598831  inv_L_scale:  [1.0, 1.0]
Epoch :  78  Time:  0.743  Rel. Train L2 Loss :  0.05395162847306993  Rel. Test L2 Loss :  0.05685120075941086  Test L2 Loss :  0.09852861821651458  inv_L_scale:  [1.0, 1.0]
Epoch :  79  Time:  0.744  Rel. Train L2 Loss :  0.05267232606808345  Rel. Test L2 Loss :  0.05500375673174858  Test L2 Loss :  0.09664857566356659  inv_L_scale:  [1.0, 1.0]
Epoch :  80  Time:  0.744  Rel. Train L2 Loss :  0.05301053335269292  Rel. Test L2 Loss :  0.05800839930772781  Test L2 Loss :  0.10287713497877121  inv_L_scale:  [1.0, 1.0]
Epoch :  81  Time:  0.743  Rel. Train L2 Loss :  0.05341253611776564  Rel. Test L2 Loss :  0.06033706337213516  Test L2 Loss :  0.1049898773431778  inv_L_scale:  [1.0, 1.0]
Epoch :  82  Time:  0.743  Rel. Train L2 Loss :  0.052982572548919256  Rel. Test L2 Loss :  0.057397351115942  Test L2 Loss :  0.10004817932844162  inv_L_scale:  [1.0, 1.0]
Epoch :  83  Time:  0.743  Rel. Train L2 Loss :  0.053513350354300604  Rel. Test L2 Loss :  0.05934170961380005  Test L2 Loss :  0.10255070894956589  inv_L_scale:  [1.0, 1.0]
Epoch :  84  Time:  0.743  Rel. Train L2 Loss :  0.05267456753386392  Rel. Test L2 Loss :  0.054648901224136355  Test L2 Loss :  0.09490668654441833  inv_L_scale:  [1.0, 1.0]
Epoch :  85  Time:  0.743  Rel. Train L2 Loss :  0.052567574861976836  Rel. Test L2 Loss :  0.05476852431893349  Test L2 Loss :  0.09502673029899597  inv_L_scale:  [1.0, 1.0]
Epoch :  86  Time:  0.743  Rel. Train L2 Loss :  0.05235090371635225  Rel. Test L2 Loss :  0.05384328067302704  Test L2 Loss :  0.09393064856529236  inv_L_scale:  [1.0, 1.0]
Epoch :  87  Time:  0.743  Rel. Train L2 Loss :  0.052381768226623535  Rel. Test L2 Loss :  0.05418939352035523  Test L2 Loss :  0.09479123294353485  inv_L_scale:  [1.0, 1.0]
Epoch :  88  Time:  0.743  Rel. Train L2 Loss :  0.052495379994312925  Rel. Test L2 Loss :  0.05620472192764282  Test L2 Loss :  0.09841524571180343  inv_L_scale:  [1.0, 1.0]
Epoch :  89  Time:  0.744  Rel. Train L2 Loss :  0.05205866383181678  Rel. Test L2 Loss :  0.05690748631954193  Test L2 Loss :  0.09874366581439972  inv_L_scale:  [1.0, 1.0]
Epoch :  90  Time:  0.743  Rel. Train L2 Loss :  0.051756972405645585  Rel. Test L2 Loss :  0.058235952854156496  Test L2 Loss :  0.10315546333789825  inv_L_scale:  [1.0, 1.0]
Epoch :  91  Time:  0.743  Rel. Train L2 Loss :  0.05198391949137052  Rel. Test L2 Loss :  0.06325361892580986  Test L2 Loss :  0.11194065511226654  inv_L_scale:  [1.0, 1.0]
Epoch :  92  Time:  0.742  Rel. Train L2 Loss :  0.05088331249025133  Rel. Test L2 Loss :  0.0527083346247673  Test L2 Loss :  0.09187078058719635  inv_L_scale:  [1.0, 1.0]
Epoch :  93  Time:  0.743  Rel. Train L2 Loss :  0.05198775087793668  Rel. Test L2 Loss :  0.056854911148548126  Test L2 Loss :  0.09876581072807313  inv_L_scale:  [1.0, 1.0]
Epoch :  94  Time:  0.743  Rel. Train L2 Loss :  0.05135535796483358  Rel. Test L2 Loss :  0.05928723901510238  Test L2 Loss :  0.10371991366147995  inv_L_scale:  [1.0, 1.0]
Epoch :  95  Time:  0.742  Rel. Train L2 Loss :  0.05090165437923538  Rel. Test L2 Loss :  0.05510827600955963  Test L2 Loss :  0.09623937100172043  inv_L_scale:  [1.0, 1.0]
Epoch :  96  Time:  0.742  Rel. Train L2 Loss :  0.05094711277219984  Rel. Test L2 Loss :  0.0570271646976471  Test L2 Loss :  0.09875216454267502  inv_L_scale:  [1.0, 1.0]
Epoch :  97  Time:  0.742  Rel. Train L2 Loss :  0.05097546925147375  Rel. Test L2 Loss :  0.054981665462255476  Test L2 Loss :  0.09545236498117447  inv_L_scale:  [1.0, 1.0]
Epoch :  98  Time:  0.742  Rel. Train L2 Loss :  0.05115804589456982  Rel. Test L2 Loss :  0.06016252905130386  Test L2 Loss :  0.10455783367156983  inv_L_scale:  [1.0, 1.0]
Epoch :  99  Time:  0.743  Rel. Train L2 Loss :  0.0510789155960083  Rel. Test L2 Loss :  0.054796375930309296  Test L2 Loss :  0.09483008444309235  inv_L_scale:  [1.0, 1.0]
Epoch :  100  Time:  0.746  Rel. Train L2 Loss :  0.05000474906629986  Rel. Test L2 Loss :  0.05389220178127289  Test L2 Loss :  0.09328982830047608  inv_L_scale:  [1.0, 1.0]
Epoch :  101  Time:  0.743  Rel. Train L2 Loss :  0.05130997497174475  Rel. Test L2 Loss :  0.053541221022605896  Test L2 Loss :  0.09231978476047516  inv_L_scale:  [1.0, 1.0]
Epoch :  102  Time:  0.743  Rel. Train L2 Loss :  0.05071334199772941  Rel. Test L2 Loss :  0.05468286797404289  Test L2 Loss :  0.09611583828926086  inv_L_scale:  [1.0, 1.0]
Epoch :  103  Time:  0.742  Rel. Train L2 Loss :  0.050706707139809924  Rel. Test L2 Loss :  0.05293793797492981  Test L2 Loss :  0.09179096817970275  inv_L_scale:  [1.0, 1.0]
Epoch :  104  Time:  0.742  Rel. Train L2 Loss :  0.050506610009405345  Rel. Test L2 Loss :  0.05298518434166908  Test L2 Loss :  0.09189935028553009  inv_L_scale:  [1.0, 1.0]
Epoch :  105  Time:  0.743  Rel. Train L2 Loss :  0.05063404500484467  Rel. Test L2 Loss :  0.05402076601982117  Test L2 Loss :  0.09344523578882218  inv_L_scale:  [1.0, 1.0]
Epoch :  106  Time:  0.743  Rel. Train L2 Loss :  0.050257960326141785  Rel. Test L2 Loss :  0.05615392744541168  Test L2 Loss :  0.09734845638275147  inv_L_scale:  [1.0, 1.0]
Epoch :  107  Time:  0.742  Rel. Train L2 Loss :  0.05003872609800763  Rel. Test L2 Loss :  0.058431123495101926  Test L2 Loss :  0.10180874079465867  inv_L_scale:  [1.0, 1.0]
Epoch :  108  Time:  0.742  Rel. Train L2 Loss :  0.05085089517964257  Rel. Test L2 Loss :  0.057012785077095035  Test L2 Loss :  0.09987276524305344  inv_L_scale:  [1.0, 1.0]
Epoch :  109  Time:  0.742  Rel. Train L2 Loss :  0.04968161082930035  Rel. Test L2 Loss :  0.051695561110973356  Test L2 Loss :  0.08907733619213104  inv_L_scale:  [1.0, 1.0]
Epoch :  110  Time:  0.742  Rel. Train L2 Loss :  0.04944214501314693  Rel. Test L2 Loss :  0.05240287661552429  Test L2 Loss :  0.09074564784765243  inv_L_scale:  [1.0, 1.0]
Epoch :  111  Time:  0.743  Rel. Train L2 Loss :  0.04961630827850766  Rel. Test L2 Loss :  0.05177458494901657  Test L2 Loss :  0.08962581038475037  inv_L_scale:  [1.0, 1.0]
Epoch :  112  Time:  0.743  Rel. Train L2 Loss :  0.0494646218419075  Rel. Test L2 Loss :  0.05273798167705536  Test L2 Loss :  0.09219032019376755  inv_L_scale:  [1.0, 1.0]
Epoch :  113  Time:  0.742  Rel. Train L2 Loss :  0.04932043236162927  Rel. Test L2 Loss :  0.05567841529846192  Test L2 Loss :  0.09741645276546479  inv_L_scale:  [1.0, 1.0]
Epoch :  114  Time:  0.743  Rel. Train L2 Loss :  0.04953929121295611  Rel. Test L2 Loss :  0.0535554575920105  Test L2 Loss :  0.09322104036808014  inv_L_scale:  [1.0, 1.0]
Epoch :  115  Time:  0.743  Rel. Train L2 Loss :  0.0496230482061704  Rel. Test L2 Loss :  0.05424455612897873  Test L2 Loss :  0.09522767901420594  inv_L_scale:  [1.0, 1.0]
Epoch :  116  Time:  0.742  Rel. Train L2 Loss :  0.049633379909727306  Rel. Test L2 Loss :  0.05141533344984055  Test L2 Loss :  0.08979938954114913  inv_L_scale:  [1.0, 1.0]
Epoch :  117  Time:  0.743  Rel. Train L2 Loss :  0.048666269232829414  Rel. Test L2 Loss :  0.05071611776947975  Test L2 Loss :  0.08783666491508484  inv_L_scale:  [1.0, 1.0]
Epoch :  118  Time:  0.742  Rel. Train L2 Loss :  0.048991332832309935  Rel. Test L2 Loss :  0.056127152144908904  Test L2 Loss :  0.09794527649879456  inv_L_scale:  [1.0, 1.0]
Epoch :  119  Time:  0.742  Rel. Train L2 Loss :  0.0494916771683428  Rel. Test L2 Loss :  0.0504931914806366  Test L2 Loss :  0.08786819368600846  inv_L_scale:  [1.0, 1.0]
Epoch :  120  Time:  0.742  Rel. Train L2 Loss :  0.04968511594666375  Rel. Test L2 Loss :  0.05484189987182617  Test L2 Loss :  0.09615123242139817  inv_L_scale:  [1.0, 1.0]
Epoch :  121  Time:  0.742  Rel. Train L2 Loss :  0.04906159632735782  Rel. Test L2 Loss :  0.05097624242305756  Test L2 Loss :  0.08777230679988861  inv_L_scale:  [1.0, 1.0]
Epoch :  122  Time:  0.743  Rel. Train L2 Loss :  0.049034968449009786  Rel. Test L2 Loss :  0.05218435198068619  Test L2 Loss :  0.09002177149057389  inv_L_scale:  [1.0, 1.0]
Epoch :  123  Time:  0.743  Rel. Train L2 Loss :  0.04909134566783905  Rel. Test L2 Loss :  0.05074142515659332  Test L2 Loss :  0.08766603410243988  inv_L_scale:  [1.0, 1.0]
Epoch :  124  Time:  0.745  Rel. Train L2 Loss :  0.04895146457685365  Rel. Test L2 Loss :  0.05170167699456215  Test L2 Loss :  0.08960469454526901  inv_L_scale:  [1.0, 1.0]
Epoch :  125  Time:  0.744  Rel. Train L2 Loss :  0.048661897761954204  Rel. Test L2 Loss :  0.05222301423549652  Test L2 Loss :  0.09082020342350006  inv_L_scale:  [1.0, 1.0]
Epoch :  126  Time:  0.742  Rel. Train L2 Loss :  0.04835424416595035  Rel. Test L2 Loss :  0.0510384164750576  Test L2 Loss :  0.08854698032140731  inv_L_scale:  [1.0, 1.0]
Epoch :  127  Time:  0.742  Rel. Train L2 Loss :  0.04882105554143588  Rel. Test L2 Loss :  0.05432367250323296  Test L2 Loss :  0.0957990062236786  inv_L_scale:  [1.0, 1.0]
Epoch :  128  Time:  0.742  Rel. Train L2 Loss :  0.04907929930422041  Rel. Test L2 Loss :  0.051784357130527495  Test L2 Loss :  0.08978747189044953  inv_L_scale:  [1.0, 1.0]
Epoch :  129  Time:  0.743  Rel. Train L2 Loss :  0.04898721698257658  Rel. Test L2 Loss :  0.05295790314674378  Test L2 Loss :  0.09193545401096344  inv_L_scale:  [1.0, 1.0]
Epoch :  130  Time:  0.742  Rel. Train L2 Loss :  0.048699832061926525  Rel. Test L2 Loss :  0.051860196888446806  Test L2 Loss :  0.08935586899518967  inv_L_scale:  [1.0, 1.0]
Epoch :  131  Time:  0.743  Rel. Train L2 Loss :  0.04844226843780942  Rel. Test L2 Loss :  0.053970694839954376  Test L2 Loss :  0.09349350392818451  inv_L_scale:  [1.0, 1.0]
Epoch :  132  Time:  0.742  Rel. Train L2 Loss :  0.04898294193877114  Rel. Test L2 Loss :  0.053518010079860685  Test L2 Loss :  0.09206034243106842  inv_L_scale:  [1.0, 1.0]
Epoch :  133  Time:  0.742  Rel. Train L2 Loss :  0.04929406611455811  Rel. Test L2 Loss :  0.05180624306201935  Test L2 Loss :  0.08987313687801361  inv_L_scale:  [1.0, 1.0]
Epoch :  134  Time:  0.742  Rel. Train L2 Loss :  0.04856850392288632  Rel. Test L2 Loss :  0.05379953026771545  Test L2 Loss :  0.09293390154838561  inv_L_scale:  [1.0, 1.0]
Epoch :  135  Time:  0.742  Rel. Train L2 Loss :  0.048311153418487976  Rel. Test L2 Loss :  0.050310327410697936  Test L2 Loss :  0.0865987241268158  inv_L_scale:  [1.0, 1.0]
Epoch :  136  Time:  0.742  Rel. Train L2 Loss :  0.04858795220653216  Rel. Test L2 Loss :  0.05182272240519523  Test L2 Loss :  0.09016740083694458  inv_L_scale:  [1.0, 1.0]
Epoch :  137  Time:  0.742  Rel. Train L2 Loss :  0.048206459350056116  Rel. Test L2 Loss :  0.05340980470180511  Test L2 Loss :  0.0925365287065506  inv_L_scale:  [1.0, 1.0]
Epoch :  138  Time:  0.744  Rel. Train L2 Loss :  0.04839776037467851  Rel. Test L2 Loss :  0.05097582265734672  Test L2 Loss :  0.08755912572145462  inv_L_scale:  [1.0, 1.0]
Epoch :  139  Time:  0.743  Rel. Train L2 Loss :  0.04785081254111396  Rel. Test L2 Loss :  0.05231986820697784  Test L2 Loss :  0.09130027949810028  inv_L_scale:  [1.0, 1.0]
Epoch :  140  Time:  0.742  Rel. Train L2 Loss :  0.04900489134920968  Rel. Test L2 Loss :  0.05591576024889946  Test L2 Loss :  0.09749760419130325  inv_L_scale:  [1.0, 1.0]
Epoch :  141  Time:  0.742  Rel. Train L2 Loss :  0.04795832407143381  Rel. Test L2 Loss :  0.05476514011621475  Test L2 Loss :  0.09579857856035233  inv_L_scale:  [1.0, 1.0]
Epoch :  142  Time:  0.742  Rel. Train L2 Loss :  0.048430212901698216  Rel. Test L2 Loss :  0.05314419999718666  Test L2 Loss :  0.09225851505994796  inv_L_scale:  [1.0, 1.0]
Epoch :  143  Time:  0.742  Rel. Train L2 Loss :  0.04851786156495412  Rel. Test L2 Loss :  0.0514379695057869  Test L2 Loss :  0.08893429815769195  inv_L_scale:  [1.0, 1.0]
Epoch :  144  Time:  0.742  Rel. Train L2 Loss :  0.047655780365069705  Rel. Test L2 Loss :  0.05141457200050354  Test L2 Loss :  0.08909539341926574  inv_L_scale:  [1.0, 1.0]
Epoch :  145  Time:  0.743  Rel. Train L2 Loss :  0.04763208304842313  Rel. Test L2 Loss :  0.05222867697477341  Test L2 Loss :  0.09064704447984695  inv_L_scale:  [1.0, 1.0]
Epoch :  146  Time:  0.742  Rel. Train L2 Loss :  0.04851344774166743  Rel. Test L2 Loss :  0.05179798185825348  Test L2 Loss :  0.08999356985092163  inv_L_scale:  [1.0, 1.0]
Epoch :  147  Time:  0.743  Rel. Train L2 Loss :  0.04763405955500073  Rel. Test L2 Loss :  0.049916928112506864  Test L2 Loss :  0.08656826496124267  inv_L_scale:  [1.0, 1.0]
Epoch :  148  Time:  0.742  Rel. Train L2 Loss :  0.04773842869533433  Rel. Test L2 Loss :  0.049535469263792035  Test L2 Loss :  0.08556204378604888  inv_L_scale:  [1.0, 1.0]
Epoch :  149  Time:  0.742  Rel. Train L2 Loss :  0.04798429081837336  Rel. Test L2 Loss :  0.049584191888570786  Test L2 Loss :  0.08596580028533936  inv_L_scale:  [1.0, 1.0]
Epoch :  150  Time:  0.742  Rel. Train L2 Loss :  0.047927125179105336  Rel. Test L2 Loss :  0.04989255905151367  Test L2 Loss :  0.08609241932630539  inv_L_scale:  [1.0, 1.0]
Epoch :  151  Time:  0.742  Rel. Train L2 Loss :  0.04788166657090187  Rel. Test L2 Loss :  0.052757702469825744  Test L2 Loss :  0.09206125766038895  inv_L_scale:  [1.0, 1.0]
Epoch :  152  Time:  0.742  Rel. Train L2 Loss :  0.04759448849492603  Rel. Test L2 Loss :  0.052655045390129086  Test L2 Loss :  0.09064886271953583  inv_L_scale:  [1.0, 1.0]
Epoch :  153  Time:  0.742  Rel. Train L2 Loss :  0.04759005284971661  Rel. Test L2 Loss :  0.04938052639365196  Test L2 Loss :  0.08498263955116273  inv_L_scale:  [1.0, 1.0]
Epoch :  154  Time:  0.746  Rel. Train L2 Loss :  0.047191311203771166  Rel. Test L2 Loss :  0.05037166342139244  Test L2 Loss :  0.08678037226200104  inv_L_scale:  [1.0, 1.0]
Epoch :  155  Time:  0.743  Rel. Train L2 Loss :  0.04731459021568298  Rel. Test L2 Loss :  0.052635654360055927  Test L2 Loss :  0.09140795767307282  inv_L_scale:  [1.0, 1.0]
Epoch :  156  Time:  0.743  Rel. Train L2 Loss :  0.047765179425477984  Rel. Test L2 Loss :  0.05026708975434303  Test L2 Loss :  0.08695681899785995  inv_L_scale:  [1.0, 1.0]
Epoch :  157  Time:  0.742  Rel. Train L2 Loss :  0.047544407861100306  Rel. Test L2 Loss :  0.050262702405452726  Test L2 Loss :  0.08704127967357636  inv_L_scale:  [1.0, 1.0]
Epoch :  158  Time:  0.742  Rel. Train L2 Loss :  0.04719096001651552  Rel. Test L2 Loss :  0.05223018601536751  Test L2 Loss :  0.08988435566425323  inv_L_scale:  [1.0, 1.0]
Epoch :  159  Time:  0.742  Rel. Train L2 Loss :  0.047584028707610235  Rel. Test L2 Loss :  0.05291783720254898  Test L2 Loss :  0.09190351933240891  inv_L_scale:  [1.0, 1.0]
Epoch :  160  Time:  0.742  Rel. Train L2 Loss :  0.04736520296997494  Rel. Test L2 Loss :  0.05042498588562012  Test L2 Loss :  0.08689617872238159  inv_L_scale:  [1.0, 1.0]
Epoch :  161  Time:  0.743  Rel. Train L2 Loss :  0.04783220807711283  Rel. Test L2 Loss :  0.0499327751994133  Test L2 Loss :  0.08633640766143799  inv_L_scale:  [1.0, 1.0]
Epoch :  162  Time:  0.743  Rel. Train L2 Loss :  0.04702593488825692  Rel. Test L2 Loss :  0.051296855807304385  Test L2 Loss :  0.08902475953102112  inv_L_scale:  [1.0, 1.0]
Epoch :  163  Time:  0.743  Rel. Train L2 Loss :  0.04717461178700129  Rel. Test L2 Loss :  0.05118840277194977  Test L2 Loss :  0.08903035759925843  inv_L_scale:  [1.0, 1.0]
Epoch :  164  Time:  0.742  Rel. Train L2 Loss :  0.04771410127480825  Rel. Test L2 Loss :  0.051775839328765866  Test L2 Loss :  0.0900851023197174  inv_L_scale:  [1.0, 1.0]
Epoch :  165  Time:  0.742  Rel. Train L2 Loss :  0.047215668708086016  Rel. Test L2 Loss :  0.04935605078935623  Test L2 Loss :  0.08531343638896942  inv_L_scale:  [1.0, 1.0]
Epoch :  166  Time:  0.742  Rel. Train L2 Loss :  0.04717947651942571  Rel. Test L2 Loss :  0.04984702557325363  Test L2 Loss :  0.08596451163291931  inv_L_scale:  [1.0, 1.0]
Epoch :  167  Time:  0.743  Rel. Train L2 Loss :  0.04736920474304093  Rel. Test L2 Loss :  0.05191946744918823  Test L2 Loss :  0.0899947726726532  inv_L_scale:  [1.0, 1.0]
Epoch :  168  Time:  0.742  Rel. Train L2 Loss :  0.04738537311553955  Rel. Test L2 Loss :  0.05016037404537201  Test L2 Loss :  0.0861563390493393  inv_L_scale:  [1.0, 1.0]
Epoch :  169  Time:  0.743  Rel. Train L2 Loss :  0.046873379945755  Rel. Test L2 Loss :  0.04938133463263512  Test L2 Loss :  0.08509188711643219  inv_L_scale:  [1.0, 1.0]
Epoch :  170  Time:  0.743  Rel. Train L2 Loss :  0.04704905370871226  Rel. Test L2 Loss :  0.04904057741165161  Test L2 Loss :  0.08426079213619232  inv_L_scale:  [1.0, 1.0]
Epoch :  171  Time:  0.743  Rel. Train L2 Loss :  0.04709596727457312  Rel. Test L2 Loss :  0.053361215144395825  Test L2 Loss :  0.09218433082103729  inv_L_scale:  [1.0, 1.0]
Epoch :  172  Time:  0.742  Rel. Train L2 Loss :  0.0473870415157742  Rel. Test L2 Loss :  0.049263233542442324  Test L2 Loss :  0.08521541059017182  inv_L_scale:  [1.0, 1.0]
Epoch :  173  Time:  0.742  Rel. Train L2 Loss :  0.04657225309146775  Rel. Test L2 Loss :  0.051515059918165206  Test L2 Loss :  0.08894485056400299  inv_L_scale:  [1.0, 1.0]
Epoch :  174  Time:  0.743  Rel. Train L2 Loss :  0.047010005993975534  Rel. Test L2 Loss :  0.04935172095894814  Test L2 Loss :  0.08599487453699112  inv_L_scale:  [1.0, 1.0]
Epoch :  175  Time:  0.742  Rel. Train L2 Loss :  0.04658307769232326  Rel. Test L2 Loss :  0.050848222821950916  Test L2 Loss :  0.08849665820598603  inv_L_scale:  [1.0, 1.0]
Epoch :  176  Time:  0.742  Rel. Train L2 Loss :  0.04655973696046405  Rel. Test L2 Loss :  0.049265624284744264  Test L2 Loss :  0.08496063679456711  inv_L_scale:  [1.0, 1.0]
Epoch :  177  Time:  0.742  Rel. Train L2 Loss :  0.04681940464509858  Rel. Test L2 Loss :  0.05049884170293808  Test L2 Loss :  0.08710851013660431  inv_L_scale:  [1.0, 1.0]
Epoch :  178  Time:  0.742  Rel. Train L2 Loss :  0.04676472061210209  Rel. Test L2 Loss :  0.05024313300848007  Test L2 Loss :  0.08695289760828018  inv_L_scale:  [1.0, 1.0]
Epoch :  179  Time:  0.743  Rel. Train L2 Loss :  0.0470542663998074  Rel. Test L2 Loss :  0.0500289186835289  Test L2 Loss :  0.08749758750200272  inv_L_scale:  [1.0, 1.0]
Epoch :  180  Time:  0.743  Rel. Train L2 Loss :  0.04646369260218408  Rel. Test L2 Loss :  0.04867188677191734  Test L2 Loss :  0.08421495884656906  inv_L_scale:  [1.0, 1.0]
Epoch :  181  Time:  0.742  Rel. Train L2 Loss :  0.04693391611178716  Rel. Test L2 Loss :  0.0510198649764061  Test L2 Loss :  0.08886956781148911  inv_L_scale:  [1.0, 1.0]
Epoch :  182  Time:  0.742  Rel. Train L2 Loss :  0.046583858215146594  Rel. Test L2 Loss :  0.052580113261938094  Test L2 Loss :  0.0908327829837799  inv_L_scale:  [1.0, 1.0]
Epoch :  183  Time:  0.742  Rel. Train L2 Loss :  0.047132864230208925  Rel. Test L2 Loss :  0.04939502745866776  Test L2 Loss :  0.0854521694779396  inv_L_scale:  [1.0, 1.0]
Epoch :  184  Time:  0.742  Rel. Train L2 Loss :  0.046493628289964464  Rel. Test L2 Loss :  0.04990103885531425  Test L2 Loss :  0.08579436898231506  inv_L_scale:  [1.0, 1.0]
Epoch :  185  Time:  0.742  Rel. Train L2 Loss :  0.04673311763339572  Rel. Test L2 Loss :  0.05170858889818192  Test L2 Loss :  0.09043690025806427  inv_L_scale:  [1.0, 1.0]
Epoch :  186  Time:  0.742  Rel. Train L2 Loss :  0.046777124570475684  Rel. Test L2 Loss :  0.04889406830072403  Test L2 Loss :  0.08380896210670472  inv_L_scale:  [1.0, 1.0]
Epoch :  187  Time:  0.742  Rel. Train L2 Loss :  0.046420921054151326  Rel. Test L2 Loss :  0.05035737529397011  Test L2 Loss :  0.08702928662300109  inv_L_scale:  [1.0, 1.0]
Epoch :  188  Time:  0.742  Rel. Train L2 Loss :  0.046500255680746505  Rel. Test L2 Loss :  0.04923501998186111  Test L2 Loss :  0.08458070009946823  inv_L_scale:  [1.0, 1.0]
Epoch :  189  Time:  0.745  Rel. Train L2 Loss :  0.04640094348125988  Rel. Test L2 Loss :  0.05103466719388962  Test L2 Loss :  0.08773237973451614  inv_L_scale:  [1.0, 1.0]
Epoch :  190  Time:  0.743  Rel. Train L2 Loss :  0.046501322438319524  Rel. Test L2 Loss :  0.052678544372320175  Test L2 Loss :  0.0908644276857376  inv_L_scale:  [1.0, 1.0]
Epoch :  191  Time:  0.742  Rel. Train L2 Loss :  0.04678723707795143  Rel. Test L2 Loss :  0.048757366836071014  Test L2 Loss :  0.08443740129470825  inv_L_scale:  [1.0, 1.0]
Epoch :  192  Time:  0.742  Rel. Train L2 Loss :  0.04683429237869051  Rel. Test L2 Loss :  0.05123242169618607  Test L2 Loss :  0.08939101994037628  inv_L_scale:  [1.0, 1.0]
Epoch :  193  Time:  0.743  Rel. Train L2 Loss :  0.046550519698195986  Rel. Test L2 Loss :  0.05005836248397827  Test L2 Loss :  0.08607469350099564  inv_L_scale:  [1.0, 1.0]
Epoch :  194  Time:  0.742  Rel. Train L2 Loss :  0.046547269026438395  Rel. Test L2 Loss :  0.04836865544319153  Test L2 Loss :  0.08325187355279923  inv_L_scale:  [1.0, 1.0]
Epoch :  195  Time:  0.743  Rel. Train L2 Loss :  0.04635206561949518  Rel. Test L2 Loss :  0.04938813894987106  Test L2 Loss :  0.08547525227069855  inv_L_scale:  [1.0, 1.0]
Epoch :  196  Time:  0.742  Rel. Train L2 Loss :  0.04648043238454395  Rel. Test L2 Loss :  0.0485423718392849  Test L2 Loss :  0.08366702497005463  inv_L_scale:  [1.0, 1.0]
Epoch :  197  Time:  0.742  Rel. Train L2 Loss :  0.046087683422697916  Rel. Test L2 Loss :  0.04894470065832138  Test L2 Loss :  0.08432669639587402  inv_L_scale:  [1.0, 1.0]
Epoch :  198  Time:  0.743  Rel. Train L2 Loss :  0.04620457828044891  Rel. Test L2 Loss :  0.04898937314748764  Test L2 Loss :  0.0852455312013626  inv_L_scale:  [1.0, 1.0]
Epoch :  199  Time:  0.743  Rel. Train L2 Loss :  0.04653251830074522  Rel. Test L2 Loss :  0.04965818822383881  Test L2 Loss :  0.08550365149974823  inv_L_scale:  [1.0, 1.0]
Epoch :  200  Time:  0.742  Rel. Train L2 Loss :  0.04600018398629294  Rel. Test L2 Loss :  0.05129867732524872  Test L2 Loss :  0.08855205059051513  inv_L_scale:  [1.0, 1.0]
Epoch :  201  Time:  0.742  Rel. Train L2 Loss :  0.046217140720950234  Rel. Test L2 Loss :  0.04918244078755379  Test L2 Loss :  0.08579884856939315  inv_L_scale:  [1.0, 1.0]
Epoch :  202  Time:  0.742  Rel. Train L2 Loss :  0.04606202643778589  Rel. Test L2 Loss :  0.05038176000118256  Test L2 Loss :  0.08700719773769379  inv_L_scale:  [1.0, 1.0]
Epoch :  203  Time:  0.743  Rel. Train L2 Loss :  0.046427449567450416  Rel. Test L2 Loss :  0.04922804266214371  Test L2 Loss :  0.08539477229118347  inv_L_scale:  [1.0, 1.0]
Epoch :  204  Time:  0.742  Rel. Train L2 Loss :  0.04622141483757231  Rel. Test L2 Loss :  0.04937063097953796  Test L2 Loss :  0.08484730958938598  inv_L_scale:  [1.0, 1.0]
Epoch :  205  Time:  0.742  Rel. Train L2 Loss :  0.045835255086421965  Rel. Test L2 Loss :  0.04876723259687424  Test L2 Loss :  0.08412382334470749  inv_L_scale:  [1.0, 1.0]
Epoch :  206  Time:  0.743  Rel. Train L2 Loss :  0.04597059549556838  Rel. Test L2 Loss :  0.04975071668624878  Test L2 Loss :  0.08591162323951722  inv_L_scale:  [1.0, 1.0]
Epoch :  207  Time:  0.742  Rel. Train L2 Loss :  0.04587811902165413  Rel. Test L2 Loss :  0.04946016922593117  Test L2 Loss :  0.08537396192550659  inv_L_scale:  [1.0, 1.0]
Epoch :  208  Time:  0.742  Rel. Train L2 Loss :  0.04595220969782935  Rel. Test L2 Loss :  0.04800174713134766  Test L2 Loss :  0.08281692147254943  inv_L_scale:  [1.0, 1.0]
Epoch :  209  Time:  0.744  Rel. Train L2 Loss :  0.04623033417595757  Rel. Test L2 Loss :  0.04877711623907089  Test L2 Loss :  0.08432708203792572  inv_L_scale:  [1.0, 1.0]
Epoch :  210  Time:  0.743  Rel. Train L2 Loss :  0.04627831669317351  Rel. Test L2 Loss :  0.04818827763199806  Test L2 Loss :  0.08337583243846894  inv_L_scale:  [1.0, 1.0]
Epoch :  211  Time:  0.743  Rel. Train L2 Loss :  0.046381483425696694  Rel. Test L2 Loss :  0.050903132557868956  Test L2 Loss :  0.08795550465583801  inv_L_scale:  [1.0, 1.0]
Epoch :  212  Time:  0.742  Rel. Train L2 Loss :  0.04622878114382426  Rel. Test L2 Loss :  0.04746350020170212  Test L2 Loss :  0.08142346024513245  inv_L_scale:  [1.0, 1.0]
Epoch :  213  Time:  0.742  Rel. Train L2 Loss :  0.04592887105213271  Rel. Test L2 Loss :  0.05124988421797752  Test L2 Loss :  0.0903092309832573  inv_L_scale:  [1.0, 1.0]
Epoch :  214  Time:  0.742  Rel. Train L2 Loss :  0.04580027166340086  Rel. Test L2 Loss :  0.04867257714271545  Test L2 Loss :  0.08386381626129151  inv_L_scale:  [1.0, 1.0]
Epoch :  215  Time:  0.742  Rel. Train L2 Loss :  0.045968493223190306  Rel. Test L2 Loss :  0.049090840369462964  Test L2 Loss :  0.08459752708673478  inv_L_scale:  [1.0, 1.0]
Epoch :  216  Time:  0.742  Rel. Train L2 Loss :  0.04573968142271042  Rel. Test L2 Loss :  0.04906380504369736  Test L2 Loss :  0.08453966915607453  inv_L_scale:  [1.0, 1.0]
Epoch :  217  Time:  0.742  Rel. Train L2 Loss :  0.04600688899556796  Rel. Test L2 Loss :  0.04875988185405731  Test L2 Loss :  0.08437574088573456  inv_L_scale:  [1.0, 1.0]
Epoch :  218  Time:  0.742  Rel. Train L2 Loss :  0.04566195067432192  Rel. Test L2 Loss :  0.04865008264780044  Test L2 Loss :  0.08369161725044251  inv_L_scale:  [1.0, 1.0]
Epoch :  219  Time:  0.744  Rel. Train L2 Loss :  0.04571859177615908  Rel. Test L2 Loss :  0.04894438326358795  Test L2 Loss :  0.08436415493488311  inv_L_scale:  [1.0, 1.0]
Epoch :  220  Time:  0.742  Rel. Train L2 Loss :  0.0456923741598924  Rel. Test L2 Loss :  0.048100579082965854  Test L2 Loss :  0.08278845489025116  inv_L_scale:  [1.0, 1.0]
Epoch :  221  Time:  0.742  Rel. Train L2 Loss :  0.0456277880900436  Rel. Test L2 Loss :  0.049149896502494815  Test L2 Loss :  0.08427749365568162  inv_L_scale:  [1.0, 1.0]
Epoch :  222  Time:  0.742  Rel. Train L2 Loss :  0.04591127735045221  Rel. Test L2 Loss :  0.04994221717119217  Test L2 Loss :  0.08611300379037858  inv_L_scale:  [1.0, 1.0]
Epoch :  223  Time:  0.742  Rel. Train L2 Loss :  0.04585323969523112  Rel. Test L2 Loss :  0.04809378415346146  Test L2 Loss :  0.08282584875822067  inv_L_scale:  [1.0, 1.0]
Epoch :  224  Time:  0.742  Rel. Train L2 Loss :  0.04578301217820909  Rel. Test L2 Loss :  0.048720619678497314  Test L2 Loss :  0.08350749254226685  inv_L_scale:  [1.0, 1.0]
Epoch :  225  Time:  0.742  Rel. Train L2 Loss :  0.04560604039165709  Rel. Test L2 Loss :  0.04888163238763809  Test L2 Loss :  0.0844169294834137  inv_L_scale:  [1.0, 1.0]
Epoch :  226  Time:  0.742  Rel. Train L2 Loss :  0.04574723594718509  Rel. Test L2 Loss :  0.0495944356918335  Test L2 Loss :  0.08553272068500518  inv_L_scale:  [1.0, 1.0]
Epoch :  227  Time:  0.743  Rel. Train L2 Loss :  0.045663337939315374  Rel. Test L2 Loss :  0.049761894643306735  Test L2 Loss :  0.08592579454183578  inv_L_scale:  [1.0, 1.0]
Epoch :  228  Time:  0.742  Rel. Train L2 Loss :  0.04553233855300479  Rel. Test L2 Loss :  0.04859040409326553  Test L2 Loss :  0.083553506731987  inv_L_scale:  [1.0, 1.0]
Epoch :  229  Time:  0.742  Rel. Train L2 Loss :  0.04571009410752191  Rel. Test L2 Loss :  0.04968976765871048  Test L2 Loss :  0.08605098575353623  inv_L_scale:  [1.0, 1.0]
Epoch :  230  Time:  0.742  Rel. Train L2 Loss :  0.045472598671913146  Rel. Test L2 Loss :  0.04705037653446197  Test L2 Loss :  0.08113772332668305  inv_L_scale:  [1.0, 1.0]
Epoch :  231  Time:  0.744  Rel. Train L2 Loss :  0.0453640150030454  Rel. Test L2 Loss :  0.04911675661802292  Test L2 Loss :  0.08458947569131851  inv_L_scale:  [1.0, 1.0]
Epoch :  232  Time:  0.744  Rel. Train L2 Loss :  0.04529263729850451  Rel. Test L2 Loss :  0.04787266761064529  Test L2 Loss :  0.0823443067073822  inv_L_scale:  [1.0, 1.0]
Epoch :  233  Time:  0.742  Rel. Train L2 Loss :  0.04552887582116657  Rel. Test L2 Loss :  0.0485028675198555  Test L2 Loss :  0.08358393669128418  inv_L_scale:  [1.0, 1.0]
Epoch :  234  Time:  0.742  Rel. Train L2 Loss :  0.04540803253650665  Rel. Test L2 Loss :  0.04813988655805588  Test L2 Loss :  0.08293159186840057  inv_L_scale:  [1.0, 1.0]
Epoch :  235  Time:  0.742  Rel. Train L2 Loss :  0.045435731444093914  Rel. Test L2 Loss :  0.049297770708799364  Test L2 Loss :  0.08468065738677978  inv_L_scale:  [1.0, 1.0]
Epoch :  236  Time:  0.742  Rel. Train L2 Loss :  0.04542709017793337  Rel. Test L2 Loss :  0.047558183819055556  Test L2 Loss :  0.08181119561195374  inv_L_scale:  [1.0, 1.0]
Epoch :  237  Time:  0.742  Rel. Train L2 Loss :  0.045232601198885176  Rel. Test L2 Loss :  0.0492284893989563  Test L2 Loss :  0.08504591405391693  inv_L_scale:  [1.0, 1.0]
Epoch :  238  Time:  0.742  Rel. Train L2 Loss :  0.04548329288760821  Rel. Test L2 Loss :  0.04809375762939453  Test L2 Loss :  0.08268611907958984  inv_L_scale:  [1.0, 1.0]
Epoch :  239  Time:  0.742  Rel. Train L2 Loss :  0.045030335982640585  Rel. Test L2 Loss :  0.04794404596090317  Test L2 Loss :  0.08268952399492263  inv_L_scale:  [1.0, 1.0]
Epoch :  240  Time:  0.742  Rel. Train L2 Loss :  0.04522698250081804  Rel. Test L2 Loss :  0.04885541766881943  Test L2 Loss :  0.08406138300895691  inv_L_scale:  [1.0, 1.0]
Epoch :  241  Time:  0.742  Rel. Train L2 Loss :  0.04541830372479227  Rel. Test L2 Loss :  0.0494951069355011  Test L2 Loss :  0.08548589169979096  inv_L_scale:  [1.0, 1.0]
Epoch :  242  Time:  0.742  Rel. Train L2 Loss :  0.04525523965557416  Rel. Test L2 Loss :  0.04818598210811615  Test L2 Loss :  0.08342850983142852  inv_L_scale:  [1.0, 1.0]
Epoch :  243  Time:  0.743  Rel. Train L2 Loss :  0.04543003532621596  Rel. Test L2 Loss :  0.0481201408803463  Test L2 Loss :  0.08290087461471557  inv_L_scale:  [1.0, 1.0]
Epoch :  244  Time:  0.742  Rel. Train L2 Loss :  0.04508481952879164  Rel. Test L2 Loss :  0.048771629333496096  Test L2 Loss :  0.08378532081842423  inv_L_scale:  [1.0, 1.0]
Epoch :  245  Time:  0.742  Rel. Train L2 Loss :  0.04533762921889623  Rel. Test L2 Loss :  0.04745807468891144  Test L2 Loss :  0.08176614940166474  inv_L_scale:  [1.0, 1.0]
Epoch :  246  Time:  0.742  Rel. Train L2 Loss :  0.04521275084879663  Rel. Test L2 Loss :  0.04959991440176964  Test L2 Loss :  0.08511385470628738  inv_L_scale:  [1.0, 1.0]
Epoch :  247  Time:  0.742  Rel. Train L2 Loss :  0.04538969329661793  Rel. Test L2 Loss :  0.04788079634308815  Test L2 Loss :  0.08269584238529205  inv_L_scale:  [1.0, 1.0]
Epoch :  248  Time:  0.742  Rel. Train L2 Loss :  0.045095685886012184  Rel. Test L2 Loss :  0.04893344074487686  Test L2 Loss :  0.08494977980852127  inv_L_scale:  [1.0, 1.0]
Epoch :  249  Time:  0.742  Rel. Train L2 Loss :  0.04511820223596361  Rel. Test L2 Loss :  0.04837711155414581  Test L2 Loss :  0.08348405838012696  inv_L_scale:  [1.0, 1.0]
Epoch :  250  Time:  0.743  Rel. Train L2 Loss :  0.045427049497763314  Rel. Test L2 Loss :  0.048153766095638276  Test L2 Loss :  0.08279029607772827  inv_L_scale:  [1.0, 1.0]
Epoch :  251  Time:  0.742  Rel. Train L2 Loss :  0.04523035403754976  Rel. Test L2 Loss :  0.04799401819705963  Test L2 Loss :  0.08238390803337098  inv_L_scale:  [1.0, 1.0]
Epoch :  252  Time:  0.742  Rel. Train L2 Loss :  0.045165616969267526  Rel. Test L2 Loss :  0.04748719558119774  Test L2 Loss :  0.0816274082660675  inv_L_scale:  [1.0, 1.0]
Epoch :  253  Time:  0.742  Rel. Train L2 Loss :  0.045163738131523135  Rel. Test L2 Loss :  0.047272966057062146  Test L2 Loss :  0.08155252397060395  inv_L_scale:  [1.0, 1.0]
Epoch :  254  Time:  0.742  Rel. Train L2 Loss :  0.044957166231340835  Rel. Test L2 Loss :  0.04737712159752846  Test L2 Loss :  0.0813282459974289  inv_L_scale:  [1.0, 1.0]
Epoch :  255  Time:  0.742  Rel. Train L2 Loss :  0.04497764870524407  Rel. Test L2 Loss :  0.04783206269145012  Test L2 Loss :  0.08205025911331176  inv_L_scale:  [1.0, 1.0]
Epoch :  256  Time:  0.744  Rel. Train L2 Loss :  0.04514392718672752  Rel. Test L2 Loss :  0.04793905138969421  Test L2 Loss :  0.08220698297023774  inv_L_scale:  [1.0, 1.0]
Epoch :  257  Time:  0.742  Rel. Train L2 Loss :  0.045142990383836956  Rel. Test L2 Loss :  0.048027953803539275  Test L2 Loss :  0.08289403676986694  inv_L_scale:  [1.0, 1.0]
Epoch :  258  Time:  0.742  Rel. Train L2 Loss :  0.04488490601380666  Rel. Test L2 Loss :  0.047596706300973894  Test L2 Loss :  0.08184842079877853  inv_L_scale:  [1.0, 1.0]
Epoch :  259  Time:  0.742  Rel. Train L2 Loss :  0.04501345526840952  Rel. Test L2 Loss :  0.04805866837501526  Test L2 Loss :  0.08242997586727142  inv_L_scale:  [1.0, 1.0]
Epoch :  260  Time:  0.742  Rel. Train L2 Loss :  0.04488570287823677  Rel. Test L2 Loss :  0.04893430262804031  Test L2 Loss :  0.08425957173109054  inv_L_scale:  [1.0, 1.0]
Epoch :  261  Time:  0.742  Rel. Train L2 Loss :  0.04507091545396381  Rel. Test L2 Loss :  0.04869746744632721  Test L2 Loss :  0.08375134110450745  inv_L_scale:  [1.0, 1.0]
Epoch :  262  Time:  0.742  Rel. Train L2 Loss :  0.04479816627171305  Rel. Test L2 Loss :  0.04760051786899567  Test L2 Loss :  0.08193563789129257  inv_L_scale:  [1.0, 1.0]
Epoch :  263  Time:  0.742  Rel. Train L2 Loss :  0.04488704938027594  Rel. Test L2 Loss :  0.047998094856739046  Test L2 Loss :  0.08284261614084244  inv_L_scale:  [1.0, 1.0]
Epoch :  264  Time:  0.742  Rel. Train L2 Loss :  0.044890049364831715  Rel. Test L2 Loss :  0.048221498131752014  Test L2 Loss :  0.08329951643943787  inv_L_scale:  [1.0, 1.0]
Epoch :  265  Time:  0.742  Rel. Train L2 Loss :  0.044962622043159275  Rel. Test L2 Loss :  0.049015012979507444  Test L2 Loss :  0.0846616804599762  inv_L_scale:  [1.0, 1.0]
Epoch :  266  Time:  0.742  Rel. Train L2 Loss :  0.04461333450343874  Rel. Test L2 Loss :  0.04752977713942528  Test L2 Loss :  0.08177166759967804  inv_L_scale:  [1.0, 1.0]
Epoch :  267  Time:  0.742  Rel. Train L2 Loss :  0.044717548853821225  Rel. Test L2 Loss :  0.04760794878005981  Test L2 Loss :  0.08213284462690354  inv_L_scale:  [1.0, 1.0]
Epoch :  268  Time:  0.741  Rel. Train L2 Loss :  0.0446926478544871  Rel. Test L2 Loss :  0.04776622861623764  Test L2 Loss :  0.08230990022420884  inv_L_scale:  [1.0, 1.0]
Epoch :  269  Time:  0.738  Rel. Train L2 Loss :  0.044835656575030754  Rel. Test L2 Loss :  0.04756479024887085  Test L2 Loss :  0.08179257929325104  inv_L_scale:  [1.0, 1.0]
Epoch :  270  Time:  0.738  Rel. Train L2 Loss :  0.044685522185431585  Rel. Test L2 Loss :  0.0481463748216629  Test L2 Loss :  0.0822671240568161  inv_L_scale:  [1.0, 1.0]
Epoch :  271  Time:  0.738  Rel. Train L2 Loss :  0.04469853611456023  Rel. Test L2 Loss :  0.04771896541118622  Test L2 Loss :  0.08203546017408371  inv_L_scale:  [1.0, 1.0]
Epoch :  272  Time:  0.738  Rel. Train L2 Loss :  0.04483811731139819  Rel. Test L2 Loss :  0.048617628663778306  Test L2 Loss :  0.08397836476564408  inv_L_scale:  [1.0, 1.0]
Epoch :  273  Time:  0.738  Rel. Train L2 Loss :  0.044730712638960946  Rel. Test L2 Loss :  0.04748521357774735  Test L2 Loss :  0.08179965853691101  inv_L_scale:  [1.0, 1.0]
Epoch :  274  Time:  0.738  Rel. Train L2 Loss :  0.04461634423997667  Rel. Test L2 Loss :  0.04784025609493256  Test L2 Loss :  0.08181537121534348  inv_L_scale:  [1.0, 1.0]
Epoch :  275  Time:  0.739  Rel. Train L2 Loss :  0.04442982375621796  Rel. Test L2 Loss :  0.04723633617162704  Test L2 Loss :  0.08135254919528961  inv_L_scale:  [1.0, 1.0]
Epoch :  276  Time:  0.738  Rel. Train L2 Loss :  0.04442870029144817  Rel. Test L2 Loss :  0.04737427204847336  Test L2 Loss :  0.08153189092874527  inv_L_scale:  [1.0, 1.0]
Epoch :  277  Time:  0.738  Rel. Train L2 Loss :  0.04440976677669419  Rel. Test L2 Loss :  0.0478663370013237  Test L2 Loss :  0.08235864460468292  inv_L_scale:  [1.0, 1.0]
Epoch :  278  Time:  0.738  Rel. Train L2 Loss :  0.044701948348018855  Rel. Test L2 Loss :  0.047222875356674195  Test L2 Loss :  0.08090828120708465  inv_L_scale:  [1.0, 1.0]
Epoch :  279  Time:  0.738  Rel. Train L2 Loss :  0.04439771408836047  Rel. Test L2 Loss :  0.0477545553445816  Test L2 Loss :  0.08195222854614258  inv_L_scale:  [1.0, 1.0]
Epoch :  280  Time:  0.738  Rel. Train L2 Loss :  0.04435720771551132  Rel. Test L2 Loss :  0.04763345256447792  Test L2 Loss :  0.08192130088806153  inv_L_scale:  [1.0, 1.0]
Epoch :  281  Time:  0.738  Rel. Train L2 Loss :  0.04448016226291657  Rel. Test L2 Loss :  0.0477600234746933  Test L2 Loss :  0.08216860562562943  inv_L_scale:  [1.0, 1.0]
Epoch :  282  Time:  0.74  Rel. Train L2 Loss :  0.0445440573990345  Rel. Test L2 Loss :  0.047409657686948777  Test L2 Loss :  0.08160628318786621  inv_L_scale:  [1.0, 1.0]
Epoch :  283  Time:  0.741  Rel. Train L2 Loss :  0.04428153564532598  Rel. Test L2 Loss :  0.04800156384706497  Test L2 Loss :  0.08234626442193985  inv_L_scale:  [1.0, 1.0]
Epoch :  284  Time:  0.738  Rel. Train L2 Loss :  0.04449701049261623  Rel. Test L2 Loss :  0.04721604287624359  Test L2 Loss :  0.08085006475448608  inv_L_scale:  [1.0, 1.0]
Epoch :  285  Time:  0.738  Rel. Train L2 Loss :  0.044377503295739494  Rel. Test L2 Loss :  0.047781364023685456  Test L2 Loss :  0.08179682433605194  inv_L_scale:  [1.0, 1.0]
Epoch :  286  Time:  0.738  Rel. Train L2 Loss :  0.04428422714273135  Rel. Test L2 Loss :  0.04681512251496315  Test L2 Loss :  0.08027496814727783  inv_L_scale:  [1.0, 1.0]
Epoch :  287  Time:  0.738  Rel. Train L2 Loss :  0.0441757844057348  Rel. Test L2 Loss :  0.047161145508289336  Test L2 Loss :  0.08077351212501525  inv_L_scale:  [1.0, 1.0]
Epoch :  288  Time:  0.737  Rel. Train L2 Loss :  0.0442827447089884  Rel. Test L2 Loss :  0.04689813509583473  Test L2 Loss :  0.08070872753858566  inv_L_scale:  [1.0, 1.0]
Epoch :  289  Time:  0.738  Rel. Train L2 Loss :  0.04430608759323756  Rel. Test L2 Loss :  0.047650143802165985  Test L2 Loss :  0.08159012913703918  inv_L_scale:  [1.0, 1.0]
Epoch :  290  Time:  0.738  Rel. Train L2 Loss :  0.044277962976031836  Rel. Test L2 Loss :  0.048595395684242246  Test L2 Loss :  0.08334433138370514  inv_L_scale:  [1.0, 1.0]
Epoch :  291  Time:  0.738  Rel. Train L2 Loss :  0.044315112713310456  Rel. Test L2 Loss :  0.047054513692855834  Test L2 Loss :  0.08083387941122055  inv_L_scale:  [1.0, 1.0]
Epoch :  292  Time:  0.737  Rel. Train L2 Loss :  0.04416718105475108  Rel. Test L2 Loss :  0.047051441222429276  Test L2 Loss :  0.08112567722797394  inv_L_scale:  [1.0, 1.0]
Epoch :  293  Time:  0.738  Rel. Train L2 Loss :  0.0442820918891165  Rel. Test L2 Loss :  0.04707467645406723  Test L2 Loss :  0.08130117952823639  inv_L_scale:  [1.0, 1.0]
Epoch :  294  Time:  0.738  Rel. Train L2 Loss :  0.04405541934900813  Rel. Test L2 Loss :  0.04679841816425324  Test L2 Loss :  0.0802150559425354  inv_L_scale:  [1.0, 1.0]
Epoch :  295  Time:  0.738  Rel. Train L2 Loss :  0.044155553579330445  Rel. Test L2 Loss :  0.04682802125811577  Test L2 Loss :  0.08041019707918168  inv_L_scale:  [1.0, 1.0]
Epoch :  296  Time:  0.738  Rel. Train L2 Loss :  0.04394942459132936  Rel. Test L2 Loss :  0.04671548053622246  Test L2 Loss :  0.08046418130397796  inv_L_scale:  [1.0, 1.0]
Epoch :  297  Time:  0.738  Rel. Train L2 Loss :  0.04416277094019784  Rel. Test L2 Loss :  0.047678085267543795  Test L2 Loss :  0.08187041521072387  inv_L_scale:  [1.0, 1.0]
Epoch :  298  Time:  0.738  Rel. Train L2 Loss :  0.04404882033665975  Rel. Test L2 Loss :  0.04728539779782295  Test L2 Loss :  0.08107531249523163  inv_L_scale:  [1.0, 1.0]
Epoch :  299  Time:  0.738  Rel. Train L2 Loss :  0.04417693085140652  Rel. Test L2 Loss :  0.046783784925937655  Test L2 Loss :  0.08058535218238831  inv_L_scale:  [1.0, 1.0]
Epoch :  300  Time:  0.738  Rel. Train L2 Loss :  0.044129682663414216  Rel. Test L2 Loss :  0.04689771980047226  Test L2 Loss :  0.08057502150535584  inv_L_scale:  [1.0, 1.0]
Epoch :  301  Time:  0.738  Rel. Train L2 Loss :  0.044107070962587994  Rel. Test L2 Loss :  0.04707181021571159  Test L2 Loss :  0.08080091178417206  inv_L_scale:  [1.0, 1.0]
Epoch :  302  Time:  0.738  Rel. Train L2 Loss :  0.04410896708567937  Rel. Test L2 Loss :  0.046595458984375  Test L2 Loss :  0.08012851059436799  inv_L_scale:  [1.0, 1.0]
Epoch :  303  Time:  0.738  Rel. Train L2 Loss :  0.043956095957093766  Rel. Test L2 Loss :  0.04750875174999237  Test L2 Loss :  0.08161560773849487  inv_L_scale:  [1.0, 1.0]
Epoch :  304  Time:  0.737  Rel. Train L2 Loss :  0.04403558772471216  Rel. Test L2 Loss :  0.04759859472513199  Test L2 Loss :  0.08224404871463775  inv_L_scale:  [1.0, 1.0]
Epoch :  305  Time:  0.738  Rel. Train L2 Loss :  0.044088813844654295  Rel. Test L2 Loss :  0.0470844878256321  Test L2 Loss :  0.08068016827106476  inv_L_scale:  [1.0, 1.0]
Epoch :  306  Time:  0.738  Rel. Train L2 Loss :  0.04389728448457188  Rel. Test L2 Loss :  0.04677797257900238  Test L2 Loss :  0.08035959005355835  inv_L_scale:  [1.0, 1.0]
Epoch :  307  Time:  0.738  Rel. Train L2 Loss :  0.044056491206089655  Rel. Test L2 Loss :  0.047370364665985105  Test L2 Loss :  0.08194738388061523  inv_L_scale:  [1.0, 1.0]
Epoch :  308  Time:  0.738  Rel. Train L2 Loss :  0.04396639145082898  Rel. Test L2 Loss :  0.047038118690252304  Test L2 Loss :  0.08073033571243286  inv_L_scale:  [1.0, 1.0]
Epoch :  309  Time:  0.738  Rel. Train L2 Loss :  0.043889472087224324  Rel. Test L2 Loss :  0.0471025475859642  Test L2 Loss :  0.0811320674419403  inv_L_scale:  [1.0, 1.0]
Epoch :  310  Time:  0.738  Rel. Train L2 Loss :  0.044143612798717285  Rel. Test L2 Loss :  0.0474595707654953  Test L2 Loss :  0.08177426099777221  inv_L_scale:  [1.0, 1.0]
Epoch :  311  Time:  0.738  Rel. Train L2 Loss :  0.04385286890798145  Rel. Test L2 Loss :  0.04777211531996727  Test L2 Loss :  0.08210543900728226  inv_L_scale:  [1.0, 1.0]
Epoch :  312  Time:  0.739  Rel. Train L2 Loss :  0.04381467941734526  Rel. Test L2 Loss :  0.04669964015483856  Test L2 Loss :  0.08013422220945358  inv_L_scale:  [1.0, 1.0]
Epoch :  313  Time:  0.738  Rel. Train L2 Loss :  0.04399079062872463  Rel. Test L2 Loss :  0.046965605318546294  Test L2 Loss :  0.08086762905120849  inv_L_scale:  [1.0, 1.0]
Epoch :  314  Time:  0.738  Rel. Train L2 Loss :  0.04377335834834311  Rel. Test L2 Loss :  0.048526411950588225  Test L2 Loss :  0.0834038370847702  inv_L_scale:  [1.0, 1.0]
Epoch :  315  Time:  0.738  Rel. Train L2 Loss :  0.043761346307065754  Rel. Test L2 Loss :  0.04710756927728653  Test L2 Loss :  0.08111977279186249  inv_L_scale:  [1.0, 1.0]
Epoch :  316  Time:  0.737  Rel. Train L2 Loss :  0.04389817472961214  Rel. Test L2 Loss :  0.047165482342243194  Test L2 Loss :  0.0813300797343254  inv_L_scale:  [1.0, 1.0]
Epoch :  317  Time:  0.738  Rel. Train L2 Loss :  0.04382037674387296  Rel. Test L2 Loss :  0.0469993782043457  Test L2 Loss :  0.08060339272022247  inv_L_scale:  [1.0, 1.0]
Epoch :  318  Time:  0.738  Rel. Train L2 Loss :  0.04367322042584419  Rel. Test L2 Loss :  0.04678310871124267  Test L2 Loss :  0.0803081738948822  inv_L_scale:  [1.0, 1.0]
Epoch :  319  Time:  0.738  Rel. Train L2 Loss :  0.04367991319961018  Rel. Test L2 Loss :  0.047164547592401504  Test L2 Loss :  0.08103413999080658  inv_L_scale:  [1.0, 1.0]
Epoch :  320  Time:  0.737  Rel. Train L2 Loss :  0.043780115909046596  Rel. Test L2 Loss :  0.04701453298330307  Test L2 Loss :  0.08076756715774536  inv_L_scale:  [1.0, 1.0]
Epoch :  321  Time:  0.738  Rel. Train L2 Loss :  0.04370294666952557  Rel. Test L2 Loss :  0.046745329797267914  Test L2 Loss :  0.08020567387342453  inv_L_scale:  [1.0, 1.0]
Epoch :  322  Time:  0.738  Rel. Train L2 Loss :  0.04366060763597488  Rel. Test L2 Loss :  0.04715641364455223  Test L2 Loss :  0.08105216920375824  inv_L_scale:  [1.0, 1.0]
Epoch :  323  Time:  0.738  Rel. Train L2 Loss :  0.04372171445025338  Rel. Test L2 Loss :  0.04686442941427231  Test L2 Loss :  0.08059460073709487  inv_L_scale:  [1.0, 1.0]
Epoch :  324  Time:  0.737  Rel. Train L2 Loss :  0.0434981675280465  Rel. Test L2 Loss :  0.04705096572637558  Test L2 Loss :  0.08088790357112885  inv_L_scale:  [1.0, 1.0]
Epoch :  325  Time:  0.737  Rel. Train L2 Loss :  0.04352733006079992  Rel. Test L2 Loss :  0.04737643778324127  Test L2 Loss :  0.08134869873523712  inv_L_scale:  [1.0, 1.0]
Epoch :  326  Time:  0.738  Rel. Train L2 Loss :  0.043662032501565085  Rel. Test L2 Loss :  0.04637416332960129  Test L2 Loss :  0.07961583167314529  inv_L_scale:  [1.0, 1.0]
Epoch :  327  Time:  0.738  Rel. Train L2 Loss :  0.04349367770883772  Rel. Test L2 Loss :  0.04692986398935318  Test L2 Loss :  0.08060531139373779  inv_L_scale:  [1.0, 1.0]
Epoch :  328  Time:  0.738  Rel. Train L2 Loss :  0.04356205681959788  Rel. Test L2 Loss :  0.04734276354312897  Test L2 Loss :  0.08188618183135986  inv_L_scale:  [1.0, 1.0]
Epoch :  329  Time:  0.738  Rel. Train L2 Loss :  0.04363118564089139  Rel. Test L2 Loss :  0.04662369757890701  Test L2 Loss :  0.08020258486270905  inv_L_scale:  [1.0, 1.0]
Epoch :  330  Time:  0.738  Rel. Train L2 Loss :  0.043562360141012405  Rel. Test L2 Loss :  0.047267621159553526  Test L2 Loss :  0.08155128419399262  inv_L_scale:  [1.0, 1.0]
Epoch :  331  Time:  0.738  Rel. Train L2 Loss :  0.043647238082355926  Rel. Test L2 Loss :  0.04690442055463791  Test L2 Loss :  0.08028035938739776  inv_L_scale:  [1.0, 1.0]
Epoch :  332  Time:  0.737  Rel. Train L2 Loss :  0.043571171512206394  Rel. Test L2 Loss :  0.04714364945888519  Test L2 Loss :  0.08100831478834153  inv_L_scale:  [1.0, 1.0]
Epoch :  333  Time:  0.738  Rel. Train L2 Loss :  0.04345669612288475  Rel. Test L2 Loss :  0.046390967667102816  Test L2 Loss :  0.07982250690460205  inv_L_scale:  [1.0, 1.0]
Epoch :  334  Time:  0.738  Rel. Train L2 Loss :  0.04356469073229366  Rel. Test L2 Loss :  0.046937828361988065  Test L2 Loss :  0.08047316491603851  inv_L_scale:  [1.0, 1.0]
Epoch :  335  Time:  0.738  Rel. Train L2 Loss :  0.04322402965691355  Rel. Test L2 Loss :  0.04667927384376526  Test L2 Loss :  0.08032861113548279  inv_L_scale:  [1.0, 1.0]
Epoch :  336  Time:  0.738  Rel. Train L2 Loss :  0.04349347066548136  Rel. Test L2 Loss :  0.04649295330047607  Test L2 Loss :  0.07987045735120774  inv_L_scale:  [1.0, 1.0]
Epoch :  337  Time:  0.738  Rel. Train L2 Loss :  0.04343107064565023  Rel. Test L2 Loss :  0.046619388163089755  Test L2 Loss :  0.07994826912879943  inv_L_scale:  [1.0, 1.0]
Epoch :  338  Time:  0.738  Rel. Train L2 Loss :  0.04349703899688191  Rel. Test L2 Loss :  0.04697638362646103  Test L2 Loss :  0.08077942997217179  inv_L_scale:  [1.0, 1.0]
Epoch :  339  Time:  0.738  Rel. Train L2 Loss :  0.043447354634602864  Rel. Test L2 Loss :  0.04660143420100212  Test L2 Loss :  0.08011432588100434  inv_L_scale:  [1.0, 1.0]
Epoch :  340  Time:  0.737  Rel. Train L2 Loss :  0.043336332481768394  Rel. Test L2 Loss :  0.047265090346336365  Test L2 Loss :  0.08137281954288483  inv_L_scale:  [1.0, 1.0]
Epoch :  341  Time:  0.738  Rel. Train L2 Loss :  0.04338104582495159  Rel. Test L2 Loss :  0.04687164679169655  Test L2 Loss :  0.08041652292013168  inv_L_scale:  [1.0, 1.0]
Epoch :  342  Time:  0.738  Rel. Train L2 Loss :  0.043403343823220995  Rel. Test L2 Loss :  0.046628335118293764  Test L2 Loss :  0.08003643393516541  inv_L_scale:  [1.0, 1.0]
Epoch :  343  Time:  0.738  Rel. Train L2 Loss :  0.04330619868304995  Rel. Test L2 Loss :  0.046695245802402495  Test L2 Loss :  0.08018620014190674  inv_L_scale:  [1.0, 1.0]
Epoch :  344  Time:  0.74  Rel. Train L2 Loss :  0.04342014438576169  Rel. Test L2 Loss :  0.04700233548879623  Test L2 Loss :  0.08106602668762207  inv_L_scale:  [1.0, 1.0]
Epoch :  345  Time:  0.739  Rel. Train L2 Loss :  0.04338579439454608  Rel. Test L2 Loss :  0.04664020299911499  Test L2 Loss :  0.07990660429000855  inv_L_scale:  [1.0, 1.0]
Epoch :  346  Time:  0.738  Rel. Train L2 Loss :  0.043415472971068486  Rel. Test L2 Loss :  0.04671554550528526  Test L2 Loss :  0.0801367500424385  inv_L_scale:  [1.0, 1.0]
Epoch :  347  Time:  0.738  Rel. Train L2 Loss :  0.04327632369266616  Rel. Test L2 Loss :  0.04693091422319412  Test L2 Loss :  0.08067153513431549  inv_L_scale:  [1.0, 1.0]
Epoch :  348  Time:  0.738  Rel. Train L2 Loss :  0.04315963197085593  Rel. Test L2 Loss :  0.04635734155774116  Test L2 Loss :  0.07950498402118683  inv_L_scale:  [1.0, 1.0]
Epoch :  349  Time:  0.738  Rel. Train L2 Loss :  0.04306808158755302  Rel. Test L2 Loss :  0.04661317020654678  Test L2 Loss :  0.08021820366382598  inv_L_scale:  [1.0, 1.0]
Epoch :  350  Time:  0.738  Rel. Train L2 Loss :  0.04322565495967865  Rel. Test L2 Loss :  0.046631190776824955  Test L2 Loss :  0.07991243660449981  inv_L_scale:  [1.0, 1.0]
Epoch :  351  Time:  0.737  Rel. Train L2 Loss :  0.043136532803376516  Rel. Test L2 Loss :  0.04644340395927429  Test L2 Loss :  0.07974144399166107  inv_L_scale:  [1.0, 1.0]
Epoch :  352  Time:  0.737  Rel. Train L2 Loss :  0.04306545842025015  Rel. Test L2 Loss :  0.046298940628767014  Test L2 Loss :  0.07938740760087967  inv_L_scale:  [1.0, 1.0]
Epoch :  353  Time:  0.738  Rel. Train L2 Loss :  0.04326368363367187  Rel. Test L2 Loss :  0.04613571271300316  Test L2 Loss :  0.0792499452829361  inv_L_scale:  [1.0, 1.0]
Epoch :  354  Time:  0.738  Rel. Train L2 Loss :  0.043152968800730176  Rel. Test L2 Loss :  0.04669459566473961  Test L2 Loss :  0.08006422519683838  inv_L_scale:  [1.0, 1.0]
Epoch :  355  Time:  0.738  Rel. Train L2 Loss :  0.04305724248290062  Rel. Test L2 Loss :  0.046068165302276615  Test L2 Loss :  0.07898296058177948  inv_L_scale:  [1.0, 1.0]
Epoch :  356  Time:  0.738  Rel. Train L2 Loss :  0.043108148508601715  Rel. Test L2 Loss :  0.0465998575091362  Test L2 Loss :  0.07986946195363999  inv_L_scale:  [1.0, 1.0]
Epoch :  357  Time:  0.738  Rel. Train L2 Loss :  0.0430762632853455  Rel. Test L2 Loss :  0.046431662291288374  Test L2 Loss :  0.07971356153488159  inv_L_scale:  [1.0, 1.0]
Epoch :  358  Time:  0.738  Rel. Train L2 Loss :  0.04301350759135352  Rel. Test L2 Loss :  0.04622973173856735  Test L2 Loss :  0.07955875009298324  inv_L_scale:  [1.0, 1.0]
Epoch :  359  Time:  0.738  Rel. Train L2 Loss :  0.04304967691500982  Rel. Test L2 Loss :  0.04672489881515503  Test L2 Loss :  0.08073298543691636  inv_L_scale:  [1.0, 1.0]
Epoch :  360  Time:  0.738  Rel. Train L2 Loss :  0.04304691821336746  Rel. Test L2 Loss :  0.04630868718028069  Test L2 Loss :  0.07942603260278702  inv_L_scale:  [1.0, 1.0]
Epoch :  361  Time:  0.738  Rel. Train L2 Loss :  0.043026179009013704  Rel. Test L2 Loss :  0.046573762893676755  Test L2 Loss :  0.08024063289165496  inv_L_scale:  [1.0, 1.0]
Epoch :  362  Time:  0.738  Rel. Train L2 Loss :  0.0429902017613252  Rel. Test L2 Loss :  0.04640266448259354  Test L2 Loss :  0.07962043464183807  inv_L_scale:  [1.0, 1.0]
Epoch :  363  Time:  0.738  Rel. Train L2 Loss :  0.04295583902133836  Rel. Test L2 Loss :  0.04659946903586388  Test L2 Loss :  0.07996819525957108  inv_L_scale:  [1.0, 1.0]
Epoch :  364  Time:  0.738  Rel. Train L2 Loss :  0.04289059903886583  Rel. Test L2 Loss :  0.04632047981023788  Test L2 Loss :  0.07957413524389267  inv_L_scale:  [1.0, 1.0]
Epoch :  365  Time:  0.738  Rel. Train L2 Loss :  0.042901742483178774  Rel. Test L2 Loss :  0.046457921266555784  Test L2 Loss :  0.07999595224857331  inv_L_scale:  [1.0, 1.0]
Epoch :  366  Time:  0.738  Rel. Train L2 Loss :  0.0429151204890675  Rel. Test L2 Loss :  0.04634921222925186  Test L2 Loss :  0.07958442836999893  inv_L_scale:  [1.0, 1.0]
Epoch :  367  Time:  0.738  Rel. Train L2 Loss :  0.042847047514385644  Rel. Test L2 Loss :  0.04626629561185837  Test L2 Loss :  0.079509916305542  inv_L_scale:  [1.0, 1.0]
Epoch :  368  Time:  0.738  Rel. Train L2 Loss :  0.04288287172714869  Rel. Test L2 Loss :  0.04607903242111206  Test L2 Loss :  0.07915889322757722  inv_L_scale:  [1.0, 1.0]
Epoch :  369  Time:  0.738  Rel. Train L2 Loss :  0.04295033160183165  Rel. Test L2 Loss :  0.046476942896842954  Test L2 Loss :  0.07983828574419022  inv_L_scale:  [1.0, 1.0]
Epoch :  370  Time:  0.738  Rel. Train L2 Loss :  0.042889291793107985  Rel. Test L2 Loss :  0.046172381937503816  Test L2 Loss :  0.07915427953004837  inv_L_scale:  [1.0, 1.0]
Epoch :  371  Time:  0.738  Rel. Train L2 Loss :  0.042811200585630205  Rel. Test L2 Loss :  0.046313369870185854  Test L2 Loss :  0.07953613638877868  inv_L_scale:  [1.0, 1.0]
Epoch :  372  Time:  0.738  Rel. Train L2 Loss :  0.042794451663891474  Rel. Test L2 Loss :  0.04623117566108704  Test L2 Loss :  0.07929605841636658  inv_L_scale:  [1.0, 1.0]
Epoch :  373  Time:  0.738  Rel. Train L2 Loss :  0.042816624070207275  Rel. Test L2 Loss :  0.046337788105010984  Test L2 Loss :  0.07959347397089005  inv_L_scale:  [1.0, 1.0]
Epoch :  374  Time:  0.738  Rel. Train L2 Loss :  0.04284599718120363  Rel. Test L2 Loss :  0.046220024228096006  Test L2 Loss :  0.07908633649349213  inv_L_scale:  [1.0, 1.0]
Epoch :  375  Time:  0.738  Rel. Train L2 Loss :  0.04289224715696441  Rel. Test L2 Loss :  0.04603888362646103  Test L2 Loss :  0.07897907614707947  inv_L_scale:  [1.0, 1.0]
Epoch :  376  Time:  0.738  Rel. Train L2 Loss :  0.0427649953464667  Rel. Test L2 Loss :  0.046331895738840105  Test L2 Loss :  0.0797891241312027  inv_L_scale:  [1.0, 1.0]
Epoch :  377  Time:  0.738  Rel. Train L2 Loss :  0.04279831714100308  Rel. Test L2 Loss :  0.04631790786981583  Test L2 Loss :  0.07929670870304108  inv_L_scale:  [1.0, 1.0]
Epoch :  378  Time:  0.738  Rel. Train L2 Loss :  0.04270087649424871  Rel. Test L2 Loss :  0.046759508401155475  Test L2 Loss :  0.08049728393554688  inv_L_scale:  [1.0, 1.0]
Epoch :  379  Time:  0.739  Rel. Train L2 Loss :  0.04286952598227395  Rel. Test L2 Loss :  0.045875488668680194  Test L2 Loss :  0.07885863065719605  inv_L_scale:  [1.0, 1.0]
Epoch :  380  Time:  0.738  Rel. Train L2 Loss :  0.042752930720647175  Rel. Test L2 Loss :  0.0462455740571022  Test L2 Loss :  0.07938552290201187  inv_L_scale:  [1.0, 1.0]
Epoch :  381  Time:  0.738  Rel. Train L2 Loss :  0.04257947064108319  Rel. Test L2 Loss :  0.04620158493518829  Test L2 Loss :  0.0792187511920929  inv_L_scale:  [1.0, 1.0]
Epoch :  382  Time:  0.738  Rel. Train L2 Loss :  0.042665668427944184  Rel. Test L2 Loss :  0.04627454400062561  Test L2 Loss :  0.07934196054935455  inv_L_scale:  [1.0, 1.0]
Epoch :  383  Time:  0.738  Rel. Train L2 Loss :  0.042718050794468984  Rel. Test L2 Loss :  0.04614492923021316  Test L2 Loss :  0.0792759269475937  inv_L_scale:  [1.0, 1.0]
Epoch :  384  Time:  0.738  Rel. Train L2 Loss :  0.04261998212999768  Rel. Test L2 Loss :  0.04599310010671616  Test L2 Loss :  0.07878474920988082  inv_L_scale:  [1.0, 1.0]
Epoch :  385  Time:  0.738  Rel. Train L2 Loss :  0.04264430322580867  Rel. Test L2 Loss :  0.04649054169654846  Test L2 Loss :  0.08015977710485458  inv_L_scale:  [1.0, 1.0]
Epoch :  386  Time:  0.738  Rel. Train L2 Loss :  0.04267806568079525  Rel. Test L2 Loss :  0.04615810930728912  Test L2 Loss :  0.07912904024124146  inv_L_scale:  [1.0, 1.0]
Epoch :  387  Time:  0.738  Rel. Train L2 Loss :  0.04261734081639184  Rel. Test L2 Loss :  0.04589505791664124  Test L2 Loss :  0.07871528625488282  inv_L_scale:  [1.0, 1.0]
Epoch :  388  Time:  0.738  Rel. Train L2 Loss :  0.04253018425570594  Rel. Test L2 Loss :  0.04599432528018951  Test L2 Loss :  0.07887104481458664  inv_L_scale:  [1.0, 1.0]
Epoch :  389  Time:  0.738  Rel. Train L2 Loss :  0.04254448061188062  Rel. Test L2 Loss :  0.04620533749461174  Test L2 Loss :  0.07931364595890045  inv_L_scale:  [1.0, 1.0]
Epoch :  390  Time:  0.738  Rel. Train L2 Loss :  0.042560287184185454  Rel. Test L2 Loss :  0.046122413277626034  Test L2 Loss :  0.07903103053569793  inv_L_scale:  [1.0, 1.0]
Epoch :  391  Time:  0.738  Rel. Train L2 Loss :  0.04256922604309188  Rel. Test L2 Loss :  0.04622847020626068  Test L2 Loss :  0.07934870660305023  inv_L_scale:  [1.0, 1.0]
Epoch :  392  Time:  0.738  Rel. Train L2 Loss :  0.04256229220992989  Rel. Test L2 Loss :  0.04600420013070106  Test L2 Loss :  0.07883100926876069  inv_L_scale:  [1.0, 1.0]
Epoch :  393  Time:  0.738  Rel. Train L2 Loss :  0.042487056718932256  Rel. Test L2 Loss :  0.04596534103155136  Test L2 Loss :  0.0788378432393074  inv_L_scale:  [1.0, 1.0]
Epoch :  394  Time:  0.738  Rel. Train L2 Loss :  0.042528878152370456  Rel. Test L2 Loss :  0.04610637038946152  Test L2 Loss :  0.07918604165315628  inv_L_scale:  [1.0, 1.0]
Epoch :  395  Time:  0.738  Rel. Train L2 Loss :  0.04251303129725986  Rel. Test L2 Loss :  0.045829808712005614  Test L2 Loss :  0.0786212632060051  inv_L_scale:  [1.0, 1.0]
Epoch :  396  Time:  0.738  Rel. Train L2 Loss :  0.04248832696013981  Rel. Test L2 Loss :  0.04606333404779434  Test L2 Loss :  0.0791931301355362  inv_L_scale:  [1.0, 1.0]
Epoch :  397  Time:  0.739  Rel. Train L2 Loss :  0.04245502246750726  Rel. Test L2 Loss :  0.04662077367305756  Test L2 Loss :  0.08006560117006302  inv_L_scale:  [1.0, 1.0]
Epoch :  398  Time:  0.738  Rel. Train L2 Loss :  0.04247387967175908  Rel. Test L2 Loss :  0.04618213415145874  Test L2 Loss :  0.07915052026510239  inv_L_scale:  [1.0, 1.0]
Epoch :  399  Time:  0.738  Rel. Train L2 Loss :  0.04242564971248309  Rel. Test L2 Loss :  0.04576848119497299  Test L2 Loss :  0.07858616590499878  inv_L_scale:  [1.0, 1.0]
Epoch :  400  Time:  0.738  Rel. Train L2 Loss :  0.04244627265466584  Rel. Test L2 Loss :  0.04588019266724586  Test L2 Loss :  0.07874046683311463  inv_L_scale:  [1.0, 1.0]
Epoch :  401  Time:  0.738  Rel. Train L2 Loss :  0.042416974438561336  Rel. Test L2 Loss :  0.04606051057577133  Test L2 Loss :  0.07893814921379089  inv_L_scale:  [1.0, 1.0]
Epoch :  402  Time:  0.738  Rel. Train L2 Loss :  0.04238741773698065  Rel. Test L2 Loss :  0.046029349267482755  Test L2 Loss :  0.0788533753156662  inv_L_scale:  [1.0, 1.0]
Epoch :  403  Time:  0.738  Rel. Train L2 Loss :  0.04242563456296921  Rel. Test L2 Loss :  0.045876146852970125  Test L2 Loss :  0.07871046841144562  inv_L_scale:  [1.0, 1.0]
Epoch :  404  Time:  0.738  Rel. Train L2 Loss :  0.042438736491733124  Rel. Test L2 Loss :  0.045960255116224286  Test L2 Loss :  0.07890912890434265  inv_L_scale:  [1.0, 1.0]
Epoch :  405  Time:  0.738  Rel. Train L2 Loss :  0.042363851815462115  Rel. Test L2 Loss :  0.04612123608589172  Test L2 Loss :  0.07913915067911148  inv_L_scale:  [1.0, 1.0]
Epoch :  406  Time:  0.738  Rel. Train L2 Loss :  0.04234757587313652  Rel. Test L2 Loss :  0.046061583161354065  Test L2 Loss :  0.07897800266742706  inv_L_scale:  [1.0, 1.0]
Epoch :  407  Time:  0.738  Rel. Train L2 Loss :  0.04231614996989568  Rel. Test L2 Loss :  0.046193187236785886  Test L2 Loss :  0.07921632170677186  inv_L_scale:  [1.0, 1.0]
Epoch :  408  Time:  0.738  Rel. Train L2 Loss :  0.042321356733640035  Rel. Test L2 Loss :  0.045913217961788176  Test L2 Loss :  0.07871773183345794  inv_L_scale:  [1.0, 1.0]
Epoch :  409  Time:  0.738  Rel. Train L2 Loss :  0.04229488846328523  Rel. Test L2 Loss :  0.045955585092306135  Test L2 Loss :  0.07878039002418519  inv_L_scale:  [1.0, 1.0]
Epoch :  410  Time:  0.738  Rel. Train L2 Loss :  0.04233397296733327  Rel. Test L2 Loss :  0.04586819604039192  Test L2 Loss :  0.07861196637153625  inv_L_scale:  [1.0, 1.0]
Epoch :  411  Time:  0.738  Rel. Train L2 Loss :  0.04222127646207809  Rel. Test L2 Loss :  0.0457360428571701  Test L2 Loss :  0.0785193046927452  inv_L_scale:  [1.0, 1.0]
Epoch :  412  Time:  0.738  Rel. Train L2 Loss :  0.042306873202323916  Rel. Test L2 Loss :  0.04613617241382599  Test L2 Loss :  0.07927131414413452  inv_L_scale:  [1.0, 1.0]
Epoch :  413  Time:  0.737  Rel. Train L2 Loss :  0.04232075134913127  Rel. Test L2 Loss :  0.04585802048444748  Test L2 Loss :  0.0785501766204834  inv_L_scale:  [1.0, 1.0]
Epoch :  414  Time:  0.738  Rel. Train L2 Loss :  0.04229539109600915  Rel. Test L2 Loss :  0.04601803794503212  Test L2 Loss :  0.07886443048715591  inv_L_scale:  [1.0, 1.0]
Epoch :  415  Time:  0.74  Rel. Train L2 Loss :  0.042247972322834865  Rel. Test L2 Loss :  0.04605857938528061  Test L2 Loss :  0.07907181411981583  inv_L_scale:  [1.0, 1.0]
Epoch :  416  Time:  0.737  Rel. Train L2 Loss :  0.04220326700144344  Rel. Test L2 Loss :  0.045845680236816407  Test L2 Loss :  0.07861878335475922  inv_L_scale:  [1.0, 1.0]
Epoch :  417  Time:  0.737  Rel. Train L2 Loss :  0.04216424271464348  Rel. Test L2 Loss :  0.045839496105909344  Test L2 Loss :  0.07854311347007752  inv_L_scale:  [1.0, 1.0]
Epoch :  418  Time:  0.74  Rel. Train L2 Loss :  0.042224162138170665  Rel. Test L2 Loss :  0.04589978456497192  Test L2 Loss :  0.07869719207286835  inv_L_scale:  [1.0, 1.0]
Epoch :  419  Time:  0.738  Rel. Train L2 Loss :  0.04227845042943954  Rel. Test L2 Loss :  0.04574478939175606  Test L2 Loss :  0.07848618447780609  inv_L_scale:  [1.0, 1.0]
Epoch :  420  Time:  0.737  Rel. Train L2 Loss :  0.04221318768130408  Rel. Test L2 Loss :  0.04580888241529465  Test L2 Loss :  0.07853320717811585  inv_L_scale:  [1.0, 1.0]
Epoch :  421  Time:  0.738  Rel. Train L2 Loss :  0.04218824963602755  Rel. Test L2 Loss :  0.04597441211342811  Test L2 Loss :  0.07882814168930054  inv_L_scale:  [1.0, 1.0]
Epoch :  422  Time:  0.738  Rel. Train L2 Loss :  0.042130492677291236  Rel. Test L2 Loss :  0.0457821823656559  Test L2 Loss :  0.07845510482788086  inv_L_scale:  [1.0, 1.0]
Epoch :  423  Time:  0.738  Rel. Train L2 Loss :  0.04217092129919264  Rel. Test L2 Loss :  0.04579725325107575  Test L2 Loss :  0.07857729017734527  inv_L_scale:  [1.0, 1.0]
Epoch :  424  Time:  0.738  Rel. Train L2 Loss :  0.042121736307938897  Rel. Test L2 Loss :  0.04589499175548553  Test L2 Loss :  0.07877013951539993  inv_L_scale:  [1.0, 1.0]
Epoch :  425  Time:  0.737  Rel. Train L2 Loss :  0.042099795987208685  Rel. Test L2 Loss :  0.04582209214568138  Test L2 Loss :  0.0784954971075058  inv_L_scale:  [1.0, 1.0]
Epoch :  426  Time:  0.738  Rel. Train L2 Loss :  0.04211532476875517  Rel. Test L2 Loss :  0.045839986503124236  Test L2 Loss :  0.07865241140127183  inv_L_scale:  [1.0, 1.0]
Epoch :  427  Time:  0.738  Rel. Train L2 Loss :  0.04207611438300875  Rel. Test L2 Loss :  0.04574910014867783  Test L2 Loss :  0.07839378654956818  inv_L_scale:  [1.0, 1.0]
Epoch :  428  Time:  0.737  Rel. Train L2 Loss :  0.04209172382950783  Rel. Test L2 Loss :  0.045810848474502563  Test L2 Loss :  0.0785544565320015  inv_L_scale:  [1.0, 1.0]
Epoch :  429  Time:  0.738  Rel. Train L2 Loss :  0.042071047541168  Rel. Test L2 Loss :  0.04591286942362785  Test L2 Loss :  0.07875107854604721  inv_L_scale:  [1.0, 1.0]
Epoch :  430  Time:  0.737  Rel. Train L2 Loss :  0.04207099358240763  Rel. Test L2 Loss :  0.04586230993270874  Test L2 Loss :  0.07863328337669373  inv_L_scale:  [1.0, 1.0]
Epoch :  431  Time:  0.737  Rel. Train L2 Loss :  0.04202460481888718  Rel. Test L2 Loss :  0.045737692415714265  Test L2 Loss :  0.07847054600715637  inv_L_scale:  [1.0, 1.0]
Epoch :  432  Time:  0.737  Rel. Train L2 Loss :  0.04207016093863381  Rel. Test L2 Loss :  0.04584920182824135  Test L2 Loss :  0.07867088198661804  inv_L_scale:  [1.0, 1.0]
Epoch :  433  Time:  0.737  Rel. Train L2 Loss :  0.042032903846767215  Rel. Test L2 Loss :  0.04595067858695984  Test L2 Loss :  0.0787476795911789  inv_L_scale:  [1.0, 1.0]
Epoch :  434  Time:  0.738  Rel. Train L2 Loss :  0.04202840968966484  Rel. Test L2 Loss :  0.04567228481173515  Test L2 Loss :  0.07837004810571671  inv_L_scale:  [1.0, 1.0]
Epoch :  435  Time:  0.738  Rel. Train L2 Loss :  0.042001194639338386  Rel. Test L2 Loss :  0.045792840123176574  Test L2 Loss :  0.07865060329437255  inv_L_scale:  [1.0, 1.0]
Epoch :  436  Time:  0.737  Rel. Train L2 Loss :  0.04202644086546368  Rel. Test L2 Loss :  0.0457850082218647  Test L2 Loss :  0.07855012953281403  inv_L_scale:  [1.0, 1.0]
Epoch :  437  Time:  0.738  Rel. Train L2 Loss :  0.0420332893398073  Rel. Test L2 Loss :  0.045662889778614046  Test L2 Loss :  0.07836817562580109  inv_L_scale:  [1.0, 1.0]
Epoch :  438  Time:  0.738  Rel. Train L2 Loss :  0.04199786350131035  Rel. Test L2 Loss :  0.045798781216144564  Test L2 Loss :  0.07848608911037445  inv_L_scale:  [1.0, 1.0]
Epoch :  439  Time:  0.738  Rel. Train L2 Loss :  0.041966023511356775  Rel. Test L2 Loss :  0.045881467461586  Test L2 Loss :  0.07867639422416688  inv_L_scale:  [1.0, 1.0]
Epoch :  440  Time:  0.738  Rel. Train L2 Loss :  0.041959161079592175  Rel. Test L2 Loss :  0.04571996957063675  Test L2 Loss :  0.0784168940782547  inv_L_scale:  [1.0, 1.0]
Epoch :  441  Time:  0.738  Rel. Train L2 Loss :  0.041952267951435515  Rel. Test L2 Loss :  0.0457830223441124  Test L2 Loss :  0.07856462329626084  inv_L_scale:  [1.0, 1.0]
Epoch :  442  Time:  0.738  Rel. Train L2 Loss :  0.04194081145028273  Rel. Test L2 Loss :  0.04570938259363175  Test L2 Loss :  0.07838025987148285  inv_L_scale:  [1.0, 1.0]
Epoch :  443  Time:  0.738  Rel. Train L2 Loss :  0.04194275675548448  Rel. Test L2 Loss :  0.04571618393063545  Test L2 Loss :  0.07837743401527404  inv_L_scale:  [1.0, 1.0]
Epoch :  444  Time:  0.737  Rel. Train L2 Loss :  0.04193029251363543  Rel. Test L2 Loss :  0.045751995146274566  Test L2 Loss :  0.07841886132955551  inv_L_scale:  [1.0, 1.0]
Epoch :  445  Time:  0.737  Rel. Train L2 Loss :  0.041913949896891914  Rel. Test L2 Loss :  0.04579899802803993  Test L2 Loss :  0.0784980845451355  inv_L_scale:  [1.0, 1.0]
Epoch :  446  Time:  0.738  Rel. Train L2 Loss :  0.04191487736172146  Rel. Test L2 Loss :  0.04573830306529999  Test L2 Loss :  0.07841943442821503  inv_L_scale:  [1.0, 1.0]
Epoch :  447  Time:  0.737  Rel. Train L2 Loss :  0.0419003836148315  Rel. Test L2 Loss :  0.04570834785699844  Test L2 Loss :  0.07842469364404678  inv_L_scale:  [1.0, 1.0]
Epoch :  448  Time:  0.737  Rel. Train L2 Loss :  0.041896591517660356  Rel. Test L2 Loss :  0.045760840475559235  Test L2 Loss :  0.07848680377006531  inv_L_scale:  [1.0, 1.0]
Epoch :  449  Time:  0.738  Rel. Train L2 Loss :  0.04190422861112489  Rel. Test L2 Loss :  0.045766341090202334  Test L2 Loss :  0.07860968321561813  inv_L_scale:  [1.0, 1.0]
Epoch :  450  Time:  0.737  Rel. Train L2 Loss :  0.041875898324780995  Rel. Test L2 Loss :  0.04566315412521362  Test L2 Loss :  0.07829054147005081  inv_L_scale:  [1.0, 1.0]
Epoch :  451  Time:  0.738  Rel. Train L2 Loss :  0.041889408512247935  Rel. Test L2 Loss :  0.04568730890750885  Test L2 Loss :  0.07838112741708755  inv_L_scale:  [1.0, 1.0]
Epoch :  452  Time:  0.737  Rel. Train L2 Loss :  0.041856699569357766  Rel. Test L2 Loss :  0.04573231488466263  Test L2 Loss :  0.07844342023134232  inv_L_scale:  [1.0, 1.0]
Epoch :  453  Time:  0.738  Rel. Train L2 Loss :  0.04185520519812902  Rel. Test L2 Loss :  0.04581285506486893  Test L2 Loss :  0.07852060377597808  inv_L_scale:  [1.0, 1.0]
Epoch :  454  Time:  0.737  Rel. Train L2 Loss :  0.04185447658101717  Rel. Test L2 Loss :  0.04571336954832077  Test L2 Loss :  0.0784157708287239  inv_L_scale:  [1.0, 1.0]
Epoch :  455  Time:  0.737  Rel. Train L2 Loss :  0.04184825937781069  Rel. Test L2 Loss :  0.04570121854543686  Test L2 Loss :  0.0783435845375061  inv_L_scale:  [1.0, 1.0]
Epoch :  456  Time:  0.737  Rel. Train L2 Loss :  0.04184748416145643  Rel. Test L2 Loss :  0.045711304843425754  Test L2 Loss :  0.07839920341968537  inv_L_scale:  [1.0, 1.0]
Epoch :  457  Time:  0.739  Rel. Train L2 Loss :  0.04183762626515494  Rel. Test L2 Loss :  0.04570000395178795  Test L2 Loss :  0.07837301075458526  inv_L_scale:  [1.0, 1.0]
Epoch :  458  Time:  0.737  Rel. Train L2 Loss :  0.04181767415669229  Rel. Test L2 Loss :  0.045739299952983856  Test L2 Loss :  0.07842365443706513  inv_L_scale:  [1.0, 1.0]
Epoch :  459  Time:  0.738  Rel. Train L2 Loss :  0.04183040801021788  Rel. Test L2 Loss :  0.04566919654607773  Test L2 Loss :  0.0782746770977974  inv_L_scale:  [1.0, 1.0]
Epoch :  460  Time:  0.739  Rel. Train L2 Loss :  0.041799870646662185  Rel. Test L2 Loss :  0.0457298544049263  Test L2 Loss :  0.07842554152011871  inv_L_scale:  [1.0, 1.0]
Epoch :  461  Time:  0.737  Rel. Train L2 Loss :  0.041805182347695036  Rel. Test L2 Loss :  0.045682470202445986  Test L2 Loss :  0.07833447188138962  inv_L_scale:  [1.0, 1.0]
Epoch :  462  Time:  0.738  Rel. Train L2 Loss :  0.041791143351131016  Rel. Test L2 Loss :  0.04567417949438095  Test L2 Loss :  0.07837338864803314  inv_L_scale:  [1.0, 1.0]
Epoch :  463  Time:  0.737  Rel. Train L2 Loss :  0.04179113088382615  Rel. Test L2 Loss :  0.04570230811834335  Test L2 Loss :  0.07835311263799667  inv_L_scale:  [1.0, 1.0]
Epoch :  464  Time:  0.737  Rel. Train L2 Loss :  0.04178857598039839  Rel. Test L2 Loss :  0.04568081110715866  Test L2 Loss :  0.0783179572224617  inv_L_scale:  [1.0, 1.0]
Epoch :  465  Time:  0.737  Rel. Train L2 Loss :  0.04178204067879253  Rel. Test L2 Loss :  0.04562549471855164  Test L2 Loss :  0.07829141497612  inv_L_scale:  [1.0, 1.0]
Epoch :  466  Time:  0.737  Rel. Train L2 Loss :  0.04178477838635444  Rel. Test L2 Loss :  0.04566047921776772  Test L2 Loss :  0.07831836700439453  inv_L_scale:  [1.0, 1.0]
Epoch :  467  Time:  0.738  Rel. Train L2 Loss :  0.041758286505937575  Rel. Test L2 Loss :  0.04568634331226349  Test L2 Loss :  0.07833037078380585  inv_L_scale:  [1.0, 1.0]
Epoch :  468  Time:  0.737  Rel. Train L2 Loss :  0.041763129341933464  Rel. Test L2 Loss :  0.045669796019792555  Test L2 Loss :  0.07830989301204681  inv_L_scale:  [1.0, 1.0]
Epoch :  469  Time:  0.738  Rel. Train L2 Loss :  0.041747110072109433  Rel. Test L2 Loss :  0.04570605903863907  Test L2 Loss :  0.07836278140544892  inv_L_scale:  [1.0, 1.0]
Epoch :  470  Time:  0.738  Rel. Train L2 Loss :  0.04175764362017314  Rel. Test L2 Loss :  0.04573701411485672  Test L2 Loss :  0.0784006416797638  inv_L_scale:  [1.0, 1.0]
Epoch :  471  Time:  0.739  Rel. Train L2 Loss :  0.04175192869371838  Rel. Test L2 Loss :  0.04570978611707687  Test L2 Loss :  0.07839127451181412  inv_L_scale:  [1.0, 1.0]
Epoch :  472  Time:  0.738  Rel. Train L2 Loss :  0.04174433635340796  Rel. Test L2 Loss :  0.04570747256278992  Test L2 Loss :  0.0783679461479187  inv_L_scale:  [1.0, 1.0]
Epoch :  473  Time:  0.738  Rel. Train L2 Loss :  0.04175181317660544  Rel. Test L2 Loss :  0.04572437822818756  Test L2 Loss :  0.07839519321918488  inv_L_scale:  [1.0, 1.0]
Epoch :  474  Time:  0.738  Rel. Train L2 Loss :  0.041735611624187895  Rel. Test L2 Loss :  0.045659572333097455  Test L2 Loss :  0.07830993831157684  inv_L_scale:  [1.0, 1.0]
Epoch :  475  Time:  0.738  Rel. Train L2 Loss :  0.04172821400894059  Rel. Test L2 Loss :  0.04566833034157753  Test L2 Loss :  0.07831375062465668  inv_L_scale:  [1.0, 1.0]
Epoch :  476  Time:  0.738  Rel. Train L2 Loss :  0.041727702402406266  Rel. Test L2 Loss :  0.0456960141658783  Test L2 Loss :  0.07835840821266174  inv_L_scale:  [1.0, 1.0]
Epoch :  477  Time:  0.737  Rel. Train L2 Loss :  0.04172630692521731  Rel. Test L2 Loss :  0.04567685842514038  Test L2 Loss :  0.07832369208335876  inv_L_scale:  [1.0, 1.0]
Epoch :  478  Time:  0.738  Rel. Train L2 Loss :  0.0417192288984855  Rel. Test L2 Loss :  0.0456632786989212  Test L2 Loss :  0.07830673694610596  inv_L_scale:  [1.0, 1.0]
Epoch :  479  Time:  0.738  Rel. Train L2 Loss :  0.041724487692117694  Rel. Test L2 Loss :  0.04565541505813599  Test L2 Loss :  0.07829273730516434  inv_L_scale:  [1.0, 1.0]
Epoch :  480  Time:  0.737  Rel. Train L2 Loss :  0.04171470024519496  Rel. Test L2 Loss :  0.045683225393295286  Test L2 Loss :  0.07832888424396516  inv_L_scale:  [1.0, 1.0]
Epoch :  481  Time:  0.739  Rel. Train L2 Loss :  0.04170499152607388  Rel. Test L2 Loss :  0.04566002458333969  Test L2 Loss :  0.07829870402812958  inv_L_scale:  [1.0, 1.0]
Epoch :  482  Time:  0.737  Rel. Train L2 Loss :  0.04170662083559566  Rel. Test L2 Loss :  0.045673979073762895  Test L2 Loss :  0.0783283644914627  inv_L_scale:  [1.0, 1.0]
Epoch :  483  Time:  0.738  Rel. Train L2 Loss :  0.041701534390449525  Rel. Test L2 Loss :  0.04567658573389053  Test L2 Loss :  0.07833734512329102  inv_L_scale:  [1.0, 1.0]
Epoch :  484  Time:  0.739  Rel. Train L2 Loss :  0.04170195617609554  Rel. Test L2 Loss :  0.04569122776389122  Test L2 Loss :  0.07834748327732086  inv_L_scale:  [1.0, 1.0]
Epoch :  485  Time:  0.737  Rel. Train L2 Loss :  0.04169898001684083  Rel. Test L2 Loss :  0.04565963014960289  Test L2 Loss :  0.07831828892230988  inv_L_scale:  [1.0, 1.0]
Epoch :  486  Time:  0.738  Rel. Train L2 Loss :  0.041694107784165275  Rel. Test L2 Loss :  0.04567390263080597  Test L2 Loss :  0.0783269116282463  inv_L_scale:  [1.0, 1.0]
Epoch :  487  Time:  0.737  Rel. Train L2 Loss :  0.04169251895613141  Rel. Test L2 Loss :  0.04569400519132614  Test L2 Loss :  0.07835633128881454  inv_L_scale:  [1.0, 1.0]
Epoch :  488  Time:  0.737  Rel. Train L2 Loss :  0.041696268849902685  Rel. Test L2 Loss :  0.04567091256380081  Test L2 Loss :  0.07833750128746032  inv_L_scale:  [1.0, 1.0]
Epoch :  489  Time:  0.737  Rel. Train L2 Loss :  0.04168854556149906  Rel. Test L2 Loss :  0.045689514875411986  Test L2 Loss :  0.07834579050540924  inv_L_scale:  [1.0, 1.0]
Epoch :  490  Time:  0.737  Rel. Train L2 Loss :  0.04169104741679298  Rel. Test L2 Loss :  0.04567703098058701  Test L2 Loss :  0.07833889782428742  inv_L_scale:  [1.0, 1.0]
Epoch :  491  Time:  0.737  Rel. Train L2 Loss :  0.041691259874237906  Rel. Test L2 Loss :  0.04567783549427986  Test L2 Loss :  0.07833461940288544  inv_L_scale:  [1.0, 1.0]
Epoch :  492  Time:  0.737  Rel. Train L2 Loss :  0.04168515102730857  Rel. Test L2 Loss :  0.04568435043096542  Test L2 Loss :  0.07833375066518783  inv_L_scale:  [1.0, 1.0]
Epoch :  493  Time:  0.737  Rel. Train L2 Loss :  0.04168154153558943  Rel. Test L2 Loss :  0.045684128403663635  Test L2 Loss :  0.07833773583173752  inv_L_scale:  [1.0, 1.0]
Epoch :  494  Time:  0.737  Rel. Train L2 Loss :  0.041685875571436354  Rel. Test L2 Loss :  0.04567935600876808  Test L2 Loss :  0.07833253145217896  inv_L_scale:  [1.0, 1.0]
Epoch :  495  Time:  0.737  Rel. Train L2 Loss :  0.041682461980316374  Rel. Test L2 Loss :  0.04567390605807305  Test L2 Loss :  0.07832472264766693  inv_L_scale:  [1.0, 1.0]
Epoch :  496  Time:  0.737  Rel. Train L2 Loss :  0.04168262208501498  Rel. Test L2 Loss :  0.04567064315080643  Test L2 Loss :  0.07832863152027131  inv_L_scale:  [1.0, 1.0]
Epoch :  497  Time:  0.737  Rel. Train L2 Loss :  0.041682631191280156  Rel. Test L2 Loss :  0.045667802691459654  Test L2 Loss :  0.07832090198993683  inv_L_scale:  [1.0, 1.0]
Epoch :  498  Time:  0.738  Rel. Train L2 Loss :  0.04168068922228283  Rel. Test L2 Loss :  0.045708950608968735  Test L2 Loss :  0.07837185025215149  inv_L_scale:  [1.0, 1.0]
Epoch :  499  Time:  0.737  Rel. Train L2 Loss :  0.0416834874285592  Rel. Test L2 Loss :  0.04568593442440033  Test L2 Loss :  0.07834129095077515  inv_L_scale:  [1.0, 1.0]
