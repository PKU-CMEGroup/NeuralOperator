(1000,) (1000, 1000, 1) (1000, 1000, 2)
use normalized raw measures
Casting to tensor
x_train shape torch.Size([900, 1000, 8]), y_train shape torch.Size([900, 1000, 1])
length of each dim:  tensor([6.5573987960815430, 6.1420288085937500])
kmax = 16
L =  10
In PCNO_train, ndims =  2
Epoch :  0  Time:  1.617  Rel. Train L2 Loss :  0.5570593757099576  Rel. Test L2 Loss :  0.4616838908195496  Test L2 Loss :  0.6639164471626282  inv_L_scale:  [1.0, 1.0]
Epoch :  1  Time:  0.952  Rel. Train L2 Loss :  0.3651029051674737  Rel. Test L2 Loss :  0.29609454870224  Test L2 Loss :  0.42467026472091673  inv_L_scale:  [1.0, 1.0]
Epoch :  2  Time:  0.949  Rel. Train L2 Loss :  0.2625556915336185  Rel. Test L2 Loss :  0.22617003321647644  Test L2 Loss :  0.3215649604797363  inv_L_scale:  [1.0, 1.0]
Epoch :  3  Time:  0.95  Rel. Train L2 Loss :  0.1944333850675159  Rel. Test L2 Loss :  0.17528119027614594  Test L2 Loss :  0.24813201189041137  inv_L_scale:  [1.0, 1.0]
Epoch :  4  Time:  0.952  Rel. Train L2 Loss :  0.16167808277739418  Rel. Test L2 Loss :  0.15574662864208222  Test L2 Loss :  0.22009501516819  inv_L_scale:  [1.0, 1.0]
Epoch :  5  Time:  0.949  Rel. Train L2 Loss :  0.14609925005171034  Rel. Test L2 Loss :  0.14428091704845428  Test L2 Loss :  0.20383954405784607  inv_L_scale:  [1.0, 1.0]
Epoch :  6  Time:  0.95  Rel. Train L2 Loss :  0.1341715904408031  Rel. Test L2 Loss :  0.12686283230781556  Test L2 Loss :  0.18056353986263274  inv_L_scale:  [1.0, 1.0]
Epoch :  7  Time:  0.949  Rel. Train L2 Loss :  0.12202722390492757  Rel. Test L2 Loss :  0.12348583400249481  Test L2 Loss :  0.17532579600811005  inv_L_scale:  [1.0, 1.0]
Epoch :  8  Time:  0.951  Rel. Train L2 Loss :  0.11768478128645155  Rel. Test L2 Loss :  0.11658042311668396  Test L2 Loss :  0.16494258046150206  inv_L_scale:  [1.0, 1.0]
Epoch :  9  Time:  0.949  Rel. Train L2 Loss :  0.11545505632956822  Rel. Test L2 Loss :  0.11179542541503906  Test L2 Loss :  0.15922793745994568  inv_L_scale:  [1.0, 1.0]
Epoch :  10  Time:  0.949  Rel. Train L2 Loss :  0.10933628148502773  Rel. Test L2 Loss :  0.10940952479839325  Test L2 Loss :  0.15530423283576966  inv_L_scale:  [1.0, 1.0]
Epoch :  11  Time:  0.948  Rel. Train L2 Loss :  0.11020031160778469  Rel. Test L2 Loss :  0.10913654088974  Test L2 Loss :  0.15527388274669648  inv_L_scale:  [1.0, 1.0]
Epoch :  12  Time:  0.948  Rel. Train L2 Loss :  0.10560835775401857  Rel. Test L2 Loss :  0.10446081548929215  Test L2 Loss :  0.14880258202552796  inv_L_scale:  [1.0, 1.0]
Epoch :  13  Time:  0.95  Rel. Train L2 Loss :  0.10164742092291514  Rel. Test L2 Loss :  0.10203011780977249  Test L2 Loss :  0.14537689805030823  inv_L_scale:  [1.0, 1.0]
Epoch :  14  Time:  0.95  Rel. Train L2 Loss :  0.09967707739935981  Rel. Test L2 Loss :  0.09963121563196183  Test L2 Loss :  0.1413404154777527  inv_L_scale:  [1.0, 1.0]
Epoch :  15  Time:  0.95  Rel. Train L2 Loss :  0.09912118448151483  Rel. Test L2 Loss :  0.09938977062702178  Test L2 Loss :  0.14107526898384093  inv_L_scale:  [1.0, 1.0]
Epoch :  16  Time:  0.949  Rel. Train L2 Loss :  0.09793256786134508  Rel. Test L2 Loss :  0.09703941524028778  Test L2 Loss :  0.13840316355228424  inv_L_scale:  [1.0, 1.0]
Epoch :  17  Time:  0.949  Rel. Train L2 Loss :  0.09704725391334958  Rel. Test L2 Loss :  0.10229552209377289  Test L2 Loss :  0.1449059534072876  inv_L_scale:  [1.0, 1.0]
Epoch :  18  Time:  0.948  Rel. Train L2 Loss :  0.09486278136571248  Rel. Test L2 Loss :  0.09070077061653137  Test L2 Loss :  0.12946629673242568  inv_L_scale:  [1.0, 1.0]
Epoch :  19  Time:  0.949  Rel. Train L2 Loss :  0.0922744670841429  Rel. Test L2 Loss :  0.09285796821117401  Test L2 Loss :  0.13242072224617005  inv_L_scale:  [1.0, 1.0]
Epoch :  20  Time:  0.949  Rel. Train L2 Loss :  0.09214136567380693  Rel. Test L2 Loss :  0.09482232511043548  Test L2 Loss :  0.13475910902023316  inv_L_scale:  [1.0, 1.0]
Epoch :  21  Time:  0.951  Rel. Train L2 Loss :  0.09098331418302325  Rel. Test L2 Loss :  0.08826832234859466  Test L2 Loss :  0.12640677392482758  inv_L_scale:  [1.0, 1.0]
Epoch :  22  Time:  0.949  Rel. Train L2 Loss :  0.0902898508310318  Rel. Test L2 Loss :  0.08892936080694198  Test L2 Loss :  0.12712545573711395  inv_L_scale:  [1.0, 1.0]
Epoch :  23  Time:  0.948  Rel. Train L2 Loss :  0.08945221089654498  Rel. Test L2 Loss :  0.09033894032239914  Test L2 Loss :  0.1287600314617157  inv_L_scale:  [1.0, 1.0]
Epoch :  24  Time:  0.949  Rel. Train L2 Loss :  0.08922259959909651  Rel. Test L2 Loss :  0.08690139949321747  Test L2 Loss :  0.12414103031158447  inv_L_scale:  [1.0, 1.0]
Epoch :  25  Time:  0.948  Rel. Train L2 Loss :  0.0884104531009992  Rel. Test L2 Loss :  0.08658787965774536  Test L2 Loss :  0.12312208652496338  inv_L_scale:  [1.0, 1.0]
Epoch :  26  Time:  0.95  Rel. Train L2 Loss :  0.08742109186119504  Rel. Test L2 Loss :  0.09162991106510163  Test L2 Loss :  0.1300567638874054  inv_L_scale:  [1.0, 1.0]
Epoch :  27  Time:  0.949  Rel. Train L2 Loss :  0.0873879724740982  Rel. Test L2 Loss :  0.08384225666522979  Test L2 Loss :  0.119761603474617  inv_L_scale:  [1.0, 1.0]
Epoch :  28  Time:  0.951  Rel. Train L2 Loss :  0.08570221606228087  Rel. Test L2 Loss :  0.08626006066799163  Test L2 Loss :  0.12361757725477218  inv_L_scale:  [1.0, 1.0]
Epoch :  29  Time:  0.949  Rel. Train L2 Loss :  0.08540899412499534  Rel. Test L2 Loss :  0.08427645683288575  Test L2 Loss :  0.12039434254169464  inv_L_scale:  [1.0, 1.0]
Epoch :  30  Time:  0.949  Rel. Train L2 Loss :  0.08461083624098036  Rel. Test L2 Loss :  0.08341358155012131  Test L2 Loss :  0.11976598143577576  inv_L_scale:  [1.0, 1.0]
Epoch :  31  Time:  0.949  Rel. Train L2 Loss :  0.08485542578829659  Rel. Test L2 Loss :  0.08370578348636627  Test L2 Loss :  0.12016819298267364  inv_L_scale:  [1.0, 1.0]
Epoch :  32  Time:  0.949  Rel. Train L2 Loss :  0.08390979203912947  Rel. Test L2 Loss :  0.08238163530826569  Test L2 Loss :  0.11816757172346115  inv_L_scale:  [1.0, 1.0]
Epoch :  33  Time:  0.949  Rel. Train L2 Loss :  0.08324655307663811  Rel. Test L2 Loss :  0.0813450613617897  Test L2 Loss :  0.11606252104043961  inv_L_scale:  [1.0, 1.0]
Epoch :  34  Time:  0.949  Rel. Train L2 Loss :  0.08253386550479465  Rel. Test L2 Loss :  0.08181782722473145  Test L2 Loss :  0.11664993822574615  inv_L_scale:  [1.0, 1.0]
Epoch :  35  Time:  0.949  Rel. Train L2 Loss :  0.08380132347345352  Rel. Test L2 Loss :  0.0819794237613678  Test L2 Loss :  0.11796009957790375  inv_L_scale:  [1.0, 1.0]
Epoch :  36  Time:  0.948  Rel. Train L2 Loss :  0.08164028065072165  Rel. Test L2 Loss :  0.08400120615959167  Test L2 Loss :  0.1204492211341858  inv_L_scale:  [1.0, 1.0]
Epoch :  37  Time:  0.951  Rel. Train L2 Loss :  0.08142411496904162  Rel. Test L2 Loss :  0.0797899368405342  Test L2 Loss :  0.11413216561079026  inv_L_scale:  [1.0, 1.0]
Epoch :  38  Time:  0.949  Rel. Train L2 Loss :  0.0814422826303376  Rel. Test L2 Loss :  0.08045214414596558  Test L2 Loss :  0.11531172513961792  inv_L_scale:  [1.0, 1.0]
Epoch :  39  Time:  0.948  Rel. Train L2 Loss :  0.08010206745730505  Rel. Test L2 Loss :  0.0798534944653511  Test L2 Loss :  0.11409718424081802  inv_L_scale:  [1.0, 1.0]
Epoch :  40  Time:  0.949  Rel. Train L2 Loss :  0.08140429728560977  Rel. Test L2 Loss :  0.08096395611763  Test L2 Loss :  0.11555785477161408  inv_L_scale:  [1.0, 1.0]
Epoch :  41  Time:  0.948  Rel. Train L2 Loss :  0.07970842599868774  Rel. Test L2 Loss :  0.08296988248825073  Test L2 Loss :  0.11835994422435761  inv_L_scale:  [1.0, 1.0]
Epoch :  42  Time:  0.949  Rel. Train L2 Loss :  0.08013626499308481  Rel. Test L2 Loss :  0.08021383076906204  Test L2 Loss :  0.11498541235923768  inv_L_scale:  [1.0, 1.0]
Epoch :  43  Time:  0.948  Rel. Train L2 Loss :  0.08204667290051779  Rel. Test L2 Loss :  0.08047348499298096  Test L2 Loss :  0.11516806423664093  inv_L_scale:  [1.0, 1.0]
Epoch :  44  Time:  0.949  Rel. Train L2 Loss :  0.0805312399400605  Rel. Test L2 Loss :  0.07728350043296814  Test L2 Loss :  0.1103832983970642  inv_L_scale:  [1.0, 1.0]
Epoch :  45  Time:  0.95  Rel. Train L2 Loss :  0.07999759455521901  Rel. Test L2 Loss :  0.08041768014431  Test L2 Loss :  0.11463215351104736  inv_L_scale:  [1.0, 1.0]
Epoch :  46  Time:  0.949  Rel. Train L2 Loss :  0.07824186500575807  Rel. Test L2 Loss :  0.08283375233411788  Test L2 Loss :  0.11847063004970551  inv_L_scale:  [1.0, 1.0]
Epoch :  47  Time:  0.948  Rel. Train L2 Loss :  0.07774455689721638  Rel. Test L2 Loss :  0.07993074476718903  Test L2 Loss :  0.11407480031251907  inv_L_scale:  [1.0, 1.0]
Epoch :  48  Time:  0.951  Rel. Train L2 Loss :  0.07888070394595464  Rel. Test L2 Loss :  0.0774117162823677  Test L2 Loss :  0.111164028942585  inv_L_scale:  [1.0, 1.0]
Epoch :  49  Time:  0.949  Rel. Train L2 Loss :  0.07808947341309654  Rel. Test L2 Loss :  0.07546832978725433  Test L2 Loss :  0.1084597161412239  inv_L_scale:  [1.0, 1.0]
Epoch :  50  Time:  0.948  Rel. Train L2 Loss :  0.07765823927190568  Rel. Test L2 Loss :  0.07725109189748763  Test L2 Loss :  0.1104275643825531  inv_L_scale:  [1.0, 1.0]
Epoch :  51  Time:  0.95  Rel. Train L2 Loss :  0.07801371369096968  Rel. Test L2 Loss :  0.0794014635682106  Test L2 Loss :  0.11342668950557709  inv_L_scale:  [1.0, 1.0]
Epoch :  52  Time:  0.949  Rel. Train L2 Loss :  0.07739761461814244  Rel. Test L2 Loss :  0.07675508290529251  Test L2 Loss :  0.11049637496471405  inv_L_scale:  [1.0, 1.0]
Epoch :  53  Time:  0.949  Rel. Train L2 Loss :  0.07645833790302277  Rel. Test L2 Loss :  0.07534057080745697  Test L2 Loss :  0.10819220900535584  inv_L_scale:  [1.0, 1.0]
Epoch :  54  Time:  0.95  Rel. Train L2 Loss :  0.07720956302351421  Rel. Test L2 Loss :  0.07827018976211547  Test L2 Loss :  0.11201350092887878  inv_L_scale:  [1.0, 1.0]
Epoch :  55  Time:  0.949  Rel. Train L2 Loss :  0.07593803962071737  Rel. Test L2 Loss :  0.07319675862789154  Test L2 Loss :  0.1051863494515419  inv_L_scale:  [1.0, 1.0]
Epoch :  56  Time:  0.949  Rel. Train L2 Loss :  0.07597359210252762  Rel. Test L2 Loss :  0.0761305570602417  Test L2 Loss :  0.10872810244560242  inv_L_scale:  [1.0, 1.0]
Epoch :  57  Time:  0.95  Rel. Train L2 Loss :  0.07624557981888454  Rel. Test L2 Loss :  0.07468618273735046  Test L2 Loss :  0.10720701217651367  inv_L_scale:  [1.0, 1.0]
Epoch :  58  Time:  0.949  Rel. Train L2 Loss :  0.07530017736885283  Rel. Test L2 Loss :  0.07500994622707367  Test L2 Loss :  0.10741367936134338  inv_L_scale:  [1.0, 1.0]
Epoch :  59  Time:  0.949  Rel. Train L2 Loss :  0.07660335292418798  Rel. Test L2 Loss :  0.07595835983753205  Test L2 Loss :  0.10869326144456863  inv_L_scale:  [1.0, 1.0]
Epoch :  60  Time:  0.949  Rel. Train L2 Loss :  0.07631835480531057  Rel. Test L2 Loss :  0.07444391340017319  Test L2 Loss :  0.10668253928422927  inv_L_scale:  [1.0, 1.0]
Epoch :  61  Time:  0.951  Rel. Train L2 Loss :  0.07493739485740662  Rel. Test L2 Loss :  0.0761536955833435  Test L2 Loss :  0.1099202910065651  inv_L_scale:  [1.0, 1.0]
Epoch :  62  Time:  0.95  Rel. Train L2 Loss :  0.07596966995133295  Rel. Test L2 Loss :  0.0762751567363739  Test L2 Loss :  0.10857515722513199  inv_L_scale:  [1.0, 1.0]
Epoch :  63  Time:  0.949  Rel. Train L2 Loss :  0.0754090332157082  Rel. Test L2 Loss :  0.07247468531131744  Test L2 Loss :  0.10397465795278549  inv_L_scale:  [1.0, 1.0]
Epoch :  64  Time:  0.949  Rel. Train L2 Loss :  0.07533350653118558  Rel. Test L2 Loss :  0.0745518085360527  Test L2 Loss :  0.10713032454252243  inv_L_scale:  [1.0, 1.0]
Epoch :  65  Time:  0.949  Rel. Train L2 Loss :  0.07486185911628936  Rel. Test L2 Loss :  0.07562294751405715  Test L2 Loss :  0.10873069971799851  inv_L_scale:  [1.0, 1.0]
Epoch :  66  Time:  0.949  Rel. Train L2 Loss :  0.07478419138325586  Rel. Test L2 Loss :  0.07458327203989029  Test L2 Loss :  0.10699300408363342  inv_L_scale:  [1.0, 1.0]
Epoch :  67  Time:  0.949  Rel. Train L2 Loss :  0.07405072450637817  Rel. Test L2 Loss :  0.07399949848651886  Test L2 Loss :  0.10648131787776947  inv_L_scale:  [1.0, 1.0]
Epoch :  68  Time:  0.949  Rel. Train L2 Loss :  0.07468214770158133  Rel. Test L2 Loss :  0.07542347699403763  Test L2 Loss :  0.10836320400238036  inv_L_scale:  [1.0, 1.0]
Epoch :  69  Time:  0.949  Rel. Train L2 Loss :  0.07432612783379025  Rel. Test L2 Loss :  0.07357337921857834  Test L2 Loss :  0.1055510550737381  inv_L_scale:  [1.0, 1.0]
Epoch :  70  Time:  0.949  Rel. Train L2 Loss :  0.07312963909573025  Rel. Test L2 Loss :  0.07306624293327331  Test L2 Loss :  0.10521371126174926  inv_L_scale:  [1.0, 1.0]
Epoch :  71  Time:  0.949  Rel. Train L2 Loss :  0.07478753258784612  Rel. Test L2 Loss :  0.07425410151481629  Test L2 Loss :  0.10685293108224869  inv_L_scale:  [1.0, 1.0]
Epoch :  72  Time:  0.95  Rel. Train L2 Loss :  0.07339911533726587  Rel. Test L2 Loss :  0.07468749016523361  Test L2 Loss :  0.10714874923229217  inv_L_scale:  [1.0, 1.0]
Epoch :  73  Time:  0.949  Rel. Train L2 Loss :  0.07347830111781756  Rel. Test L2 Loss :  0.07217106819152833  Test L2 Loss :  0.10383472800254821  inv_L_scale:  [1.0, 1.0]
Epoch :  74  Time:  0.949  Rel. Train L2 Loss :  0.07495496398872799  Rel. Test L2 Loss :  0.07217304259538651  Test L2 Loss :  0.10358743995428085  inv_L_scale:  [1.0, 1.0]
Epoch :  75  Time:  0.949  Rel. Train L2 Loss :  0.07409147600332897  Rel. Test L2 Loss :  0.07299466490745544  Test L2 Loss :  0.10483933389186859  inv_L_scale:  [1.0, 1.0]
Epoch :  76  Time:  0.948  Rel. Train L2 Loss :  0.07336725099219216  Rel. Test L2 Loss :  0.07470072627067566  Test L2 Loss :  0.10697655141353607  inv_L_scale:  [1.0, 1.0]
Epoch :  77  Time:  0.945  Rel. Train L2 Loss :  0.07316988638705678  Rel. Test L2 Loss :  0.07566282242536544  Test L2 Loss :  0.10852042108774185  inv_L_scale:  [1.0, 1.0]
Epoch :  78  Time:  0.942  Rel. Train L2 Loss :  0.0735798747671975  Rel. Test L2 Loss :  0.07175697386264801  Test L2 Loss :  0.10315132856369019  inv_L_scale:  [1.0, 1.0]
Epoch :  79  Time:  0.942  Rel. Train L2 Loss :  0.07245663755469851  Rel. Test L2 Loss :  0.07095487147569657  Test L2 Loss :  0.10186143219470978  inv_L_scale:  [1.0, 1.0]
Epoch :  80  Time:  0.941  Rel. Train L2 Loss :  0.07285653160678016  Rel. Test L2 Loss :  0.0740746459364891  Test L2 Loss :  0.10591724634170532  inv_L_scale:  [1.0, 1.0]
Epoch :  81  Time:  0.94  Rel. Train L2 Loss :  0.07197087610761324  Rel. Test L2 Loss :  0.07043768554925918  Test L2 Loss :  0.10112812399864196  inv_L_scale:  [1.0, 1.0]
Epoch :  82  Time:  0.94  Rel. Train L2 Loss :  0.07299384123749203  Rel. Test L2 Loss :  0.07124306857585908  Test L2 Loss :  0.10212649703025818  inv_L_scale:  [1.0, 1.0]
Epoch :  83  Time:  0.94  Rel. Train L2 Loss :  0.07307825144794253  Rel. Test L2 Loss :  0.07033137947320939  Test L2 Loss :  0.10133623957633972  inv_L_scale:  [1.0, 1.0]
Epoch :  84  Time:  0.94  Rel. Train L2 Loss :  0.07208700044287576  Rel. Test L2 Loss :  0.07371382921934128  Test L2 Loss :  0.10606455981731415  inv_L_scale:  [1.0, 1.0]
Epoch :  85  Time:  0.94  Rel. Train L2 Loss :  0.0720973590347502  Rel. Test L2 Loss :  0.07219670116901397  Test L2 Loss :  0.10337612569332123  inv_L_scale:  [1.0, 1.0]
Epoch :  86  Time:  0.94  Rel. Train L2 Loss :  0.0719218283229404  Rel. Test L2 Loss :  0.07006701558828354  Test L2 Loss :  0.10086695253849029  inv_L_scale:  [1.0, 1.0]
Epoch :  87  Time:  0.94  Rel. Train L2 Loss :  0.07090627514653736  Rel. Test L2 Loss :  0.06995571106672287  Test L2 Loss :  0.10101202130317688  inv_L_scale:  [1.0, 1.0]
Epoch :  88  Time:  0.94  Rel. Train L2 Loss :  0.07105786859989166  Rel. Test L2 Loss :  0.072771837413311  Test L2 Loss :  0.10450532227754593  inv_L_scale:  [1.0, 1.0]
Epoch :  89  Time:  0.94  Rel. Train L2 Loss :  0.07205869240893258  Rel. Test L2 Loss :  0.07420029789209366  Test L2 Loss :  0.10639826387166977  inv_L_scale:  [1.0, 1.0]
Epoch :  90  Time:  0.941  Rel. Train L2 Loss :  0.07160307023260329  Rel. Test L2 Loss :  0.07324103534221649  Test L2 Loss :  0.10494181036949157  inv_L_scale:  [1.0, 1.0]
Epoch :  91  Time:  0.941  Rel. Train L2 Loss :  0.07088625381390254  Rel. Test L2 Loss :  0.07223837733268738  Test L2 Loss :  0.10338818699121476  inv_L_scale:  [1.0, 1.0]
Epoch :  92  Time:  0.94  Rel. Train L2 Loss :  0.07179201687375704  Rel. Test L2 Loss :  0.06984699606895446  Test L2 Loss :  0.10080611318349839  inv_L_scale:  [1.0, 1.0]
Epoch :  93  Time:  0.94  Rel. Train L2 Loss :  0.07168974214129978  Rel. Test L2 Loss :  0.07119910657405853  Test L2 Loss :  0.10250914573669434  inv_L_scale:  [1.0, 1.0]
Epoch :  94  Time:  0.94  Rel. Train L2 Loss :  0.07060730252001021  Rel. Test L2 Loss :  0.06999350190162659  Test L2 Loss :  0.100779350399971  inv_L_scale:  [1.0, 1.0]
Epoch :  95  Time:  0.942  Rel. Train L2 Loss :  0.07051202538940642  Rel. Test L2 Loss :  0.07054197907447815  Test L2 Loss :  0.10133364409208298  inv_L_scale:  [1.0, 1.0]
Epoch :  96  Time:  0.941  Rel. Train L2 Loss :  0.0706721756193373  Rel. Test L2 Loss :  0.06991664797067643  Test L2 Loss :  0.10047624796628953  inv_L_scale:  [1.0, 1.0]
Epoch :  97  Time:  0.941  Rel. Train L2 Loss :  0.07015900731086731  Rel. Test L2 Loss :  0.06932294964790345  Test L2 Loss :  0.09970121771097183  inv_L_scale:  [1.0, 1.0]
Epoch :  98  Time:  0.941  Rel. Train L2 Loss :  0.07064656962951024  Rel. Test L2 Loss :  0.06986909031867981  Test L2 Loss :  0.1004510149359703  inv_L_scale:  [1.0, 1.0]
Epoch :  99  Time:  0.941  Rel. Train L2 Loss :  0.07012679835160573  Rel. Test L2 Loss :  0.06975984930992127  Test L2 Loss :  0.10081796824932099  inv_L_scale:  [1.0, 1.0]
Epoch :  100  Time:  0.944  Rel. Train L2 Loss :  0.07035957290066613  Rel. Test L2 Loss :  0.0723759838938713  Test L2 Loss :  0.10377382069826126  inv_L_scale:  [1.0, 1.0]
Epoch :  101  Time:  0.942  Rel. Train L2 Loss :  0.0700115775068601  Rel. Test L2 Loss :  0.06849549889564514  Test L2 Loss :  0.0984625506401062  inv_L_scale:  [1.0, 1.0]
Epoch :  102  Time:  0.941  Rel. Train L2 Loss :  0.06964315613110861  Rel. Test L2 Loss :  0.06998813241720199  Test L2 Loss :  0.10072532832622529  inv_L_scale:  [1.0, 1.0]
Epoch :  103  Time:  0.941  Rel. Train L2 Loss :  0.06953702873653836  Rel. Test L2 Loss :  0.07045978397130966  Test L2 Loss :  0.1013557916879654  inv_L_scale:  [1.0, 1.0]
Epoch :  104  Time:  0.941  Rel. Train L2 Loss :  0.06968826002544827  Rel. Test L2 Loss :  0.06906241923570633  Test L2 Loss :  0.0993725448846817  inv_L_scale:  [1.0, 1.0]
Epoch :  105  Time:  0.945  Rel. Train L2 Loss :  0.06916084690226448  Rel. Test L2 Loss :  0.06742358475923538  Test L2 Loss :  0.09709370255470276  inv_L_scale:  [1.0, 1.0]
Epoch :  106  Time:  0.955  Rel. Train L2 Loss :  0.06896554787953695  Rel. Test L2 Loss :  0.06957586467266083  Test L2 Loss :  0.10012380450963974  inv_L_scale:  [1.0, 1.0]
Epoch :  107  Time:  0.941  Rel. Train L2 Loss :  0.06872832205560472  Rel. Test L2 Loss :  0.07135937601327896  Test L2 Loss :  0.10219251602888108  inv_L_scale:  [1.0, 1.0]
Epoch :  108  Time:  0.941  Rel. Train L2 Loss :  0.06851942393514845  Rel. Test L2 Loss :  0.06984354943037033  Test L2 Loss :  0.10022256821393967  inv_L_scale:  [1.0, 1.0]
Epoch :  109  Time:  0.941  Rel. Train L2 Loss :  0.0690659518374337  Rel. Test L2 Loss :  0.07279953986406326  Test L2 Loss :  0.10452659904956818  inv_L_scale:  [1.0, 1.0]
Epoch :  110  Time:  0.941  Rel. Train L2 Loss :  0.06941799130704668  Rel. Test L2 Loss :  0.06761670112609863  Test L2 Loss :  0.09758898466825486  inv_L_scale:  [1.0, 1.0]
Epoch :  111  Time:  0.941  Rel. Train L2 Loss :  0.06855207827356126  Rel. Test L2 Loss :  0.06760258972644806  Test L2 Loss :  0.09726176679134368  inv_L_scale:  [1.0, 1.0]
Epoch :  112  Time:  0.941  Rel. Train L2 Loss :  0.06878706249925826  Rel. Test L2 Loss :  0.07229944288730622  Test L2 Loss :  0.10419801265001297  inv_L_scale:  [1.0, 1.0]
Epoch :  113  Time:  0.94  Rel. Train L2 Loss :  0.06869199984603458  Rel. Test L2 Loss :  0.06840085148811341  Test L2 Loss :  0.09852588534355164  inv_L_scale:  [1.0, 1.0]
Epoch :  114  Time:  0.94  Rel. Train L2 Loss :  0.06879241542683708  Rel. Test L2 Loss :  0.06890675783157349  Test L2 Loss :  0.09946453273296356  inv_L_scale:  [1.0, 1.0]
Epoch :  115  Time:  0.94  Rel. Train L2 Loss :  0.06793687095244726  Rel. Test L2 Loss :  0.06781902968883514  Test L2 Loss :  0.09745379209518433  inv_L_scale:  [1.0, 1.0]
Epoch :  116  Time:  0.941  Rel. Train L2 Loss :  0.06858427047729493  Rel. Test L2 Loss :  0.06784344702959061  Test L2 Loss :  0.09761823862791061  inv_L_scale:  [1.0, 1.0]
Epoch :  117  Time:  0.941  Rel. Train L2 Loss :  0.06802616715431213  Rel. Test L2 Loss :  0.06665348947048187  Test L2 Loss :  0.09616954714059829  inv_L_scale:  [1.0, 1.0]
Epoch :  118  Time:  0.94  Rel. Train L2 Loss :  0.06897943158944447  Rel. Test L2 Loss :  0.06963799804449082  Test L2 Loss :  0.10023156762123107  inv_L_scale:  [1.0, 1.0]
Epoch :  119  Time:  0.94  Rel. Train L2 Loss :  0.06789015514983071  Rel. Test L2 Loss :  0.0702678918838501  Test L2 Loss :  0.1013464504480362  inv_L_scale:  [1.0, 1.0]
Epoch :  120  Time:  0.941  Rel. Train L2 Loss :  0.06756636960638894  Rel. Test L2 Loss :  0.06720750451087952  Test L2 Loss :  0.0967584329843521  inv_L_scale:  [1.0, 1.0]
Epoch :  121  Time:  0.941  Rel. Train L2 Loss :  0.06785318692525227  Rel. Test L2 Loss :  0.0663075190782547  Test L2 Loss :  0.09576857537031173  inv_L_scale:  [1.0, 1.0]
Epoch :  122  Time:  0.941  Rel. Train L2 Loss :  0.0677066128121482  Rel. Test L2 Loss :  0.06652921617031098  Test L2 Loss :  0.09592949211597443  inv_L_scale:  [1.0, 1.0]
Epoch :  123  Time:  0.944  Rel. Train L2 Loss :  0.06790566527181202  Rel. Test L2 Loss :  0.06963865280151367  Test L2 Loss :  0.10064153224229813  inv_L_scale:  [1.0, 1.0]
Epoch :  124  Time:  0.942  Rel. Train L2 Loss :  0.06794344607326719  Rel. Test L2 Loss :  0.06824596136808396  Test L2 Loss :  0.09808506220579147  inv_L_scale:  [1.0, 1.0]
Epoch :  125  Time:  0.941  Rel. Train L2 Loss :  0.06756368140379587  Rel. Test L2 Loss :  0.0676751658320427  Test L2 Loss :  0.09730657786130906  inv_L_scale:  [1.0, 1.0]
Epoch :  126  Time:  0.941  Rel. Train L2 Loss :  0.06800443636046516  Rel. Test L2 Loss :  0.069479960501194  Test L2 Loss :  0.10015316843986512  inv_L_scale:  [1.0, 1.0]
Epoch :  127  Time:  0.94  Rel. Train L2 Loss :  0.06728869520955616  Rel. Test L2 Loss :  0.06900177389383316  Test L2 Loss :  0.09952743500471115  inv_L_scale:  [1.0, 1.0]
Epoch :  128  Time:  0.94  Rel. Train L2 Loss :  0.06728339476717843  Rel. Test L2 Loss :  0.06598444014787674  Test L2 Loss :  0.09533260643482208  inv_L_scale:  [1.0, 1.0]
Epoch :  129  Time:  0.94  Rel. Train L2 Loss :  0.0682655531167984  Rel. Test L2 Loss :  0.06794643372297288  Test L2 Loss :  0.09768813073635102  inv_L_scale:  [1.0, 1.0]
Epoch :  130  Time:  0.94  Rel. Train L2 Loss :  0.06743518683645461  Rel. Test L2 Loss :  0.0688813778758049  Test L2 Loss :  0.09887744724750519  inv_L_scale:  [1.0, 1.0]
Epoch :  131  Time:  0.941  Rel. Train L2 Loss :  0.06693276911973953  Rel. Test L2 Loss :  0.06795408397912979  Test L2 Loss :  0.09780443012714386  inv_L_scale:  [1.0, 1.0]
Epoch :  132  Time:  0.94  Rel. Train L2 Loss :  0.06701986703607771  Rel. Test L2 Loss :  0.06711167097091675  Test L2 Loss :  0.09664097011089325  inv_L_scale:  [1.0, 1.0]
Epoch :  133  Time:  0.94  Rel. Train L2 Loss :  0.06720028433534835  Rel. Test L2 Loss :  0.0662862303853035  Test L2 Loss :  0.09566865384578704  inv_L_scale:  [1.0, 1.0]
Epoch :  134  Time:  0.94  Rel. Train L2 Loss :  0.06670612557066811  Rel. Test L2 Loss :  0.06705451995134354  Test L2 Loss :  0.09632791489362717  inv_L_scale:  [1.0, 1.0]
Epoch :  135  Time:  0.939  Rel. Train L2 Loss :  0.06670943680736753  Rel. Test L2 Loss :  0.06570871621370315  Test L2 Loss :  0.094988734126091  inv_L_scale:  [1.0, 1.0]
Epoch :  136  Time:  0.94  Rel. Train L2 Loss :  0.06655948453479343  Rel. Test L2 Loss :  0.06601390212774277  Test L2 Loss :  0.09527424901723862  inv_L_scale:  [1.0, 1.0]
Epoch :  137  Time:  0.939  Rel. Train L2 Loss :  0.06698624826139873  Rel. Test L2 Loss :  0.06583924293518066  Test L2 Loss :  0.09502285957336426  inv_L_scale:  [1.0, 1.0]
Epoch :  138  Time:  0.94  Rel. Train L2 Loss :  0.06690530651145511  Rel. Test L2 Loss :  0.06750185549259186  Test L2 Loss :  0.09690145790576934  inv_L_scale:  [1.0, 1.0]
Epoch :  139  Time:  0.939  Rel. Train L2 Loss :  0.06642989198366801  Rel. Test L2 Loss :  0.06615493655204772  Test L2 Loss :  0.09536957770586013  inv_L_scale:  [1.0, 1.0]
Epoch :  140  Time:  0.939  Rel. Train L2 Loss :  0.06626806244254112  Rel. Test L2 Loss :  0.06731459468603135  Test L2 Loss :  0.09675409555435181  inv_L_scale:  [1.0, 1.0]
Epoch :  141  Time:  0.94  Rel. Train L2 Loss :  0.06628520942396587  Rel. Test L2 Loss :  0.06706464797258377  Test L2 Loss :  0.09644958972930909  inv_L_scale:  [1.0, 1.0]
Epoch :  142  Time:  0.94  Rel. Train L2 Loss :  0.06629547721809811  Rel. Test L2 Loss :  0.06458154082298279  Test L2 Loss :  0.09327541023492814  inv_L_scale:  [1.0, 1.0]
Epoch :  143  Time:  0.94  Rel. Train L2 Loss :  0.06604768842458725  Rel. Test L2 Loss :  0.06553803473711013  Test L2 Loss :  0.09465797394514083  inv_L_scale:  [1.0, 1.0]
Epoch :  144  Time:  0.94  Rel. Train L2 Loss :  0.06585162616438336  Rel. Test L2 Loss :  0.06431903302669525  Test L2 Loss :  0.09281903356313706  inv_L_scale:  [1.0, 1.0]
Epoch :  145  Time:  0.94  Rel. Train L2 Loss :  0.0656948615445031  Rel. Test L2 Loss :  0.06857652217149734  Test L2 Loss :  0.09833460628986358  inv_L_scale:  [1.0, 1.0]
Epoch :  146  Time:  0.94  Rel. Train L2 Loss :  0.06575381942921214  Rel. Test L2 Loss :  0.0674360117316246  Test L2 Loss :  0.09680277168750763  inv_L_scale:  [1.0, 1.0]
Epoch :  147  Time:  0.939  Rel. Train L2 Loss :  0.06579786045683755  Rel. Test L2 Loss :  0.06615396082401276  Test L2 Loss :  0.09523069232702255  inv_L_scale:  [1.0, 1.0]
Epoch :  148  Time:  0.939  Rel. Train L2 Loss :  0.06594749248690075  Rel. Test L2 Loss :  0.06590801000595092  Test L2 Loss :  0.09518637597560882  inv_L_scale:  [1.0, 1.0]
Epoch :  149  Time:  0.941  Rel. Train L2 Loss :  0.06557013558016883  Rel. Test L2 Loss :  0.06602755457162857  Test L2 Loss :  0.0952095302939415  inv_L_scale:  [1.0, 1.0]
Epoch :  150  Time:  0.939  Rel. Train L2 Loss :  0.06648313947849803  Rel. Test L2 Loss :  0.06492681682109833  Test L2 Loss :  0.09341937601566315  inv_L_scale:  [1.0, 1.0]
Epoch :  151  Time:  0.939  Rel. Train L2 Loss :  0.06623830182684792  Rel. Test L2 Loss :  0.06691967457532882  Test L2 Loss :  0.09639837563037873  inv_L_scale:  [1.0, 1.0]
Epoch :  152  Time:  0.939  Rel. Train L2 Loss :  0.06570996512969335  Rel. Test L2 Loss :  0.06434884428977966  Test L2 Loss :  0.09282580584287643  inv_L_scale:  [1.0, 1.0]
Epoch :  153  Time:  0.939  Rel. Train L2 Loss :  0.06499380068646538  Rel. Test L2 Loss :  0.06472749412059783  Test L2 Loss :  0.0932472848892212  inv_L_scale:  [1.0, 1.0]
Epoch :  154  Time:  0.94  Rel. Train L2 Loss :  0.06571846309635375  Rel. Test L2 Loss :  0.07213938444852828  Test L2 Loss :  0.1030882453918457  inv_L_scale:  [1.0, 1.0]
Epoch :  155  Time:  0.939  Rel. Train L2 Loss :  0.06565981596708298  Rel. Test L2 Loss :  0.06604431807994843  Test L2 Loss :  0.09487091958522796  inv_L_scale:  [1.0, 1.0]
Epoch :  156  Time:  0.939  Rel. Train L2 Loss :  0.06543822871314155  Rel. Test L2 Loss :  0.06606266736984252  Test L2 Loss :  0.09520610243082046  inv_L_scale:  [1.0, 1.0]
Epoch :  157  Time:  0.942  Rel. Train L2 Loss :  0.06552160272995632  Rel. Test L2 Loss :  0.0640894502401352  Test L2 Loss :  0.09255362749099731  inv_L_scale:  [1.0, 1.0]
Epoch :  158  Time:  0.94  Rel. Train L2 Loss :  0.06505597104628881  Rel. Test L2 Loss :  0.06502174019813538  Test L2 Loss :  0.09382475614547729  inv_L_scale:  [1.0, 1.0]
Epoch :  159  Time:  0.939  Rel. Train L2 Loss :  0.06515234114395248  Rel. Test L2 Loss :  0.06668221980333328  Test L2 Loss :  0.09597913563251495  inv_L_scale:  [1.0, 1.0]
Epoch :  160  Time:  0.939  Rel. Train L2 Loss :  0.0650879556271765  Rel. Test L2 Loss :  0.06502168238162995  Test L2 Loss :  0.09367631465196609  inv_L_scale:  [1.0, 1.0]
Epoch :  161  Time:  0.939  Rel. Train L2 Loss :  0.06467915660805172  Rel. Test L2 Loss :  0.06468553453683853  Test L2 Loss :  0.0936264830827713  inv_L_scale:  [1.0, 1.0]
Epoch :  162  Time:  0.939  Rel. Train L2 Loss :  0.06493721955352359  Rel. Test L2 Loss :  0.06427085608243942  Test L2 Loss :  0.09292503714561462  inv_L_scale:  [1.0, 1.0]
Epoch :  163  Time:  0.939  Rel. Train L2 Loss :  0.0648562201195293  Rel. Test L2 Loss :  0.06502986371517182  Test L2 Loss :  0.09369435012340546  inv_L_scale:  [1.0, 1.0]
Epoch :  164  Time:  0.939  Rel. Train L2 Loss :  0.06500461339950561  Rel. Test L2 Loss :  0.06477632492780686  Test L2 Loss :  0.09327348291873933  inv_L_scale:  [1.0, 1.0]
Epoch :  165  Time:  0.939  Rel. Train L2 Loss :  0.06482443335983488  Rel. Test L2 Loss :  0.06503267586231232  Test L2 Loss :  0.09352630019187927  inv_L_scale:  [1.0, 1.0]
Epoch :  166  Time:  0.939  Rel. Train L2 Loss :  0.06456832074456745  Rel. Test L2 Loss :  0.06347349435091018  Test L2 Loss :  0.09164604395627976  inv_L_scale:  [1.0, 1.0]
Epoch :  167  Time:  0.939  Rel. Train L2 Loss :  0.06463811023367776  Rel. Test L2 Loss :  0.06446484178304672  Test L2 Loss :  0.09287085354328156  inv_L_scale:  [1.0, 1.0]
Epoch :  168  Time:  0.939  Rel. Train L2 Loss :  0.06478889531559415  Rel. Test L2 Loss :  0.06383484840393067  Test L2 Loss :  0.09201648324728012  inv_L_scale:  [1.0, 1.0]
Epoch :  169  Time:  0.939  Rel. Train L2 Loss :  0.06404273526536094  Rel. Test L2 Loss :  0.06730911463499069  Test L2 Loss :  0.09755910813808441  inv_L_scale:  [1.0, 1.0]
Epoch :  170  Time:  0.939  Rel. Train L2 Loss :  0.06471748444769118  Rel. Test L2 Loss :  0.0640779909491539  Test L2 Loss :  0.0927187865972519  inv_L_scale:  [1.0, 1.0]
Epoch :  171  Time:  0.939  Rel. Train L2 Loss :  0.06457975293199221  Rel. Test L2 Loss :  0.0638537946343422  Test L2 Loss :  0.09232976734638214  inv_L_scale:  [1.0, 1.0]
Epoch :  172  Time:  0.94  Rel. Train L2 Loss :  0.06438026623593436  Rel. Test L2 Loss :  0.06435504913330078  Test L2 Loss :  0.09317047148942947  inv_L_scale:  [1.0, 1.0]
Epoch :  173  Time:  0.939  Rel. Train L2 Loss :  0.06440543909867605  Rel. Test L2 Loss :  0.06353891849517822  Test L2 Loss :  0.0919304233789444  inv_L_scale:  [1.0, 1.0]
Epoch :  174  Time:  0.939  Rel. Train L2 Loss :  0.06431257489654753  Rel. Test L2 Loss :  0.06568439245223999  Test L2 Loss :  0.09489540636539459  inv_L_scale:  [1.0, 1.0]
Epoch :  175  Time:  0.939  Rel. Train L2 Loss :  0.06472282197740342  Rel. Test L2 Loss :  0.06348519444465638  Test L2 Loss :  0.091600920855999  inv_L_scale:  [1.0, 1.0]
Epoch :  176  Time:  0.939  Rel. Train L2 Loss :  0.0643018223841985  Rel. Test L2 Loss :  0.06550676673650742  Test L2 Loss :  0.09427076637744904  inv_L_scale:  [1.0, 1.0]
Epoch :  177  Time:  0.939  Rel. Train L2 Loss :  0.06418958928849962  Rel. Test L2 Loss :  0.06393236488103866  Test L2 Loss :  0.09234189212322236  inv_L_scale:  [1.0, 1.0]
Epoch :  178  Time:  0.939  Rel. Train L2 Loss :  0.06420439001586702  Rel. Test L2 Loss :  0.06513840705156326  Test L2 Loss :  0.0940477642416954  inv_L_scale:  [1.0, 1.0]
Epoch :  179  Time:  0.939  Rel. Train L2 Loss :  0.06391506108972761  Rel. Test L2 Loss :  0.06490148484706879  Test L2 Loss :  0.0933807823061943  inv_L_scale:  [1.0, 1.0]
Epoch :  180  Time:  0.94  Rel. Train L2 Loss :  0.063974848770433  Rel. Test L2 Loss :  0.06301965951919555  Test L2 Loss :  0.09116273522377014  inv_L_scale:  [1.0, 1.0]
Epoch :  181  Time:  0.939  Rel. Train L2 Loss :  0.06380681473347875  Rel. Test L2 Loss :  0.06664628595113754  Test L2 Loss :  0.0956970626115799  inv_L_scale:  [1.0, 1.0]
Epoch :  182  Time:  0.939  Rel. Train L2 Loss :  0.06381249340044128  Rel. Test L2 Loss :  0.06435155093669892  Test L2 Loss :  0.0928522264957428  inv_L_scale:  [1.0, 1.0]
Epoch :  183  Time:  0.939  Rel. Train L2 Loss :  0.06342812415626314  Rel. Test L2 Loss :  0.06295776396989822  Test L2 Loss :  0.09110661178827285  inv_L_scale:  [1.0, 1.0]
Epoch :  184  Time:  0.939  Rel. Train L2 Loss :  0.06356124695804384  Rel. Test L2 Loss :  0.06373434096574783  Test L2 Loss :  0.091881645321846  inv_L_scale:  [1.0, 1.0]
Epoch :  185  Time:  0.939  Rel. Train L2 Loss :  0.06357331893510289  Rel. Test L2 Loss :  0.06480708360671997  Test L2 Loss :  0.0935385486483574  inv_L_scale:  [1.0, 1.0]
Epoch :  186  Time:  0.939  Rel. Train L2 Loss :  0.06346883043646813  Rel. Test L2 Loss :  0.06316137045621872  Test L2 Loss :  0.09105870515108108  inv_L_scale:  [1.0, 1.0]
Epoch :  187  Time:  0.939  Rel. Train L2 Loss :  0.06363853961229324  Rel. Test L2 Loss :  0.06266127407550812  Test L2 Loss :  0.0905884039402008  inv_L_scale:  [1.0, 1.0]
Epoch :  188  Time:  0.939  Rel. Train L2 Loss :  0.06391585942771699  Rel. Test L2 Loss :  0.0631899219751358  Test L2 Loss :  0.09134422451257705  inv_L_scale:  [1.0, 1.0]
Epoch :  189  Time:  0.94  Rel. Train L2 Loss :  0.0636199625995424  Rel. Test L2 Loss :  0.0653055500984192  Test L2 Loss :  0.09480526566505432  inv_L_scale:  [1.0, 1.0]
Epoch :  190  Time:  0.942  Rel. Train L2 Loss :  0.06376060436169306  Rel. Test L2 Loss :  0.06297363579273224  Test L2 Loss :  0.09099576056003571  inv_L_scale:  [1.0, 1.0]
Epoch :  191  Time:  0.939  Rel. Train L2 Loss :  0.0632886998852094  Rel. Test L2 Loss :  0.06363694190979004  Test L2 Loss :  0.09201694875955582  inv_L_scale:  [1.0, 1.0]
Epoch :  192  Time:  0.939  Rel. Train L2 Loss :  0.0635882635249032  Rel. Test L2 Loss :  0.06384986102581024  Test L2 Loss :  0.09207427591085433  inv_L_scale:  [1.0, 1.0]
Epoch :  193  Time:  0.939  Rel. Train L2 Loss :  0.06366085631979837  Rel. Test L2 Loss :  0.06606081426143647  Test L2 Loss :  0.09517380625009536  inv_L_scale:  [1.0, 1.0]
Epoch :  194  Time:  0.939  Rel. Train L2 Loss :  0.0635272290971544  Rel. Test L2 Loss :  0.06420938730239868  Test L2 Loss :  0.09264654517173768  inv_L_scale:  [1.0, 1.0]
Epoch :  195  Time:  0.939  Rel. Train L2 Loss :  0.0632885593507025  Rel. Test L2 Loss :  0.06223946422338486  Test L2 Loss :  0.08975074172019959  inv_L_scale:  [1.0, 1.0]
Epoch :  196  Time:  0.939  Rel. Train L2 Loss :  0.06340855171283086  Rel. Test L2 Loss :  0.06415421456098556  Test L2 Loss :  0.09254227459430694  inv_L_scale:  [1.0, 1.0]
Epoch :  197  Time:  0.939  Rel. Train L2 Loss :  0.06309552599986394  Rel. Test L2 Loss :  0.06521998703479767  Test L2 Loss :  0.0939019674062729  inv_L_scale:  [1.0, 1.0]
Epoch :  198  Time:  0.94  Rel. Train L2 Loss :  0.0629234598411454  Rel. Test L2 Loss :  0.06351728528738022  Test L2 Loss :  0.09152148991823196  inv_L_scale:  [1.0, 1.0]
Epoch :  199  Time:  0.94  Rel. Train L2 Loss :  0.0629756929145919  Rel. Test L2 Loss :  0.06298030495643615  Test L2 Loss :  0.09086015224456787  inv_L_scale:  [1.0, 1.0]
Epoch :  200  Time:  0.939  Rel. Train L2 Loss :  0.06308253314759996  Rel. Test L2 Loss :  0.06385143131017684  Test L2 Loss :  0.09210915863513947  inv_L_scale:  [1.0, 1.0]
Epoch :  201  Time:  0.939  Rel. Train L2 Loss :  0.06284384234084023  Rel. Test L2 Loss :  0.06422031849622727  Test L2 Loss :  0.09246810704469681  inv_L_scale:  [1.0, 1.0]
Epoch :  202  Time:  0.939  Rel. Train L2 Loss :  0.06316126018762588  Rel. Test L2 Loss :  0.06347396790981293  Test L2 Loss :  0.0917628875374794  inv_L_scale:  [1.0, 1.0]
Epoch :  203  Time:  0.939  Rel. Train L2 Loss :  0.062751478585932  Rel. Test L2 Loss :  0.06356403231620789  Test L2 Loss :  0.09181759297847748  inv_L_scale:  [1.0, 1.0]
Epoch :  204  Time:  0.939  Rel. Train L2 Loss :  0.06259471313820945  Rel. Test L2 Loss :  0.06288363009691239  Test L2 Loss :  0.09085719734430313  inv_L_scale:  [1.0, 1.0]
Epoch :  205  Time:  0.939  Rel. Train L2 Loss :  0.06286899333198866  Rel. Test L2 Loss :  0.06403303444385529  Test L2 Loss :  0.09258448153734207  inv_L_scale:  [1.0, 1.0]
Epoch :  206  Time:  0.939  Rel. Train L2 Loss :  0.06256272700097826  Rel. Test L2 Loss :  0.06491231620311737  Test L2 Loss :  0.09389788389205933  inv_L_scale:  [1.0, 1.0]
Epoch :  207  Time:  0.94  Rel. Train L2 Loss :  0.06321967360046175  Rel. Test L2 Loss :  0.0640126782655716  Test L2 Loss :  0.09278803408145904  inv_L_scale:  [1.0, 1.0]
Epoch :  208  Time:  0.94  Rel. Train L2 Loss :  0.062791661520799  Rel. Test L2 Loss :  0.06300575643777848  Test L2 Loss :  0.09125701129436493  inv_L_scale:  [1.0, 1.0]
Epoch :  209  Time:  0.939  Rel. Train L2 Loss :  0.0626121527618832  Rel. Test L2 Loss :  0.061943417489528654  Test L2 Loss :  0.08984634041786194  inv_L_scale:  [1.0, 1.0]
Epoch :  210  Time:  0.939  Rel. Train L2 Loss :  0.0627948800722758  Rel. Test L2 Loss :  0.0623080912232399  Test L2 Loss :  0.089998639523983  inv_L_scale:  [1.0, 1.0]
Epoch :  211  Time:  0.939  Rel. Train L2 Loss :  0.0624820057882203  Rel. Test L2 Loss :  0.0626684308052063  Test L2 Loss :  0.09046782225370407  inv_L_scale:  [1.0, 1.0]
Epoch :  212  Time:  0.939  Rel. Train L2 Loss :  0.06249769570098983  Rel. Test L2 Loss :  0.06274717658758164  Test L2 Loss :  0.09080365896224976  inv_L_scale:  [1.0, 1.0]
Epoch :  213  Time:  0.938  Rel. Train L2 Loss :  0.06221707062588798  Rel. Test L2 Loss :  0.06362289994955063  Test L2 Loss :  0.09186244577169418  inv_L_scale:  [1.0, 1.0]
Epoch :  214  Time:  0.939  Rel. Train L2 Loss :  0.06279755648639467  Rel. Test L2 Loss :  0.06178152471780777  Test L2 Loss :  0.08944079905748367  inv_L_scale:  [1.0, 1.0]
Epoch :  215  Time:  0.939  Rel. Train L2 Loss :  0.06241416454315186  Rel. Test L2 Loss :  0.06190207690000534  Test L2 Loss :  0.0893662679195404  inv_L_scale:  [1.0, 1.0]
Epoch :  216  Time:  0.939  Rel. Train L2 Loss :  0.06232954194148382  Rel. Test L2 Loss :  0.06274473205208779  Test L2 Loss :  0.09056374073028564  inv_L_scale:  [1.0, 1.0]
Epoch :  217  Time:  0.939  Rel. Train L2 Loss :  0.06240333307120535  Rel. Test L2 Loss :  0.06187347561120987  Test L2 Loss :  0.08953960835933686  inv_L_scale:  [1.0, 1.0]
Epoch :  218  Time:  0.941  Rel. Train L2 Loss :  0.06229449348317252  Rel. Test L2 Loss :  0.061837014257907864  Test L2 Loss :  0.08943771362304688  inv_L_scale:  [1.0, 1.0]
Epoch :  219  Time:  0.94  Rel. Train L2 Loss :  0.06253430118163426  Rel. Test L2 Loss :  0.06285946071147919  Test L2 Loss :  0.0907512503862381  inv_L_scale:  [1.0, 1.0]
Epoch :  220  Time:  0.939  Rel. Train L2 Loss :  0.06239379654328028  Rel. Test L2 Loss :  0.06563048422336579  Test L2 Loss :  0.09437546491622925  inv_L_scale:  [1.0, 1.0]
Epoch :  221  Time:  0.939  Rel. Train L2 Loss :  0.06216321587562561  Rel. Test L2 Loss :  0.06211469531059265  Test L2 Loss :  0.08970489978790283  inv_L_scale:  [1.0, 1.0]
Epoch :  222  Time:  0.94  Rel. Train L2 Loss :  0.06203694442907969  Rel. Test L2 Loss :  0.06311637073755265  Test L2 Loss :  0.0909979796409607  inv_L_scale:  [1.0, 1.0]
Epoch :  223  Time:  0.939  Rel. Train L2 Loss :  0.06216061313947042  Rel. Test L2 Loss :  0.06295913815498352  Test L2 Loss :  0.09066977113485336  inv_L_scale:  [1.0, 1.0]
Epoch :  224  Time:  0.94  Rel. Train L2 Loss :  0.06210729961593946  Rel. Test L2 Loss :  0.06163298547267914  Test L2 Loss :  0.08901081204414368  inv_L_scale:  [1.0, 1.0]
Epoch :  225  Time:  0.942  Rel. Train L2 Loss :  0.06207196394602458  Rel. Test L2 Loss :  0.06326040655374526  Test L2 Loss :  0.09174830973148346  inv_L_scale:  [1.0, 1.0]
Epoch :  226  Time:  0.941  Rel. Train L2 Loss :  0.06172076576285892  Rel. Test L2 Loss :  0.06344499468803405  Test L2 Loss :  0.09169523179531097  inv_L_scale:  [1.0, 1.0]
Epoch :  227  Time:  0.94  Rel. Train L2 Loss :  0.06186832611759504  Rel. Test L2 Loss :  0.0632825630903244  Test L2 Loss :  0.0914989846944809  inv_L_scale:  [1.0, 1.0]
Epoch :  228  Time:  0.94  Rel. Train L2 Loss :  0.062042952676614124  Rel. Test L2 Loss :  0.062372353374958035  Test L2 Loss :  0.09013756722211838  inv_L_scale:  [1.0, 1.0]
Epoch :  229  Time:  0.94  Rel. Train L2 Loss :  0.06214038858811061  Rel. Test L2 Loss :  0.06275104314088821  Test L2 Loss :  0.09083333373069763  inv_L_scale:  [1.0, 1.0]
Epoch :  230  Time:  0.94  Rel. Train L2 Loss :  0.06192007134358088  Rel. Test L2 Loss :  0.06233333379030228  Test L2 Loss :  0.09026399195194244  inv_L_scale:  [1.0, 1.0]
Epoch :  231  Time:  0.94  Rel. Train L2 Loss :  0.061681899080673855  Rel. Test L2 Loss :  0.06385665804147721  Test L2 Loss :  0.09203378558158874  inv_L_scale:  [1.0, 1.0]
Epoch :  232  Time:  0.94  Rel. Train L2 Loss :  0.06180655810568068  Rel. Test L2 Loss :  0.06292459607124329  Test L2 Loss :  0.09063459128141403  inv_L_scale:  [1.0, 1.0]
Epoch :  233  Time:  0.94  Rel. Train L2 Loss :  0.0618101766705513  Rel. Test L2 Loss :  0.062494210600852966  Test L2 Loss :  0.09030977189540863  inv_L_scale:  [1.0, 1.0]
Epoch :  234  Time:  0.94  Rel. Train L2 Loss :  0.0616347360279825  Rel. Test L2 Loss :  0.06275836676359177  Test L2 Loss :  0.0908046504855156  inv_L_scale:  [1.0, 1.0]
Epoch :  235  Time:  0.94  Rel. Train L2 Loss :  0.061790499654081135  Rel. Test L2 Loss :  0.06418638706207275  Test L2 Loss :  0.09264768838882446  inv_L_scale:  [1.0, 1.0]
Epoch :  236  Time:  0.94  Rel. Train L2 Loss :  0.061548272371292116  Rel. Test L2 Loss :  0.06160605400800705  Test L2 Loss :  0.08920029670000076  inv_L_scale:  [1.0, 1.0]
Epoch :  237  Time:  0.94  Rel. Train L2 Loss :  0.06143315768904156  Rel. Test L2 Loss :  0.06225842624902725  Test L2 Loss :  0.0899696746468544  inv_L_scale:  [1.0, 1.0]
Epoch :  238  Time:  0.94  Rel. Train L2 Loss :  0.06129039618704054  Rel. Test L2 Loss :  0.06142122983932495  Test L2 Loss :  0.08898780524730682  inv_L_scale:  [1.0, 1.0]
Epoch :  239  Time:  0.94  Rel. Train L2 Loss :  0.06128375427590476  Rel. Test L2 Loss :  0.06369601756334305  Test L2 Loss :  0.09207040697336197  inv_L_scale:  [1.0, 1.0]
Epoch :  240  Time:  0.941  Rel. Train L2 Loss :  0.061593204687039056  Rel. Test L2 Loss :  0.06144939839839935  Test L2 Loss :  0.08894378095865249  inv_L_scale:  [1.0, 1.0]
Epoch :  241  Time:  0.941  Rel. Train L2 Loss :  0.0616060865090953  Rel. Test L2 Loss :  0.06395581156015397  Test L2 Loss :  0.09210858881473541  inv_L_scale:  [1.0, 1.0]
Epoch :  242  Time:  0.94  Rel. Train L2 Loss :  0.061446939706802366  Rel. Test L2 Loss :  0.0618843275308609  Test L2 Loss :  0.08924072444438934  inv_L_scale:  [1.0, 1.0]
Epoch :  243  Time:  0.94  Rel. Train L2 Loss :  0.06147729582256741  Rel. Test L2 Loss :  0.0618702706694603  Test L2 Loss :  0.08937386512756347  inv_L_scale:  [1.0, 1.0]
Epoch :  244  Time:  0.94  Rel. Train L2 Loss :  0.061517676843537226  Rel. Test L2 Loss :  0.0624729859828949  Test L2 Loss :  0.09040243148803712  inv_L_scale:  [1.0, 1.0]
Epoch :  245  Time:  0.94  Rel. Train L2 Loss :  0.06122626827822791  Rel. Test L2 Loss :  0.06199325516819954  Test L2 Loss :  0.08966359794139862  inv_L_scale:  [1.0, 1.0]
Epoch :  246  Time:  0.94  Rel. Train L2 Loss :  0.061438570320606234  Rel. Test L2 Loss :  0.06282501637935639  Test L2 Loss :  0.09068039208650588  inv_L_scale:  [1.0, 1.0]
Epoch :  247  Time:  0.94  Rel. Train L2 Loss :  0.06151893729964892  Rel. Test L2 Loss :  0.06290562361478806  Test L2 Loss :  0.09083236098289489  inv_L_scale:  [1.0, 1.0]
Epoch :  248  Time:  0.94  Rel. Train L2 Loss :  0.061076107223828634  Rel. Test L2 Loss :  0.06183723449707031  Test L2 Loss :  0.08954117864370346  inv_L_scale:  [1.0, 1.0]
Epoch :  249  Time:  0.94  Rel. Train L2 Loss :  0.061137083421150845  Rel. Test L2 Loss :  0.061772974282503126  Test L2 Loss :  0.08928445875644683  inv_L_scale:  [1.0, 1.0]
Epoch :  250  Time:  0.942  Rel. Train L2 Loss :  0.061035120321644674  Rel. Test L2 Loss :  0.06188883721828461  Test L2 Loss :  0.08944885432720184  inv_L_scale:  [1.0, 1.0]
Epoch :  251  Time:  0.943  Rel. Train L2 Loss :  0.06122273423605495  Rel. Test L2 Loss :  0.062131756842136385  Test L2 Loss :  0.08979499667882919  inv_L_scale:  [1.0, 1.0]
Epoch :  252  Time:  0.94  Rel. Train L2 Loss :  0.06123070634073681  Rel. Test L2 Loss :  0.06224536329507828  Test L2 Loss :  0.08995945543050766  inv_L_scale:  [1.0, 1.0]
Epoch :  253  Time:  0.94  Rel. Train L2 Loss :  0.06096795005930795  Rel. Test L2 Loss :  0.06243381679058075  Test L2 Loss :  0.09048005580902099  inv_L_scale:  [1.0, 1.0]
Epoch :  254  Time:  0.943  Rel. Train L2 Loss :  0.061311847170193993  Rel. Test L2 Loss :  0.06169149965047836  Test L2 Loss :  0.08914635598659515  inv_L_scale:  [1.0, 1.0]
Epoch :  255  Time:  0.94  Rel. Train L2 Loss :  0.06106837105419901  Rel. Test L2 Loss :  0.06194825917482376  Test L2 Loss :  0.08938802719116211  inv_L_scale:  [1.0, 1.0]
Epoch :  256  Time:  0.939  Rel. Train L2 Loss :  0.060897737840811414  Rel. Test L2 Loss :  0.06047482833266258  Test L2 Loss :  0.08754773557186127  inv_L_scale:  [1.0, 1.0]
Epoch :  257  Time:  0.939  Rel. Train L2 Loss :  0.06077094955576791  Rel. Test L2 Loss :  0.06119878441095352  Test L2 Loss :  0.08854649782180786  inv_L_scale:  [1.0, 1.0]
Epoch :  258  Time:  0.939  Rel. Train L2 Loss :  0.060671765903631845  Rel. Test L2 Loss :  0.06090033620595932  Test L2 Loss :  0.08810922503471375  inv_L_scale:  [1.0, 1.0]
Epoch :  259  Time:  0.939  Rel. Train L2 Loss :  0.06068981021642685  Rel. Test L2 Loss :  0.062312277853488925  Test L2 Loss :  0.09000894963741303  inv_L_scale:  [1.0, 1.0]
Epoch :  260  Time:  0.939  Rel. Train L2 Loss :  0.06067148251665963  Rel. Test L2 Loss :  0.061251307129859926  Test L2 Loss :  0.08848349124193192  inv_L_scale:  [1.0, 1.0]
Epoch :  261  Time:  0.939  Rel. Train L2 Loss :  0.06073041942384508  Rel. Test L2 Loss :  0.060556065440177914  Test L2 Loss :  0.08772281974554062  inv_L_scale:  [1.0, 1.0]
Epoch :  262  Time:  0.939  Rel. Train L2 Loss :  0.06075109375847711  Rel. Test L2 Loss :  0.06181110590696335  Test L2 Loss :  0.0892970895767212  inv_L_scale:  [1.0, 1.0]
Epoch :  263  Time:  0.941  Rel. Train L2 Loss :  0.06060597280661265  Rel. Test L2 Loss :  0.06164731532335281  Test L2 Loss :  0.0888965117931366  inv_L_scale:  [1.0, 1.0]
Epoch :  264  Time:  0.94  Rel. Train L2 Loss :  0.060730654862191945  Rel. Test L2 Loss :  0.061655195951461794  Test L2 Loss :  0.0891065776348114  inv_L_scale:  [1.0, 1.0]
Epoch :  265  Time:  0.939  Rel. Train L2 Loss :  0.060590399040116205  Rel. Test L2 Loss :  0.061291114389896394  Test L2 Loss :  0.08859067380428315  inv_L_scale:  [1.0, 1.0]
Epoch :  266  Time:  0.94  Rel. Train L2 Loss :  0.0603949041167895  Rel. Test L2 Loss :  0.060476570427417754  Test L2 Loss :  0.08760010063648224  inv_L_scale:  [1.0, 1.0]
Epoch :  267  Time:  0.939  Rel. Train L2 Loss :  0.06050646980603536  Rel. Test L2 Loss :  0.06123450458049774  Test L2 Loss :  0.08858955502510071  inv_L_scale:  [1.0, 1.0]
Epoch :  268  Time:  0.94  Rel. Train L2 Loss :  0.06067724150088098  Rel. Test L2 Loss :  0.06064954161643982  Test L2 Loss :  0.08783582746982574  inv_L_scale:  [1.0, 1.0]
Epoch :  269  Time:  0.94  Rel. Train L2 Loss :  0.06044394592444102  Rel. Test L2 Loss :  0.06242723345756531  Test L2 Loss :  0.090179183781147  inv_L_scale:  [1.0, 1.0]
Epoch :  270  Time:  0.94  Rel. Train L2 Loss :  0.06046351108286116  Rel. Test L2 Loss :  0.06121289640665054  Test L2 Loss :  0.0885374402999878  inv_L_scale:  [1.0, 1.0]
Epoch :  271  Time:  0.94  Rel. Train L2 Loss :  0.06043276679184702  Rel. Test L2 Loss :  0.06101325362920761  Test L2 Loss :  0.08803418576717377  inv_L_scale:  [1.0, 1.0]
Epoch :  272  Time:  0.94  Rel. Train L2 Loss :  0.060437448157204525  Rel. Test L2 Loss :  0.06131969809532165  Test L2 Loss :  0.08864903688430786  inv_L_scale:  [1.0, 1.0]
Epoch :  273  Time:  0.942  Rel. Train L2 Loss :  0.060388341049353284  Rel. Test L2 Loss :  0.06107324093580246  Test L2 Loss :  0.08832579642534256  inv_L_scale:  [1.0, 1.0]
Epoch :  274  Time:  0.942  Rel. Train L2 Loss :  0.06025129973888397  Rel. Test L2 Loss :  0.061012822389602664  Test L2 Loss :  0.0882033959031105  inv_L_scale:  [1.0, 1.0]
Epoch :  275  Time:  0.941  Rel. Train L2 Loss :  0.06030146320660909  Rel. Test L2 Loss :  0.061060872972011564  Test L2 Loss :  0.08839350581169128  inv_L_scale:  [1.0, 1.0]
Epoch :  276  Time:  0.94  Rel. Train L2 Loss :  0.06041356003946728  Rel. Test L2 Loss :  0.06028144180774689  Test L2 Loss :  0.08722861170768738  inv_L_scale:  [1.0, 1.0]
Epoch :  277  Time:  0.94  Rel. Train L2 Loss :  0.06022897717025545  Rel. Test L2 Loss :  0.06015191286802292  Test L2 Loss :  0.08707431972026825  inv_L_scale:  [1.0, 1.0]
Epoch :  278  Time:  0.94  Rel. Train L2 Loss :  0.06015264405144585  Rel. Test L2 Loss :  0.06095792710781098  Test L2 Loss :  0.08822284281253814  inv_L_scale:  [1.0, 1.0]
Epoch :  279  Time:  0.94  Rel. Train L2 Loss :  0.05990564049945937  Rel. Test L2 Loss :  0.06082998543977738  Test L2 Loss :  0.08794811427593231  inv_L_scale:  [1.0, 1.0]
Epoch :  280  Time:  0.941  Rel. Train L2 Loss :  0.06004528651634852  Rel. Test L2 Loss :  0.06032742783427238  Test L2 Loss :  0.08736832171678544  inv_L_scale:  [1.0, 1.0]
Epoch :  281  Time:  0.94  Rel. Train L2 Loss :  0.06015633311536577  Rel. Test L2 Loss :  0.060854199528694156  Test L2 Loss :  0.08798053562641144  inv_L_scale:  [1.0, 1.0]
Epoch :  282  Time:  0.939  Rel. Train L2 Loss :  0.059925889124472935  Rel. Test L2 Loss :  0.06076519727706909  Test L2 Loss :  0.08790418654680252  inv_L_scale:  [1.0, 1.0]
Epoch :  283  Time:  0.939  Rel. Train L2 Loss :  0.06003806406425105  Rel. Test L2 Loss :  0.061114504635334015  Test L2 Loss :  0.08829000294208526  inv_L_scale:  [1.0, 1.0]
Epoch :  284  Time:  0.939  Rel. Train L2 Loss :  0.05991410232252545  Rel. Test L2 Loss :  0.060830042362213135  Test L2 Loss :  0.0881013023853302  inv_L_scale:  [1.0, 1.0]
Epoch :  285  Time:  0.939  Rel. Train L2 Loss :  0.05990318030118942  Rel. Test L2 Loss :  0.06052596986293793  Test L2 Loss :  0.08750261306762695  inv_L_scale:  [1.0, 1.0]
Epoch :  286  Time:  0.939  Rel. Train L2 Loss :  0.059896767454014885  Rel. Test L2 Loss :  0.06143288001418114  Test L2 Loss :  0.08877367436885834  inv_L_scale:  [1.0, 1.0]
Epoch :  287  Time:  0.939  Rel. Train L2 Loss :  0.06012782548864683  Rel. Test L2 Loss :  0.06052668064832687  Test L2 Loss :  0.08770231425762176  inv_L_scale:  [1.0, 1.0]
Epoch :  288  Time:  0.939  Rel. Train L2 Loss :  0.059727551970216966  Rel. Test L2 Loss :  0.06087800458073616  Test L2 Loss :  0.08815107226371766  inv_L_scale:  [1.0, 1.0]
Epoch :  289  Time:  0.94  Rel. Train L2 Loss :  0.059770331117841934  Rel. Test L2 Loss :  0.05996986910700798  Test L2 Loss :  0.08685097932815551  inv_L_scale:  [1.0, 1.0]
Epoch :  290  Time:  0.941  Rel. Train L2 Loss :  0.0598141798708174  Rel. Test L2 Loss :  0.06071994841098785  Test L2 Loss :  0.08786348700523376  inv_L_scale:  [1.0, 1.0]
Epoch :  291  Time:  0.939  Rel. Train L2 Loss :  0.05972493913438585  Rel. Test L2 Loss :  0.06113185703754425  Test L2 Loss :  0.08830692738294602  inv_L_scale:  [1.0, 1.0]
Epoch :  292  Time:  0.94  Rel. Train L2 Loss :  0.05981356605887413  Rel. Test L2 Loss :  0.06054290950298309  Test L2 Loss :  0.08767303049564362  inv_L_scale:  [1.0, 1.0]
Epoch :  293  Time:  0.94  Rel. Train L2 Loss :  0.05957278826170497  Rel. Test L2 Loss :  0.06027476668357849  Test L2 Loss :  0.08727038413286209  inv_L_scale:  [1.0, 1.0]
Epoch :  294  Time:  0.94  Rel. Train L2 Loss :  0.05963006661997901  Rel. Test L2 Loss :  0.060426712930202485  Test L2 Loss :  0.08736945062875748  inv_L_scale:  [1.0, 1.0]
Epoch :  295  Time:  0.94  Rel. Train L2 Loss :  0.059991934299468995  Rel. Test L2 Loss :  0.06086224943399429  Test L2 Loss :  0.08816131979227065  inv_L_scale:  [1.0, 1.0]
Epoch :  296  Time:  0.94  Rel. Train L2 Loss :  0.059725722836123575  Rel. Test L2 Loss :  0.06084949612617493  Test L2 Loss :  0.08789907187223435  inv_L_scale:  [1.0, 1.0]
Epoch :  297  Time:  0.94  Rel. Train L2 Loss :  0.059602797776460645  Rel. Test L2 Loss :  0.059910869896411895  Test L2 Loss :  0.08679623693227768  inv_L_scale:  [1.0, 1.0]
Epoch :  298  Time:  0.94  Rel. Train L2 Loss :  0.059397193127208286  Rel. Test L2 Loss :  0.05984338507056236  Test L2 Loss :  0.08659786522388459  inv_L_scale:  [1.0, 1.0]
Epoch :  299  Time:  0.94  Rel. Train L2 Loss :  0.059387632575300005  Rel. Test L2 Loss :  0.06071137547492981  Test L2 Loss :  0.08786575585603713  inv_L_scale:  [1.0, 1.0]
Epoch :  300  Time:  0.94  Rel. Train L2 Loss :  0.059357789324389565  Rel. Test L2 Loss :  0.06049952864646912  Test L2 Loss :  0.08741762161254883  inv_L_scale:  [1.0, 1.0]
Epoch :  301  Time:  0.94  Rel. Train L2 Loss :  0.059350939790407814  Rel. Test L2 Loss :  0.059788079261779786  Test L2 Loss :  0.08651397705078125  inv_L_scale:  [1.0, 1.0]
Epoch :  302  Time:  0.94  Rel. Train L2 Loss :  0.05943924413786994  Rel. Test L2 Loss :  0.06050004094839096  Test L2 Loss :  0.08761218965053558  inv_L_scale:  [1.0, 1.0]
Epoch :  303  Time:  0.941  Rel. Train L2 Loss :  0.05943522264560064  Rel. Test L2 Loss :  0.05990234196186066  Test L2 Loss :  0.08695273071527482  inv_L_scale:  [1.0, 1.0]
Epoch :  304  Time:  0.94  Rel. Train L2 Loss :  0.059198054869969687  Rel. Test L2 Loss :  0.06042587578296661  Test L2 Loss :  0.0876446732878685  inv_L_scale:  [1.0, 1.0]
Epoch :  305  Time:  0.94  Rel. Train L2 Loss :  0.05944369826051924  Rel. Test L2 Loss :  0.05975549876689911  Test L2 Loss :  0.0863771241903305  inv_L_scale:  [1.0, 1.0]
Epoch :  306  Time:  0.94  Rel. Train L2 Loss :  0.059291228983137344  Rel. Test L2 Loss :  0.0602289205789566  Test L2 Loss :  0.08710125625133515  inv_L_scale:  [1.0, 1.0]
Epoch :  307  Time:  0.94  Rel. Train L2 Loss :  0.059153933525085446  Rel. Test L2 Loss :  0.0610396933555603  Test L2 Loss :  0.08836336672306061  inv_L_scale:  [1.0, 1.0]
Epoch :  308  Time:  0.94  Rel. Train L2 Loss :  0.05932251165310542  Rel. Test L2 Loss :  0.06085687682032585  Test L2 Loss :  0.08807265371084214  inv_L_scale:  [1.0, 1.0]
Epoch :  309  Time:  0.94  Rel. Train L2 Loss :  0.05925229208336936  Rel. Test L2 Loss :  0.05966867446899414  Test L2 Loss :  0.08638127803802491  inv_L_scale:  [1.0, 1.0]
Epoch :  310  Time:  0.94  Rel. Train L2 Loss :  0.05908702108595106  Rel. Test L2 Loss :  0.06002868860960007  Test L2 Loss :  0.0870380824804306  inv_L_scale:  [1.0, 1.0]
Epoch :  311  Time:  0.94  Rel. Train L2 Loss :  0.05901553955343034  Rel. Test L2 Loss :  0.060357902050018314  Test L2 Loss :  0.08749689429998397  inv_L_scale:  [1.0, 1.0]
Epoch :  312  Time:  0.939  Rel. Train L2 Loss :  0.05908222119841311  Rel. Test L2 Loss :  0.059975045174360274  Test L2 Loss :  0.08693735241889954  inv_L_scale:  [1.0, 1.0]
Epoch :  313  Time:  0.94  Rel. Train L2 Loss :  0.05892846037944158  Rel. Test L2 Loss :  0.06031538218259811  Test L2 Loss :  0.08726825207471847  inv_L_scale:  [1.0, 1.0]
Epoch :  314  Time:  0.94  Rel. Train L2 Loss :  0.0590596138437589  Rel. Test L2 Loss :  0.059322391003370285  Test L2 Loss :  0.08592564523220063  inv_L_scale:  [1.0, 1.0]
Epoch :  315  Time:  0.94  Rel. Train L2 Loss :  0.059012091706196465  Rel. Test L2 Loss :  0.05978554904460907  Test L2 Loss :  0.08639993846416473  inv_L_scale:  [1.0, 1.0]
Epoch :  316  Time:  0.94  Rel. Train L2 Loss :  0.058919321364826624  Rel. Test L2 Loss :  0.059548433125019076  Test L2 Loss :  0.08630847990512848  inv_L_scale:  [1.0, 1.0]
Epoch :  317  Time:  0.942  Rel. Train L2 Loss :  0.05904755456580056  Rel. Test L2 Loss :  0.05925315290689468  Test L2 Loss :  0.08595243573188782  inv_L_scale:  [1.0, 1.0]
Epoch :  318  Time:  0.939  Rel. Train L2 Loss :  0.05874044289191564  Rel. Test L2 Loss :  0.06016443207859993  Test L2 Loss :  0.08697750568389892  inv_L_scale:  [1.0, 1.0]
Epoch :  319  Time:  0.94  Rel. Train L2 Loss :  0.05878819475571315  Rel. Test L2 Loss :  0.05935531735420227  Test L2 Loss :  0.08596614718437195  inv_L_scale:  [1.0, 1.0]
Epoch :  320  Time:  0.94  Rel. Train L2 Loss :  0.05872585677438312  Rel. Test L2 Loss :  0.05934437617659569  Test L2 Loss :  0.08593950033187867  inv_L_scale:  [1.0, 1.0]
Epoch :  321  Time:  0.94  Rel. Train L2 Loss :  0.05885554073585404  Rel. Test L2 Loss :  0.05986222356557846  Test L2 Loss :  0.08671218872070313  inv_L_scale:  [1.0, 1.0]
Epoch :  322  Time:  0.94  Rel. Train L2 Loss :  0.05858249914315012  Rel. Test L2 Loss :  0.06032765030860901  Test L2 Loss :  0.08731424689292908  inv_L_scale:  [1.0, 1.0]
Epoch :  323  Time:  0.94  Rel. Train L2 Loss :  0.058783807555834455  Rel. Test L2 Loss :  0.059645525217056274  Test L2 Loss :  0.08641695857048035  inv_L_scale:  [1.0, 1.0]
Epoch :  324  Time:  0.939  Rel. Train L2 Loss :  0.05857351402441661  Rel. Test L2 Loss :  0.05964439168572426  Test L2 Loss :  0.08635715126991272  inv_L_scale:  [1.0, 1.0]
Epoch :  325  Time:  0.94  Rel. Train L2 Loss :  0.05865286909871631  Rel. Test L2 Loss :  0.059458815604448316  Test L2 Loss :  0.08621634960174561  inv_L_scale:  [1.0, 1.0]
Epoch :  326  Time:  0.94  Rel. Train L2 Loss :  0.058736792190207374  Rel. Test L2 Loss :  0.05963724449276924  Test L2 Loss :  0.08629923313856125  inv_L_scale:  [1.0, 1.0]
Epoch :  327  Time:  0.939  Rel. Train L2 Loss :  0.0586378413438797  Rel. Test L2 Loss :  0.05947432965040207  Test L2 Loss :  0.08609330952167511  inv_L_scale:  [1.0, 1.0]
Epoch :  328  Time:  0.94  Rel. Train L2 Loss :  0.05871469706296921  Rel. Test L2 Loss :  0.05933294340968132  Test L2 Loss :  0.08589319854974747  inv_L_scale:  [1.0, 1.0]
Epoch :  329  Time:  0.939  Rel. Train L2 Loss :  0.05858924945195516  Rel. Test L2 Loss :  0.05902130737900734  Test L2 Loss :  0.08550787329673767  inv_L_scale:  [1.0, 1.0]
Epoch :  330  Time:  0.94  Rel. Train L2 Loss :  0.0585892444021172  Rel. Test L2 Loss :  0.059832566380500794  Test L2 Loss :  0.08657172113656998  inv_L_scale:  [1.0, 1.0]
Epoch :  331  Time:  0.939  Rel. Train L2 Loss :  0.05842097863554954  Rel. Test L2 Loss :  0.05908439919352532  Test L2 Loss :  0.08552169591188431  inv_L_scale:  [1.0, 1.0]
Epoch :  332  Time:  0.939  Rel. Train L2 Loss :  0.05847164380881521  Rel. Test L2 Loss :  0.05970824003219605  Test L2 Loss :  0.08631631553173065  inv_L_scale:  [1.0, 1.0]
Epoch :  333  Time:  0.942  Rel. Train L2 Loss :  0.05841887798574236  Rel. Test L2 Loss :  0.05969270974397659  Test L2 Loss :  0.08640712708234786  inv_L_scale:  [1.0, 1.0]
Epoch :  334  Time:  0.94  Rel. Train L2 Loss :  0.0583830170167817  Rel. Test L2 Loss :  0.059687746465206144  Test L2 Loss :  0.08646872401237488  inv_L_scale:  [1.0, 1.0]
Epoch :  335  Time:  0.94  Rel. Train L2 Loss :  0.05842087285386192  Rel. Test L2 Loss :  0.05936891913414002  Test L2 Loss :  0.08594626724720002  inv_L_scale:  [1.0, 1.0]
Epoch :  336  Time:  0.939  Rel. Train L2 Loss :  0.058332824607690174  Rel. Test L2 Loss :  0.05904760465025902  Test L2 Loss :  0.08556037157773971  inv_L_scale:  [1.0, 1.0]
Epoch :  337  Time:  0.939  Rel. Train L2 Loss :  0.058342665400769975  Rel. Test L2 Loss :  0.05900391429662705  Test L2 Loss :  0.08545439332723617  inv_L_scale:  [1.0, 1.0]
Epoch :  338  Time:  0.939  Rel. Train L2 Loss :  0.058197078737947674  Rel. Test L2 Loss :  0.05952059879899025  Test L2 Loss :  0.08617248058319092  inv_L_scale:  [1.0, 1.0]
Epoch :  339  Time:  0.939  Rel. Train L2 Loss :  0.05832421455118391  Rel. Test L2 Loss :  0.05940697327256203  Test L2 Loss :  0.08607980102300644  inv_L_scale:  [1.0, 1.0]
Epoch :  340  Time:  0.939  Rel. Train L2 Loss :  0.05818106664551629  Rel. Test L2 Loss :  0.06005488723516464  Test L2 Loss :  0.08683190941810608  inv_L_scale:  [1.0, 1.0]
Epoch :  341  Time:  0.939  Rel. Train L2 Loss :  0.05813639897439215  Rel. Test L2 Loss :  0.059386472404003146  Test L2 Loss :  0.08593777775764465  inv_L_scale:  [1.0, 1.0]
Epoch :  342  Time:  0.939  Rel. Train L2 Loss :  0.058133878343635134  Rel. Test L2 Loss :  0.05983632728457451  Test L2 Loss :  0.08673648893833161  inv_L_scale:  [1.0, 1.0]
Epoch :  343  Time:  0.939  Rel. Train L2 Loss :  0.0580673161149025  Rel. Test L2 Loss :  0.05940585538744927  Test L2 Loss :  0.08611074626445771  inv_L_scale:  [1.0, 1.0]
Epoch :  344  Time:  0.939  Rel. Train L2 Loss :  0.05804742068052292  Rel. Test L2 Loss :  0.05923719838261604  Test L2 Loss :  0.08574223577976227  inv_L_scale:  [1.0, 1.0]
Epoch :  345  Time:  0.939  Rel. Train L2 Loss :  0.058168768386046094  Rel. Test L2 Loss :  0.05902619674801826  Test L2 Loss :  0.08549266934394836  inv_L_scale:  [1.0, 1.0]
Epoch :  346  Time:  0.939  Rel. Train L2 Loss :  0.05803024893005689  Rel. Test L2 Loss :  0.05900239259004593  Test L2 Loss :  0.08542955368757248  inv_L_scale:  [1.0, 1.0]
Epoch :  347  Time:  0.939  Rel. Train L2 Loss :  0.05794035527441237  Rel. Test L2 Loss :  0.05887413471937179  Test L2 Loss :  0.08532145738601685  inv_L_scale:  [1.0, 1.0]
Epoch :  348  Time:  0.939  Rel. Train L2 Loss :  0.05800133622354931  Rel. Test L2 Loss :  0.058763979226350786  Test L2 Loss :  0.08517439723014832  inv_L_scale:  [1.0, 1.0]
Epoch :  349  Time:  0.94  Rel. Train L2 Loss :  0.05798828817076153  Rel. Test L2 Loss :  0.05970459923148155  Test L2 Loss :  0.08637356847524642  inv_L_scale:  [1.0, 1.0]
Epoch :  350  Time:  0.94  Rel. Train L2 Loss :  0.05800585198733542  Rel. Test L2 Loss :  0.05888376384973526  Test L2 Loss :  0.08536172151565552  inv_L_scale:  [1.0, 1.0]
Epoch :  351  Time:  0.939  Rel. Train L2 Loss :  0.057788688672913445  Rel. Test L2 Loss :  0.05944281071424484  Test L2 Loss :  0.08603169679641724  inv_L_scale:  [1.0, 1.0]
Epoch :  352  Time:  0.939  Rel. Train L2 Loss :  0.05782523294289907  Rel. Test L2 Loss :  0.059182870090007784  Test L2 Loss :  0.08564688175916672  inv_L_scale:  [1.0, 1.0]
Epoch :  353  Time:  0.939  Rel. Train L2 Loss :  0.05781843453645706  Rel. Test L2 Loss :  0.05893211781978607  Test L2 Loss :  0.08545051783323288  inv_L_scale:  [1.0, 1.0]
Epoch :  354  Time:  0.939  Rel. Train L2 Loss :  0.05779095007313623  Rel. Test L2 Loss :  0.058759865909814836  Test L2 Loss :  0.08514716774225235  inv_L_scale:  [1.0, 1.0]
Epoch :  355  Time:  0.939  Rel. Train L2 Loss :  0.05765522400538126  Rel. Test L2 Loss :  0.05894834339618683  Test L2 Loss :  0.08535119056701661  inv_L_scale:  [1.0, 1.0]
Epoch :  356  Time:  0.939  Rel. Train L2 Loss :  0.057821247196859785  Rel. Test L2 Loss :  0.058964021503925323  Test L2 Loss :  0.08555101692676544  inv_L_scale:  [1.0, 1.0]
Epoch :  357  Time:  0.94  Rel. Train L2 Loss :  0.05763046165307363  Rel. Test L2 Loss :  0.058803673982620236  Test L2 Loss :  0.08519681483507156  inv_L_scale:  [1.0, 1.0]
Epoch :  358  Time:  0.94  Rel. Train L2 Loss :  0.0576857680744595  Rel. Test L2 Loss :  0.05892856314778328  Test L2 Loss :  0.08536052763462067  inv_L_scale:  [1.0, 1.0]
Epoch :  359  Time:  0.939  Rel. Train L2 Loss :  0.05769191364447276  Rel. Test L2 Loss :  0.059102320671081544  Test L2 Loss :  0.08554384410381317  inv_L_scale:  [1.0, 1.0]
Epoch :  360  Time:  0.94  Rel. Train L2 Loss :  0.05764388700326284  Rel. Test L2 Loss :  0.058917245715856555  Test L2 Loss :  0.08531182825565338  inv_L_scale:  [1.0, 1.0]
Epoch :  361  Time:  0.94  Rel. Train L2 Loss :  0.05756928869419628  Rel. Test L2 Loss :  0.05861191809177399  Test L2 Loss :  0.08496130108833314  inv_L_scale:  [1.0, 1.0]
Epoch :  362  Time:  0.94  Rel. Train L2 Loss :  0.05756850772433811  Rel. Test L2 Loss :  0.05849083632230759  Test L2 Loss :  0.08471449851989746  inv_L_scale:  [1.0, 1.0]
Epoch :  363  Time:  0.94  Rel. Train L2 Loss :  0.057508560915788015  Rel. Test L2 Loss :  0.058810172230005266  Test L2 Loss :  0.08524231970310212  inv_L_scale:  [1.0, 1.0]
Epoch :  364  Time:  0.94  Rel. Train L2 Loss :  0.05753283755646812  Rel. Test L2 Loss :  0.059203179478645326  Test L2 Loss :  0.08579976618289947  inv_L_scale:  [1.0, 1.0]
Epoch :  365  Time:  0.941  Rel. Train L2 Loss :  0.05742437137497796  Rel. Test L2 Loss :  0.05872898727655411  Test L2 Loss :  0.0851741087436676  inv_L_scale:  [1.0, 1.0]
Epoch :  366  Time:  0.94  Rel. Train L2 Loss :  0.057507591247558595  Rel. Test L2 Loss :  0.05889817088842392  Test L2 Loss :  0.08538429707288742  inv_L_scale:  [1.0, 1.0]
Epoch :  367  Time:  0.94  Rel. Train L2 Loss :  0.05739878528647953  Rel. Test L2 Loss :  0.05879613697528839  Test L2 Loss :  0.08514116585254669  inv_L_scale:  [1.0, 1.0]
Epoch :  368  Time:  0.94  Rel. Train L2 Loss :  0.057471864720185596  Rel. Test L2 Loss :  0.05841030031442642  Test L2 Loss :  0.08472998946905136  inv_L_scale:  [1.0, 1.0]
Epoch :  369  Time:  0.94  Rel. Train L2 Loss :  0.057286927070882586  Rel. Test L2 Loss :  0.059522855430841445  Test L2 Loss :  0.08608778357505799  inv_L_scale:  [1.0, 1.0]
Epoch :  370  Time:  0.94  Rel. Train L2 Loss :  0.05737849732240041  Rel. Test L2 Loss :  0.05862506866455078  Test L2 Loss :  0.08496351391077042  inv_L_scale:  [1.0, 1.0]
Epoch :  371  Time:  0.94  Rel. Train L2 Loss :  0.05735925737354491  Rel. Test L2 Loss :  0.05858969509601593  Test L2 Loss :  0.08491700172424316  inv_L_scale:  [1.0, 1.0]
Epoch :  372  Time:  0.94  Rel. Train L2 Loss :  0.05728360700938437  Rel. Test L2 Loss :  0.05867307186126709  Test L2 Loss :  0.08499937951564789  inv_L_scale:  [1.0, 1.0]
Epoch :  373  Time:  0.94  Rel. Train L2 Loss :  0.05725632516874207  Rel. Test L2 Loss :  0.05891559988260269  Test L2 Loss :  0.08521890699863434  inv_L_scale:  [1.0, 1.0]
Epoch :  374  Time:  0.94  Rel. Train L2 Loss :  0.05719624453120761  Rel. Test L2 Loss :  0.058817290365695954  Test L2 Loss :  0.08525311678647995  inv_L_scale:  [1.0, 1.0]
Epoch :  375  Time:  0.94  Rel. Train L2 Loss :  0.05726948156952858  Rel. Test L2 Loss :  0.059045635312795636  Test L2 Loss :  0.08561820358037948  inv_L_scale:  [1.0, 1.0]
Epoch :  376  Time:  0.94  Rel. Train L2 Loss :  0.057258325152926975  Rel. Test L2 Loss :  0.05868857726454735  Test L2 Loss :  0.08495043367147445  inv_L_scale:  [1.0, 1.0]
Epoch :  377  Time:  0.94  Rel. Train L2 Loss :  0.057171782751878106  Rel. Test L2 Loss :  0.05865458354353905  Test L2 Loss :  0.08495970755815506  inv_L_scale:  [1.0, 1.0]
Epoch :  378  Time:  0.94  Rel. Train L2 Loss :  0.05714265826675627  Rel. Test L2 Loss :  0.058324975967407225  Test L2 Loss :  0.08459304064512253  inv_L_scale:  [1.0, 1.0]
Epoch :  379  Time:  0.94  Rel. Train L2 Loss :  0.05707075165377723  Rel. Test L2 Loss :  0.05873094439506531  Test L2 Loss :  0.08518989711999893  inv_L_scale:  [1.0, 1.0]
Epoch :  380  Time:  0.94  Rel. Train L2 Loss :  0.057095722026295134  Rel. Test L2 Loss :  0.05846790537238121  Test L2 Loss :  0.0847265127301216  inv_L_scale:  [1.0, 1.0]
Epoch :  381  Time:  0.941  Rel. Train L2 Loss :  0.05708838091956245  Rel. Test L2 Loss :  0.05855149120092392  Test L2 Loss :  0.08487235486507416  inv_L_scale:  [1.0, 1.0]
Epoch :  382  Time:  0.941  Rel. Train L2 Loss :  0.05712015736434195  Rel. Test L2 Loss :  0.05851083636283874  Test L2 Loss :  0.08480556160211564  inv_L_scale:  [1.0, 1.0]
Epoch :  383  Time:  0.941  Rel. Train L2 Loss :  0.0570083075761795  Rel. Test L2 Loss :  0.058770004361867904  Test L2 Loss :  0.08507069051265717  inv_L_scale:  [1.0, 1.0]
Epoch :  384  Time:  0.94  Rel. Train L2 Loss :  0.05695671836535136  Rel. Test L2 Loss :  0.05858680233359337  Test L2 Loss :  0.08487720519304276  inv_L_scale:  [1.0, 1.0]
Epoch :  385  Time:  0.941  Rel. Train L2 Loss :  0.056995756212208  Rel. Test L2 Loss :  0.058227846026420595  Test L2 Loss :  0.0844506961107254  inv_L_scale:  [1.0, 1.0]
Epoch :  386  Time:  0.941  Rel. Train L2 Loss :  0.056904052197933194  Rel. Test L2 Loss :  0.05820749416947365  Test L2 Loss :  0.08445620775222779  inv_L_scale:  [1.0, 1.0]
Epoch :  387  Time:  0.941  Rel. Train L2 Loss :  0.056908515526188745  Rel. Test L2 Loss :  0.058349803388118744  Test L2 Loss :  0.0845589804649353  inv_L_scale:  [1.0, 1.0]
Epoch :  388  Time:  0.941  Rel. Train L2 Loss :  0.056919017285108564  Rel. Test L2 Loss :  0.05836080864071846  Test L2 Loss :  0.08458490431308746  inv_L_scale:  [1.0, 1.0]
Epoch :  389  Time:  0.941  Rel. Train L2 Loss :  0.05692942718664805  Rel. Test L2 Loss :  0.058735134452581404  Test L2 Loss :  0.08506477415561677  inv_L_scale:  [1.0, 1.0]
Epoch :  390  Time:  0.941  Rel. Train L2 Loss :  0.05684647568398052  Rel. Test L2 Loss :  0.058572553992271424  Test L2 Loss :  0.08479210257530212  inv_L_scale:  [1.0, 1.0]
Epoch :  391  Time:  0.941  Rel. Train L2 Loss :  0.05684522569179535  Rel. Test L2 Loss :  0.058198065906763075  Test L2 Loss :  0.08437752485275268  inv_L_scale:  [1.0, 1.0]
Epoch :  392  Time:  0.94  Rel. Train L2 Loss :  0.05684715608755748  Rel. Test L2 Loss :  0.05849967181682587  Test L2 Loss :  0.08472054660320281  inv_L_scale:  [1.0, 1.0]
Epoch :  393  Time:  0.94  Rel. Train L2 Loss :  0.05676254050599204  Rel. Test L2 Loss :  0.05846338540315628  Test L2 Loss :  0.08472751289606094  inv_L_scale:  [1.0, 1.0]
Epoch :  394  Time:  0.941  Rel. Train L2 Loss :  0.05679350395997365  Rel. Test L2 Loss :  0.0583280748128891  Test L2 Loss :  0.08450210213661194  inv_L_scale:  [1.0, 1.0]
Epoch :  395  Time:  0.941  Rel. Train L2 Loss :  0.056699085103140937  Rel. Test L2 Loss :  0.05817491188645363  Test L2 Loss :  0.08435759782791137  inv_L_scale:  [1.0, 1.0]
Epoch :  396  Time:  0.94  Rel. Train L2 Loss :  0.05671675642331441  Rel. Test L2 Loss :  0.05847990050911903  Test L2 Loss :  0.08478546798229218  inv_L_scale:  [1.0, 1.0]
Epoch :  397  Time:  0.94  Rel. Train L2 Loss :  0.05671037212014198  Rel. Test L2 Loss :  0.05840562090277672  Test L2 Loss :  0.08464093983173371  inv_L_scale:  [1.0, 1.0]
Epoch :  398  Time:  0.941  Rel. Train L2 Loss :  0.056657566163274976  Rel. Test L2 Loss :  0.05835142612457275  Test L2 Loss :  0.08459970712661743  inv_L_scale:  [1.0, 1.0]
Epoch :  399  Time:  0.943  Rel. Train L2 Loss :  0.056667838195959726  Rel. Test L2 Loss :  0.05823906451463699  Test L2 Loss :  0.08438922256231308  inv_L_scale:  [1.0, 1.0]
Epoch :  400  Time:  0.942  Rel. Train L2 Loss :  0.056570170372724535  Rel. Test L2 Loss :  0.05838660389184952  Test L2 Loss :  0.08459620654582978  inv_L_scale:  [1.0, 1.0]
Epoch :  401  Time:  0.941  Rel. Train L2 Loss :  0.05657193471988042  Rel. Test L2 Loss :  0.05807920202612877  Test L2 Loss :  0.08422069251537323  inv_L_scale:  [1.0, 1.0]
Epoch :  402  Time:  0.941  Rel. Train L2 Loss :  0.056574905465046565  Rel. Test L2 Loss :  0.05838703393936157  Test L2 Loss :  0.0845443394780159  inv_L_scale:  [1.0, 1.0]
Epoch :  403  Time:  0.941  Rel. Train L2 Loss :  0.05652523782518175  Rel. Test L2 Loss :  0.05830730959773064  Test L2 Loss :  0.084497991502285  inv_L_scale:  [1.0, 1.0]
Epoch :  404  Time:  0.941  Rel. Train L2 Loss :  0.056500012907716966  Rel. Test L2 Loss :  0.05826699197292328  Test L2 Loss :  0.08447030544281006  inv_L_scale:  [1.0, 1.0]
Epoch :  405  Time:  0.941  Rel. Train L2 Loss :  0.05643978406985601  Rel. Test L2 Loss :  0.058108435571193696  Test L2 Loss :  0.08422224462032318  inv_L_scale:  [1.0, 1.0]
Epoch :  406  Time:  0.941  Rel. Train L2 Loss :  0.05646853897306654  Rel. Test L2 Loss :  0.05815898135304451  Test L2 Loss :  0.08429147899150849  inv_L_scale:  [1.0, 1.0]
Epoch :  407  Time:  0.941  Rel. Train L2 Loss :  0.05650342227684127  Rel. Test L2 Loss :  0.05823490619659424  Test L2 Loss :  0.0843912786245346  inv_L_scale:  [1.0, 1.0]
Epoch :  408  Time:  0.941  Rel. Train L2 Loss :  0.05647111025121477  Rel. Test L2 Loss :  0.05806224405765534  Test L2 Loss :  0.08421190738677979  inv_L_scale:  [1.0, 1.0]
Epoch :  409  Time:  0.941  Rel. Train L2 Loss :  0.05643490460183885  Rel. Test L2 Loss :  0.058378307819366454  Test L2 Loss :  0.0846108165383339  inv_L_scale:  [1.0, 1.0]
Epoch :  410  Time:  0.942  Rel. Train L2 Loss :  0.056420263979170056  Rel. Test L2 Loss :  0.05829928636550903  Test L2 Loss :  0.0845022001862526  inv_L_scale:  [1.0, 1.0]
Epoch :  411  Time:  0.941  Rel. Train L2 Loss :  0.05637128829956055  Rel. Test L2 Loss :  0.05824812650680542  Test L2 Loss :  0.0843778121471405  inv_L_scale:  [1.0, 1.0]
Epoch :  412  Time:  0.941  Rel. Train L2 Loss :  0.05632722232076857  Rel. Test L2 Loss :  0.05831622719764709  Test L2 Loss :  0.08457181215286255  inv_L_scale:  [1.0, 1.0]
Epoch :  413  Time:  0.941  Rel. Train L2 Loss :  0.05633515651027361  Rel. Test L2 Loss :  0.05809933692216873  Test L2 Loss :  0.0842012858390808  inv_L_scale:  [1.0, 1.0]
Epoch :  414  Time:  0.941  Rel. Train L2 Loss :  0.05628312495019701  Rel. Test L2 Loss :  0.058146247416734693  Test L2 Loss :  0.08430706351995468  inv_L_scale:  [1.0, 1.0]
Epoch :  415  Time:  0.941  Rel. Train L2 Loss :  0.05624746759732564  Rel. Test L2 Loss :  0.05802298367023468  Test L2 Loss :  0.08405238032341003  inv_L_scale:  [1.0, 1.0]
Epoch :  416  Time:  0.941  Rel. Train L2 Loss :  0.056289368238714006  Rel. Test L2 Loss :  0.05794827118515968  Test L2 Loss :  0.08404110431671143  inv_L_scale:  [1.0, 1.0]
Epoch :  417  Time:  0.941  Rel. Train L2 Loss :  0.05625681395332018  Rel. Test L2 Loss :  0.05822375759482384  Test L2 Loss :  0.08435937285423278  inv_L_scale:  [1.0, 1.0]
Epoch :  418  Time:  0.941  Rel. Train L2 Loss :  0.05620106056332588  Rel. Test L2 Loss :  0.058096154481172564  Test L2 Loss :  0.08421414524316788  inv_L_scale:  [1.0, 1.0]
Epoch :  419  Time:  0.941  Rel. Train L2 Loss :  0.05619580808613035  Rel. Test L2 Loss :  0.05827915400266647  Test L2 Loss :  0.08441768944263459  inv_L_scale:  [1.0, 1.0]
Epoch :  420  Time:  0.941  Rel. Train L2 Loss :  0.0562779548101955  Rel. Test L2 Loss :  0.05813597962260246  Test L2 Loss :  0.08431002527475356  inv_L_scale:  [1.0, 1.0]
Epoch :  421  Time:  0.941  Rel. Train L2 Loss :  0.05617080231507619  Rel. Test L2 Loss :  0.057915307432413105  Test L2 Loss :  0.08398387789726257  inv_L_scale:  [1.0, 1.0]
Epoch :  422  Time:  0.941  Rel. Train L2 Loss :  0.05614004972908232  Rel. Test L2 Loss :  0.058059221804142  Test L2 Loss :  0.08418894112110138  inv_L_scale:  [1.0, 1.0]
Epoch :  423  Time:  0.941  Rel. Train L2 Loss :  0.05612900263733334  Rel. Test L2 Loss :  0.057841355353593825  Test L2 Loss :  0.08388568639755249  inv_L_scale:  [1.0, 1.0]
Epoch :  424  Time:  0.941  Rel. Train L2 Loss :  0.05609590480724971  Rel. Test L2 Loss :  0.05835963636636734  Test L2 Loss :  0.08459324896335602  inv_L_scale:  [1.0, 1.0]
Epoch :  425  Time:  0.941  Rel. Train L2 Loss :  0.056100970755020775  Rel. Test L2 Loss :  0.05813332319259643  Test L2 Loss :  0.0842742109298706  inv_L_scale:  [1.0, 1.0]
Epoch :  426  Time:  0.941  Rel. Train L2 Loss :  0.05609624650743272  Rel. Test L2 Loss :  0.058143700361251834  Test L2 Loss :  0.08428687274456025  inv_L_scale:  [1.0, 1.0]
Epoch :  427  Time:  0.941  Rel. Train L2 Loss :  0.05605379627810584  Rel. Test L2 Loss :  0.05806302472949028  Test L2 Loss :  0.08417074829339981  inv_L_scale:  [1.0, 1.0]
Epoch :  428  Time:  0.941  Rel. Train L2 Loss :  0.05605560981565052  Rel. Test L2 Loss :  0.05813511371612549  Test L2 Loss :  0.08427008152008057  inv_L_scale:  [1.0, 1.0]
Epoch :  429  Time:  0.941  Rel. Train L2 Loss :  0.056025606327586706  Rel. Test L2 Loss :  0.05796965301036835  Test L2 Loss :  0.08403072059154511  inv_L_scale:  [1.0, 1.0]
Epoch :  430  Time:  0.941  Rel. Train L2 Loss :  0.05599376834101147  Rel. Test L2 Loss :  0.0579633592069149  Test L2 Loss :  0.08409814476966858  inv_L_scale:  [1.0, 1.0]
Epoch :  431  Time:  0.941  Rel. Train L2 Loss :  0.05599923820959197  Rel. Test L2 Loss :  0.0580471059679985  Test L2 Loss :  0.08411268711090088  inv_L_scale:  [1.0, 1.0]
Epoch :  432  Time:  0.941  Rel. Train L2 Loss :  0.05595011439588335  Rel. Test L2 Loss :  0.057956348657608035  Test L2 Loss :  0.08400339275598526  inv_L_scale:  [1.0, 1.0]
Epoch :  433  Time:  0.941  Rel. Train L2 Loss :  0.05596352159976959  Rel. Test L2 Loss :  0.058000312000513074  Test L2 Loss :  0.08409856617450714  inv_L_scale:  [1.0, 1.0]
Epoch :  434  Time:  0.941  Rel. Train L2 Loss :  0.05591996063788732  Rel. Test L2 Loss :  0.058006801307201386  Test L2 Loss :  0.08409364074468613  inv_L_scale:  [1.0, 1.0]
Epoch :  435  Time:  0.941  Rel. Train L2 Loss :  0.055928600049681136  Rel. Test L2 Loss :  0.05791102722287178  Test L2 Loss :  0.08400689661502839  inv_L_scale:  [1.0, 1.0]
Epoch :  436  Time:  0.941  Rel. Train L2 Loss :  0.055903465698162715  Rel. Test L2 Loss :  0.05790660247206688  Test L2 Loss :  0.08395585596561432  inv_L_scale:  [1.0, 1.0]
Epoch :  437  Time:  0.941  Rel. Train L2 Loss :  0.05586170636945301  Rel. Test L2 Loss :  0.0579582591354847  Test L2 Loss :  0.08399329662322998  inv_L_scale:  [1.0, 1.0]
Epoch :  438  Time:  0.941  Rel. Train L2 Loss :  0.055894217011001376  Rel. Test L2 Loss :  0.05803650960326195  Test L2 Loss :  0.08411666929721832  inv_L_scale:  [1.0, 1.0]
Epoch :  439  Time:  0.94  Rel. Train L2 Loss :  0.05583911759985818  Rel. Test L2 Loss :  0.05798009425401687  Test L2 Loss :  0.08403199732303619  inv_L_scale:  [1.0, 1.0]
Epoch :  440  Time:  0.94  Rel. Train L2 Loss :  0.05585513258973757  Rel. Test L2 Loss :  0.05799172550439834  Test L2 Loss :  0.08406194627285003  inv_L_scale:  [1.0, 1.0]
Epoch :  441  Time:  0.94  Rel. Train L2 Loss :  0.05582642406225204  Rel. Test L2 Loss :  0.05786305472254753  Test L2 Loss :  0.08390579760074615  inv_L_scale:  [1.0, 1.0]
Epoch :  442  Time:  0.939  Rel. Train L2 Loss :  0.055812743769751656  Rel. Test L2 Loss :  0.05782497689127922  Test L2 Loss :  0.08386900007724762  inv_L_scale:  [1.0, 1.0]
Epoch :  443  Time:  0.94  Rel. Train L2 Loss :  0.0558110863632626  Rel. Test L2 Loss :  0.05783823370933533  Test L2 Loss :  0.08387020230293274  inv_L_scale:  [1.0, 1.0]
Epoch :  444  Time:  0.94  Rel. Train L2 Loss :  0.055780305200152924  Rel. Test L2 Loss :  0.05796069100499153  Test L2 Loss :  0.08403095930814743  inv_L_scale:  [1.0, 1.0]
Epoch :  445  Time:  0.94  Rel. Train L2 Loss :  0.055790920522477895  Rel. Test L2 Loss :  0.058005860447883605  Test L2 Loss :  0.08407271564006806  inv_L_scale:  [1.0, 1.0]
Epoch :  446  Time:  0.94  Rel. Train L2 Loss :  0.0557805120282703  Rel. Test L2 Loss :  0.05793206632137299  Test L2 Loss :  0.0839754244685173  inv_L_scale:  [1.0, 1.0]
Epoch :  447  Time:  0.939  Rel. Train L2 Loss :  0.055763188832336004  Rel. Test L2 Loss :  0.05793957114219665  Test L2 Loss :  0.08401148825883865  inv_L_scale:  [1.0, 1.0]
Epoch :  448  Time:  0.94  Rel. Train L2 Loss :  0.055710029469596016  Rel. Test L2 Loss :  0.057860181778669355  Test L2 Loss :  0.0839026579260826  inv_L_scale:  [1.0, 1.0]
Epoch :  449  Time:  0.94  Rel. Train L2 Loss :  0.0557140974369314  Rel. Test L2 Loss :  0.05790000930428505  Test L2 Loss :  0.08394434332847595  inv_L_scale:  [1.0, 1.0]
Epoch :  450  Time:  0.939  Rel. Train L2 Loss :  0.0557092692454656  Rel. Test L2 Loss :  0.05784830093383789  Test L2 Loss :  0.08387433290481568  inv_L_scale:  [1.0, 1.0]
Epoch :  451  Time:  0.941  Rel. Train L2 Loss :  0.05568722605705261  Rel. Test L2 Loss :  0.05786285281181335  Test L2 Loss :  0.08390074729919433  inv_L_scale:  [1.0, 1.0]
Epoch :  452  Time:  0.94  Rel. Train L2 Loss :  0.05567563666237725  Rel. Test L2 Loss :  0.05788033366203308  Test L2 Loss :  0.08392239272594453  inv_L_scale:  [1.0, 1.0]
Epoch :  453  Time:  0.939  Rel. Train L2 Loss :  0.05567125058836407  Rel. Test L2 Loss :  0.057920960187911985  Test L2 Loss :  0.08396932363510132  inv_L_scale:  [1.0, 1.0]
Epoch :  454  Time:  0.94  Rel. Train L2 Loss :  0.05566521926058663  Rel. Test L2 Loss :  0.05783693641424179  Test L2 Loss :  0.0838619089126587  inv_L_scale:  [1.0, 1.0]
Epoch :  455  Time:  0.94  Rel. Train L2 Loss :  0.055644395583205754  Rel. Test L2 Loss :  0.057867425233125686  Test L2 Loss :  0.08388222992420197  inv_L_scale:  [1.0, 1.0]
Epoch :  456  Time:  0.94  Rel. Train L2 Loss :  0.05561956551339891  Rel. Test L2 Loss :  0.057794146388769146  Test L2 Loss :  0.08381528496742248  inv_L_scale:  [1.0, 1.0]
Epoch :  457  Time:  0.94  Rel. Train L2 Loss :  0.05561034636365043  Rel. Test L2 Loss :  0.057860341668128965  Test L2 Loss :  0.08388472199440003  inv_L_scale:  [1.0, 1.0]
Epoch :  458  Time:  0.94  Rel. Train L2 Loss :  0.05559904502497779  Rel. Test L2 Loss :  0.05787803187966347  Test L2 Loss :  0.08390514135360717  inv_L_scale:  [1.0, 1.0]
Epoch :  459  Time:  0.94  Rel. Train L2 Loss :  0.0555822869307465  Rel. Test L2 Loss :  0.057811126261949536  Test L2 Loss :  0.08382688313722611  inv_L_scale:  [1.0, 1.0]
Epoch :  460  Time:  0.94  Rel. Train L2 Loss :  0.055577824181980554  Rel. Test L2 Loss :  0.057858038395643234  Test L2 Loss :  0.08387665867805481  inv_L_scale:  [1.0, 1.0]
Epoch :  461  Time:  0.94  Rel. Train L2 Loss :  0.05557607703738742  Rel. Test L2 Loss :  0.057839070856571195  Test L2 Loss :  0.08387721359729766  inv_L_scale:  [1.0, 1.0]
Epoch :  462  Time:  0.94  Rel. Train L2 Loss :  0.05555970766478115  Rel. Test L2 Loss :  0.057791858166456225  Test L2 Loss :  0.08380197525024415  inv_L_scale:  [1.0, 1.0]
Epoch :  463  Time:  0.939  Rel. Train L2 Loss :  0.05554938733577728  Rel. Test L2 Loss :  0.05775820553302765  Test L2 Loss :  0.08375205487012863  inv_L_scale:  [1.0, 1.0]
Epoch :  464  Time:  0.939  Rel. Train L2 Loss :  0.055536819580528474  Rel. Test L2 Loss :  0.057807767987251284  Test L2 Loss :  0.0838090267777443  inv_L_scale:  [1.0, 1.0]
Epoch :  465  Time:  0.94  Rel. Train L2 Loss :  0.0555244912703832  Rel. Test L2 Loss :  0.057830178141593934  Test L2 Loss :  0.08383569777011872  inv_L_scale:  [1.0, 1.0]
Epoch :  466  Time:  0.941  Rel. Train L2 Loss :  0.055519427392217845  Rel. Test L2 Loss :  0.05784816324710846  Test L2 Loss :  0.08388671070337296  inv_L_scale:  [1.0, 1.0]
Epoch :  467  Time:  0.94  Rel. Train L2 Loss :  0.05552008643746376  Rel. Test L2 Loss :  0.05784297525882721  Test L2 Loss :  0.08385919153690338  inv_L_scale:  [1.0, 1.0]
Epoch :  468  Time:  0.939  Rel. Train L2 Loss :  0.055497866008016795  Rel. Test L2 Loss :  0.0578032061457634  Test L2 Loss :  0.08381105661392212  inv_L_scale:  [1.0, 1.0]
Epoch :  469  Time:  0.939  Rel. Train L2 Loss :  0.05550086634026633  Rel. Test L2 Loss :  0.05779505789279938  Test L2 Loss :  0.08379728019237519  inv_L_scale:  [1.0, 1.0]
Epoch :  470  Time:  0.939  Rel. Train L2 Loss :  0.055494566592905255  Rel. Test L2 Loss :  0.057823854088783266  Test L2 Loss :  0.08383876383304596  inv_L_scale:  [1.0, 1.0]
Epoch :  471  Time:  0.939  Rel. Train L2 Loss :  0.05547650878628095  Rel. Test L2 Loss :  0.05783116102218628  Test L2 Loss :  0.08384840250015259  inv_L_scale:  [1.0, 1.0]
Epoch :  472  Time:  0.939  Rel. Train L2 Loss :  0.05546637429131402  Rel. Test L2 Loss :  0.0577979251742363  Test L2 Loss :  0.08380086898803711  inv_L_scale:  [1.0, 1.0]
Epoch :  473  Time:  0.939  Rel. Train L2 Loss :  0.05546275552776125  Rel. Test L2 Loss :  0.05781845137476921  Test L2 Loss :  0.08382957577705383  inv_L_scale:  [1.0, 1.0]
Epoch :  474  Time:  0.939  Rel. Train L2 Loss :  0.05545672953128815  Rel. Test L2 Loss :  0.057836434841156005  Test L2 Loss :  0.08385776102542877  inv_L_scale:  [1.0, 1.0]
Epoch :  475  Time:  0.939  Rel. Train L2 Loss :  0.05545170024037361  Rel. Test L2 Loss :  0.05781512469053268  Test L2 Loss :  0.08382485657930375  inv_L_scale:  [1.0, 1.0]
Epoch :  476  Time:  0.939  Rel. Train L2 Loss :  0.05544519517156813  Rel. Test L2 Loss :  0.0578016796708107  Test L2 Loss :  0.08381903022527695  inv_L_scale:  [1.0, 1.0]
Epoch :  477  Time:  0.939  Rel. Train L2 Loss :  0.05543756465117137  Rel. Test L2 Loss :  0.05780491828918457  Test L2 Loss :  0.08381777167320252  inv_L_scale:  [1.0, 1.0]
Epoch :  478  Time:  0.938  Rel. Train L2 Loss :  0.0554276041355398  Rel. Test L2 Loss :  0.05779946818947792  Test L2 Loss :  0.08381294757127762  inv_L_scale:  [1.0, 1.0]
Epoch :  479  Time:  0.939  Rel. Train L2 Loss :  0.05542433021797074  Rel. Test L2 Loss :  0.05781224563717842  Test L2 Loss :  0.08382766962051391  inv_L_scale:  [1.0, 1.0]
Epoch :  480  Time:  0.939  Rel. Train L2 Loss :  0.055424109763569304  Rel. Test L2 Loss :  0.05781551212072372  Test L2 Loss :  0.08383125245571137  inv_L_scale:  [1.0, 1.0]
Epoch :  481  Time:  0.939  Rel. Train L2 Loss :  0.05541377908653683  Rel. Test L2 Loss :  0.05782114982604981  Test L2 Loss :  0.08384935647249221  inv_L_scale:  [1.0, 1.0]
Epoch :  482  Time:  0.939  Rel. Train L2 Loss :  0.055417617443535065  Rel. Test L2 Loss :  0.05780640915036202  Test L2 Loss :  0.08382450222969055  inv_L_scale:  [1.0, 1.0]
Epoch :  483  Time:  0.939  Rel. Train L2 Loss :  0.055406772792339326  Rel. Test L2 Loss :  0.05782209485769272  Test L2 Loss :  0.08384248554706573  inv_L_scale:  [1.0, 1.0]
Epoch :  484  Time:  0.939  Rel. Train L2 Loss :  0.055404978758758966  Rel. Test L2 Loss :  0.057820869386196135  Test L2 Loss :  0.08383678674697875  inv_L_scale:  [1.0, 1.0]
Epoch :  485  Time:  0.939  Rel. Train L2 Loss :  0.05539715553323428  Rel. Test L2 Loss :  0.05781016543507576  Test L2 Loss :  0.08382483005523682  inv_L_scale:  [1.0, 1.0]
Epoch :  486  Time:  0.939  Rel. Train L2 Loss :  0.055389216542243956  Rel. Test L2 Loss :  0.0578009632229805  Test L2 Loss :  0.08382337301969528  inv_L_scale:  [1.0, 1.0]
Epoch :  487  Time:  0.939  Rel. Train L2 Loss :  0.05539354231622484  Rel. Test L2 Loss :  0.05779863327741623  Test L2 Loss :  0.08380681216716766  inv_L_scale:  [1.0, 1.0]
Epoch :  488  Time:  0.939  Rel. Train L2 Loss :  0.05539196570714315  Rel. Test L2 Loss :  0.05780051320791244  Test L2 Loss :  0.08380313873291016  inv_L_scale:  [1.0, 1.0]
Epoch :  489  Time:  0.939  Rel. Train L2 Loss :  0.05538546403249105  Rel. Test L2 Loss :  0.05779486879706383  Test L2 Loss :  0.08379859000444412  inv_L_scale:  [1.0, 1.0]
Epoch :  490  Time:  0.939  Rel. Train L2 Loss :  0.05538327230347528  Rel. Test L2 Loss :  0.05780553251504898  Test L2 Loss :  0.08382468461990357  inv_L_scale:  [1.0, 1.0]
Epoch :  491  Time:  0.939  Rel. Train L2 Loss :  0.05538193121552468  Rel. Test L2 Loss :  0.05780570805072784  Test L2 Loss :  0.08382041692733765  inv_L_scale:  [1.0, 1.0]
Epoch :  492  Time:  0.938  Rel. Train L2 Loss :  0.05537795773810811  Rel. Test L2 Loss :  0.05780421882867813  Test L2 Loss :  0.08381602853536606  inv_L_scale:  [1.0, 1.0]
Epoch :  493  Time:  0.939  Rel. Train L2 Loss :  0.05537408745951123  Rel. Test L2 Loss :  0.057820404767990115  Test L2 Loss :  0.08383728981018067  inv_L_scale:  [1.0, 1.0]
Epoch :  494  Time:  0.938  Rel. Train L2 Loss :  0.05537839146123992  Rel. Test L2 Loss :  0.057798454463481905  Test L2 Loss :  0.0838116842508316  inv_L_scale:  [1.0, 1.0]
Epoch :  495  Time:  0.939  Rel. Train L2 Loss :  0.05537552159693506  Rel. Test L2 Loss :  0.05780305713415146  Test L2 Loss :  0.08381935566663742  inv_L_scale:  [1.0, 1.0]
Epoch :  496  Time:  0.939  Rel. Train L2 Loss :  0.05537147925959693  Rel. Test L2 Loss :  0.05781018853187561  Test L2 Loss :  0.08382528483867645  inv_L_scale:  [1.0, 1.0]
Epoch :  497  Time:  0.939  Rel. Train L2 Loss :  0.05536894298262066  Rel. Test L2 Loss :  0.05779598116874695  Test L2 Loss :  0.08380312979221344  inv_L_scale:  [1.0, 1.0]
Epoch :  498  Time:  0.939  Rel. Train L2 Loss :  0.055369754052824446  Rel. Test L2 Loss :  0.057806952446699145  Test L2 Loss :  0.08381882071495056  inv_L_scale:  [1.0, 1.0]
Epoch :  499  Time:  0.939  Rel. Train L2 Loss :  0.0553704939948188  Rel. Test L2 Loss :  0.057801379561424254  Test L2 Loss :  0.08381012678146363  inv_L_scale:  [1.0, 1.0]
