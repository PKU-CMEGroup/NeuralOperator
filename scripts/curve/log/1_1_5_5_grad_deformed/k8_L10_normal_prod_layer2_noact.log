(1000,) (1000, 1000, 1) (1000, 1000, 2)
use normalized raw measures
Computing normal vector
Casting to tensor
x_train shape torch.Size([900, 1000, 8]), y_train shape torch.Size([900, 1000, 1])
length of each dim:  tensor([6.5573987960815430, 6.1420288085937500])
kmax = 8
L = 10
use cube modes, scale = 0 (144, 2, 1)
In PCNO_train, ndims =  2
Epoch :  0  Time:  8.284  Rel. Train L2 Loss :  0.514627853234609  Rel. Test L2 Loss :  0.3743404269218445  Test L2 Loss :  0.5446481823921203  inv_L_scale:  [1.0, 1.0]
Epoch :  1  Time:  0.66  Rel. Train L2 Loss :  0.32150793340471057  Rel. Test L2 Loss :  0.2605768430233002  Test L2 Loss :  0.376268697977066  inv_L_scale:  [1.0, 1.0]
Epoch :  2  Time:  0.666  Rel. Train L2 Loss :  0.24143351097901664  Rel. Test L2 Loss :  0.22007549583911895  Test L2 Loss :  0.3178619527816772  inv_L_scale:  [1.0, 1.0]
Epoch :  3  Time:  0.663  Rel. Train L2 Loss :  0.20541780604256524  Rel. Test L2 Loss :  0.187584947347641  Test L2 Loss :  0.26869712114334104  inv_L_scale:  [1.0, 1.0]
Epoch :  4  Time:  0.662  Rel. Train L2 Loss :  0.18469608962535858  Rel. Test L2 Loss :  0.1785866701602936  Test L2 Loss :  0.25668542861938476  inv_L_scale:  [1.0, 1.0]
Epoch :  5  Time:  0.662  Rel. Train L2 Loss :  0.17743372758229572  Rel. Test L2 Loss :  0.17358529567718506  Test L2 Loss :  0.24889515280723573  inv_L_scale:  [1.0, 1.0]
Epoch :  6  Time:  0.664  Rel. Train L2 Loss :  0.17334561692343817  Rel. Test L2 Loss :  0.16762324154376984  Test L2 Loss :  0.24188642859458923  inv_L_scale:  [1.0, 1.0]
Epoch :  7  Time:  0.662  Rel. Train L2 Loss :  0.16830126067002615  Rel. Test L2 Loss :  0.16981251299381256  Test L2 Loss :  0.24468080937862396  inv_L_scale:  [1.0, 1.0]
Epoch :  8  Time:  0.662  Rel. Train L2 Loss :  0.16409128255314298  Rel. Test L2 Loss :  0.1693217498064041  Test L2 Loss :  0.24237538933753966  inv_L_scale:  [1.0, 1.0]
Epoch :  9  Time:  0.663  Rel. Train L2 Loss :  0.16446009006765153  Rel. Test L2 Loss :  0.15925832569599152  Test L2 Loss :  0.22933599591255188  inv_L_scale:  [1.0, 1.0]
Epoch :  10  Time:  0.664  Rel. Train L2 Loss :  0.158587606549263  Rel. Test L2 Loss :  0.1534019124507904  Test L2 Loss :  0.22182223558425904  inv_L_scale:  [1.0, 1.0]
Epoch :  11  Time:  0.662  Rel. Train L2 Loss :  0.16120049801137712  Rel. Test L2 Loss :  0.16145028710365295  Test L2 Loss :  0.23300784647464753  inv_L_scale:  [1.0, 1.0]
Epoch :  12  Time:  0.662  Rel. Train L2 Loss :  0.16002106103632185  Rel. Test L2 Loss :  0.15925984144210814  Test L2 Loss :  0.22959713578224183  inv_L_scale:  [1.0, 1.0]
Epoch :  13  Time:  0.663  Rel. Train L2 Loss :  0.15569192700915865  Rel. Test L2 Loss :  0.15525526642799378  Test L2 Loss :  0.22354910850524903  inv_L_scale:  [1.0, 1.0]
Epoch :  14  Time:  0.665  Rel. Train L2 Loss :  0.15437572333547805  Rel. Test L2 Loss :  0.1564625871181488  Test L2 Loss :  0.2267863917350769  inv_L_scale:  [1.0, 1.0]
Epoch :  15  Time:  0.663  Rel. Train L2 Loss :  0.15419194413555992  Rel. Test L2 Loss :  0.15410735011100768  Test L2 Loss :  0.22219865143299103  inv_L_scale:  [1.0, 1.0]
Epoch :  16  Time:  0.662  Rel. Train L2 Loss :  0.15524588478936088  Rel. Test L2 Loss :  0.1505354881286621  Test L2 Loss :  0.21820348739624024  inv_L_scale:  [1.0, 1.0]
Epoch :  17  Time:  0.662  Rel. Train L2 Loss :  0.1531776542133755  Rel. Test L2 Loss :  0.15195972502231597  Test L2 Loss :  0.21871791183948516  inv_L_scale:  [1.0, 1.0]
Epoch :  18  Time:  0.664  Rel. Train L2 Loss :  0.15310253196292453  Rel. Test L2 Loss :  0.14903605341911316  Test L2 Loss :  0.2158198684453964  inv_L_scale:  [1.0, 1.0]
Epoch :  19  Time:  0.662  Rel. Train L2 Loss :  0.1523994235859977  Rel. Test L2 Loss :  0.14626038551330567  Test L2 Loss :  0.21150298953056335  inv_L_scale:  [1.0, 1.0]
Epoch :  20  Time:  0.662  Rel. Train L2 Loss :  0.15194067286120522  Rel. Test L2 Loss :  0.15161677718162536  Test L2 Loss :  0.21944345116615296  inv_L_scale:  [1.0, 1.0]
Epoch :  21  Time:  0.662  Rel. Train L2 Loss :  0.15143873857127296  Rel. Test L2 Loss :  0.1446111398935318  Test L2 Loss :  0.2101784563064575  inv_L_scale:  [1.0, 1.0]
Epoch :  22  Time:  0.662  Rel. Train L2 Loss :  0.14967672146028943  Rel. Test L2 Loss :  0.1459862244129181  Test L2 Loss :  0.21084811806678772  inv_L_scale:  [1.0, 1.0]
Epoch :  23  Time:  0.662  Rel. Train L2 Loss :  0.14884244521458945  Rel. Test L2 Loss :  0.14917379021644592  Test L2 Loss :  0.21639373183250427  inv_L_scale:  [1.0, 1.0]
Epoch :  24  Time:  0.666  Rel. Train L2 Loss :  0.14948304533958434  Rel. Test L2 Loss :  0.1467009162902832  Test L2 Loss :  0.2131143641471863  inv_L_scale:  [1.0, 1.0]
Epoch :  25  Time:  0.663  Rel. Train L2 Loss :  0.14819471584426033  Rel. Test L2 Loss :  0.14915889263153076  Test L2 Loss :  0.218163942694664  inv_L_scale:  [1.0, 1.0]
Epoch :  26  Time:  0.663  Rel. Train L2 Loss :  0.14968897130754258  Rel. Test L2 Loss :  0.14655499219894408  Test L2 Loss :  0.2120443993806839  inv_L_scale:  [1.0, 1.0]
Epoch :  27  Time:  0.662  Rel. Train L2 Loss :  0.14838075710667503  Rel. Test L2 Loss :  0.1448777461051941  Test L2 Loss :  0.21097236394882202  inv_L_scale:  [1.0, 1.0]
Epoch :  28  Time:  0.662  Rel. Train L2 Loss :  0.14812710609700944  Rel. Test L2 Loss :  0.14529649794101715  Test L2 Loss :  0.21109902024269103  inv_L_scale:  [1.0, 1.0]
Epoch :  29  Time:  0.663  Rel. Train L2 Loss :  0.14807499024603102  Rel. Test L2 Loss :  0.14711979508399964  Test L2 Loss :  0.21217975556850432  inv_L_scale:  [1.0, 1.0]
Epoch :  30  Time:  0.662  Rel. Train L2 Loss :  0.1489725543393029  Rel. Test L2 Loss :  0.14972223103046417  Test L2 Loss :  0.21638017773628235  inv_L_scale:  [1.0, 1.0]
Epoch :  31  Time:  0.662  Rel. Train L2 Loss :  0.14766751958264246  Rel. Test L2 Loss :  0.14941184759140014  Test L2 Loss :  0.21671779334545135  inv_L_scale:  [1.0, 1.0]
Epoch :  32  Time:  0.662  Rel. Train L2 Loss :  0.1488921758863661  Rel. Test L2 Loss :  0.14426887512207032  Test L2 Loss :  0.20897139430046083  inv_L_scale:  [1.0, 1.0]
Epoch :  33  Time:  0.662  Rel. Train L2 Loss :  0.146387124326494  Rel. Test L2 Loss :  0.1486740964651108  Test L2 Loss :  0.21499389469623564  inv_L_scale:  [1.0, 1.0]
Epoch :  34  Time:  0.663  Rel. Train L2 Loss :  0.14592212663756476  Rel. Test L2 Loss :  0.14521412491798402  Test L2 Loss :  0.21083383798599242  inv_L_scale:  [1.0, 1.0]
Epoch :  35  Time:  0.662  Rel. Train L2 Loss :  0.14639285955164166  Rel. Test L2 Loss :  0.1450074076652527  Test L2 Loss :  0.21101824760437013  inv_L_scale:  [1.0, 1.0]
Epoch :  36  Time:  0.662  Rel. Train L2 Loss :  0.14549142569303514  Rel. Test L2 Loss :  0.14609886229038238  Test L2 Loss :  0.21205738484859465  inv_L_scale:  [1.0, 1.0]
Epoch :  37  Time:  0.662  Rel. Train L2 Loss :  0.14616633150312636  Rel. Test L2 Loss :  0.14357222199440003  Test L2 Loss :  0.20937967598438262  inv_L_scale:  [1.0, 1.0]
Epoch :  38  Time:  0.662  Rel. Train L2 Loss :  0.1453994287384881  Rel. Test L2 Loss :  0.14122460782527924  Test L2 Loss :  0.20464805126190186  inv_L_scale:  [1.0, 1.0]
Epoch :  39  Time:  0.664  Rel. Train L2 Loss :  0.14501960231198205  Rel. Test L2 Loss :  0.14179353177547455  Test L2 Loss :  0.20505446553230286  inv_L_scale:  [1.0, 1.0]
Epoch :  40  Time:  0.662  Rel. Train L2 Loss :  0.14494429343276555  Rel. Test L2 Loss :  0.14516395211219787  Test L2 Loss :  0.21144234776496887  inv_L_scale:  [1.0, 1.0]
Epoch :  41  Time:  0.662  Rel. Train L2 Loss :  0.14494382401307424  Rel. Test L2 Loss :  0.14280777156352997  Test L2 Loss :  0.20707432985305785  inv_L_scale:  [1.0, 1.0]
Epoch :  42  Time:  0.662  Rel. Train L2 Loss :  0.1442544233136707  Rel. Test L2 Loss :  0.14657056391239165  Test L2 Loss :  0.2112183141708374  inv_L_scale:  [1.0, 1.0]
Epoch :  43  Time:  0.662  Rel. Train L2 Loss :  0.14422924134466383  Rel. Test L2 Loss :  0.14271019399166107  Test L2 Loss :  0.20643136262893677  inv_L_scale:  [1.0, 1.0]
Epoch :  44  Time:  0.663  Rel. Train L2 Loss :  0.14526928391721514  Rel. Test L2 Loss :  0.14289278149604798  Test L2 Loss :  0.20656091332435608  inv_L_scale:  [1.0, 1.0]
Epoch :  45  Time:  0.662  Rel. Train L2 Loss :  0.14530864702330695  Rel. Test L2 Loss :  0.1443964099884033  Test L2 Loss :  0.2083172905445099  inv_L_scale:  [1.0, 1.0]
Epoch :  46  Time:  0.664  Rel. Train L2 Loss :  0.14431093917952645  Rel. Test L2 Loss :  0.14245009064674377  Test L2 Loss :  0.2072280913591385  inv_L_scale:  [1.0, 1.0]
Epoch :  47  Time:  0.664  Rel. Train L2 Loss :  0.1440082272556093  Rel. Test L2 Loss :  0.1416360592842102  Test L2 Loss :  0.2058902657032013  inv_L_scale:  [1.0, 1.0]
Epoch :  48  Time:  0.662  Rel. Train L2 Loss :  0.14494894855552248  Rel. Test L2 Loss :  0.14482029974460603  Test L2 Loss :  0.209197296500206  inv_L_scale:  [1.0, 1.0]
Epoch :  49  Time:  0.662  Rel. Train L2 Loss :  0.1440723012553321  Rel. Test L2 Loss :  0.14185090005397796  Test L2 Loss :  0.20547292709350587  inv_L_scale:  [1.0, 1.0]
Epoch :  50  Time:  0.662  Rel. Train L2 Loss :  0.14478494101100498  Rel. Test L2 Loss :  0.1412963253259659  Test L2 Loss :  0.20478471755981445  inv_L_scale:  [1.0, 1.0]
Epoch :  51  Time:  0.662  Rel. Train L2 Loss :  0.14410368078284794  Rel. Test L2 Loss :  0.13798649430274965  Test L2 Loss :  0.2009594804048538  inv_L_scale:  [1.0, 1.0]
Epoch :  52  Time:  0.662  Rel. Train L2 Loss :  0.14303793119059668  Rel. Test L2 Loss :  0.1431415170431137  Test L2 Loss :  0.2071506017446518  inv_L_scale:  [1.0, 1.0]
Epoch :  53  Time:  0.663  Rel. Train L2 Loss :  0.1433208163579305  Rel. Test L2 Loss :  0.13955330669879915  Test L2 Loss :  0.20333608150482177  inv_L_scale:  [1.0, 1.0]
Epoch :  54  Time:  0.662  Rel. Train L2 Loss :  0.14244943877061209  Rel. Test L2 Loss :  0.13830334216356277  Test L2 Loss :  0.20199312448501586  inv_L_scale:  [1.0, 1.0]
Epoch :  55  Time:  0.662  Rel. Train L2 Loss :  0.14259549743599362  Rel. Test L2 Loss :  0.1432383191585541  Test L2 Loss :  0.20837120354175567  inv_L_scale:  [1.0, 1.0]
Epoch :  56  Time:  0.662  Rel. Train L2 Loss :  0.1430223528544108  Rel. Test L2 Loss :  0.13981468379497528  Test L2 Loss :  0.20283172726631166  inv_L_scale:  [1.0, 1.0]
Epoch :  57  Time:  0.662  Rel. Train L2 Loss :  0.14288315759764778  Rel. Test L2 Loss :  0.13981255948543547  Test L2 Loss :  0.20377305150032043  inv_L_scale:  [1.0, 1.0]
Epoch :  58  Time:  0.662  Rel. Train L2 Loss :  0.1421636982427703  Rel. Test L2 Loss :  0.14154674410820006  Test L2 Loss :  0.20489305555820464  inv_L_scale:  [1.0, 1.0]
Epoch :  59  Time:  0.663  Rel. Train L2 Loss :  0.14246201025115118  Rel. Test L2 Loss :  0.14479365468025207  Test L2 Loss :  0.21224822759628295  inv_L_scale:  [1.0, 1.0]
Epoch :  60  Time:  0.662  Rel. Train L2 Loss :  0.14327665872044035  Rel. Test L2 Loss :  0.14068223118782044  Test L2 Loss :  0.20349319636821747  inv_L_scale:  [1.0, 1.0]
Epoch :  61  Time:  0.662  Rel. Train L2 Loss :  0.14188160558541615  Rel. Test L2 Loss :  0.1376960927248001  Test L2 Loss :  0.2002726435661316  inv_L_scale:  [1.0, 1.0]
Epoch :  62  Time:  0.662  Rel. Train L2 Loss :  0.14152761373254988  Rel. Test L2 Loss :  0.14207042515277862  Test L2 Loss :  0.20513063430786133  inv_L_scale:  [1.0, 1.0]
Epoch :  63  Time:  0.662  Rel. Train L2 Loss :  0.14198392315043343  Rel. Test L2 Loss :  0.13974230468273163  Test L2 Loss :  0.2028769761323929  inv_L_scale:  [1.0, 1.0]
Epoch :  64  Time:  0.662  Rel. Train L2 Loss :  0.1421163895395067  Rel. Test L2 Loss :  0.14259665429592133  Test L2 Loss :  0.20656116008758546  inv_L_scale:  [1.0, 1.0]
Epoch :  65  Time:  0.664  Rel. Train L2 Loss :  0.1412625484334098  Rel. Test L2 Loss :  0.1403416359424591  Test L2 Loss :  0.2029755902290344  inv_L_scale:  [1.0, 1.0]
Epoch :  66  Time:  0.663  Rel. Train L2 Loss :  0.1418611944384045  Rel. Test L2 Loss :  0.13683849066495896  Test L2 Loss :  0.19896795034408568  inv_L_scale:  [1.0, 1.0]
Epoch :  67  Time:  0.662  Rel. Train L2 Loss :  0.14098942697048186  Rel. Test L2 Loss :  0.13721363365650177  Test L2 Loss :  0.19993600606918335  inv_L_scale:  [1.0, 1.0]
Epoch :  68  Time:  0.662  Rel. Train L2 Loss :  0.14188677628835042  Rel. Test L2 Loss :  0.14128864288330079  Test L2 Loss :  0.20521090507507325  inv_L_scale:  [1.0, 1.0]
Epoch :  69  Time:  0.662  Rel. Train L2 Loss :  0.14150824106401869  Rel. Test L2 Loss :  0.1380762904882431  Test L2 Loss :  0.20043564915657044  inv_L_scale:  [1.0, 1.0]
Epoch :  70  Time:  0.662  Rel. Train L2 Loss :  0.14186481747362348  Rel. Test L2 Loss :  0.13824893832206725  Test L2 Loss :  0.20130956947803497  inv_L_scale:  [1.0, 1.0]
Epoch :  71  Time:  0.662  Rel. Train L2 Loss :  0.14215995338228013  Rel. Test L2 Loss :  0.13749021112918855  Test L2 Loss :  0.199825758934021  inv_L_scale:  [1.0, 1.0]
Epoch :  72  Time:  0.663  Rel. Train L2 Loss :  0.14006325754854415  Rel. Test L2 Loss :  0.1390780106186867  Test L2 Loss :  0.20235628187656401  inv_L_scale:  [1.0, 1.0]
Epoch :  73  Time:  0.662  Rel. Train L2 Loss :  0.14129207531611124  Rel. Test L2 Loss :  0.13724679708480836  Test L2 Loss :  0.19922798097133637  inv_L_scale:  [1.0, 1.0]
Epoch :  74  Time:  0.662  Rel. Train L2 Loss :  0.14106041736072963  Rel. Test L2 Loss :  0.14058385252952577  Test L2 Loss :  0.20440703868865967  inv_L_scale:  [1.0, 1.0]
Epoch :  75  Time:  0.662  Rel. Train L2 Loss :  0.14070932110150655  Rel. Test L2 Loss :  0.13602187097072602  Test L2 Loss :  0.19826777458190917  inv_L_scale:  [1.0, 1.0]
Epoch :  76  Time:  0.662  Rel. Train L2 Loss :  0.14019195232126447  Rel. Test L2 Loss :  0.13739947259426116  Test L2 Loss :  0.19968074202537536  inv_L_scale:  [1.0, 1.0]
Epoch :  77  Time:  0.665  Rel. Train L2 Loss :  0.14036743690570194  Rel. Test L2 Loss :  0.13968725383281708  Test L2 Loss :  0.20301406979560851  inv_L_scale:  [1.0, 1.0]
Epoch :  78  Time:  0.663  Rel. Train L2 Loss :  0.1400360342529085  Rel. Test L2 Loss :  0.13462561756372451  Test L2 Loss :  0.19629933476448058  inv_L_scale:  [1.0, 1.0]
Epoch :  79  Time:  0.662  Rel. Train L2 Loss :  0.14055673261483512  Rel. Test L2 Loss :  0.13720783174037934  Test L2 Loss :  0.19878330409526826  inv_L_scale:  [1.0, 1.0]
Epoch :  80  Time:  0.662  Rel. Train L2 Loss :  0.14072979191939036  Rel. Test L2 Loss :  0.13966458320617675  Test L2 Loss :  0.2032604056596756  inv_L_scale:  [1.0, 1.0]
Epoch :  81  Time:  0.662  Rel. Train L2 Loss :  0.14014963613616097  Rel. Test L2 Loss :  0.14016500294208525  Test L2 Loss :  0.20290964007377624  inv_L_scale:  [1.0, 1.0]
Epoch :  82  Time:  0.662  Rel. Train L2 Loss :  0.1399567527241177  Rel. Test L2 Loss :  0.13698958456516266  Test L2 Loss :  0.19917798280715943  inv_L_scale:  [1.0, 1.0]
Epoch :  83  Time:  0.662  Rel. Train L2 Loss :  0.13988501386510002  Rel. Test L2 Loss :  0.13770051598548888  Test L2 Loss :  0.1996628475189209  inv_L_scale:  [1.0, 1.0]
Epoch :  84  Time:  0.662  Rel. Train L2 Loss :  0.13973490569326613  Rel. Test L2 Loss :  0.13735512018203735  Test L2 Loss :  0.19917322993278502  inv_L_scale:  [1.0, 1.0]
Epoch :  85  Time:  0.663  Rel. Train L2 Loss :  0.1391369620958964  Rel. Test L2 Loss :  0.13524357318878175  Test L2 Loss :  0.19640872597694398  inv_L_scale:  [1.0, 1.0]
Epoch :  86  Time:  0.663  Rel. Train L2 Loss :  0.13942883736557432  Rel. Test L2 Loss :  0.1375403094291687  Test L2 Loss :  0.19960774064064027  inv_L_scale:  [1.0, 1.0]
Epoch :  87  Time:  0.662  Rel. Train L2 Loss :  0.13920733557807075  Rel. Test L2 Loss :  0.13551948666572572  Test L2 Loss :  0.19716132044792176  inv_L_scale:  [1.0, 1.0]
Epoch :  88  Time:  0.662  Rel. Train L2 Loss :  0.1396695362859302  Rel. Test L2 Loss :  0.13823068618774415  Test L2 Loss :  0.20062165856361389  inv_L_scale:  [1.0, 1.0]
Epoch :  89  Time:  0.662  Rel. Train L2 Loss :  0.13961779793103535  Rel. Test L2 Loss :  0.1361028814315796  Test L2 Loss :  0.197890807390213  inv_L_scale:  [1.0, 1.0]
Epoch :  90  Time:  0.662  Rel. Train L2 Loss :  0.13909353521135118  Rel. Test L2 Loss :  0.1405390280485153  Test L2 Loss :  0.20310453534126283  inv_L_scale:  [1.0, 1.0]
Epoch :  91  Time:  0.662  Rel. Train L2 Loss :  0.13907962600390117  Rel. Test L2 Loss :  0.1390250778198242  Test L2 Loss :  0.2017621421813965  inv_L_scale:  [1.0, 1.0]
Epoch :  92  Time:  0.662  Rel. Train L2 Loss :  0.13817390931977167  Rel. Test L2 Loss :  0.13672346830368043  Test L2 Loss :  0.19881446182727813  inv_L_scale:  [1.0, 1.0]
Epoch :  93  Time:  0.663  Rel. Train L2 Loss :  0.13857265359825557  Rel. Test L2 Loss :  0.1372784072160721  Test L2 Loss :  0.19958480834960937  inv_L_scale:  [1.0, 1.0]
Epoch :  94  Time:  0.663  Rel. Train L2 Loss :  0.1382579626639684  Rel. Test L2 Loss :  0.13719257950782776  Test L2 Loss :  0.19919766426086427  inv_L_scale:  [1.0, 1.0]
Epoch :  95  Time:  0.662  Rel. Train L2 Loss :  0.1385471467839347  Rel. Test L2 Loss :  0.13717576563358308  Test L2 Loss :  0.20004896104335784  inv_L_scale:  [1.0, 1.0]
Epoch :  96  Time:  0.662  Rel. Train L2 Loss :  0.13892747196886274  Rel. Test L2 Loss :  0.1395293265581131  Test L2 Loss :  0.2021159225702286  inv_L_scale:  [1.0, 1.0]
Epoch :  97  Time:  0.662  Rel. Train L2 Loss :  0.13902237017949423  Rel. Test L2 Loss :  0.13651090919971465  Test L2 Loss :  0.19847041726112366  inv_L_scale:  [1.0, 1.0]
Epoch :  98  Time:  0.662  Rel. Train L2 Loss :  0.13892892837524415  Rel. Test L2 Loss :  0.13801781117916107  Test L2 Loss :  0.20198414444923402  inv_L_scale:  [1.0, 1.0]
Epoch :  99  Time:  0.662  Rel. Train L2 Loss :  0.13802906552950542  Rel. Test L2 Loss :  0.1374250280857086  Test L2 Loss :  0.1994189465045929  inv_L_scale:  [1.0, 1.0]
Epoch :  100  Time:  0.665  Rel. Train L2 Loss :  0.13810331410831875  Rel. Test L2 Loss :  0.1368647360801697  Test L2 Loss :  0.1988365638256073  inv_L_scale:  [1.0, 1.0]
Epoch :  101  Time:  0.664  Rel. Train L2 Loss :  0.13757680628034805  Rel. Test L2 Loss :  0.1337173056602478  Test L2 Loss :  0.19481131911277771  inv_L_scale:  [1.0, 1.0]
Epoch :  102  Time:  0.664  Rel. Train L2 Loss :  0.13782279200024075  Rel. Test L2 Loss :  0.1353351104259491  Test L2 Loss :  0.1968950831890106  inv_L_scale:  [1.0, 1.0]
Epoch :  103  Time:  0.662  Rel. Train L2 Loss :  0.13763412780231898  Rel. Test L2 Loss :  0.13531057864427568  Test L2 Loss :  0.19726755917072297  inv_L_scale:  [1.0, 1.0]
Epoch :  104  Time:  0.663  Rel. Train L2 Loss :  0.1375973442527983  Rel. Test L2 Loss :  0.13480855107307435  Test L2 Loss :  0.19643053352832796  inv_L_scale:  [1.0, 1.0]
Epoch :  105  Time:  0.662  Rel. Train L2 Loss :  0.1371832932366265  Rel. Test L2 Loss :  0.13627765119075774  Test L2 Loss :  0.1982483047246933  inv_L_scale:  [1.0, 1.0]
Epoch :  106  Time:  0.663  Rel. Train L2 Loss :  0.13730498201317257  Rel. Test L2 Loss :  0.13504748404026032  Test L2 Loss :  0.1960858404636383  inv_L_scale:  [1.0, 1.0]
Epoch :  107  Time:  0.662  Rel. Train L2 Loss :  0.13794332643349966  Rel. Test L2 Loss :  0.13676654815673828  Test L2 Loss :  0.19893308281898497  inv_L_scale:  [1.0, 1.0]
Epoch :  108  Time:  0.662  Rel. Train L2 Loss :  0.13717725495497385  Rel. Test L2 Loss :  0.13665633022785187  Test L2 Loss :  0.1994039762020111  inv_L_scale:  [1.0, 1.0]
Epoch :  109  Time:  0.663  Rel. Train L2 Loss :  0.13719440778096517  Rel. Test L2 Loss :  0.13806512653827668  Test L2 Loss :  0.20023690342903136  inv_L_scale:  [1.0, 1.0]
Epoch :  110  Time:  0.663  Rel. Train L2 Loss :  0.13685063706503975  Rel. Test L2 Loss :  0.1385165548324585  Test L2 Loss :  0.20128080487251282  inv_L_scale:  [1.0, 1.0]
Epoch :  111  Time:  0.663  Rel. Train L2 Loss :  0.13745675676398808  Rel. Test L2 Loss :  0.13480068892240524  Test L2 Loss :  0.19684529900550843  inv_L_scale:  [1.0, 1.0]
Epoch :  112  Time:  0.662  Rel. Train L2 Loss :  0.13785829106966654  Rel. Test L2 Loss :  0.1350406077504158  Test L2 Loss :  0.19697431683540345  inv_L_scale:  [1.0, 1.0]
Epoch :  113  Time:  0.662  Rel. Train L2 Loss :  0.13673385096920862  Rel. Test L2 Loss :  0.1366803130507469  Test L2 Loss :  0.19966959893703462  inv_L_scale:  [1.0, 1.0]
Epoch :  114  Time:  0.663  Rel. Train L2 Loss :  0.13710156904326545  Rel. Test L2 Loss :  0.1319447347521782  Test L2 Loss :  0.19248657286167145  inv_L_scale:  [1.0, 1.0]
Epoch :  115  Time:  0.663  Rel. Train L2 Loss :  0.13671661582258013  Rel. Test L2 Loss :  0.13618308186531067  Test L2 Loss :  0.1985890781879425  inv_L_scale:  [1.0, 1.0]
Epoch :  116  Time:  0.662  Rel. Train L2 Loss :  0.13718252817789714  Rel. Test L2 Loss :  0.1342744743824005  Test L2 Loss :  0.19528822660446166  inv_L_scale:  [1.0, 1.0]
Epoch :  117  Time:  0.662  Rel. Train L2 Loss :  0.13661145283116236  Rel. Test L2 Loss :  0.13654303729534148  Test L2 Loss :  0.1981053251028061  inv_L_scale:  [1.0, 1.0]
Epoch :  118  Time:  0.663  Rel. Train L2 Loss :  0.13690991312265396  Rel. Test L2 Loss :  0.13607699930667877  Test L2 Loss :  0.1976064682006836  inv_L_scale:  [1.0, 1.0]
Epoch :  119  Time:  0.663  Rel. Train L2 Loss :  0.1365269657307201  Rel. Test L2 Loss :  0.13488460540771485  Test L2 Loss :  0.1969812697172165  inv_L_scale:  [1.0, 1.0]
Epoch :  120  Time:  0.666  Rel. Train L2 Loss :  0.13663206699821684  Rel. Test L2 Loss :  0.13531646370887757  Test L2 Loss :  0.1964708697795868  inv_L_scale:  [1.0, 1.0]
Epoch :  121  Time:  0.664  Rel. Train L2 Loss :  0.13642534666591222  Rel. Test L2 Loss :  0.1351916089653969  Test L2 Loss :  0.19789778232574462  inv_L_scale:  [1.0, 1.0]
Epoch :  122  Time:  0.663  Rel. Train L2 Loss :  0.13647134986188678  Rel. Test L2 Loss :  0.13423233449459077  Test L2 Loss :  0.19538435220718384  inv_L_scale:  [1.0, 1.0]
Epoch :  123  Time:  0.663  Rel. Train L2 Loss :  0.13624950839413538  Rel. Test L2 Loss :  0.13332710087299346  Test L2 Loss :  0.1938469308614731  inv_L_scale:  [1.0, 1.0]
Epoch :  124  Time:  0.663  Rel. Train L2 Loss :  0.13582690868112776  Rel. Test L2 Loss :  0.13279048144817351  Test L2 Loss :  0.193485626578331  inv_L_scale:  [1.0, 1.0]
Epoch :  125  Time:  0.662  Rel. Train L2 Loss :  0.13687724868456522  Rel. Test L2 Loss :  0.13629574775695802  Test L2 Loss :  0.19877946734428406  inv_L_scale:  [1.0, 1.0]
Epoch :  126  Time:  0.663  Rel. Train L2 Loss :  0.13607656882868874  Rel. Test L2 Loss :  0.13354867160320283  Test L2 Loss :  0.19475191593170166  inv_L_scale:  [1.0, 1.0]
Epoch :  127  Time:  0.662  Rel. Train L2 Loss :  0.1357549751136038  Rel. Test L2 Loss :  0.13289749562740327  Test L2 Loss :  0.19364384412765503  inv_L_scale:  [1.0, 1.0]
Epoch :  128  Time:  0.663  Rel. Train L2 Loss :  0.13642371038595835  Rel. Test L2 Loss :  0.13365872144699098  Test L2 Loss :  0.1946030819416046  inv_L_scale:  [1.0, 1.0]
Epoch :  129  Time:  0.663  Rel. Train L2 Loss :  0.1357260893450843  Rel. Test L2 Loss :  0.13471443831920624  Test L2 Loss :  0.19637649178504943  inv_L_scale:  [1.0, 1.0]
Epoch :  130  Time:  0.663  Rel. Train L2 Loss :  0.13574821670850118  Rel. Test L2 Loss :  0.13532428145408631  Test L2 Loss :  0.1967055928707123  inv_L_scale:  [1.0, 1.0]
Epoch :  131  Time:  0.663  Rel. Train L2 Loss :  0.13581350207328796  Rel. Test L2 Loss :  0.13555308997631074  Test L2 Loss :  0.19725451350212098  inv_L_scale:  [1.0, 1.0]
Epoch :  132  Time:  0.662  Rel. Train L2 Loss :  0.13568741189108954  Rel. Test L2 Loss :  0.13156711876392366  Test L2 Loss :  0.1914107644557953  inv_L_scale:  [1.0, 1.0]
Epoch :  133  Time:  0.662  Rel. Train L2 Loss :  0.1356852051946852  Rel. Test L2 Loss :  0.13508467316627504  Test L2 Loss :  0.1968419933319092  inv_L_scale:  [1.0, 1.0]
Epoch :  134  Time:  0.663  Rel. Train L2 Loss :  0.1354402318265703  Rel. Test L2 Loss :  0.13144434243440628  Test L2 Loss :  0.1918758475780487  inv_L_scale:  [1.0, 1.0]
Epoch :  135  Time:  0.663  Rel. Train L2 Loss :  0.13545662860075633  Rel. Test L2 Loss :  0.13318857729434966  Test L2 Loss :  0.19468570590019227  inv_L_scale:  [1.0, 1.0]
Epoch :  136  Time:  0.663  Rel. Train L2 Loss :  0.13546488523483277  Rel. Test L2 Loss :  0.13390649735927582  Test L2 Loss :  0.19468355417251587  inv_L_scale:  [1.0, 1.0]
Epoch :  137  Time:  0.662  Rel. Train L2 Loss :  0.1353955457939042  Rel. Test L2 Loss :  0.1319408917427063  Test L2 Loss :  0.19264406323432923  inv_L_scale:  [1.0, 1.0]
Epoch :  138  Time:  0.662  Rel. Train L2 Loss :  0.13522818817032708  Rel. Test L2 Loss :  0.13629380583763123  Test L2 Loss :  0.19820679128170013  inv_L_scale:  [1.0, 1.0]
Epoch :  139  Time:  0.662  Rel. Train L2 Loss :  0.13507528258694543  Rel. Test L2 Loss :  0.13369536727666856  Test L2 Loss :  0.19432926177978516  inv_L_scale:  [1.0, 1.0]
Epoch :  140  Time:  0.664  Rel. Train L2 Loss :  0.1353422004315588  Rel. Test L2 Loss :  0.13369027495384217  Test L2 Loss :  0.19451496601104737  inv_L_scale:  [1.0, 1.0]
Epoch :  141  Time:  0.663  Rel. Train L2 Loss :  0.1347208885351817  Rel. Test L2 Loss :  0.1361432456970215  Test L2 Loss :  0.19743210554122925  inv_L_scale:  [1.0, 1.0]
Epoch :  142  Time:  0.662  Rel. Train L2 Loss :  0.134774339430862  Rel. Test L2 Loss :  0.13280712366104125  Test L2 Loss :  0.1930360370874405  inv_L_scale:  [1.0, 1.0]
Epoch :  143  Time:  0.663  Rel. Train L2 Loss :  0.1354301977157593  Rel. Test L2 Loss :  0.1332598489522934  Test L2 Loss :  0.1940654706954956  inv_L_scale:  [1.0, 1.0]
Epoch :  144  Time:  0.663  Rel. Train L2 Loss :  0.1357021352648735  Rel. Test L2 Loss :  0.13809219181537627  Test L2 Loss :  0.2013096958398819  inv_L_scale:  [1.0, 1.0]
Epoch :  145  Time:  0.662  Rel. Train L2 Loss :  0.1351167196697659  Rel. Test L2 Loss :  0.13268193006515502  Test L2 Loss :  0.19320320844650268  inv_L_scale:  [1.0, 1.0]
Epoch :  146  Time:  0.663  Rel. Train L2 Loss :  0.1349996324049102  Rel. Test L2 Loss :  0.1318020850419998  Test L2 Loss :  0.19203598856925963  inv_L_scale:  [1.0, 1.0]
Epoch :  147  Time:  0.663  Rel. Train L2 Loss :  0.13458365569512049  Rel. Test L2 Loss :  0.13794339656829835  Test L2 Loss :  0.20146575927734375  inv_L_scale:  [1.0, 1.0]
Epoch :  148  Time:  0.663  Rel. Train L2 Loss :  0.13489555451605056  Rel. Test L2 Loss :  0.13284534722566604  Test L2 Loss :  0.19371794581413268  inv_L_scale:  [1.0, 1.0]
Epoch :  149  Time:  0.664  Rel. Train L2 Loss :  0.13512801362408533  Rel. Test L2 Loss :  0.1361103856563568  Test L2 Loss :  0.19763482391834258  inv_L_scale:  [1.0, 1.0]
Epoch :  150  Time:  0.663  Rel. Train L2 Loss :  0.1351177308956782  Rel. Test L2 Loss :  0.1397654289007187  Test L2 Loss :  0.20231277942657472  inv_L_scale:  [1.0, 1.0]
Epoch :  151  Time:  0.662  Rel. Train L2 Loss :  0.1346440123518308  Rel. Test L2 Loss :  0.13461779356002807  Test L2 Loss :  0.19588242292404176  inv_L_scale:  [1.0, 1.0]
Epoch :  152  Time:  0.662  Rel. Train L2 Loss :  0.13451834552817873  Rel. Test L2 Loss :  0.13315037310123443  Test L2 Loss :  0.19346094250679016  inv_L_scale:  [1.0, 1.0]
Epoch :  153  Time:  0.662  Rel. Train L2 Loss :  0.13443332334359487  Rel. Test L2 Loss :  0.13580566346645356  Test L2 Loss :  0.19756634950637816  inv_L_scale:  [1.0, 1.0]
Epoch :  154  Time:  0.662  Rel. Train L2 Loss :  0.13478814555539026  Rel. Test L2 Loss :  0.13355084717273713  Test L2 Loss :  0.19412843406200408  inv_L_scale:  [1.0, 1.0]
Epoch :  155  Time:  0.662  Rel. Train L2 Loss :  0.1345292121834225  Rel. Test L2 Loss :  0.13281168639659882  Test L2 Loss :  0.1934186899662018  inv_L_scale:  [1.0, 1.0]
Epoch :  156  Time:  0.662  Rel. Train L2 Loss :  0.13390282531579337  Rel. Test L2 Loss :  0.13261479765176773  Test L2 Loss :  0.19308903813362122  inv_L_scale:  [1.0, 1.0]
Epoch :  157  Time:  0.663  Rel. Train L2 Loss :  0.1336932655175527  Rel. Test L2 Loss :  0.13264081120491028  Test L2 Loss :  0.1933160889148712  inv_L_scale:  [1.0, 1.0]
Epoch :  158  Time:  0.663  Rel. Train L2 Loss :  0.1349463810523351  Rel. Test L2 Loss :  0.1333047306537628  Test L2 Loss :  0.19434289932250975  inv_L_scale:  [1.0, 1.0]
Epoch :  159  Time:  0.662  Rel. Train L2 Loss :  0.13419181982676187  Rel. Test L2 Loss :  0.1339554578065872  Test L2 Loss :  0.1947492516040802  inv_L_scale:  [1.0, 1.0]
Epoch :  160  Time:  0.662  Rel. Train L2 Loss :  0.13433173047171698  Rel. Test L2 Loss :  0.13187472462654115  Test L2 Loss :  0.1920030790567398  inv_L_scale:  [1.0, 1.0]
Epoch :  161  Time:  0.662  Rel. Train L2 Loss :  0.1341456601354811  Rel. Test L2 Loss :  0.13244729489088058  Test L2 Loss :  0.19292047441005708  inv_L_scale:  [1.0, 1.0]
Epoch :  162  Time:  0.662  Rel. Train L2 Loss :  0.13400328838162953  Rel. Test L2 Loss :  0.1333218562602997  Test L2 Loss :  0.19356598615646362  inv_L_scale:  [1.0, 1.0]
Epoch :  163  Time:  0.663  Rel. Train L2 Loss :  0.13385382738378312  Rel. Test L2 Loss :  0.13260313272476196  Test L2 Loss :  0.19345622837543489  inv_L_scale:  [1.0, 1.0]
Epoch :  164  Time:  0.665  Rel. Train L2 Loss :  0.13415131880177392  Rel. Test L2 Loss :  0.13215524971485137  Test L2 Loss :  0.19254974126815796  inv_L_scale:  [1.0, 1.0]
Epoch :  165  Time:  0.664  Rel. Train L2 Loss :  0.13425796926021577  Rel. Test L2 Loss :  0.13335847645998  Test L2 Loss :  0.19402071297168733  inv_L_scale:  [1.0, 1.0]
Epoch :  166  Time:  0.662  Rel. Train L2 Loss :  0.13448692043622335  Rel. Test L2 Loss :  0.13151433050632477  Test L2 Loss :  0.19151434183120727  inv_L_scale:  [1.0, 1.0]
Epoch :  167  Time:  0.662  Rel. Train L2 Loss :  0.13411668853627312  Rel. Test L2 Loss :  0.13194357395172118  Test L2 Loss :  0.19239207863807678  inv_L_scale:  [1.0, 1.0]
Epoch :  168  Time:  0.663  Rel. Train L2 Loss :  0.13361114545000924  Rel. Test L2 Loss :  0.13105639398097993  Test L2 Loss :  0.19101910710334777  inv_L_scale:  [1.0, 1.0]
Epoch :  169  Time:  0.663  Rel. Train L2 Loss :  0.1338955674568812  Rel. Test L2 Loss :  0.13086590707302093  Test L2 Loss :  0.19120937943458557  inv_L_scale:  [1.0, 1.0]
Epoch :  170  Time:  0.663  Rel. Train L2 Loss :  0.1337156754732132  Rel. Test L2 Loss :  0.1332458370923996  Test L2 Loss :  0.19399237155914306  inv_L_scale:  [1.0, 1.0]
Epoch :  171  Time:  0.662  Rel. Train L2 Loss :  0.13329633149835798  Rel. Test L2 Loss :  0.1312360954284668  Test L2 Loss :  0.1914629578590393  inv_L_scale:  [1.0, 1.0]
Epoch :  172  Time:  0.663  Rel. Train L2 Loss :  0.13344026221169367  Rel. Test L2 Loss :  0.13334993064403533  Test L2 Loss :  0.19385183870792388  inv_L_scale:  [1.0, 1.0]
Epoch :  173  Time:  0.663  Rel. Train L2 Loss :  0.13334705015023549  Rel. Test L2 Loss :  0.13294264495372773  Test L2 Loss :  0.1938994997739792  inv_L_scale:  [1.0, 1.0]
Epoch :  174  Time:  0.663  Rel. Train L2 Loss :  0.13363193896081713  Rel. Test L2 Loss :  0.13220070123672487  Test L2 Loss :  0.1926376587152481  inv_L_scale:  [1.0, 1.0]
Epoch :  175  Time:  0.663  Rel. Train L2 Loss :  0.13329832871754965  Rel. Test L2 Loss :  0.13250851273536682  Test L2 Loss :  0.1931093764305115  inv_L_scale:  [1.0, 1.0]
Epoch :  176  Time:  0.662  Rel. Train L2 Loss :  0.1333798619111379  Rel. Test L2 Loss :  0.1323809152841568  Test L2 Loss :  0.1928798758983612  inv_L_scale:  [1.0, 1.0]
Epoch :  177  Time:  0.662  Rel. Train L2 Loss :  0.13350785050127242  Rel. Test L2 Loss :  0.13186640828847884  Test L2 Loss :  0.19209577023983002  inv_L_scale:  [1.0, 1.0]
Epoch :  178  Time:  0.661  Rel. Train L2 Loss :  0.13319545686244966  Rel. Test L2 Loss :  0.13093887150287628  Test L2 Loss :  0.19120935678482057  inv_L_scale:  [1.0, 1.0]
Epoch :  179  Time:  0.661  Rel. Train L2 Loss :  0.1334803620311949  Rel. Test L2 Loss :  0.13172892212867737  Test L2 Loss :  0.19189760684967042  inv_L_scale:  [1.0, 1.0]
Epoch :  180  Time:  0.661  Rel. Train L2 Loss :  0.13322669466336567  Rel. Test L2 Loss :  0.13141199171543122  Test L2 Loss :  0.19171107470989227  inv_L_scale:  [1.0, 1.0]
Epoch :  181  Time:  0.661  Rel. Train L2 Loss :  0.13310001419650183  Rel. Test L2 Loss :  0.13236477911472322  Test L2 Loss :  0.1925382947921753  inv_L_scale:  [1.0, 1.0]
Epoch :  182  Time:  0.661  Rel. Train L2 Loss :  0.13306155731280644  Rel. Test L2 Loss :  0.13128717482089997  Test L2 Loss :  0.1913146424293518  inv_L_scale:  [1.0, 1.0]
Epoch :  183  Time:  0.66  Rel. Train L2 Loss :  0.13310494158003067  Rel. Test L2 Loss :  0.13187524169683457  Test L2 Loss :  0.19207272291183472  inv_L_scale:  [1.0, 1.0]
Epoch :  184  Time:  0.66  Rel. Train L2 Loss :  0.13355655001269445  Rel. Test L2 Loss :  0.13049197673797608  Test L2 Loss :  0.1902845686674118  inv_L_scale:  [1.0, 1.0]
Epoch :  185  Time:  0.661  Rel. Train L2 Loss :  0.1327895943323771  Rel. Test L2 Loss :  0.1328326040506363  Test L2 Loss :  0.19336730480194092  inv_L_scale:  [1.0, 1.0]
Epoch :  186  Time:  0.66  Rel. Train L2 Loss :  0.1332080520523919  Rel. Test L2 Loss :  0.13114334225654603  Test L2 Loss :  0.19126253187656403  inv_L_scale:  [1.0, 1.0]
Epoch :  187  Time:  0.66  Rel. Train L2 Loss :  0.132966111600399  Rel. Test L2 Loss :  0.131955506503582  Test L2 Loss :  0.1924014389514923  inv_L_scale:  [1.0, 1.0]
Epoch :  188  Time:  0.66  Rel. Train L2 Loss :  0.13289126137892404  Rel. Test L2 Loss :  0.13024925649166108  Test L2 Loss :  0.19009286999702454  inv_L_scale:  [1.0, 1.0]
Epoch :  189  Time:  0.661  Rel. Train L2 Loss :  0.1328939280576176  Rel. Test L2 Loss :  0.1339426028728485  Test L2 Loss :  0.19459861397743225  inv_L_scale:  [1.0, 1.0]
Epoch :  190  Time:  0.663  Rel. Train L2 Loss :  0.13315995123651292  Rel. Test L2 Loss :  0.13274664044380188  Test L2 Loss :  0.1931435251235962  inv_L_scale:  [1.0, 1.0]
Epoch :  191  Time:  0.661  Rel. Train L2 Loss :  0.13327211611800724  Rel. Test L2 Loss :  0.13295189827680587  Test L2 Loss :  0.19353844940662385  inv_L_scale:  [1.0, 1.0]
Epoch :  192  Time:  0.661  Rel. Train L2 Loss :  0.132604804303911  Rel. Test L2 Loss :  0.13117218792438506  Test L2 Loss :  0.1918309086561203  inv_L_scale:  [1.0, 1.0]
Epoch :  193  Time:  0.662  Rel. Train L2 Loss :  0.13248443047205608  Rel. Test L2 Loss :  0.13231725573539735  Test L2 Loss :  0.19242094397544862  inv_L_scale:  [1.0, 1.0]
Epoch :  194  Time:  0.661  Rel. Train L2 Loss :  0.13248070153925154  Rel. Test L2 Loss :  0.13301765024662018  Test L2 Loss :  0.19375160872936248  inv_L_scale:  [1.0, 1.0]
Epoch :  195  Time:  0.661  Rel. Train L2 Loss :  0.1326872553428014  Rel. Test L2 Loss :  0.1306665551662445  Test L2 Loss :  0.1904422378540039  inv_L_scale:  [1.0, 1.0]
Epoch :  196  Time:  0.661  Rel. Train L2 Loss :  0.13260223315821754  Rel. Test L2 Loss :  0.13138051927089692  Test L2 Loss :  0.19134496688842773  inv_L_scale:  [1.0, 1.0]
Epoch :  197  Time:  0.661  Rel. Train L2 Loss :  0.13249273174338871  Rel. Test L2 Loss :  0.13040496170520782  Test L2 Loss :  0.19025079846382142  inv_L_scale:  [1.0, 1.0]
Epoch :  198  Time:  0.661  Rel. Train L2 Loss :  0.13307732191350724  Rel. Test L2 Loss :  0.1317664709687233  Test L2 Loss :  0.1920720648765564  inv_L_scale:  [1.0, 1.0]
Epoch :  199  Time:  0.661  Rel. Train L2 Loss :  0.1321654948592186  Rel. Test L2 Loss :  0.13099715620279312  Test L2 Loss :  0.19075445353984832  inv_L_scale:  [1.0, 1.0]
Epoch :  200  Time:  0.663  Rel. Train L2 Loss :  0.13224718040890163  Rel. Test L2 Loss :  0.13068512618541717  Test L2 Loss :  0.1903892356157303  inv_L_scale:  [1.0, 1.0]
Epoch :  201  Time:  0.662  Rel. Train L2 Loss :  0.1323282927274704  Rel. Test L2 Loss :  0.1307391941547394  Test L2 Loss :  0.19036794662475587  inv_L_scale:  [1.0, 1.0]
Epoch :  202  Time:  0.662  Rel. Train L2 Loss :  0.13200128687752619  Rel. Test L2 Loss :  0.13032364308834077  Test L2 Loss :  0.1895228111743927  inv_L_scale:  [1.0, 1.0]
Epoch :  203  Time:  0.661  Rel. Train L2 Loss :  0.1323515142334832  Rel. Test L2 Loss :  0.13076798141002655  Test L2 Loss :  0.19042612254619598  inv_L_scale:  [1.0, 1.0]
Epoch :  204  Time:  0.662  Rel. Train L2 Loss :  0.13227389249536725  Rel. Test L2 Loss :  0.1305248510837555  Test L2 Loss :  0.19051819264888764  inv_L_scale:  [1.0, 1.0]
Epoch :  205  Time:  0.662  Rel. Train L2 Loss :  0.13194397707780203  Rel. Test L2 Loss :  0.13065533578395844  Test L2 Loss :  0.19113181114196778  inv_L_scale:  [1.0, 1.0]
Epoch :  206  Time:  0.661  Rel. Train L2 Loss :  0.13207848449548085  Rel. Test L2 Loss :  0.13003926932811738  Test L2 Loss :  0.18945918202400208  inv_L_scale:  [1.0, 1.0]
Epoch :  207  Time:  0.661  Rel. Train L2 Loss :  0.131952832142512  Rel. Test L2 Loss :  0.13150587320327758  Test L2 Loss :  0.1917944234609604  inv_L_scale:  [1.0, 1.0]
Epoch :  208  Time:  0.661  Rel. Train L2 Loss :  0.13205175247457293  Rel. Test L2 Loss :  0.13076863706111908  Test L2 Loss :  0.19067647695541382  inv_L_scale:  [1.0, 1.0]
Epoch :  209  Time:  0.662  Rel. Train L2 Loss :  0.13209620581732856  Rel. Test L2 Loss :  0.13183313429355623  Test L2 Loss :  0.1922428774833679  inv_L_scale:  [1.0, 1.0]
Epoch :  210  Time:  0.662  Rel. Train L2 Loss :  0.13192840774854026  Rel. Test L2 Loss :  0.12969836950302124  Test L2 Loss :  0.18915538609027863  inv_L_scale:  [1.0, 1.0]
Epoch :  211  Time:  0.661  Rel. Train L2 Loss :  0.13207728452152676  Rel. Test L2 Loss :  0.12997508764266968  Test L2 Loss :  0.18978455185890197  inv_L_scale:  [1.0, 1.0]
Epoch :  212  Time:  0.661  Rel. Train L2 Loss :  0.13189218117131127  Rel. Test L2 Loss :  0.13113270282745362  Test L2 Loss :  0.19086175322532653  inv_L_scale:  [1.0, 1.0]
Epoch :  213  Time:  0.661  Rel. Train L2 Loss :  0.1316737769709693  Rel. Test L2 Loss :  0.13098787546157836  Test L2 Loss :  0.19124238014221193  inv_L_scale:  [1.0, 1.0]
Epoch :  214  Time:  0.661  Rel. Train L2 Loss :  0.13184376411967808  Rel. Test L2 Loss :  0.13130453944206238  Test L2 Loss :  0.19195631861686707  inv_L_scale:  [1.0, 1.0]
Epoch :  215  Time:  0.661  Rel. Train L2 Loss :  0.1316790489355723  Rel. Test L2 Loss :  0.13085348784923553  Test L2 Loss :  0.19091200053691865  inv_L_scale:  [1.0, 1.0]
Epoch :  216  Time:  0.661  Rel. Train L2 Loss :  0.13183307932482827  Rel. Test L2 Loss :  0.13082401514053343  Test L2 Loss :  0.1905658197402954  inv_L_scale:  [1.0, 1.0]
Epoch :  217  Time:  0.662  Rel. Train L2 Loss :  0.13185920788182154  Rel. Test L2 Loss :  0.13099545747041702  Test L2 Loss :  0.1906173700094223  inv_L_scale:  [1.0, 1.0]
Epoch :  218  Time:  0.665  Rel. Train L2 Loss :  0.1316879692673683  Rel. Test L2 Loss :  0.1312880766391754  Test L2 Loss :  0.1911682540178299  inv_L_scale:  [1.0, 1.0]
Epoch :  219  Time:  0.662  Rel. Train L2 Loss :  0.1316048116154141  Rel. Test L2 Loss :  0.13017449170351028  Test L2 Loss :  0.1894668561220169  inv_L_scale:  [1.0, 1.0]
Epoch :  220  Time:  0.662  Rel. Train L2 Loss :  0.1312857555018531  Rel. Test L2 Loss :  0.12937997341156005  Test L2 Loss :  0.18882207095623016  inv_L_scale:  [1.0, 1.0]
Epoch :  221  Time:  0.662  Rel. Train L2 Loss :  0.13136270112461515  Rel. Test L2 Loss :  0.130931333899498  Test L2 Loss :  0.19104452013969422  inv_L_scale:  [1.0, 1.0]
Epoch :  222  Time:  0.662  Rel. Train L2 Loss :  0.1319478060801824  Rel. Test L2 Loss :  0.13146210581064224  Test L2 Loss :  0.19158533215522766  inv_L_scale:  [1.0, 1.0]
Epoch :  223  Time:  0.662  Rel. Train L2 Loss :  0.13136526637607152  Rel. Test L2 Loss :  0.1315196406841278  Test L2 Loss :  0.1913543736934662  inv_L_scale:  [1.0, 1.0]
Epoch :  224  Time:  0.661  Rel. Train L2 Loss :  0.13134933458434211  Rel. Test L2 Loss :  0.12987581193447112  Test L2 Loss :  0.1895449584722519  inv_L_scale:  [1.0, 1.0]
Epoch :  225  Time:  0.662  Rel. Train L2 Loss :  0.13103816436396704  Rel. Test L2 Loss :  0.12952465325593948  Test L2 Loss :  0.1892103111743927  inv_L_scale:  [1.0, 1.0]
Epoch :  226  Time:  0.661  Rel. Train L2 Loss :  0.13111231274074978  Rel. Test L2 Loss :  0.13086220920085906  Test L2 Loss :  0.19080537796020508  inv_L_scale:  [1.0, 1.0]
Epoch :  227  Time:  0.661  Rel. Train L2 Loss :  0.1313767538468043  Rel. Test L2 Loss :  0.1295919930934906  Test L2 Loss :  0.18870658338069915  inv_L_scale:  [1.0, 1.0]
Epoch :  228  Time:  0.661  Rel. Train L2 Loss :  0.13113284634219274  Rel. Test L2 Loss :  0.1302693286538124  Test L2 Loss :  0.190084525346756  inv_L_scale:  [1.0, 1.0]
Epoch :  229  Time:  0.662  Rel. Train L2 Loss :  0.1309845280647278  Rel. Test L2 Loss :  0.1297647500038147  Test L2 Loss :  0.18932556807994844  inv_L_scale:  [1.0, 1.0]
Epoch :  230  Time:  0.662  Rel. Train L2 Loss :  0.13089805483818054  Rel. Test L2 Loss :  0.1300339949131012  Test L2 Loss :  0.18983207106590272  inv_L_scale:  [1.0, 1.0]
Epoch :  231  Time:  0.662  Rel. Train L2 Loss :  0.13119003732999165  Rel. Test L2 Loss :  0.12982160806655885  Test L2 Loss :  0.18904112100601198  inv_L_scale:  [1.0, 1.0]
Epoch :  232  Time:  0.662  Rel. Train L2 Loss :  0.13136251946290334  Rel. Test L2 Loss :  0.12982690155506135  Test L2 Loss :  0.18895779252052308  inv_L_scale:  [1.0, 1.0]
Epoch :  233  Time:  0.662  Rel. Train L2 Loss :  0.13099208745691512  Rel. Test L2 Loss :  0.12911549478769302  Test L2 Loss :  0.18823371291160584  inv_L_scale:  [1.0, 1.0]
Epoch :  234  Time:  0.662  Rel. Train L2 Loss :  0.131087673107783  Rel. Test L2 Loss :  0.1299680095911026  Test L2 Loss :  0.18993327140808106  inv_L_scale:  [1.0, 1.0]
Epoch :  235  Time:  0.661  Rel. Train L2 Loss :  0.13097902244991727  Rel. Test L2 Loss :  0.1299478840827942  Test L2 Loss :  0.18933216035366057  inv_L_scale:  [1.0, 1.0]
Epoch :  236  Time:  0.661  Rel. Train L2 Loss :  0.13143863413068985  Rel. Test L2 Loss :  0.13046039938926696  Test L2 Loss :  0.18991711258888244  inv_L_scale:  [1.0, 1.0]
Epoch :  237  Time:  0.662  Rel. Train L2 Loss :  0.1311193641026815  Rel. Test L2 Loss :  0.13002274960279464  Test L2 Loss :  0.18941429734230042  inv_L_scale:  [1.0, 1.0]
Epoch :  238  Time:  0.662  Rel. Train L2 Loss :  0.13107168608241612  Rel. Test L2 Loss :  0.12967581450939178  Test L2 Loss :  0.1893429672718048  inv_L_scale:  [1.0, 1.0]
Epoch :  239  Time:  0.661  Rel. Train L2 Loss :  0.13100977626111773  Rel. Test L2 Loss :  0.12985371738672258  Test L2 Loss :  0.1894766318798065  inv_L_scale:  [1.0, 1.0]
Epoch :  240  Time:  0.661  Rel. Train L2 Loss :  0.13055922352605395  Rel. Test L2 Loss :  0.13063121795654298  Test L2 Loss :  0.1903737360239029  inv_L_scale:  [1.0, 1.0]
Epoch :  241  Time:  0.661  Rel. Train L2 Loss :  0.13052475174268086  Rel. Test L2 Loss :  0.13029738187789916  Test L2 Loss :  0.18988787829875947  inv_L_scale:  [1.0, 1.0]
Epoch :  242  Time:  0.662  Rel. Train L2 Loss :  0.1305996349122789  Rel. Test L2 Loss :  0.128172949552536  Test L2 Loss :  0.18711906373500825  inv_L_scale:  [1.0, 1.0]
Epoch :  243  Time:  0.661  Rel. Train L2 Loss :  0.13075386650032467  Rel. Test L2 Loss :  0.1284584391117096  Test L2 Loss :  0.18764372587203978  inv_L_scale:  [1.0, 1.0]
Epoch :  244  Time:  0.661  Rel. Train L2 Loss :  0.1302363744046953  Rel. Test L2 Loss :  0.12882467180490495  Test L2 Loss :  0.18785038888454436  inv_L_scale:  [1.0, 1.0]
Epoch :  245  Time:  0.663  Rel. Train L2 Loss :  0.13050974667072296  Rel. Test L2 Loss :  0.13006321251392364  Test L2 Loss :  0.18992578506469726  inv_L_scale:  [1.0, 1.0]
Epoch :  246  Time:  0.663  Rel. Train L2 Loss :  0.13033456981182098  Rel. Test L2 Loss :  0.12875700175762175  Test L2 Loss :  0.1878058969974518  inv_L_scale:  [1.0, 1.0]
Epoch :  247  Time:  0.662  Rel. Train L2 Loss :  0.1302288481261995  Rel. Test L2 Loss :  0.1309366488456726  Test L2 Loss :  0.19133668661117553  inv_L_scale:  [1.0, 1.0]
Epoch :  248  Time:  0.662  Rel. Train L2 Loss :  0.13039557596047718  Rel. Test L2 Loss :  0.13004431545734405  Test L2 Loss :  0.1898715627193451  inv_L_scale:  [1.0, 1.0]
Epoch :  249  Time:  0.662  Rel. Train L2 Loss :  0.13031764162911308  Rel. Test L2 Loss :  0.1293698474764824  Test L2 Loss :  0.18887128472328185  inv_L_scale:  [1.0, 1.0]
Epoch :  250  Time:  0.662  Rel. Train L2 Loss :  0.13032633139027489  Rel. Test L2 Loss :  0.12868991136550903  Test L2 Loss :  0.18781981706619263  inv_L_scale:  [1.0, 1.0]
Epoch :  251  Time:  0.662  Rel. Train L2 Loss :  0.1302623909049564  Rel. Test L2 Loss :  0.1306343361735344  Test L2 Loss :  0.19029592633247375  inv_L_scale:  [1.0, 1.0]
Epoch :  252  Time:  0.662  Rel. Train L2 Loss :  0.13073480241828495  Rel. Test L2 Loss :  0.12977231293916702  Test L2 Loss :  0.1892215418815613  inv_L_scale:  [1.0, 1.0]
Epoch :  253  Time:  0.662  Rel. Train L2 Loss :  0.13032358500692579  Rel. Test L2 Loss :  0.12900193750858308  Test L2 Loss :  0.18788112699985504  inv_L_scale:  [1.0, 1.0]
Epoch :  254  Time:  0.662  Rel. Train L2 Loss :  0.1304250360197491  Rel. Test L2 Loss :  0.12910493284463884  Test L2 Loss :  0.18818654477596283  inv_L_scale:  [1.0, 1.0]
Epoch :  255  Time:  0.662  Rel. Train L2 Loss :  0.13044198056062062  Rel. Test L2 Loss :  0.12841931432485582  Test L2 Loss :  0.1873626458644867  inv_L_scale:  [1.0, 1.0]
Epoch :  256  Time:  0.662  Rel. Train L2 Loss :  0.13025120986832514  Rel. Test L2 Loss :  0.13047051399946213  Test L2 Loss :  0.1898467379808426  inv_L_scale:  [1.0, 1.0]
Epoch :  257  Time:  0.662  Rel. Train L2 Loss :  0.13045809070269268  Rel. Test L2 Loss :  0.13090655446052551  Test L2 Loss :  0.1905185306072235  inv_L_scale:  [1.0, 1.0]
Epoch :  258  Time:  0.664  Rel. Train L2 Loss :  0.12981086876657275  Rel. Test L2 Loss :  0.1301431292295456  Test L2 Loss :  0.18984007894992827  inv_L_scale:  [1.0, 1.0]
Epoch :  259  Time:  0.663  Rel. Train L2 Loss :  0.13015261703067355  Rel. Test L2 Loss :  0.12911381989717483  Test L2 Loss :  0.18817612171173095  inv_L_scale:  [1.0, 1.0]
Epoch :  260  Time:  0.662  Rel. Train L2 Loss :  0.1298661282989714  Rel. Test L2 Loss :  0.1287873086333275  Test L2 Loss :  0.18800592064857483  inv_L_scale:  [1.0, 1.0]
Epoch :  261  Time:  0.662  Rel. Train L2 Loss :  0.13017373628086515  Rel. Test L2 Loss :  0.1287900584936142  Test L2 Loss :  0.18819344460964202  inv_L_scale:  [1.0, 1.0]
Epoch :  262  Time:  0.662  Rel. Train L2 Loss :  0.13007844219605127  Rel. Test L2 Loss :  0.1297853684425354  Test L2 Loss :  0.18906298875808716  inv_L_scale:  [1.0, 1.0]
Epoch :  263  Time:  0.663  Rel. Train L2 Loss :  0.12970081898901198  Rel. Test L2 Loss :  0.1295175951719284  Test L2 Loss :  0.18870324850082398  inv_L_scale:  [1.0, 1.0]
Epoch :  264  Time:  0.662  Rel. Train L2 Loss :  0.129697751071718  Rel. Test L2 Loss :  0.12981235802173616  Test L2 Loss :  0.18929319500923156  inv_L_scale:  [1.0, 1.0]
Epoch :  265  Time:  0.662  Rel. Train L2 Loss :  0.12971278813150194  Rel. Test L2 Loss :  0.12845432817935942  Test L2 Loss :  0.18758237540721892  inv_L_scale:  [1.0, 1.0]
Epoch :  266  Time:  0.662  Rel. Train L2 Loss :  0.1295623920361201  Rel. Test L2 Loss :  0.1292976850271225  Test L2 Loss :  0.18842190980911255  inv_L_scale:  [1.0, 1.0]
Epoch :  267  Time:  0.663  Rel. Train L2 Loss :  0.12991455518537098  Rel. Test L2 Loss :  0.12919596314430237  Test L2 Loss :  0.18838778376579285  inv_L_scale:  [1.0, 1.0]
Epoch :  268  Time:  0.662  Rel. Train L2 Loss :  0.12959500597582924  Rel. Test L2 Loss :  0.12826986253261566  Test L2 Loss :  0.18720112144947051  inv_L_scale:  [1.0, 1.0]
Epoch :  269  Time:  0.662  Rel. Train L2 Loss :  0.12958390603462855  Rel. Test L2 Loss :  0.1287924602627754  Test L2 Loss :  0.1879130607843399  inv_L_scale:  [1.0, 1.0]
Epoch :  270  Time:  0.662  Rel. Train L2 Loss :  0.12960012171003554  Rel. Test L2 Loss :  0.12971936911344528  Test L2 Loss :  0.1890276837348938  inv_L_scale:  [1.0, 1.0]
Epoch :  271  Time:  0.663  Rel. Train L2 Loss :  0.13006886104742685  Rel. Test L2 Loss :  0.1308296126127243  Test L2 Loss :  0.19059313893318175  inv_L_scale:  [1.0, 1.0]
Epoch :  272  Time:  0.662  Rel. Train L2 Loss :  0.12993262347247866  Rel. Test L2 Loss :  0.12877440065145493  Test L2 Loss :  0.18794870674610137  inv_L_scale:  [1.0, 1.0]
Epoch :  273  Time:  0.662  Rel. Train L2 Loss :  0.1292384566201104  Rel. Test L2 Loss :  0.12864871442317963  Test L2 Loss :  0.1873883455991745  inv_L_scale:  [1.0, 1.0]
Epoch :  274  Time:  0.662  Rel. Train L2 Loss :  0.12946098751491972  Rel. Test L2 Loss :  0.12897352010011673  Test L2 Loss :  0.18823886036872864  inv_L_scale:  [1.0, 1.0]
Epoch :  275  Time:  0.662  Rel. Train L2 Loss :  0.12985711703697841  Rel. Test L2 Loss :  0.12870373606681823  Test L2 Loss :  0.1878250402212143  inv_L_scale:  [1.0, 1.0]
Epoch :  276  Time:  0.662  Rel. Train L2 Loss :  0.12910676214430067  Rel. Test L2 Loss :  0.1286342304944992  Test L2 Loss :  0.1880202543735504  inv_L_scale:  [1.0, 1.0]
Epoch :  277  Time:  0.662  Rel. Train L2 Loss :  0.12934719138675266  Rel. Test L2 Loss :  0.12980347871780396  Test L2 Loss :  0.1896352005004883  inv_L_scale:  [1.0, 1.0]
Epoch :  278  Time:  0.662  Rel. Train L2 Loss :  0.1293690252966351  Rel. Test L2 Loss :  0.12917255610227585  Test L2 Loss :  0.18822956442832947  inv_L_scale:  [1.0, 1.0]
Epoch :  279  Time:  0.662  Rel. Train L2 Loss :  0.12911045173803964  Rel. Test L2 Loss :  0.12866662859916686  Test L2 Loss :  0.18797428369522096  inv_L_scale:  [1.0, 1.0]
Epoch :  280  Time:  0.662  Rel. Train L2 Loss :  0.12935071302784815  Rel. Test L2 Loss :  0.1280159232020378  Test L2 Loss :  0.1871367847919464  inv_L_scale:  [1.0, 1.0]
Epoch :  281  Time:  0.664  Rel. Train L2 Loss :  0.1293066629436281  Rel. Test L2 Loss :  0.128271484375  Test L2 Loss :  0.18725446105003357  inv_L_scale:  [1.0, 1.0]
Epoch :  282  Time:  0.665  Rel. Train L2 Loss :  0.12927861101097532  Rel. Test L2 Loss :  0.12889319598674776  Test L2 Loss :  0.1878207331895828  inv_L_scale:  [1.0, 1.0]
Epoch :  283  Time:  0.663  Rel. Train L2 Loss :  0.12929685221778023  Rel. Test L2 Loss :  0.1286720559000969  Test L2 Loss :  0.1874767315387726  inv_L_scale:  [1.0, 1.0]
Epoch :  284  Time:  0.663  Rel. Train L2 Loss :  0.12907668736245898  Rel. Test L2 Loss :  0.12785464823246  Test L2 Loss :  0.1868564146757126  inv_L_scale:  [1.0, 1.0]
Epoch :  285  Time:  0.662  Rel. Train L2 Loss :  0.129188704556889  Rel. Test L2 Loss :  0.12911529332399369  Test L2 Loss :  0.18853491187095642  inv_L_scale:  [1.0, 1.0]
Epoch :  286  Time:  0.662  Rel. Train L2 Loss :  0.1293242816792594  Rel. Test L2 Loss :  0.12811675578355788  Test L2 Loss :  0.1870395165681839  inv_L_scale:  [1.0, 1.0]
Epoch :  287  Time:  0.662  Rel. Train L2 Loss :  0.1290137269761827  Rel. Test L2 Loss :  0.12866753995418548  Test L2 Loss :  0.1875299745798111  inv_L_scale:  [1.0, 1.0]
Epoch :  288  Time:  0.662  Rel. Train L2 Loss :  0.12925560540623135  Rel. Test L2 Loss :  0.12832748681306838  Test L2 Loss :  0.18711536526679992  inv_L_scale:  [1.0, 1.0]
Epoch :  289  Time:  0.662  Rel. Train L2 Loss :  0.12923125750488706  Rel. Test L2 Loss :  0.12846149623394013  Test L2 Loss :  0.18731731176376343  inv_L_scale:  [1.0, 1.0]
Epoch :  290  Time:  0.662  Rel. Train L2 Loss :  0.12884225328763327  Rel. Test L2 Loss :  0.128323555290699  Test L2 Loss :  0.18727443635463714  inv_L_scale:  [1.0, 1.0]
Epoch :  291  Time:  0.663  Rel. Train L2 Loss :  0.12887542532549964  Rel. Test L2 Loss :  0.12899434566497803  Test L2 Loss :  0.1883976948261261  inv_L_scale:  [1.0, 1.0]
Epoch :  292  Time:  0.662  Rel. Train L2 Loss :  0.12899820347627003  Rel. Test L2 Loss :  0.12857839226722717  Test L2 Loss :  0.1875033813714981  inv_L_scale:  [1.0, 1.0]
Epoch :  293  Time:  0.662  Rel. Train L2 Loss :  0.12899369928571913  Rel. Test L2 Loss :  0.1283169159293175  Test L2 Loss :  0.1871090829372406  inv_L_scale:  [1.0, 1.0]
Epoch :  294  Time:  0.662  Rel. Train L2 Loss :  0.1288060767783059  Rel. Test L2 Loss :  0.1283627539873123  Test L2 Loss :  0.18726818799972533  inv_L_scale:  [1.0, 1.0]
Epoch :  295  Time:  0.662  Rel. Train L2 Loss :  0.12886621163951026  Rel. Test L2 Loss :  0.1283080345392227  Test L2 Loss :  0.18732647478580475  inv_L_scale:  [1.0, 1.0]
Epoch :  296  Time:  0.662  Rel. Train L2 Loss :  0.12886731869644588  Rel. Test L2 Loss :  0.128786780834198  Test L2 Loss :  0.1875914466381073  inv_L_scale:  [1.0, 1.0]
Epoch :  297  Time:  0.662  Rel. Train L2 Loss :  0.12898814943101672  Rel. Test L2 Loss :  0.12863893061876297  Test L2 Loss :  0.18790911197662352  inv_L_scale:  [1.0, 1.0]
Epoch :  298  Time:  0.662  Rel. Train L2 Loss :  0.12876802040470972  Rel. Test L2 Loss :  0.12904665023088455  Test L2 Loss :  0.1880044847726822  inv_L_scale:  [1.0, 1.0]
Epoch :  299  Time:  0.662  Rel. Train L2 Loss :  0.12870690084165998  Rel. Test L2 Loss :  0.1284495198726654  Test L2 Loss :  0.18743365585803987  inv_L_scale:  [1.0, 1.0]
Epoch :  300  Time:  0.665  Rel. Train L2 Loss :  0.1285443440410826  Rel. Test L2 Loss :  0.12875419944524766  Test L2 Loss :  0.18770147740840912  inv_L_scale:  [1.0, 1.0]
Epoch :  301  Time:  0.663  Rel. Train L2 Loss :  0.12891743421554566  Rel. Test L2 Loss :  0.12858117401599883  Test L2 Loss :  0.1875537133216858  inv_L_scale:  [1.0, 1.0]
Epoch :  302  Time:  0.662  Rel. Train L2 Loss :  0.12862528565857145  Rel. Test L2 Loss :  0.1279704439640045  Test L2 Loss :  0.18648872375488282  inv_L_scale:  [1.0, 1.0]
Epoch :  303  Time:  0.663  Rel. Train L2 Loss :  0.12850268099043105  Rel. Test L2 Loss :  0.12876987278461458  Test L2 Loss :  0.1876677966117859  inv_L_scale:  [1.0, 1.0]
Epoch :  304  Time:  0.662  Rel. Train L2 Loss :  0.12849502722422282  Rel. Test L2 Loss :  0.12810935765504838  Test L2 Loss :  0.1871118175983429  inv_L_scale:  [1.0, 1.0]
Epoch :  305  Time:  0.662  Rel. Train L2 Loss :  0.128913177980317  Rel. Test L2 Loss :  0.13103410720825195  Test L2 Loss :  0.19057326912879943  inv_L_scale:  [1.0, 1.0]
Epoch :  306  Time:  0.662  Rel. Train L2 Loss :  0.12864747537506951  Rel. Test L2 Loss :  0.12761885911226273  Test L2 Loss :  0.18623338460922242  inv_L_scale:  [1.0, 1.0]
Epoch :  307  Time:  0.662  Rel. Train L2 Loss :  0.1281909669770135  Rel. Test L2 Loss :  0.12796777486801147  Test L2 Loss :  0.18667801558971406  inv_L_scale:  [1.0, 1.0]
Epoch :  308  Time:  0.663  Rel. Train L2 Loss :  0.1282681295606825  Rel. Test L2 Loss :  0.12884658634662627  Test L2 Loss :  0.18773466110229492  inv_L_scale:  [1.0, 1.0]
Epoch :  309  Time:  0.662  Rel. Train L2 Loss :  0.12824060850673252  Rel. Test L2 Loss :  0.12765276670455933  Test L2 Loss :  0.18613801419734954  inv_L_scale:  [1.0, 1.0]
Epoch :  310  Time:  0.662  Rel. Train L2 Loss :  0.1282589249478446  Rel. Test L2 Loss :  0.12805667221546174  Test L2 Loss :  0.1870489263534546  inv_L_scale:  [1.0, 1.0]
Epoch :  311  Time:  0.662  Rel. Train L2 Loss :  0.12833752850691477  Rel. Test L2 Loss :  0.12779809832572936  Test L2 Loss :  0.1863640522956848  inv_L_scale:  [1.0, 1.0]
Epoch :  312  Time:  0.662  Rel. Train L2 Loss :  0.1282578428917461  Rel. Test L2 Loss :  0.12716682106256486  Test L2 Loss :  0.18555715382099153  inv_L_scale:  [1.0, 1.0]
Epoch :  313  Time:  0.662  Rel. Train L2 Loss :  0.12810161378648546  Rel. Test L2 Loss :  0.12799402236938476  Test L2 Loss :  0.18640408992767335  inv_L_scale:  [1.0, 1.0]
Epoch :  314  Time:  0.662  Rel. Train L2 Loss :  0.12827333311239877  Rel. Test L2 Loss :  0.12802301287651063  Test L2 Loss :  0.1867487895488739  inv_L_scale:  [1.0, 1.0]
Epoch :  315  Time:  0.662  Rel. Train L2 Loss :  0.12810944729381138  Rel. Test L2 Loss :  0.12773376494646071  Test L2 Loss :  0.18642453074455262  inv_L_scale:  [1.0, 1.0]
Epoch :  316  Time:  0.662  Rel. Train L2 Loss :  0.12817518419689602  Rel. Test L2 Loss :  0.1279618501663208  Test L2 Loss :  0.18668190479278565  inv_L_scale:  [1.0, 1.0]
Epoch :  317  Time:  0.662  Rel. Train L2 Loss :  0.12803798105981615  Rel. Test L2 Loss :  0.12822248697280883  Test L2 Loss :  0.1867730176448822  inv_L_scale:  [1.0, 1.0]
Epoch :  318  Time:  0.663  Rel. Train L2 Loss :  0.12806968013445535  Rel. Test L2 Loss :  0.12852885246276854  Test L2 Loss :  0.18745182871818541  inv_L_scale:  [1.0, 1.0]
Epoch :  319  Time:  0.662  Rel. Train L2 Loss :  0.12811853614118365  Rel. Test L2 Loss :  0.12742273449897767  Test L2 Loss :  0.1859791123867035  inv_L_scale:  [1.0, 1.0]
Epoch :  320  Time:  0.662  Rel. Train L2 Loss :  0.12796523908774057  Rel. Test L2 Loss :  0.1276439118385315  Test L2 Loss :  0.1861688596010208  inv_L_scale:  [1.0, 1.0]
Epoch :  321  Time:  0.662  Rel. Train L2 Loss :  0.1279075066248576  Rel. Test L2 Loss :  0.12789623081684112  Test L2 Loss :  0.18674295663833618  inv_L_scale:  [1.0, 1.0]
Epoch :  322  Time:  0.662  Rel. Train L2 Loss :  0.12780118094550239  Rel. Test L2 Loss :  0.12790366858243943  Test L2 Loss :  0.18665298461914062  inv_L_scale:  [1.0, 1.0]
Epoch :  323  Time:  0.662  Rel. Train L2 Loss :  0.12810634162690904  Rel. Test L2 Loss :  0.12753294467926024  Test L2 Loss :  0.1862332344055176  inv_L_scale:  [1.0, 1.0]
Epoch :  324  Time:  0.662  Rel. Train L2 Loss :  0.12802986174821854  Rel. Test L2 Loss :  0.12805529654026032  Test L2 Loss :  0.18696005940437316  inv_L_scale:  [1.0, 1.0]
Epoch :  325  Time:  0.662  Rel. Train L2 Loss :  0.12785450167126125  Rel. Test L2 Loss :  0.1273992609977722  Test L2 Loss :  0.1859251356124878  inv_L_scale:  [1.0, 1.0]
Epoch :  326  Time:  0.662  Rel. Train L2 Loss :  0.12767287545733982  Rel. Test L2 Loss :  0.12765346765518187  Test L2 Loss :  0.1864561802148819  inv_L_scale:  [1.0, 1.0]
Epoch :  327  Time:  0.662  Rel. Train L2 Loss :  0.12769543442461226  Rel. Test L2 Loss :  0.1274959471821785  Test L2 Loss :  0.18581140518188477  inv_L_scale:  [1.0, 1.0]
Epoch :  328  Time:  0.663  Rel. Train L2 Loss :  0.1277507487932841  Rel. Test L2 Loss :  0.12716851145029068  Test L2 Loss :  0.18586997389793397  inv_L_scale:  [1.0, 1.0]
Epoch :  329  Time:  0.662  Rel. Train L2 Loss :  0.12776916013823617  Rel. Test L2 Loss :  0.12740459084510802  Test L2 Loss :  0.1860378009080887  inv_L_scale:  [1.0, 1.0]
Epoch :  330  Time:  0.662  Rel. Train L2 Loss :  0.12774401618374717  Rel. Test L2 Loss :  0.1275571644306183  Test L2 Loss :  0.18603040814399718  inv_L_scale:  [1.0, 1.0]
Epoch :  331  Time:  0.662  Rel. Train L2 Loss :  0.12756120953294967  Rel. Test L2 Loss :  0.12764426052570343  Test L2 Loss :  0.18634807229042052  inv_L_scale:  [1.0, 1.0]
Epoch :  332  Time:  0.662  Rel. Train L2 Loss :  0.12754342370563082  Rel. Test L2 Loss :  0.1274525171518326  Test L2 Loss :  0.18590062260627746  inv_L_scale:  [1.0, 1.0]
Epoch :  333  Time:  0.662  Rel. Train L2 Loss :  0.12754181461201775  Rel. Test L2 Loss :  0.12709499508142472  Test L2 Loss :  0.1855736517906189  inv_L_scale:  [1.0, 1.0]
Epoch :  334  Time:  0.662  Rel. Train L2 Loss :  0.12763630708058676  Rel. Test L2 Loss :  0.12756121546030044  Test L2 Loss :  0.1860734760761261  inv_L_scale:  [1.0, 1.0]
Epoch :  335  Time:  0.664  Rel. Train L2 Loss :  0.12763160119454067  Rel. Test L2 Loss :  0.12723881423473357  Test L2 Loss :  0.18578346014022828  inv_L_scale:  [1.0, 1.0]
Epoch :  336  Time:  0.662  Rel. Train L2 Loss :  0.1275339549117618  Rel. Test L2 Loss :  0.12777913689613343  Test L2 Loss :  0.18640714049339294  inv_L_scale:  [1.0, 1.0]
Epoch :  337  Time:  0.662  Rel. Train L2 Loss :  0.1273358271519343  Rel. Test L2 Loss :  0.12730526328086852  Test L2 Loss :  0.18586784839630127  inv_L_scale:  [1.0, 1.0]
Epoch :  338  Time:  0.662  Rel. Train L2 Loss :  0.1273940955930286  Rel. Test L2 Loss :  0.12740522503852844  Test L2 Loss :  0.18620279908180237  inv_L_scale:  [1.0, 1.0]
Epoch :  339  Time:  0.662  Rel. Train L2 Loss :  0.12727018932501474  Rel. Test L2 Loss :  0.12711727261543274  Test L2 Loss :  0.18574734926223754  inv_L_scale:  [1.0, 1.0]
Epoch :  340  Time:  0.662  Rel. Train L2 Loss :  0.12734799143340853  Rel. Test L2 Loss :  0.12658443450927734  Test L2 Loss :  0.185018550157547  inv_L_scale:  [1.0, 1.0]
Epoch :  341  Time:  0.662  Rel. Train L2 Loss :  0.12738377789656322  Rel. Test L2 Loss :  0.1275279214978218  Test L2 Loss :  0.18608620882034302  inv_L_scale:  [1.0, 1.0]
Epoch :  342  Time:  0.662  Rel. Train L2 Loss :  0.12750784701771206  Rel. Test L2 Loss :  0.12717755496501923  Test L2 Loss :  0.1857809019088745  inv_L_scale:  [1.0, 1.0]
Epoch :  343  Time:  0.662  Rel. Train L2 Loss :  0.12752284990416632  Rel. Test L2 Loss :  0.12694088637828826  Test L2 Loss :  0.18529349505901338  inv_L_scale:  [1.0, 1.0]
Epoch :  344  Time:  0.662  Rel. Train L2 Loss :  0.12737844970491197  Rel. Test L2 Loss :  0.12714249193668364  Test L2 Loss :  0.1856206488609314  inv_L_scale:  [1.0, 1.0]
Epoch :  345  Time:  0.662  Rel. Train L2 Loss :  0.12707301083538267  Rel. Test L2 Loss :  0.12676417887210845  Test L2 Loss :  0.1851377332210541  inv_L_scale:  [1.0, 1.0]
Epoch :  346  Time:  0.662  Rel. Train L2 Loss :  0.12714209225442674  Rel. Test L2 Loss :  0.12694102704524993  Test L2 Loss :  0.18542057454586028  inv_L_scale:  [1.0, 1.0]
Epoch :  347  Time:  0.662  Rel. Train L2 Loss :  0.12731288115183512  Rel. Test L2 Loss :  0.12732318729162218  Test L2 Loss :  0.1857961571216583  inv_L_scale:  [1.0, 1.0]
Epoch :  348  Time:  0.662  Rel. Train L2 Loss :  0.12714908275339337  Rel. Test L2 Loss :  0.1275636747479439  Test L2 Loss :  0.18596848368644714  inv_L_scale:  [1.0, 1.0]
Epoch :  349  Time:  0.662  Rel. Train L2 Loss :  0.12715714010927412  Rel. Test L2 Loss :  0.1272537413239479  Test L2 Loss :  0.18579035520553588  inv_L_scale:  [1.0, 1.0]
Epoch :  350  Time:  0.662  Rel. Train L2 Loss :  0.12705511897802352  Rel. Test L2 Loss :  0.12703337013721466  Test L2 Loss :  0.18543556213378906  inv_L_scale:  [1.0, 1.0]
Epoch :  351  Time:  0.663  Rel. Train L2 Loss :  0.1270493123266432  Rel. Test L2 Loss :  0.1274411192536354  Test L2 Loss :  0.1857764506340027  inv_L_scale:  [1.0, 1.0]
Epoch :  352  Time:  0.662  Rel. Train L2 Loss :  0.12708278550042046  Rel. Test L2 Loss :  0.12751396834850312  Test L2 Loss :  0.18602705121040344  inv_L_scale:  [1.0, 1.0]
Epoch :  353  Time:  0.662  Rel. Train L2 Loss :  0.12706075621975793  Rel. Test L2 Loss :  0.12675092577934266  Test L2 Loss :  0.18529439091682434  inv_L_scale:  [1.0, 1.0]
Epoch :  354  Time:  0.662  Rel. Train L2 Loss :  0.12687595135635799  Rel. Test L2 Loss :  0.12714762836694718  Test L2 Loss :  0.1854570710659027  inv_L_scale:  [1.0, 1.0]
Epoch :  355  Time:  0.662  Rel. Train L2 Loss :  0.12706625435087415  Rel. Test L2 Loss :  0.12712612628936767  Test L2 Loss :  0.18540539383888244  inv_L_scale:  [1.0, 1.0]
Epoch :  356  Time:  0.662  Rel. Train L2 Loss :  0.12696966316964892  Rel. Test L2 Loss :  0.12725718855857848  Test L2 Loss :  0.1856513214111328  inv_L_scale:  [1.0, 1.0]
Epoch :  357  Time:  0.662  Rel. Train L2 Loss :  0.12715300394429102  Rel. Test L2 Loss :  0.12755744874477387  Test L2 Loss :  0.1860128480195999  inv_L_scale:  [1.0, 1.0]
Epoch :  358  Time:  0.663  Rel. Train L2 Loss :  0.1270085409283638  Rel. Test L2 Loss :  0.127151899933815  Test L2 Loss :  0.18553039252758027  inv_L_scale:  [1.0, 1.0]
Epoch :  359  Time:  0.66  Rel. Train L2 Loss :  0.12683562682734595  Rel. Test L2 Loss :  0.1268358615040779  Test L2 Loss :  0.18517747163772583  inv_L_scale:  [1.0, 1.0]
Epoch :  360  Time:  0.66  Rel. Train L2 Loss :  0.12668602218230565  Rel. Test L2 Loss :  0.12685225129127503  Test L2 Loss :  0.18512725353240966  inv_L_scale:  [1.0, 1.0]
Epoch :  361  Time:  0.66  Rel. Train L2 Loss :  0.126825449930297  Rel. Test L2 Loss :  0.12710852921009064  Test L2 Loss :  0.1855465817451477  inv_L_scale:  [1.0, 1.0]
Epoch :  362  Time:  0.66  Rel. Train L2 Loss :  0.1268108222219679  Rel. Test L2 Loss :  0.1269276463985443  Test L2 Loss :  0.18532583355903626  inv_L_scale:  [1.0, 1.0]
Epoch :  363  Time:  0.66  Rel. Train L2 Loss :  0.12678611152701907  Rel. Test L2 Loss :  0.1274532347917557  Test L2 Loss :  0.18598090171813964  inv_L_scale:  [1.0, 1.0]
Epoch :  364  Time:  0.66  Rel. Train L2 Loss :  0.126675692598025  Rel. Test L2 Loss :  0.12699031710624695  Test L2 Loss :  0.18542810499668122  inv_L_scale:  [1.0, 1.0]
Epoch :  365  Time:  0.66  Rel. Train L2 Loss :  0.1267103502485487  Rel. Test L2 Loss :  0.12684398412704467  Test L2 Loss :  0.18507448017597197  inv_L_scale:  [1.0, 1.0]
Epoch :  366  Time:  0.66  Rel. Train L2 Loss :  0.12676958719889322  Rel. Test L2 Loss :  0.1273748505115509  Test L2 Loss :  0.18583841025829315  inv_L_scale:  [1.0, 1.0]
Epoch :  367  Time:  0.66  Rel. Train L2 Loss :  0.12662474552790323  Rel. Test L2 Loss :  0.12695970505475998  Test L2 Loss :  0.18526515185832979  inv_L_scale:  [1.0, 1.0]
Epoch :  368  Time:  0.66  Rel. Train L2 Loss :  0.1266070450014538  Rel. Test L2 Loss :  0.12694715470075607  Test L2 Loss :  0.18521786332130433  inv_L_scale:  [1.0, 1.0]
Epoch :  369  Time:  0.66  Rel. Train L2 Loss :  0.12650603201654223  Rel. Test L2 Loss :  0.12687403261661528  Test L2 Loss :  0.18524489283561707  inv_L_scale:  [1.0, 1.0]
Epoch :  370  Time:  0.661  Rel. Train L2 Loss :  0.12656859238942464  Rel. Test L2 Loss :  0.12660851180553437  Test L2 Loss :  0.1848229932785034  inv_L_scale:  [1.0, 1.0]
Epoch :  371  Time:  0.664  Rel. Train L2 Loss :  0.1266144092215432  Rel. Test L2 Loss :  0.12688467800617217  Test L2 Loss :  0.18515254139900209  inv_L_scale:  [1.0, 1.0]
Epoch :  372  Time:  0.661  Rel. Train L2 Loss :  0.12662606716156005  Rel. Test L2 Loss :  0.1267431503534317  Test L2 Loss :  0.18515752911567687  inv_L_scale:  [1.0, 1.0]
Epoch :  373  Time:  0.661  Rel. Train L2 Loss :  0.12660772817002403  Rel. Test L2 Loss :  0.12669775426387786  Test L2 Loss :  0.18505578815937043  inv_L_scale:  [1.0, 1.0]
Epoch :  374  Time:  0.661  Rel. Train L2 Loss :  0.12655652662118275  Rel. Test L2 Loss :  0.1266994884610176  Test L2 Loss :  0.18493642210960387  inv_L_scale:  [1.0, 1.0]
Epoch :  375  Time:  0.661  Rel. Train L2 Loss :  0.1263353846470515  Rel. Test L2 Loss :  0.12688472896814346  Test L2 Loss :  0.18513381361961365  inv_L_scale:  [1.0, 1.0]
Epoch :  376  Time:  0.661  Rel. Train L2 Loss :  0.12640057825379902  Rel. Test L2 Loss :  0.12673551946878434  Test L2 Loss :  0.18499154448509217  inv_L_scale:  [1.0, 1.0]
Epoch :  377  Time:  0.661  Rel. Train L2 Loss :  0.1264319803317388  Rel. Test L2 Loss :  0.1266209203004837  Test L2 Loss :  0.1849547392129898  inv_L_scale:  [1.0, 1.0]
Epoch :  378  Time:  0.661  Rel. Train L2 Loss :  0.12639759825335609  Rel. Test L2 Loss :  0.12693827211856842  Test L2 Loss :  0.1853123426437378  inv_L_scale:  [1.0, 1.0]
Epoch :  379  Time:  0.66  Rel. Train L2 Loss :  0.12629192213217416  Rel. Test L2 Loss :  0.12677909404039384  Test L2 Loss :  0.18508832454681395  inv_L_scale:  [1.0, 1.0]
Epoch :  380  Time:  0.661  Rel. Train L2 Loss :  0.12633498291174572  Rel. Test L2 Loss :  0.12639520585536956  Test L2 Loss :  0.18459055423736573  inv_L_scale:  [1.0, 1.0]
Epoch :  381  Time:  0.661  Rel. Train L2 Loss :  0.12630898700820076  Rel. Test L2 Loss :  0.12681915014982223  Test L2 Loss :  0.18514963626861572  inv_L_scale:  [1.0, 1.0]
Epoch :  382  Time:  0.661  Rel. Train L2 Loss :  0.1261876298321618  Rel. Test L2 Loss :  0.12711234211921693  Test L2 Loss :  0.18543688654899598  inv_L_scale:  [1.0, 1.0]
Epoch :  383  Time:  0.661  Rel. Train L2 Loss :  0.12631259275807274  Rel. Test L2 Loss :  0.12640596628189088  Test L2 Loss :  0.18456849753856658  inv_L_scale:  [1.0, 1.0]
Epoch :  384  Time:  0.661  Rel. Train L2 Loss :  0.12634644899103376  Rel. Test L2 Loss :  0.12636231899261474  Test L2 Loss :  0.18456327438354492  inv_L_scale:  [1.0, 1.0]
Epoch :  385  Time:  0.66  Rel. Train L2 Loss :  0.1261863312125206  Rel. Test L2 Loss :  0.1269414421916008  Test L2 Loss :  0.18548232138156892  inv_L_scale:  [1.0, 1.0]
Epoch :  386  Time:  0.661  Rel. Train L2 Loss :  0.12612307257122463  Rel. Test L2 Loss :  0.12683334171772004  Test L2 Loss :  0.18502039551734925  inv_L_scale:  [1.0, 1.0]
Epoch :  387  Time:  0.661  Rel. Train L2 Loss :  0.12615464866161347  Rel. Test L2 Loss :  0.1265805581212044  Test L2 Loss :  0.18473939776420592  inv_L_scale:  [1.0, 1.0]
Epoch :  388  Time:  0.661  Rel. Train L2 Loss :  0.12607991834481558  Rel. Test L2 Loss :  0.1268031641840935  Test L2 Loss :  0.18497483372688295  inv_L_scale:  [1.0, 1.0]
Epoch :  389  Time:  0.66  Rel. Train L2 Loss :  0.1260989625255267  Rel. Test L2 Loss :  0.12652979224920272  Test L2 Loss :  0.18477731347084045  inv_L_scale:  [1.0, 1.0]
Epoch :  390  Time:  0.661  Rel. Train L2 Loss :  0.12605543593565624  Rel. Test L2 Loss :  0.12643328368663787  Test L2 Loss :  0.18473145246505737  inv_L_scale:  [1.0, 1.0]
Epoch :  391  Time:  0.661  Rel. Train L2 Loss :  0.12602756824758318  Rel. Test L2 Loss :  0.12658524572849272  Test L2 Loss :  0.184858740568161  inv_L_scale:  [1.0, 1.0]
Epoch :  392  Time:  0.66  Rel. Train L2 Loss :  0.12602063688966963  Rel. Test L2 Loss :  0.1266871726512909  Test L2 Loss :  0.18494455754756928  inv_L_scale:  [1.0, 1.0]
Epoch :  393  Time:  0.661  Rel. Train L2 Loss :  0.12595876620875465  Rel. Test L2 Loss :  0.1267004856467247  Test L2 Loss :  0.18500862240791321  inv_L_scale:  [1.0, 1.0]
Epoch :  394  Time:  0.661  Rel. Train L2 Loss :  0.1260068592760298  Rel. Test L2 Loss :  0.1266636610031128  Test L2 Loss :  0.1847994804382324  inv_L_scale:  [1.0, 1.0]
Epoch :  395  Time:  0.661  Rel. Train L2 Loss :  0.12587613178624046  Rel. Test L2 Loss :  0.12659797370433806  Test L2 Loss :  0.18489150524139406  inv_L_scale:  [1.0, 1.0]
Epoch :  396  Time:  0.661  Rel. Train L2 Loss :  0.12586247477266524  Rel. Test L2 Loss :  0.12702843099832534  Test L2 Loss :  0.18520551919937134  inv_L_scale:  [1.0, 1.0]
Epoch :  397  Time:  0.661  Rel. Train L2 Loss :  0.12586705803871154  Rel. Test L2 Loss :  0.1265826082229614  Test L2 Loss :  0.18471055567264558  inv_L_scale:  [1.0, 1.0]
Epoch :  398  Time:  0.661  Rel. Train L2 Loss :  0.12581907762421501  Rel. Test L2 Loss :  0.12658598721027375  Test L2 Loss :  0.1847984164953232  inv_L_scale:  [1.0, 1.0]
Epoch :  399  Time:  0.661  Rel. Train L2 Loss :  0.12587873346275755  Rel. Test L2 Loss :  0.12654308140277862  Test L2 Loss :  0.18470686674118042  inv_L_scale:  [1.0, 1.0]
Epoch :  400  Time:  0.663  Rel. Train L2 Loss :  0.1258355760574341  Rel. Test L2 Loss :  0.1271052598953247  Test L2 Loss :  0.18541084766387939  inv_L_scale:  [1.0, 1.0]
Epoch :  401  Time:  0.661  Rel. Train L2 Loss :  0.12585310227341123  Rel. Test L2 Loss :  0.12650998175144196  Test L2 Loss :  0.1846778392791748  inv_L_scale:  [1.0, 1.0]
Epoch :  402  Time:  0.661  Rel. Train L2 Loss :  0.125810652507676  Rel. Test L2 Loss :  0.12666159391403198  Test L2 Loss :  0.18488481581211091  inv_L_scale:  [1.0, 1.0]
Epoch :  403  Time:  0.661  Rel. Train L2 Loss :  0.12578119532929527  Rel. Test L2 Loss :  0.1262894967198372  Test L2 Loss :  0.184273841381073  inv_L_scale:  [1.0, 1.0]
Epoch :  404  Time:  0.661  Rel. Train L2 Loss :  0.12577334509955512  Rel. Test L2 Loss :  0.1265254282951355  Test L2 Loss :  0.18469237089157103  inv_L_scale:  [1.0, 1.0]
Epoch :  405  Time:  0.661  Rel. Train L2 Loss :  0.12572305728991826  Rel. Test L2 Loss :  0.1266569074988365  Test L2 Loss :  0.184970463514328  inv_L_scale:  [1.0, 1.0]
Epoch :  406  Time:  0.66  Rel. Train L2 Loss :  0.12569865233368344  Rel. Test L2 Loss :  0.126647529900074  Test L2 Loss :  0.18471184313297273  inv_L_scale:  [1.0, 1.0]
Epoch :  407  Time:  0.661  Rel. Train L2 Loss :  0.12569753309090934  Rel. Test L2 Loss :  0.1264084780216217  Test L2 Loss :  0.18441988825798034  inv_L_scale:  [1.0, 1.0]
Epoch :  408  Time:  0.661  Rel. Train L2 Loss :  0.12564136902491252  Rel. Test L2 Loss :  0.12643484145402908  Test L2 Loss :  0.1845431935787201  inv_L_scale:  [1.0, 1.0]
Epoch :  409  Time:  0.662  Rel. Train L2 Loss :  0.12565041518873638  Rel. Test L2 Loss :  0.12640820413827897  Test L2 Loss :  0.18446729123592376  inv_L_scale:  [1.0, 1.0]
Epoch :  410  Time:  0.661  Rel. Train L2 Loss :  0.1256209110882547  Rel. Test L2 Loss :  0.12639798432588578  Test L2 Loss :  0.184596990942955  inv_L_scale:  [1.0, 1.0]
Epoch :  411  Time:  0.662  Rel. Train L2 Loss :  0.12554242061244117  Rel. Test L2 Loss :  0.12633650720119477  Test L2 Loss :  0.18439071595668793  inv_L_scale:  [1.0, 1.0]
Epoch :  412  Time:  0.661  Rel. Train L2 Loss :  0.12560938712623385  Rel. Test L2 Loss :  0.12629319489002228  Test L2 Loss :  0.18430341720581056  inv_L_scale:  [1.0, 1.0]
Epoch :  413  Time:  0.661  Rel. Train L2 Loss :  0.12558317806985644  Rel. Test L2 Loss :  0.12627653926610946  Test L2 Loss :  0.18430083751678467  inv_L_scale:  [1.0, 1.0]
Epoch :  414  Time:  0.661  Rel. Train L2 Loss :  0.12553704414102768  Rel. Test L2 Loss :  0.12659477889537812  Test L2 Loss :  0.18478336155414582  inv_L_scale:  [1.0, 1.0]
Epoch :  415  Time:  0.661  Rel. Train L2 Loss :  0.12555810497866737  Rel. Test L2 Loss :  0.1264284697175026  Test L2 Loss :  0.18456103563308715  inv_L_scale:  [1.0, 1.0]
Epoch :  416  Time:  0.661  Rel. Train L2 Loss :  0.12550172454781003  Rel. Test L2 Loss :  0.1262988814711571  Test L2 Loss :  0.18435446977615355  inv_L_scale:  [1.0, 1.0]
Epoch :  417  Time:  0.662  Rel. Train L2 Loss :  0.12544643647140927  Rel. Test L2 Loss :  0.12628779351711272  Test L2 Loss :  0.1844260549545288  inv_L_scale:  [1.0, 1.0]
Epoch :  418  Time:  0.661  Rel. Train L2 Loss :  0.12546233786476982  Rel. Test L2 Loss :  0.1264862647652626  Test L2 Loss :  0.18459298849105835  inv_L_scale:  [1.0, 1.0]
Epoch :  419  Time:  0.661  Rel. Train L2 Loss :  0.12541344351238676  Rel. Test L2 Loss :  0.12636951297521593  Test L2 Loss :  0.1844524610042572  inv_L_scale:  [1.0, 1.0]
Epoch :  420  Time:  0.661  Rel. Train L2 Loss :  0.12541323476367527  Rel. Test L2 Loss :  0.12630501449108122  Test L2 Loss :  0.18440894901752472  inv_L_scale:  [1.0, 1.0]
Epoch :  421  Time:  0.661  Rel. Train L2 Loss :  0.12539102918571896  Rel. Test L2 Loss :  0.12622222393751145  Test L2 Loss :  0.18428312063217164  inv_L_scale:  [1.0, 1.0]
Epoch :  422  Time:  0.661  Rel. Train L2 Loss :  0.1254053388039271  Rel. Test L2 Loss :  0.1263462173938751  Test L2 Loss :  0.18444977283477784  inv_L_scale:  [1.0, 1.0]
Epoch :  423  Time:  0.661  Rel. Train L2 Loss :  0.12536711699432798  Rel. Test L2 Loss :  0.12637547463178633  Test L2 Loss :  0.1844197678565979  inv_L_scale:  [1.0, 1.0]
Epoch :  424  Time:  0.661  Rel. Train L2 Loss :  0.12533123943540786  Rel. Test L2 Loss :  0.1263891988992691  Test L2 Loss :  0.1844556874036789  inv_L_scale:  [1.0, 1.0]
Epoch :  425  Time:  0.661  Rel. Train L2 Loss :  0.12538019375668633  Rel. Test L2 Loss :  0.12628469705581666  Test L2 Loss :  0.1843798863887787  inv_L_scale:  [1.0, 1.0]
Epoch :  426  Time:  0.661  Rel. Train L2 Loss :  0.1253859203060468  Rel. Test L2 Loss :  0.1263536450266838  Test L2 Loss :  0.18450291812419892  inv_L_scale:  [1.0, 1.0]
Epoch :  427  Time:  0.661  Rel. Train L2 Loss :  0.12530268341302872  Rel. Test L2 Loss :  0.126221464574337  Test L2 Loss :  0.18427075386047365  inv_L_scale:  [1.0, 1.0]
Epoch :  428  Time:  0.663  Rel. Train L2 Loss :  0.1253029257721371  Rel. Test L2 Loss :  0.12642694264650345  Test L2 Loss :  0.18465703308582307  inv_L_scale:  [1.0, 1.0]
Epoch :  429  Time:  0.662  Rel. Train L2 Loss :  0.12526681476169163  Rel. Test L2 Loss :  0.12656468093395234  Test L2 Loss :  0.18464758038520812  inv_L_scale:  [1.0, 1.0]
Epoch :  430  Time:  0.661  Rel. Train L2 Loss :  0.12527090695169238  Rel. Test L2 Loss :  0.12626409351825715  Test L2 Loss :  0.18430678486824037  inv_L_scale:  [1.0, 1.0]
Epoch :  431  Time:  0.661  Rel. Train L2 Loss :  0.12523160202635658  Rel. Test L2 Loss :  0.12631188660860063  Test L2 Loss :  0.18438513576984406  inv_L_scale:  [1.0, 1.0]
Epoch :  432  Time:  0.661  Rel. Train L2 Loss :  0.12527784562773175  Rel. Test L2 Loss :  0.1263957840204239  Test L2 Loss :  0.18451836943626404  inv_L_scale:  [1.0, 1.0]
Epoch :  433  Time:  0.662  Rel. Train L2 Loss :  0.1252402381764518  Rel. Test L2 Loss :  0.1262046590447426  Test L2 Loss :  0.1842459750175476  inv_L_scale:  [1.0, 1.0]
Epoch :  434  Time:  0.661  Rel. Train L2 Loss :  0.12518061372968886  Rel. Test L2 Loss :  0.1261831185221672  Test L2 Loss :  0.18424007654190064  inv_L_scale:  [1.0, 1.0]
Epoch :  435  Time:  0.661  Rel. Train L2 Loss :  0.12521306077639263  Rel. Test L2 Loss :  0.1262110534310341  Test L2 Loss :  0.18430314421653748  inv_L_scale:  [1.0, 1.0]
Epoch :  436  Time:  0.661  Rel. Train L2 Loss :  0.1251874933971299  Rel. Test L2 Loss :  0.1262325593829155  Test L2 Loss :  0.1842753666639328  inv_L_scale:  [1.0, 1.0]
Epoch :  437  Time:  0.661  Rel. Train L2 Loss :  0.12516387025515238  Rel. Test L2 Loss :  0.12612641394138335  Test L2 Loss :  0.18414463400840758  inv_L_scale:  [1.0, 1.0]
Epoch :  438  Time:  0.661  Rel. Train L2 Loss :  0.1251525961028205  Rel. Test L2 Loss :  0.12627681136131286  Test L2 Loss :  0.18437655210494996  inv_L_scale:  [1.0, 1.0]
Epoch :  439  Time:  0.661  Rel. Train L2 Loss :  0.125125798980395  Rel. Test L2 Loss :  0.12623181015253068  Test L2 Loss :  0.1843294894695282  inv_L_scale:  [1.0, 1.0]
Epoch :  440  Time:  0.662  Rel. Train L2 Loss :  0.12515131844414604  Rel. Test L2 Loss :  0.1261817619204521  Test L2 Loss :  0.18419683575630189  inv_L_scale:  [1.0, 1.0]
Epoch :  441  Time:  0.661  Rel. Train L2 Loss :  0.12508872081836064  Rel. Test L2 Loss :  0.1261833155155182  Test L2 Loss :  0.18420715212821961  inv_L_scale:  [1.0, 1.0]
Epoch :  442  Time:  0.661  Rel. Train L2 Loss :  0.12507108827431998  Rel. Test L2 Loss :  0.1261907958984375  Test L2 Loss :  0.18419344782829283  inv_L_scale:  [1.0, 1.0]
Epoch :  443  Time:  0.661  Rel. Train L2 Loss :  0.12505715396669176  Rel. Test L2 Loss :  0.12612900048494338  Test L2 Loss :  0.18419432699680327  inv_L_scale:  [1.0, 1.0]
Epoch :  444  Time:  0.661  Rel. Train L2 Loss :  0.12504962272114223  Rel. Test L2 Loss :  0.12621744513511657  Test L2 Loss :  0.1841975200176239  inv_L_scale:  [1.0, 1.0]
Epoch :  445  Time:  0.661  Rel. Train L2 Loss :  0.1250219746430715  Rel. Test L2 Loss :  0.12621692329645157  Test L2 Loss :  0.18427619457244873  inv_L_scale:  [1.0, 1.0]
Epoch :  446  Time:  0.661  Rel. Train L2 Loss :  0.12500064505471123  Rel. Test L2 Loss :  0.12623890429735185  Test L2 Loss :  0.1842489594221115  inv_L_scale:  [1.0, 1.0]
Epoch :  447  Time:  0.662  Rel. Train L2 Loss :  0.12500591496626537  Rel. Test L2 Loss :  0.126360267996788  Test L2 Loss :  0.18436545729637147  inv_L_scale:  [1.0, 1.0]
Epoch :  448  Time:  0.661  Rel. Train L2 Loss :  0.12500442326068878  Rel. Test L2 Loss :  0.12614697217941284  Test L2 Loss :  0.18415111660957337  inv_L_scale:  [1.0, 1.0]
Epoch :  449  Time:  0.661  Rel. Train L2 Loss :  0.12496390756633546  Rel. Test L2 Loss :  0.12621369630098342  Test L2 Loss :  0.18423908352851867  inv_L_scale:  [1.0, 1.0]
Epoch :  450  Time:  0.661  Rel. Train L2 Loss :  0.12495332373513116  Rel. Test L2 Loss :  0.1261269110441208  Test L2 Loss :  0.18415389001369475  inv_L_scale:  [1.0, 1.0]
Epoch :  451  Time:  0.661  Rel. Train L2 Loss :  0.12494794368743896  Rel. Test L2 Loss :  0.12615083277225494  Test L2 Loss :  0.18419276118278505  inv_L_scale:  [1.0, 1.0]
Epoch :  452  Time:  0.661  Rel. Train L2 Loss :  0.12495112246937222  Rel. Test L2 Loss :  0.12614337503910064  Test L2 Loss :  0.1841665905714035  inv_L_scale:  [1.0, 1.0]
Epoch :  453  Time:  0.661  Rel. Train L2 Loss :  0.1249321072631412  Rel. Test L2 Loss :  0.12623424261808394  Test L2 Loss :  0.1843121361732483  inv_L_scale:  [1.0, 1.0]
Epoch :  454  Time:  0.661  Rel. Train L2 Loss :  0.12495363248719109  Rel. Test L2 Loss :  0.12612187266349792  Test L2 Loss :  0.18417803525924684  inv_L_scale:  [1.0, 1.0]
Epoch :  455  Time:  0.661  Rel. Train L2 Loss :  0.12492131511370341  Rel. Test L2 Loss :  0.12618150293827057  Test L2 Loss :  0.18420521020889283  inv_L_scale:  [1.0, 1.0]
Epoch :  456  Time:  0.661  Rel. Train L2 Loss :  0.12491490417056614  Rel. Test L2 Loss :  0.1261702811717987  Test L2 Loss :  0.1841614955663681  inv_L_scale:  [1.0, 1.0]
Epoch :  457  Time:  0.661  Rel. Train L2 Loss :  0.12486889395448897  Rel. Test L2 Loss :  0.1261582699418068  Test L2 Loss :  0.18422037243843079  inv_L_scale:  [1.0, 1.0]
Epoch :  458  Time:  0.661  Rel. Train L2 Loss :  0.12489079230361515  Rel. Test L2 Loss :  0.1261000418663025  Test L2 Loss :  0.18412923574447632  inv_L_scale:  [1.0, 1.0]
Epoch :  459  Time:  0.661  Rel. Train L2 Loss :  0.12488937348127366  Rel. Test L2 Loss :  0.12616043359041215  Test L2 Loss :  0.18419066786766053  inv_L_scale:  [1.0, 1.0]
Epoch :  460  Time:  0.661  Rel. Train L2 Loss :  0.12485169963704215  Rel. Test L2 Loss :  0.12616533398628235  Test L2 Loss :  0.18421592116355895  inv_L_scale:  [1.0, 1.0]
Epoch :  461  Time:  0.664  Rel. Train L2 Loss :  0.12486030677954356  Rel. Test L2 Loss :  0.1261075446009636  Test L2 Loss :  0.18411016047000886  inv_L_scale:  [1.0, 1.0]
Epoch :  462  Time:  0.663  Rel. Train L2 Loss :  0.12482907546891106  Rel. Test L2 Loss :  0.12618806213140488  Test L2 Loss :  0.18418016374111176  inv_L_scale:  [1.0, 1.0]
Epoch :  463  Time:  0.662  Rel. Train L2 Loss :  0.12482944938871596  Rel. Test L2 Loss :  0.12613797038793564  Test L2 Loss :  0.18414029002189636  inv_L_scale:  [1.0, 1.0]
Epoch :  464  Time:  0.662  Rel. Train L2 Loss :  0.12481502367390526  Rel. Test L2 Loss :  0.12615918695926667  Test L2 Loss :  0.18416400790214538  inv_L_scale:  [1.0, 1.0]
Epoch :  465  Time:  0.662  Rel. Train L2 Loss :  0.1248121945725547  Rel. Test L2 Loss :  0.12619131028652192  Test L2 Loss :  0.1842108190059662  inv_L_scale:  [1.0, 1.0]
Epoch :  466  Time:  0.662  Rel. Train L2 Loss :  0.12480638517273797  Rel. Test L2 Loss :  0.12612911611795424  Test L2 Loss :  0.1841286301612854  inv_L_scale:  [1.0, 1.0]
Epoch :  467  Time:  0.662  Rel. Train L2 Loss :  0.1247786678870519  Rel. Test L2 Loss :  0.12613695591688157  Test L2 Loss :  0.1841432821750641  inv_L_scale:  [1.0, 1.0]
Epoch :  468  Time:  0.662  Rel. Train L2 Loss :  0.12480090061823527  Rel. Test L2 Loss :  0.1262030178308487  Test L2 Loss :  0.1842127537727356  inv_L_scale:  [1.0, 1.0]
Epoch :  469  Time:  0.662  Rel. Train L2 Loss :  0.12478941420714061  Rel. Test L2 Loss :  0.12610942870378494  Test L2 Loss :  0.18412468314170838  inv_L_scale:  [1.0, 1.0]
Epoch :  470  Time:  0.662  Rel. Train L2 Loss :  0.12477891736560398  Rel. Test L2 Loss :  0.12610559552907943  Test L2 Loss :  0.18410972714424134  inv_L_scale:  [1.0, 1.0]
Epoch :  471  Time:  0.661  Rel. Train L2 Loss :  0.12476997938421037  Rel. Test L2 Loss :  0.12611124962568282  Test L2 Loss :  0.1841243815422058  inv_L_scale:  [1.0, 1.0]
Epoch :  472  Time:  0.662  Rel. Train L2 Loss :  0.1247622651524014  Rel. Test L2 Loss :  0.12617301791906357  Test L2 Loss :  0.18418270826339722  inv_L_scale:  [1.0, 1.0]
Epoch :  473  Time:  0.662  Rel. Train L2 Loss :  0.12474599245521757  Rel. Test L2 Loss :  0.12614234566688537  Test L2 Loss :  0.1841544932126999  inv_L_scale:  [1.0, 1.0]
Epoch :  474  Time:  0.662  Rel. Train L2 Loss :  0.12475386010275946  Rel. Test L2 Loss :  0.12613783419132232  Test L2 Loss :  0.1841640841960907  inv_L_scale:  [1.0, 1.0]
Epoch :  475  Time:  0.662  Rel. Train L2 Loss :  0.12474457207653257  Rel. Test L2 Loss :  0.12614016473293305  Test L2 Loss :  0.1841437554359436  inv_L_scale:  [1.0, 1.0]
Epoch :  476  Time:  0.662  Rel. Train L2 Loss :  0.12474197973807653  Rel. Test L2 Loss :  0.12615436106920241  Test L2 Loss :  0.184173002243042  inv_L_scale:  [1.0, 1.0]
Epoch :  477  Time:  0.662  Rel. Train L2 Loss :  0.12473858343230354  Rel. Test L2 Loss :  0.12615153282880784  Test L2 Loss :  0.18415642499923707  inv_L_scale:  [1.0, 1.0]
Epoch :  478  Time:  0.662  Rel. Train L2 Loss :  0.12472014990117815  Rel. Test L2 Loss :  0.12611571252346038  Test L2 Loss :  0.1841203474998474  inv_L_scale:  [1.0, 1.0]
Epoch :  479  Time:  0.661  Rel. Train L2 Loss :  0.12472223828236262  Rel. Test L2 Loss :  0.12613724768161774  Test L2 Loss :  0.1841433435678482  inv_L_scale:  [1.0, 1.0]
Epoch :  480  Time:  0.662  Rel. Train L2 Loss :  0.12471311489741008  Rel. Test L2 Loss :  0.12612987965345382  Test L2 Loss :  0.18413320302963257  inv_L_scale:  [1.0, 1.0]
Epoch :  481  Time:  0.662  Rel. Train L2 Loss :  0.1247076544827885  Rel. Test L2 Loss :  0.12615090996026992  Test L2 Loss :  0.18415582299232483  inv_L_scale:  [1.0, 1.0]
Epoch :  482  Time:  0.662  Rel. Train L2 Loss :  0.12470701707734003  Rel. Test L2 Loss :  0.1261455574631691  Test L2 Loss :  0.18414244055747986  inv_L_scale:  [1.0, 1.0]
Epoch :  483  Time:  0.662  Rel. Train L2 Loss :  0.12469808101654052  Rel. Test L2 Loss :  0.12613316535949706  Test L2 Loss :  0.18413595139980315  inv_L_scale:  [1.0, 1.0]
Epoch :  484  Time:  0.662  Rel. Train L2 Loss :  0.12470761113696628  Rel. Test L2 Loss :  0.1261405438184738  Test L2 Loss :  0.18413409113883972  inv_L_scale:  [1.0, 1.0]
Epoch :  485  Time:  0.662  Rel. Train L2 Loss :  0.12468813770347172  Rel. Test L2 Loss :  0.12612845122814179  Test L2 Loss :  0.18412714302539826  inv_L_scale:  [1.0, 1.0]
Epoch :  486  Time:  0.662  Rel. Train L2 Loss :  0.12469086491399341  Rel. Test L2 Loss :  0.12612305372953414  Test L2 Loss :  0.18412923336029052  inv_L_scale:  [1.0, 1.0]
Epoch :  487  Time:  0.662  Rel. Train L2 Loss :  0.1246820765402582  Rel. Test L2 Loss :  0.12612863928079604  Test L2 Loss :  0.18413236379623413  inv_L_scale:  [1.0, 1.0]
Epoch :  488  Time:  0.662  Rel. Train L2 Loss :  0.12468062092860539  Rel. Test L2 Loss :  0.12612685322761535  Test L2 Loss :  0.18412826240062713  inv_L_scale:  [1.0, 1.0]
Epoch :  489  Time:  0.662  Rel. Train L2 Loss :  0.12467754913700951  Rel. Test L2 Loss :  0.12612761348485946  Test L2 Loss :  0.18413908481597902  inv_L_scale:  [1.0, 1.0]
Epoch :  490  Time:  0.662  Rel. Train L2 Loss :  0.12468388494518068  Rel. Test L2 Loss :  0.12612400114536285  Test L2 Loss :  0.18412843942642212  inv_L_scale:  [1.0, 1.0]
Epoch :  491  Time:  0.662  Rel. Train L2 Loss :  0.12467188315259085  Rel. Test L2 Loss :  0.12612962692975999  Test L2 Loss :  0.1841359668970108  inv_L_scale:  [1.0, 1.0]
Epoch :  492  Time:  0.662  Rel. Train L2 Loss :  0.12466980086432564  Rel. Test L2 Loss :  0.12613708436489104  Test L2 Loss :  0.18413736581802367  inv_L_scale:  [1.0, 1.0]
Epoch :  493  Time:  0.662  Rel. Train L2 Loss :  0.12467114951875474  Rel. Test L2 Loss :  0.12612774342298508  Test L2 Loss :  0.18413727164268492  inv_L_scale:  [1.0, 1.0]
Epoch :  494  Time:  0.662  Rel. Train L2 Loss :  0.1246707041396035  Rel. Test L2 Loss :  0.1261298391222954  Test L2 Loss :  0.18412928760051728  inv_L_scale:  [1.0, 1.0]
Epoch :  495  Time:  0.662  Rel. Train L2 Loss :  0.12467153231302897  Rel. Test L2 Loss :  0.12613006681203842  Test L2 Loss :  0.18413222670555116  inv_L_scale:  [1.0, 1.0]
Epoch :  496  Time:  0.662  Rel. Train L2 Loss :  0.12467136962546242  Rel. Test L2 Loss :  0.12613389760255814  Test L2 Loss :  0.1841425406932831  inv_L_scale:  [1.0, 1.0]
Epoch :  497  Time:  0.662  Rel. Train L2 Loss :  0.12466283841265573  Rel. Test L2 Loss :  0.12613536149263382  Test L2 Loss :  0.1841367292404175  inv_L_scale:  [1.0, 1.0]
Epoch :  498  Time:  0.662  Rel. Train L2 Loss :  0.12466651803917354  Rel. Test L2 Loss :  0.12613401114940642  Test L2 Loss :  0.1841330796480179  inv_L_scale:  [1.0, 1.0]
Epoch :  499  Time:  0.662  Rel. Train L2 Loss :  0.12466172715028127  Rel. Test L2 Loss :  0.12613012582063676  Test L2 Loss :  0.18413130044937134  inv_L_scale:  [1.0, 1.0]
