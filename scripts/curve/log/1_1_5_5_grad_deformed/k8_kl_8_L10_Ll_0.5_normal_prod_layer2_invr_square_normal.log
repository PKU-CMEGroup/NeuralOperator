(1000,) (1000, 1000, 1) (1000, 1000, 2)
use normalized raw measures
Preprocessing data : computing close_node_pairs
100%|█████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:15<00:00, 63.17it/s] 
maximum number of close node pairs is  10000
Casting to tensor
x train:torch.Size([900, 1000, 8]), y train:torch.Size([900, 1000, 1]), x test:torch.Size([100, 1000, 8]), y test:torch.Size([100, 1000, 1])
length of each dim:  tensor([6.5573987960815430, 6.1420288085937500])
kmax = 8, kmax_local = 8
L =  10  L_local =  0.5
In PCNO_train, ndims =  2
Epoch :  0  Time:  2.022  Rel. Train L2 Loss :  0.5114538510640462  Rel. Test L2 Loss :  0.354794020652771  Test L2 Loss :  0.5106587409973145  inv_L_scale:  [1.0, 1.0]
Epoch :  1  Time:  1.659  Rel. Train L2 Loss :  0.28415919820467633  Rel. Test L2 Loss :  0.24415511012077332  Test L2 Loss :  0.34563755989074707  inv_L_scale:  [1.0, 1.0]
Epoch :  2  Time:  1.665  Rel. Train L2 Loss :  0.20274905774328444  Rel. Test L2 Loss :  0.2007680332660675  Test L2 Loss :  0.28608487367630003  inv_L_scale:  [1.0, 1.0]
Epoch :  3  Time:  1.676  Rel. Train L2 Loss :  0.16776120556725396  Rel. Test L2 Loss :  0.16802522420883179  Test L2 Loss :  0.24068886220455168  inv_L_scale:  [1.0, 1.0]
Epoch :  4  Time:  1.672  Rel. Train L2 Loss :  0.14324385431077746  Rel. Test L2 Loss :  0.15890113592147828  Test L2 Loss :  0.22692299127578736  inv_L_scale:  [1.0, 1.0]
Epoch :  5  Time:  1.666  Rel. Train L2 Loss :  0.13683401160769992  Rel. Test L2 Loss :  0.15107028126716615  Test L2 Loss :  0.21613604843616485  inv_L_scale:  [1.0, 1.0]
Epoch :  6  Time:  1.669  Rel. Train L2 Loss :  0.12275322092903986  Rel. Test L2 Loss :  0.14931939721107482  Test L2 Loss :  0.21297546625137329  inv_L_scale:  [1.0, 1.0]
Epoch :  7  Time:  1.677  Rel. Train L2 Loss :  0.1142983838584688  Rel. Test L2 Loss :  0.13566966116428375  Test L2 Loss :  0.19287245154380797  inv_L_scale:  [1.0, 1.0]
Epoch :  8  Time:  1.657  Rel. Train L2 Loss :  0.10561834441290961  Rel. Test L2 Loss :  0.13157278716564177  Test L2 Loss :  0.18682872772216796  inv_L_scale:  [1.0, 1.0]
Epoch :  9  Time:  1.652  Rel. Train L2 Loss :  0.10184774329264959  Rel. Test L2 Loss :  0.1267681086063385  Test L2 Loss :  0.18046995043754577  inv_L_scale:  [1.0, 1.0]
Epoch :  10  Time:  1.68  Rel. Train L2 Loss :  0.0955531253417333  Rel. Test L2 Loss :  0.12335685193538666  Test L2 Loss :  0.17458703219890595  inv_L_scale:  [1.0, 1.0]
Epoch :  11  Time:  1.641  Rel. Train L2 Loss :  0.09347809920708339  Rel. Test L2 Loss :  0.12021157383918762  Test L2 Loss :  0.17077872157096863  inv_L_scale:  [1.0, 1.0]
Epoch :  12  Time:  1.658  Rel. Train L2 Loss :  0.08923219392697017  Rel. Test L2 Loss :  0.11800286293029785  Test L2 Loss :  0.1677517092227936  inv_L_scale:  [1.0, 1.0]
Epoch :  13  Time:  1.645  Rel. Train L2 Loss :  0.08813018898169199  Rel. Test L2 Loss :  0.11711913704872132  Test L2 Loss :  0.16594484686851502  inv_L_scale:  [1.0, 1.0]
Epoch :  14  Time:  1.641  Rel. Train L2 Loss :  0.08590231663650937  Rel. Test L2 Loss :  0.1208705735206604  Test L2 Loss :  0.17158278107643127  inv_L_scale:  [1.0, 1.0]
Epoch :  15  Time:  1.662  Rel. Train L2 Loss :  0.0838311133450932  Rel. Test L2 Loss :  0.11432126879692078  Test L2 Loss :  0.163311248421669  inv_L_scale:  [1.0, 1.0]
Epoch :  16  Time:  1.667  Rel. Train L2 Loss :  0.08495751462048955  Rel. Test L2 Loss :  0.11333895206451416  Test L2 Loss :  0.16093387424945832  inv_L_scale:  [1.0, 1.0]
Epoch :  17  Time:  1.658  Rel. Train L2 Loss :  0.07909818606244193  Rel. Test L2 Loss :  0.11818722188472748  Test L2 Loss :  0.16820281028747558  inv_L_scale:  [1.0, 1.0]
Epoch :  18  Time:  1.656  Rel. Train L2 Loss :  0.0757803080479304  Rel. Test L2 Loss :  0.11269491136074067  Test L2 Loss :  0.16128268957138062  inv_L_scale:  [1.0, 1.0]
Epoch :  19  Time:  1.665  Rel. Train L2 Loss :  0.07564192437463337  Rel. Test L2 Loss :  0.11000332891941071  Test L2 Loss :  0.15653124570846558  inv_L_scale:  [1.0, 1.0]
Epoch :  20  Time:  1.647  Rel. Train L2 Loss :  0.07439320438437992  Rel. Test L2 Loss :  0.12006007254123688  Test L2 Loss :  0.16977194607257842  inv_L_scale:  [1.0, 1.0]
Epoch :  21  Time:  1.656  Rel. Train L2 Loss :  0.0759744260708491  Rel. Test L2 Loss :  0.11199604988098144  Test L2 Loss :  0.15996706366539  inv_L_scale:  [1.0, 1.0]
Epoch :  22  Time:  1.642  Rel. Train L2 Loss :  0.07289909028344684  Rel. Test L2 Loss :  0.11219879150390626  Test L2 Loss :  0.16047083258628844  inv_L_scale:  [1.0, 1.0]
Epoch :  23  Time:  1.71  Rel. Train L2 Loss :  0.0727514875266287  Rel. Test L2 Loss :  0.11054607450962067  Test L2 Loss :  0.15716757118701935  inv_L_scale:  [1.0, 1.0]
Epoch :  24  Time:  1.659  Rel. Train L2 Loss :  0.07094873567422232  Rel. Test L2 Loss :  0.10715738713741302  Test L2 Loss :  0.15255192518234253  inv_L_scale:  [1.0, 1.0]
Epoch :  25  Time:  1.664  Rel. Train L2 Loss :  0.069990670118067  Rel. Test L2 Loss :  0.11031744599342347  Test L2 Loss :  0.15758549988269807  inv_L_scale:  [1.0, 1.0]
Epoch :  26  Time:  1.695  Rel. Train L2 Loss :  0.07001942743857702  Rel. Test L2 Loss :  0.10967905521392822  Test L2 Loss :  0.15642426729202272  inv_L_scale:  [1.0, 1.0]
Epoch :  27  Time:  1.687  Rel. Train L2 Loss :  0.06942696074644725  Rel. Test L2 Loss :  0.1115351790189743  Test L2 Loss :  0.15814510941505433  inv_L_scale:  [1.0, 1.0]
Epoch :  28  Time:  1.652  Rel. Train L2 Loss :  0.0694621469742722  Rel. Test L2 Loss :  0.10687112033367158  Test L2 Loss :  0.15204451441764832  inv_L_scale:  [1.0, 1.0]
Epoch :  29  Time:  1.666  Rel. Train L2 Loss :  0.07110923813449012  Rel. Test L2 Loss :  0.10896387934684754  Test L2 Loss :  0.15502000153064727  inv_L_scale:  [1.0, 1.0]
Epoch :  30  Time:  1.728  Rel. Train L2 Loss :  0.06856510842839877  Rel. Test L2 Loss :  0.10891382157802582  Test L2 Loss :  0.15525473892688751  inv_L_scale:  [1.0, 1.0]
Epoch :  31  Time:  1.662  Rel. Train L2 Loss :  0.06462047507365544  Rel. Test L2 Loss :  0.10823514580726623  Test L2 Loss :  0.15406241416931152  inv_L_scale:  [1.0, 1.0]
Epoch :  32  Time:  1.666  Rel. Train L2 Loss :  0.06472600635555055  Rel. Test L2 Loss :  0.1049419867992401  Test L2 Loss :  0.14875707387924195  inv_L_scale:  [1.0, 1.0]
Epoch :  33  Time:  1.697  Rel. Train L2 Loss :  0.06472591893540489  Rel. Test L2 Loss :  0.10531465083360672  Test L2 Loss :  0.15039920210838317  inv_L_scale:  [1.0, 1.0]
Epoch :  34  Time:  1.701  Rel. Train L2 Loss :  0.06688372780879338  Rel. Test L2 Loss :  0.11103465676307678  Test L2 Loss :  0.15860211610794067  inv_L_scale:  [1.0, 1.0]
Epoch :  35  Time:  1.657  Rel. Train L2 Loss :  0.06486302534739176  Rel. Test L2 Loss :  0.10428443968296051  Test L2 Loss :  0.14866607666015624  inv_L_scale:  [1.0, 1.0]
Epoch :  36  Time:  1.679  Rel. Train L2 Loss :  0.061634995705551573  Rel. Test L2 Loss :  0.10481193125247955  Test L2 Loss :  0.14936024069786072  inv_L_scale:  [1.0, 1.0]
Epoch :  37  Time:  1.647  Rel. Train L2 Loss :  0.06440163946814008  Rel. Test L2 Loss :  0.10963659524917603  Test L2 Loss :  0.15698180258274078  inv_L_scale:  [1.0, 1.0]
Epoch :  38  Time:  1.672  Rel. Train L2 Loss :  0.06441952026552625  Rel. Test L2 Loss :  0.10624484956264496  Test L2 Loss :  0.15270661771297456  inv_L_scale:  [1.0, 1.0]
Epoch :  39  Time:  1.645  Rel. Train L2 Loss :  0.06333096568783124  Rel. Test L2 Loss :  0.10752893447875976  Test L2 Loss :  0.15313073635101318  inv_L_scale:  [1.0, 1.0]
Epoch :  40  Time:  1.71  Rel. Train L2 Loss :  0.06355895275870958  Rel. Test L2 Loss :  0.10658753633499146  Test L2 Loss :  0.1527559417486191  inv_L_scale:  [1.0, 1.0]
Epoch :  41  Time:  1.671  Rel. Train L2 Loss :  0.06296338554885653  Rel. Test L2 Loss :  0.10847445964813232  Test L2 Loss :  0.15493384301662444  inv_L_scale:  [1.0, 1.0]
Epoch :  42  Time:  1.677  Rel. Train L2 Loss :  0.0617199362648858  Rel. Test L2 Loss :  0.10291022270917892  Test L2 Loss :  0.1477493304014206  inv_L_scale:  [1.0, 1.0]
Epoch :  43  Time:  1.676  Rel. Train L2 Loss :  0.0624117358856731  Rel. Test L2 Loss :  0.10424308240413666  Test L2 Loss :  0.1491857135295868  inv_L_scale:  [1.0, 1.0]
Epoch :  44  Time:  1.681  Rel. Train L2 Loss :  0.060905062291357254  Rel. Test L2 Loss :  0.10447312384843827  Test L2 Loss :  0.14857204079627992  inv_L_scale:  [1.0, 1.0]
Epoch :  45  Time:  1.657  Rel. Train L2 Loss :  0.06269897354973687  Rel. Test L2 Loss :  0.10784887433052064  Test L2 Loss :  0.15467095494270325  inv_L_scale:  [1.0, 1.0]
Epoch :  46  Time:  1.643  Rel. Train L2 Loss :  0.062307639618714654  Rel. Test L2 Loss :  0.10424634993076325  Test L2 Loss :  0.1478911316394806  inv_L_scale:  [1.0, 1.0]
Epoch :  47  Time:  1.644  Rel. Train L2 Loss :  0.06298444231351216  Rel. Test L2 Loss :  0.1080660355091095  Test L2 Loss :  0.1550925576686859  inv_L_scale:  [1.0, 1.0]
Epoch :  48  Time:  1.645  Rel. Train L2 Loss :  0.06005024313926697  Rel. Test L2 Loss :  0.10415756523609161  Test L2 Loss :  0.14885522603988646  inv_L_scale:  [1.0, 1.0]
Epoch :  49  Time:  1.657  Rel. Train L2 Loss :  0.0606670287085904  Rel. Test L2 Loss :  0.1019679832458496  Test L2 Loss :  0.1463083291053772  inv_L_scale:  [1.0, 1.0]
Epoch :  50  Time:  1.653  Rel. Train L2 Loss :  0.06042084952195485  Rel. Test L2 Loss :  0.10193533629179001  Test L2 Loss :  0.1453663456439972  inv_L_scale:  [1.0, 1.0]
Epoch :  51  Time:  1.644  Rel. Train L2 Loss :  0.05937611063321432  Rel. Test L2 Loss :  0.10185125172138214  Test L2 Loss :  0.14513234972953795  inv_L_scale:  [1.0, 1.0]
Epoch :  52  Time:  1.655  Rel. Train L2 Loss :  0.05876437654097875  Rel. Test L2 Loss :  0.10375810414552689  Test L2 Loss :  0.14753033280372618  inv_L_scale:  [1.0, 1.0]
Epoch :  53  Time:  1.67  Rel. Train L2 Loss :  0.060522385868761276  Rel. Test L2 Loss :  0.10225280940532684  Test L2 Loss :  0.14543684244155883  inv_L_scale:  [1.0, 1.0]
Epoch :  54  Time:  1.659  Rel. Train L2 Loss :  0.06087271432081858  Rel. Test L2 Loss :  0.10197974056005478  Test L2 Loss :  0.1463370406627655  inv_L_scale:  [1.0, 1.0]
Epoch :  55  Time:  1.696  Rel. Train L2 Loss :  0.06118683642811246  Rel. Test L2 Loss :  0.10583233773708343  Test L2 Loss :  0.1508355838060379  inv_L_scale:  [1.0, 1.0]
Epoch :  56  Time:  1.649  Rel. Train L2 Loss :  0.05997695753971736  Rel. Test L2 Loss :  0.10395799487829209  Test L2 Loss :  0.14958665609359742  inv_L_scale:  [1.0, 1.0]
Epoch :  57  Time:  1.646  Rel. Train L2 Loss :  0.06032929039663738  Rel. Test L2 Loss :  0.10125956296920777  Test L2 Loss :  0.14476624965667725  inv_L_scale:  [1.0, 1.0]
Epoch :  58  Time:  1.655  Rel. Train L2 Loss :  0.05871987726953295  Rel. Test L2 Loss :  0.10218552827835083  Test L2 Loss :  0.14684722125530242  inv_L_scale:  [1.0, 1.0]
Epoch :  59  Time:  1.642  Rel. Train L2 Loss :  0.05962497815489769  Rel. Test L2 Loss :  0.10246801882982254  Test L2 Loss :  0.14680591583251953  inv_L_scale:  [1.0, 1.0]
Epoch :  60  Time:  1.659  Rel. Train L2 Loss :  0.061503433121575246  Rel. Test L2 Loss :  0.10280594795942306  Test L2 Loss :  0.14646723985671997  inv_L_scale:  [1.0, 1.0]
Epoch :  61  Time:  1.652  Rel. Train L2 Loss :  0.06044377363390393  Rel. Test L2 Loss :  0.10032303124666214  Test L2 Loss :  0.14339822590351103  inv_L_scale:  [1.0, 1.0]
Epoch :  62  Time:  1.647  Rel. Train L2 Loss :  0.05818745644556152  Rel. Test L2 Loss :  0.0994203343987465  Test L2 Loss :  0.14192625224590302  inv_L_scale:  [1.0, 1.0]
Epoch :  63  Time:  1.673  Rel. Train L2 Loss :  0.05726443989409341  Rel. Test L2 Loss :  0.10059771656990052  Test L2 Loss :  0.14360988438129424  inv_L_scale:  [1.0, 1.0]