Loading data from  ../../data/curve//pcno_curve_data_1_1_5_5_stokes.npz
(1000,) (1000, 1000, 1) (1000, 1000, 2)
use normalized raw measures
Casting to tensor
x_train shape torch.Size([900, 1000, 8]), y_train shape torch.Size([900, 1000, 1])
length of each dim:  tensor([6.6455335617065430, 6.6654777526855469])
kmax = 16
L = 14
geo_dims = [1, 2, 5, 6], num_grad = 3
In PCNO_train, ndims =  2
Epoch :  0  Time:  1.409  Rel. Train L2 Loss :  0.38028135153982373  Rel. Test L2 Loss :  0.24391570448875427  Test L2 Loss :  0.47236180305480957  inv_L_scale:  [1.0, 1.0]
Epoch :  1  Time:  1.098  Rel. Train L2 Loss :  0.19579111635684968  Rel. Test L2 Loss :  0.15848032414913177  Test L2 Loss :  0.3040137791633606  inv_L_scale:  [1.0, 1.0]
Epoch :  2  Time:  1.099  Rel. Train L2 Loss :  0.13956504546933704  Rel. Test L2 Loss :  0.12681074678897858  Test L2 Loss :  0.23372155606746672  inv_L_scale:  [1.0, 1.0]
Epoch :  3  Time:  1.101  Rel. Train L2 Loss :  0.11781800385978487  Rel. Test L2 Loss :  0.1123124098777771  Test L2 Loss :  0.20718656420707704  inv_L_scale:  [1.0, 1.0]
Epoch :  4  Time:  1.098  Rel. Train L2 Loss :  0.10357707248793709  Rel. Test L2 Loss :  0.09948979407548904  Test L2 Loss :  0.18448052763938905  inv_L_scale:  [1.0, 1.0]
Epoch :  5  Time:  1.099  Rel. Train L2 Loss :  0.09093274960915247  Rel. Test L2 Loss :  0.09362518429756164  Test L2 Loss :  0.1732052117586136  inv_L_scale:  [1.0, 1.0]
Epoch :  6  Time:  1.099  Rel. Train L2 Loss :  0.08286397301488453  Rel. Test L2 Loss :  0.08409891337156296  Test L2 Loss :  0.1538146686553955  inv_L_scale:  [1.0, 1.0]
Epoch :  7  Time:  1.098  Rel. Train L2 Loss :  0.07747560732894473  Rel. Test L2 Loss :  0.08356230020523071  Test L2 Loss :  0.15346771240234375  inv_L_scale:  [1.0, 1.0]
Epoch :  8  Time:  1.099  Rel. Train L2 Loss :  0.0737221669157346  Rel. Test L2 Loss :  0.07693255215883255  Test L2 Loss :  0.14244353234767915  inv_L_scale:  [1.0, 1.0]
Epoch :  9  Time:  1.098  Rel. Train L2 Loss :  0.06789466351270676  Rel. Test L2 Loss :  0.07397550553083419  Test L2 Loss :  0.1352022284269333  inv_L_scale:  [1.0, 1.0]
Epoch :  10  Time:  1.099  Rel. Train L2 Loss :  0.06932617581552929  Rel. Test L2 Loss :  0.06992172479629516  Test L2 Loss :  0.1270783621072769  inv_L_scale:  [1.0, 1.0]
Epoch :  11  Time:  1.097  Rel. Train L2 Loss :  0.0658871477180057  Rel. Test L2 Loss :  0.0667017138004303  Test L2 Loss :  0.11911607801914215  inv_L_scale:  [1.0, 1.0]
Epoch :  12  Time:  1.098  Rel. Train L2 Loss :  0.06475077291329702  Rel. Test L2 Loss :  0.06998069733381271  Test L2 Loss :  0.12830239593982695  inv_L_scale:  [1.0, 1.0]
Epoch :  13  Time:  1.098  Rel. Train L2 Loss :  0.05996219482686785  Rel. Test L2 Loss :  0.06644561916589736  Test L2 Loss :  0.12140195965766906  inv_L_scale:  [1.0, 1.0]
Epoch :  14  Time:  1.099  Rel. Train L2 Loss :  0.0555374531282319  Rel. Test L2 Loss :  0.06266182288527489  Test L2 Loss :  0.11409167349338531  inv_L_scale:  [1.0, 1.0]
Epoch :  15  Time:  1.098  Rel. Train L2 Loss :  0.05847549428542455  Rel. Test L2 Loss :  0.06610737174749375  Test L2 Loss :  0.12078325808048249  inv_L_scale:  [1.0, 1.0]
Epoch :  16  Time:  1.097  Rel. Train L2 Loss :  0.054169013930691616  Rel. Test L2 Loss :  0.05637940913438797  Test L2 Loss :  0.10323518931865693  inv_L_scale:  [1.0, 1.0]
Epoch :  17  Time:  1.098  Rel. Train L2 Loss :  0.050353408869769835  Rel. Test L2 Loss :  0.05410798490047455  Test L2 Loss :  0.09742091059684753  inv_L_scale:  [1.0, 1.0]
Epoch :  18  Time:  1.098  Rel. Train L2 Loss :  0.04868803537554211  Rel. Test L2 Loss :  0.058075471222400664  Test L2 Loss :  0.10354560017585754  inv_L_scale:  [1.0, 1.0]
Epoch :  19  Time:  1.096  Rel. Train L2 Loss :  0.04837316695186827  Rel. Test L2 Loss :  0.05366008847951889  Test L2 Loss :  0.09788426995277405  inv_L_scale:  [1.0, 1.0]
Epoch :  20  Time:  1.099  Rel. Train L2 Loss :  0.0484858363866806  Rel. Test L2 Loss :  0.055311209857463836  Test L2 Loss :  0.09907035797834396  inv_L_scale:  [1.0, 1.0]
Epoch :  21  Time:  1.098  Rel. Train L2 Loss :  0.049262262417210476  Rel. Test L2 Loss :  0.05425549894571304  Test L2 Loss :  0.0975694078207016  inv_L_scale:  [1.0, 1.0]
Epoch :  22  Time:  1.098  Rel. Train L2 Loss :  0.047997298604912225  Rel. Test L2 Loss :  0.048464622795581815  Test L2 Loss :  0.08828269481658936  inv_L_scale:  [1.0, 1.0]
Epoch :  23  Time:  1.098  Rel. Train L2 Loss :  0.048353441970215905  Rel. Test L2 Loss :  0.049717042148113254  Test L2 Loss :  0.08972064346075058  inv_L_scale:  [1.0, 1.0]
Epoch :  24  Time:  1.096  Rel. Train L2 Loss :  0.04527822540866004  Rel. Test L2 Loss :  0.047201161980628965  Test L2 Loss :  0.08569348454475403  inv_L_scale:  [1.0, 1.0]
Epoch :  25  Time:  1.098  Rel. Train L2 Loss :  0.044804745448960195  Rel. Test L2 Loss :  0.0471242456138134  Test L2 Loss :  0.08606457889080048  inv_L_scale:  [1.0, 1.0]
Epoch :  26  Time:  1.096  Rel. Train L2 Loss :  0.04482162889507082  Rel. Test L2 Loss :  0.04546155750751495  Test L2 Loss :  0.08140525102615356  inv_L_scale:  [1.0, 1.0]
Epoch :  27  Time:  1.1  Rel. Train L2 Loss :  0.043528011060423324  Rel. Test L2 Loss :  0.048063782453536985  Test L2 Loss :  0.08716245979070664  inv_L_scale:  [1.0, 1.0]
Epoch :  28  Time:  1.098  Rel. Train L2 Loss :  0.045312092767821416  Rel. Test L2 Loss :  0.04889881879091263  Test L2 Loss :  0.09022757858037948  inv_L_scale:  [1.0, 1.0]
Epoch :  29  Time:  1.097  Rel. Train L2 Loss :  0.04189702813824018  Rel. Test L2 Loss :  0.04985945820808411  Test L2 Loss :  0.09085719168186188  inv_L_scale:  [1.0, 1.0]
Epoch :  30  Time:  1.097  Rel. Train L2 Loss :  0.04269964050915506  Rel. Test L2 Loss :  0.051617116034030915  Test L2 Loss :  0.09562872052192688  inv_L_scale:  [1.0, 1.0]
Epoch :  31  Time:  1.097  Rel. Train L2 Loss :  0.04258644415272607  Rel. Test L2 Loss :  0.048272008001804353  Test L2 Loss :  0.0875412631034851  inv_L_scale:  [1.0, 1.0]
Epoch :  32  Time:  1.097  Rel. Train L2 Loss :  0.04301006666488118  Rel. Test L2 Loss :  0.05270396411418915  Test L2 Loss :  0.09944987118244171  inv_L_scale:  [1.0, 1.0]
Epoch :  33  Time:  1.099  Rel. Train L2 Loss :  0.043799275043937894  Rel. Test L2 Loss :  0.04435373544692993  Test L2 Loss :  0.07933781802654266  inv_L_scale:  [1.0, 1.0]
Epoch :  34  Time:  1.097  Rel. Train L2 Loss :  0.042383595721589194  Rel. Test L2 Loss :  0.05112986460328102  Test L2 Loss :  0.09255557805299759  inv_L_scale:  [1.0, 1.0]
Epoch :  35  Time:  1.098  Rel. Train L2 Loss :  0.04150693097048336  Rel. Test L2 Loss :  0.042095894664525985  Test L2 Loss :  0.07570964574813843  inv_L_scale:  [1.0, 1.0]
Epoch :  36  Time:  1.099  Rel. Train L2 Loss :  0.039010482596026526  Rel. Test L2 Loss :  0.04456937521696091  Test L2 Loss :  0.08077485382556915  inv_L_scale:  [1.0, 1.0]
Epoch :  37  Time:  1.097  Rel. Train L2 Loss :  0.03887322574853897  Rel. Test L2 Loss :  0.0416173680126667  Test L2 Loss :  0.07488673567771911  inv_L_scale:  [1.0, 1.0]
Epoch :  38  Time:  1.097  Rel. Train L2 Loss :  0.038507379558351304  Rel. Test L2 Loss :  0.039361069351434706  Test L2 Loss :  0.07069433450698853  inv_L_scale:  [1.0, 1.0]
Epoch :  39  Time:  1.096  Rel. Train L2 Loss :  0.039577656222714315  Rel. Test L2 Loss :  0.040894629657268526  Test L2 Loss :  0.07314402341842652  inv_L_scale:  [1.0, 1.0]
Epoch :  40  Time:  1.098  Rel. Train L2 Loss :  0.03831133397089111  Rel. Test L2 Loss :  0.03989764779806137  Test L2 Loss :  0.07298558235168456  inv_L_scale:  [1.0, 1.0]
Epoch :  41  Time:  1.097  Rel. Train L2 Loss :  0.03912567910220888  Rel. Test L2 Loss :  0.045909039527177814  Test L2 Loss :  0.08238209247589111  inv_L_scale:  [1.0, 1.0]
Epoch :  42  Time:  1.097  Rel. Train L2 Loss :  0.040291181885533864  Rel. Test L2 Loss :  0.04573475420475006  Test L2 Loss :  0.08244783639907836  inv_L_scale:  [1.0, 1.0]
Epoch :  43  Time:  1.097  Rel. Train L2 Loss :  0.03776172738936212  Rel. Test L2 Loss :  0.04358505785465241  Test L2 Loss :  0.07971895903348923  inv_L_scale:  [1.0, 1.0]
Epoch :  44  Time:  1.096  Rel. Train L2 Loss :  0.037377706103854706  Rel. Test L2 Loss :  0.04563394159078598  Test L2 Loss :  0.08248729586601257  inv_L_scale:  [1.0, 1.0]
Epoch :  45  Time:  1.098  Rel. Train L2 Loss :  0.038589577145046655  Rel. Test L2 Loss :  0.04121341347694397  Test L2 Loss :  0.07300718575716018  inv_L_scale:  [1.0, 1.0]
Epoch :  46  Time:  1.099  Rel. Train L2 Loss :  0.03687691658735275  Rel. Test L2 Loss :  0.05423126563429832  Test L2 Loss :  0.09762403458356857  inv_L_scale:  [1.0, 1.0]
Epoch :  47  Time:  1.096  Rel. Train L2 Loss :  0.03840798247191641  Rel. Test L2 Loss :  0.040793978124856946  Test L2 Loss :  0.07350781440734863  inv_L_scale:  [1.0, 1.0]
Epoch :  48  Time:  1.097  Rel. Train L2 Loss :  0.03688460232483016  Rel. Test L2 Loss :  0.03995675921440125  Test L2 Loss :  0.07073841661214829  inv_L_scale:  [1.0, 1.0]
Epoch :  49  Time:  1.096  Rel. Train L2 Loss :  0.03711606135798825  Rel. Test L2 Loss :  0.03960322260856628  Test L2 Loss :  0.07131213039159774  inv_L_scale:  [1.0, 1.0]
Epoch :  50  Time:  1.096  Rel. Train L2 Loss :  0.03661764269073804  Rel. Test L2 Loss :  0.03879573479294777  Test L2 Loss :  0.06943751960992812  inv_L_scale:  [1.0, 1.0]
Epoch :  51  Time:  1.098  Rel. Train L2 Loss :  0.034658723490105736  Rel. Test L2 Loss :  0.04121463090181351  Test L2 Loss :  0.07277167856693267  inv_L_scale:  [1.0, 1.0]
Epoch :  52  Time:  1.096  Rel. Train L2 Loss :  0.03787487659189436  Rel. Test L2 Loss :  0.053012455850839614  Test L2 Loss :  0.09872931718826294  inv_L_scale:  [1.0, 1.0]
Epoch :  53  Time:  1.095  Rel. Train L2 Loss :  0.035943688915835485  Rel. Test L2 Loss :  0.03852908879518509  Test L2 Loss :  0.06991123735904693  inv_L_scale:  [1.0, 1.0]
Epoch :  54  Time:  1.098  Rel. Train L2 Loss :  0.033953794803884295  Rel. Test L2 Loss :  0.04272100836038589  Test L2 Loss :  0.0780357438325882  inv_L_scale:  [1.0, 1.0]
Epoch :  55  Time:  1.097  Rel. Train L2 Loss :  0.0390099821653631  Rel. Test L2 Loss :  0.041807183176279065  Test L2 Loss :  0.07791914910078049  inv_L_scale:  [1.0, 1.0]
Epoch :  56  Time:  1.096  Rel. Train L2 Loss :  0.03494659326970577  Rel. Test L2 Loss :  0.036074328571558  Test L2 Loss :  0.06591063857078552  inv_L_scale:  [1.0, 1.0]
Epoch :  57  Time:  1.098  Rel. Train L2 Loss :  0.03401577855149905  Rel. Test L2 Loss :  0.03594235435128212  Test L2 Loss :  0.06520422786474228  inv_L_scale:  [1.0, 1.0]
Epoch :  58  Time:  1.099  Rel. Train L2 Loss :  0.035269655254152085  Rel. Test L2 Loss :  0.045203040540218356  Test L2 Loss :  0.08291770964860916  inv_L_scale:  [1.0, 1.0]
Epoch :  59  Time:  1.096  Rel. Train L2 Loss :  0.035350855886936185  Rel. Test L2 Loss :  0.0397240024805069  Test L2 Loss :  0.07152256369590759  inv_L_scale:  [1.0, 1.0]
Epoch :  60  Time:  1.096  Rel. Train L2 Loss :  0.03489020468460189  Rel. Test L2 Loss :  0.03593127138912678  Test L2 Loss :  0.06470483705401421  inv_L_scale:  [1.0, 1.0]
Epoch :  61  Time:  1.097  Rel. Train L2 Loss :  0.03474392710460557  Rel. Test L2 Loss :  0.04386702984571457  Test L2 Loss :  0.07737342476844787  inv_L_scale:  [1.0, 1.0]
Epoch :  62  Time:  1.096  Rel. Train L2 Loss :  0.03334927178091473  Rel. Test L2 Loss :  0.036323260068893436  Test L2 Loss :  0.0651027050614357  inv_L_scale:  [1.0, 1.0]
Epoch :  63  Time:  1.096  Rel. Train L2 Loss :  0.0334328777425819  Rel. Test L2 Loss :  0.03504709638655186  Test L2 Loss :  0.0639498008787632  inv_L_scale:  [1.0, 1.0]
Epoch :  64  Time:  1.096  Rel. Train L2 Loss :  0.033709527403116224  Rel. Test L2 Loss :  0.037895811647176744  Test L2 Loss :  0.06939659267663956  inv_L_scale:  [1.0, 1.0]
Epoch :  65  Time:  1.096  Rel. Train L2 Loss :  0.03338823041982121  Rel. Test L2 Loss :  0.03282909631729126  Test L2 Loss :  0.05861662581562996  inv_L_scale:  [1.0, 1.0]
Epoch :  66  Time:  1.096  Rel. Train L2 Loss :  0.03283810388710764  Rel. Test L2 Loss :  0.036322910189628604  Test L2 Loss :  0.06717587143182754  inv_L_scale:  [1.0, 1.0]
Epoch :  67  Time:  1.096  Rel. Train L2 Loss :  0.03539297925101386  Rel. Test L2 Loss :  0.04303469270467758  Test L2 Loss :  0.07887966752052307  inv_L_scale:  [1.0, 1.0]
Epoch :  68  Time:  1.098  Rel. Train L2 Loss :  0.03367073569032881  Rel. Test L2 Loss :  0.033727228343486786  Test L2 Loss :  0.060326552391052245  inv_L_scale:  [1.0, 1.0]
Epoch :  69  Time:  1.096  Rel. Train L2 Loss :  0.03464212975568241  Rel. Test L2 Loss :  0.03257544718682766  Test L2 Loss :  0.05840179592370987  inv_L_scale:  [1.0, 1.0]
Epoch :  70  Time:  1.096  Rel. Train L2 Loss :  0.031231479280524783  Rel. Test L2 Loss :  0.034240670949220654  Test L2 Loss :  0.06091877400875092  inv_L_scale:  [1.0, 1.0]
Epoch :  71  Time:  1.095  Rel. Train L2 Loss :  0.031733666078911885  Rel. Test L2 Loss :  0.0334272699803114  Test L2 Loss :  0.060182009935379026  inv_L_scale:  [1.0, 1.0]
Epoch :  72  Time:  1.099  Rel. Train L2 Loss :  0.03170274327198664  Rel. Test L2 Loss :  0.03277434132993221  Test L2 Loss :  0.05916381150484085  inv_L_scale:  [1.0, 1.0]
Epoch :  73  Time:  1.097  Rel. Train L2 Loss :  0.031833726548486284  Rel. Test L2 Loss :  0.03484688714146614  Test L2 Loss :  0.062683295160532  inv_L_scale:  [1.0, 1.0]
Epoch :  74  Time:  1.096  Rel. Train L2 Loss :  0.03186130455798573  Rel. Test L2 Loss :  0.032975879833102226  Test L2 Loss :  0.058936588764190674  inv_L_scale:  [1.0, 1.0]
Epoch :  75  Time:  1.096  Rel. Train L2 Loss :  0.030719785756535  Rel. Test L2 Loss :  0.030239705592393876  Test L2 Loss :  0.05434108674526215  inv_L_scale:  [1.0, 1.0]
Epoch :  76  Time:  1.096  Rel. Train L2 Loss :  0.03230016041133139  Rel. Test L2 Loss :  0.03486452855169773  Test L2 Loss :  0.06378561407327651  inv_L_scale:  [1.0, 1.0]
Epoch :  77  Time:  1.096  Rel. Train L2 Loss :  0.03188917096290324  Rel. Test L2 Loss :  0.03255344830453396  Test L2 Loss :  0.05798497170209885  inv_L_scale:  [1.0, 1.0]
Epoch :  78  Time:  1.096  Rel. Train L2 Loss :  0.032386610673533545  Rel. Test L2 Loss :  0.03693570725619793  Test L2 Loss :  0.06631076648831367  inv_L_scale:  [1.0, 1.0]
Epoch :  79  Time:  1.096  Rel. Train L2 Loss :  0.03266061256329218  Rel. Test L2 Loss :  0.047363852262496946  Test L2 Loss :  0.08809461832046508  inv_L_scale:  [1.0, 1.0]
Epoch :  80  Time:  1.098  Rel. Train L2 Loss :  0.029882315430376265  Rel. Test L2 Loss :  0.03390517584979534  Test L2 Loss :  0.060680405646562574  inv_L_scale:  [1.0, 1.0]
Epoch :  81  Time:  1.096  Rel. Train L2 Loss :  0.03164709043999513  Rel. Test L2 Loss :  0.02891825407743454  Test L2 Loss :  0.052065159976482395  inv_L_scale:  [1.0, 1.0]
Epoch :  82  Time:  1.097  Rel. Train L2 Loss :  0.02982217258049382  Rel. Test L2 Loss :  0.029612000659108163  Test L2 Loss :  0.053042952120304104  inv_L_scale:  [1.0, 1.0]
Epoch :  83  Time:  1.096  Rel. Train L2 Loss :  0.030531133479542203  Rel. Test L2 Loss :  0.03640716716647148  Test L2 Loss :  0.06481641680002212  inv_L_scale:  [1.0, 1.0]
Epoch :  84  Time:  1.098  Rel. Train L2 Loss :  0.030526084817118115  Rel. Test L2 Loss :  0.03182610437273979  Test L2 Loss :  0.05759020745754242  inv_L_scale:  [1.0, 1.0]
Epoch :  85  Time:  1.096  Rel. Train L2 Loss :  0.02972374666068289  Rel. Test L2 Loss :  0.0308432437479496  Test L2 Loss :  0.054772321879863736  inv_L_scale:  [1.0, 1.0]
Epoch :  86  Time:  1.096  Rel. Train L2 Loss :  0.029932623008886973  Rel. Test L2 Loss :  0.03656559824943542  Test L2 Loss :  0.06523175328969956  inv_L_scale:  [1.0, 1.0]
Epoch :  87  Time:  1.096  Rel. Train L2 Loss :  0.030584886314140424  Rel. Test L2 Loss :  0.036775682121515274  Test L2 Loss :  0.06599980354309082  inv_L_scale:  [1.0, 1.0]
Epoch :  88  Time:  1.096  Rel. Train L2 Loss :  0.030657254341575835  Rel. Test L2 Loss :  0.03353922002017498  Test L2 Loss :  0.06068939492106438  inv_L_scale:  [1.0, 1.0]
Epoch :  89  Time:  1.098  Rel. Train L2 Loss :  0.02940329498714871  Rel. Test L2 Loss :  0.034177721664309504  Test L2 Loss :  0.061458276212215425  inv_L_scale:  [1.0, 1.0]
Epoch :  90  Time:  1.099  Rel. Train L2 Loss :  0.028707922125856083  Rel. Test L2 Loss :  0.028900239244103433  Test L2 Loss :  0.051941415071487425  inv_L_scale:  [1.0, 1.0]
Epoch :  91  Time:  1.097  Rel. Train L2 Loss :  0.028838680303759044  Rel. Test L2 Loss :  0.03236913233995438  Test L2 Loss :  0.058075965344905854  inv_L_scale:  [1.0, 1.0]
Epoch :  92  Time:  1.097  Rel. Train L2 Loss :  0.02824809675415357  Rel. Test L2 Loss :  0.03003441520035267  Test L2 Loss :  0.05415320068597793  inv_L_scale:  [1.0, 1.0]
Epoch :  93  Time:  1.097  Rel. Train L2 Loss :  0.02825872586833106  Rel. Test L2 Loss :  0.03275559015572071  Test L2 Loss :  0.05948959589004517  inv_L_scale:  [1.0, 1.0]
Epoch :  94  Time:  1.097  Rel. Train L2 Loss :  0.02787198230624199  Rel. Test L2 Loss :  0.029408365413546564  Test L2 Loss :  0.052689578384160995  inv_L_scale:  [1.0, 1.0]
Epoch :  95  Time:  1.097  Rel. Train L2 Loss :  0.029256738540199067  Rel. Test L2 Loss :  0.028472131565213204  Test L2 Loss :  0.05139178425073623  inv_L_scale:  [1.0, 1.0]
Epoch :  96  Time:  1.095  Rel. Train L2 Loss :  0.02760769666896926  Rel. Test L2 Loss :  0.03291771434247494  Test L2 Loss :  0.058377669900655745  inv_L_scale:  [1.0, 1.0]
Epoch :  97  Time:  1.095  Rel. Train L2 Loss :  0.02823147703376081  Rel. Test L2 Loss :  0.041391843259334565  Test L2 Loss :  0.0763430941104889  inv_L_scale:  [1.0, 1.0]
Epoch :  98  Time:  1.095  Rel. Train L2 Loss :  0.027826757546928194  Rel. Test L2 Loss :  0.031001678705215453  Test L2 Loss :  0.05511321857571602  inv_L_scale:  [1.0, 1.0]
Epoch :  99  Time:  1.096  Rel. Train L2 Loss :  0.026616177592012617  Rel. Test L2 Loss :  0.02904914744198322  Test L2 Loss :  0.05212003841996193  inv_L_scale:  [1.0, 1.0]
Epoch :  100  Time:  1.093  Rel. Train L2 Loss :  0.027138286050823  Rel. Test L2 Loss :  0.03207728385925293  Test L2 Loss :  0.0582318788766861  inv_L_scale:  [1.0, 1.0]
Epoch :  101  Time:  1.094  Rel. Train L2 Loss :  0.026991727815734015  Rel. Test L2 Loss :  0.03046473741531372  Test L2 Loss :  0.05520922645926476  inv_L_scale:  [1.0, 1.0]
Epoch :  102  Time:  1.095  Rel. Train L2 Loss :  0.027461496624681683  Rel. Test L2 Loss :  0.03046404369175434  Test L2 Loss :  0.05468855395913124  inv_L_scale:  [1.0, 1.0]
Epoch :  103  Time:  1.092  Rel. Train L2 Loss :  0.02755752361483044  Rel. Test L2 Loss :  0.0321121820807457  Test L2 Loss :  0.05921279728412628  inv_L_scale:  [1.0, 1.0]
Epoch :  104  Time:  1.095  Rel. Train L2 Loss :  0.026985358910428154  Rel. Test L2 Loss :  0.028012731820344926  Test L2 Loss :  0.049677596986293794  inv_L_scale:  [1.0, 1.0]
Epoch :  105  Time:  1.095  Rel. Train L2 Loss :  0.02693534372581376  Rel. Test L2 Loss :  0.031039307042956352  Test L2 Loss :  0.05574061781167984  inv_L_scale:  [1.0, 1.0]
Epoch :  106  Time:  1.094  Rel. Train L2 Loss :  0.02853289326859845  Rel. Test L2 Loss :  0.028354325890541078  Test L2 Loss :  0.050258129239082336  inv_L_scale:  [1.0, 1.0]
Epoch :  107  Time:  1.094  Rel. Train L2 Loss :  0.02684735403292709  Rel. Test L2 Loss :  0.02734728395938873  Test L2 Loss :  0.04944564670324326  inv_L_scale:  [1.0, 1.0]
Epoch :  108  Time:  1.094  Rel. Train L2 Loss :  0.02648023557331827  Rel. Test L2 Loss :  0.02752313733100891  Test L2 Loss :  0.04894109755754471  inv_L_scale:  [1.0, 1.0]
Epoch :  109  Time:  1.095  Rel. Train L2 Loss :  0.024390389513638283  Rel. Test L2 Loss :  0.025635035559535026  Test L2 Loss :  0.045565506517887114  inv_L_scale:  [1.0, 1.0]
Epoch :  110  Time:  1.097  Rel. Train L2 Loss :  0.025268768303924136  Rel. Test L2 Loss :  0.028547584116458892  Test L2 Loss :  0.05119006931781769  inv_L_scale:  [1.0, 1.0]
Epoch :  111  Time:  1.096  Rel. Train L2 Loss :  0.025647278941339918  Rel. Test L2 Loss :  0.029519483596086502  Test L2 Loss :  0.053168559223413465  inv_L_scale:  [1.0, 1.0]
Epoch :  112  Time:  1.094  Rel. Train L2 Loss :  0.025569201616777313  Rel. Test L2 Loss :  0.02985514432191849  Test L2 Loss :  0.05457739919424057  inv_L_scale:  [1.0, 1.0]
Epoch :  113  Time:  1.094  Rel. Train L2 Loss :  0.025757836898167928  Rel. Test L2 Loss :  0.02581609822809696  Test L2 Loss :  0.046302911341190335  inv_L_scale:  [1.0, 1.0]
Epoch :  114  Time:  1.095  Rel. Train L2 Loss :  0.026433823191457324  Rel. Test L2 Loss :  0.029297846108675002  Test L2 Loss :  0.05210264638066292  inv_L_scale:  [1.0, 1.0]
Epoch :  115  Time:  1.094  Rel. Train L2 Loss :  0.02485391713678837  Rel. Test L2 Loss :  0.02505648598074913  Test L2 Loss :  0.04458332389593125  inv_L_scale:  [1.0, 1.0]
Epoch :  116  Time:  1.095  Rel. Train L2 Loss :  0.025550719698270163  Rel. Test L2 Loss :  0.030459281280636786  Test L2 Loss :  0.055903040170669556  inv_L_scale:  [1.0, 1.0]
Epoch :  117  Time:  1.094  Rel. Train L2 Loss :  0.024620406793223488  Rel. Test L2 Loss :  0.026351126581430434  Test L2 Loss :  0.04697198554873466  inv_L_scale:  [1.0, 1.0]
Epoch :  118  Time:  1.094  Rel. Train L2 Loss :  0.025221536664499177  Rel. Test L2 Loss :  0.026887823566794394  Test L2 Loss :  0.04831592231988907  inv_L_scale:  [1.0, 1.0]
Epoch :  119  Time:  1.094  Rel. Train L2 Loss :  0.024826967558927007  Rel. Test L2 Loss :  0.025067651718854903  Test L2 Loss :  0.044891043156385424  inv_L_scale:  [1.0, 1.0]
Epoch :  120  Time:  1.094  Rel. Train L2 Loss :  0.024990146044227814  Rel. Test L2 Loss :  0.0279722860455513  Test L2 Loss :  0.05020169317722321  inv_L_scale:  [1.0, 1.0]
Epoch :  121  Time:  1.094  Rel. Train L2 Loss :  0.02520065438416269  Rel. Test L2 Loss :  0.02662805259227753  Test L2 Loss :  0.04769057616591454  inv_L_scale:  [1.0, 1.0]
Epoch :  122  Time:  1.095  Rel. Train L2 Loss :  0.023955195198456448  Rel. Test L2 Loss :  0.027072056457400323  Test L2 Loss :  0.04793381899595261  inv_L_scale:  [1.0, 1.0]
Epoch :  123  Time:  1.094  Rel. Train L2 Loss :  0.024656136284271876  Rel. Test L2 Loss :  0.027533351629972457  Test L2 Loss :  0.04883743569254875  inv_L_scale:  [1.0, 1.0]
Epoch :  124  Time:  1.095  Rel. Train L2 Loss :  0.02483045363591777  Rel. Test L2 Loss :  0.02535486400127411  Test L2 Loss :  0.045460743606090544  inv_L_scale:  [1.0, 1.0]
Epoch :  125  Time:  1.094  Rel. Train L2 Loss :  0.024006207353538936  Rel. Test L2 Loss :  0.025951391980051995  Test L2 Loss :  0.04639390677213669  inv_L_scale:  [1.0, 1.0]
Epoch :  126  Time:  1.094  Rel. Train L2 Loss :  0.02379531351228555  Rel. Test L2 Loss :  0.02764167293906212  Test L2 Loss :  0.049376240819692614  inv_L_scale:  [1.0, 1.0]
Epoch :  127  Time:  1.094  Rel. Train L2 Loss :  0.025282346432407697  Rel. Test L2 Loss :  0.030335932672023773  Test L2 Loss :  0.054840300679206845  inv_L_scale:  [1.0, 1.0]
Epoch :  128  Time:  1.096  Rel. Train L2 Loss :  0.02493432520992226  Rel. Test L2 Loss :  0.025410966575145723  Test L2 Loss :  0.04528010293841362  inv_L_scale:  [1.0, 1.0]
Epoch :  129  Time:  1.094  Rel. Train L2 Loss :  0.024577573430207042  Rel. Test L2 Loss :  0.026899946480989458  Test L2 Loss :  0.04909628629684448  inv_L_scale:  [1.0, 1.0]
Epoch :  130  Time:  1.094  Rel. Train L2 Loss :  0.02354116557372941  Rel. Test L2 Loss :  0.02778580576181412  Test L2 Loss :  0.050690420269966126  inv_L_scale:  [1.0, 1.0]
Epoch :  131  Time:  1.094  Rel. Train L2 Loss :  0.02399892489115397  Rel. Test L2 Loss :  0.026408794447779656  Test L2 Loss :  0.04742540836334228  inv_L_scale:  [1.0, 1.0]
Epoch :  132  Time:  1.094  Rel. Train L2 Loss :  0.023322357046935294  Rel. Test L2 Loss :  0.024045089483261107  Test L2 Loss :  0.04277620762586594  inv_L_scale:  [1.0, 1.0]
Epoch :  133  Time:  1.094  Rel. Train L2 Loss :  0.02389988692270385  Rel. Test L2 Loss :  0.022646365761756895  Test L2 Loss :  0.04025586187839508  inv_L_scale:  [1.0, 1.0]
Epoch :  134  Time:  1.095  Rel. Train L2 Loss :  0.02334705063038402  Rel. Test L2 Loss :  0.028792645409703256  Test L2 Loss :  0.052207974642515184  inv_L_scale:  [1.0, 1.0]
Epoch :  135  Time:  1.096  Rel. Train L2 Loss :  0.023586652105053264  Rel. Test L2 Loss :  0.023964340686798095  Test L2 Loss :  0.04241944894194603  inv_L_scale:  [1.0, 1.0]
Epoch :  136  Time:  1.095  Rel. Train L2 Loss :  0.02350134978691737  Rel. Test L2 Loss :  0.03063291922211647  Test L2 Loss :  0.05650695323944092  inv_L_scale:  [1.0, 1.0]
Epoch :  137  Time:  1.093  Rel. Train L2 Loss :  0.024898733786410755  Rel. Test L2 Loss :  0.02579112060368061  Test L2 Loss :  0.045865847170352934  inv_L_scale:  [1.0, 1.0]
Epoch :  138  Time:  1.094  Rel. Train L2 Loss :  0.02405464384290907  Rel. Test L2 Loss :  0.024762421995401383  Test L2 Loss :  0.04396553039550781  inv_L_scale:  [1.0, 1.0]
Epoch :  139  Time:  1.094  Rel. Train L2 Loss :  0.023430935690800347  Rel. Test L2 Loss :  0.027208028584718703  Test L2 Loss :  0.04963059037923813  inv_L_scale:  [1.0, 1.0]
Epoch :  140  Time:  1.094  Rel. Train L2 Loss :  0.023424226426415975  Rel. Test L2 Loss :  0.02610260158777237  Test L2 Loss :  0.04672156542539597  inv_L_scale:  [1.0, 1.0]
Epoch :  141  Time:  1.094  Rel. Train L2 Loss :  0.023931203476256796  Rel. Test L2 Loss :  0.026728345304727553  Test L2 Loss :  0.04805493414402008  inv_L_scale:  [1.0, 1.0]
Epoch :  142  Time:  1.095  Rel. Train L2 Loss :  0.02387622152765592  Rel. Test L2 Loss :  0.023271647095680238  Test L2 Loss :  0.04123245820403099  inv_L_scale:  [1.0, 1.0]
Epoch :  143  Time:  1.094  Rel. Train L2 Loss :  0.022844663908084234  Rel. Test L2 Loss :  0.02408974587917328  Test L2 Loss :  0.04217874184250832  inv_L_scale:  [1.0, 1.0]
Epoch :  144  Time:  1.095  Rel. Train L2 Loss :  0.02301718911363019  Rel. Test L2 Loss :  0.023892868384718893  Test L2 Loss :  0.042420469671487805  inv_L_scale:  [1.0, 1.0]
Epoch :  145  Time:  1.094  Rel. Train L2 Loss :  0.023308403939008713  Rel. Test L2 Loss :  0.02447423920035362  Test L2 Loss :  0.04367979899048805  inv_L_scale:  [1.0, 1.0]
Epoch :  146  Time:  1.094  Rel. Train L2 Loss :  0.02241625470419725  Rel. Test L2 Loss :  0.023460552021861078  Test L2 Loss :  0.041295119076967236  inv_L_scale:  [1.0, 1.0]
Epoch :  147  Time:  1.094  Rel. Train L2 Loss :  0.022262904933757252  Rel. Test L2 Loss :  0.022973441183567048  Test L2 Loss :  0.04092536151409149  inv_L_scale:  [1.0, 1.0]
Epoch :  148  Time:  1.094  Rel. Train L2 Loss :  0.022844358326660263  Rel. Test L2 Loss :  0.024676282107830048  Test L2 Loss :  0.04386462181806564  inv_L_scale:  [1.0, 1.0]
Epoch :  149  Time:  1.094  Rel. Train L2 Loss :  0.02283541039460235  Rel. Test L2 Loss :  0.023304384872317313  Test L2 Loss :  0.041371467113494875  inv_L_scale:  [1.0, 1.0]
Epoch :  150  Time:  1.095  Rel. Train L2 Loss :  0.022390289157629015  Rel. Test L2 Loss :  0.024081680104136468  Test L2 Loss :  0.04285905882716179  inv_L_scale:  [1.0, 1.0]
Epoch :  151  Time:  1.094  Rel. Train L2 Loss :  0.022032216067115466  Rel. Test L2 Loss :  0.026076548993587495  Test L2 Loss :  0.04658502250909805  inv_L_scale:  [1.0, 1.0]
Epoch :  152  Time:  1.094  Rel. Train L2 Loss :  0.022480478940738572  Rel. Test L2 Loss :  0.02449958920478821  Test L2 Loss :  0.04361590296030045  inv_L_scale:  [1.0, 1.0]
Epoch :  153  Time:  1.094  Rel. Train L2 Loss :  0.02272512238058779  Rel. Test L2 Loss :  0.022971949577331542  Test L2 Loss :  0.040537775456905366  inv_L_scale:  [1.0, 1.0]
Epoch :  154  Time:  1.094  Rel. Train L2 Loss :  0.02226361061135928  Rel. Test L2 Loss :  0.024317529276013373  Test L2 Loss :  0.044156150817871095  inv_L_scale:  [1.0, 1.0]
Epoch :  155  Time:  1.093  Rel. Train L2 Loss :  0.021856931464539636  Rel. Test L2 Loss :  0.025154058933258058  Test L2 Loss :  0.04453427493572235  inv_L_scale:  [1.0, 1.0]
Epoch :  156  Time:  1.094  Rel. Train L2 Loss :  0.02230205794175466  Rel. Test L2 Loss :  0.02479686863720417  Test L2 Loss :  0.04426778689026833  inv_L_scale:  [1.0, 1.0]
Epoch :  157  Time:  1.096  Rel. Train L2 Loss :  0.021733872319261233  Rel. Test L2 Loss :  0.023868116065859795  Test L2 Loss :  0.04249377623200416  inv_L_scale:  [1.0, 1.0]
Epoch :  158  Time:  1.095  Rel. Train L2 Loss :  0.02267029895550675  Rel. Test L2 Loss :  0.02439092308282852  Test L2 Loss :  0.043058600723743436  inv_L_scale:  [1.0, 1.0]
Epoch :  159  Time:  1.094  Rel. Train L2 Loss :  0.022366206455561848  Rel. Test L2 Loss :  0.023695115745067597  Test L2 Loss :  0.041815584301948545  inv_L_scale:  [1.0, 1.0]
Epoch :  160  Time:  1.094  Rel. Train L2 Loss :  0.022467130935854382  Rel. Test L2 Loss :  0.02323782756924629  Test L2 Loss :  0.041274622678756714  inv_L_scale:  [1.0, 1.0]
Epoch :  161  Time:  1.094  Rel. Train L2 Loss :  0.021780761033296583  Rel. Test L2 Loss :  0.023688626736402513  Test L2 Loss :  0.041992618441581725  inv_L_scale:  [1.0, 1.0]
Epoch :  162  Time:  1.094  Rel. Train L2 Loss :  0.022249625821908314  Rel. Test L2 Loss :  0.023109999746084214  Test L2 Loss :  0.0412170547246933  inv_L_scale:  [1.0, 1.0]
Epoch :  163  Time:  1.094  Rel. Train L2 Loss :  0.02216106788151794  Rel. Test L2 Loss :  0.021771727502346037  Test L2 Loss :  0.03880707278847694  inv_L_scale:  [1.0, 1.0]
Epoch :  164  Time:  1.094  Rel. Train L2 Loss :  0.02182142370276981  Rel. Test L2 Loss :  0.022639620155096053  Test L2 Loss :  0.0403705133497715  inv_L_scale:  [1.0, 1.0]
Epoch :  165  Time:  1.096  Rel. Train L2 Loss :  0.02255982193681929  Rel. Test L2 Loss :  0.02322817400097847  Test L2 Loss :  0.041032887399196624  inv_L_scale:  [1.0, 1.0]
Epoch :  166  Time:  1.096  Rel. Train L2 Loss :  0.022689869834317103  Rel. Test L2 Loss :  0.02318762622773647  Test L2 Loss :  0.04090466529130936  inv_L_scale:  [1.0, 1.0]
Epoch :  167  Time:  1.094  Rel. Train L2 Loss :  0.021814316676722633  Rel. Test L2 Loss :  0.02284915491938591  Test L2 Loss :  0.04110452443361282  inv_L_scale:  [1.0, 1.0]
Epoch :  168  Time:  1.094  Rel. Train L2 Loss :  0.021729633104470042  Rel. Test L2 Loss :  0.023205236569046973  Test L2 Loss :  0.04115956500172615  inv_L_scale:  [1.0, 1.0]
Epoch :  169  Time:  1.093  Rel. Train L2 Loss :  0.021588573530316353  Rel. Test L2 Loss :  0.022425724416971205  Test L2 Loss :  0.040056309700012206  inv_L_scale:  [1.0, 1.0]
Epoch :  170  Time:  1.094  Rel. Train L2 Loss :  0.021725019539395967  Rel. Test L2 Loss :  0.021945666521787643  Test L2 Loss :  0.038972111344337465  inv_L_scale:  [1.0, 1.0]
Epoch :  171  Time:  1.094  Rel. Train L2 Loss :  0.02230297424727016  Rel. Test L2 Loss :  0.02263983592391014  Test L2 Loss :  0.040571295171976086  inv_L_scale:  [1.0, 1.0]
Epoch :  172  Time:  1.094  Rel. Train L2 Loss :  0.02206579037838512  Rel. Test L2 Loss :  0.023548960238695144  Test L2 Loss :  0.042005510330200196  inv_L_scale:  [1.0, 1.0]
Epoch :  173  Time:  1.094  Rel. Train L2 Loss :  0.02131946916381518  Rel. Test L2 Loss :  0.02395934596657753  Test L2 Loss :  0.043220442235469815  inv_L_scale:  [1.0, 1.0]
Epoch :  174  Time:  1.095  Rel. Train L2 Loss :  0.02150335228277577  Rel. Test L2 Loss :  0.023052090108394624  Test L2 Loss :  0.04104912176728249  inv_L_scale:  [1.0, 1.0]
Epoch :  175  Time:  1.094  Rel. Train L2 Loss :  0.021013570328553517  Rel. Test L2 Loss :  0.023433928340673447  Test L2 Loss :  0.042070855796337125  inv_L_scale:  [1.0, 1.0]
Epoch :  176  Time:  1.095  Rel. Train L2 Loss :  0.021848996496862835  Rel. Test L2 Loss :  0.023042123317718505  Test L2 Loss :  0.04106810957193375  inv_L_scale:  [1.0, 1.0]
Epoch :  177  Time:  1.094  Rel. Train L2 Loss :  0.020719460911220976  Rel. Test L2 Loss :  0.023327920883893967  Test L2 Loss :  0.04140689045190811  inv_L_scale:  [1.0, 1.0]
Epoch :  178  Time:  1.094  Rel. Train L2 Loss :  0.021391062827573883  Rel. Test L2 Loss :  0.023020108044147492  Test L2 Loss :  0.04150817051529884  inv_L_scale:  [1.0, 1.0]
Epoch :  179  Time:  1.094  Rel. Train L2 Loss :  0.02192081512676345  Rel. Test L2 Loss :  0.025604767352342607  Test L2 Loss :  0.046073157191276554  inv_L_scale:  [1.0, 1.0]
Epoch :  180  Time:  1.094  Rel. Train L2 Loss :  0.021432886314060953  Rel. Test L2 Loss :  0.021183777526021005  Test L2 Loss :  0.0375766584277153  inv_L_scale:  [1.0, 1.0]
Epoch :  181  Time:  1.094  Rel. Train L2 Loss :  0.020486956710616747  Rel. Test L2 Loss :  0.02525039404630661  Test L2 Loss :  0.04530701190233231  inv_L_scale:  [1.0, 1.0]
Epoch :  182  Time:  1.094  Rel. Train L2 Loss :  0.02066812365419335  Rel. Test L2 Loss :  0.025084698498249056  Test L2 Loss :  0.044789781123399736  inv_L_scale:  [1.0, 1.0]
Epoch :  183  Time:  1.095  Rel. Train L2 Loss :  0.02099198079771466  Rel. Test L2 Loss :  0.022848069220781326  Test L2 Loss :  0.041163558810949324  inv_L_scale:  [1.0, 1.0]
Epoch :  184  Time:  1.095  Rel. Train L2 Loss :  0.020327427751488155  Rel. Test L2 Loss :  0.021303143203258514  Test L2 Loss :  0.03771270543336868  inv_L_scale:  [1.0, 1.0]
Epoch :  185  Time:  1.094  Rel. Train L2 Loss :  0.0205649804075559  Rel. Test L2 Loss :  0.02141682952642441  Test L2 Loss :  0.038028482794761655  inv_L_scale:  [1.0, 1.0]
Epoch :  186  Time:  1.095  Rel. Train L2 Loss :  0.02083496314783891  Rel. Test L2 Loss :  0.02522620737552643  Test L2 Loss :  0.045806409120559693  inv_L_scale:  [1.0, 1.0]
Epoch :  187  Time:  1.094  Rel. Train L2 Loss :  0.02046561429070102  Rel. Test L2 Loss :  0.020644761472940445  Test L2 Loss :  0.03645225316286087  inv_L_scale:  [1.0, 1.0]
Epoch :  188  Time:  1.094  Rel. Train L2 Loss :  0.01999713404311074  Rel. Test L2 Loss :  0.021832673475146294  Test L2 Loss :  0.03907401978969574  inv_L_scale:  [1.0, 1.0]
Epoch :  189  Time:  1.094  Rel. Train L2 Loss :  0.020370527555545172  Rel. Test L2 Loss :  0.0205180124938488  Test L2 Loss :  0.03654699981212616  inv_L_scale:  [1.0, 1.0]
Epoch :  190  Time:  1.094  Rel. Train L2 Loss :  0.021011078167292807  Rel. Test L2 Loss :  0.021461244970560074  Test L2 Loss :  0.03797488123178482  inv_L_scale:  [1.0, 1.0]
Epoch :  191  Time:  1.095  Rel. Train L2 Loss :  0.019914513871901567  Rel. Test L2 Loss :  0.021041753962635995  Test L2 Loss :  0.0375047767162323  inv_L_scale:  [1.0, 1.0]
Epoch :  192  Time:  1.094  Rel. Train L2 Loss :  0.020878872291909323  Rel. Test L2 Loss :  0.02323127880692482  Test L2 Loss :  0.04157535567879677  inv_L_scale:  [1.0, 1.0]
Epoch :  193  Time:  1.094  Rel. Train L2 Loss :  0.020450333940486114  Rel. Test L2 Loss :  0.02154212221503258  Test L2 Loss :  0.038115196228027344  inv_L_scale:  [1.0, 1.0]
Epoch :  194  Time:  1.094  Rel. Train L2 Loss :  0.02084727963225709  Rel. Test L2 Loss :  0.023938403725624086  Test L2 Loss :  0.04281367659568787  inv_L_scale:  [1.0, 1.0]
Epoch :  195  Time:  1.094  Rel. Train L2 Loss :  0.020682449895474644  Rel. Test L2 Loss :  0.020981543511152268  Test L2 Loss :  0.03698653146624565  inv_L_scale:  [1.0, 1.0]
Epoch :  196  Time:  1.094  Rel. Train L2 Loss :  0.020695644070704778  Rel. Test L2 Loss :  0.021589568853378295  Test L2 Loss :  0.03848915338516235  inv_L_scale:  [1.0, 1.0]
Epoch :  197  Time:  1.094  Rel. Train L2 Loss :  0.020115415073103375  Rel. Test L2 Loss :  0.022660452723503113  Test L2 Loss :  0.04017023041844368  inv_L_scale:  [1.0, 1.0]
Epoch :  198  Time:  1.094  Rel. Train L2 Loss :  0.02040746265815364  Rel. Test L2 Loss :  0.023384433537721634  Test L2 Loss :  0.04134062573313713  inv_L_scale:  [1.0, 1.0]
Epoch :  199  Time:  1.095  Rel. Train L2 Loss :  0.020843233846955828  Rel. Test L2 Loss :  0.023785826936364173  Test L2 Loss :  0.042971826791763305  inv_L_scale:  [1.0, 1.0]
Epoch :  200  Time:  1.094  Rel. Train L2 Loss :  0.020232438445091247  Rel. Test L2 Loss :  0.02122135803103447  Test L2 Loss :  0.03777859807014465  inv_L_scale:  [1.0, 1.0]
Epoch :  201  Time:  1.096  Rel. Train L2 Loss :  0.020478952593273588  Rel. Test L2 Loss :  0.020235860347747804  Test L2 Loss :  0.03590873971581459  inv_L_scale:  [1.0, 1.0]
Epoch :  202  Time:  1.096  Rel. Train L2 Loss :  0.019974033791157933  Rel. Test L2 Loss :  0.02246671065688133  Test L2 Loss :  0.04029155999422073  inv_L_scale:  [1.0, 1.0]
Epoch :  203  Time:  1.094  Rel. Train L2 Loss :  0.020421372503042223  Rel. Test L2 Loss :  0.025533197075128557  Test L2 Loss :  0.045716444700956343  inv_L_scale:  [1.0, 1.0]
Epoch :  204  Time:  1.094  Rel. Train L2 Loss :  0.02027401382724444  Rel. Test L2 Loss :  0.02053005203604698  Test L2 Loss :  0.036297560036182404  inv_L_scale:  [1.0, 1.0]
Epoch :  205  Time:  1.094  Rel. Train L2 Loss :  0.020276876125070783  Rel. Test L2 Loss :  0.020550854802131653  Test L2 Loss :  0.03635454922914505  inv_L_scale:  [1.0, 1.0]
Epoch :  206  Time:  1.094  Rel. Train L2 Loss :  0.019809981137514115  Rel. Test L2 Loss :  0.022199579402804374  Test L2 Loss :  0.04043822973966599  inv_L_scale:  [1.0, 1.0]
Epoch :  207  Time:  1.095  Rel. Train L2 Loss :  0.020712293287118277  Rel. Test L2 Loss :  0.02165211021900177  Test L2 Loss :  0.03847855806350708  inv_L_scale:  [1.0, 1.0]
Epoch :  208  Time:  1.094  Rel. Train L2 Loss :  0.019767075181007385  Rel. Test L2 Loss :  0.020755087435245515  Test L2 Loss :  0.03702566713094711  inv_L_scale:  [1.0, 1.0]
Epoch :  209  Time:  1.094  Rel. Train L2 Loss :  0.020072233536177212  Rel. Test L2 Loss :  0.022924531996250153  Test L2 Loss :  0.041394007503986356  inv_L_scale:  [1.0, 1.0]
Epoch :  210  Time:  1.096  Rel. Train L2 Loss :  0.020013952395982214  Rel. Test L2 Loss :  0.021533393189311027  Test L2 Loss :  0.03811431959271431  inv_L_scale:  [1.0, 1.0]
Epoch :  211  Time:  1.094  Rel. Train L2 Loss :  0.019676245599985123  Rel. Test L2 Loss :  0.020662454515695573  Test L2 Loss :  0.036702905148267746  inv_L_scale:  [1.0, 1.0]
Epoch :  212  Time:  1.094  Rel. Train L2 Loss :  0.019762095130152174  Rel. Test L2 Loss :  0.020765264332294465  Test L2 Loss :  0.03670338451862335  inv_L_scale:  [1.0, 1.0]
Epoch :  213  Time:  1.093  Rel. Train L2 Loss :  0.01972523616419898  Rel. Test L2 Loss :  0.021017096489667892  Test L2 Loss :  0.037116741091012956  inv_L_scale:  [1.0, 1.0]
Epoch :  214  Time:  1.093  Rel. Train L2 Loss :  0.01946473525216182  Rel. Test L2 Loss :  0.019401523545384408  Test L2 Loss :  0.03422106146812439  inv_L_scale:  [1.0, 1.0]
Epoch :  215  Time:  1.093  Rel. Train L2 Loss :  0.019479173256291282  Rel. Test L2 Loss :  0.02061210885643959  Test L2 Loss :  0.03649690240621567  inv_L_scale:  [1.0, 1.0]
Epoch :  216  Time:  1.093  Rel. Train L2 Loss :  0.019347145164178476  Rel. Test L2 Loss :  0.02026673324406147  Test L2 Loss :  0.03588719129562378  inv_L_scale:  [1.0, 1.0]
Epoch :  217  Time:  1.093  Rel. Train L2 Loss :  0.019540267942680253  Rel. Test L2 Loss :  0.019577981755137443  Test L2 Loss :  0.03472055934369564  inv_L_scale:  [1.0, 1.0]
Epoch :  218  Time:  1.092  Rel. Train L2 Loss :  0.01971276897109217  Rel. Test L2 Loss :  0.02181200459599495  Test L2 Loss :  0.03872722238302231  inv_L_scale:  [1.0, 1.0]
Epoch :  219  Time:  1.092  Rel. Train L2 Loss :  0.019791500278645093  Rel. Test L2 Loss :  0.020832220315933226  Test L2 Loss :  0.036908053755760194  inv_L_scale:  [1.0, 1.0]
Epoch :  220  Time:  1.092  Rel. Train L2 Loss :  0.019391876351502208  Rel. Test L2 Loss :  0.020323625355958937  Test L2 Loss :  0.03595832645893097  inv_L_scale:  [1.0, 1.0]
Epoch :  221  Time:  1.092  Rel. Train L2 Loss :  0.019997778543167644  Rel. Test L2 Loss :  0.021393513455986977  Test L2 Loss :  0.038136148154735566  inv_L_scale:  [1.0, 1.0]
Epoch :  222  Time:  1.093  Rel. Train L2 Loss :  0.020025610095924802  Rel. Test L2 Loss :  0.0216737462580204  Test L2 Loss :  0.03865321934223175  inv_L_scale:  [1.0, 1.0]
Epoch :  223  Time:  1.093  Rel. Train L2 Loss :  0.019405225796831977  Rel. Test L2 Loss :  0.021788694858551026  Test L2 Loss :  0.03872964382171631  inv_L_scale:  [1.0, 1.0]
Epoch :  224  Time:  1.092  Rel. Train L2 Loss :  0.019215438870920077  Rel. Test L2 Loss :  0.020021255314350127  Test L2 Loss :  0.035332113802433014  inv_L_scale:  [1.0, 1.0]
Epoch :  225  Time:  1.092  Rel. Train L2 Loss :  0.019195522434181638  Rel. Test L2 Loss :  0.02210222452878952  Test L2 Loss :  0.03949267894029617  inv_L_scale:  [1.0, 1.0]
Epoch :  226  Time:  1.092  Rel. Train L2 Loss :  0.019154979992243977  Rel. Test L2 Loss :  0.02229737088084221  Test L2 Loss :  0.03949579447507858  inv_L_scale:  [1.0, 1.0]
Epoch :  227  Time:  1.092  Rel. Train L2 Loss :  0.019178001922037866  Rel. Test L2 Loss :  0.02032918594777584  Test L2 Loss :  0.03624046742916107  inv_L_scale:  [1.0, 1.0]
Epoch :  228  Time:  1.092  Rel. Train L2 Loss :  0.019194415973292456  Rel. Test L2 Loss :  0.021237132996320726  Test L2 Loss :  0.037703381180763246  inv_L_scale:  [1.0, 1.0]
Epoch :  229  Time:  1.092  Rel. Train L2 Loss :  0.01942430770231618  Rel. Test L2 Loss :  0.021133109629154205  Test L2 Loss :  0.03719625562429428  inv_L_scale:  [1.0, 1.0]
Epoch :  230  Time:  1.092  Rel. Train L2 Loss :  0.018593600094318388  Rel. Test L2 Loss :  0.020067981854081155  Test L2 Loss :  0.03569643780589104  inv_L_scale:  [1.0, 1.0]
Epoch :  231  Time:  1.092  Rel. Train L2 Loss :  0.019040273370014297  Rel. Test L2 Loss :  0.01928040534257889  Test L2 Loss :  0.03412119925022125  inv_L_scale:  [1.0, 1.0]
Epoch :  232  Time:  1.094  Rel. Train L2 Loss :  0.018789334189560677  Rel. Test L2 Loss :  0.019218582659959793  Test L2 Loss :  0.033865428119897845  inv_L_scale:  [1.0, 1.0]
Epoch :  233  Time:  1.094  Rel. Train L2 Loss :  0.01894800446099705  Rel. Test L2 Loss :  0.01909184493124485  Test L2 Loss :  0.0340019029378891  inv_L_scale:  [1.0, 1.0]
Epoch :  234  Time:  1.093  Rel. Train L2 Loss :  0.01864777529405223  Rel. Test L2 Loss :  0.019696325734257697  Test L2 Loss :  0.03505090825259685  inv_L_scale:  [1.0, 1.0]
Epoch :  235  Time:  1.092  Rel. Train L2 Loss :  0.018414426926109527  Rel. Test L2 Loss :  0.01915363185107708  Test L2 Loss :  0.033828775361180306  inv_L_scale:  [1.0, 1.0]
Epoch :  236  Time:  1.091  Rel. Train L2 Loss :  0.018782023092110953  Rel. Test L2 Loss :  0.019887394085526467  Test L2 Loss :  0.035161619633436204  inv_L_scale:  [1.0, 1.0]
Epoch :  237  Time:  1.091  Rel. Train L2 Loss :  0.01928708687838581  Rel. Test L2 Loss :  0.019988096952438354  Test L2 Loss :  0.035590661764144896  inv_L_scale:  [1.0, 1.0]
Epoch :  238  Time:  1.092  Rel. Train L2 Loss :  0.018467319077915614  Rel. Test L2 Loss :  0.01837597891688347  Test L2 Loss :  0.03228942066431045  inv_L_scale:  [1.0, 1.0]
Epoch :  239  Time:  1.091  Rel. Train L2 Loss :  0.018117004566722446  Rel. Test L2 Loss :  0.019607511907815935  Test L2 Loss :  0.03449506819248199  inv_L_scale:  [1.0, 1.0]
Epoch :  240  Time:  1.091  Rel. Train L2 Loss :  0.018533414726456008  Rel. Test L2 Loss :  0.019412528648972513  Test L2 Loss :  0.03423585429787636  inv_L_scale:  [1.0, 1.0]
Epoch :  241  Time:  1.091  Rel. Train L2 Loss :  0.018546100325054594  Rel. Test L2 Loss :  0.02150954566895962  Test L2 Loss :  0.03853111281991005  inv_L_scale:  [1.0, 1.0]
Epoch :  242  Time:  1.092  Rel. Train L2 Loss :  0.019001345485448837  Rel. Test L2 Loss :  0.020176019892096518  Test L2 Loss :  0.03560358375310898  inv_L_scale:  [1.0, 1.0]
Epoch :  243  Time:  1.091  Rel. Train L2 Loss :  0.019433103932274712  Rel. Test L2 Loss :  0.020466757342219352  Test L2 Loss :  0.03654639482498169  inv_L_scale:  [1.0, 1.0]
Epoch :  244  Time:  1.091  Rel. Train L2 Loss :  0.018983778605858485  Rel. Test L2 Loss :  0.020068587735295296  Test L2 Loss :  0.03546393737196922  inv_L_scale:  [1.0, 1.0]
Epoch :  245  Time:  1.097  Rel. Train L2 Loss :  0.01906054690480232  Rel. Test L2 Loss :  0.01880838967859745  Test L2 Loss :  0.03327824138104916  inv_L_scale:  [1.0, 1.0]
Epoch :  246  Time:  1.094  Rel. Train L2 Loss :  0.018769479278061125  Rel. Test L2 Loss :  0.021242640018463134  Test L2 Loss :  0.03759203016757965  inv_L_scale:  [1.0, 1.0]
Epoch :  247  Time:  1.094  Rel. Train L2 Loss :  0.018904135036799642  Rel. Test L2 Loss :  0.019915601089596748  Test L2 Loss :  0.035420533716678616  inv_L_scale:  [1.0, 1.0]
Epoch :  248  Time:  1.094  Rel. Train L2 Loss :  0.018329936125212245  Rel. Test L2 Loss :  0.020941749215126038  Test L2 Loss :  0.037382197827100755  inv_L_scale:  [1.0, 1.0]
Epoch :  249  Time:  1.094  Rel. Train L2 Loss :  0.018403826364212564  Rel. Test L2 Loss :  0.01997449144721031  Test L2 Loss :  0.03564871162176132  inv_L_scale:  [1.0, 1.0]
Epoch :  250  Time:  1.094  Rel. Train L2 Loss :  0.018003442957997322  Rel. Test L2 Loss :  0.018897413834929468  Test L2 Loss :  0.033452786207199096  inv_L_scale:  [1.0, 1.0]
Epoch :  251  Time:  1.094  Rel. Train L2 Loss :  0.018258416433301238  Rel. Test L2 Loss :  0.018835755586624144  Test L2 Loss :  0.033303458094596866  inv_L_scale:  [1.0, 1.0]
Epoch :  252  Time:  1.094  Rel. Train L2 Loss :  0.018130684759881763  Rel. Test L2 Loss :  0.01824921488761902  Test L2 Loss :  0.03229061588644981  inv_L_scale:  [1.0, 1.0]
Epoch :  253  Time:  1.093  Rel. Train L2 Loss :  0.01824410975807243  Rel. Test L2 Loss :  0.019052372425794602  Test L2 Loss :  0.03351232811808586  inv_L_scale:  [1.0, 1.0]
Epoch :  254  Time:  1.093  Rel. Train L2 Loss :  0.01828399827496873  Rel. Test L2 Loss :  0.02002132385969162  Test L2 Loss :  0.03548450887203217  inv_L_scale:  [1.0, 1.0]
Epoch :  255  Time:  1.094  Rel. Train L2 Loss :  0.0180705250468519  Rel. Test L2 Loss :  0.02306452304124832  Test L2 Loss :  0.042414038479328155  inv_L_scale:  [1.0, 1.0]
Epoch :  256  Time:  1.094  Rel. Train L2 Loss :  0.018423976625005403  Rel. Test L2 Loss :  0.01875969026237726  Test L2 Loss :  0.033259746804833415  inv_L_scale:  [1.0, 1.0]
Epoch :  257  Time:  1.094  Rel. Train L2 Loss :  0.01817508026957512  Rel. Test L2 Loss :  0.020323866680264473  Test L2 Loss :  0.03624491825699806  inv_L_scale:  [1.0, 1.0]
Epoch :  258  Time:  1.094  Rel. Train L2 Loss :  0.018458783212635253  Rel. Test L2 Loss :  0.01920819506049156  Test L2 Loss :  0.03392238602042198  inv_L_scale:  [1.0, 1.0]
Epoch :  259  Time:  1.094  Rel. Train L2 Loss :  0.018132862879170313  Rel. Test L2 Loss :  0.018732698187232017  Test L2 Loss :  0.03333495959639549  inv_L_scale:  [1.0, 1.0]
Epoch :  260  Time:  1.094  Rel. Train L2 Loss :  0.01790746164818605  Rel. Test L2 Loss :  0.01842318706214428  Test L2 Loss :  0.03252096310257912  inv_L_scale:  [1.0, 1.0]
Epoch :  261  Time:  1.094  Rel. Train L2 Loss :  0.01767499084273974  Rel. Test L2 Loss :  0.01903472699224949  Test L2 Loss :  0.033691675215959546  inv_L_scale:  [1.0, 1.0]
Epoch :  262  Time:  1.095  Rel. Train L2 Loss :  0.01806797172460291  Rel. Test L2 Loss :  0.018729702308773993  Test L2 Loss :  0.03323207274079323  inv_L_scale:  [1.0, 1.0]
Epoch :  263  Time:  1.094  Rel. Train L2 Loss :  0.018173457748360104  Rel. Test L2 Loss :  0.018779975771903993  Test L2 Loss :  0.03306473568081856  inv_L_scale:  [1.0, 1.0]
Epoch :  264  Time:  1.092  Rel. Train L2 Loss :  0.018417421612474654  Rel. Test L2 Loss :  0.023560985326766967  Test L2 Loss :  0.0426330029964447  inv_L_scale:  [1.0, 1.0]
Epoch :  265  Time:  1.092  Rel. Train L2 Loss :  0.018513734034366076  Rel. Test L2 Loss :  0.01884081281721592  Test L2 Loss :  0.0333604134619236  inv_L_scale:  [1.0, 1.0]
Epoch :  266  Time:  1.092  Rel. Train L2 Loss :  0.017894134546319645  Rel. Test L2 Loss :  0.01954370826482773  Test L2 Loss :  0.034685768485069275  inv_L_scale:  [1.0, 1.0]
Epoch :  267  Time:  1.092  Rel. Train L2 Loss :  0.017583711358408135  Rel. Test L2 Loss :  0.018961222544312477  Test L2 Loss :  0.03386320188641548  inv_L_scale:  [1.0, 1.0]
Epoch :  268  Time:  1.092  Rel. Train L2 Loss :  0.017709618616435264  Rel. Test L2 Loss :  0.019362227246165275  Test L2 Loss :  0.03443049266934395  inv_L_scale:  [1.0, 1.0]
Epoch :  269  Time:  1.093  Rel. Train L2 Loss :  0.017799267280432914  Rel. Test L2 Loss :  0.0210834014415741  Test L2 Loss :  0.037939144670963286  inv_L_scale:  [1.0, 1.0]
Epoch :  270  Time:  1.093  Rel. Train L2 Loss :  0.018168171205454404  Rel. Test L2 Loss :  0.018533967062830926  Test L2 Loss :  0.03278289757668972  inv_L_scale:  [1.0, 1.0]
Epoch :  271  Time:  1.092  Rel. Train L2 Loss :  0.017479716911911965  Rel. Test L2 Loss :  0.018370828069746496  Test L2 Loss :  0.03235475152730942  inv_L_scale:  [1.0, 1.0]
Epoch :  272  Time:  1.092  Rel. Train L2 Loss :  0.0175666667562392  Rel. Test L2 Loss :  0.01981672637164593  Test L2 Loss :  0.034991357177495956  inv_L_scale:  [1.0, 1.0]
Epoch :  273  Time:  1.092  Rel. Train L2 Loss :  0.01780078196691142  Rel. Test L2 Loss :  0.019724407978355885  Test L2 Loss :  0.034727417528629304  inv_L_scale:  [1.0, 1.0]
Epoch :  274  Time:  1.092  Rel. Train L2 Loss :  0.018045887185467614  Rel. Test L2 Loss :  0.019079116433858873  Test L2 Loss :  0.0335462548583746  inv_L_scale:  [1.0, 1.0]
Epoch :  275  Time:  1.093  Rel. Train L2 Loss :  0.01779731468194061  Rel. Test L2 Loss :  0.018257667683064936  Test L2 Loss :  0.0321958039700985  inv_L_scale:  [1.0, 1.0]
Epoch :  276  Time:  1.092  Rel. Train L2 Loss :  0.018055460047390726  Rel. Test L2 Loss :  0.0195165553689003  Test L2 Loss :  0.034392644762992856  inv_L_scale:  [1.0, 1.0]
Epoch :  277  Time:  1.092  Rel. Train L2 Loss :  0.017761945244338776  Rel. Test L2 Loss :  0.019163508862257005  Test L2 Loss :  0.033863965421915054  inv_L_scale:  [1.0, 1.0]
Epoch :  278  Time:  1.093  Rel. Train L2 Loss :  0.017529690720968775  Rel. Test L2 Loss :  0.019787377528846264  Test L2 Loss :  0.03522334665060043  inv_L_scale:  [1.0, 1.0]
Epoch :  279  Time:  1.092  Rel. Train L2 Loss :  0.017332138957248795  Rel. Test L2 Loss :  0.01811958312988281  Test L2 Loss :  0.03180874556303024  inv_L_scale:  [1.0, 1.0]
Epoch :  280  Time:  1.092  Rel. Train L2 Loss :  0.017218610934085315  Rel. Test L2 Loss :  0.017790777385234834  Test L2 Loss :  0.031422780081629756  inv_L_scale:  [1.0, 1.0]
Epoch :  281  Time:  1.093  Rel. Train L2 Loss :  0.017552747651934625  Rel. Test L2 Loss :  0.02002807229757309  Test L2 Loss :  0.03597869262099266  inv_L_scale:  [1.0, 1.0]
Epoch :  282  Time:  1.095  Rel. Train L2 Loss :  0.01743451083699862  Rel. Test L2 Loss :  0.01885141998529434  Test L2 Loss :  0.03378851383924484  inv_L_scale:  [1.0, 1.0]
Epoch :  283  Time:  1.094  Rel. Train L2 Loss :  0.017232739730841582  Rel. Test L2 Loss :  0.017955865934491156  Test L2 Loss :  0.03146510072052479  inv_L_scale:  [1.0, 1.0]
Epoch :  284  Time:  1.094  Rel. Train L2 Loss :  0.01687969122495916  Rel. Test L2 Loss :  0.017692601531744002  Test L2 Loss :  0.03109507992863655  inv_L_scale:  [1.0, 1.0]
Epoch :  285  Time:  1.094  Rel. Train L2 Loss :  0.01704591754410002  Rel. Test L2 Loss :  0.018037827983498574  Test L2 Loss :  0.03191631928086281  inv_L_scale:  [1.0, 1.0]
Epoch :  286  Time:  1.094  Rel. Train L2 Loss :  0.017690237901277012  Rel. Test L2 Loss :  0.018508497178554534  Test L2 Loss :  0.032584383860230444  inv_L_scale:  [1.0, 1.0]
Epoch :  287  Time:  1.094  Rel. Train L2 Loss :  0.017568536740210323  Rel. Test L2 Loss :  0.01810935780405998  Test L2 Loss :  0.031930041387677195  inv_L_scale:  [1.0, 1.0]
Epoch :  288  Time:  1.094  Rel. Train L2 Loss :  0.01721910246130493  Rel. Test L2 Loss :  0.01794855676591396  Test L2 Loss :  0.03179951325058937  inv_L_scale:  [1.0, 1.0]
Epoch :  289  Time:  1.094  Rel. Train L2 Loss :  0.017119631825221908  Rel. Test L2 Loss :  0.017629888094961643  Test L2 Loss :  0.031010749489068984  inv_L_scale:  [1.0, 1.0]
Epoch :  290  Time:  1.094  Rel. Train L2 Loss :  0.01703190203342173  Rel. Test L2 Loss :  0.017721600718796252  Test L2 Loss :  0.03114888072013855  inv_L_scale:  [1.0, 1.0]
Epoch :  291  Time:  1.094  Rel. Train L2 Loss :  0.016811527071727648  Rel. Test L2 Loss :  0.0191834656894207  Test L2 Loss :  0.03415400102734566  inv_L_scale:  [1.0, 1.0]
Epoch :  292  Time:  1.095  Rel. Train L2 Loss :  0.01704946515460809  Rel. Test L2 Loss :  0.018726646304130554  Test L2 Loss :  0.03314999289810658  inv_L_scale:  [1.0, 1.0]
Epoch :  293  Time:  1.094  Rel. Train L2 Loss :  0.017046983415881792  Rel. Test L2 Loss :  0.017823043987154962  Test L2 Loss :  0.031435590013861654  inv_L_scale:  [1.0, 1.0]
Epoch :  294  Time:  1.094  Rel. Train L2 Loss :  0.01691765874210331  Rel. Test L2 Loss :  0.018096062690019607  Test L2 Loss :  0.03191756248474121  inv_L_scale:  [1.0, 1.0]
Epoch :  295  Time:  1.094  Rel. Train L2 Loss :  0.016812485742072263  Rel. Test L2 Loss :  0.018471915982663633  Test L2 Loss :  0.033009321689605714  inv_L_scale:  [1.0, 1.0]
Epoch :  296  Time:  1.094  Rel. Train L2 Loss :  0.01693430629869302  Rel. Test L2 Loss :  0.01735274463891983  Test L2 Loss :  0.030614547058939935  inv_L_scale:  [1.0, 1.0]
Epoch :  297  Time:  1.098  Rel. Train L2 Loss :  0.016700017261836266  Rel. Test L2 Loss :  0.01753016635775566  Test L2 Loss :  0.031078703105449676  inv_L_scale:  [1.0, 1.0]
Epoch :  298  Time:  1.095  Rel. Train L2 Loss :  0.01659780950182014  Rel. Test L2 Loss :  0.01790790818631649  Test L2 Loss :  0.031727836579084394  inv_L_scale:  [1.0, 1.0]
Epoch :  299  Time:  1.094  Rel. Train L2 Loss :  0.016532331224944855  Rel. Test L2 Loss :  0.01721302554011345  Test L2 Loss :  0.03026768907904625  inv_L_scale:  [1.0, 1.0]
Epoch :  300  Time:  1.094  Rel. Train L2 Loss :  0.01703294153842661  Rel. Test L2 Loss :  0.018684220686554908  Test L2 Loss :  0.03293773427605629  inv_L_scale:  [1.0, 1.0]
Epoch :  301  Time:  1.093  Rel. Train L2 Loss :  0.017028450460897553  Rel. Test L2 Loss :  0.017805989980697632  Test L2 Loss :  0.03145041286945343  inv_L_scale:  [1.0, 1.0]
Epoch :  302  Time:  1.094  Rel. Train L2 Loss :  0.016763525439633265  Rel. Test L2 Loss :  0.017760584354400633  Test L2 Loss :  0.03151799112558365  inv_L_scale:  [1.0, 1.0]
Epoch :  303  Time:  1.095  Rel. Train L2 Loss :  0.016803950013385877  Rel. Test L2 Loss :  0.017763522192835807  Test L2 Loss :  0.03135575696825981  inv_L_scale:  [1.0, 1.0]
Epoch :  304  Time:  1.094  Rel. Train L2 Loss :  0.016670790248446993  Rel. Test L2 Loss :  0.01747942954301834  Test L2 Loss :  0.03075889065861702  inv_L_scale:  [1.0, 1.0]
Epoch :  305  Time:  1.093  Rel. Train L2 Loss :  0.016672761390606562  Rel. Test L2 Loss :  0.017959368154406546  Test L2 Loss :  0.03162962928414345  inv_L_scale:  [1.0, 1.0]
Epoch :  306  Time:  1.094  Rel. Train L2 Loss :  0.016615896779629918  Rel. Test L2 Loss :  0.01737048901617527  Test L2 Loss :  0.03043730229139328  inv_L_scale:  [1.0, 1.0]
Epoch :  307  Time:  1.094  Rel. Train L2 Loss :  0.01653371219833692  Rel. Test L2 Loss :  0.01876769006252289  Test L2 Loss :  0.03311348602175713  inv_L_scale:  [1.0, 1.0]
Epoch :  308  Time:  1.094  Rel. Train L2 Loss :  0.016684184074401854  Rel. Test L2 Loss :  0.017355093844234944  Test L2 Loss :  0.030729803144931792  inv_L_scale:  [1.0, 1.0]
Epoch :  309  Time:  1.093  Rel. Train L2 Loss :  0.01639258576764001  Rel. Test L2 Loss :  0.01770678736269474  Test L2 Loss :  0.0313776782900095  inv_L_scale:  [1.0, 1.0]
Epoch :  310  Time:  1.094  Rel. Train L2 Loss :  0.016346658344070116  Rel. Test L2 Loss :  0.017354081869125366  Test L2 Loss :  0.030725345239043234  inv_L_scale:  [1.0, 1.0]
Epoch :  311  Time:  1.094  Rel. Train L2 Loss :  0.01654003026170863  Rel. Test L2 Loss :  0.017330851927399634  Test L2 Loss :  0.03054954744875431  inv_L_scale:  [1.0, 1.0]
Epoch :  312  Time:  1.094  Rel. Train L2 Loss :  0.016378222281734148  Rel. Test L2 Loss :  0.017618051394820214  Test L2 Loss :  0.03096777342259884  inv_L_scale:  [1.0, 1.0]
Epoch :  313  Time:  1.094  Rel. Train L2 Loss :  0.016580400442083677  Rel. Test L2 Loss :  0.017358519919216633  Test L2 Loss :  0.030597209483385086  inv_L_scale:  [1.0, 1.0]
Epoch :  314  Time:  1.094  Rel. Train L2 Loss :  0.016337239717443785  Rel. Test L2 Loss :  0.017054224088788032  Test L2 Loss :  0.029885148257017137  inv_L_scale:  [1.0, 1.0]
Epoch :  315  Time:  1.095  Rel. Train L2 Loss :  0.016524920041362443  Rel. Test L2 Loss :  0.017970428839325904  Test L2 Loss :  0.03180417373776436  inv_L_scale:  [1.0, 1.0]
Epoch :  316  Time:  1.094  Rel. Train L2 Loss :  0.01644760847091675  Rel. Test L2 Loss :  0.017726564817130565  Test L2 Loss :  0.031346429735422135  inv_L_scale:  [1.0, 1.0]
Epoch :  317  Time:  1.094  Rel. Train L2 Loss :  0.016153673289550675  Rel. Test L2 Loss :  0.017077368944883348  Test L2 Loss :  0.030055572092533112  inv_L_scale:  [1.0, 1.0]
Epoch :  318  Time:  1.094  Rel. Train L2 Loss :  0.016206674869689675  Rel. Test L2 Loss :  0.017118520215153695  Test L2 Loss :  0.029973774626851083  inv_L_scale:  [1.0, 1.0]
Epoch :  319  Time:  1.094  Rel. Train L2 Loss :  0.01619747969839308  Rel. Test L2 Loss :  0.017711670249700547  Test L2 Loss :  0.031146767362952233  inv_L_scale:  [1.0, 1.0]
Epoch :  320  Time:  1.094  Rel. Train L2 Loss :  0.016227957697378264  Rel. Test L2 Loss :  0.017172166630625724  Test L2 Loss :  0.03036119982600212  inv_L_scale:  [1.0, 1.0]
Epoch :  321  Time:  1.092  Rel. Train L2 Loss :  0.016095201762186158  Rel. Test L2 Loss :  0.017323651760816575  Test L2 Loss :  0.030595742389559744  inv_L_scale:  [1.0, 1.0]
Epoch :  322  Time:  1.095  Rel. Train L2 Loss :  0.016312124729156493  Rel. Test L2 Loss :  0.016998630575835706  Test L2 Loss :  0.029751559421420097  inv_L_scale:  [1.0, 1.0]
Epoch :  323  Time:  1.094  Rel. Train L2 Loss :  0.016211439958877034  Rel. Test L2 Loss :  0.016713116094470026  Test L2 Loss :  0.029315459430217742  inv_L_scale:  [1.0, 1.0]
Epoch :  324  Time:  1.095  Rel. Train L2 Loss :  0.01615375992324617  Rel. Test L2 Loss :  0.016772634424269198  Test L2 Loss :  0.029427869692444802  inv_L_scale:  [1.0, 1.0]
Epoch :  325  Time:  1.094  Rel. Train L2 Loss :  0.01618463310930464  Rel. Test L2 Loss :  0.01686687335371971  Test L2 Loss :  0.02976809173822403  inv_L_scale:  [1.0, 1.0]
Epoch :  326  Time:  1.095  Rel. Train L2 Loss :  0.016024616749750243  Rel. Test L2 Loss :  0.01816133413463831  Test L2 Loss :  0.03202496543526649  inv_L_scale:  [1.0, 1.0]
Epoch :  327  Time:  1.095  Rel. Train L2 Loss :  0.016044817045331002  Rel. Test L2 Loss :  0.016822643242776394  Test L2 Loss :  0.02959857143461704  inv_L_scale:  [1.0, 1.0]
Epoch :  328  Time:  1.095  Rel. Train L2 Loss :  0.01585336134251621  Rel. Test L2 Loss :  0.016507104262709616  Test L2 Loss :  0.02896543011069298  inv_L_scale:  [1.0, 1.0]
Epoch :  329  Time:  1.095  Rel. Train L2 Loss :  0.015847011870808073  Rel. Test L2 Loss :  0.01710705116391182  Test L2 Loss :  0.030178628340363504  inv_L_scale:  [1.0, 1.0]
Epoch :  330  Time:  1.095  Rel. Train L2 Loss :  0.015929023404088284  Rel. Test L2 Loss :  0.016999795883893967  Test L2 Loss :  0.029863884672522545  inv_L_scale:  [1.0, 1.0]
Epoch :  331  Time:  1.095  Rel. Train L2 Loss :  0.016146381869912147  Rel. Test L2 Loss :  0.016781459599733352  Test L2 Loss :  0.029527978524565696  inv_L_scale:  [1.0, 1.0]
Epoch :  332  Time:  1.095  Rel. Train L2 Loss :  0.015852189304100144  Rel. Test L2 Loss :  0.01689980149269104  Test L2 Loss :  0.029738886356353758  inv_L_scale:  [1.0, 1.0]
Epoch :  333  Time:  1.095  Rel. Train L2 Loss :  0.015782650022043123  Rel. Test L2 Loss :  0.016864809691905975  Test L2 Loss :  0.029694176465272903  inv_L_scale:  [1.0, 1.0]
Epoch :  334  Time:  1.094  Rel. Train L2 Loss :  0.015881254884103933  Rel. Test L2 Loss :  0.017003729492425918  Test L2 Loss :  0.02998902417719364  inv_L_scale:  [1.0, 1.0]
Epoch :  335  Time:  1.095  Rel. Train L2 Loss :  0.015820928638180097  Rel. Test L2 Loss :  0.017193089872598648  Test L2 Loss :  0.030374604389071466  inv_L_scale:  [1.0, 1.0]
Epoch :  336  Time:  1.095  Rel. Train L2 Loss :  0.015880785721043747  Rel. Test L2 Loss :  0.016556321159005166  Test L2 Loss :  0.029108065217733382  inv_L_scale:  [1.0, 1.0]
Epoch :  337  Time:  1.095  Rel. Train L2 Loss :  0.015770821215377914  Rel. Test L2 Loss :  0.01740258954465389  Test L2 Loss :  0.030624801218509676  inv_L_scale:  [1.0, 1.0]
Epoch :  338  Time:  1.095  Rel. Train L2 Loss :  0.016007978328400188  Rel. Test L2 Loss :  0.017087160125374794  Test L2 Loss :  0.030061096623539924  inv_L_scale:  [1.0, 1.0]
Epoch :  339  Time:  1.094  Rel. Train L2 Loss :  0.015844375184840626  Rel. Test L2 Loss :  0.016850701197981835  Test L2 Loss :  0.029665505290031435  inv_L_scale:  [1.0, 1.0]
Epoch :  340  Time:  1.095  Rel. Train L2 Loss :  0.015717819705605506  Rel. Test L2 Loss :  0.0169219771027565  Test L2 Loss :  0.02984700843691826  inv_L_scale:  [1.0, 1.0]
Epoch :  341  Time:  1.097  Rel. Train L2 Loss :  0.015847345309125054  Rel. Test L2 Loss :  0.016947967894375325  Test L2 Loss :  0.02996684730052948  inv_L_scale:  [1.0, 1.0]
Epoch :  342  Time:  1.096  Rel. Train L2 Loss :  0.015886742696166037  Rel. Test L2 Loss :  0.01717384621500969  Test L2 Loss :  0.030231225937604904  inv_L_scale:  [1.0, 1.0]
Epoch :  343  Time:  1.096  Rel. Train L2 Loss :  0.0157059684726927  Rel. Test L2 Loss :  0.016839257441461086  Test L2 Loss :  0.02952276661992073  inv_L_scale:  [1.0, 1.0]
Epoch :  344  Time:  1.096  Rel. Train L2 Loss :  0.015693283991681205  Rel. Test L2 Loss :  0.016435170620679854  Test L2 Loss :  0.028653146028518678  inv_L_scale:  [1.0, 1.0]
Epoch :  345  Time:  1.095  Rel. Train L2 Loss :  0.015649249826868376  Rel. Test L2 Loss :  0.016333018131554126  Test L2 Loss :  0.028764570057392122  inv_L_scale:  [1.0, 1.0]
Epoch :  346  Time:  1.095  Rel. Train L2 Loss :  0.01563149722913901  Rel. Test L2 Loss :  0.01662303302437067  Test L2 Loss :  0.029187529385089873  inv_L_scale:  [1.0, 1.0]
Epoch :  347  Time:  1.096  Rel. Train L2 Loss :  0.015562994678815206  Rel. Test L2 Loss :  0.01667867712676525  Test L2 Loss :  0.029201455116271972  inv_L_scale:  [1.0, 1.0]
Epoch :  348  Time:  1.095  Rel. Train L2 Loss :  0.015590946682625346  Rel. Test L2 Loss :  0.016586143001914026  Test L2 Loss :  0.028963004052639008  inv_L_scale:  [1.0, 1.0]
Epoch :  349  Time:  1.095  Rel. Train L2 Loss :  0.015811287090182303  Rel. Test L2 Loss :  0.01683843236416578  Test L2 Loss :  0.029465735405683518  inv_L_scale:  [1.0, 1.0]
Epoch :  350  Time:  1.096  Rel. Train L2 Loss :  0.015948405977752475  Rel. Test L2 Loss :  0.01658449590206146  Test L2 Loss :  0.029075918048620225  inv_L_scale:  [1.0, 1.0]
Epoch :  351  Time:  1.095  Rel. Train L2 Loss :  0.015637202138702073  Rel. Test L2 Loss :  0.016869987063109874  Test L2 Loss :  0.02974721185863018  inv_L_scale:  [1.0, 1.0]
Epoch :  352  Time:  1.096  Rel. Train L2 Loss :  0.01564677426384555  Rel. Test L2 Loss :  0.016427166834473608  Test L2 Loss :  0.028740606904029846  inv_L_scale:  [1.0, 1.0]
Epoch :  353  Time:  1.095  Rel. Train L2 Loss :  0.015481023407644696  Rel. Test L2 Loss :  0.0163679963350296  Test L2 Loss :  0.028622769564390183  inv_L_scale:  [1.0, 1.0]
Epoch :  354  Time:  1.096  Rel. Train L2 Loss :  0.015386948709686597  Rel. Test L2 Loss :  0.016415532007813455  Test L2 Loss :  0.028758114874362944  inv_L_scale:  [1.0, 1.0]
Epoch :  355  Time:  1.095  Rel. Train L2 Loss :  0.015480171495841608  Rel. Test L2 Loss :  0.01621396541595459  Test L2 Loss :  0.02837835967540741  inv_L_scale:  [1.0, 1.0]
Epoch :  356  Time:  1.1  Rel. Train L2 Loss :  0.015294851888385084  Rel. Test L2 Loss :  0.01621423624455929  Test L2 Loss :  0.028453185185790063  inv_L_scale:  [1.0, 1.0]
Epoch :  357  Time:  1.096  Rel. Train L2 Loss :  0.015384395209451517  Rel. Test L2 Loss :  0.01633229874074459  Test L2 Loss :  0.02857988841831684  inv_L_scale:  [1.0, 1.0]
Epoch :  358  Time:  1.096  Rel. Train L2 Loss :  0.015431616281469662  Rel. Test L2 Loss :  0.01616102010011673  Test L2 Loss :  0.02830710545182228  inv_L_scale:  [1.0, 1.0]
Epoch :  359  Time:  1.096  Rel. Train L2 Loss :  0.01529206779681974  Rel. Test L2 Loss :  0.0172539596632123  Test L2 Loss :  0.03031254455447197  inv_L_scale:  [1.0, 1.0]
Epoch :  360  Time:  1.096  Rel. Train L2 Loss :  0.0152990320407682  Rel. Test L2 Loss :  0.016899494230747224  Test L2 Loss :  0.029700846895575523  inv_L_scale:  [1.0, 1.0]
Epoch :  361  Time:  1.095  Rel. Train L2 Loss :  0.015268637032972442  Rel. Test L2 Loss :  0.016157196685671806  Test L2 Loss :  0.02841298058629036  inv_L_scale:  [1.0, 1.0]
Epoch :  362  Time:  1.096  Rel. Train L2 Loss :  0.01532622568309307  Rel. Test L2 Loss :  0.01627391152083874  Test L2 Loss :  0.028539583683013917  inv_L_scale:  [1.0, 1.0]
Epoch :  363  Time:  1.096  Rel. Train L2 Loss :  0.01517823410530885  Rel. Test L2 Loss :  0.01626017201691866  Test L2 Loss :  0.02847385674715042  inv_L_scale:  [1.0, 1.0]
Epoch :  364  Time:  1.095  Rel. Train L2 Loss :  0.01517231400228209  Rel. Test L2 Loss :  0.0163898479193449  Test L2 Loss :  0.02868693172931671  inv_L_scale:  [1.0, 1.0]
Epoch :  365  Time:  1.095  Rel. Train L2 Loss :  0.015447664550609058  Rel. Test L2 Loss :  0.01630412954837084  Test L2 Loss :  0.02864359125494957  inv_L_scale:  [1.0, 1.0]
Epoch :  366  Time:  1.095  Rel. Train L2 Loss :  0.015170945707294676  Rel. Test L2 Loss :  0.016079598926007747  Test L2 Loss :  0.028242644444108008  inv_L_scale:  [1.0, 1.0]
Epoch :  367  Time:  1.095  Rel. Train L2 Loss :  0.015078356944852406  Rel. Test L2 Loss :  0.016048135086894035  Test L2 Loss :  0.02804130978882313  inv_L_scale:  [1.0, 1.0]
Epoch :  368  Time:  1.096  Rel. Train L2 Loss :  0.01512718838122156  Rel. Test L2 Loss :  0.016089462600648405  Test L2 Loss :  0.028176941871643067  inv_L_scale:  [1.0, 1.0]
Epoch :  369  Time:  1.095  Rel. Train L2 Loss :  0.015117655321955682  Rel. Test L2 Loss :  0.01614860262721777  Test L2 Loss :  0.02837837040424347  inv_L_scale:  [1.0, 1.0]
Epoch :  370  Time:  1.096  Rel. Train L2 Loss :  0.015040470767352316  Rel. Test L2 Loss :  0.015851934514939783  Test L2 Loss :  0.027707837447524072  inv_L_scale:  [1.0, 1.0]
Epoch :  371  Time:  1.095  Rel. Train L2 Loss :  0.015091343290275998  Rel. Test L2 Loss :  0.01577766239643097  Test L2 Loss :  0.027539990842342377  inv_L_scale:  [1.0, 1.0]
Epoch :  372  Time:  1.095  Rel. Train L2 Loss :  0.01492869022819731  Rel. Test L2 Loss :  0.015890374816954135  Test L2 Loss :  0.02789302870631218  inv_L_scale:  [1.0, 1.0]
Epoch :  373  Time:  1.096  Rel. Train L2 Loss :  0.014945390944679579  Rel. Test L2 Loss :  0.016020053550601005  Test L2 Loss :  0.028017383739352225  inv_L_scale:  [1.0, 1.0]
Epoch :  374  Time:  1.095  Rel. Train L2 Loss :  0.01507748285929362  Rel. Test L2 Loss :  0.016010152362287044  Test L2 Loss :  0.027996758297085762  inv_L_scale:  [1.0, 1.0]
Epoch :  375  Time:  1.095  Rel. Train L2 Loss :  0.014917320211728414  Rel. Test L2 Loss :  0.015709350183606148  Test L2 Loss :  0.02746122732758522  inv_L_scale:  [1.0, 1.0]
Epoch :  376  Time:  1.095  Rel. Train L2 Loss :  0.014988382301396794  Rel. Test L2 Loss :  0.016045280545949937  Test L2 Loss :  0.028129788637161254  inv_L_scale:  [1.0, 1.0]
Epoch :  377  Time:  1.096  Rel. Train L2 Loss :  0.014933073818683624  Rel. Test L2 Loss :  0.015811182223260403  Test L2 Loss :  0.02765577256679535  inv_L_scale:  [1.0, 1.0]
Epoch :  378  Time:  1.096  Rel. Train L2 Loss :  0.014924227818846702  Rel. Test L2 Loss :  0.016162870302796364  Test L2 Loss :  0.028476855829358102  inv_L_scale:  [1.0, 1.0]
Epoch :  379  Time:  1.096  Rel. Train L2 Loss :  0.014998706777890523  Rel. Test L2 Loss :  0.015862375646829605  Test L2 Loss :  0.02776470348238945  inv_L_scale:  [1.0, 1.0]
Epoch :  380  Time:  1.095  Rel. Train L2 Loss :  0.014915973448918925  Rel. Test L2 Loss :  0.015841419585049154  Test L2 Loss :  0.027768043503165245  inv_L_scale:  [1.0, 1.0]
Epoch :  381  Time:  1.096  Rel. Train L2 Loss :  0.014911920213037068  Rel. Test L2 Loss :  0.015790368244051934  Test L2 Loss :  0.02763762339949608  inv_L_scale:  [1.0, 1.0]
Epoch :  382  Time:  1.096  Rel. Train L2 Loss :  0.014881655809779962  Rel. Test L2 Loss :  0.016106289438903333  Test L2 Loss :  0.028240104019641877  inv_L_scale:  [1.0, 1.0]
Epoch :  383  Time:  1.096  Rel. Train L2 Loss :  0.01490699999862247  Rel. Test L2 Loss :  0.015828491523861885  Test L2 Loss :  0.02769012987613678  inv_L_scale:  [1.0, 1.0]
Epoch :  384  Time:  1.096  Rel. Train L2 Loss :  0.01481475540333324  Rel. Test L2 Loss :  0.01574490562081337  Test L2 Loss :  0.027557572573423384  inv_L_scale:  [1.0, 1.0]
Epoch :  385  Time:  1.096  Rel. Train L2 Loss :  0.014796547782089975  Rel. Test L2 Loss :  0.015853879004716874  Test L2 Loss :  0.027793240249156952  inv_L_scale:  [1.0, 1.0]
Epoch :  386  Time:  1.096  Rel. Train L2 Loss :  0.014763653510146671  Rel. Test L2 Loss :  0.015906844437122345  Test L2 Loss :  0.027878421172499657  inv_L_scale:  [1.0, 1.0]
Epoch :  387  Time:  1.096  Rel. Train L2 Loss :  0.014718864692582025  Rel. Test L2 Loss :  0.015798626095056535  Test L2 Loss :  0.02768113136291504  inv_L_scale:  [1.0, 1.0]
Epoch :  388  Time:  1.096  Rel. Train L2 Loss :  0.01472605517341031  Rel. Test L2 Loss :  0.015749979093670846  Test L2 Loss :  0.027595236897468567  inv_L_scale:  [1.0, 1.0]
Epoch :  389  Time:  1.096  Rel. Train L2 Loss :  0.014731055800285605  Rel. Test L2 Loss :  0.015881835743784906  Test L2 Loss :  0.027860198467969895  inv_L_scale:  [1.0, 1.0]
Epoch :  390  Time:  1.096  Rel. Train L2 Loss :  0.014690546260939704  Rel. Test L2 Loss :  0.015660758428275585  Test L2 Loss :  0.027378461956977844  inv_L_scale:  [1.0, 1.0]
Epoch :  391  Time:  1.096  Rel. Train L2 Loss :  0.014714783355593682  Rel. Test L2 Loss :  0.01564416155219078  Test L2 Loss :  0.02734837755560875  inv_L_scale:  [1.0, 1.0]
Epoch :  392  Time:  1.096  Rel. Train L2 Loss :  0.014798420096437136  Rel. Test L2 Loss :  0.015583260506391526  Test L2 Loss :  0.027256248444318773  inv_L_scale:  [1.0, 1.0]
Epoch :  393  Time:  1.096  Rel. Train L2 Loss :  0.01464758293496238  Rel. Test L2 Loss :  0.015595410317182541  Test L2 Loss :  0.027298296317458153  inv_L_scale:  [1.0, 1.0]
Epoch :  394  Time:  1.095  Rel. Train L2 Loss :  0.014578453513483207  Rel. Test L2 Loss :  0.015567196384072304  Test L2 Loss :  0.027306967228651047  inv_L_scale:  [1.0, 1.0]
Epoch :  395  Time:  1.095  Rel. Train L2 Loss :  0.0146043697413471  Rel. Test L2 Loss :  0.01577234610915184  Test L2 Loss :  0.02753743380308151  inv_L_scale:  [1.0, 1.0]
Epoch :  396  Time:  1.096  Rel. Train L2 Loss :  0.014634015444252226  Rel. Test L2 Loss :  0.015523357465863228  Test L2 Loss :  0.027095013707876207  inv_L_scale:  [1.0, 1.0]
Epoch :  397  Time:  1.096  Rel. Train L2 Loss :  0.01459416033493148  Rel. Test L2 Loss :  0.015384905077517032  Test L2 Loss :  0.026969461143016814  inv_L_scale:  [1.0, 1.0]
Epoch :  398  Time:  1.095  Rel. Train L2 Loss :  0.014544675805502469  Rel. Test L2 Loss :  0.015518317185342311  Test L2 Loss :  0.027154341638088227  inv_L_scale:  [1.0, 1.0]
Epoch :  399  Time:  1.094  Rel. Train L2 Loss :  0.014551568532155619  Rel. Test L2 Loss :  0.01567938018590212  Test L2 Loss :  0.02748166970908642  inv_L_scale:  [1.0, 1.0]
Epoch :  400  Time:  1.097  Rel. Train L2 Loss :  0.014576588376528686  Rel. Test L2 Loss :  0.015532213672995567  Test L2 Loss :  0.02716783031821251  inv_L_scale:  [1.0, 1.0]
Epoch :  401  Time:  1.095  Rel. Train L2 Loss :  0.014489199854433537  Rel. Test L2 Loss :  0.015409299433231353  Test L2 Loss :  0.02696941137313843  inv_L_scale:  [1.0, 1.0]
Epoch :  402  Time:  1.096  Rel. Train L2 Loss :  0.014457028905550638  Rel. Test L2 Loss :  0.015572087727487088  Test L2 Loss :  0.02726255141198635  inv_L_scale:  [1.0, 1.0]
Epoch :  403  Time:  1.096  Rel. Train L2 Loss :  0.014520258100496399  Rel. Test L2 Loss :  0.015425208508968353  Test L2 Loss :  0.026993369311094285  inv_L_scale:  [1.0, 1.0]
Epoch :  404  Time:  1.094  Rel. Train L2 Loss :  0.014483126236332787  Rel. Test L2 Loss :  0.016038460433483125  Test L2 Loss :  0.028303967118263246  inv_L_scale:  [1.0, 1.0]
Epoch :  405  Time:  1.094  Rel. Train L2 Loss :  0.014482579645183352  Rel. Test L2 Loss :  0.015469537898898125  Test L2 Loss :  0.027064146772027016  inv_L_scale:  [1.0, 1.0]
Epoch :  406  Time:  1.094  Rel. Train L2 Loss :  0.014455196923679775  Rel. Test L2 Loss :  0.015456563420593738  Test L2 Loss :  0.02705836735665798  inv_L_scale:  [1.0, 1.0]
Epoch :  407  Time:  1.094  Rel. Train L2 Loss :  0.014425644609663222  Rel. Test L2 Loss :  0.015575920306146145  Test L2 Loss :  0.027264650911092758  inv_L_scale:  [1.0, 1.0]
Epoch :  408  Time:  1.094  Rel. Train L2 Loss :  0.01449248952170213  Rel. Test L2 Loss :  0.015388711094856263  Test L2 Loss :  0.026858239695429803  inv_L_scale:  [1.0, 1.0]
Epoch :  409  Time:  1.093  Rel. Train L2 Loss :  0.014408324348429839  Rel. Test L2 Loss :  0.01530779868364334  Test L2 Loss :  0.02673674426972866  inv_L_scale:  [1.0, 1.0]
Epoch :  410  Time:  1.093  Rel. Train L2 Loss :  0.014379418931073612  Rel. Test L2 Loss :  0.015455581843852997  Test L2 Loss :  0.027051220312714577  inv_L_scale:  [1.0, 1.0]
Epoch :  411  Time:  1.094  Rel. Train L2 Loss :  0.014440847171677483  Rel. Test L2 Loss :  0.015273955427110195  Test L2 Loss :  0.02672135204076767  inv_L_scale:  [1.0, 1.0]
Epoch :  412  Time:  1.097  Rel. Train L2 Loss :  0.014351147496038013  Rel. Test L2 Loss :  0.015318358652293682  Test L2 Loss :  0.026761803179979324  inv_L_scale:  [1.0, 1.0]
Epoch :  413  Time:  1.093  Rel. Train L2 Loss :  0.01431220393213961  Rel. Test L2 Loss :  0.015391959995031356  Test L2 Loss :  0.026907877549529075  inv_L_scale:  [1.0, 1.0]
Epoch :  414  Time:  1.094  Rel. Train L2 Loss :  0.01426287723912133  Rel. Test L2 Loss :  0.015311733894050121  Test L2 Loss :  0.02679447129368782  inv_L_scale:  [1.0, 1.0]
Epoch :  415  Time:  1.098  Rel. Train L2 Loss :  0.01431137631336848  Rel. Test L2 Loss :  0.015342526212334633  Test L2 Loss :  0.026801646649837495  inv_L_scale:  [1.0, 1.0]
Epoch :  416  Time:  1.095  Rel. Train L2 Loss :  0.014300475219885507  Rel. Test L2 Loss :  0.015250595137476921  Test L2 Loss :  0.026639868542551993  inv_L_scale:  [1.0, 1.0]
Epoch :  417  Time:  1.095  Rel. Train L2 Loss :  0.014218609780073166  Rel. Test L2 Loss :  0.015274253487586976  Test L2 Loss :  0.026770973801612852  inv_L_scale:  [1.0, 1.0]
Epoch :  418  Time:  1.095  Rel. Train L2 Loss :  0.014246807181172902  Rel. Test L2 Loss :  0.015339444056153298  Test L2 Loss :  0.026842288076877593  inv_L_scale:  [1.0, 1.0]
Epoch :  419  Time:  1.094  Rel. Train L2 Loss :  0.014247993615766367  Rel. Test L2 Loss :  0.01528568185865879  Test L2 Loss :  0.02664691150188446  inv_L_scale:  [1.0, 1.0]
Epoch :  420  Time:  1.095  Rel. Train L2 Loss :  0.01426408422489961  Rel. Test L2 Loss :  0.015279544405639172  Test L2 Loss :  0.026730901449918746  inv_L_scale:  [1.0, 1.0]
Epoch :  421  Time:  1.095  Rel. Train L2 Loss :  0.014225401530663172  Rel. Test L2 Loss :  0.015313816592097282  Test L2 Loss :  0.02676460236310959  inv_L_scale:  [1.0, 1.0]
Epoch :  422  Time:  1.095  Rel. Train L2 Loss :  0.014238410881823963  Rel. Test L2 Loss :  0.0152907133102417  Test L2 Loss :  0.026725983768701552  inv_L_scale:  [1.0, 1.0]
Epoch :  423  Time:  1.094  Rel. Train L2 Loss :  0.014179992485377524  Rel. Test L2 Loss :  0.015241649597883225  Test L2 Loss :  0.02662016361951828  inv_L_scale:  [1.0, 1.0]
Epoch :  424  Time:  1.095  Rel. Train L2 Loss :  0.014186970873011483  Rel. Test L2 Loss :  0.015201031379401684  Test L2 Loss :  0.0265312135219574  inv_L_scale:  [1.0, 1.0]
Epoch :  425  Time:  1.094  Rel. Train L2 Loss :  0.01421038777463966  Rel. Test L2 Loss :  0.015286916941404343  Test L2 Loss :  0.026700159683823586  inv_L_scale:  [1.0, 1.0]
Epoch :  426  Time:  1.094  Rel. Train L2 Loss :  0.014169511554969682  Rel. Test L2 Loss :  0.015207087397575378  Test L2 Loss :  0.026563254073262214  inv_L_scale:  [1.0, 1.0]
Epoch :  427  Time:  1.094  Rel. Train L2 Loss :  0.014132978344957034  Rel. Test L2 Loss :  0.01521916564553976  Test L2 Loss :  0.026571926921606065  inv_L_scale:  [1.0, 1.0]
Epoch :  428  Time:  1.095  Rel. Train L2 Loss :  0.01414419509884384  Rel. Test L2 Loss :  0.015139944478869438  Test L2 Loss :  0.026449612528085708  inv_L_scale:  [1.0, 1.0]
Epoch :  429  Time:  1.094  Rel. Train L2 Loss :  0.01417007654491398  Rel. Test L2 Loss :  0.015205800905823708  Test L2 Loss :  0.026573644205927848  inv_L_scale:  [1.0, 1.0]
Epoch :  430  Time:  1.095  Rel. Train L2 Loss :  0.014082717080083159  Rel. Test L2 Loss :  0.015389844849705696  Test L2 Loss :  0.026967535018920897  inv_L_scale:  [1.0, 1.0]
Epoch :  431  Time:  1.096  Rel. Train L2 Loss :  0.014196130318774118  Rel. Test L2 Loss :  0.0151430294662714  Test L2 Loss :  0.026451628357172012  inv_L_scale:  [1.0, 1.0]
Epoch :  432  Time:  1.091  Rel. Train L2 Loss :  0.014146237447857857  Rel. Test L2 Loss :  0.015210442803800106  Test L2 Loss :  0.02658307909965515  inv_L_scale:  [1.0, 1.0]
Epoch :  433  Time:  1.09  Rel. Train L2 Loss :  0.014077451816863484  Rel. Test L2 Loss :  0.01514664813876152  Test L2 Loss :  0.026455751955509185  inv_L_scale:  [1.0, 1.0]
Epoch :  434  Time:  1.09  Rel. Train L2 Loss :  0.014113918965061506  Rel. Test L2 Loss :  0.015322747491300106  Test L2 Loss :  0.02677045427262783  inv_L_scale:  [1.0, 1.0]
Epoch :  435  Time:  1.09  Rel. Train L2 Loss :  0.014129885265396701  Rel. Test L2 Loss :  0.01514503575861454  Test L2 Loss :  0.026420599669218062  inv_L_scale:  [1.0, 1.0]
Epoch :  436  Time:  1.09  Rel. Train L2 Loss :  0.014063738220267826  Rel. Test L2 Loss :  0.015123191326856612  Test L2 Loss :  0.026422566473484038  inv_L_scale:  [1.0, 1.0]
Epoch :  437  Time:  1.09  Rel. Train L2 Loss :  0.01404162361803982  Rel. Test L2 Loss :  0.015129213705658912  Test L2 Loss :  0.026426421850919722  inv_L_scale:  [1.0, 1.0]
Epoch :  438  Time:  1.09  Rel. Train L2 Loss :  0.014046207070350647  Rel. Test L2 Loss :  0.015333959087729453  Test L2 Loss :  0.026810402795672417  inv_L_scale:  [1.0, 1.0]
Epoch :  439  Time:  1.09  Rel. Train L2 Loss :  0.01409730816880862  Rel. Test L2 Loss :  0.015191623605787755  Test L2 Loss :  0.026535189151763915  inv_L_scale:  [1.0, 1.0]
Epoch :  440  Time:  1.093  Rel. Train L2 Loss :  0.014029043374790086  Rel. Test L2 Loss :  0.015147127173841  Test L2 Loss :  0.02647463820874691  inv_L_scale:  [1.0, 1.0]
Epoch :  441  Time:  1.09  Rel. Train L2 Loss :  0.014007319493426217  Rel. Test L2 Loss :  0.015075980201363564  Test L2 Loss :  0.026324703618884088  inv_L_scale:  [1.0, 1.0]
Epoch :  442  Time:  1.09  Rel. Train L2 Loss :  0.013988055818610722  Rel. Test L2 Loss :  0.01508317194879055  Test L2 Loss :  0.0263454669713974  inv_L_scale:  [1.0, 1.0]
Epoch :  443  Time:  1.091  Rel. Train L2 Loss :  0.013967799374626742  Rel. Test L2 Loss :  0.015095198862254619  Test L2 Loss :  0.026341266632080078  inv_L_scale:  [1.0, 1.0]
Epoch :  444  Time:  1.09  Rel. Train L2 Loss :  0.013991922438144684  Rel. Test L2 Loss :  0.015080650225281716  Test L2 Loss :  0.026303981244564057  inv_L_scale:  [1.0, 1.0]
Epoch :  445  Time:  1.09  Rel. Train L2 Loss :  0.013957435447308751  Rel. Test L2 Loss :  0.015110075920820237  Test L2 Loss :  0.026352890729904176  inv_L_scale:  [1.0, 1.0]
Epoch :  446  Time:  1.091  Rel. Train L2 Loss :  0.013956426878770193  Rel. Test L2 Loss :  0.015150574296712875  Test L2 Loss :  0.026447286605834962  inv_L_scale:  [1.0, 1.0]
Epoch :  447  Time:  1.091  Rel. Train L2 Loss :  0.013962190076708793  Rel. Test L2 Loss :  0.01500676792114973  Test L2 Loss :  0.026190558969974517  inv_L_scale:  [1.0, 1.0]
Epoch :  448  Time:  1.091  Rel. Train L2 Loss :  0.013986203939550452  Rel. Test L2 Loss :  0.01516969345510006  Test L2 Loss :  0.026497519612312316  inv_L_scale:  [1.0, 1.0]
Epoch :  449  Time:  1.091  Rel. Train L2 Loss :  0.013955412825776472  Rel. Test L2 Loss :  0.015120443776249886  Test L2 Loss :  0.026398643404245376  inv_L_scale:  [1.0, 1.0]
Epoch :  450  Time:  1.092  Rel. Train L2 Loss :  0.013918742934862772  Rel. Test L2 Loss :  0.015107828602194786  Test L2 Loss :  0.026373246088624  inv_L_scale:  [1.0, 1.0]
Epoch :  451  Time:  1.09  Rel. Train L2 Loss :  0.013901155210203594  Rel. Test L2 Loss :  0.014973387345671654  Test L2 Loss :  0.026120239198207856  inv_L_scale:  [1.0, 1.0]
Epoch :  452  Time:  1.09  Rel. Train L2 Loss :  0.013905154942638344  Rel. Test L2 Loss :  0.015093287900090218  Test L2 Loss :  0.026353768706321716  inv_L_scale:  [1.0, 1.0]
Epoch :  453  Time:  1.09  Rel. Train L2 Loss :  0.013890660570727454  Rel. Test L2 Loss :  0.015023611299693585  Test L2 Loss :  0.026217363998293875  inv_L_scale:  [1.0, 1.0]
Epoch :  454  Time:  1.091  Rel. Train L2 Loss :  0.013877226590282387  Rel. Test L2 Loss :  0.014991081431508064  Test L2 Loss :  0.02615766115486622  inv_L_scale:  [1.0, 1.0]
Epoch :  455  Time:  1.09  Rel. Train L2 Loss :  0.013864784232444234  Rel. Test L2 Loss :  0.014984900578856469  Test L2 Loss :  0.0261583162099123  inv_L_scale:  [1.0, 1.0]
Epoch :  456  Time:  1.091  Rel. Train L2 Loss :  0.013862102313174142  Rel. Test L2 Loss :  0.015012687779963016  Test L2 Loss :  0.026203453540802002  inv_L_scale:  [1.0, 1.0]
Epoch :  457  Time:  1.091  Rel. Train L2 Loss :  0.013836221616301271  Rel. Test L2 Loss :  0.015020366981625557  Test L2 Loss :  0.02620172806084156  inv_L_scale:  [1.0, 1.0]
Epoch :  458  Time:  1.09  Rel. Train L2 Loss :  0.01383557467824883  Rel. Test L2 Loss :  0.015018463283777237  Test L2 Loss :  0.0261996690928936  inv_L_scale:  [1.0, 1.0]
Epoch :  459  Time:  1.093  Rel. Train L2 Loss :  0.013837502304878499  Rel. Test L2 Loss :  0.014977798759937287  Test L2 Loss :  0.026144163981080056  inv_L_scale:  [1.0, 1.0]
Epoch :  460  Time:  1.091  Rel. Train L2 Loss :  0.013833010411924786  Rel. Test L2 Loss :  0.014998702481389046  Test L2 Loss :  0.02616596072912216  inv_L_scale:  [1.0, 1.0]
Epoch :  461  Time:  1.091  Rel. Train L2 Loss :  0.013852520208391879  Rel. Test L2 Loss :  0.015061273723840713  Test L2 Loss :  0.02630364254117012  inv_L_scale:  [1.0, 1.0]
Epoch :  462  Time:  1.09  Rel. Train L2 Loss :  0.013810263723134994  Rel. Test L2 Loss :  0.01499474748969078  Test L2 Loss :  0.026168830394744873  inv_L_scale:  [1.0, 1.0]
Epoch :  463  Time:  1.092  Rel. Train L2 Loss :  0.01379795778542757  Rel. Test L2 Loss :  0.015027476996183396  Test L2 Loss :  0.026209423691034316  inv_L_scale:  [1.0, 1.0]
Epoch :  464  Time:  1.091  Rel. Train L2 Loss :  0.013785473116570048  Rel. Test L2 Loss :  0.01503228858113289  Test L2 Loss :  0.026233836114406585  inv_L_scale:  [1.0, 1.0]
Epoch :  465  Time:  1.09  Rel. Train L2 Loss :  0.013790897578001022  Rel. Test L2 Loss :  0.015016377866268159  Test L2 Loss :  0.02623930349946022  inv_L_scale:  [1.0, 1.0]
Epoch :  466  Time:  1.091  Rel. Train L2 Loss :  0.013783728885981771  Rel. Test L2 Loss :  0.014961739555001258  Test L2 Loss :  0.02609549045562744  inv_L_scale:  [1.0, 1.0]
Epoch :  467  Time:  1.091  Rel. Train L2 Loss :  0.013775336936944061  Rel. Test L2 Loss :  0.01499350555241108  Test L2 Loss :  0.026151233911514284  inv_L_scale:  [1.0, 1.0]
Epoch :  468  Time:  1.091  Rel. Train L2 Loss :  0.013768699222968684  Rel. Test L2 Loss :  0.014997511506080627  Test L2 Loss :  0.02616121307015419  inv_L_scale:  [1.0, 1.0]
Epoch :  469  Time:  1.091  Rel. Train L2 Loss :  0.013775638139082325  Rel. Test L2 Loss :  0.014983055703341961  Test L2 Loss :  0.02614272862672806  inv_L_scale:  [1.0, 1.0]
Epoch :  470  Time:  1.091  Rel. Train L2 Loss :  0.013772652360300223  Rel. Test L2 Loss :  0.014975904151797295  Test L2 Loss :  0.02613684743642807  inv_L_scale:  [1.0, 1.0]
Epoch :  471  Time:  1.091  Rel. Train L2 Loss :  0.013750260455740822  Rel. Test L2 Loss :  0.014958700835704804  Test L2 Loss :  0.026091859340667725  inv_L_scale:  [1.0, 1.0]
Epoch :  472  Time:  1.091  Rel. Train L2 Loss :  0.013746119584474298  Rel. Test L2 Loss :  0.014980082288384438  Test L2 Loss :  0.026127834022045136  inv_L_scale:  [1.0, 1.0]
Epoch :  473  Time:  1.091  Rel. Train L2 Loss :  0.01373690487196048  Rel. Test L2 Loss :  0.014954728707671165  Test L2 Loss :  0.02609357438981533  inv_L_scale:  [1.0, 1.0]
Epoch :  474  Time:  1.093  Rel. Train L2 Loss :  0.013740186351868841  Rel. Test L2 Loss :  0.014991387650370598  Test L2 Loss :  0.026158703267574312  inv_L_scale:  [1.0, 1.0]
Epoch :  475  Time:  1.092  Rel. Train L2 Loss :  0.013736274002326859  Rel. Test L2 Loss :  0.01495445415377617  Test L2 Loss :  0.026089106798171998  inv_L_scale:  [1.0, 1.0]
Epoch :  476  Time:  1.09  Rel. Train L2 Loss :  0.01372576229688194  Rel. Test L2 Loss :  0.014964170679450035  Test L2 Loss :  0.026096964702010155  inv_L_scale:  [1.0, 1.0]
Epoch :  477  Time:  1.09  Rel. Train L2 Loss :  0.01372545551094744  Rel. Test L2 Loss :  0.014954797476530075  Test L2 Loss :  0.02608420416712761  inv_L_scale:  [1.0, 1.0]
Epoch :  478  Time:  1.091  Rel. Train L2 Loss :  0.013717213430338436  Rel. Test L2 Loss :  0.014959992840886116  Test L2 Loss :  0.026096160560846328  inv_L_scale:  [1.0, 1.0]
Epoch :  479  Time:  1.091  Rel. Train L2 Loss :  0.013712288584146234  Rel. Test L2 Loss :  0.014941454492509365  Test L2 Loss :  0.026061407923698425  inv_L_scale:  [1.0, 1.0]
Epoch :  480  Time:  1.091  Rel. Train L2 Loss :  0.01371416851050324  Rel. Test L2 Loss :  0.014959567934274673  Test L2 Loss :  0.02608555108308792  inv_L_scale:  [1.0, 1.0]
Epoch :  481  Time:  1.091  Rel. Train L2 Loss :  0.01370511144813564  Rel. Test L2 Loss :  0.014947418868541718  Test L2 Loss :  0.026072790697216987  inv_L_scale:  [1.0, 1.0]
Epoch :  482  Time:  1.091  Rel. Train L2 Loss :  0.013701694127586152  Rel. Test L2 Loss :  0.014953337796032428  Test L2 Loss :  0.02608032763004303  inv_L_scale:  [1.0, 1.0]
Epoch :  483  Time:  1.091  Rel. Train L2 Loss :  0.013706351862185532  Rel. Test L2 Loss :  0.014969961270689964  Test L2 Loss :  0.026107058674097062  inv_L_scale:  [1.0, 1.0]
Epoch :  484  Time:  1.091  Rel. Train L2 Loss :  0.013699616251720323  Rel. Test L2 Loss :  0.014950126260519028  Test L2 Loss :  0.026078812777996063  inv_L_scale:  [1.0, 1.0]
Epoch :  485  Time:  1.091  Rel. Train L2 Loss :  0.013695712892545594  Rel. Test L2 Loss :  0.014958952069282532  Test L2 Loss :  0.026095800995826722  inv_L_scale:  [1.0, 1.0]
Epoch :  486  Time:  1.092  Rel. Train L2 Loss :  0.013696318500571781  Rel. Test L2 Loss :  0.014963490962982178  Test L2 Loss :  0.02610767975449562  inv_L_scale:  [1.0, 1.0]
Epoch :  487  Time:  1.091  Rel. Train L2 Loss :  0.013693928519884746  Rel. Test L2 Loss :  0.014958458170294762  Test L2 Loss :  0.02608930766582489  inv_L_scale:  [1.0, 1.0]
Epoch :  488  Time:  1.092  Rel. Train L2 Loss :  0.013689094682534536  Rel. Test L2 Loss :  0.014952980652451516  Test L2 Loss :  0.026085061430931093  inv_L_scale:  [1.0, 1.0]
Epoch :  489  Time:  1.091  Rel. Train L2 Loss :  0.013688103647695647  Rel. Test L2 Loss :  0.0149470903724432  Test L2 Loss :  0.026073999926447867  inv_L_scale:  [1.0, 1.0]
Epoch :  490  Time:  1.091  Rel. Train L2 Loss :  0.013682914583219422  Rel. Test L2 Loss :  0.014952901713550092  Test L2 Loss :  0.026079202890396117  inv_L_scale:  [1.0, 1.0]
Epoch :  491  Time:  1.091  Rel. Train L2 Loss :  0.013678267602291372  Rel. Test L2 Loss :  0.014948911890387535  Test L2 Loss :  0.02607383728027344  inv_L_scale:  [1.0, 1.0]
Epoch :  492  Time:  1.092  Rel. Train L2 Loss :  0.013681780025362968  Rel. Test L2 Loss :  0.01495122529566288  Test L2 Loss :  0.026081254705786705  inv_L_scale:  [1.0, 1.0]
Epoch :  493  Time:  1.091  Rel. Train L2 Loss :  0.013674845981101195  Rel. Test L2 Loss :  0.014954781234264374  Test L2 Loss :  0.026082903444767  inv_L_scale:  [1.0, 1.0]
Epoch :  494  Time:  1.091  Rel. Train L2 Loss :  0.013678014257715808  Rel. Test L2 Loss :  0.014957940988242626  Test L2 Loss :  0.02609391085803509  inv_L_scale:  [1.0, 1.0]
Epoch :  495  Time:  1.091  Rel. Train L2 Loss :  0.013676863234076235  Rel. Test L2 Loss :  0.014947834797203541  Test L2 Loss :  0.02607871651649475  inv_L_scale:  [1.0, 1.0]
Epoch :  496  Time:  1.091  Rel. Train L2 Loss :  0.01367185680816571  Rel. Test L2 Loss :  0.014947363920509816  Test L2 Loss :  0.02606662333011627  inv_L_scale:  [1.0, 1.0]
Epoch :  497  Time:  1.091  Rel. Train L2 Loss :  0.013673536603649457  Rel. Test L2 Loss :  0.014948240146040917  Test L2 Loss :  0.026068341359496115  inv_L_scale:  [1.0, 1.0]
Epoch :  498  Time:  1.091  Rel. Train L2 Loss :  0.013674316224124697  Rel. Test L2 Loss :  0.014941960200667381  Test L2 Loss :  0.02606001190841198  inv_L_scale:  [1.0, 1.0]
Epoch :  499  Time:  1.091  Rel. Train L2 Loss :  0.013672713413834572  Rel. Test L2 Loss :  0.014940661303699017  Test L2 Loss :  0.026058014407753946  inv_L_scale:  [1.0, 1.0]
