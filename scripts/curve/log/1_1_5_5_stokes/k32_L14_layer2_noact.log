Loading data from  ../../data/curve//pcno_curve_data_1_1_5_5_stokes.npz
(1000,) (1000, 1000, 1) (1000, 1000, 2)
use normalized raw measures
Casting to tensor
x_train shape torch.Size([900, 1000, 6]), y_train shape torch.Size([900, 1000, 1])
length of each dim:  tensor([6.6455335617065430, 6.6654777526855469])
kmax = 32
L =  14
In PCNO_train, ndims =  2
Epoch :  0  Time:  9.663  Rel. Train L2 Loss :  0.5028153491020203  Rel. Test L2 Loss :  0.3061547005176544  Test L2 Loss :  0.5519606113433838  inv_L_scale:  [1.0, 1.0]
Epoch :  1  Time:  2.577  Rel. Train L2 Loss :  0.24973210136095683  Rel. Test L2 Loss :  0.2116682571172714  Test L2 Loss :  0.38843265891075135  inv_L_scale:  [1.0, 1.0]
Epoch :  2  Time:  2.576  Rel. Train L2 Loss :  0.18333746121989355  Rel. Test L2 Loss :  0.1766521030664444  Test L2 Loss :  0.33628638863563537  inv_L_scale:  [1.0, 1.0]
Epoch :  3  Time:  2.577  Rel. Train L2 Loss :  0.15112630122237736  Rel. Test L2 Loss :  0.14332017600536345  Test L2 Loss :  0.2660836219787598  inv_L_scale:  [1.0, 1.0]
Epoch :  4  Time:  2.576  Rel. Train L2 Loss :  0.1283664176861445  Rel. Test L2 Loss :  0.12280762374401093  Test L2 Loss :  0.22907690942287445  inv_L_scale:  [1.0, 1.0]
Epoch :  5  Time:  2.577  Rel. Train L2 Loss :  0.11427973263793521  Rel. Test L2 Loss :  0.11208210468292236  Test L2 Loss :  0.21269529044628144  inv_L_scale:  [1.0, 1.0]
Epoch :  6  Time:  2.574  Rel. Train L2 Loss :  0.10649006681309806  Rel. Test L2 Loss :  0.10323854118585586  Test L2 Loss :  0.1927215951681137  inv_L_scale:  [1.0, 1.0]
Epoch :  7  Time:  2.575  Rel. Train L2 Loss :  0.09672855214940176  Rel. Test L2 Loss :  0.09935183078050613  Test L2 Loss :  0.18319386065006257  inv_L_scale:  [1.0, 1.0]
Epoch :  8  Time:  2.576  Rel. Train L2 Loss :  0.08810520874129402  Rel. Test L2 Loss :  0.10121669888496398  Test L2 Loss :  0.18477773904800415  inv_L_scale:  [1.0, 1.0]
Epoch :  9  Time:  2.575  Rel. Train L2 Loss :  0.08554544823037254  Rel. Test L2 Loss :  0.08847549200057983  Test L2 Loss :  0.16150423049926757  inv_L_scale:  [1.0, 1.0]
Epoch :  10  Time:  2.576  Rel. Train L2 Loss :  0.08151944388945898  Rel. Test L2 Loss :  0.0887736988067627  Test L2 Loss :  0.16585389256477356  inv_L_scale:  [1.0, 1.0]
Epoch :  11  Time:  2.574  Rel. Train L2 Loss :  0.07813631819354164  Rel. Test L2 Loss :  0.07985013306140899  Test L2 Loss :  0.14676768124103545  inv_L_scale:  [1.0, 1.0]
Epoch :  12  Time:  2.573  Rel. Train L2 Loss :  0.0708178570204311  Rel. Test L2 Loss :  0.08531262874603271  Test L2 Loss :  0.15540967285633087  inv_L_scale:  [1.0, 1.0]
Epoch :  13  Time:  2.575  Rel. Train L2 Loss :  0.07329741140206655  Rel. Test L2 Loss :  0.07176686599850654  Test L2 Loss :  0.13125238120555877  inv_L_scale:  [1.0, 1.0]
Epoch :  14  Time:  2.573  Rel. Train L2 Loss :  0.06705654849608739  Rel. Test L2 Loss :  0.07102370589971542  Test L2 Loss :  0.1305120050907135  inv_L_scale:  [1.0, 1.0]
Epoch :  15  Time:  2.573  Rel. Train L2 Loss :  0.0636665304005146  Rel. Test L2 Loss :  0.06641912847757339  Test L2 Loss :  0.12398976981639862  inv_L_scale:  [1.0, 1.0]
Epoch :  16  Time:  2.576  Rel. Train L2 Loss :  0.06070096400048998  Rel. Test L2 Loss :  0.06859950736165046  Test L2 Loss :  0.12456919074058533  inv_L_scale:  [1.0, 1.0]
Epoch :  17  Time:  2.574  Rel. Train L2 Loss :  0.060981259412235686  Rel. Test L2 Loss :  0.06398032203316689  Test L2 Loss :  0.11701285481452942  inv_L_scale:  [1.0, 1.0]
Epoch :  18  Time:  2.574  Rel. Train L2 Loss :  0.056471740206082664  Rel. Test L2 Loss :  0.06461986005306244  Test L2 Loss :  0.1196105906367302  inv_L_scale:  [1.0, 1.0]
Epoch :  19  Time:  2.573  Rel. Train L2 Loss :  0.05591621491644118  Rel. Test L2 Loss :  0.05865628376603126  Test L2 Loss :  0.10753091812133789  inv_L_scale:  [1.0, 1.0]
Epoch :  20  Time:  2.575  Rel. Train L2 Loss :  0.05450413819816378  Rel. Test L2 Loss :  0.06853200629353523  Test L2 Loss :  0.12340112656354904  inv_L_scale:  [1.0, 1.0]
Epoch :  21  Time:  2.574  Rel. Train L2 Loss :  0.05963916291793187  Rel. Test L2 Loss :  0.06052560016512871  Test L2 Loss :  0.11216902852058411  inv_L_scale:  [1.0, 1.0]
Epoch :  22  Time:  2.574  Rel. Train L2 Loss :  0.05285763512055079  Rel. Test L2 Loss :  0.0628251412510872  Test L2 Loss :  0.1145265257358551  inv_L_scale:  [1.0, 1.0]
Epoch :  23  Time:  2.576  Rel. Train L2 Loss :  0.05338177816735373  Rel. Test L2 Loss :  0.06135768428444863  Test L2 Loss :  0.11075305759906769  inv_L_scale:  [1.0, 1.0]
Epoch :  24  Time:  2.574  Rel. Train L2 Loss :  0.051893277333842386  Rel. Test L2 Loss :  0.05158133491873741  Test L2 Loss :  0.09358887910842896  inv_L_scale:  [1.0, 1.0]
Epoch :  25  Time:  2.573  Rel. Train L2 Loss :  0.050261327723662055  Rel. Test L2 Loss :  0.056667303442955015  Test L2 Loss :  0.10356180131435394  inv_L_scale:  [1.0, 1.0]
Epoch :  26  Time:  2.573  Rel. Train L2 Loss :  0.049905670318338605  Rel. Test L2 Loss :  0.05138032615184784  Test L2 Loss :  0.09359624743461609  inv_L_scale:  [1.0, 1.0]
Epoch :  27  Time:  2.572  Rel. Train L2 Loss :  0.052453900691535736  Rel. Test L2 Loss :  0.05931552827358246  Test L2 Loss :  0.10646538525819778  inv_L_scale:  [1.0, 1.0]
Epoch :  28  Time:  2.574  Rel. Train L2 Loss :  0.0498842332429356  Rel. Test L2 Loss :  0.05943799749016762  Test L2 Loss :  0.11028383493423462  inv_L_scale:  [1.0, 1.0]
Epoch :  29  Time:  2.572  Rel. Train L2 Loss :  0.04990919573439492  Rel. Test L2 Loss :  0.05796025425195694  Test L2 Loss :  0.10764061540365219  inv_L_scale:  [1.0, 1.0]
Epoch :  30  Time:  2.572  Rel. Train L2 Loss :  0.051336209194527735  Rel. Test L2 Loss :  0.05294083148241043  Test L2 Loss :  0.09520939409732819  inv_L_scale:  [1.0, 1.0]
Epoch :  31  Time:  2.574  Rel. Train L2 Loss :  0.048503758973545495  Rel. Test L2 Loss :  0.05688308626413345  Test L2 Loss :  0.1050696337223053  inv_L_scale:  [1.0, 1.0]
Epoch :  32  Time:  2.573  Rel. Train L2 Loss :  0.04832220491435793  Rel. Test L2 Loss :  0.048846139311790465  Test L2 Loss :  0.08789710760116577  inv_L_scale:  [1.0, 1.0]
Epoch :  33  Time:  2.574  Rel. Train L2 Loss :  0.04626131320993106  Rel. Test L2 Loss :  0.050920492112636564  Test L2 Loss :  0.09208334386348724  inv_L_scale:  [1.0, 1.0]
Epoch :  34  Time:  2.571  Rel. Train L2 Loss :  0.04611176629861196  Rel. Test L2 Loss :  0.05258818581700325  Test L2 Loss :  0.09802383720874787  inv_L_scale:  [1.0, 1.0]
Epoch :  35  Time:  2.57  Rel. Train L2 Loss :  0.04368376394112905  Rel. Test L2 Loss :  0.05333272784948349  Test L2 Loss :  0.09575584292411804  inv_L_scale:  [1.0, 1.0]
Epoch :  36  Time:  2.565  Rel. Train L2 Loss :  0.0457615194718043  Rel. Test L2 Loss :  0.051479933261871336  Test L2 Loss :  0.0924912452697754  inv_L_scale:  [1.0, 1.0]
Epoch :  37  Time:  2.566  Rel. Train L2 Loss :  0.04494150365392367  Rel. Test L2 Loss :  0.046916663348674774  Test L2 Loss :  0.08505414009094238  inv_L_scale:  [1.0, 1.0]
Epoch :  38  Time:  2.565  Rel. Train L2 Loss :  0.044453990823692745  Rel. Test L2 Loss :  0.05146234706044197  Test L2 Loss :  0.09423433959484101  inv_L_scale:  [1.0, 1.0]
Epoch :  39  Time:  2.566  Rel. Train L2 Loss :  0.042696738027864035  Rel. Test L2 Loss :  0.04531286999583244  Test L2 Loss :  0.08262696623802185  inv_L_scale:  [1.0, 1.0]
Epoch :  40  Time:  2.566  Rel. Train L2 Loss :  0.042415236234664914  Rel. Test L2 Loss :  0.04893457561731338  Test L2 Loss :  0.0894666287302971  inv_L_scale:  [1.0, 1.0]
Epoch :  41  Time:  2.567  Rel. Train L2 Loss :  0.04469492604335149  Rel. Test L2 Loss :  0.049571926891803744  Test L2 Loss :  0.0889360249042511  inv_L_scale:  [1.0, 1.0]
Epoch :  42  Time:  2.567  Rel. Train L2 Loss :  0.044413602699836095  Rel. Test L2 Loss :  0.051882712692022326  Test L2 Loss :  0.09439893573522568  inv_L_scale:  [1.0, 1.0]
Epoch :  43  Time:  2.568  Rel. Train L2 Loss :  0.04295682001445029  Rel. Test L2 Loss :  0.047538134157657626  Test L2 Loss :  0.0861470091342926  inv_L_scale:  [1.0, 1.0]
Epoch :  44  Time:  2.568  Rel. Train L2 Loss :  0.04194770559668541  Rel. Test L2 Loss :  0.04462298333644867  Test L2 Loss :  0.08016062021255493  inv_L_scale:  [1.0, 1.0]
Epoch :  45  Time:  2.571  Rel. Train L2 Loss :  0.04237535254822837  Rel. Test L2 Loss :  0.046319873332977296  Test L2 Loss :  0.08460401237010956  inv_L_scale:  [1.0, 1.0]
Epoch :  46  Time:  2.572  Rel. Train L2 Loss :  0.040698168559206854  Rel. Test L2 Loss :  0.0533273708820343  Test L2 Loss :  0.09675248503684998  inv_L_scale:  [1.0, 1.0]
Epoch :  47  Time:  2.575  Rel. Train L2 Loss :  0.04067285481426451  Rel. Test L2 Loss :  0.048622775673866275  Test L2 Loss :  0.0876795044541359  inv_L_scale:  [1.0, 1.0]
Epoch :  48  Time:  2.576  Rel. Train L2 Loss :  0.04000882224904166  Rel. Test L2 Loss :  0.04643566429615021  Test L2 Loss :  0.0855773350596428  inv_L_scale:  [1.0, 1.0]
Epoch :  49  Time:  2.581  Rel. Train L2 Loss :  0.042041182633903294  Rel. Test L2 Loss :  0.04484504669904709  Test L2 Loss :  0.08131009936332703  inv_L_scale:  [1.0, 1.0]
Epoch :  50  Time:  2.582  Rel. Train L2 Loss :  0.0405299836728308  Rel. Test L2 Loss :  0.04779299467802048  Test L2 Loss :  0.08630194038152694  inv_L_scale:  [1.0, 1.0]
Epoch :  51  Time:  2.582  Rel. Train L2 Loss :  0.03991191628906462  Rel. Test L2 Loss :  0.045160427242517474  Test L2 Loss :  0.08066469728946686  inv_L_scale:  [1.0, 1.0]
Epoch :  52  Time:  2.581  Rel. Train L2 Loss :  0.04040860391325421  Rel. Test L2 Loss :  0.04302102297544479  Test L2 Loss :  0.07693912208080292  inv_L_scale:  [1.0, 1.0]
Epoch :  53  Time:  2.575  Rel. Train L2 Loss :  0.03785714281929864  Rel. Test L2 Loss :  0.04670803666114807  Test L2 Loss :  0.08328267335891723  inv_L_scale:  [1.0, 1.0]
Epoch :  54  Time:  2.574  Rel. Train L2 Loss :  0.04042211578951942  Rel. Test L2 Loss :  0.0446765398979187  Test L2 Loss :  0.0802398157119751  inv_L_scale:  [1.0, 1.0]
Epoch :  55  Time:  2.57  Rel. Train L2 Loss :  0.041027327511045666  Rel. Test L2 Loss :  0.046252745985984806  Test L2 Loss :  0.08213745564222336  inv_L_scale:  [1.0, 1.0]
Epoch :  56  Time:  2.569  Rel. Train L2 Loss :  0.03821931312481562  Rel. Test L2 Loss :  0.03947314530611038  Test L2 Loss :  0.07097665667533874  inv_L_scale:  [1.0, 1.0]
Epoch :  57  Time:  2.565  Rel. Train L2 Loss :  0.040155086095134414  Rel. Test L2 Loss :  0.044902353733778  Test L2 Loss :  0.08071472764015197  inv_L_scale:  [1.0, 1.0]
Epoch :  58  Time:  2.564  Rel. Train L2 Loss :  0.0397297103703022  Rel. Test L2 Loss :  0.046938116252422335  Test L2 Loss :  0.08729974150657654  inv_L_scale:  [1.0, 1.0]
Epoch :  59  Time:  2.565  Rel. Train L2 Loss :  0.038614130400949055  Rel. Test L2 Loss :  0.04215287834405899  Test L2 Loss :  0.07636255204677582  inv_L_scale:  [1.0, 1.0]
Epoch :  60  Time:  2.564  Rel. Train L2 Loss :  0.03675772690110737  Rel. Test L2 Loss :  0.04426537528634071  Test L2 Loss :  0.0809856754541397  inv_L_scale:  [1.0, 1.0]
Epoch :  61  Time:  2.563  Rel. Train L2 Loss :  0.03738662944899665  Rel. Test L2 Loss :  0.04239655911922455  Test L2 Loss :  0.07542251914739609  inv_L_scale:  [1.0, 1.0]
Epoch :  62  Time:  2.565  Rel. Train L2 Loss :  0.03795061162776417  Rel. Test L2 Loss :  0.04100966155529022  Test L2 Loss :  0.07434577584266662  inv_L_scale:  [1.0, 1.0]
Epoch :  63  Time:  2.564  Rel. Train L2 Loss :  0.03653392428325282  Rel. Test L2 Loss :  0.04337115213274956  Test L2 Loss :  0.07803895145654678  inv_L_scale:  [1.0, 1.0]
Epoch :  64  Time:  2.564  Rel. Train L2 Loss :  0.038001793722311654  Rel. Test L2 Loss :  0.03847133055329323  Test L2 Loss :  0.06854680329561233  inv_L_scale:  [1.0, 1.0]
Epoch :  65  Time:  2.563  Rel. Train L2 Loss :  0.03615051981475618  Rel. Test L2 Loss :  0.049249076545238496  Test L2 Loss :  0.0904065215587616  inv_L_scale:  [1.0, 1.0]
Epoch :  66  Time:  2.563  Rel. Train L2 Loss :  0.036724928650591106  Rel. Test L2 Loss :  0.043481408506631854  Test L2 Loss :  0.07783153474330902  inv_L_scale:  [1.0, 1.0]
Epoch :  67  Time:  2.564  Rel. Train L2 Loss :  0.03496020062102212  Rel. Test L2 Loss :  0.04441356688737869  Test L2 Loss :  0.07964863926172257  inv_L_scale:  [1.0, 1.0]
Epoch :  68  Time:  2.564  Rel. Train L2 Loss :  0.03657501796881358  Rel. Test L2 Loss :  0.035833745673298834  Test L2 Loss :  0.06416621446609497  inv_L_scale:  [1.0, 1.0]
Epoch :  69  Time:  2.566  Rel. Train L2 Loss :  0.03461840998795297  Rel. Test L2 Loss :  0.03660665422677994  Test L2 Loss :  0.06527799636125564  inv_L_scale:  [1.0, 1.0]
Epoch :  70  Time:  2.564  Rel. Train L2 Loss :  0.03293382050262557  Rel. Test L2 Loss :  0.03813931196928024  Test L2 Loss :  0.06858901798725128  inv_L_scale:  [1.0, 1.0]
Epoch :  71  Time:  2.564  Rel. Train L2 Loss :  0.03342586389846272  Rel. Test L2 Loss :  0.037211408019065854  Test L2 Loss :  0.06669125348329544  inv_L_scale:  [1.0, 1.0]
Epoch :  72  Time:  2.565  Rel. Train L2 Loss :  0.033554883235030704  Rel. Test L2 Loss :  0.037234192490577696  Test L2 Loss :  0.06656734809279442  inv_L_scale:  [1.0, 1.0]
Epoch :  73  Time:  2.564  Rel. Train L2 Loss :  0.03647025917967161  Rel. Test L2 Loss :  0.041498683393001556  Test L2 Loss :  0.07423677682876587  inv_L_scale:  [1.0, 1.0]
Epoch :  74  Time:  2.564  Rel. Train L2 Loss :  0.03335644829604361  Rel. Test L2 Loss :  0.03654595375061035  Test L2 Loss :  0.06566835880279541  inv_L_scale:  [1.0, 1.0]
Epoch :  75  Time:  2.565  Rel. Train L2 Loss :  0.03336978420615196  Rel. Test L2 Loss :  0.03704389989376068  Test L2 Loss :  0.06743659943342209  inv_L_scale:  [1.0, 1.0]
Epoch :  76  Time:  2.564  Rel. Train L2 Loss :  0.03392220324940152  Rel. Test L2 Loss :  0.03521558552980423  Test L2 Loss :  0.0635744246840477  inv_L_scale:  [1.0, 1.0]
Epoch :  77  Time:  2.565  Rel. Train L2 Loss :  0.032595800211032235  Rel. Test L2 Loss :  0.036323142722249034  Test L2 Loss :  0.0643577218055725  inv_L_scale:  [1.0, 1.0]
Epoch :  78  Time:  2.565  Rel. Train L2 Loss :  0.0329754728741116  Rel. Test L2 Loss :  0.03661608159542084  Test L2 Loss :  0.06542632609605789  inv_L_scale:  [1.0, 1.0]
Epoch :  79  Time:  2.566  Rel. Train L2 Loss :  0.0334370887445079  Rel. Test L2 Loss :  0.032129524275660515  Test L2 Loss :  0.05709891825914383  inv_L_scale:  [1.0, 1.0]
Epoch :  80  Time:  2.564  Rel. Train L2 Loss :  0.03222494911816385  Rel. Test L2 Loss :  0.034896845892071725  Test L2 Loss :  0.0631570826470852  inv_L_scale:  [1.0, 1.0]
Epoch :  81  Time:  2.565  Rel. Train L2 Loss :  0.03210614543822077  Rel. Test L2 Loss :  0.03635827913880348  Test L2 Loss :  0.064848363250494  inv_L_scale:  [1.0, 1.0]
Epoch :  82  Time:  2.565  Rel. Train L2 Loss :  0.030959406942129133  Rel. Test L2 Loss :  0.040482692420482635  Test L2 Loss :  0.07497669517993927  inv_L_scale:  [1.0, 1.0]
Epoch :  83  Time:  2.565  Rel. Train L2 Loss :  0.031462520675526726  Rel. Test L2 Loss :  0.03443404823541641  Test L2 Loss :  0.0613898691534996  inv_L_scale:  [1.0, 1.0]
Epoch :  84  Time:  2.564  Rel. Train L2 Loss :  0.03200299898783366  Rel. Test L2 Loss :  0.0407775154709816  Test L2 Loss :  0.07519614338874817  inv_L_scale:  [1.0, 1.0]
Epoch :  85  Time:  2.564  Rel. Train L2 Loss :  0.030668709352612497  Rel. Test L2 Loss :  0.03545091986656189  Test L2 Loss :  0.06369703993201256  inv_L_scale:  [1.0, 1.0]
Epoch :  86  Time:  2.565  Rel. Train L2 Loss :  0.030800757333636283  Rel. Test L2 Loss :  0.03501710921525955  Test L2 Loss :  0.06317729353904725  inv_L_scale:  [1.0, 1.0]
Epoch :  87  Time:  2.565  Rel. Train L2 Loss :  0.030915647579563988  Rel. Test L2 Loss :  0.033711807951331135  Test L2 Loss :  0.06002197995781899  inv_L_scale:  [1.0, 1.0]
Epoch :  88  Time:  2.564  Rel. Train L2 Loss :  0.030695923243959745  Rel. Test L2 Loss :  0.037638798803091046  Test L2 Loss :  0.06767080843448639  inv_L_scale:  [1.0, 1.0]
Epoch :  89  Time:  2.564  Rel. Train L2 Loss :  0.030101855678690805  Rel. Test L2 Loss :  0.030515365824103354  Test L2 Loss :  0.05432317778468132  inv_L_scale:  [1.0, 1.0]
Epoch :  90  Time:  2.565  Rel. Train L2 Loss :  0.029383792637123003  Rel. Test L2 Loss :  0.037991833984851835  Test L2 Loss :  0.06989238262176514  inv_L_scale:  [1.0, 1.0]
Epoch :  91  Time:  2.564  Rel. Train L2 Loss :  0.02988328453567293  Rel. Test L2 Loss :  0.03603852331638336  Test L2 Loss :  0.06543285220861435  inv_L_scale:  [1.0, 1.0]
Epoch :  92  Time:  2.563  Rel. Train L2 Loss :  0.030009942485226527  Rel. Test L2 Loss :  0.03339119374752045  Test L2 Loss :  0.05964527502655983  inv_L_scale:  [1.0, 1.0]
Epoch :  93  Time:  2.564  Rel. Train L2 Loss :  0.029375993526644176  Rel. Test L2 Loss :  0.03172261983156204  Test L2 Loss :  0.056788723766803745  inv_L_scale:  [1.0, 1.0]
Epoch :  94  Time:  2.565  Rel. Train L2 Loss :  0.028551046715842354  Rel. Test L2 Loss :  0.030873593538999558  Test L2 Loss :  0.055246388018131254  inv_L_scale:  [1.0, 1.0]
Epoch :  95  Time:  2.564  Rel. Train L2 Loss :  0.02850572985907396  Rel. Test L2 Loss :  0.03220925986766815  Test L2 Loss :  0.058115478754043576  inv_L_scale:  [1.0, 1.0]
Epoch :  96  Time:  2.564  Rel. Train L2 Loss :  0.028444060335556666  Rel. Test L2 Loss :  0.031200576424598694  Test L2 Loss :  0.055569111555814746  inv_L_scale:  [1.0, 1.0]
Epoch :  97  Time:  2.563  Rel. Train L2 Loss :  0.028572829961776732  Rel. Test L2 Loss :  0.03390601992607117  Test L2 Loss :  0.06013074576854706  inv_L_scale:  [1.0, 1.0]
Epoch :  98  Time:  2.564  Rel. Train L2 Loss :  0.027787739700741238  Rel. Test L2 Loss :  0.03347153551876545  Test L2 Loss :  0.06043732896447182  inv_L_scale:  [1.0, 1.0]
Epoch :  99  Time:  2.564  Rel. Train L2 Loss :  0.02821572028928333  Rel. Test L2 Loss :  0.0312280510365963  Test L2 Loss :  0.05595267742872238  inv_L_scale:  [1.0, 1.0]
Epoch :  100  Time:  2.564  Rel. Train L2 Loss :  0.027578505650162698  Rel. Test L2 Loss :  0.029987132549285887  Test L2 Loss :  0.05360727965831757  inv_L_scale:  [1.0, 1.0]
Epoch :  101  Time:  2.565  Rel. Train L2 Loss :  0.028443813390201994  Rel. Test L2 Loss :  0.034178415909409524  Test L2 Loss :  0.0614974556863308  inv_L_scale:  [1.0, 1.0]
Epoch :  102  Time:  2.568  Rel. Train L2 Loss :  0.027794814854860305  Rel. Test L2 Loss :  0.03657114326953888  Test L2 Loss :  0.06487272441387176  inv_L_scale:  [1.0, 1.0]
Epoch :  103  Time:  2.571  Rel. Train L2 Loss :  0.027892731146679985  Rel. Test L2 Loss :  0.03115728735923767  Test L2 Loss :  0.055977417826652526  inv_L_scale:  [1.0, 1.0]
Epoch :  104  Time:  2.565  Rel. Train L2 Loss :  0.0271453963054551  Rel. Test L2 Loss :  0.030448871254920958  Test L2 Loss :  0.054846264719963074  inv_L_scale:  [1.0, 1.0]
Epoch :  105  Time:  2.564  Rel. Train L2 Loss :  0.026929634875721403  Rel. Test L2 Loss :  0.029415097534656525  Test L2 Loss :  0.052265163660049435  inv_L_scale:  [1.0, 1.0]
Epoch :  106  Time:  2.564  Rel. Train L2 Loss :  0.026831861469480727  Rel. Test L2 Loss :  0.029055095687508584  Test L2 Loss :  0.0527783876657486  inv_L_scale:  [1.0, 1.0]
Epoch :  107  Time:  2.566  Rel. Train L2 Loss :  0.02604962425927321  Rel. Test L2 Loss :  0.03128428116440773  Test L2 Loss :  0.05582883790135384  inv_L_scale:  [1.0, 1.0]
Epoch :  108  Time:  2.566  Rel. Train L2 Loss :  0.027353462220893965  Rel. Test L2 Loss :  0.028819146305322646  Test L2 Loss :  0.05145277976989746  inv_L_scale:  [1.0, 1.0]
Epoch :  109  Time:  2.567  Rel. Train L2 Loss :  0.02706762634217739  Rel. Test L2 Loss :  0.02895932987332344  Test L2 Loss :  0.05153755664825439  inv_L_scale:  [1.0, 1.0]
Epoch :  110  Time:  2.568  Rel. Train L2 Loss :  0.025599398993783527  Rel. Test L2 Loss :  0.032554456889629366  Test L2 Loss :  0.05888668209314346  inv_L_scale:  [1.0, 1.0]
Epoch :  111  Time:  2.569  Rel. Train L2 Loss :  0.02599308399690522  Rel. Test L2 Loss :  0.027286770939826965  Test L2 Loss :  0.048592234253883364  inv_L_scale:  [1.0, 1.0]
Epoch :  112  Time:  2.57  Rel. Train L2 Loss :  0.0250813351240423  Rel. Test L2 Loss :  0.027248702421784402  Test L2 Loss :  0.04828859806060791  inv_L_scale:  [1.0, 1.0]
Epoch :  113  Time:  2.57  Rel. Train L2 Loss :  0.024781260093053183  Rel. Test L2 Loss :  0.03431653663516045  Test L2 Loss :  0.06306896805763244  inv_L_scale:  [1.0, 1.0]
Epoch :  114  Time:  2.57  Rel. Train L2 Loss :  0.0260049045085907  Rel. Test L2 Loss :  0.029317052215337754  Test L2 Loss :  0.05215544700622558  inv_L_scale:  [1.0, 1.0]
Epoch :  115  Time:  2.57  Rel. Train L2 Loss :  0.025974087003204558  Rel. Test L2 Loss :  0.03164013788104057  Test L2 Loss :  0.05666413128376007  inv_L_scale:  [1.0, 1.0]
Epoch :  116  Time:  2.573  Rel. Train L2 Loss :  0.026121121504240567  Rel. Test L2 Loss :  0.028946664705872534  Test L2 Loss :  0.052145060002803806  inv_L_scale:  [1.0, 1.0]
Epoch :  117  Time:  2.572  Rel. Train L2 Loss :  0.025202263825469546  Rel. Test L2 Loss :  0.029188134521245957  Test L2 Loss :  0.05269535019993782  inv_L_scale:  [1.0, 1.0]
Epoch :  118  Time:  2.571  Rel. Train L2 Loss :  0.025169092135296927  Rel. Test L2 Loss :  0.029800898134708403  Test L2 Loss :  0.05294575974345207  inv_L_scale:  [1.0, 1.0]
Epoch :  119  Time:  2.57  Rel. Train L2 Loss :  0.025382969636056157  Rel. Test L2 Loss :  0.032485444769263266  Test L2 Loss :  0.059319393634796144  inv_L_scale:  [1.0, 1.0]
Epoch :  120  Time:  2.57  Rel. Train L2 Loss :  0.025012362168894874  Rel. Test L2 Loss :  0.027353131547570228  Test L2 Loss :  0.048871242105960847  inv_L_scale:  [1.0, 1.0]
Epoch :  121  Time:  2.569  Rel. Train L2 Loss :  0.025249562938180235  Rel. Test L2 Loss :  0.028934104815125466  Test L2 Loss :  0.051610177755355834  inv_L_scale:  [1.0, 1.0]
Epoch :  122  Time:  2.568  Rel. Train L2 Loss :  0.024697505368126763  Rel. Test L2 Loss :  0.03168957479298115  Test L2 Loss :  0.05623527497053146  inv_L_scale:  [1.0, 1.0]
Epoch :  123  Time:  2.567  Rel. Train L2 Loss :  0.025566748397217856  Rel. Test L2 Loss :  0.029167399555444718  Test L2 Loss :  0.052238072454929355  inv_L_scale:  [1.0, 1.0]
Epoch :  124  Time:  2.566  Rel. Train L2 Loss :  0.0246943399310112  Rel. Test L2 Loss :  0.026431810706853867  Test L2 Loss :  0.04731214910745621  inv_L_scale:  [1.0, 1.0]
Epoch :  125  Time:  2.563  Rel. Train L2 Loss :  0.024675259904728995  Rel. Test L2 Loss :  0.025913824141025544  Test L2 Loss :  0.04619790583848953  inv_L_scale:  [1.0, 1.0]
Epoch :  126  Time:  2.563  Rel. Train L2 Loss :  0.023900253971417745  Rel. Test L2 Loss :  0.03116789013147354  Test L2 Loss :  0.056038968116045  inv_L_scale:  [1.0, 1.0]
Epoch :  127  Time:  2.561  Rel. Train L2 Loss :  0.024789191650019752  Rel. Test L2 Loss :  0.02885327935218811  Test L2 Loss :  0.05126224100589752  inv_L_scale:  [1.0, 1.0]
Epoch :  128  Time:  2.56  Rel. Train L2 Loss :  0.02414398704965909  Rel. Test L2 Loss :  0.027739141434431076  Test L2 Loss :  0.04958331316709518  inv_L_scale:  [1.0, 1.0]
Epoch :  129  Time:  2.561  Rel. Train L2 Loss :  0.024137502229875988  Rel. Test L2 Loss :  0.026543427854776383  Test L2 Loss :  0.04720442399382591  inv_L_scale:  [1.0, 1.0]
Epoch :  130  Time:  2.562  Rel. Train L2 Loss :  0.024035852005084356  Rel. Test L2 Loss :  0.027762435972690583  Test L2 Loss :  0.04972951307892799  inv_L_scale:  [1.0, 1.0]
Epoch :  131  Time:  2.562  Rel. Train L2 Loss :  0.025193910284174812  Rel. Test L2 Loss :  0.025844507068395615  Test L2 Loss :  0.046447844356298444  inv_L_scale:  [1.0, 1.0]
Epoch :  132  Time:  2.562  Rel. Train L2 Loss :  0.023726453623837896  Rel. Test L2 Loss :  0.02586747393012047  Test L2 Loss :  0.04607769936323166  inv_L_scale:  [1.0, 1.0]
Epoch :  133  Time:  2.562  Rel. Train L2 Loss :  0.023857040868865118  Rel. Test L2 Loss :  0.024733675420284273  Test L2 Loss :  0.043990519493818284  inv_L_scale:  [1.0, 1.0]
Epoch :  134  Time:  2.561  Rel. Train L2 Loss :  0.023839749743541083  Rel. Test L2 Loss :  0.027337404936552047  Test L2 Loss :  0.04793754547834397  inv_L_scale:  [1.0, 1.0]
Epoch :  135  Time:  2.561  Rel. Train L2 Loss :  0.024102370573414696  Rel. Test L2 Loss :  0.025969255715608597  Test L2 Loss :  0.046214445531368255  inv_L_scale:  [1.0, 1.0]
Epoch :  136  Time:  2.561  Rel. Train L2 Loss :  0.023393071509069868  Rel. Test L2 Loss :  0.02721504494547844  Test L2 Loss :  0.04895743995904923  inv_L_scale:  [1.0, 1.0]
Epoch :  137  Time:  2.561  Rel. Train L2 Loss :  0.023943516463041305  Rel. Test L2 Loss :  0.02692051209509373  Test L2 Loss :  0.04884364202618599  inv_L_scale:  [1.0, 1.0]
Epoch :  138  Time:  2.561  Rel. Train L2 Loss :  0.023436665634314218  Rel. Test L2 Loss :  0.026057006195187568  Test L2 Loss :  0.04648837804794312  inv_L_scale:  [1.0, 1.0]
Epoch :  139  Time:  2.562  Rel. Train L2 Loss :  0.0233245968984233  Rel. Test L2 Loss :  0.028745399340987205  Test L2 Loss :  0.05124191164970398  inv_L_scale:  [1.0, 1.0]
Epoch :  140  Time:  2.561  Rel. Train L2 Loss :  0.023455241355631085  Rel. Test L2 Loss :  0.025755554363131525  Test L2 Loss :  0.045838774144649506  inv_L_scale:  [1.0, 1.0]
Epoch :  141  Time:  2.562  Rel. Train L2 Loss :  0.024207315155201487  Rel. Test L2 Loss :  0.023851434215903283  Test L2 Loss :  0.04230017960071564  inv_L_scale:  [1.0, 1.0]
Epoch :  142  Time:  2.562  Rel. Train L2 Loss :  0.022066771818531884  Rel. Test L2 Loss :  0.026149745136499404  Test L2 Loss :  0.04643109083175659  inv_L_scale:  [1.0, 1.0]
Epoch :  143  Time:  2.563  Rel. Train L2 Loss :  0.023001171516047584  Rel. Test L2 Loss :  0.024502408131957053  Test L2 Loss :  0.04340480074286461  inv_L_scale:  [1.0, 1.0]
Epoch :  144  Time:  2.562  Rel. Train L2 Loss :  0.02269137674735652  Rel. Test L2 Loss :  0.028583209216594695  Test L2 Loss :  0.0508514392375946  inv_L_scale:  [1.0, 1.0]
Epoch :  145  Time:  2.562  Rel. Train L2 Loss :  0.022504717566900784  Rel. Test L2 Loss :  0.024327148497104645  Test L2 Loss :  0.04360304117202759  inv_L_scale:  [1.0, 1.0]
Epoch :  146  Time:  2.561  Rel. Train L2 Loss :  0.02240851250787576  Rel. Test L2 Loss :  0.028002151101827622  Test L2 Loss :  0.050035524368286136  inv_L_scale:  [1.0, 1.0]
Epoch :  147  Time:  2.562  Rel. Train L2 Loss :  0.022714233994483947  Rel. Test L2 Loss :  0.02787716343998909  Test L2 Loss :  0.04938497856259346  inv_L_scale:  [1.0, 1.0]
Epoch :  148  Time:  2.563  Rel. Train L2 Loss :  0.022866880032751294  Rel. Test L2 Loss :  0.026251152604818345  Test L2 Loss :  0.04678351446986198  inv_L_scale:  [1.0, 1.0]
Epoch :  149  Time:  2.562  Rel. Train L2 Loss :  0.02235243880914317  Rel. Test L2 Loss :  0.025092114880681037  Test L2 Loss :  0.04455203860998154  inv_L_scale:  [1.0, 1.0]
Epoch :  150  Time:  2.562  Rel. Train L2 Loss :  0.022635052940911716  Rel. Test L2 Loss :  0.02484112374484539  Test L2 Loss :  0.04421855896711349  inv_L_scale:  [1.0, 1.0]
Epoch :  151  Time:  2.562  Rel. Train L2 Loss :  0.022563102311558194  Rel. Test L2 Loss :  0.02592085674405098  Test L2 Loss :  0.04618851065635681  inv_L_scale:  [1.0, 1.0]
Epoch :  152  Time:  2.562  Rel. Train L2 Loss :  0.021950367962320645  Rel. Test L2 Loss :  0.02393427610397339  Test L2 Loss :  0.042822377979755404  inv_L_scale:  [1.0, 1.0]
Epoch :  153  Time:  2.562  Rel. Train L2 Loss :  0.02231686515112718  Rel. Test L2 Loss :  0.025300415903329848  Test L2 Loss :  0.045077537596225736  inv_L_scale:  [1.0, 1.0]
Epoch :  154  Time:  2.562  Rel. Train L2 Loss :  0.022025226354598998  Rel. Test L2 Loss :  0.027330262362957002  Test L2 Loss :  0.04941169053316116  inv_L_scale:  [1.0, 1.0]
Epoch :  155  Time:  2.562  Rel. Train L2 Loss :  0.021989558769596948  Rel. Test L2 Loss :  0.025930477231740953  Test L2 Loss :  0.046563322991132736  inv_L_scale:  [1.0, 1.0]
Epoch :  156  Time:  2.562  Rel. Train L2 Loss :  0.02238218309978644  Rel. Test L2 Loss :  0.026670915186405183  Test L2 Loss :  0.0476785197854042  inv_L_scale:  [1.0, 1.0]
Epoch :  157  Time:  2.562  Rel. Train L2 Loss :  0.022687677302294307  Rel. Test L2 Loss :  0.02467972457408905  Test L2 Loss :  0.04408737897872925  inv_L_scale:  [1.0, 1.0]
Epoch :  158  Time:  2.563  Rel. Train L2 Loss :  0.021840759217739106  Rel. Test L2 Loss :  0.02534722775220871  Test L2 Loss :  0.04530086874961853  inv_L_scale:  [1.0, 1.0]
Epoch :  159  Time:  2.563  Rel. Train L2 Loss :  0.02152002324660619  Rel. Test L2 Loss :  0.024130857810378076  Test L2 Loss :  0.042855492979288104  inv_L_scale:  [1.0, 1.0]
Epoch :  160  Time:  2.564  Rel. Train L2 Loss :  0.021774026147193377  Rel. Test L2 Loss :  0.022341214790940284  Test L2 Loss :  0.039560596346855166  inv_L_scale:  [1.0, 1.0]
Epoch :  161  Time:  2.562  Rel. Train L2 Loss :  0.021458197948005464  Rel. Test L2 Loss :  0.023823399245738983  Test L2 Loss :  0.042480705976486205  inv_L_scale:  [1.0, 1.0]
Epoch :  162  Time:  2.563  Rel. Train L2 Loss :  0.02174184934132629  Rel. Test L2 Loss :  0.02622226983308792  Test L2 Loss :  0.04697763279080391  inv_L_scale:  [1.0, 1.0]
Epoch :  163  Time:  2.563  Rel. Train L2 Loss :  0.02130216434597969  Rel. Test L2 Loss :  0.02533048689365387  Test L2 Loss :  0.045494016855955124  inv_L_scale:  [1.0, 1.0]
Epoch :  164  Time:  2.562  Rel. Train L2 Loss :  0.02201559681031439  Rel. Test L2 Loss :  0.02643835552036762  Test L2 Loss :  0.04731722682714462  inv_L_scale:  [1.0, 1.0]
Epoch :  165  Time:  2.563  Rel. Train L2 Loss :  0.021559218698077733  Rel. Test L2 Loss :  0.02380532018840313  Test L2 Loss :  0.04223378390073776  inv_L_scale:  [1.0, 1.0]
Epoch :  166  Time:  2.563  Rel. Train L2 Loss :  0.020805466779404216  Rel. Test L2 Loss :  0.02466202884912491  Test L2 Loss :  0.04387054160237312  inv_L_scale:  [1.0, 1.0]
Epoch :  167  Time:  2.562  Rel. Train L2 Loss :  0.0209887103156911  Rel. Test L2 Loss :  0.02433641016483307  Test L2 Loss :  0.043383681923151014  inv_L_scale:  [1.0, 1.0]
Epoch :  168  Time:  2.562  Rel. Train L2 Loss :  0.021082371340857612  Rel. Test L2 Loss :  0.023678761273622513  Test L2 Loss :  0.04195569097995758  inv_L_scale:  [1.0, 1.0]
Epoch :  169  Time:  2.563  Rel. Train L2 Loss :  0.02116850578950511  Rel. Test L2 Loss :  0.02367659702897072  Test L2 Loss :  0.041784105449914934  inv_L_scale:  [1.0, 1.0]
Epoch :  170  Time:  2.562  Rel. Train L2 Loss :  0.021090673936737907  Rel. Test L2 Loss :  0.02400801032781601  Test L2 Loss :  0.042581757009029386  inv_L_scale:  [1.0, 1.0]
Epoch :  171  Time:  2.563  Rel. Train L2 Loss :  0.021014066628283923  Rel. Test L2 Loss :  0.02323956787586212  Test L2 Loss :  0.04111495763063431  inv_L_scale:  [1.0, 1.0]
Epoch :  172  Time:  2.564  Rel. Train L2 Loss :  0.02084509058131112  Rel. Test L2 Loss :  0.0249440935254097  Test L2 Loss :  0.04434531107544899  inv_L_scale:  [1.0, 1.0]
Epoch :  173  Time:  2.564  Rel. Train L2 Loss :  0.02089190016190211  Rel. Test L2 Loss :  0.02492988795042038  Test L2 Loss :  0.04416590869426727  inv_L_scale:  [1.0, 1.0]
Epoch :  174  Time:  2.567  Rel. Train L2 Loss :  0.021593830063939095  Rel. Test L2 Loss :  0.0236895552277565  Test L2 Loss :  0.04225519597530365  inv_L_scale:  [1.0, 1.0]
Epoch :  175  Time:  2.566  Rel. Train L2 Loss :  0.020710855747262637  Rel. Test L2 Loss :  0.02376535698771477  Test L2 Loss :  0.042032077610492706  inv_L_scale:  [1.0, 1.0]
Epoch :  176  Time:  2.565  Rel. Train L2 Loss :  0.021117805225981605  Rel. Test L2 Loss :  0.024298217445611954  Test L2 Loss :  0.04364785209298134  inv_L_scale:  [1.0, 1.0]
Epoch :  177  Time:  2.565  Rel. Train L2 Loss :  0.0213688188791275  Rel. Test L2 Loss :  0.02297510899603367  Test L2 Loss :  0.040366486757993696  inv_L_scale:  [1.0, 1.0]
Epoch :  178  Time:  2.569  Rel. Train L2 Loss :  0.020904334237178166  Rel. Test L2 Loss :  0.02396354451775551  Test L2 Loss :  0.04228929698467255  inv_L_scale:  [1.0, 1.0]
Epoch :  179  Time:  2.569  Rel. Train L2 Loss :  0.020816245128711063  Rel. Test L2 Loss :  0.02350705921649933  Test L2 Loss :  0.042143195718526844  inv_L_scale:  [1.0, 1.0]
Epoch :  180  Time:  2.569  Rel. Train L2 Loss :  0.02106213482303752  Rel. Test L2 Loss :  0.022968319952487947  Test L2 Loss :  0.04062644004821778  inv_L_scale:  [1.0, 1.0]
Epoch :  181  Time:  2.569  Rel. Train L2 Loss :  0.020356530249118807  Rel. Test L2 Loss :  0.02429847329854965  Test L2 Loss :  0.04289278715848923  inv_L_scale:  [1.0, 1.0]
Epoch :  182  Time:  2.568  Rel. Train L2 Loss :  0.020689089861181047  Rel. Test L2 Loss :  0.0221912807226181  Test L2 Loss :  0.039217940717935565  inv_L_scale:  [1.0, 1.0]
Epoch :  183  Time:  2.57  Rel. Train L2 Loss :  0.02046917791167895  Rel. Test L2 Loss :  0.023162092566490173  Test L2 Loss :  0.04152810588479042  inv_L_scale:  [1.0, 1.0]
Epoch :  184  Time:  2.57  Rel. Train L2 Loss :  0.020345683689746593  Rel. Test L2 Loss :  0.02234855681657791  Test L2 Loss :  0.039533494859933856  inv_L_scale:  [1.0, 1.0]
Epoch :  185  Time:  2.57  Rel. Train L2 Loss :  0.02026064765950044  Rel. Test L2 Loss :  0.02286516308784485  Test L2 Loss :  0.04033571988344192  inv_L_scale:  [1.0, 1.0]
Epoch :  186  Time:  2.569  Rel. Train L2 Loss :  0.0207816501127349  Rel. Test L2 Loss :  0.023219972550868988  Test L2 Loss :  0.04105414390563965  inv_L_scale:  [1.0, 1.0]
Epoch :  187  Time:  2.568  Rel. Train L2 Loss :  0.020175806888275676  Rel. Test L2 Loss :  0.022473320886492728  Test L2 Loss :  0.039948783218860626  inv_L_scale:  [1.0, 1.0]
Epoch :  188  Time:  2.567  Rel. Train L2 Loss :  0.020643524370259708  Rel. Test L2 Loss :  0.022357315123081208  Test L2 Loss :  0.03952694416046142  inv_L_scale:  [1.0, 1.0]
Epoch :  189  Time:  2.567  Rel. Train L2 Loss :  0.0201443748590019  Rel. Test L2 Loss :  0.02150769770145416  Test L2 Loss :  0.03787648245692253  inv_L_scale:  [1.0, 1.0]
Epoch :  190  Time:  2.567  Rel. Train L2 Loss :  0.020100491009652614  Rel. Test L2 Loss :  0.022451953291893006  Test L2 Loss :  0.039474622905254365  inv_L_scale:  [1.0, 1.0]
Epoch :  191  Time:  2.566  Rel. Train L2 Loss :  0.020336320623755455  Rel. Test L2 Loss :  0.022153782695531844  Test L2 Loss :  0.03910094425082207  inv_L_scale:  [1.0, 1.0]
Epoch :  192  Time:  2.565  Rel. Train L2 Loss :  0.019984031377567185  Rel. Test L2 Loss :  0.021336800903081894  Test L2 Loss :  0.03777402892708778  inv_L_scale:  [1.0, 1.0]
Epoch :  193  Time:  2.562  Rel. Train L2 Loss :  0.019938250564866596  Rel. Test L2 Loss :  0.022681330069899558  Test L2 Loss :  0.03965833753347397  inv_L_scale:  [1.0, 1.0]
Epoch :  194  Time:  2.562  Rel. Train L2 Loss :  0.020576651030116612  Rel. Test L2 Loss :  0.023159461542963982  Test L2 Loss :  0.04082646816968918  inv_L_scale:  [1.0, 1.0]
Epoch :  195  Time:  2.562  Rel. Train L2 Loss :  0.020315292220976618  Rel. Test L2 Loss :  0.024174795746803285  Test L2 Loss :  0.04290787398815155  inv_L_scale:  [1.0, 1.0]
Epoch :  196  Time:  2.56  Rel. Train L2 Loss :  0.020263057301441827  Rel. Test L2 Loss :  0.024757539182901384  Test L2 Loss :  0.04450887948274612  inv_L_scale:  [1.0, 1.0]
Epoch :  197  Time:  2.561  Rel. Train L2 Loss :  0.01996163644724422  Rel. Test L2 Loss :  0.023420310020446776  Test L2 Loss :  0.04140710115432739  inv_L_scale:  [1.0, 1.0]
Epoch :  198  Time:  2.561  Rel. Train L2 Loss :  0.020097181648015976  Rel. Test L2 Loss :  0.02348404884338379  Test L2 Loss :  0.041917880475521085  inv_L_scale:  [1.0, 1.0]
Epoch :  199  Time:  2.561  Rel. Train L2 Loss :  0.01970346863898966  Rel. Test L2 Loss :  0.02168500542640686  Test L2 Loss :  0.038661367744207385  inv_L_scale:  [1.0, 1.0]
Epoch :  200  Time:  2.562  Rel. Train L2 Loss :  0.019985382159550983  Rel. Test L2 Loss :  0.023786817714571952  Test L2 Loss :  0.04196896344423294  inv_L_scale:  [1.0, 1.0]
Epoch :  201  Time:  2.561  Rel. Train L2 Loss :  0.01985041360060374  Rel. Test L2 Loss :  0.02501166895031929  Test L2 Loss :  0.044858791530132294  inv_L_scale:  [1.0, 1.0]
Epoch :  202  Time:  2.561  Rel. Train L2 Loss :  0.019985089699427288  Rel. Test L2 Loss :  0.022225651293992996  Test L2 Loss :  0.03910449147224426  inv_L_scale:  [1.0, 1.0]
Epoch :  203  Time:  2.56  Rel. Train L2 Loss :  0.019956575772828528  Rel. Test L2 Loss :  0.02089612275362015  Test L2 Loss :  0.036797631978988644  inv_L_scale:  [1.0, 1.0]
Epoch :  204  Time:  2.561  Rel. Train L2 Loss :  0.019799297592706152  Rel. Test L2 Loss :  0.022522622495889665  Test L2 Loss :  0.03963896840810776  inv_L_scale:  [1.0, 1.0]
Epoch :  205  Time:  2.561  Rel. Train L2 Loss :  0.01950989478164249  Rel. Test L2 Loss :  0.022560286074876784  Test L2 Loss :  0.04032980591058731  inv_L_scale:  [1.0, 1.0]
Epoch :  206  Time:  2.561  Rel. Train L2 Loss :  0.019481944599085383  Rel. Test L2 Loss :  0.022035340219736098  Test L2 Loss :  0.039012602269649505  inv_L_scale:  [1.0, 1.0]
Epoch :  207  Time:  2.56  Rel. Train L2 Loss :  0.01961923303703467  Rel. Test L2 Loss :  0.02176247149705887  Test L2 Loss :  0.03847178354859352  inv_L_scale:  [1.0, 1.0]
Epoch :  208  Time:  2.561  Rel. Train L2 Loss :  0.019401051592495708  Rel. Test L2 Loss :  0.02151177391409874  Test L2 Loss :  0.037642239779233935  inv_L_scale:  [1.0, 1.0]
Epoch :  209  Time:  2.561  Rel. Train L2 Loss :  0.019351772061652606  Rel. Test L2 Loss :  0.023235499933362005  Test L2 Loss :  0.04158683925867081  inv_L_scale:  [1.0, 1.0]
Epoch :  210  Time:  2.561  Rel. Train L2 Loss :  0.019769774162107043  Rel. Test L2 Loss :  0.021633609607815744  Test L2 Loss :  0.03777531176805496  inv_L_scale:  [1.0, 1.0]
Epoch :  211  Time:  2.562  Rel. Train L2 Loss :  0.01955123150514232  Rel. Test L2 Loss :  0.023395689278841017  Test L2 Loss :  0.041646558046340945  inv_L_scale:  [1.0, 1.0]
Epoch :  212  Time:  2.56  Rel. Train L2 Loss :  0.019601439841919477  Rel. Test L2 Loss :  0.021652593314647674  Test L2 Loss :  0.03827963337302208  inv_L_scale:  [1.0, 1.0]
Epoch :  213  Time:  2.56  Rel. Train L2 Loss :  0.019613179978397156  Rel. Test L2 Loss :  0.02173324704170227  Test L2 Loss :  0.038375082910060886  inv_L_scale:  [1.0, 1.0]
Epoch :  214  Time:  2.562  Rel. Train L2 Loss :  0.019465156975719662  Rel. Test L2 Loss :  0.021587601080536842  Test L2 Loss :  0.038278711438179014  inv_L_scale:  [1.0, 1.0]
Epoch :  215  Time:  2.56  Rel. Train L2 Loss :  0.019091955547531445  Rel. Test L2 Loss :  0.02175540365278721  Test L2 Loss :  0.03833104401826858  inv_L_scale:  [1.0, 1.0]
Epoch :  216  Time:  2.56  Rel. Train L2 Loss :  0.019538304830590884  Rel. Test L2 Loss :  0.022930498942732813  Test L2 Loss :  0.040816348195075985  inv_L_scale:  [1.0, 1.0]
Epoch :  217  Time:  2.56  Rel. Train L2 Loss :  0.019361295219924714  Rel. Test L2 Loss :  0.020443662405014038  Test L2 Loss :  0.03598085671663284  inv_L_scale:  [1.0, 1.0]
Epoch :  218  Time:  2.559  Rel. Train L2 Loss :  0.018959306296375062  Rel. Test L2 Loss :  0.020768932700157165  Test L2 Loss :  0.03643469467759133  inv_L_scale:  [1.0, 1.0]
Epoch :  219  Time:  2.56  Rel. Train L2 Loss :  0.01917529152499305  Rel. Test L2 Loss :  0.02107041984796524  Test L2 Loss :  0.03710423946380615  inv_L_scale:  [1.0, 1.0]
Epoch :  220  Time:  2.56  Rel. Train L2 Loss :  0.01926717640625106  Rel. Test L2 Loss :  0.021432586312294007  Test L2 Loss :  0.03757404401898384  inv_L_scale:  [1.0, 1.0]
Epoch :  221  Time:  2.56  Rel. Train L2 Loss :  0.018864043802022935  Rel. Test L2 Loss :  0.021378800943493842  Test L2 Loss :  0.03794665724039078  inv_L_scale:  [1.0, 1.0]
Epoch :  222  Time:  2.56  Rel. Train L2 Loss :  0.019139532960123485  Rel. Test L2 Loss :  0.02121924325823784  Test L2 Loss :  0.03751814603805542  inv_L_scale:  [1.0, 1.0]
Epoch :  223  Time:  2.56  Rel. Train L2 Loss :  0.019394762768513627  Rel. Test L2 Loss :  0.021697701811790468  Test L2 Loss :  0.03875879049301147  inv_L_scale:  [1.0, 1.0]
Epoch :  224  Time:  2.56  Rel. Train L2 Loss :  0.019118245533770985  Rel. Test L2 Loss :  0.02179514490067959  Test L2 Loss :  0.03842545002698898  inv_L_scale:  [1.0, 1.0]
Epoch :  225  Time:  2.56  Rel. Train L2 Loss :  0.019182383178008928  Rel. Test L2 Loss :  0.021460593789815904  Test L2 Loss :  0.037687576711177825  inv_L_scale:  [1.0, 1.0]
Epoch :  226  Time:  2.56  Rel. Train L2 Loss :  0.01874268833961752  Rel. Test L2 Loss :  0.020944531112909316  Test L2 Loss :  0.036743341386318205  inv_L_scale:  [1.0, 1.0]
Epoch :  227  Time:  2.562  Rel. Train L2 Loss :  0.018687009041508038  Rel. Test L2 Loss :  0.02109349086880684  Test L2 Loss :  0.037182742059230806  inv_L_scale:  [1.0, 1.0]
Epoch :  228  Time:  2.561  Rel. Train L2 Loss :  0.01879092528588242  Rel. Test L2 Loss :  0.021940571516752244  Test L2 Loss :  0.03884514048695564  inv_L_scale:  [1.0, 1.0]
Epoch :  229  Time:  2.56  Rel. Train L2 Loss :  0.018723664813571506  Rel. Test L2 Loss :  0.02271143436431885  Test L2 Loss :  0.04083849310874939  inv_L_scale:  [1.0, 1.0]
Epoch :  230  Time:  2.56  Rel. Train L2 Loss :  0.018735846057534217  Rel. Test L2 Loss :  0.020859993547201156  Test L2 Loss :  0.03657539695501327  inv_L_scale:  [1.0, 1.0]
Epoch :  231  Time:  2.56  Rel. Train L2 Loss :  0.01877869201203187  Rel. Test L2 Loss :  0.021467576920986175  Test L2 Loss :  0.03780506163835526  inv_L_scale:  [1.0, 1.0]
Epoch :  232  Time:  2.561  Rel. Train L2 Loss :  0.01824733400510417  Rel. Test L2 Loss :  0.021937804371118544  Test L2 Loss :  0.03890220910310745  inv_L_scale:  [1.0, 1.0]
Epoch :  233  Time:  2.561  Rel. Train L2 Loss :  0.018702347630427944  Rel. Test L2 Loss :  0.020089764073491098  Test L2 Loss :  0.03527598738670349  inv_L_scale:  [1.0, 1.0]
Epoch :  234  Time:  2.561  Rel. Train L2 Loss :  0.018352725737624698  Rel. Test L2 Loss :  0.020981459617614745  Test L2 Loss :  0.03703014343976974  inv_L_scale:  [1.0, 1.0]
Epoch :  235  Time:  2.561  Rel. Train L2 Loss :  0.018719119396474627  Rel. Test L2 Loss :  0.021299350783228876  Test L2 Loss :  0.037439124882221224  inv_L_scale:  [1.0, 1.0]
Epoch :  236  Time:  2.561  Rel. Train L2 Loss :  0.01870181088646253  Rel. Test L2 Loss :  0.020730914771556853  Test L2 Loss :  0.03614900067448616  inv_L_scale:  [1.0, 1.0]
Epoch :  237  Time:  2.561  Rel. Train L2 Loss :  0.018478386766380733  Rel. Test L2 Loss :  0.02120495222508907  Test L2 Loss :  0.03752071559429169  inv_L_scale:  [1.0, 1.0]
Epoch :  238  Time:  2.561  Rel. Train L2 Loss :  0.018553185338775317  Rel. Test L2 Loss :  0.019856711328029634  Test L2 Loss :  0.034668179899454116  inv_L_scale:  [1.0, 1.0]
Epoch :  239  Time:  2.562  Rel. Train L2 Loss :  0.01849218808942371  Rel. Test L2 Loss :  0.021314215809106828  Test L2 Loss :  0.037858439087867735  inv_L_scale:  [1.0, 1.0]
Epoch :  240  Time:  2.561  Rel. Train L2 Loss :  0.018305613092250293  Rel. Test L2 Loss :  0.021785954982042312  Test L2 Loss :  0.038862183839082715  inv_L_scale:  [1.0, 1.0]
Epoch :  241  Time:  2.56  Rel. Train L2 Loss :  0.018243454777532152  Rel. Test L2 Loss :  0.02285962350666523  Test L2 Loss :  0.04126790583133697  inv_L_scale:  [1.0, 1.0]
Epoch :  242  Time:  2.561  Rel. Train L2 Loss :  0.018538933503958913  Rel. Test L2 Loss :  0.020454956889152526  Test L2 Loss :  0.03579034015536308  inv_L_scale:  [1.0, 1.0]
Epoch :  243  Time:  2.562  Rel. Train L2 Loss :  0.01820397273533874  Rel. Test L2 Loss :  0.020769860595464706  Test L2 Loss :  0.03658352494239807  inv_L_scale:  [1.0, 1.0]
Epoch :  244  Time:  2.56  Rel. Train L2 Loss :  0.01847764626145363  Rel. Test L2 Loss :  0.02011729568243027  Test L2 Loss :  0.03527867376804352  inv_L_scale:  [1.0, 1.0]
Epoch :  245  Time:  2.561  Rel. Train L2 Loss :  0.018185461941692564  Rel. Test L2 Loss :  0.01992826201021671  Test L2 Loss :  0.03478929489850998  inv_L_scale:  [1.0, 1.0]
Epoch :  246  Time:  2.561  Rel. Train L2 Loss :  0.01811812865237395  Rel. Test L2 Loss :  0.020668191611766817  Test L2 Loss :  0.03669924944639206  inv_L_scale:  [1.0, 1.0]
Epoch :  247  Time:  2.561  Rel. Train L2 Loss :  0.01805228596760167  Rel. Test L2 Loss :  0.0198930624127388  Test L2 Loss :  0.034928016215562824  inv_L_scale:  [1.0, 1.0]
Epoch :  248  Time:  2.562  Rel. Train L2 Loss :  0.018534316254986655  Rel. Test L2 Loss :  0.021295481324195863  Test L2 Loss :  0.03820774838328361  inv_L_scale:  [1.0, 1.0]
Epoch :  249  Time:  2.561  Rel. Train L2 Loss :  0.018262531202700404  Rel. Test L2 Loss :  0.021479662954807282  Test L2 Loss :  0.03808148458600044  inv_L_scale:  [1.0, 1.0]
Epoch :  250  Time:  2.561  Rel. Train L2 Loss :  0.01801135508964459  Rel. Test L2 Loss :  0.020327151715755463  Test L2 Loss :  0.035751830339431766  inv_L_scale:  [1.0, 1.0]
Epoch :  251  Time:  2.561  Rel. Train L2 Loss :  0.018369816111193763  Rel. Test L2 Loss :  0.02082494005560875  Test L2 Loss :  0.036958647966384886  inv_L_scale:  [1.0, 1.0]
Epoch :  252  Time:  2.561  Rel. Train L2 Loss :  0.018004555155833563  Rel. Test L2 Loss :  0.020473021566867828  Test L2 Loss :  0.03601616770029068  inv_L_scale:  [1.0, 1.0]
Epoch :  253  Time:  2.561  Rel. Train L2 Loss :  0.018167797658178542  Rel. Test L2 Loss :  0.020870868414640427  Test L2 Loss :  0.03655608475208282  inv_L_scale:  [1.0, 1.0]
Epoch :  254  Time:  2.56  Rel. Train L2 Loss :  0.017927024397585128  Rel. Test L2 Loss :  0.02009294033050537  Test L2 Loss :  0.03509290084242821  inv_L_scale:  [1.0, 1.0]
Epoch :  255  Time:  2.561  Rel. Train L2 Loss :  0.01787333562142319  Rel. Test L2 Loss :  0.020448508113622664  Test L2 Loss :  0.035863581597805026  inv_L_scale:  [1.0, 1.0]
Epoch :  256  Time:  2.56  Rel. Train L2 Loss :  0.017778931996888583  Rel. Test L2 Loss :  0.020772117376327514  Test L2 Loss :  0.036691903471946716  inv_L_scale:  [1.0, 1.0]
Epoch :  257  Time:  2.562  Rel. Train L2 Loss :  0.01808050274848938  Rel. Test L2 Loss :  0.020973140075802803  Test L2 Loss :  0.036755675077438356  inv_L_scale:  [1.0, 1.0]
Epoch :  258  Time:  2.562  Rel. Train L2 Loss :  0.017966928113665844  Rel. Test L2 Loss :  0.020613578259944917  Test L2 Loss :  0.03620444744825363  inv_L_scale:  [1.0, 1.0]
Epoch :  259  Time:  2.561  Rel. Train L2 Loss :  0.017822696082293987  Rel. Test L2 Loss :  0.020368199944496155  Test L2 Loss :  0.0357835628092289  inv_L_scale:  [1.0, 1.0]
Epoch :  260  Time:  2.56  Rel. Train L2 Loss :  0.01773710941274961  Rel. Test L2 Loss :  0.01936728186905384  Test L2 Loss :  0.03409325450658798  inv_L_scale:  [1.0, 1.0]
Epoch :  261  Time:  2.561  Rel. Train L2 Loss :  0.017603686385684544  Rel. Test L2 Loss :  0.020353744849562646  Test L2 Loss :  0.035750673413276673  inv_L_scale:  [1.0, 1.0]
Epoch :  262  Time:  2.561  Rel. Train L2 Loss :  0.017708502295944426  Rel. Test L2 Loss :  0.02005271442234516  Test L2 Loss :  0.035796565413475034  inv_L_scale:  [1.0, 1.0]
Epoch :  263  Time:  2.56  Rel. Train L2 Loss :  0.017749292105436326  Rel. Test L2 Loss :  0.01980585902929306  Test L2 Loss :  0.03472019910812378  inv_L_scale:  [1.0, 1.0]
Epoch :  264  Time:  2.56  Rel. Train L2 Loss :  0.01743026551273134  Rel. Test L2 Loss :  0.020013265013694763  Test L2 Loss :  0.035114440321922305  inv_L_scale:  [1.0, 1.0]
Epoch :  265  Time:  2.56  Rel. Train L2 Loss :  0.0175937922216124  Rel. Test L2 Loss :  0.019489791691303254  Test L2 Loss :  0.03418838649988174  inv_L_scale:  [1.0, 1.0]
Epoch :  266  Time:  2.56  Rel. Train L2 Loss :  0.017719163265493183  Rel. Test L2 Loss :  0.019920085296034812  Test L2 Loss :  0.03476826161146164  inv_L_scale:  [1.0, 1.0]
Epoch :  267  Time:  2.56  Rel. Train L2 Loss :  0.017396708329518635  Rel. Test L2 Loss :  0.018892778381705284  Test L2 Loss :  0.033222799450159074  inv_L_scale:  [1.0, 1.0]
Epoch :  268  Time:  2.56  Rel. Train L2 Loss :  0.01747396813498603  Rel. Test L2 Loss :  0.01928559526801109  Test L2 Loss :  0.033766966760158536  inv_L_scale:  [1.0, 1.0]
Epoch :  269  Time:  2.56  Rel. Train L2 Loss :  0.017282208046979376  Rel. Test L2 Loss :  0.019672531932592392  Test L2 Loss :  0.03449634820222855  inv_L_scale:  [1.0, 1.0]
Epoch :  270  Time:  2.561  Rel. Train L2 Loss :  0.01775357496407297  Rel. Test L2 Loss :  0.020432096123695374  Test L2 Loss :  0.03594071477651596  inv_L_scale:  [1.0, 1.0]
Epoch :  271  Time:  2.562  Rel. Train L2 Loss :  0.01780090206199222  Rel. Test L2 Loss :  0.02016646057367325  Test L2 Loss :  0.035466595441102984  inv_L_scale:  [1.0, 1.0]
Epoch :  272  Time:  2.56  Rel. Train L2 Loss :  0.017372095920145512  Rel. Test L2 Loss :  0.020147036239504815  Test L2 Loss :  0.035498531013727186  inv_L_scale:  [1.0, 1.0]
Epoch :  273  Time:  2.56  Rel. Train L2 Loss :  0.01775183514588409  Rel. Test L2 Loss :  0.022379353269934656  Test L2 Loss :  0.03974790617823601  inv_L_scale:  [1.0, 1.0]
Epoch :  274  Time:  2.561  Rel. Train L2 Loss :  0.017749445819192463  Rel. Test L2 Loss :  0.01991723619401455  Test L2 Loss :  0.034849130511283875  inv_L_scale:  [1.0, 1.0]
Epoch :  275  Time:  2.56  Rel. Train L2 Loss :  0.017274850739373102  Rel. Test L2 Loss :  0.01960928738117218  Test L2 Loss :  0.03421908646821976  inv_L_scale:  [1.0, 1.0]
Epoch :  276  Time:  2.56  Rel. Train L2 Loss :  0.01723034852494796  Rel. Test L2 Loss :  0.019534571394324303  Test L2 Loss :  0.034528077840805055  inv_L_scale:  [1.0, 1.0]
Epoch :  277  Time:  2.56  Rel. Train L2 Loss :  0.01708132617175579  Rel. Test L2 Loss :  0.01926192671060562  Test L2 Loss :  0.033691339939832685  inv_L_scale:  [1.0, 1.0]
Epoch :  278  Time:  2.56  Rel. Train L2 Loss :  0.01713965063293775  Rel. Test L2 Loss :  0.01937060847878456  Test L2 Loss :  0.03402609363198281  inv_L_scale:  [1.0, 1.0]
Epoch :  279  Time:  2.562  Rel. Train L2 Loss :  0.017291955633295907  Rel. Test L2 Loss :  0.019776843562722204  Test L2 Loss :  0.03487837299704552  inv_L_scale:  [1.0, 1.0]
Epoch :  280  Time:  2.56  Rel. Train L2 Loss :  0.017239039747251404  Rel. Test L2 Loss :  0.019839293509721755  Test L2 Loss :  0.034574110507965085  inv_L_scale:  [1.0, 1.0]
Epoch :  281  Time:  2.56  Rel. Train L2 Loss :  0.017322513088583947  Rel. Test L2 Loss :  0.01988682709634304  Test L2 Loss :  0.03518685042858124  inv_L_scale:  [1.0, 1.0]
Epoch :  282  Time:  2.56  Rel. Train L2 Loss :  0.017109094278679952  Rel. Test L2 Loss :  0.01915403634309769  Test L2 Loss :  0.03348623365163803  inv_L_scale:  [1.0, 1.0]
Epoch :  283  Time:  2.56  Rel. Train L2 Loss :  0.01699852919412984  Rel. Test L2 Loss :  0.019559881761670114  Test L2 Loss :  0.03427981808781624  inv_L_scale:  [1.0, 1.0]
Epoch :  284  Time:  2.56  Rel. Train L2 Loss :  0.017033253014087677  Rel. Test L2 Loss :  0.018778236284852028  Test L2 Loss :  0.03296258293092251  inv_L_scale:  [1.0, 1.0]
Epoch :  285  Time:  2.56  Rel. Train L2 Loss :  0.017016890421509744  Rel. Test L2 Loss :  0.019493700340390205  Test L2 Loss :  0.034323399513959886  inv_L_scale:  [1.0, 1.0]
Epoch :  286  Time:  2.56  Rel. Train L2 Loss :  0.017075888440012933  Rel. Test L2 Loss :  0.0190291690826416  Test L2 Loss :  0.033368212580680845  inv_L_scale:  [1.0, 1.0]
Epoch :  287  Time:  2.56  Rel. Train L2 Loss :  0.016953629296686916  Rel. Test L2 Loss :  0.019444818273186684  Test L2 Loss :  0.034215806424617766  inv_L_scale:  [1.0, 1.0]
Epoch :  288  Time:  2.56  Rel. Train L2 Loss :  0.017094750652710596  Rel. Test L2 Loss :  0.01941738322377205  Test L2 Loss :  0.033922885358333585  inv_L_scale:  [1.0, 1.0]
Epoch :  289  Time:  2.56  Rel. Train L2 Loss :  0.01684747418595685  Rel. Test L2 Loss :  0.019228609055280687  Test L2 Loss :  0.03373967438936234  inv_L_scale:  [1.0, 1.0]
Epoch :  290  Time:  2.56  Rel. Train L2 Loss :  0.016871049718724357  Rel. Test L2 Loss :  0.01921810142695904  Test L2 Loss :  0.033642624467611314  inv_L_scale:  [1.0, 1.0]
Epoch :  291  Time:  2.56  Rel. Train L2 Loss :  0.01691072901089986  Rel. Test L2 Loss :  0.01956070922315121  Test L2 Loss :  0.034284605830907824  inv_L_scale:  [1.0, 1.0]
Epoch :  292  Time:  2.561  Rel. Train L2 Loss :  0.016864974002043405  Rel. Test L2 Loss :  0.0191512930393219  Test L2 Loss :  0.03362032815814018  inv_L_scale:  [1.0, 1.0]
Epoch :  293  Time:  2.56  Rel. Train L2 Loss :  0.01706893492076132  Rel. Test L2 Loss :  0.01852960094809532  Test L2 Loss :  0.032367997020483014  inv_L_scale:  [1.0, 1.0]
Epoch :  294  Time:  2.56  Rel. Train L2 Loss :  0.016884795336259736  Rel. Test L2 Loss :  0.01953580282628536  Test L2 Loss :  0.034375492036342624  inv_L_scale:  [1.0, 1.0]
Epoch :  295  Time:  2.56  Rel. Train L2 Loss :  0.016749549325969483  Rel. Test L2 Loss :  0.020624392852187156  Test L2 Loss :  0.0366781410574913  inv_L_scale:  [1.0, 1.0]
Epoch :  296  Time:  2.56  Rel. Train L2 Loss :  0.01691040000981755  Rel. Test L2 Loss :  0.021409525349736214  Test L2 Loss :  0.037907200157642366  inv_L_scale:  [1.0, 1.0]
Epoch :  297  Time:  2.56  Rel. Train L2 Loss :  0.016853921206461057  Rel. Test L2 Loss :  0.01920809917151928  Test L2 Loss :  0.033410060405731204  inv_L_scale:  [1.0, 1.0]
Epoch :  298  Time:  2.56  Rel. Train L2 Loss :  0.016666470252805286  Rel. Test L2 Loss :  0.019957816004753114  Test L2 Loss :  0.03509158313274383  inv_L_scale:  [1.0, 1.0]
Epoch :  299  Time:  2.56  Rel. Train L2 Loss :  0.01663770659102334  Rel. Test L2 Loss :  0.019186626300215722  Test L2 Loss :  0.03362507537007332  inv_L_scale:  [1.0, 1.0]
Epoch :  300  Time:  2.561  Rel. Train L2 Loss :  0.016796122168501217  Rel. Test L2 Loss :  0.018243886530399323  Test L2 Loss :  0.0317018785327673  inv_L_scale:  [1.0, 1.0]
Epoch :  301  Time:  2.56  Rel. Train L2 Loss :  0.016604196594821083  Rel. Test L2 Loss :  0.0185662180185318  Test L2 Loss :  0.03247964732348919  inv_L_scale:  [1.0, 1.0]
Epoch :  302  Time:  2.559  Rel. Train L2 Loss :  0.016519121676683426  Rel. Test L2 Loss :  0.01918425232172012  Test L2 Loss :  0.03369875892996788  inv_L_scale:  [1.0, 1.0]
Epoch :  303  Time:  2.56  Rel. Train L2 Loss :  0.016665675275855593  Rel. Test L2 Loss :  0.018181915506720544  Test L2 Loss :  0.03178380198776722  inv_L_scale:  [1.0, 1.0]
Epoch :  304  Time:  2.56  Rel. Train L2 Loss :  0.016432672498954668  Rel. Test L2 Loss :  0.018734547942876816  Test L2 Loss :  0.032620621919631956  inv_L_scale:  [1.0, 1.0]
Epoch :  305  Time:  2.56  Rel. Train L2 Loss :  0.01642296124663618  Rel. Test L2 Loss :  0.019454968348145484  Test L2 Loss :  0.03419142156839371  inv_L_scale:  [1.0, 1.0]
Epoch :  306  Time:  2.56  Rel. Train L2 Loss :  0.016604822973410288  Rel. Test L2 Loss :  0.018828262016177176  Test L2 Loss :  0.03282354012131691  inv_L_scale:  [1.0, 1.0]
Epoch :  307  Time:  2.56  Rel. Train L2 Loss :  0.01654388491478231  Rel. Test L2 Loss :  0.018653260320425035  Test L2 Loss :  0.03260245695710182  inv_L_scale:  [1.0, 1.0]
Epoch :  308  Time:  2.559  Rel. Train L2 Loss :  0.0165523428718249  Rel. Test L2 Loss :  0.019118000566959382  Test L2 Loss :  0.033626922518014905  inv_L_scale:  [1.0, 1.0]
Epoch :  309  Time:  2.559  Rel. Train L2 Loss :  0.016640102308657433  Rel. Test L2 Loss :  0.01843173608183861  Test L2 Loss :  0.032166142612695695  inv_L_scale:  [1.0, 1.0]
Epoch :  310  Time:  2.559  Rel. Train L2 Loss :  0.01633459631767538  Rel. Test L2 Loss :  0.01881517767906189  Test L2 Loss :  0.03272943377494812  inv_L_scale:  [1.0, 1.0]
Epoch :  311  Time:  2.559  Rel. Train L2 Loss :  0.01633434023294184  Rel. Test L2 Loss :  0.01830810084939003  Test L2 Loss :  0.03212377727031708  inv_L_scale:  [1.0, 1.0]
Epoch :  312  Time:  2.559  Rel. Train L2 Loss :  0.016448426619172098  Rel. Test L2 Loss :  0.019025373309850692  Test L2 Loss :  0.033166376054286954  inv_L_scale:  [1.0, 1.0]
Epoch :  313  Time:  2.56  Rel. Train L2 Loss :  0.01636266555637121  Rel. Test L2 Loss :  0.018734127879142762  Test L2 Loss :  0.03284336119890213  inv_L_scale:  [1.0, 1.0]
Epoch :  314  Time:  2.56  Rel. Train L2 Loss :  0.016280243835515445  Rel. Test L2 Loss :  0.018174873515963554  Test L2 Loss :  0.03172256886959076  inv_L_scale:  [1.0, 1.0]
Epoch :  315  Time:  2.56  Rel. Train L2 Loss :  0.016246586309538947  Rel. Test L2 Loss :  0.018442737758159636  Test L2 Loss :  0.03216162621974945  inv_L_scale:  [1.0, 1.0]
Epoch :  316  Time:  2.56  Rel. Train L2 Loss :  0.016398000071446102  Rel. Test L2 Loss :  0.018314788341522215  Test L2 Loss :  0.03213984325528145  inv_L_scale:  [1.0, 1.0]
Epoch :  317  Time:  2.56  Rel. Train L2 Loss :  0.016148381750616763  Rel. Test L2 Loss :  0.018830128386616705  Test L2 Loss :  0.03317731037735939  inv_L_scale:  [1.0, 1.0]
Epoch :  318  Time:  2.56  Rel. Train L2 Loss :  0.01621192365884781  Rel. Test L2 Loss :  0.018577966764569284  Test L2 Loss :  0.032659824937582016  inv_L_scale:  [1.0, 1.0]
Epoch :  319  Time:  2.56  Rel. Train L2 Loss :  0.016156459459000162  Rel. Test L2 Loss :  0.018097926154732703  Test L2 Loss :  0.031710372418165204  inv_L_scale:  [1.0, 1.0]
Epoch :  320  Time:  2.56  Rel. Train L2 Loss :  0.016073885659376782  Rel. Test L2 Loss :  0.017912876531481742  Test L2 Loss :  0.031135135889053346  inv_L_scale:  [1.0, 1.0]
Epoch :  321  Time:  2.56  Rel. Train L2 Loss :  0.01601455382588837  Rel. Test L2 Loss :  0.018607903495430945  Test L2 Loss :  0.03231746792793274  inv_L_scale:  [1.0, 1.0]
Epoch :  322  Time:  2.562  Rel. Train L2 Loss :  0.016066034560402235  Rel. Test L2 Loss :  0.01837158724665642  Test L2 Loss :  0.03210388705134392  inv_L_scale:  [1.0, 1.0]
Epoch :  323  Time:  2.56  Rel. Train L2 Loss :  0.016099400768677392  Rel. Test L2 Loss :  0.018047809898853302  Test L2 Loss :  0.031469430029392245  inv_L_scale:  [1.0, 1.0]
Epoch :  324  Time:  2.56  Rel. Train L2 Loss :  0.01602762044303947  Rel. Test L2 Loss :  0.018456889688968657  Test L2 Loss :  0.03211907774209976  inv_L_scale:  [1.0, 1.0]
Epoch :  325  Time:  2.56  Rel. Train L2 Loss :  0.016008788123726844  Rel. Test L2 Loss :  0.01800166390836239  Test L2 Loss :  0.03143991574645042  inv_L_scale:  [1.0, 1.0]
Epoch :  326  Time:  2.56  Rel. Train L2 Loss :  0.016251014123360316  Rel. Test L2 Loss :  0.01802177056670189  Test L2 Loss :  0.03144299641251564  inv_L_scale:  [1.0, 1.0]
Epoch :  327  Time:  2.56  Rel. Train L2 Loss :  0.016009843746821087  Rel. Test L2 Loss :  0.01780023917555809  Test L2 Loss :  0.030999801680445672  inv_L_scale:  [1.0, 1.0]
Epoch :  328  Time:  2.56  Rel. Train L2 Loss :  0.01599965217212836  Rel. Test L2 Loss :  0.018285670056939124  Test L2 Loss :  0.031915563866496084  inv_L_scale:  [1.0, 1.0]
Epoch :  329  Time:  2.56  Rel. Train L2 Loss :  0.01591880410909653  Rel. Test L2 Loss :  0.01789549008011818  Test L2 Loss :  0.03116491585969925  inv_L_scale:  [1.0, 1.0]
Epoch :  330  Time:  2.56  Rel. Train L2 Loss :  0.015855221334430906  Rel. Test L2 Loss :  0.017971350401639937  Test L2 Loss :  0.031199205890297888  inv_L_scale:  [1.0, 1.0]
Epoch :  331  Time:  2.56  Rel. Train L2 Loss :  0.01589250173419714  Rel. Test L2 Loss :  0.017822661474347114  Test L2 Loss :  0.031132526993751526  inv_L_scale:  [1.0, 1.0]
Epoch :  332  Time:  2.56  Rel. Train L2 Loss :  0.015928393792774942  Rel. Test L2 Loss :  0.017987322136759756  Test L2 Loss :  0.03116768002510071  inv_L_scale:  [1.0, 1.0]
Epoch :  333  Time:  2.56  Rel. Train L2 Loss :  0.015780460408164394  Rel. Test L2 Loss :  0.017472217194736003  Test L2 Loss :  0.03038527548313141  inv_L_scale:  [1.0, 1.0]
Epoch :  334  Time:  2.56  Rel. Train L2 Loss :  0.01585061949160364  Rel. Test L2 Loss :  0.01868658818304539  Test L2 Loss :  0.032652089297771456  inv_L_scale:  [1.0, 1.0]
Epoch :  335  Time:  2.561  Rel. Train L2 Loss :  0.015853627944986026  Rel. Test L2 Loss :  0.017991405725479127  Test L2 Loss :  0.031347480714321134  inv_L_scale:  [1.0, 1.0]
Epoch :  336  Time:  2.56  Rel. Train L2 Loss :  0.01583407298558288  Rel. Test L2 Loss :  0.01817187026143074  Test L2 Loss :  0.03186762645840645  inv_L_scale:  [1.0, 1.0]
Epoch :  337  Time:  2.56  Rel. Train L2 Loss :  0.01592784959408972  Rel. Test L2 Loss :  0.01771131604909897  Test L2 Loss :  0.030925825834274293  inv_L_scale:  [1.0, 1.0]
Epoch :  338  Time:  2.56  Rel. Train L2 Loss :  0.015698338291711276  Rel. Test L2 Loss :  0.018030590303242208  Test L2 Loss :  0.03142413839697838  inv_L_scale:  [1.0, 1.0]
Epoch :  339  Time:  2.56  Rel. Train L2 Loss :  0.015766529792712796  Rel. Test L2 Loss :  0.01775032751262188  Test L2 Loss :  0.030945666134357452  inv_L_scale:  [1.0, 1.0]
Epoch :  340  Time:  2.56  Rel. Train L2 Loss :  0.01566715646949079  Rel. Test L2 Loss :  0.018248279243707657  Test L2 Loss :  0.03163727924227715  inv_L_scale:  [1.0, 1.0]
Epoch :  341  Time:  2.56  Rel. Train L2 Loss :  0.01569532051682472  Rel. Test L2 Loss :  0.017644498720765112  Test L2 Loss :  0.030673142671585083  inv_L_scale:  [1.0, 1.0]
Epoch :  342  Time:  2.559  Rel. Train L2 Loss :  0.015641420483589172  Rel. Test L2 Loss :  0.017773679569363595  Test L2 Loss :  0.030904148370027543  inv_L_scale:  [1.0, 1.0]
Epoch :  343  Time:  2.559  Rel. Train L2 Loss :  0.015615641151865324  Rel. Test L2 Loss :  0.017656019851565362  Test L2 Loss :  0.030724086165428162  inv_L_scale:  [1.0, 1.0]
Epoch :  344  Time:  2.561  Rel. Train L2 Loss :  0.015728218985928428  Rel. Test L2 Loss :  0.017740701362490653  Test L2 Loss :  0.03094501927495003  inv_L_scale:  [1.0, 1.0]
Epoch :  345  Time:  2.56  Rel. Train L2 Loss :  0.015600473562048542  Rel. Test L2 Loss :  0.018357388824224472  Test L2 Loss :  0.03231738045811653  inv_L_scale:  [1.0, 1.0]
Epoch :  346  Time:  2.56  Rel. Train L2 Loss :  0.015580387637019157  Rel. Test L2 Loss :  0.01769469752907753  Test L2 Loss :  0.03075461693108082  inv_L_scale:  [1.0, 1.0]
Epoch :  347  Time:  2.559  Rel. Train L2 Loss :  0.01551900198062261  Rel. Test L2 Loss :  0.01730142317712307  Test L2 Loss :  0.030107179954648018  inv_L_scale:  [1.0, 1.0]
Epoch :  348  Time:  2.56  Rel. Train L2 Loss :  0.015538010473052661  Rel. Test L2 Loss :  0.017830505669116974  Test L2 Loss :  0.031128872111439707  inv_L_scale:  [1.0, 1.0]
Epoch :  349  Time:  2.561  Rel. Train L2 Loss :  0.015533902876906924  Rel. Test L2 Loss :  0.017622409909963607  Test L2 Loss :  0.030623608976602556  inv_L_scale:  [1.0, 1.0]
Epoch :  350  Time:  2.559  Rel. Train L2 Loss :  0.015413806256320741  Rel. Test L2 Loss :  0.017398828528821467  Test L2 Loss :  0.030256426483392714  inv_L_scale:  [1.0, 1.0]
Epoch :  351  Time:  2.559  Rel. Train L2 Loss :  0.015436585487590896  Rel. Test L2 Loss :  0.017491455599665643  Test L2 Loss :  0.030482308864593508  inv_L_scale:  [1.0, 1.0]
Epoch :  352  Time:  2.562  Rel. Train L2 Loss :  0.015516441928015814  Rel. Test L2 Loss :  0.01765683725476265  Test L2 Loss :  0.03079165458679199  inv_L_scale:  [1.0, 1.0]
Epoch :  353  Time:  2.566  Rel. Train L2 Loss :  0.015504528159896532  Rel. Test L2 Loss :  0.017301309406757354  Test L2 Loss :  0.030148607790470124  inv_L_scale:  [1.0, 1.0]
Epoch :  354  Time:  2.565  Rel. Train L2 Loss :  0.015391053561535147  Rel. Test L2 Loss :  0.01754361152648926  Test L2 Loss :  0.03032229617238045  inv_L_scale:  [1.0, 1.0]
Epoch :  355  Time:  2.565  Rel. Train L2 Loss :  0.015346694439649582  Rel. Test L2 Loss :  0.01754331812262535  Test L2 Loss :  0.03046822629868984  inv_L_scale:  [1.0, 1.0]
Epoch :  356  Time:  2.564  Rel. Train L2 Loss :  0.015301267637146844  Rel. Test L2 Loss :  0.017478040009737014  Test L2 Loss :  0.03051180124282837  inv_L_scale:  [1.0, 1.0]
Epoch :  357  Time:  2.566  Rel. Train L2 Loss :  0.015348088956541486  Rel. Test L2 Loss :  0.017597865760326386  Test L2 Loss :  0.03067443408071995  inv_L_scale:  [1.0, 1.0]
Epoch :  358  Time:  2.565  Rel. Train L2 Loss :  0.01530186550070842  Rel. Test L2 Loss :  0.017396649271249773  Test L2 Loss :  0.030248037949204446  inv_L_scale:  [1.0, 1.0]
Epoch :  359  Time:  2.565  Rel. Train L2 Loss :  0.015325425312750869  Rel. Test L2 Loss :  0.0177184496819973  Test L2 Loss :  0.03105449691414833  inv_L_scale:  [1.0, 1.0]
Epoch :  360  Time:  2.566  Rel. Train L2 Loss :  0.015436554708414608  Rel. Test L2 Loss :  0.017169559895992278  Test L2 Loss :  0.029880574345588683  inv_L_scale:  [1.0, 1.0]
Epoch :  361  Time:  2.565  Rel. Train L2 Loss :  0.015253703445196151  Rel. Test L2 Loss :  0.0173042668774724  Test L2 Loss :  0.029998042434453965  inv_L_scale:  [1.0, 1.0]
Epoch :  362  Time:  2.565  Rel. Train L2 Loss :  0.01529838098420037  Rel. Test L2 Loss :  0.017382476702332495  Test L2 Loss :  0.030064400881528855  inv_L_scale:  [1.0, 1.0]
Epoch :  363  Time:  2.565  Rel. Train L2 Loss :  0.01516325211773316  Rel. Test L2 Loss :  0.017489826157689094  Test L2 Loss :  0.03040923222899437  inv_L_scale:  [1.0, 1.0]
Epoch :  364  Time:  2.565  Rel. Train L2 Loss :  0.015173564553260804  Rel. Test L2 Loss :  0.017358684353530406  Test L2 Loss :  0.030125291869044304  inv_L_scale:  [1.0, 1.0]
Epoch :  365  Time:  2.566  Rel. Train L2 Loss :  0.01514648038480017  Rel. Test L2 Loss :  0.01748348392546177  Test L2 Loss :  0.03038160040974617  inv_L_scale:  [1.0, 1.0]
Epoch :  366  Time:  2.566  Rel. Train L2 Loss :  0.015207164126137892  Rel. Test L2 Loss :  0.01711165063083172  Test L2 Loss :  0.02976059079170227  inv_L_scale:  [1.0, 1.0]
Epoch :  367  Time:  2.566  Rel. Train L2 Loss :  0.015117134791281489  Rel. Test L2 Loss :  0.01725068524479866  Test L2 Loss :  0.029948585107922553  inv_L_scale:  [1.0, 1.0]
Epoch :  368  Time:  2.565  Rel. Train L2 Loss :  0.015091467731528812  Rel. Test L2 Loss :  0.017172389775514604  Test L2 Loss :  0.02973261095583439  inv_L_scale:  [1.0, 1.0]
Epoch :  369  Time:  2.565  Rel. Train L2 Loss :  0.015146828004055554  Rel. Test L2 Loss :  0.017232900485396385  Test L2 Loss :  0.030007269084453583  inv_L_scale:  [1.0, 1.0]
Epoch :  370  Time:  2.565  Rel. Train L2 Loss :  0.015070984044836627  Rel. Test L2 Loss :  0.01713037919253111  Test L2 Loss :  0.02975970983505249  inv_L_scale:  [1.0, 1.0]
Epoch :  371  Time:  2.565  Rel. Train L2 Loss :  0.015073656998574735  Rel. Test L2 Loss :  0.017072504237294197  Test L2 Loss :  0.02959688112139702  inv_L_scale:  [1.0, 1.0]
Epoch :  372  Time:  2.565  Rel. Train L2 Loss :  0.015058594412273831  Rel. Test L2 Loss :  0.017316342145204545  Test L2 Loss :  0.02996476337313652  inv_L_scale:  [1.0, 1.0]
Epoch :  373  Time:  2.566  Rel. Train L2 Loss :  0.015032549529439873  Rel. Test L2 Loss :  0.01714633584022522  Test L2 Loss :  0.02977666862308979  inv_L_scale:  [1.0, 1.0]
Epoch :  374  Time:  2.566  Rel. Train L2 Loss :  0.015023121941420766  Rel. Test L2 Loss :  0.017246768921613694  Test L2 Loss :  0.029944868236780168  inv_L_scale:  [1.0, 1.0]
Epoch :  375  Time:  2.566  Rel. Train L2 Loss :  0.015031247101724148  Rel. Test L2 Loss :  0.01748314708471298  Test L2 Loss :  0.03053177960216999  inv_L_scale:  [1.0, 1.0]
Epoch :  376  Time:  2.566  Rel. Train L2 Loss :  0.015052887623508772  Rel. Test L2 Loss :  0.017118005156517027  Test L2 Loss :  0.029794141799211502  inv_L_scale:  [1.0, 1.0]
Epoch :  377  Time:  2.566  Rel. Train L2 Loss :  0.015025588861770101  Rel. Test L2 Loss :  0.017258234433829785  Test L2 Loss :  0.029931925013661386  inv_L_scale:  [1.0, 1.0]
Epoch :  378  Time:  2.567  Rel. Train L2 Loss :  0.014932271662271686  Rel. Test L2 Loss :  0.017036795616149902  Test L2 Loss :  0.029617357775568964  inv_L_scale:  [1.0, 1.0]
Epoch :  379  Time:  2.566  Rel. Train L2 Loss :  0.014915106635954646  Rel. Test L2 Loss :  0.01741608701646328  Test L2 Loss :  0.030290952399373055  inv_L_scale:  [1.0, 1.0]
Epoch :  380  Time:  2.565  Rel. Train L2 Loss :  0.014906125946177377  Rel. Test L2 Loss :  0.016805050335824488  Test L2 Loss :  0.0290896662324667  inv_L_scale:  [1.0, 1.0]
Epoch :  381  Time:  2.566  Rel. Train L2 Loss :  0.014896364841196273  Rel. Test L2 Loss :  0.017055610790848733  Test L2 Loss :  0.029554096832871437  inv_L_scale:  [1.0, 1.0]
Epoch :  382  Time:  2.566  Rel. Train L2 Loss :  0.014856222056680255  Rel. Test L2 Loss :  0.01729032050818205  Test L2 Loss :  0.03017388567328453  inv_L_scale:  [1.0, 1.0]
Epoch :  383  Time:  2.566  Rel. Train L2 Loss :  0.014901858121156693  Rel. Test L2 Loss :  0.016989606134593487  Test L2 Loss :  0.029422196596860885  inv_L_scale:  [1.0, 1.0]
Epoch :  384  Time:  2.565  Rel. Train L2 Loss :  0.014793919614619679  Rel. Test L2 Loss :  0.017006941325962543  Test L2 Loss :  0.029487176910042764  inv_L_scale:  [1.0, 1.0]
Epoch :  385  Time:  2.565  Rel. Train L2 Loss :  0.014812952288322979  Rel. Test L2 Loss :  0.01690056547522545  Test L2 Loss :  0.029350316375494002  inv_L_scale:  [1.0, 1.0]
Epoch :  386  Time:  2.565  Rel. Train L2 Loss :  0.014842247097856469  Rel. Test L2 Loss :  0.016806992888450622  Test L2 Loss :  0.029127349555492402  inv_L_scale:  [1.0, 1.0]
Epoch :  387  Time:  2.567  Rel. Train L2 Loss :  0.014764743314849007  Rel. Test L2 Loss :  0.017006294764578343  Test L2 Loss :  0.029552187025547027  inv_L_scale:  [1.0, 1.0]
Epoch :  388  Time:  2.566  Rel. Train L2 Loss :  0.01475111920800474  Rel. Test L2 Loss :  0.01679894469678402  Test L2 Loss :  0.029116594046354295  inv_L_scale:  [1.0, 1.0]
Epoch :  389  Time:  2.565  Rel. Train L2 Loss :  0.014718182637459701  Rel. Test L2 Loss :  0.016963522769510745  Test L2 Loss :  0.02933490715920925  inv_L_scale:  [1.0, 1.0]
Epoch :  390  Time:  2.565  Rel. Train L2 Loss :  0.014755127388570044  Rel. Test L2 Loss :  0.017040775045752524  Test L2 Loss :  0.02968573659658432  inv_L_scale:  [1.0, 1.0]
Epoch :  391  Time:  2.565  Rel. Train L2 Loss :  0.01476309689382712  Rel. Test L2 Loss :  0.016872255057096483  Test L2 Loss :  0.029239248484373093  inv_L_scale:  [1.0, 1.0]
Epoch :  392  Time:  2.566  Rel. Train L2 Loss :  0.014697151076462535  Rel. Test L2 Loss :  0.017137026861310006  Test L2 Loss :  0.02967177554965019  inv_L_scale:  [1.0, 1.0]
Epoch :  393  Time:  2.565  Rel. Train L2 Loss :  0.014666531946923998  Rel. Test L2 Loss :  0.01679745152592659  Test L2 Loss :  0.02910617783665657  inv_L_scale:  [1.0, 1.0]
Epoch :  394  Time:  2.565  Rel. Train L2 Loss :  0.014619863480329514  Rel. Test L2 Loss :  0.01692330975085497  Test L2 Loss :  0.029437611624598504  inv_L_scale:  [1.0, 1.0]
Epoch :  395  Time:  2.565  Rel. Train L2 Loss :  0.0146574808532993  Rel. Test L2 Loss :  0.016953642815351486  Test L2 Loss :  0.029320539087057115  inv_L_scale:  [1.0, 1.0]
Epoch :  396  Time:  2.565  Rel. Train L2 Loss :  0.01472011912200186  Rel. Test L2 Loss :  0.01684591982513666  Test L2 Loss :  0.02916608676314354  inv_L_scale:  [1.0, 1.0]
Epoch :  397  Time:  2.565  Rel. Train L2 Loss :  0.014592161426941554  Rel. Test L2 Loss :  0.016843603774905205  Test L2 Loss :  0.02928980566561222  inv_L_scale:  [1.0, 1.0]
Epoch :  398  Time:  2.565  Rel. Train L2 Loss :  0.014559440356161859  Rel. Test L2 Loss :  0.016819327250123025  Test L2 Loss :  0.029153525680303573  inv_L_scale:  [1.0, 1.0]
Epoch :  399  Time:  2.565  Rel. Train L2 Loss :  0.014582705058985287  Rel. Test L2 Loss :  0.016877432614564897  Test L2 Loss :  0.029187363609671592  inv_L_scale:  [1.0, 1.0]
Epoch :  400  Time:  2.567  Rel. Train L2 Loss :  0.014540166300204065  Rel. Test L2 Loss :  0.016723481826484202  Test L2 Loss :  0.029124333560466766  inv_L_scale:  [1.0, 1.0]
Epoch :  401  Time:  2.565  Rel. Train L2 Loss :  0.014536771269308196  Rel. Test L2 Loss :  0.016649888157844545  Test L2 Loss :  0.02888264298439026  inv_L_scale:  [1.0, 1.0]
Epoch :  402  Time:  2.566  Rel. Train L2 Loss :  0.014472549023727577  Rel. Test L2 Loss :  0.016880520842969416  Test L2 Loss :  0.029120662957429887  inv_L_scale:  [1.0, 1.0]
Epoch :  403  Time:  2.565  Rel. Train L2 Loss :  0.014503485163052877  Rel. Test L2 Loss :  0.016701075956225397  Test L2 Loss :  0.028978476524353026  inv_L_scale:  [1.0, 1.0]
Epoch :  404  Time:  2.565  Rel. Train L2 Loss :  0.014508229022224744  Rel. Test L2 Loss :  0.016677556596696376  Test L2 Loss :  0.028901696056127548  inv_L_scale:  [1.0, 1.0]
Epoch :  405  Time:  2.565  Rel. Train L2 Loss :  0.01447808695336183  Rel. Test L2 Loss :  0.016753029972314835  Test L2 Loss :  0.02893163710832596  inv_L_scale:  [1.0, 1.0]
Epoch :  406  Time:  2.565  Rel. Train L2 Loss :  0.01450931443936295  Rel. Test L2 Loss :  0.016584176421165466  Test L2 Loss :  0.028731725960969925  inv_L_scale:  [1.0, 1.0]
Epoch :  407  Time:  2.565  Rel. Train L2 Loss :  0.014466637969017029  Rel. Test L2 Loss :  0.01660792600363493  Test L2 Loss :  0.028772944658994673  inv_L_scale:  [1.0, 1.0]
Epoch :  408  Time:  2.566  Rel. Train L2 Loss :  0.014462837295399772  Rel. Test L2 Loss :  0.016647144332528115  Test L2 Loss :  0.02881522089242935  inv_L_scale:  [1.0, 1.0]
Epoch :  409  Time:  2.566  Rel. Train L2 Loss :  0.014411731337507566  Rel. Test L2 Loss :  0.016746516898274423  Test L2 Loss :  0.028982796743512153  inv_L_scale:  [1.0, 1.0]
Epoch :  410  Time:  2.565  Rel. Train L2 Loss :  0.014446569246550401  Rel. Test L2 Loss :  0.01680283959954977  Test L2 Loss :  0.029242134541273116  inv_L_scale:  [1.0, 1.0]
Epoch :  411  Time:  2.565  Rel. Train L2 Loss :  0.01441594998869631  Rel. Test L2 Loss :  0.0165678022056818  Test L2 Loss :  0.02864285320043564  inv_L_scale:  [1.0, 1.0]
Epoch :  412  Time:  2.565  Rel. Train L2 Loss :  0.01436602148744795  Rel. Test L2 Loss :  0.016615091152489186  Test L2 Loss :  0.028717624992132186  inv_L_scale:  [1.0, 1.0]
Epoch :  413  Time:  2.565  Rel. Train L2 Loss :  0.0143195248560773  Rel. Test L2 Loss :  0.016737575605511666  Test L2 Loss :  0.028955061361193656  inv_L_scale:  [1.0, 1.0]
Epoch :  414  Time:  2.566  Rel. Train L2 Loss :  0.014352258000936773  Rel. Test L2 Loss :  0.016588396802544595  Test L2 Loss :  0.028671419769525527  inv_L_scale:  [1.0, 1.0]
Epoch :  415  Time:  2.566  Rel. Train L2 Loss :  0.01435778756108549  Rel. Test L2 Loss :  0.016605296805500984  Test L2 Loss :  0.02873607203364372  inv_L_scale:  [1.0, 1.0]
Epoch :  416  Time:  2.565  Rel. Train L2 Loss :  0.014337861401339372  Rel. Test L2 Loss :  0.01666528273373842  Test L2 Loss :  0.028795584440231323  inv_L_scale:  [1.0, 1.0]
Epoch :  417  Time:  2.566  Rel. Train L2 Loss :  0.01431319701174895  Rel. Test L2 Loss :  0.01651590146124363  Test L2 Loss :  0.028562975227832795  inv_L_scale:  [1.0, 1.0]
Epoch :  418  Time:  2.566  Rel. Train L2 Loss :  0.0142730500549078  Rel. Test L2 Loss :  0.016646991707384585  Test L2 Loss :  0.028718816116452217  inv_L_scale:  [1.0, 1.0]
Epoch :  419  Time:  2.565  Rel. Train L2 Loss :  0.014317257487111622  Rel. Test L2 Loss :  0.016714237853884695  Test L2 Loss :  0.028985142186284066  inv_L_scale:  [1.0, 1.0]
Epoch :  420  Time:  2.565  Rel. Train L2 Loss :  0.014263371353348096  Rel. Test L2 Loss :  0.01655812028795481  Test L2 Loss :  0.028706556260585783  inv_L_scale:  [1.0, 1.0]
Epoch :  421  Time:  2.566  Rel. Train L2 Loss :  0.014261434036824438  Rel. Test L2 Loss :  0.016462226696312428  Test L2 Loss :  0.028464823365211486  inv_L_scale:  [1.0, 1.0]
Epoch :  422  Time:  2.565  Rel. Train L2 Loss :  0.014227924299322896  Rel. Test L2 Loss :  0.016502061523497105  Test L2 Loss :  0.02855030708014965  inv_L_scale:  [1.0, 1.0]
Epoch :  423  Time:  2.565  Rel. Train L2 Loss :  0.014230276395877203  Rel. Test L2 Loss :  0.01655218280851841  Test L2 Loss :  0.028556168526411057  inv_L_scale:  [1.0, 1.0]
Epoch :  424  Time:  2.566  Rel. Train L2 Loss :  0.014207411698169178  Rel. Test L2 Loss :  0.016490917801856995  Test L2 Loss :  0.02852225512266159  inv_L_scale:  [1.0, 1.0]
Epoch :  425  Time:  2.565  Rel. Train L2 Loss :  0.014237237373987834  Rel. Test L2 Loss :  0.01648860651999712  Test L2 Loss :  0.02849854901432991  inv_L_scale:  [1.0, 1.0]
Epoch :  426  Time:  2.566  Rel. Train L2 Loss :  0.014245691978269153  Rel. Test L2 Loss :  0.016536296866834162  Test L2 Loss :  0.028636526614427567  inv_L_scale:  [1.0, 1.0]
Epoch :  427  Time:  2.561  Rel. Train L2 Loss :  0.01418943834801515  Rel. Test L2 Loss :  0.016508721075952054  Test L2 Loss :  0.028561789244413376  inv_L_scale:  [1.0, 1.0]
Epoch :  428  Time:  2.56  Rel. Train L2 Loss :  0.014168999046087266  Rel. Test L2 Loss :  0.01649566862732172  Test L2 Loss :  0.028573695197701456  inv_L_scale:  [1.0, 1.0]
Epoch :  429  Time:  2.56  Rel. Train L2 Loss :  0.014179705902934074  Rel. Test L2 Loss :  0.01655102625489235  Test L2 Loss :  0.028605866953730585  inv_L_scale:  [1.0, 1.0]
Epoch :  430  Time:  2.561  Rel. Train L2 Loss :  0.014161550982130898  Rel. Test L2 Loss :  0.0164419424533844  Test L2 Loss :  0.02843282550573349  inv_L_scale:  [1.0, 1.0]
Epoch :  431  Time:  2.561  Rel. Train L2 Loss :  0.014133622381422255  Rel. Test L2 Loss :  0.01647963535040617  Test L2 Loss :  0.028516996949911118  inv_L_scale:  [1.0, 1.0]
Epoch :  432  Time:  2.56  Rel. Train L2 Loss :  0.014116851083106464  Rel. Test L2 Loss :  0.016521260850131513  Test L2 Loss :  0.028511762470006943  inv_L_scale:  [1.0, 1.0]
Epoch :  433  Time:  2.56  Rel. Train L2 Loss :  0.014111871798005368  Rel. Test L2 Loss :  0.016580362133681775  Test L2 Loss :  0.028685038536787034  inv_L_scale:  [1.0, 1.0]
Epoch :  434  Time:  2.56  Rel. Train L2 Loss :  0.014114007875323296  Rel. Test L2 Loss :  0.016506238952279092  Test L2 Loss :  0.02857407808303833  inv_L_scale:  [1.0, 1.0]
Epoch :  435  Time:  2.56  Rel. Train L2 Loss :  0.014074859105878405  Rel. Test L2 Loss :  0.01642375849187374  Test L2 Loss :  0.02838401362299919  inv_L_scale:  [1.0, 1.0]
Epoch :  436  Time:  2.56  Rel. Train L2 Loss :  0.014081285231643252  Rel. Test L2 Loss :  0.016463943272829056  Test L2 Loss :  0.028508984968066215  inv_L_scale:  [1.0, 1.0]
Epoch :  437  Time:  2.559  Rel. Train L2 Loss :  0.014070829161339336  Rel. Test L2 Loss :  0.01643361948430538  Test L2 Loss :  0.028404777795076372  inv_L_scale:  [1.0, 1.0]
Epoch :  438  Time:  2.559  Rel. Train L2 Loss :  0.01408493198040459  Rel. Test L2 Loss :  0.016452442854642868  Test L2 Loss :  0.028411317989230155  inv_L_scale:  [1.0, 1.0]
Epoch :  439  Time:  2.56  Rel. Train L2 Loss :  0.014066863916814326  Rel. Test L2 Loss :  0.01642612311989069  Test L2 Loss :  0.028446708545088767  inv_L_scale:  [1.0, 1.0]
Epoch :  440  Time:  2.56  Rel. Train L2 Loss :  0.014058856003814273  Rel. Test L2 Loss :  0.016451946422457696  Test L2 Loss :  0.028426560908555984  inv_L_scale:  [1.0, 1.0]
Epoch :  441  Time:  2.56  Rel. Train L2 Loss :  0.014037450916237301  Rel. Test L2 Loss :  0.016390949189662933  Test L2 Loss :  0.028368492498993873  inv_L_scale:  [1.0, 1.0]
Epoch :  442  Time:  2.56  Rel. Train L2 Loss :  0.014030958463748296  Rel. Test L2 Loss :  0.016434767358005045  Test L2 Loss :  0.028408442512154578  inv_L_scale:  [1.0, 1.0]
Epoch :  443  Time:  2.561  Rel. Train L2 Loss :  0.014020675412482685  Rel. Test L2 Loss :  0.016399494335055352  Test L2 Loss :  0.02835227780044079  inv_L_scale:  [1.0, 1.0]
Epoch :  444  Time:  2.56  Rel. Train L2 Loss :  0.013996775771180789  Rel. Test L2 Loss :  0.01646455332636833  Test L2 Loss :  0.028469271138310433  inv_L_scale:  [1.0, 1.0]
Epoch :  445  Time:  2.56  Rel. Train L2 Loss :  0.013997257438798745  Rel. Test L2 Loss :  0.01645694300532341  Test L2 Loss :  0.028447463661432266  inv_L_scale:  [1.0, 1.0]
Epoch :  446  Time:  2.56  Rel. Train L2 Loss :  0.013959418998824226  Rel. Test L2 Loss :  0.016377455070614815  Test L2 Loss :  0.028327805623412132  inv_L_scale:  [1.0, 1.0]
Epoch :  447  Time:  2.559  Rel. Train L2 Loss :  0.013980580079886649  Rel. Test L2 Loss :  0.01639700811356306  Test L2 Loss :  0.028344304710626603  inv_L_scale:  [1.0, 1.0]
Epoch :  448  Time:  2.559  Rel. Train L2 Loss :  0.013968943357467652  Rel. Test L2 Loss :  0.01637911647558212  Test L2 Loss :  0.028336024582386016  inv_L_scale:  [1.0, 1.0]
Epoch :  449  Time:  2.56  Rel. Train L2 Loss :  0.013962122855914964  Rel. Test L2 Loss :  0.016347008198499678  Test L2 Loss :  0.028288823366165162  inv_L_scale:  [1.0, 1.0]
Epoch :  450  Time:  2.559  Rel. Train L2 Loss :  0.01395587349931399  Rel. Test L2 Loss :  0.01634247273206711  Test L2 Loss :  0.02827939569950104  inv_L_scale:  [1.0, 1.0]
Epoch :  451  Time:  2.559  Rel. Train L2 Loss :  0.013925075444082419  Rel. Test L2 Loss :  0.01634380593895912  Test L2 Loss :  0.028261411488056182  inv_L_scale:  [1.0, 1.0]
Epoch :  452  Time:  2.561  Rel. Train L2 Loss :  0.01392934348848131  Rel. Test L2 Loss :  0.01634446918964386  Test L2 Loss :  0.028244000524282456  inv_L_scale:  [1.0, 1.0]
Epoch :  453  Time:  2.56  Rel. Train L2 Loss :  0.013922348734405305  Rel. Test L2 Loss :  0.016383482813835143  Test L2 Loss :  0.02833272472023964  inv_L_scale:  [1.0, 1.0]
Epoch :  454  Time:  2.56  Rel. Train L2 Loss :  0.013899654688106642  Rel. Test L2 Loss :  0.016333610713481904  Test L2 Loss :  0.028232977613806724  inv_L_scale:  [1.0, 1.0]
Epoch :  455  Time:  2.56  Rel. Train L2 Loss :  0.013911013681855466  Rel. Test L2 Loss :  0.016364291682839392  Test L2 Loss :  0.028311418443918226  inv_L_scale:  [1.0, 1.0]
Epoch :  456  Time:  2.56  Rel. Train L2 Loss :  0.013899247861570782  Rel. Test L2 Loss :  0.016347550004720688  Test L2 Loss :  0.02826403297483921  inv_L_scale:  [1.0, 1.0]
Epoch :  457  Time:  2.56  Rel. Train L2 Loss :  0.01388900950551033  Rel. Test L2 Loss :  0.016361302733421325  Test L2 Loss :  0.028270757272839547  inv_L_scale:  [1.0, 1.0]
Epoch :  458  Time:  2.559  Rel. Train L2 Loss :  0.01388321566912863  Rel. Test L2 Loss :  0.016349650621414184  Test L2 Loss :  0.02826432965695858  inv_L_scale:  [1.0, 1.0]
Epoch :  459  Time:  2.56  Rel. Train L2 Loss :  0.013878061527179348  Rel. Test L2 Loss :  0.016354241073131562  Test L2 Loss :  0.028247670158743857  inv_L_scale:  [1.0, 1.0]
Epoch :  460  Time:  2.559  Rel. Train L2 Loss :  0.013865836080577638  Rel. Test L2 Loss :  0.016319947503507137  Test L2 Loss :  0.028203794062137605  inv_L_scale:  [1.0, 1.0]
Epoch :  461  Time:  2.559  Rel. Train L2 Loss :  0.013844193799628151  Rel. Test L2 Loss :  0.016346261464059354  Test L2 Loss :  0.028254606202244757  inv_L_scale:  [1.0, 1.0]
Epoch :  462  Time:  2.559  Rel. Train L2 Loss :  0.013860642036630047  Rel. Test L2 Loss :  0.016351224109530448  Test L2 Loss :  0.028248420655727385  inv_L_scale:  [1.0, 1.0]
Epoch :  463  Time:  2.559  Rel. Train L2 Loss :  0.013847765810787678  Rel. Test L2 Loss :  0.016313279792666436  Test L2 Loss :  0.028188894242048262  inv_L_scale:  [1.0, 1.0]
Epoch :  464  Time:  2.559  Rel. Train L2 Loss :  0.013835595341192351  Rel. Test L2 Loss :  0.0163340213149786  Test L2 Loss :  0.02821114532649517  inv_L_scale:  [1.0, 1.0]
Epoch :  465  Time:  2.56  Rel. Train L2 Loss :  0.013829391226172447  Rel. Test L2 Loss :  0.016303304210305215  Test L2 Loss :  0.028180419951677322  inv_L_scale:  [1.0, 1.0]
Epoch :  466  Time:  2.559  Rel. Train L2 Loss :  0.013826134304205576  Rel. Test L2 Loss :  0.0163393859192729  Test L2 Loss :  0.028258833438158035  inv_L_scale:  [1.0, 1.0]
Epoch :  467  Time:  2.56  Rel. Train L2 Loss :  0.013814455415639613  Rel. Test L2 Loss :  0.016317828372120858  Test L2 Loss :  0.028186982721090315  inv_L_scale:  [1.0, 1.0]
Epoch :  468  Time:  2.56  Rel. Train L2 Loss :  0.013811082786156071  Rel. Test L2 Loss :  0.0163283946365118  Test L2 Loss :  0.02823920100927353  inv_L_scale:  [1.0, 1.0]
Epoch :  469  Time:  2.559  Rel. Train L2 Loss :  0.013811806341012318  Rel. Test L2 Loss :  0.016323709636926653  Test L2 Loss :  0.028189939111471177  inv_L_scale:  [1.0, 1.0]
Epoch :  470  Time:  2.56  Rel. Train L2 Loss :  0.013796231341030862  Rel. Test L2 Loss :  0.01632325295358896  Test L2 Loss :  0.028207355812191963  inv_L_scale:  [1.0, 1.0]
Epoch :  471  Time:  2.56  Rel. Train L2 Loss :  0.013796614441606734  Rel. Test L2 Loss :  0.016320217475295065  Test L2 Loss :  0.028208167180418967  inv_L_scale:  [1.0, 1.0]
Epoch :  472  Time:  2.56  Rel. Train L2 Loss :  0.013781466459234556  Rel. Test L2 Loss :  0.01630149085074663  Test L2 Loss :  0.028180003613233567  inv_L_scale:  [1.0, 1.0]
Epoch :  473  Time:  2.56  Rel. Train L2 Loss :  0.013779424308902688  Rel. Test L2 Loss :  0.016315630823373794  Test L2 Loss :  0.02818526089191437  inv_L_scale:  [1.0, 1.0]
Epoch :  474  Time:  2.561  Rel. Train L2 Loss :  0.013782741816507446  Rel. Test L2 Loss :  0.016308203525841235  Test L2 Loss :  0.028178180530667306  inv_L_scale:  [1.0, 1.0]
Epoch :  475  Time:  2.56  Rel. Train L2 Loss :  0.013769442927506235  Rel. Test L2 Loss :  0.016286857053637506  Test L2 Loss :  0.02813712276518345  inv_L_scale:  [1.0, 1.0]
Epoch :  476  Time:  2.559  Rel. Train L2 Loss :  0.013767631066342195  Rel. Test L2 Loss :  0.016302072033286093  Test L2 Loss :  0.028167565912008287  inv_L_scale:  [1.0, 1.0]
Epoch :  477  Time:  2.559  Rel. Train L2 Loss :  0.01375740004910363  Rel. Test L2 Loss :  0.01631500344723463  Test L2 Loss :  0.028196478188037874  inv_L_scale:  [1.0, 1.0]
Epoch :  478  Time:  2.56  Rel. Train L2 Loss :  0.013759916834533214  Rel. Test L2 Loss :  0.01630139246582985  Test L2 Loss :  0.028158077001571656  inv_L_scale:  [1.0, 1.0]
Epoch :  479  Time:  2.56  Rel. Train L2 Loss :  0.013753599284423722  Rel. Test L2 Loss :  0.016307366378605366  Test L2 Loss :  0.028171999752521514  inv_L_scale:  [1.0, 1.0]
Epoch :  480  Time:  2.56  Rel. Train L2 Loss :  0.013750884901318285  Rel. Test L2 Loss :  0.016295420676469802  Test L2 Loss :  0.028172340393066406  inv_L_scale:  [1.0, 1.0]
Epoch :  481  Time:  2.559  Rel. Train L2 Loss :  0.01374434912370311  Rel. Test L2 Loss :  0.016294643841683866  Test L2 Loss :  0.028151120990514755  inv_L_scale:  [1.0, 1.0]
Epoch :  482  Time:  2.56  Rel. Train L2 Loss :  0.013743651227818595  Rel. Test L2 Loss :  0.016306816451251507  Test L2 Loss :  0.0281819286942482  inv_L_scale:  [1.0, 1.0]
Epoch :  483  Time:  2.56  Rel. Train L2 Loss :  0.01374089851975441  Rel. Test L2 Loss :  0.016290524005889893  Test L2 Loss :  0.02814819537103176  inv_L_scale:  [1.0, 1.0]
Epoch :  484  Time:  2.56  Rel. Train L2 Loss :  0.013737606464160813  Rel. Test L2 Loss :  0.016297196596860887  Test L2 Loss :  0.02815751761198044  inv_L_scale:  [1.0, 1.0]
Epoch :  485  Time:  2.559  Rel. Train L2 Loss :  0.013735430075062645  Rel. Test L2 Loss :  0.016293482631444933  Test L2 Loss :  0.028147989809513094  inv_L_scale:  [1.0, 1.0]
Epoch :  486  Time:  2.56  Rel. Train L2 Loss :  0.013732846793201234  Rel. Test L2 Loss :  0.01629344590008259  Test L2 Loss :  0.02815387338399887  inv_L_scale:  [1.0, 1.0]
Epoch :  487  Time:  2.56  Rel. Train L2 Loss :  0.013731084018945693  Rel. Test L2 Loss :  0.01629113681614399  Test L2 Loss :  0.028153958171606062  inv_L_scale:  [1.0, 1.0]
Epoch :  488  Time:  2.56  Rel. Train L2 Loss :  0.01372592740588718  Rel. Test L2 Loss :  0.016298991963267326  Test L2 Loss :  0.02817699797451496  inv_L_scale:  [1.0, 1.0]
Epoch :  489  Time:  2.559  Rel. Train L2 Loss :  0.013725379763378037  Rel. Test L2 Loss :  0.01629942364990711  Test L2 Loss :  0.02817502073943615  inv_L_scale:  [1.0, 1.0]
Epoch :  490  Time:  2.56  Rel. Train L2 Loss :  0.01372368029008309  Rel. Test L2 Loss :  0.016291531324386595  Test L2 Loss :  0.028146287351846697  inv_L_scale:  [1.0, 1.0]
Epoch :  491  Time:  2.56  Rel. Train L2 Loss :  0.013720839387840696  Rel. Test L2 Loss :  0.01629022292792797  Test L2 Loss :  0.028145215958356857  inv_L_scale:  [1.0, 1.0]
Epoch :  492  Time:  2.56  Rel. Train L2 Loss :  0.013719388064410951  Rel. Test L2 Loss :  0.016290087923407554  Test L2 Loss :  0.028145457282662392  inv_L_scale:  [1.0, 1.0]
Epoch :  493  Time:  2.561  Rel. Train L2 Loss :  0.013716528204580148  Rel. Test L2 Loss :  0.016288832649588584  Test L2 Loss :  0.02814730241894722  inv_L_scale:  [1.0, 1.0]
Epoch :  494  Time:  2.559  Rel. Train L2 Loss :  0.01371615601496564  Rel. Test L2 Loss :  0.016293959766626356  Test L2 Loss :  0.028151115328073503  inv_L_scale:  [1.0, 1.0]
Epoch :  495  Time:  2.56  Rel. Train L2 Loss :  0.013715040046307775  Rel. Test L2 Loss :  0.016294540464878084  Test L2 Loss :  0.028164526224136354  inv_L_scale:  [1.0, 1.0]
Epoch :  496  Time:  2.56  Rel. Train L2 Loss :  0.01371644948505693  Rel. Test L2 Loss :  0.016290135830640793  Test L2 Loss :  0.0281457157433033  inv_L_scale:  [1.0, 1.0]
Epoch :  497  Time:  2.56  Rel. Train L2 Loss :  0.013713101065821118  Rel. Test L2 Loss :  0.01629295639693737  Test L2 Loss :  0.028157486692070962  inv_L_scale:  [1.0, 1.0]
Epoch :  498  Time:  2.559  Rel. Train L2 Loss :  0.013713806838625007  Rel. Test L2 Loss :  0.01629087418317795  Test L2 Loss :  0.028156021535396578  inv_L_scale:  [1.0, 1.0]
Epoch :  499  Time:  2.56  Rel. Train L2 Loss :  0.013715770757860608  Rel. Test L2 Loss :  0.01628569222986698  Test L2 Loss :  0.02813928373157978  inv_L_scale:  [1.0, 1.0]
