Loading data from  ../../data/curve//pcno_curve_data_1_1_5_5_stokes.npz
(1000,) (1000, 1000, 1) (1000, 1000, 2)
use normalized raw measures
Casting to tensor
x_train shape torch.Size([900, 1000, 8]), y_train shape torch.Size([900, 1000, 1])
length of each dim:  tensor([6.6455335617065430, 6.6654777526855469])
kmax = 16
L =  14
In PCNO_train, ndims =  2
Epoch :  0  Time:  0.993  Rel. Train L2 Loss :  0.40840496950679356  Rel. Test L2 Loss :  0.2511198651790619  Test L2 Loss :  0.4547348642349243  inv_L_scale:  [1.0, 1.0]
Epoch :  1  Time:  0.744  Rel. Train L2 Loss :  0.19950294746292963  Rel. Test L2 Loss :  0.15326976001262665  Test L2 Loss :  0.2876108551025391  inv_L_scale:  [1.0, 1.0]
Epoch :  2  Time:  0.744  Rel. Train L2 Loss :  0.14568383594353992  Rel. Test L2 Loss :  0.1369601857662201  Test L2 Loss :  0.2528611171245575  inv_L_scale:  [1.0, 1.0]
Epoch :  3  Time:  0.742  Rel. Train L2 Loss :  0.12129658311605454  Rel. Test L2 Loss :  0.12008363962173461  Test L2 Loss :  0.22169699430465697  inv_L_scale:  [1.0, 1.0]
Epoch :  4  Time:  0.745  Rel. Train L2 Loss :  0.10794410818152958  Rel. Test L2 Loss :  0.10450522124767303  Test L2 Loss :  0.19573563396930693  inv_L_scale:  [1.0, 1.0]
Epoch :  5  Time:  0.742  Rel. Train L2 Loss :  0.10159092565377553  Rel. Test L2 Loss :  0.0986897075176239  Test L2 Loss :  0.18420781016349794  inv_L_scale:  [1.0, 1.0]
Epoch :  6  Time:  0.743  Rel. Train L2 Loss :  0.09243884887960221  Rel. Test L2 Loss :  0.08771941930055618  Test L2 Loss :  0.16153452157974243  inv_L_scale:  [1.0, 1.0]
Epoch :  7  Time:  0.742  Rel. Train L2 Loss :  0.08433060785134633  Rel. Test L2 Loss :  0.08992197394371032  Test L2 Loss :  0.16178894639015198  inv_L_scale:  [1.0, 1.0]
Epoch :  8  Time:  0.742  Rel. Train L2 Loss :  0.08183610647916793  Rel. Test L2 Loss :  0.08637907475233078  Test L2 Loss :  0.15640177965164184  inv_L_scale:  [1.0, 1.0]
Epoch :  9  Time:  0.743  Rel. Train L2 Loss :  0.08155729502439499  Rel. Test L2 Loss :  0.0927744072675705  Test L2 Loss :  0.17202577590942383  inv_L_scale:  [1.0, 1.0]
Epoch :  10  Time:  0.743  Rel. Train L2 Loss :  0.07903307583596972  Rel. Test L2 Loss :  0.08152378797531128  Test L2 Loss :  0.14826098442077637  inv_L_scale:  [1.0, 1.0]
Epoch :  11  Time:  0.742  Rel. Train L2 Loss :  0.07264083024528291  Rel. Test L2 Loss :  0.07300532832741738  Test L2 Loss :  0.13068755239248275  inv_L_scale:  [1.0, 1.0]
Epoch :  12  Time:  0.742  Rel. Train L2 Loss :  0.07364319430457221  Rel. Test L2 Loss :  0.0825732073187828  Test L2 Loss :  0.14838987946510315  inv_L_scale:  [1.0, 1.0]
Epoch :  13  Time:  0.743  Rel. Train L2 Loss :  0.07135535814695888  Rel. Test L2 Loss :  0.07892224818468094  Test L2 Loss :  0.14148593544960023  inv_L_scale:  [1.0, 1.0]
Epoch :  14  Time:  0.742  Rel. Train L2 Loss :  0.06880112200975418  Rel. Test L2 Loss :  0.07279305785894394  Test L2 Loss :  0.13034313321113586  inv_L_scale:  [1.0, 1.0]
Epoch :  15  Time:  0.742  Rel. Train L2 Loss :  0.0687525948550966  Rel. Test L2 Loss :  0.07071124136447907  Test L2 Loss :  0.1273485678434372  inv_L_scale:  [1.0, 1.0]
Epoch :  16  Time:  0.744  Rel. Train L2 Loss :  0.06735366880893708  Rel. Test L2 Loss :  0.07700169265270233  Test L2 Loss :  0.1401088184118271  inv_L_scale:  [1.0, 1.0]
Epoch :  17  Time:  0.743  Rel. Train L2 Loss :  0.06872374047835668  Rel. Test L2 Loss :  0.07503810971975326  Test L2 Loss :  0.13471479415893556  inv_L_scale:  [1.0, 1.0]
Epoch :  18  Time:  0.742  Rel. Train L2 Loss :  0.06606188077065679  Rel. Test L2 Loss :  0.07476921930909157  Test L2 Loss :  0.13472688555717469  inv_L_scale:  [1.0, 1.0]
Epoch :  19  Time:  0.742  Rel. Train L2 Loss :  0.06421220978101094  Rel. Test L2 Loss :  0.07034154281020165  Test L2 Loss :  0.12504018902778624  inv_L_scale:  [1.0, 1.0]
Epoch :  20  Time:  0.743  Rel. Train L2 Loss :  0.0650044086575508  Rel. Test L2 Loss :  0.07712568521499634  Test L2 Loss :  0.13966931998729706  inv_L_scale:  [1.0, 1.0]
Epoch :  21  Time:  0.742  Rel. Train L2 Loss :  0.0663530280192693  Rel. Test L2 Loss :  0.06646878212690353  Test L2 Loss :  0.11896206855773926  inv_L_scale:  [1.0, 1.0]
Epoch :  22  Time:  0.743  Rel. Train L2 Loss :  0.06141930512256093  Rel. Test L2 Loss :  0.06381726920604706  Test L2 Loss :  0.11338585019111633  inv_L_scale:  [1.0, 1.0]
Epoch :  23  Time:  0.741  Rel. Train L2 Loss :  0.061579903099271985  Rel. Test L2 Loss :  0.06524515122175217  Test L2 Loss :  0.11576139867305756  inv_L_scale:  [1.0, 1.0]
Epoch :  24  Time:  0.743  Rel. Train L2 Loss :  0.060096664395597243  Rel. Test L2 Loss :  0.07040229141712188  Test L2 Loss :  0.12519726693630218  inv_L_scale:  [1.0, 1.0]
Epoch :  25  Time:  0.743  Rel. Train L2 Loss :  0.0619636865456899  Rel. Test L2 Loss :  0.06747408628463746  Test L2 Loss :  0.12030068397521973  inv_L_scale:  [1.0, 1.0]
Epoch :  26  Time:  0.742  Rel. Train L2 Loss :  0.061644951668050556  Rel. Test L2 Loss :  0.063716129809618  Test L2 Loss :  0.11333986312150955  inv_L_scale:  [1.0, 1.0]
Epoch :  27  Time:  0.742  Rel. Train L2 Loss :  0.05849042236804962  Rel. Test L2 Loss :  0.06540694922208785  Test L2 Loss :  0.11805149435997009  inv_L_scale:  [1.0, 1.0]
Epoch :  28  Time:  0.741  Rel. Train L2 Loss :  0.05890330877568987  Rel. Test L2 Loss :  0.06161269217729568  Test L2 Loss :  0.10873273104429244  inv_L_scale:  [1.0, 1.0]
Epoch :  29  Time:  0.743  Rel. Train L2 Loss :  0.06020791086885664  Rel. Test L2 Loss :  0.06303199976682664  Test L2 Loss :  0.11267871022224427  inv_L_scale:  [1.0, 1.0]
Epoch :  30  Time:  0.742  Rel. Train L2 Loss :  0.05883474714226193  Rel. Test L2 Loss :  0.06050532966852188  Test L2 Loss :  0.10632039815187454  inv_L_scale:  [1.0, 1.0]
Epoch :  31  Time:  0.742  Rel. Train L2 Loss :  0.0581294615401162  Rel. Test L2 Loss :  0.06667153894901276  Test L2 Loss :  0.11868861377239227  inv_L_scale:  [1.0, 1.0]
Epoch :  32  Time:  0.742  Rel. Train L2 Loss :  0.05656206922398673  Rel. Test L2 Loss :  0.06096215665340424  Test L2 Loss :  0.10805427700281144  inv_L_scale:  [1.0, 1.0]
Epoch :  33  Time:  0.741  Rel. Train L2 Loss :  0.05835321510831515  Rel. Test L2 Loss :  0.06122740924358368  Test L2 Loss :  0.10830423653125763  inv_L_scale:  [1.0, 1.0]
Epoch :  34  Time:  0.743  Rel. Train L2 Loss :  0.05781089637014601  Rel. Test L2 Loss :  0.06503313347697258  Test L2 Loss :  0.11547288358211517  inv_L_scale:  [1.0, 1.0]
Epoch :  35  Time:  0.742  Rel. Train L2 Loss :  0.05669289444883664  Rel. Test L2 Loss :  0.061330641210079195  Test L2 Loss :  0.1094765293598175  inv_L_scale:  [1.0, 1.0]
Epoch :  36  Time:  0.741  Rel. Train L2 Loss :  0.05717268816298909  Rel. Test L2 Loss :  0.06169822245836258  Test L2 Loss :  0.1094688230752945  inv_L_scale:  [1.0, 1.0]
Epoch :  37  Time:  0.741  Rel. Train L2 Loss :  0.05755105584859848  Rel. Test L2 Loss :  0.06348517775535584  Test L2 Loss :  0.1115574049949646  inv_L_scale:  [1.0, 1.0]
Epoch :  38  Time:  0.741  Rel. Train L2 Loss :  0.05719156894418928  Rel. Test L2 Loss :  0.06546432852745056  Test L2 Loss :  0.11663787275552749  inv_L_scale:  [1.0, 1.0]
Epoch :  39  Time:  0.741  Rel. Train L2 Loss :  0.05670443193780051  Rel. Test L2 Loss :  0.05934398114681244  Test L2 Loss :  0.1042804715037346  inv_L_scale:  [1.0, 1.0]
Epoch :  40  Time:  0.742  Rel. Train L2 Loss :  0.0571047450767623  Rel. Test L2 Loss :  0.06213969260454178  Test L2 Loss :  0.1090535718202591  inv_L_scale:  [1.0, 1.0]
Epoch :  41  Time:  0.741  Rel. Train L2 Loss :  0.056422911203569834  Rel. Test L2 Loss :  0.057256164997816085  Test L2 Loss :  0.1014354145526886  inv_L_scale:  [1.0, 1.0]
Epoch :  42  Time:  0.741  Rel. Train L2 Loss :  0.05674854518638717  Rel. Test L2 Loss :  0.06091091960668564  Test L2 Loss :  0.10857495605945587  inv_L_scale:  [1.0, 1.0]
Epoch :  43  Time:  0.742  Rel. Train L2 Loss :  0.056491487870613734  Rel. Test L2 Loss :  0.05693805202841759  Test L2 Loss :  0.10093537509441376  inv_L_scale:  [1.0, 1.0]
Epoch :  44  Time:  0.741  Rel. Train L2 Loss :  0.05693853446178966  Rel. Test L2 Loss :  0.059665330052375794  Test L2 Loss :  0.10669006019830704  inv_L_scale:  [1.0, 1.0]
Epoch :  45  Time:  0.741  Rel. Train L2 Loss :  0.05490521250499619  Rel. Test L2 Loss :  0.058915694952011106  Test L2 Loss :  0.10368946105241776  inv_L_scale:  [1.0, 1.0]
Epoch :  46  Time:  0.744  Rel. Train L2 Loss :  0.055519419312477114  Rel. Test L2 Loss :  0.06096086010336876  Test L2 Loss :  0.10673004567623139  inv_L_scale:  [1.0, 1.0]
Epoch :  47  Time:  0.742  Rel. Train L2 Loss :  0.055600563022825455  Rel. Test L2 Loss :  0.057605360150337216  Test L2 Loss :  0.10192614078521728  inv_L_scale:  [1.0, 1.0]
Epoch :  48  Time:  0.741  Rel. Train L2 Loss :  0.05461343781815635  Rel. Test L2 Loss :  0.06530669182538987  Test L2 Loss :  0.11729901522397995  inv_L_scale:  [1.0, 1.0]
Epoch :  49  Time:  0.742  Rel. Train L2 Loss :  0.05503382742404938  Rel. Test L2 Loss :  0.05953938364982605  Test L2 Loss :  0.10525402903556824  inv_L_scale:  [1.0, 1.0]
Epoch :  50  Time:  0.741  Rel. Train L2 Loss :  0.05385276857349608  Rel. Test L2 Loss :  0.06019812285900116  Test L2 Loss :  0.10609090596437454  inv_L_scale:  [1.0, 1.0]
Epoch :  51  Time:  0.741  Rel. Train L2 Loss :  0.054920053465498817  Rel. Test L2 Loss :  0.05707646161317825  Test L2 Loss :  0.10099625468254089  inv_L_scale:  [1.0, 1.0]
Epoch :  52  Time:  0.741  Rel. Train L2 Loss :  0.05381843101647165  Rel. Test L2 Loss :  0.05785236448049545  Test L2 Loss :  0.10063872873783111  inv_L_scale:  [1.0, 1.0]
Epoch :  53  Time:  0.742  Rel. Train L2 Loss :  0.05429269578721788  Rel. Test L2 Loss :  0.0692434549331665  Test L2 Loss :  0.12289757668972015  inv_L_scale:  [1.0, 1.0]
Epoch :  54  Time:  0.741  Rel. Train L2 Loss :  0.05654527319802178  Rel. Test L2 Loss :  0.057059975862503054  Test L2 Loss :  0.10175695419311523  inv_L_scale:  [1.0, 1.0]
Epoch :  55  Time:  0.741  Rel. Train L2 Loss :  0.054650979273849064  Rel. Test L2 Loss :  0.057667723298072814  Test L2 Loss :  0.10353661209344864  inv_L_scale:  [1.0, 1.0]
Epoch :  56  Time:  0.741  Rel. Train L2 Loss :  0.05384935637315114  Rel. Test L2 Loss :  0.05456730753183365  Test L2 Loss :  0.09630879342556  inv_L_scale:  [1.0, 1.0]
Epoch :  57  Time:  0.741  Rel. Train L2 Loss :  0.053801762693458134  Rel. Test L2 Loss :  0.05700193881988525  Test L2 Loss :  0.0999743390083313  inv_L_scale:  [1.0, 1.0]
Epoch :  58  Time:  0.741  Rel. Train L2 Loss :  0.05480664294626978  Rel. Test L2 Loss :  0.05535505935549736  Test L2 Loss :  0.09776228219270706  inv_L_scale:  [1.0, 1.0]
Epoch :  59  Time:  0.741  Rel. Train L2 Loss :  0.05350440849860509  Rel. Test L2 Loss :  0.05624345645308495  Test L2 Loss :  0.09888102233409882  inv_L_scale:  [1.0, 1.0]
Epoch :  60  Time:  0.744  Rel. Train L2 Loss :  0.05345865199963252  Rel. Test L2 Loss :  0.053671302497386934  Test L2 Loss :  0.09492928236722946  inv_L_scale:  [1.0, 1.0]
Epoch :  61  Time:  0.743  Rel. Train L2 Loss :  0.05226075530052185  Rel. Test L2 Loss :  0.05688435792922974  Test L2 Loss :  0.09964116245508194  inv_L_scale:  [1.0, 1.0]
Epoch :  62  Time:  0.741  Rel. Train L2 Loss :  0.05379083808925417  Rel. Test L2 Loss :  0.055481347739696506  Test L2 Loss :  0.09762667685747146  inv_L_scale:  [1.0, 1.0]
Epoch :  63  Time:  0.741  Rel. Train L2 Loss :  0.051557569884591634  Rel. Test L2 Loss :  0.05679659128189087  Test L2 Loss :  0.09939216196537018  inv_L_scale:  [1.0, 1.0]
Epoch :  64  Time:  0.742  Rel. Train L2 Loss :  0.05218045820792516  Rel. Test L2 Loss :  0.055997745990753175  Test L2 Loss :  0.09894990235567093  inv_L_scale:  [1.0, 1.0]
Epoch :  65  Time:  0.741  Rel. Train L2 Loss :  0.05210839082797369  Rel. Test L2 Loss :  0.06111065447330475  Test L2 Loss :  0.10626489996910095  inv_L_scale:  [1.0, 1.0]
Epoch :  66  Time:  0.741  Rel. Train L2 Loss :  0.052365599357419544  Rel. Test L2 Loss :  0.05556472212076187  Test L2 Loss :  0.09736311048269272  inv_L_scale:  [1.0, 1.0]
Epoch :  67  Time:  0.741  Rel. Train L2 Loss :  0.05259770055611928  Rel. Test L2 Loss :  0.05441214770078659  Test L2 Loss :  0.09585423946380615  inv_L_scale:  [1.0, 1.0]
Epoch :  68  Time:  0.742  Rel. Train L2 Loss :  0.052728182077407836  Rel. Test L2 Loss :  0.054900695830583573  Test L2 Loss :  0.09677572846412659  inv_L_scale:  [1.0, 1.0]
Epoch :  69  Time:  0.742  Rel. Train L2 Loss :  0.05137955854336421  Rel. Test L2 Loss :  0.05474400222301483  Test L2 Loss :  0.09623146533966065  inv_L_scale:  [1.0, 1.0]
Epoch :  70  Time:  0.741  Rel. Train L2 Loss :  0.05111834016111162  Rel. Test L2 Loss :  0.05947714596986771  Test L2 Loss :  0.10558287292718888  inv_L_scale:  [1.0, 1.0]
Epoch :  71  Time:  0.741  Rel. Train L2 Loss :  0.05095641682545344  Rel. Test L2 Loss :  0.05581716537475586  Test L2 Loss :  0.09905387282371521  inv_L_scale:  [1.0, 1.0]
Epoch :  72  Time:  0.742  Rel. Train L2 Loss :  0.050577211214436424  Rel. Test L2 Loss :  0.05369801104068756  Test L2 Loss :  0.09579928696155549  inv_L_scale:  [1.0, 1.0]
Epoch :  73  Time:  0.741  Rel. Train L2 Loss :  0.05154898969663514  Rel. Test L2 Loss :  0.055572061091661455  Test L2 Loss :  0.09752433776855468  inv_L_scale:  [1.0, 1.0]
Epoch :  74  Time:  0.741  Rel. Train L2 Loss :  0.0518603809343444  Rel. Test L2 Loss :  0.055239364206790924  Test L2 Loss :  0.0974953979253769  inv_L_scale:  [1.0, 1.0]
Epoch :  75  Time:  0.741  Rel. Train L2 Loss :  0.0507814846932888  Rel. Test L2 Loss :  0.05380622535943985  Test L2 Loss :  0.09528088808059693  inv_L_scale:  [1.0, 1.0]
Epoch :  76  Time:  0.741  Rel. Train L2 Loss :  0.050419516166051226  Rel. Test L2 Loss :  0.05598275557160377  Test L2 Loss :  0.09802067160606384  inv_L_scale:  [1.0, 1.0]
Epoch :  77  Time:  0.743  Rel. Train L2 Loss :  0.050561053355534874  Rel. Test L2 Loss :  0.05532331496477127  Test L2 Loss :  0.09771011233329772  inv_L_scale:  [1.0, 1.0]
Epoch :  78  Time:  0.743  Rel. Train L2 Loss :  0.05027984369132254  Rel. Test L2 Loss :  0.052805207669734955  Test L2 Loss :  0.09227273195981979  inv_L_scale:  [1.0, 1.0]
Epoch :  79  Time:  0.742  Rel. Train L2 Loss :  0.04975164582331975  Rel. Test L2 Loss :  0.05556506484746933  Test L2 Loss :  0.09810175955295562  inv_L_scale:  [1.0, 1.0]
Epoch :  80  Time:  0.742  Rel. Train L2 Loss :  0.049165547854370543  Rel. Test L2 Loss :  0.054764695167541504  Test L2 Loss :  0.09720706135034561  inv_L_scale:  [1.0, 1.0]
Epoch :  81  Time:  0.741  Rel. Train L2 Loss :  0.05064602333638403  Rel. Test L2 Loss :  0.05298120468854904  Test L2 Loss :  0.09329891294240951  inv_L_scale:  [1.0, 1.0]
Epoch :  82  Time:  0.741  Rel. Train L2 Loss :  0.0509323912858963  Rel. Test L2 Loss :  0.05758261442184448  Test L2 Loss :  0.10365233659744262  inv_L_scale:  [1.0, 1.0]
Epoch :  83  Time:  0.741  Rel. Train L2 Loss :  0.05064923647377226  Rel. Test L2 Loss :  0.054852205216884616  Test L2 Loss :  0.09598757863044739  inv_L_scale:  [1.0, 1.0]
Epoch :  84  Time:  0.741  Rel. Train L2 Loss :  0.04992522728112009  Rel. Test L2 Loss :  0.058130521327257156  Test L2 Loss :  0.10183373093605042  inv_L_scale:  [1.0, 1.0]
Epoch :  85  Time:  0.741  Rel. Train L2 Loss :  0.04996025163266394  Rel. Test L2 Loss :  0.051429924368858335  Test L2 Loss :  0.0907246220111847  inv_L_scale:  [1.0, 1.0]
Epoch :  86  Time:  0.741  Rel. Train L2 Loss :  0.04859895196225908  Rel. Test L2 Loss :  0.05079261735081673  Test L2 Loss :  0.08910706877708435  inv_L_scale:  [1.0, 1.0]
Epoch :  87  Time:  0.743  Rel. Train L2 Loss :  0.04891638191209899  Rel. Test L2 Loss :  0.05833490163087845  Test L2 Loss :  0.10205211341381074  inv_L_scale:  [1.0, 1.0]
Epoch :  88  Time:  0.742  Rel. Train L2 Loss :  0.04914156524671449  Rel. Test L2 Loss :  0.051013894975185395  Test L2 Loss :  0.0892467936873436  inv_L_scale:  [1.0, 1.0]
Epoch :  89  Time:  0.741  Rel. Train L2 Loss :  0.04845355477597978  Rel. Test L2 Loss :  0.052252291291952135  Test L2 Loss :  0.09195042043924331  inv_L_scale:  [1.0, 1.0]
Epoch :  90  Time:  0.741  Rel. Train L2 Loss :  0.048354588713910844  Rel. Test L2 Loss :  0.056516893208026886  Test L2 Loss :  0.09977695047855377  inv_L_scale:  [1.0, 1.0]
Epoch :  91  Time:  0.741  Rel. Train L2 Loss :  0.0489697193271584  Rel. Test L2 Loss :  0.05013744488358498  Test L2 Loss :  0.08795322597026825  inv_L_scale:  [1.0, 1.0]
Epoch :  92  Time:  0.742  Rel. Train L2 Loss :  0.04900070359309514  Rel. Test L2 Loss :  0.05176266118884087  Test L2 Loss :  0.0911063238978386  inv_L_scale:  [1.0, 1.0]
Epoch :  93  Time:  0.741  Rel. Train L2 Loss :  0.04952834164102872  Rel. Test L2 Loss :  0.05020669311285019  Test L2 Loss :  0.08842818558216095  inv_L_scale:  [1.0, 1.0]
Epoch :  94  Time:  0.741  Rel. Train L2 Loss :  0.04923605200317171  Rel. Test L2 Loss :  0.049698490798473355  Test L2 Loss :  0.08682159721851349  inv_L_scale:  [1.0, 1.0]
Epoch :  95  Time:  0.741  Rel. Train L2 Loss :  0.0477923075026936  Rel. Test L2 Loss :  0.0517333397269249  Test L2 Loss :  0.09071608364582062  inv_L_scale:  [1.0, 1.0]
Epoch :  96  Time:  0.741  Rel. Train L2 Loss :  0.048151303397284614  Rel. Test L2 Loss :  0.05072396069765091  Test L2 Loss :  0.08872774541378022  inv_L_scale:  [1.0, 1.0]
Epoch :  97  Time:  0.741  Rel. Train L2 Loss :  0.04847349613904953  Rel. Test L2 Loss :  0.05210575804114342  Test L2 Loss :  0.09115504801273346  inv_L_scale:  [1.0, 1.0]
Epoch :  98  Time:  0.744  Rel. Train L2 Loss :  0.04752076857619816  Rel. Test L2 Loss :  0.06628046602010727  Test L2 Loss :  0.11888242959976196  inv_L_scale:  [1.0, 1.0]
Epoch :  99  Time:  0.741  Rel. Train L2 Loss :  0.04871085007985433  Rel. Test L2 Loss :  0.057997506111860275  Test L2 Loss :  0.10271159678697586  inv_L_scale:  [1.0, 1.0]
Epoch :  100  Time:  0.741  Rel. Train L2 Loss :  0.04780413016676903  Rel. Test L2 Loss :  0.05016840234398842  Test L2 Loss :  0.08880231469869614  inv_L_scale:  [1.0, 1.0]
Epoch :  101  Time:  0.741  Rel. Train L2 Loss :  0.047600289401080874  Rel. Test L2 Loss :  0.05067731618881226  Test L2 Loss :  0.08889432698488235  inv_L_scale:  [1.0, 1.0]
Epoch :  102  Time:  0.741  Rel. Train L2 Loss :  0.048056981513897576  Rel. Test L2 Loss :  0.04951634228229523  Test L2 Loss :  0.08739660918712616  inv_L_scale:  [1.0, 1.0]
Epoch :  103  Time:  0.741  Rel. Train L2 Loss :  0.0472732502884335  Rel. Test L2 Loss :  0.04993963792920113  Test L2 Loss :  0.08806175082921981  inv_L_scale:  [1.0, 1.0]
Epoch :  104  Time:  0.741  Rel. Train L2 Loss :  0.04775197452969021  Rel. Test L2 Loss :  0.050501314848661424  Test L2 Loss :  0.08817845046520233  inv_L_scale:  [1.0, 1.0]
Epoch :  105  Time:  0.741  Rel. Train L2 Loss :  0.04772794403963619  Rel. Test L2 Loss :  0.05278897166252136  Test L2 Loss :  0.09282726466655732  inv_L_scale:  [1.0, 1.0]
Epoch :  106  Time:  0.741  Rel. Train L2 Loss :  0.047241709894604154  Rel. Test L2 Loss :  0.048704706728458405  Test L2 Loss :  0.08505026400089263  inv_L_scale:  [1.0, 1.0]
Epoch :  107  Time:  0.74  Rel. Train L2 Loss :  0.04731306059492959  Rel. Test L2 Loss :  0.052041203826665876  Test L2 Loss :  0.0912515440583229  inv_L_scale:  [1.0, 1.0]
Epoch :  108  Time:  0.741  Rel. Train L2 Loss :  0.04730904976526896  Rel. Test L2 Loss :  0.05083087772130966  Test L2 Loss :  0.09028655678033828  inv_L_scale:  [1.0, 1.0]
Epoch :  109  Time:  0.742  Rel. Train L2 Loss :  0.04671539121203953  Rel. Test L2 Loss :  0.051723778694868085  Test L2 Loss :  0.09084149569272995  inv_L_scale:  [1.0, 1.0]
Epoch :  110  Time:  0.742  Rel. Train L2 Loss :  0.0481889675060908  Rel. Test L2 Loss :  0.048582816123962404  Test L2 Loss :  0.08488033980131149  inv_L_scale:  [1.0, 1.0]
Epoch :  111  Time:  0.741  Rel. Train L2 Loss :  0.04663134793440501  Rel. Test L2 Loss :  0.05295814514160156  Test L2 Loss :  0.09362956702709198  inv_L_scale:  [1.0, 1.0]
Epoch :  112  Time:  0.741  Rel. Train L2 Loss :  0.047479988088210426  Rel. Test L2 Loss :  0.047562693059444425  Test L2 Loss :  0.08300394237041474  inv_L_scale:  [1.0, 1.0]
Epoch :  113  Time:  0.741  Rel. Train L2 Loss :  0.04652186094058885  Rel. Test L2 Loss :  0.04845588073134422  Test L2 Loss :  0.08442614674568176  inv_L_scale:  [1.0, 1.0]
Epoch :  114  Time:  0.741  Rel. Train L2 Loss :  0.04660953539941046  Rel. Test L2 Loss :  0.049654479622840884  Test L2 Loss :  0.08704670786857605  inv_L_scale:  [1.0, 1.0]
Epoch :  115  Time:  0.742  Rel. Train L2 Loss :  0.04688225309054057  Rel. Test L2 Loss :  0.04983191281557083  Test L2 Loss :  0.08705354303121567  inv_L_scale:  [1.0, 1.0]
Epoch :  116  Time:  0.741  Rel. Train L2 Loss :  0.046417084568076666  Rel. Test L2 Loss :  0.04927160367369652  Test L2 Loss :  0.0868886524438858  inv_L_scale:  [1.0, 1.0]
Epoch :  117  Time:  0.741  Rel. Train L2 Loss :  0.04649199724197388  Rel. Test L2 Loss :  0.04992048054933548  Test L2 Loss :  0.08756860256195069  inv_L_scale:  [1.0, 1.0]
Epoch :  118  Time:  0.741  Rel. Train L2 Loss :  0.04652596824698978  Rel. Test L2 Loss :  0.04795075803995132  Test L2 Loss :  0.08441911816596985  inv_L_scale:  [1.0, 1.0]
Epoch :  119  Time:  0.741  Rel. Train L2 Loss :  0.04616054871016079  Rel. Test L2 Loss :  0.048468190729618076  Test L2 Loss :  0.08447643280029297  inv_L_scale:  [1.0, 1.0]
Epoch :  120  Time:  0.741  Rel. Train L2 Loss :  0.046780192454655964  Rel. Test L2 Loss :  0.04801380395889282  Test L2 Loss :  0.0839326748251915  inv_L_scale:  [1.0, 1.0]
Epoch :  121  Time:  0.741  Rel. Train L2 Loss :  0.04635962511102359  Rel. Test L2 Loss :  0.04963220834732056  Test L2 Loss :  0.08734686583280564  inv_L_scale:  [1.0, 1.0]
Epoch :  122  Time:  0.744  Rel. Train L2 Loss :  0.045856988463136884  Rel. Test L2 Loss :  0.04982326298952103  Test L2 Loss :  0.08709979295730591  inv_L_scale:  [1.0, 1.0]
Epoch :  123  Time:  0.742  Rel. Train L2 Loss :  0.04610576286084122  Rel. Test L2 Loss :  0.04980681091547012  Test L2 Loss :  0.08779987037181854  inv_L_scale:  [1.0, 1.0]
Epoch :  124  Time:  0.741  Rel. Train L2 Loss :  0.04632685658004549  Rel. Test L2 Loss :  0.051251310110092166  Test L2 Loss :  0.08932540714740753  inv_L_scale:  [1.0, 1.0]
Epoch :  125  Time:  0.741  Rel. Train L2 Loss :  0.04553637014495002  Rel. Test L2 Loss :  0.04735085666179657  Test L2 Loss :  0.08254219084978104  inv_L_scale:  [1.0, 1.0]
Epoch :  126  Time:  0.741  Rel. Train L2 Loss :  0.04572241673866908  Rel. Test L2 Loss :  0.04772805124521255  Test L2 Loss :  0.08359861433506012  inv_L_scale:  [1.0, 1.0]
Epoch :  127  Time:  0.741  Rel. Train L2 Loss :  0.04583241119980812  Rel. Test L2 Loss :  0.047601287811994554  Test L2 Loss :  0.08287480920553207  inv_L_scale:  [1.0, 1.0]
Epoch :  128  Time:  0.741  Rel. Train L2 Loss :  0.04561155163579517  Rel. Test L2 Loss :  0.04954273760318756  Test L2 Loss :  0.0868593019247055  inv_L_scale:  [1.0, 1.0]
Epoch :  129  Time:  0.742  Rel. Train L2 Loss :  0.04564736016922527  Rel. Test L2 Loss :  0.04761132389307022  Test L2 Loss :  0.08344470620155335  inv_L_scale:  [1.0, 1.0]
Epoch :  130  Time:  0.741  Rel. Train L2 Loss :  0.045574689308802284  Rel. Test L2 Loss :  0.047166349291801454  Test L2 Loss :  0.0830721390247345  inv_L_scale:  [1.0, 1.0]
Epoch :  131  Time:  0.741  Rel. Train L2 Loss :  0.04600028220150206  Rel. Test L2 Loss :  0.05241063565015793  Test L2 Loss :  0.0939227071404457  inv_L_scale:  [1.0, 1.0]
Epoch :  132  Time:  0.741  Rel. Train L2 Loss :  0.045867350134584636  Rel. Test L2 Loss :  0.048321608006954196  Test L2 Loss :  0.08430602252483368  inv_L_scale:  [1.0, 1.0]
Epoch :  133  Time:  0.741  Rel. Train L2 Loss :  0.04610464428861936  Rel. Test L2 Loss :  0.04735816612839699  Test L2 Loss :  0.08336457520723344  inv_L_scale:  [1.0, 1.0]
Epoch :  134  Time:  0.741  Rel. Train L2 Loss :  0.045269107537137136  Rel. Test L2 Loss :  0.04764467120170593  Test L2 Loss :  0.08268351197242736  inv_L_scale:  [1.0, 1.0]
Epoch :  135  Time:  0.741  Rel. Train L2 Loss :  0.04552200671699312  Rel. Test L2 Loss :  0.048703930377960204  Test L2 Loss :  0.08547150790691375  inv_L_scale:  [1.0, 1.0]
Epoch :  136  Time:  0.743  Rel. Train L2 Loss :  0.04596678516931004  Rel. Test L2 Loss :  0.04912810906767845  Test L2 Loss :  0.08642690539360047  inv_L_scale:  [1.0, 1.0]
Epoch :  137  Time:  0.741  Rel. Train L2 Loss :  0.04517778621779548  Rel. Test L2 Loss :  0.048689316213130954  Test L2 Loss :  0.0850533527135849  inv_L_scale:  [1.0, 1.0]
Epoch :  138  Time:  0.741  Rel. Train L2 Loss :  0.045298151705000136  Rel. Test L2 Loss :  0.04798825636506081  Test L2 Loss :  0.08433111727237702  inv_L_scale:  [1.0, 1.0]
Epoch :  139  Time:  0.741  Rel. Train L2 Loss :  0.045313337908850775  Rel. Test L2 Loss :  0.04721083611249924  Test L2 Loss :  0.08231204241514206  inv_L_scale:  [1.0, 1.0]
Epoch :  140  Time:  0.741  Rel. Train L2 Loss :  0.04473659422662523  Rel. Test L2 Loss :  0.05043680191040039  Test L2 Loss :  0.0892687577009201  inv_L_scale:  [1.0, 1.0]
Epoch :  141  Time:  0.741  Rel. Train L2 Loss :  0.04550947712527381  Rel. Test L2 Loss :  0.048118702471256256  Test L2 Loss :  0.08424194157123566  inv_L_scale:  [1.0, 1.0]
Epoch :  142  Time:  0.741  Rel. Train L2 Loss :  0.04554365987579028  Rel. Test L2 Loss :  0.046334896236658096  Test L2 Loss :  0.08049913585186004  inv_L_scale:  [1.0, 1.0]
Epoch :  143  Time:  0.742  Rel. Train L2 Loss :  0.04532202939192454  Rel. Test L2 Loss :  0.04857475951313973  Test L2 Loss :  0.08491982400417328  inv_L_scale:  [1.0, 1.0]
Epoch :  144  Time:  0.741  Rel. Train L2 Loss :  0.04511031844549709  Rel. Test L2 Loss :  0.046547808051109314  Test L2 Loss :  0.08106418907642364  inv_L_scale:  [1.0, 1.0]
Epoch :  145  Time:  0.741  Rel. Train L2 Loss :  0.045420763707823227  Rel. Test L2 Loss :  0.04677062660455704  Test L2 Loss :  0.08181055635213852  inv_L_scale:  [1.0, 1.0]
Epoch :  146  Time:  0.741  Rel. Train L2 Loss :  0.04485000749429067  Rel. Test L2 Loss :  0.046241819858551025  Test L2 Loss :  0.08014627873897552  inv_L_scale:  [1.0, 1.0]
Epoch :  147  Time:  0.741  Rel. Train L2 Loss :  0.04447995343969928  Rel. Test L2 Loss :  0.047855393290519715  Test L2 Loss :  0.08445008903741837  inv_L_scale:  [1.0, 1.0]
Epoch :  148  Time:  0.741  Rel. Train L2 Loss :  0.04479980144235823  Rel. Test L2 Loss :  0.046678246557712556  Test L2 Loss :  0.08131253600120544  inv_L_scale:  [1.0, 1.0]
Epoch :  149  Time:  0.741  Rel. Train L2 Loss :  0.04471387258834309  Rel. Test L2 Loss :  0.04801603853702545  Test L2 Loss :  0.08429980307817458  inv_L_scale:  [1.0, 1.0]
Epoch :  150  Time:  0.743  Rel. Train L2 Loss :  0.04459770619869232  Rel. Test L2 Loss :  0.04664292722940445  Test L2 Loss :  0.08126826345920563  inv_L_scale:  [1.0, 1.0]
Epoch :  151  Time:  0.742  Rel. Train L2 Loss :  0.04441532630059454  Rel. Test L2 Loss :  0.048331776559352876  Test L2 Loss :  0.08481481730937958  inv_L_scale:  [1.0, 1.0]
Epoch :  152  Time:  0.741  Rel. Train L2 Loss :  0.044729598826832244  Rel. Test L2 Loss :  0.04689126431941986  Test L2 Loss :  0.08183421850204468  inv_L_scale:  [1.0, 1.0]
Epoch :  153  Time:  0.741  Rel. Train L2 Loss :  0.04450068614549107  Rel. Test L2 Loss :  0.046279184222221374  Test L2 Loss :  0.08045089811086654  inv_L_scale:  [1.0, 1.0]
Epoch :  154  Time:  0.741  Rel. Train L2 Loss :  0.04490801619158851  Rel. Test L2 Loss :  0.04768352299928665  Test L2 Loss :  0.08427668929100036  inv_L_scale:  [1.0, 1.0]
Epoch :  155  Time:  0.741  Rel. Train L2 Loss :  0.04424220068587197  Rel. Test L2 Loss :  0.04664769649505615  Test L2 Loss :  0.08161330729722976  inv_L_scale:  [1.0, 1.0]
Epoch :  156  Time:  0.741  Rel. Train L2 Loss :  0.0451473022169537  Rel. Test L2 Loss :  0.051124737560749055  Test L2 Loss :  0.0898318663239479  inv_L_scale:  [1.0, 1.0]
Epoch :  157  Time:  0.739  Rel. Train L2 Loss :  0.04459211144182417  Rel. Test L2 Loss :  0.0495006462931633  Test L2 Loss :  0.087892205119133  inv_L_scale:  [1.0, 1.0]
Epoch :  158  Time:  0.738  Rel. Train L2 Loss :  0.04459074646234512  Rel. Test L2 Loss :  0.04740453153848648  Test L2 Loss :  0.08273286402225494  inv_L_scale:  [1.0, 1.0]
Epoch :  159  Time:  0.739  Rel. Train L2 Loss :  0.04397724684741762  Rel. Test L2 Loss :  0.04726278111338615  Test L2 Loss :  0.08246578902006149  inv_L_scale:  [1.0, 1.0]
Epoch :  160  Time:  0.739  Rel. Train L2 Loss :  0.04413056492805481  Rel. Test L2 Loss :  0.04658342257142067  Test L2 Loss :  0.0812805712223053  inv_L_scale:  [1.0, 1.0]
Epoch :  161  Time:  0.739  Rel. Train L2 Loss :  0.04430034382475747  Rel. Test L2 Loss :  0.04731528252363205  Test L2 Loss :  0.08205914139747619  inv_L_scale:  [1.0, 1.0]
Epoch :  162  Time:  0.739  Rel. Train L2 Loss :  0.044391781356599595  Rel. Test L2 Loss :  0.04705550104379654  Test L2 Loss :  0.08199143081903458  inv_L_scale:  [1.0, 1.0]
Epoch :  163  Time:  0.739  Rel. Train L2 Loss :  0.04432679375012716  Rel. Test L2 Loss :  0.04614579513669014  Test L2 Loss :  0.07991403460502625  inv_L_scale:  [1.0, 1.0]
Epoch :  164  Time:  0.739  Rel. Train L2 Loss :  0.0443411290148894  Rel. Test L2 Loss :  0.04595386326313019  Test L2 Loss :  0.08009371399879456  inv_L_scale:  [1.0, 1.0]
Epoch :  165  Time:  0.739  Rel. Train L2 Loss :  0.043565569818019866  Rel. Test L2 Loss :  0.047501999437808994  Test L2 Loss :  0.08271239757537842  inv_L_scale:  [1.0, 1.0]
Epoch :  166  Time:  0.739  Rel. Train L2 Loss :  0.043995347321033475  Rel. Test L2 Loss :  0.047619017958641055  Test L2 Loss :  0.08273370623588562  inv_L_scale:  [1.0, 1.0]
Epoch :  167  Time:  0.739  Rel. Train L2 Loss :  0.044046125908692675  Rel. Test L2 Loss :  0.04603150323033333  Test L2 Loss :  0.08061778247356415  inv_L_scale:  [1.0, 1.0]
Epoch :  168  Time:  0.739  Rel. Train L2 Loss :  0.04390176844265726  Rel. Test L2 Loss :  0.04748082771897316  Test L2 Loss :  0.0835246354341507  inv_L_scale:  [1.0, 1.0]
Epoch :  169  Time:  0.739  Rel. Train L2 Loss :  0.043903217332230675  Rel. Test L2 Loss :  0.04737622484564781  Test L2 Loss :  0.08262832999229432  inv_L_scale:  [1.0, 1.0]
Epoch :  170  Time:  0.739  Rel. Train L2 Loss :  0.04378669245375527  Rel. Test L2 Loss :  0.04704282119870186  Test L2 Loss :  0.08192655861377716  inv_L_scale:  [1.0, 1.0]
Epoch :  171  Time:  0.739  Rel. Train L2 Loss :  0.043772590988212165  Rel. Test L2 Loss :  0.04696192815899849  Test L2 Loss :  0.08284959495067597  inv_L_scale:  [1.0, 1.0]
Epoch :  172  Time:  0.739  Rel. Train L2 Loss :  0.04389863452977604  Rel. Test L2 Loss :  0.04671022683382034  Test L2 Loss :  0.0823316764831543  inv_L_scale:  [1.0, 1.0]
Epoch :  173  Time:  0.739  Rel. Train L2 Loss :  0.04396882055534257  Rel. Test L2 Loss :  0.04653232097625733  Test L2 Loss :  0.08121506869792938  inv_L_scale:  [1.0, 1.0]
Epoch :  174  Time:  0.739  Rel. Train L2 Loss :  0.04374521505501535  Rel. Test L2 Loss :  0.04829363152384758  Test L2 Loss :  0.08456240147352219  inv_L_scale:  [1.0, 1.0]
Epoch :  175  Time:  0.739  Rel. Train L2 Loss :  0.0437998844186465  Rel. Test L2 Loss :  0.04632650285959244  Test L2 Loss :  0.08081182211637497  inv_L_scale:  [1.0, 1.0]
Epoch :  176  Time:  0.739  Rel. Train L2 Loss :  0.04403152992328008  Rel. Test L2 Loss :  0.047740161418914795  Test L2 Loss :  0.08315718889236451  inv_L_scale:  [1.0, 1.0]
Epoch :  177  Time:  0.74  Rel. Train L2 Loss :  0.043986956079800923  Rel. Test L2 Loss :  0.047040286958217624  Test L2 Loss :  0.08176286578178406  inv_L_scale:  [1.0, 1.0]
Epoch :  178  Time:  0.739  Rel. Train L2 Loss :  0.04356906909081671  Rel. Test L2 Loss :  0.04745049849152565  Test L2 Loss :  0.08284826576709747  inv_L_scale:  [1.0, 1.0]
Epoch :  179  Time:  0.739  Rel. Train L2 Loss :  0.043487475845548844  Rel. Test L2 Loss :  0.04707657665014267  Test L2 Loss :  0.08216516375541687  inv_L_scale:  [1.0, 1.0]
Epoch :  180  Time:  0.739  Rel. Train L2 Loss :  0.04336337367693583  Rel. Test L2 Loss :  0.04622194856405258  Test L2 Loss :  0.08049117863178253  inv_L_scale:  [1.0, 1.0]
Epoch :  181  Time:  0.739  Rel. Train L2 Loss :  0.043463911381032734  Rel. Test L2 Loss :  0.046915992051362994  Test L2 Loss :  0.08202982902526855  inv_L_scale:  [1.0, 1.0]
Epoch :  182  Time:  0.739  Rel. Train L2 Loss :  0.04334624494115512  Rel. Test L2 Loss :  0.045925319492816925  Test L2 Loss :  0.07990882635116577  inv_L_scale:  [1.0, 1.0]
Epoch :  183  Time:  0.739  Rel. Train L2 Loss :  0.04334824512402217  Rel. Test L2 Loss :  0.048220333158969876  Test L2 Loss :  0.08575453221797943  inv_L_scale:  [1.0, 1.0]
Epoch :  184  Time:  0.739  Rel. Train L2 Loss :  0.043570470247003765  Rel. Test L2 Loss :  0.04725066810846329  Test L2 Loss :  0.08276295185089111  inv_L_scale:  [1.0, 1.0]
Epoch :  185  Time:  0.74  Rel. Train L2 Loss :  0.043121145880884594  Rel. Test L2 Loss :  0.04528920039534569  Test L2 Loss :  0.07862241834402084  inv_L_scale:  [1.0, 1.0]
Epoch :  186  Time:  0.739  Rel. Train L2 Loss :  0.04331599366333749  Rel. Test L2 Loss :  0.04595119386911392  Test L2 Loss :  0.08018985211849212  inv_L_scale:  [1.0, 1.0]
Epoch :  187  Time:  0.739  Rel. Train L2 Loss :  0.04344429497917493  Rel. Test L2 Loss :  0.04793955743312836  Test L2 Loss :  0.08328408658504487  inv_L_scale:  [1.0, 1.0]
Epoch :  188  Time:  0.739  Rel. Train L2 Loss :  0.04338259827759531  Rel. Test L2 Loss :  0.04586352676153183  Test L2 Loss :  0.08005724012851716  inv_L_scale:  [1.0, 1.0]
Epoch :  189  Time:  0.739  Rel. Train L2 Loss :  0.0430771204829216  Rel. Test L2 Loss :  0.04725551515817642  Test L2 Loss :  0.0825976887345314  inv_L_scale:  [1.0, 1.0]
Epoch :  190  Time:  0.739  Rel. Train L2 Loss :  0.04334427639842033  Rel. Test L2 Loss :  0.04622112423181534  Test L2 Loss :  0.08008889824151993  inv_L_scale:  [1.0, 1.0]
Epoch :  191  Time:  0.739  Rel. Train L2 Loss :  0.043017343117131124  Rel. Test L2 Loss :  0.04686071902513504  Test L2 Loss :  0.08158486723899841  inv_L_scale:  [1.0, 1.0]
Epoch :  192  Time:  0.739  Rel. Train L2 Loss :  0.04340114382406076  Rel. Test L2 Loss :  0.0464062762260437  Test L2 Loss :  0.08071307897567749  inv_L_scale:  [1.0, 1.0]
Epoch :  193  Time:  0.739  Rel. Train L2 Loss :  0.043102941496504676  Rel. Test L2 Loss :  0.04707399308681488  Test L2 Loss :  0.08190279603004455  inv_L_scale:  [1.0, 1.0]
Epoch :  194  Time:  0.739  Rel. Train L2 Loss :  0.04294529686371485  Rel. Test L2 Loss :  0.04674912542104721  Test L2 Loss :  0.08197102129459381  inv_L_scale:  [1.0, 1.0]
Epoch :  195  Time:  0.739  Rel. Train L2 Loss :  0.043069049417972564  Rel. Test L2 Loss :  0.04603444874286652  Test L2 Loss :  0.08052692353725434  inv_L_scale:  [1.0, 1.0]
Epoch :  196  Time:  0.742  Rel. Train L2 Loss :  0.04295391922195752  Rel. Test L2 Loss :  0.046700588017702105  Test L2 Loss :  0.08226332008838654  inv_L_scale:  [1.0, 1.0]
Epoch :  197  Time:  0.739  Rel. Train L2 Loss :  0.0429589634305901  Rel. Test L2 Loss :  0.04705834656953812  Test L2 Loss :  0.08210692167282105  inv_L_scale:  [1.0, 1.0]
Epoch :  198  Time:  0.739  Rel. Train L2 Loss :  0.04291900508933597  Rel. Test L2 Loss :  0.045977624952793124  Test L2 Loss :  0.0800346338748932  inv_L_scale:  [1.0, 1.0]
Epoch :  199  Time:  0.739  Rel. Train L2 Loss :  0.042801425539784964  Rel. Test L2 Loss :  0.045558803975582124  Test L2 Loss :  0.07928582906723022  inv_L_scale:  [1.0, 1.0]
Epoch :  200  Time:  0.739  Rel. Train L2 Loss :  0.04296294407712089  Rel. Test L2 Loss :  0.04489785790443421  Test L2 Loss :  0.07813760042190551  inv_L_scale:  [1.0, 1.0]
Epoch :  201  Time:  0.739  Rel. Train L2 Loss :  0.04285554044776493  Rel. Test L2 Loss :  0.04518879145383835  Test L2 Loss :  0.07849979996681214  inv_L_scale:  [1.0, 1.0]
Epoch :  202  Time:  0.739  Rel. Train L2 Loss :  0.042843989382187524  Rel. Test L2 Loss :  0.045156835168600085  Test L2 Loss :  0.07917772948741914  inv_L_scale:  [1.0, 1.0]
Epoch :  203  Time:  0.738  Rel. Train L2 Loss :  0.042650029410918555  Rel. Test L2 Loss :  0.04463123619556427  Test L2 Loss :  0.0775835907459259  inv_L_scale:  [1.0, 1.0]
Epoch :  204  Time:  0.739  Rel. Train L2 Loss :  0.04247999186317126  Rel. Test L2 Loss :  0.04725800603628159  Test L2 Loss :  0.08279601693153381  inv_L_scale:  [1.0, 1.0]
Epoch :  205  Time:  0.739  Rel. Train L2 Loss :  0.042889384892251754  Rel. Test L2 Loss :  0.045853910744190214  Test L2 Loss :  0.07967676430940628  inv_L_scale:  [1.0, 1.0]
Epoch :  206  Time:  0.739  Rel. Train L2 Loss :  0.042724277426799136  Rel. Test L2 Loss :  0.045468728542327884  Test L2 Loss :  0.07887323379516602  inv_L_scale:  [1.0, 1.0]
Epoch :  207  Time:  0.739  Rel. Train L2 Loss :  0.042658748775720595  Rel. Test L2 Loss :  0.04546614110469818  Test L2 Loss :  0.07892102181911469  inv_L_scale:  [1.0, 1.0]
Epoch :  208  Time:  0.739  Rel. Train L2 Loss :  0.04297872872816192  Rel. Test L2 Loss :  0.045558500438928604  Test L2 Loss :  0.07927272796630859  inv_L_scale:  [1.0, 1.0]
Epoch :  209  Time:  0.739  Rel. Train L2 Loss :  0.042986661063300236  Rel. Test L2 Loss :  0.04499343782663345  Test L2 Loss :  0.07816185265779495  inv_L_scale:  [1.0, 1.0]
Epoch :  210  Time:  0.739  Rel. Train L2 Loss :  0.042698639316691295  Rel. Test L2 Loss :  0.046240656077861785  Test L2 Loss :  0.08066807925701142  inv_L_scale:  [1.0, 1.0]
Epoch :  211  Time:  0.739  Rel. Train L2 Loss :  0.042508813771936625  Rel. Test L2 Loss :  0.04540910422801971  Test L2 Loss :  0.07914994090795517  inv_L_scale:  [1.0, 1.0]
Epoch :  212  Time:  0.739  Rel. Train L2 Loss :  0.04264603697591358  Rel. Test L2 Loss :  0.04513608753681183  Test L2 Loss :  0.07879604160785675  inv_L_scale:  [1.0, 1.0]
Epoch :  213  Time:  0.739  Rel. Train L2 Loss :  0.0423879824909899  Rel. Test L2 Loss :  0.045350249856710434  Test L2 Loss :  0.07884510308504104  inv_L_scale:  [1.0, 1.0]
Epoch :  214  Time:  0.739  Rel. Train L2 Loss :  0.04254108703798718  Rel. Test L2 Loss :  0.04559029519557953  Test L2 Loss :  0.0794970828294754  inv_L_scale:  [1.0, 1.0]
Epoch :  215  Time:  0.739  Rel. Train L2 Loss :  0.042483792983823356  Rel. Test L2 Loss :  0.044856931865215305  Test L2 Loss :  0.07830656737089157  inv_L_scale:  [1.0, 1.0]
Epoch :  216  Time:  0.74  Rel. Train L2 Loss :  0.042551780773533714  Rel. Test L2 Loss :  0.046381578296422955  Test L2 Loss :  0.08069289088249207  inv_L_scale:  [1.0, 1.0]
Epoch :  217  Time:  0.739  Rel. Train L2 Loss :  0.04251246843073103  Rel. Test L2 Loss :  0.04485717475414276  Test L2 Loss :  0.0783005839586258  inv_L_scale:  [1.0, 1.0]
Epoch :  218  Time:  0.739  Rel. Train L2 Loss :  0.04215567312306828  Rel. Test L2 Loss :  0.04432111710309982  Test L2 Loss :  0.0772894161939621  inv_L_scale:  [1.0, 1.0]
Epoch :  219  Time:  0.739  Rel. Train L2 Loss :  0.042011950694852404  Rel. Test L2 Loss :  0.04472018957138062  Test L2 Loss :  0.07789982378482818  inv_L_scale:  [1.0, 1.0]
Epoch :  220  Time:  0.739  Rel. Train L2 Loss :  0.04219544629255931  Rel. Test L2 Loss :  0.04502369537949562  Test L2 Loss :  0.0787708842754364  inv_L_scale:  [1.0, 1.0]
Epoch :  221  Time:  0.739  Rel. Train L2 Loss :  0.042051211926672195  Rel. Test L2 Loss :  0.04531553730368614  Test L2 Loss :  0.07906325340270996  inv_L_scale:  [1.0, 1.0]
Epoch :  222  Time:  0.739  Rel. Train L2 Loss :  0.042756455689668654  Rel. Test L2 Loss :  0.04462289899587631  Test L2 Loss :  0.07802231311798095  inv_L_scale:  [1.0, 1.0]
Epoch :  223  Time:  0.739  Rel. Train L2 Loss :  0.04239249383409818  Rel. Test L2 Loss :  0.0459747302532196  Test L2 Loss :  0.08009445130825042  inv_L_scale:  [1.0, 1.0]
Epoch :  224  Time:  0.739  Rel. Train L2 Loss :  0.042387814919153846  Rel. Test L2 Loss :  0.04516319692134857  Test L2 Loss :  0.07904871255159378  inv_L_scale:  [1.0, 1.0]
Epoch :  225  Time:  0.739  Rel. Train L2 Loss :  0.04218290342224969  Rel. Test L2 Loss :  0.04592831999063492  Test L2 Loss :  0.08008294016122817  inv_L_scale:  [1.0, 1.0]
Epoch :  226  Time:  0.739  Rel. Train L2 Loss :  0.042107374734348724  Rel. Test L2 Loss :  0.044437106996774674  Test L2 Loss :  0.0777247792482376  inv_L_scale:  [1.0, 1.0]
Epoch :  227  Time:  0.739  Rel. Train L2 Loss :  0.042176785485612024  Rel. Test L2 Loss :  0.04393220990896225  Test L2 Loss :  0.07688035547733307  inv_L_scale:  [1.0, 1.0]
Epoch :  228  Time:  0.739  Rel. Train L2 Loss :  0.04211889127890269  Rel. Test L2 Loss :  0.044946035146713255  Test L2 Loss :  0.07820767909288406  inv_L_scale:  [1.0, 1.0]
Epoch :  229  Time:  0.739  Rel. Train L2 Loss :  0.042048265486955644  Rel. Test L2 Loss :  0.045038657933473586  Test L2 Loss :  0.07926086366176605  inv_L_scale:  [1.0, 1.0]
Epoch :  230  Time:  0.739  Rel. Train L2 Loss :  0.042165351625945834  Rel. Test L2 Loss :  0.04436405673623085  Test L2 Loss :  0.07738554358482361  inv_L_scale:  [1.0, 1.0]
Epoch :  231  Time:  0.739  Rel. Train L2 Loss :  0.04177491562234031  Rel. Test L2 Loss :  0.04527037814259529  Test L2 Loss :  0.07876639455556869  inv_L_scale:  [1.0, 1.0]
Epoch :  232  Time:  0.739  Rel. Train L2 Loss :  0.04193795692589548  Rel. Test L2 Loss :  0.04530767112970352  Test L2 Loss :  0.07883658856153489  inv_L_scale:  [1.0, 1.0]
Epoch :  233  Time:  0.739  Rel. Train L2 Loss :  0.042033635510338674  Rel. Test L2 Loss :  0.045035504400730134  Test L2 Loss :  0.07847054898738862  inv_L_scale:  [1.0, 1.0]
Epoch :  234  Time:  0.739  Rel. Train L2 Loss :  0.04200839264525308  Rel. Test L2 Loss :  0.044382287859916686  Test L2 Loss :  0.07729769349098206  inv_L_scale:  [1.0, 1.0]
Epoch :  235  Time:  0.739  Rel. Train L2 Loss :  0.04197703926099671  Rel. Test L2 Loss :  0.044430992901325225  Test L2 Loss :  0.0773554790019989  inv_L_scale:  [1.0, 1.0]
Epoch :  236  Time:  0.739  Rel. Train L2 Loss :  0.04188081325756179  Rel. Test L2 Loss :  0.045021514594554904  Test L2 Loss :  0.07866985887289048  inv_L_scale:  [1.0, 1.0]
Epoch :  237  Time:  0.741  Rel. Train L2 Loss :  0.04223951132761108  Rel. Test L2 Loss :  0.04550165385007858  Test L2 Loss :  0.07935662984848023  inv_L_scale:  [1.0, 1.0]
Epoch :  238  Time:  0.741  Rel. Train L2 Loss :  0.04176490985684925  Rel. Test L2 Loss :  0.04531744137406349  Test L2 Loss :  0.07865677416324615  inv_L_scale:  [1.0, 1.0]
Epoch :  239  Time:  0.739  Rel. Train L2 Loss :  0.04170386539565192  Rel. Test L2 Loss :  0.044643444269895555  Test L2 Loss :  0.07790929943323135  inv_L_scale:  [1.0, 1.0]
Epoch :  240  Time:  0.739  Rel. Train L2 Loss :  0.04183352053165436  Rel. Test L2 Loss :  0.04548052668571472  Test L2 Loss :  0.07920064568519593  inv_L_scale:  [1.0, 1.0]
Epoch :  241  Time:  0.739  Rel. Train L2 Loss :  0.04165310371253225  Rel. Test L2 Loss :  0.04475417003035545  Test L2 Loss :  0.07777953773736954  inv_L_scale:  [1.0, 1.0]
Epoch :  242  Time:  0.739  Rel. Train L2 Loss :  0.04201128092077043  Rel. Test L2 Loss :  0.04617184698581696  Test L2 Loss :  0.08133383572101593  inv_L_scale:  [1.0, 1.0]
Epoch :  243  Time:  0.739  Rel. Train L2 Loss :  0.042086178163687385  Rel. Test L2 Loss :  0.045696153342723846  Test L2 Loss :  0.07968286156654358  inv_L_scale:  [1.0, 1.0]
Epoch :  244  Time:  0.739  Rel. Train L2 Loss :  0.04173589468002319  Rel. Test L2 Loss :  0.04450697287917137  Test L2 Loss :  0.07796133756637573  inv_L_scale:  [1.0, 1.0]
Epoch :  245  Time:  0.739  Rel. Train L2 Loss :  0.041579940335618126  Rel. Test L2 Loss :  0.044257481545209885  Test L2 Loss :  0.07722586333751678  inv_L_scale:  [1.0, 1.0]
Epoch :  246  Time:  0.739  Rel. Train L2 Loss :  0.04179369459549586  Rel. Test L2 Loss :  0.043790756464004515  Test L2 Loss :  0.07639875650405883  inv_L_scale:  [1.0, 1.0]
Epoch :  247  Time:  0.739  Rel. Train L2 Loss :  0.0416212675968806  Rel. Test L2 Loss :  0.045028599798679354  Test L2 Loss :  0.07853039592504502  inv_L_scale:  [1.0, 1.0]
Epoch :  248  Time:  0.74  Rel. Train L2 Loss :  0.041811841626962026  Rel. Test L2 Loss :  0.044669205397367476  Test L2 Loss :  0.07786216109991073  inv_L_scale:  [1.0, 1.0]
Epoch :  249  Time:  0.739  Rel. Train L2 Loss :  0.04153790970643361  Rel. Test L2 Loss :  0.044563482105731966  Test L2 Loss :  0.07760717809200286  inv_L_scale:  [1.0, 1.0]
Epoch :  250  Time:  0.739  Rel. Train L2 Loss :  0.04145334998766581  Rel. Test L2 Loss :  0.04379998102784157  Test L2 Loss :  0.07608979761600494  inv_L_scale:  [1.0, 1.0]
Epoch :  251  Time:  0.739  Rel. Train L2 Loss :  0.04169223922822211  Rel. Test L2 Loss :  0.04443338751792908  Test L2 Loss :  0.07707993745803833  inv_L_scale:  [1.0, 1.0]
Epoch :  252  Time:  0.739  Rel. Train L2 Loss :  0.041801273359192745  Rel. Test L2 Loss :  0.04436547040939331  Test L2 Loss :  0.07711891531944275  inv_L_scale:  [1.0, 1.0]
Epoch :  253  Time:  0.739  Rel. Train L2 Loss :  0.04162039566371176  Rel. Test L2 Loss :  0.04403017580509186  Test L2 Loss :  0.07643761724233628  inv_L_scale:  [1.0, 1.0]
Epoch :  254  Time:  0.739  Rel. Train L2 Loss :  0.041587910652160644  Rel. Test L2 Loss :  0.044407321512699126  Test L2 Loss :  0.07742483139038087  inv_L_scale:  [1.0, 1.0]
Epoch :  255  Time:  0.739  Rel. Train L2 Loss :  0.04127004818783866  Rel. Test L2 Loss :  0.043898662626743315  Test L2 Loss :  0.0764312720298767  inv_L_scale:  [1.0, 1.0]
Epoch :  256  Time:  0.739  Rel. Train L2 Loss :  0.041328252719508275  Rel. Test L2 Loss :  0.0459649783372879  Test L2 Loss :  0.08006821751594544  inv_L_scale:  [1.0, 1.0]
Epoch :  257  Time:  0.739  Rel. Train L2 Loss :  0.04156861460871167  Rel. Test L2 Loss :  0.04477385878562927  Test L2 Loss :  0.07785095632076264  inv_L_scale:  [1.0, 1.0]
Epoch :  258  Time:  0.739  Rel. Train L2 Loss :  0.04134545374247763  Rel. Test L2 Loss :  0.04353765040636062  Test L2 Loss :  0.07578186869621277  inv_L_scale:  [1.0, 1.0]
Epoch :  259  Time:  0.739  Rel. Train L2 Loss :  0.04125137079093191  Rel. Test L2 Loss :  0.04557502746582031  Test L2 Loss :  0.07925065279006958  inv_L_scale:  [1.0, 1.0]
Epoch :  260  Time:  0.74  Rel. Train L2 Loss :  0.04148295564783944  Rel. Test L2 Loss :  0.04455203548073769  Test L2 Loss :  0.07792903542518616  inv_L_scale:  [1.0, 1.0]
Epoch :  261  Time:  0.739  Rel. Train L2 Loss :  0.04137247810761134  Rel. Test L2 Loss :  0.04425146907567978  Test L2 Loss :  0.07729622781276703  inv_L_scale:  [1.0, 1.0]
Epoch :  262  Time:  0.739  Rel. Train L2 Loss :  0.04130818333890703  Rel. Test L2 Loss :  0.045378753691911695  Test L2 Loss :  0.0788800948858261  inv_L_scale:  [1.0, 1.0]
Epoch :  263  Time:  0.739  Rel. Train L2 Loss :  0.04116914242506027  Rel. Test L2 Loss :  0.04464214384555817  Test L2 Loss :  0.07761977910995484  inv_L_scale:  [1.0, 1.0]
Epoch :  264  Time:  0.739  Rel. Train L2 Loss :  0.041559684856070415  Rel. Test L2 Loss :  0.04385248646140098  Test L2 Loss :  0.07618663251399994  inv_L_scale:  [1.0, 1.0]
Epoch :  265  Time:  0.739  Rel. Train L2 Loss :  0.04179552209046152  Rel. Test L2 Loss :  0.04545406371355057  Test L2 Loss :  0.07947707772254944  inv_L_scale:  [1.0, 1.0]
Epoch :  266  Time:  0.739  Rel. Train L2 Loss :  0.04122840212451087  Rel. Test L2 Loss :  0.04408130377531052  Test L2 Loss :  0.07680685937404633  inv_L_scale:  [1.0, 1.0]
Epoch :  267  Time:  0.738  Rel. Train L2 Loss :  0.041265537606345284  Rel. Test L2 Loss :  0.04406317949295044  Test L2 Loss :  0.07701809346675872  inv_L_scale:  [1.0, 1.0]
Epoch :  268  Time:  0.738  Rel. Train L2 Loss :  0.0411731977098518  Rel. Test L2 Loss :  0.044362584054470064  Test L2 Loss :  0.07697038352489471  inv_L_scale:  [1.0, 1.0]
Epoch :  269  Time:  0.739  Rel. Train L2 Loss :  0.0413743494451046  Rel. Test L2 Loss :  0.04387893468141556  Test L2 Loss :  0.07643391966819763  inv_L_scale:  [1.0, 1.0]
Epoch :  270  Time:  0.738  Rel. Train L2 Loss :  0.04114349860284063  Rel. Test L2 Loss :  0.04475086495280266  Test L2 Loss :  0.07777046233415603  inv_L_scale:  [1.0, 1.0]
Epoch :  271  Time:  0.739  Rel. Train L2 Loss :  0.040968195042676396  Rel. Test L2 Loss :  0.04413126647472382  Test L2 Loss :  0.07677418142557144  inv_L_scale:  [1.0, 1.0]
Epoch :  272  Time:  0.739  Rel. Train L2 Loss :  0.041171274450090195  Rel. Test L2 Loss :  0.04394124060869217  Test L2 Loss :  0.07652098774909973  inv_L_scale:  [1.0, 1.0]
Epoch :  273  Time:  0.739  Rel. Train L2 Loss :  0.041095731837881934  Rel. Test L2 Loss :  0.04393821015954018  Test L2 Loss :  0.07638779789209366  inv_L_scale:  [1.0, 1.0]
Epoch :  274  Time:  0.739  Rel. Train L2 Loss :  0.04099175343910853  Rel. Test L2 Loss :  0.044458310902118686  Test L2 Loss :  0.07716566145420074  inv_L_scale:  [1.0, 1.0]
Epoch :  275  Time:  0.739  Rel. Train L2 Loss :  0.04104728968607055  Rel. Test L2 Loss :  0.044168944358825686  Test L2 Loss :  0.07711989551782608  inv_L_scale:  [1.0, 1.0]
Epoch :  276  Time:  0.739  Rel. Train L2 Loss :  0.04109272034631835  Rel. Test L2 Loss :  0.043707942813634874  Test L2 Loss :  0.07564284741878509  inv_L_scale:  [1.0, 1.0]
Epoch :  277  Time:  0.739  Rel. Train L2 Loss :  0.041096493353446326  Rel. Test L2 Loss :  0.04409719467163086  Test L2 Loss :  0.07666289985179901  inv_L_scale:  [1.0, 1.0]
Epoch :  278  Time:  0.739  Rel. Train L2 Loss :  0.040993783507082195  Rel. Test L2 Loss :  0.04422701686620712  Test L2 Loss :  0.07695985585451126  inv_L_scale:  [1.0, 1.0]
Epoch :  279  Time:  0.739  Rel. Train L2 Loss :  0.041037778937154344  Rel. Test L2 Loss :  0.043558489382267  Test L2 Loss :  0.07563302665948868  inv_L_scale:  [1.0, 1.0]
Epoch :  280  Time:  0.739  Rel. Train L2 Loss :  0.040989106314049825  Rel. Test L2 Loss :  0.04511939197778702  Test L2 Loss :  0.07900139272212982  inv_L_scale:  [1.0, 1.0]
Epoch :  281  Time:  0.739  Rel. Train L2 Loss :  0.04118597065409024  Rel. Test L2 Loss :  0.04385153636336327  Test L2 Loss :  0.0764338132739067  inv_L_scale:  [1.0, 1.0]
Epoch :  282  Time:  0.739  Rel. Train L2 Loss :  0.04095661196443769  Rel. Test L2 Loss :  0.04391157239675522  Test L2 Loss :  0.07651686191558837  inv_L_scale:  [1.0, 1.0]
Epoch :  283  Time:  0.739  Rel. Train L2 Loss :  0.041029407266113496  Rel. Test L2 Loss :  0.043631940484046935  Test L2 Loss :  0.07600139677524567  inv_L_scale:  [1.0, 1.0]
Epoch :  284  Time:  0.741  Rel. Train L2 Loss :  0.04108993740545379  Rel. Test L2 Loss :  0.044257885068655016  Test L2 Loss :  0.07701492249965668  inv_L_scale:  [1.0, 1.0]
Epoch :  285  Time:  0.74  Rel. Train L2 Loss :  0.04083075351185269  Rel. Test L2 Loss :  0.04369243264198303  Test L2 Loss :  0.07602417409420013  inv_L_scale:  [1.0, 1.0]
Epoch :  286  Time:  0.739  Rel. Train L2 Loss :  0.04075981491141849  Rel. Test L2 Loss :  0.04459785401821136  Test L2 Loss :  0.07746182203292847  inv_L_scale:  [1.0, 1.0]
Epoch :  287  Time:  0.739  Rel. Train L2 Loss :  0.040963883300622304  Rel. Test L2 Loss :  0.043869622349739075  Test L2 Loss :  0.07616237968206406  inv_L_scale:  [1.0, 1.0]
Epoch :  288  Time:  0.739  Rel. Train L2 Loss :  0.040911418547232944  Rel. Test L2 Loss :  0.045281447768211365  Test L2 Loss :  0.07883397251367569  inv_L_scale:  [1.0, 1.0]
Epoch :  289  Time:  0.739  Rel. Train L2 Loss :  0.04092531073424551  Rel. Test L2 Loss :  0.043814306557178495  Test L2 Loss :  0.07598468542098999  inv_L_scale:  [1.0, 1.0]
Epoch :  290  Time:  0.739  Rel. Train L2 Loss :  0.04066404864192009  Rel. Test L2 Loss :  0.04384917765855789  Test L2 Loss :  0.07648681640625  inv_L_scale:  [1.0, 1.0]
Epoch :  291  Time:  0.739  Rel. Train L2 Loss :  0.04062201465169589  Rel. Test L2 Loss :  0.04363525539636612  Test L2 Loss :  0.07595203757286072  inv_L_scale:  [1.0, 1.0]
Epoch :  292  Time:  0.739  Rel. Train L2 Loss :  0.04067709288663334  Rel. Test L2 Loss :  0.04391497626900673  Test L2 Loss :  0.07650666683912277  inv_L_scale:  [1.0, 1.0]
Epoch :  293  Time:  0.739  Rel. Train L2 Loss :  0.04073599757419692  Rel. Test L2 Loss :  0.043779965192079544  Test L2 Loss :  0.0761280357837677  inv_L_scale:  [1.0, 1.0]
Epoch :  294  Time:  0.739  Rel. Train L2 Loss :  0.040820802003145217  Rel. Test L2 Loss :  0.04351556688547134  Test L2 Loss :  0.07574484169483185  inv_L_scale:  [1.0, 1.0]
Epoch :  295  Time:  0.739  Rel. Train L2 Loss :  0.04076774863733185  Rel. Test L2 Loss :  0.04345106601715088  Test L2 Loss :  0.07551873683929443  inv_L_scale:  [1.0, 1.0]
Epoch :  296  Time:  0.739  Rel. Train L2 Loss :  0.04071596211857266  Rel. Test L2 Loss :  0.043411712348461154  Test L2 Loss :  0.07543263375759125  inv_L_scale:  [1.0, 1.0]
Epoch :  297  Time:  0.739  Rel. Train L2 Loss :  0.040712064935101405  Rel. Test L2 Loss :  0.043480327427387236  Test L2 Loss :  0.0755458265542984  inv_L_scale:  [1.0, 1.0]
Epoch :  298  Time:  0.739  Rel. Train L2 Loss :  0.04066394590669208  Rel. Test L2 Loss :  0.043647352904081345  Test L2 Loss :  0.07601208716630936  inv_L_scale:  [1.0, 1.0]
Epoch :  299  Time:  0.739  Rel. Train L2 Loss :  0.040553688589069575  Rel. Test L2 Loss :  0.04310302197933197  Test L2 Loss :  0.07521395951509476  inv_L_scale:  [1.0, 1.0]
Epoch :  300  Time:  0.739  Rel. Train L2 Loss :  0.04060373220178816  Rel. Test L2 Loss :  0.04335767269134522  Test L2 Loss :  0.07557341754436493  inv_L_scale:  [1.0, 1.0]
Epoch :  301  Time:  0.739  Rel. Train L2 Loss :  0.04078352582123544  Rel. Test L2 Loss :  0.043692823052406314  Test L2 Loss :  0.07592573881149292  inv_L_scale:  [1.0, 1.0]
Epoch :  302  Time:  0.739  Rel. Train L2 Loss :  0.04060288442505731  Rel. Test L2 Loss :  0.043949209451675415  Test L2 Loss :  0.07637735903263092  inv_L_scale:  [1.0, 1.0]
Epoch :  303  Time:  0.739  Rel. Train L2 Loss :  0.04058473959565163  Rel. Test L2 Loss :  0.04353248625993729  Test L2 Loss :  0.07568925142288208  inv_L_scale:  [1.0, 1.0]
Epoch :  304  Time:  0.739  Rel. Train L2 Loss :  0.04060271306170358  Rel. Test L2 Loss :  0.04387630492448807  Test L2 Loss :  0.07625612169504166  inv_L_scale:  [1.0, 1.0]
Epoch :  305  Time:  0.739  Rel. Train L2 Loss :  0.04055027738213539  Rel. Test L2 Loss :  0.04367361471056938  Test L2 Loss :  0.07597434520721436  inv_L_scale:  [1.0, 1.0]
Epoch :  306  Time:  0.739  Rel. Train L2 Loss :  0.040513670477602216  Rel. Test L2 Loss :  0.043434463143348694  Test L2 Loss :  0.07581041634082794  inv_L_scale:  [1.0, 1.0]
Epoch :  307  Time:  0.739  Rel. Train L2 Loss :  0.040662743979030185  Rel. Test L2 Loss :  0.04315772220492363  Test L2 Loss :  0.07520033180713653  inv_L_scale:  [1.0, 1.0]
Epoch :  308  Time:  0.739  Rel. Train L2 Loss :  0.040349677064352565  Rel. Test L2 Loss :  0.043489590436220166  Test L2 Loss :  0.07573580473661423  inv_L_scale:  [1.0, 1.0]
Epoch :  309  Time:  0.739  Rel. Train L2 Loss :  0.0404833228720559  Rel. Test L2 Loss :  0.045881514698266984  Test L2 Loss :  0.08005146861076355  inv_L_scale:  [1.0, 1.0]
Epoch :  310  Time:  0.739  Rel. Train L2 Loss :  0.04061487005816566  Rel. Test L2 Loss :  0.043470717519521716  Test L2 Loss :  0.07559885591268539  inv_L_scale:  [1.0, 1.0]
Epoch :  311  Time:  0.739  Rel. Train L2 Loss :  0.040564580261707305  Rel. Test L2 Loss :  0.04354685217142105  Test L2 Loss :  0.07555374503135681  inv_L_scale:  [1.0, 1.0]
Epoch :  312  Time:  0.739  Rel. Train L2 Loss :  0.04040091746383243  Rel. Test L2 Loss :  0.043440488576889036  Test L2 Loss :  0.0758902096748352  inv_L_scale:  [1.0, 1.0]
Epoch :  313  Time:  0.739  Rel. Train L2 Loss :  0.040326263325081935  Rel. Test L2 Loss :  0.04354677274823189  Test L2 Loss :  0.07564152896404266  inv_L_scale:  [1.0, 1.0]
Epoch :  314  Time:  0.739  Rel. Train L2 Loss :  0.04030023554960887  Rel. Test L2 Loss :  0.04306790918111801  Test L2 Loss :  0.07497208327054977  inv_L_scale:  [1.0, 1.0]
Epoch :  315  Time:  0.739  Rel. Train L2 Loss :  0.04026154594288932  Rel. Test L2 Loss :  0.04366057157516479  Test L2 Loss :  0.07597172826528549  inv_L_scale:  [1.0, 1.0]
Epoch :  316  Time:  0.739  Rel. Train L2 Loss :  0.04026873206098874  Rel. Test L2 Loss :  0.04335417836904526  Test L2 Loss :  0.07534326732158661  inv_L_scale:  [1.0, 1.0]
Epoch :  317  Time:  0.739  Rel. Train L2 Loss :  0.04031013961467478  Rel. Test L2 Loss :  0.04331628501415253  Test L2 Loss :  0.07525392681360245  inv_L_scale:  [1.0, 1.0]
Epoch :  318  Time:  0.739  Rel. Train L2 Loss :  0.040198467440075346  Rel. Test L2 Loss :  0.043379698693752286  Test L2 Loss :  0.07544729113578796  inv_L_scale:  [1.0, 1.0]
Epoch :  319  Time:  0.739  Rel. Train L2 Loss :  0.04027175673180156  Rel. Test L2 Loss :  0.043252404928207394  Test L2 Loss :  0.07517771720886231  inv_L_scale:  [1.0, 1.0]
Epoch :  320  Time:  0.739  Rel. Train L2 Loss :  0.040413174281517666  Rel. Test L2 Loss :  0.04327617436647415  Test L2 Loss :  0.07516400277614593  inv_L_scale:  [1.0, 1.0]
Epoch :  321  Time:  0.739  Rel. Train L2 Loss :  0.040156085226270885  Rel. Test L2 Loss :  0.04303788483142853  Test L2 Loss :  0.07483842641115189  inv_L_scale:  [1.0, 1.0]
Epoch :  322  Time:  0.739  Rel. Train L2 Loss :  0.040266018187006314  Rel. Test L2 Loss :  0.04370133101940155  Test L2 Loss :  0.07601172626018524  inv_L_scale:  [1.0, 1.0]
Epoch :  323  Time:  0.739  Rel. Train L2 Loss :  0.040259523996048506  Rel. Test L2 Loss :  0.04349120318889618  Test L2 Loss :  0.07574930489063263  inv_L_scale:  [1.0, 1.0]
Epoch :  324  Time:  0.74  Rel. Train L2 Loss :  0.04013637128803465  Rel. Test L2 Loss :  0.04320168823003769  Test L2 Loss :  0.07512247890233993  inv_L_scale:  [1.0, 1.0]
Epoch :  325  Time:  0.739  Rel. Train L2 Loss :  0.04021375573343701  Rel. Test L2 Loss :  0.043359006941318515  Test L2 Loss :  0.07525308281183243  inv_L_scale:  [1.0, 1.0]
Epoch :  326  Time:  0.739  Rel. Train L2 Loss :  0.04017228184474839  Rel. Test L2 Loss :  0.043080466091632845  Test L2 Loss :  0.07501611471176148  inv_L_scale:  [1.0, 1.0]
Epoch :  327  Time:  0.739  Rel. Train L2 Loss :  0.04010141542388333  Rel. Test L2 Loss :  0.043146676421165465  Test L2 Loss :  0.07505169183015824  inv_L_scale:  [1.0, 1.0]
Epoch :  328  Time:  0.739  Rel. Train L2 Loss :  0.04009726047515869  Rel. Test L2 Loss :  0.04344627931714058  Test L2 Loss :  0.0755732649564743  inv_L_scale:  [1.0, 1.0]
Epoch :  329  Time:  0.739  Rel. Train L2 Loss :  0.04014047614402241  Rel. Test L2 Loss :  0.0431027552485466  Test L2 Loss :  0.07507020264863967  inv_L_scale:  [1.0, 1.0]
Epoch :  330  Time:  0.739  Rel. Train L2 Loss :  0.040107249551349214  Rel. Test L2 Loss :  0.04359773308038711  Test L2 Loss :  0.07570327460765838  inv_L_scale:  [1.0, 1.0]
Epoch :  331  Time:  0.739  Rel. Train L2 Loss :  0.040109084480338626  Rel. Test L2 Loss :  0.04326339542865753  Test L2 Loss :  0.07520083904266357  inv_L_scale:  [1.0, 1.0]
Epoch :  332  Time:  0.739  Rel. Train L2 Loss :  0.04003650845752822  Rel. Test L2 Loss :  0.04284851804375649  Test L2 Loss :  0.07458576560020447  inv_L_scale:  [1.0, 1.0]
Epoch :  333  Time:  0.739  Rel. Train L2 Loss :  0.04013826721244388  Rel. Test L2 Loss :  0.043297171443700794  Test L2 Loss :  0.07523492813110351  inv_L_scale:  [1.0, 1.0]
Epoch :  334  Time:  0.739  Rel. Train L2 Loss :  0.04005651871363322  Rel. Test L2 Loss :  0.04330643981695175  Test L2 Loss :  0.07539037585258485  inv_L_scale:  [1.0, 1.0]
Epoch :  335  Time:  0.739  Rel. Train L2 Loss :  0.039878996378845635  Rel. Test L2 Loss :  0.043215211927890775  Test L2 Loss :  0.07511221826076507  inv_L_scale:  [1.0, 1.0]
Epoch :  336  Time:  0.739  Rel. Train L2 Loss :  0.03993841467632188  Rel. Test L2 Loss :  0.04296425998210907  Test L2 Loss :  0.07470495760440826  inv_L_scale:  [1.0, 1.0]
Epoch :  337  Time:  0.739  Rel. Train L2 Loss :  0.03996225865350829  Rel. Test L2 Loss :  0.042856005877256395  Test L2 Loss :  0.07461221277713775  inv_L_scale:  [1.0, 1.0]
Epoch :  338  Time:  0.739  Rel. Train L2 Loss :  0.04001084178686142  Rel. Test L2 Loss :  0.04292873740196228  Test L2 Loss :  0.07459980636835098  inv_L_scale:  [1.0, 1.0]
Epoch :  339  Time:  0.739  Rel. Train L2 Loss :  0.03997100363175074  Rel. Test L2 Loss :  0.042938929498195645  Test L2 Loss :  0.0746120822429657  inv_L_scale:  [1.0, 1.0]
Epoch :  340  Time:  0.739  Rel. Train L2 Loss :  0.039814537010259096  Rel. Test L2 Loss :  0.043235615640878675  Test L2 Loss :  0.07516887068748473  inv_L_scale:  [1.0, 1.0]
Epoch :  341  Time:  0.739  Rel. Train L2 Loss :  0.03984909425179164  Rel. Test L2 Loss :  0.042945054471492765  Test L2 Loss :  0.07480819463729858  inv_L_scale:  [1.0, 1.0]
Epoch :  342  Time:  0.739  Rel. Train L2 Loss :  0.03985198305712806  Rel. Test L2 Loss :  0.04293566584587097  Test L2 Loss :  0.0747519725561142  inv_L_scale:  [1.0, 1.0]
Epoch :  343  Time:  0.739  Rel. Train L2 Loss :  0.04005542480283313  Rel. Test L2 Loss :  0.04404451340436935  Test L2 Loss :  0.07656992495059967  inv_L_scale:  [1.0, 1.0]
Epoch :  344  Time:  0.739  Rel. Train L2 Loss :  0.04000559854838583  Rel. Test L2 Loss :  0.04336159378290176  Test L2 Loss :  0.07561840176582336  inv_L_scale:  [1.0, 1.0]
Epoch :  345  Time:  0.739  Rel. Train L2 Loss :  0.03977243029408985  Rel. Test L2 Loss :  0.042847675532102586  Test L2 Loss :  0.0745658153295517  inv_L_scale:  [1.0, 1.0]
Epoch :  346  Time:  0.74  Rel. Train L2 Loss :  0.0398041832447052  Rel. Test L2 Loss :  0.043549189269542696  Test L2 Loss :  0.07560761392116547  inv_L_scale:  [1.0, 1.0]
Epoch :  347  Time:  0.739  Rel. Train L2 Loss :  0.03979637771844864  Rel. Test L2 Loss :  0.0431736333668232  Test L2 Loss :  0.07534292131662369  inv_L_scale:  [1.0, 1.0]
Epoch :  348  Time:  0.738  Rel. Train L2 Loss :  0.039700448877281615  Rel. Test L2 Loss :  0.04309866994619369  Test L2 Loss :  0.07481726586818695  inv_L_scale:  [1.0, 1.0]
Epoch :  349  Time:  0.738  Rel. Train L2 Loss :  0.039758871330155265  Rel. Test L2 Loss :  0.042845421731472016  Test L2 Loss :  0.07438475668430328  inv_L_scale:  [1.0, 1.0]
Epoch :  350  Time:  0.74  Rel. Train L2 Loss :  0.039727101458443534  Rel. Test L2 Loss :  0.04319129705429077  Test L2 Loss :  0.07507456958293915  inv_L_scale:  [1.0, 1.0]
Epoch :  351  Time:  0.737  Rel. Train L2 Loss :  0.03974873123897447  Rel. Test L2 Loss :  0.043006268739700315  Test L2 Loss :  0.07471656024456025  inv_L_scale:  [1.0, 1.0]
Epoch :  352  Time:  0.738  Rel. Train L2 Loss :  0.03975338134500715  Rel. Test L2 Loss :  0.04298271462321281  Test L2 Loss :  0.07491978019475937  inv_L_scale:  [1.0, 1.0]
Epoch :  353  Time:  0.737  Rel. Train L2 Loss :  0.03983985271718767  Rel. Test L2 Loss :  0.04306627839803696  Test L2 Loss :  0.07477015018463135  inv_L_scale:  [1.0, 1.0]
Epoch :  354  Time:  0.741  Rel. Train L2 Loss :  0.0396770241856575  Rel. Test L2 Loss :  0.04293190598487854  Test L2 Loss :  0.07462059199810028  inv_L_scale:  [1.0, 1.0]
Epoch :  355  Time:  0.739  Rel. Train L2 Loss :  0.03964784506294462  Rel. Test L2 Loss :  0.04262914732098579  Test L2 Loss :  0.07409849464893341  inv_L_scale:  [1.0, 1.0]
Epoch :  356  Time:  0.738  Rel. Train L2 Loss :  0.03966069435079893  Rel. Test L2 Loss :  0.04301723837852478  Test L2 Loss :  0.07482497274875641  inv_L_scale:  [1.0, 1.0]
Epoch :  357  Time:  0.738  Rel. Train L2 Loss :  0.03964216134614414  Rel. Test L2 Loss :  0.0428317740559578  Test L2 Loss :  0.07448720455169677  inv_L_scale:  [1.0, 1.0]
Epoch :  358  Time:  0.738  Rel. Train L2 Loss :  0.0395764774746365  Rel. Test L2 Loss :  0.042739109098911286  Test L2 Loss :  0.0743524432182312  inv_L_scale:  [1.0, 1.0]
Epoch :  359  Time:  0.738  Rel. Train L2 Loss :  0.039597474965784286  Rel. Test L2 Loss :  0.04287319853901863  Test L2 Loss :  0.07447392284870148  inv_L_scale:  [1.0, 1.0]
Epoch :  360  Time:  0.738  Rel. Train L2 Loss :  0.03951392368310028  Rel. Test L2 Loss :  0.0427631051838398  Test L2 Loss :  0.07436075776815415  inv_L_scale:  [1.0, 1.0]
Epoch :  361  Time:  0.738  Rel. Train L2 Loss :  0.039568713671631284  Rel. Test L2 Loss :  0.04259061008691788  Test L2 Loss :  0.07397940456867218  inv_L_scale:  [1.0, 1.0]
Epoch :  362  Time:  0.738  Rel. Train L2 Loss :  0.03950791546040111  Rel. Test L2 Loss :  0.04284653484821319  Test L2 Loss :  0.07439791917800903  inv_L_scale:  [1.0, 1.0]
Epoch :  363  Time:  0.738  Rel. Train L2 Loss :  0.0395965664088726  Rel. Test L2 Loss :  0.04347800463438034  Test L2 Loss :  0.07573606550693512  inv_L_scale:  [1.0, 1.0]
Epoch :  364  Time:  0.738  Rel. Train L2 Loss :  0.03951413666208585  Rel. Test L2 Loss :  0.04300153225660324  Test L2 Loss :  0.07471696943044663  inv_L_scale:  [1.0, 1.0]
Epoch :  365  Time:  0.738  Rel. Train L2 Loss :  0.0394425415330463  Rel. Test L2 Loss :  0.042804074883460996  Test L2 Loss :  0.0742223384976387  inv_L_scale:  [1.0, 1.0]
Epoch :  366  Time:  0.738  Rel. Train L2 Loss :  0.03957691488994492  Rel. Test L2 Loss :  0.042696672976017  Test L2 Loss :  0.0741147130727768  inv_L_scale:  [1.0, 1.0]
Epoch :  367  Time:  0.738  Rel. Train L2 Loss :  0.03943121155103048  Rel. Test L2 Loss :  0.042677422016859055  Test L2 Loss :  0.07427562296390533  inv_L_scale:  [1.0, 1.0]
Epoch :  368  Time:  0.738  Rel. Train L2 Loss :  0.03945725757214758  Rel. Test L2 Loss :  0.0429919844865799  Test L2 Loss :  0.07470536202192307  inv_L_scale:  [1.0, 1.0]
Epoch :  369  Time:  0.738  Rel. Train L2 Loss :  0.039433794352743363  Rel. Test L2 Loss :  0.042704391777515414  Test L2 Loss :  0.07426723688840867  inv_L_scale:  [1.0, 1.0]
Epoch :  370  Time:  0.738  Rel. Train L2 Loss :  0.03943412000934283  Rel. Test L2 Loss :  0.04297705322504044  Test L2 Loss :  0.07481253325939179  inv_L_scale:  [1.0, 1.0]
Epoch :  371  Time:  0.737  Rel. Train L2 Loss :  0.03947248874439133  Rel. Test L2 Loss :  0.04283104717731476  Test L2 Loss :  0.07459969133138657  inv_L_scale:  [1.0, 1.0]
Epoch :  372  Time:  0.738  Rel. Train L2 Loss :  0.039405659495128524  Rel. Test L2 Loss :  0.04283047467470169  Test L2 Loss :  0.07436411827802658  inv_L_scale:  [1.0, 1.0]
Epoch :  373  Time:  0.738  Rel. Train L2 Loss :  0.03935469401379426  Rel. Test L2 Loss :  0.04314613357186317  Test L2 Loss :  0.07495423853397369  inv_L_scale:  [1.0, 1.0]
Epoch :  374  Time:  0.738  Rel. Train L2 Loss :  0.03931531166036924  Rel. Test L2 Loss :  0.042615555226802826  Test L2 Loss :  0.07397352814674378  inv_L_scale:  [1.0, 1.0]
Epoch :  375  Time:  0.738  Rel. Train L2 Loss :  0.039324340009027056  Rel. Test L2 Loss :  0.042574712485074995  Test L2 Loss :  0.07409256100654601  inv_L_scale:  [1.0, 1.0]
Epoch :  376  Time:  0.738  Rel. Train L2 Loss :  0.03935049575236108  Rel. Test L2 Loss :  0.04259574592113495  Test L2 Loss :  0.07408242106437683  inv_L_scale:  [1.0, 1.0]
Epoch :  377  Time:  0.738  Rel. Train L2 Loss :  0.03929689332842827  Rel. Test L2 Loss :  0.04266716420650482  Test L2 Loss :  0.07415380358695983  inv_L_scale:  [1.0, 1.0]
Epoch :  378  Time:  0.738  Rel. Train L2 Loss :  0.03927971240546968  Rel. Test L2 Loss :  0.04290045589208603  Test L2 Loss :  0.0746752017736435  inv_L_scale:  [1.0, 1.0]
Epoch :  379  Time:  0.738  Rel. Train L2 Loss :  0.039272533125347564  Rel. Test L2 Loss :  0.04283384621143341  Test L2 Loss :  0.0743660894036293  inv_L_scale:  [1.0, 1.0]
Epoch :  380  Time:  0.738  Rel. Train L2 Loss :  0.03921161035696665  Rel. Test L2 Loss :  0.043019478917121885  Test L2 Loss :  0.07472120612859726  inv_L_scale:  [1.0, 1.0]
Epoch :  381  Time:  0.738  Rel. Train L2 Loss :  0.03931057610445553  Rel. Test L2 Loss :  0.042511967718601225  Test L2 Loss :  0.0739811259508133  inv_L_scale:  [1.0, 1.0]
Epoch :  382  Time:  0.738  Rel. Train L2 Loss :  0.039290944867663914  Rel. Test L2 Loss :  0.042748654782772066  Test L2 Loss :  0.07422712624073029  inv_L_scale:  [1.0, 1.0]
Epoch :  383  Time:  0.738  Rel. Train L2 Loss :  0.03926589818464385  Rel. Test L2 Loss :  0.04257197290658951  Test L2 Loss :  0.07396195650100708  inv_L_scale:  [1.0, 1.0]
Epoch :  384  Time:  0.738  Rel. Train L2 Loss :  0.03923484389980634  Rel. Test L2 Loss :  0.04268106237053871  Test L2 Loss :  0.0744303959608078  inv_L_scale:  [1.0, 1.0]
Epoch :  385  Time:  0.738  Rel. Train L2 Loss :  0.0391826106607914  Rel. Test L2 Loss :  0.04246012479066849  Test L2 Loss :  0.07396832883358001  inv_L_scale:  [1.0, 1.0]
Epoch :  386  Time:  0.739  Rel. Train L2 Loss :  0.03929589442080922  Rel. Test L2 Loss :  0.042537128925323485  Test L2 Loss :  0.07394873857498169  inv_L_scale:  [1.0, 1.0]
Epoch :  387  Time:  0.739  Rel. Train L2 Loss :  0.03921293810009956  Rel. Test L2 Loss :  0.04265753909945488  Test L2 Loss :  0.07407316476106644  inv_L_scale:  [1.0, 1.0]
Epoch :  388  Time:  0.739  Rel. Train L2 Loss :  0.039184235913885965  Rel. Test L2 Loss :  0.04268589645624161  Test L2 Loss :  0.07428208768367767  inv_L_scale:  [1.0, 1.0]
Epoch :  389  Time:  0.739  Rel. Train L2 Loss :  0.03911223832103941  Rel. Test L2 Loss :  0.04260609060525894  Test L2 Loss :  0.07410214215517044  inv_L_scale:  [1.0, 1.0]
Epoch :  390  Time:  0.739  Rel. Train L2 Loss :  0.039120660242107176  Rel. Test L2 Loss :  0.04266071155667305  Test L2 Loss :  0.07418180584907531  inv_L_scale:  [1.0, 1.0]
Epoch :  391  Time:  0.739  Rel. Train L2 Loss :  0.03923064712021086  Rel. Test L2 Loss :  0.04261037141084671  Test L2 Loss :  0.07418476283550263  inv_L_scale:  [1.0, 1.0]
Epoch :  392  Time:  0.739  Rel. Train L2 Loss :  0.03907482092579206  Rel. Test L2 Loss :  0.04256223499774933  Test L2 Loss :  0.07393506139516831  inv_L_scale:  [1.0, 1.0]
Epoch :  393  Time:  0.738  Rel. Train L2 Loss :  0.0391326126952966  Rel. Test L2 Loss :  0.042839997708797456  Test L2 Loss :  0.07451695770025253  inv_L_scale:  [1.0, 1.0]
Epoch :  394  Time:  0.738  Rel. Train L2 Loss :  0.03907008725735876  Rel. Test L2 Loss :  0.04284526422619819  Test L2 Loss :  0.0744055873155594  inv_L_scale:  [1.0, 1.0]
Epoch :  395  Time:  0.738  Rel. Train L2 Loss :  0.03904431910978423  Rel. Test L2 Loss :  0.042563291490077974  Test L2 Loss :  0.07399205386638641  inv_L_scale:  [1.0, 1.0]
Epoch :  396  Time:  0.738  Rel. Train L2 Loss :  0.03904864412215021  Rel. Test L2 Loss :  0.04266563028097153  Test L2 Loss :  0.0741318029165268  inv_L_scale:  [1.0, 1.0]
Epoch :  397  Time:  0.738  Rel. Train L2 Loss :  0.03902904229031669  Rel. Test L2 Loss :  0.042498477846384046  Test L2 Loss :  0.07392033755779266  inv_L_scale:  [1.0, 1.0]
Epoch :  398  Time:  0.738  Rel. Train L2 Loss :  0.0389821287492911  Rel. Test L2 Loss :  0.04245102405548096  Test L2 Loss :  0.07393026053905487  inv_L_scale:  [1.0, 1.0]
Epoch :  399  Time:  0.738  Rel. Train L2 Loss :  0.03907241861025492  Rel. Test L2 Loss :  0.04257815152406692  Test L2 Loss :  0.07392052173614502  inv_L_scale:  [1.0, 1.0]
Epoch :  400  Time:  0.738  Rel. Train L2 Loss :  0.03897030295597182  Rel. Test L2 Loss :  0.04259785830974579  Test L2 Loss :  0.07405537486076355  inv_L_scale:  [1.0, 1.0]
Epoch :  401  Time:  0.738  Rel. Train L2 Loss :  0.039007368518246543  Rel. Test L2 Loss :  0.04274997472763062  Test L2 Loss :  0.07420765340328217  inv_L_scale:  [1.0, 1.0]
Epoch :  402  Time:  0.739  Rel. Train L2 Loss :  0.039042177432113225  Rel. Test L2 Loss :  0.04266263410449028  Test L2 Loss :  0.07414000153541565  inv_L_scale:  [1.0, 1.0]
Epoch :  403  Time:  0.738  Rel. Train L2 Loss :  0.039012133065197206  Rel. Test L2 Loss :  0.042491551339626316  Test L2 Loss :  0.07390659362077713  inv_L_scale:  [1.0, 1.0]
Epoch :  404  Time:  0.738  Rel. Train L2 Loss :  0.038982516692744364  Rel. Test L2 Loss :  0.04243188351392746  Test L2 Loss :  0.0736523774266243  inv_L_scale:  [1.0, 1.0]
Epoch :  405  Time:  0.739  Rel. Train L2 Loss :  0.03894974493318134  Rel. Test L2 Loss :  0.04260108202695847  Test L2 Loss :  0.07407942473888397  inv_L_scale:  [1.0, 1.0]
Epoch :  406  Time:  0.737  Rel. Train L2 Loss :  0.03894727324446042  Rel. Test L2 Loss :  0.04253811374306679  Test L2 Loss :  0.07405506014823914  inv_L_scale:  [1.0, 1.0]
Epoch :  407  Time:  0.737  Rel. Train L2 Loss :  0.03891289816962348  Rel. Test L2 Loss :  0.042447302490472794  Test L2 Loss :  0.07364157497882844  inv_L_scale:  [1.0, 1.0]
Epoch :  408  Time:  0.738  Rel. Train L2 Loss :  0.03890278630786472  Rel. Test L2 Loss :  0.04246444374322891  Test L2 Loss :  0.07383275866508483  inv_L_scale:  [1.0, 1.0]
Epoch :  409  Time:  0.738  Rel. Train L2 Loss :  0.03889318797323439  Rel. Test L2 Loss :  0.0424321636557579  Test L2 Loss :  0.07376181244850159  inv_L_scale:  [1.0, 1.0]
Epoch :  410  Time:  0.737  Rel. Train L2 Loss :  0.03890806433227327  Rel. Test L2 Loss :  0.04257441133260727  Test L2 Loss :  0.07378697246313096  inv_L_scale:  [1.0, 1.0]
Epoch :  411  Time:  0.738  Rel. Train L2 Loss :  0.038872118807501264  Rel. Test L2 Loss :  0.042322886288166044  Test L2 Loss :  0.07362094223499298  inv_L_scale:  [1.0, 1.0]
Epoch :  412  Time:  0.737  Rel. Train L2 Loss :  0.03884974653522173  Rel. Test L2 Loss :  0.04263256549835205  Test L2 Loss :  0.07400899797677994  inv_L_scale:  [1.0, 1.0]
Epoch :  413  Time:  0.737  Rel. Train L2 Loss :  0.03884472794002957  Rel. Test L2 Loss :  0.04243544995784759  Test L2 Loss :  0.0738294318318367  inv_L_scale:  [1.0, 1.0]
Epoch :  414  Time:  0.738  Rel. Train L2 Loss :  0.03882051994403203  Rel. Test L2 Loss :  0.04245760768651962  Test L2 Loss :  0.07370715796947479  inv_L_scale:  [1.0, 1.0]
Epoch :  415  Time:  0.737  Rel. Train L2 Loss :  0.0388272619413005  Rel. Test L2 Loss :  0.042374545335769655  Test L2 Loss :  0.07371587008237838  inv_L_scale:  [1.0, 1.0]
Epoch :  416  Time:  0.737  Rel. Train L2 Loss :  0.03879265050093333  Rel. Test L2 Loss :  0.042276102602481845  Test L2 Loss :  0.07354818761348725  inv_L_scale:  [1.0, 1.0]
Epoch :  417  Time:  0.737  Rel. Train L2 Loss :  0.03891672420832846  Rel. Test L2 Loss :  0.04234939739108086  Test L2 Loss :  0.073613862991333  inv_L_scale:  [1.0, 1.0]
Epoch :  418  Time:  0.737  Rel. Train L2 Loss :  0.03881899633341365  Rel. Test L2 Loss :  0.042486120760440824  Test L2 Loss :  0.07395944714546204  inv_L_scale:  [1.0, 1.0]
Epoch :  419  Time:  0.738  Rel. Train L2 Loss :  0.03882934980922275  Rel. Test L2 Loss :  0.0424179020524025  Test L2 Loss :  0.07368699163198471  inv_L_scale:  [1.0, 1.0]
Epoch :  420  Time:  0.738  Rel. Train L2 Loss :  0.03876963751183616  Rel. Test L2 Loss :  0.04246932238340378  Test L2 Loss :  0.07373538434505462  inv_L_scale:  [1.0, 1.0]
Epoch :  421  Time:  0.737  Rel. Train L2 Loss :  0.03876949177847968  Rel. Test L2 Loss :  0.04234770759940147  Test L2 Loss :  0.0735915619134903  inv_L_scale:  [1.0, 1.0]
Epoch :  422  Time:  0.74  Rel. Train L2 Loss :  0.038746319429741966  Rel. Test L2 Loss :  0.04234627708792686  Test L2 Loss :  0.07353291213512421  inv_L_scale:  [1.0, 1.0]
Epoch :  423  Time:  0.738  Rel. Train L2 Loss :  0.03875183473030726  Rel. Test L2 Loss :  0.04236456334590912  Test L2 Loss :  0.07365254461765289  inv_L_scale:  [1.0, 1.0]
Epoch :  424  Time:  0.738  Rel. Train L2 Loss :  0.0387050637933943  Rel. Test L2 Loss :  0.04249519243836403  Test L2 Loss :  0.07384432226419449  inv_L_scale:  [1.0, 1.0]
Epoch :  425  Time:  0.737  Rel. Train L2 Loss :  0.03870353142420451  Rel. Test L2 Loss :  0.04232919096946716  Test L2 Loss :  0.07350535750389099  inv_L_scale:  [1.0, 1.0]
Epoch :  426  Time:  0.737  Rel. Train L2 Loss :  0.03872111476129956  Rel. Test L2 Loss :  0.042338817715644836  Test L2 Loss :  0.07357192635536194  inv_L_scale:  [1.0, 1.0]
Epoch :  427  Time:  0.737  Rel. Train L2 Loss :  0.0386783582634396  Rel. Test L2 Loss :  0.04231337338685989  Test L2 Loss :  0.07351268708705902  inv_L_scale:  [1.0, 1.0]
Epoch :  428  Time:  0.737  Rel. Train L2 Loss :  0.03869167133337922  Rel. Test L2 Loss :  0.04248155742883682  Test L2 Loss :  0.07393550992012024  inv_L_scale:  [1.0, 1.0]
Epoch :  429  Time:  0.737  Rel. Train L2 Loss :  0.038673082722557914  Rel. Test L2 Loss :  0.04224555522203446  Test L2 Loss :  0.07343175590038299  inv_L_scale:  [1.0, 1.0]
Epoch :  430  Time:  0.738  Rel. Train L2 Loss :  0.03869076441559527  Rel. Test L2 Loss :  0.04244693517684937  Test L2 Loss :  0.07371724247932435  inv_L_scale:  [1.0, 1.0]
Epoch :  431  Time:  0.738  Rel. Train L2 Loss :  0.03866214454174042  Rel. Test L2 Loss :  0.042386163771152494  Test L2 Loss :  0.07363445401191711  inv_L_scale:  [1.0, 1.0]
Epoch :  432  Time:  0.738  Rel. Train L2 Loss :  0.03867141081227197  Rel. Test L2 Loss :  0.04238489836454391  Test L2 Loss :  0.07362820386886597  inv_L_scale:  [1.0, 1.0]
Epoch :  433  Time:  0.739  Rel. Train L2 Loss :  0.03861304571231206  Rel. Test L2 Loss :  0.04240062266588211  Test L2 Loss :  0.07369032084941864  inv_L_scale:  [1.0, 1.0]
Epoch :  434  Time:  0.737  Rel. Train L2 Loss :  0.03862585175368521  Rel. Test L2 Loss :  0.04240752428770065  Test L2 Loss :  0.07368797063827515  inv_L_scale:  [1.0, 1.0]
Epoch :  435  Time:  0.737  Rel. Train L2 Loss :  0.038638395311103926  Rel. Test L2 Loss :  0.04236729472875595  Test L2 Loss :  0.07363601982593536  inv_L_scale:  [1.0, 1.0]
Epoch :  436  Time:  0.737  Rel. Train L2 Loss :  0.03859334462218814  Rel. Test L2 Loss :  0.042330178171396254  Test L2 Loss :  0.07356721460819245  inv_L_scale:  [1.0, 1.0]
Epoch :  437  Time:  0.737  Rel. Train L2 Loss :  0.0386002657810847  Rel. Test L2 Loss :  0.04233540937304497  Test L2 Loss :  0.07355016708374024  inv_L_scale:  [1.0, 1.0]
Epoch :  438  Time:  0.737  Rel. Train L2 Loss :  0.03858429181906912  Rel. Test L2 Loss :  0.04225059449672699  Test L2 Loss :  0.07338535279035568  inv_L_scale:  [1.0, 1.0]
Epoch :  439  Time:  0.737  Rel. Train L2 Loss :  0.0385989440480868  Rel. Test L2 Loss :  0.04234273493289947  Test L2 Loss :  0.07356538653373718  inv_L_scale:  [1.0, 1.0]
Epoch :  440  Time:  0.737  Rel. Train L2 Loss :  0.03859196954303318  Rel. Test L2 Loss :  0.04224802181124687  Test L2 Loss :  0.0734093451499939  inv_L_scale:  [1.0, 1.0]
Epoch :  441  Time:  0.737  Rel. Train L2 Loss :  0.038568887346320684  Rel. Test L2 Loss :  0.04234067440032959  Test L2 Loss :  0.07353652119636536  inv_L_scale:  [1.0, 1.0]
Epoch :  442  Time:  0.737  Rel. Train L2 Loss :  0.038560594187842474  Rel. Test L2 Loss :  0.04231019586324692  Test L2 Loss :  0.07351668119430542  inv_L_scale:  [1.0, 1.0]
Epoch :  443  Time:  0.737  Rel. Train L2 Loss :  0.03856264089544614  Rel. Test L2 Loss :  0.04231707558035851  Test L2 Loss :  0.07359671920537948  inv_L_scale:  [1.0, 1.0]
Epoch :  444  Time:  0.737  Rel. Train L2 Loss :  0.038548950503269834  Rel. Test L2 Loss :  0.04232264518737793  Test L2 Loss :  0.0735339492559433  inv_L_scale:  [1.0, 1.0]
Epoch :  445  Time:  0.737  Rel. Train L2 Loss :  0.03852639355593258  Rel. Test L2 Loss :  0.0422781802713871  Test L2 Loss :  0.07345902919769287  inv_L_scale:  [1.0, 1.0]
Epoch :  446  Time:  0.737  Rel. Train L2 Loss :  0.038520751297473906  Rel. Test L2 Loss :  0.04234372854232788  Test L2 Loss :  0.073601713180542  inv_L_scale:  [1.0, 1.0]
Epoch :  447  Time:  0.737  Rel. Train L2 Loss :  0.03854905827177896  Rel. Test L2 Loss :  0.04229476779699325  Test L2 Loss :  0.07351613283157349  inv_L_scale:  [1.0, 1.0]
Epoch :  448  Time:  0.737  Rel. Train L2 Loss :  0.038527282343970404  Rel. Test L2 Loss :  0.04230265259742737  Test L2 Loss :  0.07346914410591125  inv_L_scale:  [1.0, 1.0]
Epoch :  449  Time:  0.737  Rel. Train L2 Loss :  0.03849524501297209  Rel. Test L2 Loss :  0.04223479360342026  Test L2 Loss :  0.07338900506496429  inv_L_scale:  [1.0, 1.0]
Epoch :  450  Time:  0.737  Rel. Train L2 Loss :  0.03848567662967576  Rel. Test L2 Loss :  0.04224323958158493  Test L2 Loss :  0.07336864918470383  inv_L_scale:  [1.0, 1.0]
Epoch :  451  Time:  0.737  Rel. Train L2 Loss :  0.038514021635055545  Rel. Test L2 Loss :  0.042314105927944184  Test L2 Loss :  0.07347993671894074  inv_L_scale:  [1.0, 1.0]
Epoch :  452  Time:  0.736  Rel. Train L2 Loss :  0.038483238485124374  Rel. Test L2 Loss :  0.04222912579774857  Test L2 Loss :  0.07341654151678086  inv_L_scale:  [1.0, 1.0]
Epoch :  453  Time:  0.736  Rel. Train L2 Loss :  0.038482351385884815  Rel. Test L2 Loss :  0.042285870909690854  Test L2 Loss :  0.07344583839178086  inv_L_scale:  [1.0, 1.0]
Epoch :  454  Time:  0.737  Rel. Train L2 Loss :  0.038485539654890696  Rel. Test L2 Loss :  0.042278382480144504  Test L2 Loss :  0.0734856939315796  inv_L_scale:  [1.0, 1.0]
Epoch :  455  Time:  0.736  Rel. Train L2 Loss :  0.038476448290877874  Rel. Test L2 Loss :  0.04235908210277557  Test L2 Loss :  0.0735563364624977  inv_L_scale:  [1.0, 1.0]
Epoch :  456  Time:  0.737  Rel. Train L2 Loss :  0.03847096918357743  Rel. Test L2 Loss :  0.0422465169429779  Test L2 Loss :  0.07341696381568909  inv_L_scale:  [1.0, 1.0]
Epoch :  457  Time:  0.737  Rel. Train L2 Loss :  0.03845570845736398  Rel. Test L2 Loss :  0.04231062352657318  Test L2 Loss :  0.07349631994962692  inv_L_scale:  [1.0, 1.0]
Epoch :  458  Time:  0.737  Rel. Train L2 Loss :  0.03845061399870449  Rel. Test L2 Loss :  0.04227923780679703  Test L2 Loss :  0.07346137076616287  inv_L_scale:  [1.0, 1.0]
Epoch :  459  Time:  0.737  Rel. Train L2 Loss :  0.038446342762973575  Rel. Test L2 Loss :  0.0422922308743  Test L2 Loss :  0.07346205800771713  inv_L_scale:  [1.0, 1.0]
Epoch :  460  Time:  0.737  Rel. Train L2 Loss :  0.038425538059737946  Rel. Test L2 Loss :  0.042261886298656466  Test L2 Loss :  0.07341268539428711  inv_L_scale:  [1.0, 1.0]
Epoch :  461  Time:  0.738  Rel. Train L2 Loss :  0.03842304095625877  Rel. Test L2 Loss :  0.04223522111773491  Test L2 Loss :  0.07337188214063645  inv_L_scale:  [1.0, 1.0]
Epoch :  462  Time:  0.737  Rel. Train L2 Loss :  0.0384177330798573  Rel. Test L2 Loss :  0.04239178732037544  Test L2 Loss :  0.07362111061811447  inv_L_scale:  [1.0, 1.0]
Epoch :  463  Time:  0.737  Rel. Train L2 Loss :  0.038429386417071026  Rel. Test L2 Loss :  0.04233136266469956  Test L2 Loss :  0.07351424098014832  inv_L_scale:  [1.0, 1.0]
Epoch :  464  Time:  0.737  Rel. Train L2 Loss :  0.038408218009604346  Rel. Test L2 Loss :  0.04235471427440643  Test L2 Loss :  0.07355976998805999  inv_L_scale:  [1.0, 1.0]
Epoch :  465  Time:  0.737  Rel. Train L2 Loss :  0.038402439885669284  Rel. Test L2 Loss :  0.042322310209274294  Test L2 Loss :  0.07352879345417022  inv_L_scale:  [1.0, 1.0]
Epoch :  466  Time:  0.737  Rel. Train L2 Loss :  0.03841635455687841  Rel. Test L2 Loss :  0.042291281819343565  Test L2 Loss :  0.07347095340490341  inv_L_scale:  [1.0, 1.0]
Epoch :  467  Time:  0.737  Rel. Train L2 Loss :  0.03839791095919079  Rel. Test L2 Loss :  0.04223610281944275  Test L2 Loss :  0.07337579041719437  inv_L_scale:  [1.0, 1.0]
Epoch :  468  Time:  0.737  Rel. Train L2 Loss :  0.038384203811486564  Rel. Test L2 Loss :  0.04225841477513313  Test L2 Loss :  0.07341051876544952  inv_L_scale:  [1.0, 1.0]
Epoch :  469  Time:  0.737  Rel. Train L2 Loss :  0.03837966721091005  Rel. Test L2 Loss :  0.04227068364620209  Test L2 Loss :  0.07342117130756379  inv_L_scale:  [1.0, 1.0]
Epoch :  470  Time:  0.737  Rel. Train L2 Loss :  0.03837462327546544  Rel. Test L2 Loss :  0.0422512686252594  Test L2 Loss :  0.07338545024394989  inv_L_scale:  [1.0, 1.0]
Epoch :  471  Time:  0.737  Rel. Train L2 Loss :  0.0383749029537042  Rel. Test L2 Loss :  0.042244989424943924  Test L2 Loss :  0.07339563518762589  inv_L_scale:  [1.0, 1.0]
Epoch :  472  Time:  0.737  Rel. Train L2 Loss :  0.03837261420157221  Rel. Test L2 Loss :  0.042229546308517454  Test L2 Loss :  0.07336175441741943  inv_L_scale:  [1.0, 1.0]
Epoch :  473  Time:  0.737  Rel. Train L2 Loss :  0.03836440172460344  Rel. Test L2 Loss :  0.04223360151052475  Test L2 Loss :  0.07338213711977006  inv_L_scale:  [1.0, 1.0]
Epoch :  474  Time:  0.737  Rel. Train L2 Loss :  0.03835929607351621  Rel. Test L2 Loss :  0.04225561961531639  Test L2 Loss :  0.07341399908065796  inv_L_scale:  [1.0, 1.0]
Epoch :  475  Time:  0.737  Rel. Train L2 Loss :  0.03835699329773585  Rel. Test L2 Loss :  0.04225834369659424  Test L2 Loss :  0.07345243632793426  inv_L_scale:  [1.0, 1.0]
Epoch :  476  Time:  0.737  Rel. Train L2 Loss :  0.0383605395257473  Rel. Test L2 Loss :  0.042249277681112286  Test L2 Loss :  0.07339348047971725  inv_L_scale:  [1.0, 1.0]
Epoch :  477  Time:  0.737  Rel. Train L2 Loss :  0.038351775109767915  Rel. Test L2 Loss :  0.042248467803001406  Test L2 Loss :  0.0734097158908844  inv_L_scale:  [1.0, 1.0]
Epoch :  478  Time:  0.737  Rel. Train L2 Loss :  0.03835077933139271  Rel. Test L2 Loss :  0.04227991431951523  Test L2 Loss :  0.07345599293708802  inv_L_scale:  [1.0, 1.0]
Epoch :  479  Time:  0.737  Rel. Train L2 Loss :  0.03834310915735033  Rel. Test L2 Loss :  0.04227287232875824  Test L2 Loss :  0.07344266980886459  inv_L_scale:  [1.0, 1.0]
Epoch :  480  Time:  0.738  Rel. Train L2 Loss :  0.03834617772036129  Rel. Test L2 Loss :  0.04225894719362259  Test L2 Loss :  0.07340904951095581  inv_L_scale:  [1.0, 1.0]
Epoch :  481  Time:  0.737  Rel. Train L2 Loss :  0.03833717102805773  Rel. Test L2 Loss :  0.042244876325130465  Test L2 Loss :  0.07341227889060974  inv_L_scale:  [1.0, 1.0]
Epoch :  482  Time:  0.737  Rel. Train L2 Loss :  0.038334910290108784  Rel. Test L2 Loss :  0.04225057139992714  Test L2 Loss :  0.07340661108493805  inv_L_scale:  [1.0, 1.0]
Epoch :  483  Time:  0.737  Rel. Train L2 Loss :  0.03833076165782081  Rel. Test L2 Loss :  0.042253095209598544  Test L2 Loss :  0.07341170370578766  inv_L_scale:  [1.0, 1.0]
Epoch :  484  Time:  0.737  Rel. Train L2 Loss :  0.03832488497098287  Rel. Test L2 Loss :  0.04223475605249405  Test L2 Loss :  0.0733827567100525  inv_L_scale:  [1.0, 1.0]
Epoch :  485  Time:  0.737  Rel. Train L2 Loss :  0.03833045676350594  Rel. Test L2 Loss :  0.04224056914448738  Test L2 Loss :  0.07341447025537491  inv_L_scale:  [1.0, 1.0]
Epoch :  486  Time:  0.737  Rel. Train L2 Loss :  0.03832993083530002  Rel. Test L2 Loss :  0.04224733352661133  Test L2 Loss :  0.07340539813041687  inv_L_scale:  [1.0, 1.0]
Epoch :  487  Time:  0.737  Rel. Train L2 Loss :  0.038322907239198685  Rel. Test L2 Loss :  0.04224643990397453  Test L2 Loss :  0.07339919418096542  inv_L_scale:  [1.0, 1.0]
Epoch :  488  Time:  0.737  Rel. Train L2 Loss :  0.03832197699281904  Rel. Test L2 Loss :  0.042266158163547514  Test L2 Loss :  0.07342664420604705  inv_L_scale:  [1.0, 1.0]
Epoch :  489  Time:  0.737  Rel. Train L2 Loss :  0.03832018753720654  Rel. Test L2 Loss :  0.042280826866626736  Test L2 Loss :  0.07345107346773147  inv_L_scale:  [1.0, 1.0]
Epoch :  490  Time:  0.737  Rel. Train L2 Loss :  0.0383205616970857  Rel. Test L2 Loss :  0.04224435493350029  Test L2 Loss :  0.073394033908844  inv_L_scale:  [1.0, 1.0]
Epoch :  491  Time:  0.737  Rel. Train L2 Loss :  0.03831636900703112  Rel. Test L2 Loss :  0.042247112393379214  Test L2 Loss :  0.07341118842363357  inv_L_scale:  [1.0, 1.0]
Epoch :  492  Time:  0.737  Rel. Train L2 Loss :  0.03831478531161944  Rel. Test L2 Loss :  0.042238537967205045  Test L2 Loss :  0.07339722961187363  inv_L_scale:  [1.0, 1.0]
Epoch :  493  Time:  0.737  Rel. Train L2 Loss :  0.038314401358366015  Rel. Test L2 Loss :  0.04224730387330055  Test L2 Loss :  0.07341265380382538  inv_L_scale:  [1.0, 1.0]
Epoch :  494  Time:  0.737  Rel. Train L2 Loss :  0.03831325282653173  Rel. Test L2 Loss :  0.042255821377038955  Test L2 Loss :  0.07341190367937088  inv_L_scale:  [1.0, 1.0]
Epoch :  495  Time:  0.737  Rel. Train L2 Loss :  0.03831411802106433  Rel. Test L2 Loss :  0.04224566653370857  Test L2 Loss :  0.07340954720973969  inv_L_scale:  [1.0, 1.0]
Epoch :  496  Time:  0.737  Rel. Train L2 Loss :  0.03831066966056824  Rel. Test L2 Loss :  0.04225522205233574  Test L2 Loss :  0.0734126478433609  inv_L_scale:  [1.0, 1.0]
Epoch :  497  Time:  0.737  Rel. Train L2 Loss :  0.038311568117804  Rel. Test L2 Loss :  0.04225195229053497  Test L2 Loss :  0.0734097421169281  inv_L_scale:  [1.0, 1.0]
Epoch :  498  Time:  0.737  Rel. Train L2 Loss :  0.038310730250345336  Rel. Test L2 Loss :  0.042247255593538285  Test L2 Loss :  0.07341435223817826  inv_L_scale:  [1.0, 1.0]
Epoch :  499  Time:  0.737  Rel. Train L2 Loss :  0.038316687585579025  Rel. Test L2 Loss :  0.04225458949804306  Test L2 Loss :  0.07342046469449998  inv_L_scale:  [1.0, 1.0]
