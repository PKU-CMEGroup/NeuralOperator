use truncated 1e-6

(1000,) (1000, 1000, 1) (1000, 1000, 2)
use normalized raw measures
Preprocessing data : computing close_node_pairs
100%|█████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:15<00:00, 64.01it/s] 
maximum number of close node pairs is  10000
Casting to tensor
x train:torch.Size([900, 1000, 8]), y train:torch.Size([900, 1000, 1]), x test:torch.Size([100, 1000, 8]), y test:torch.Size([100, 1000, 1])
length of each dim:  tensor([6.5573987960815430, 6.1420288085937500])
kmax = 8, kmax_local = 8
L =  10  L_local =  0.5
In PCNO_train, ndims =  2
Epoch :  0  Time:  2.052  Rel. Train L2 Loss :  0.5058327306641472  Rel. Test L2 Loss :  0.35724117040634157  Test L2 Loss :  0.5147177124023438  inv_L_scale:  [1.0, 1.0]
Epoch :  1  Time:  1.723  Rel. Train L2 Loss :  0.2970160861147775  Rel. Test L2 Loss :  0.25008628249168396  Test L2 Loss :  0.3565833139419556  inv_L_scale:  [1.0, 1.0]
Epoch :  2  Time:  1.66  Rel. Train L2 Loss :  0.2214596688747406  Rel. Test L2 Loss :  0.20774204134941102  Test L2 Loss :  0.2937260591983795  inv_L_scale:  [1.0, 1.0]
Epoch :  3  Time:  1.68  Rel. Train L2 Loss :  0.19497144434187147  Rel. Test L2 Loss :  0.18583644270896912  Test L2 Loss :  0.266145179271698  inv_L_scale:  [1.0, 1.0]
Epoch :  4  Time:  1.659  Rel. Train L2 Loss :  0.17774305396609835  Rel. Test L2 Loss :  0.1684106171131134  Test L2 Loss :  0.24133713364601136  inv_L_scale:  [1.0, 1.0]
Epoch :  5  Time:  1.668  Rel. Train L2 Loss :  0.16904612839221955  Rel. Test L2 Loss :  0.1706860315799713  Test L2 Loss :  0.24689287185668946  inv_L_scale:  [1.0, 1.0]
Epoch :  6  Time:  1.688  Rel. Train L2 Loss :  0.16800566176573437  Rel. Test L2 Loss :  0.16847618222236632  Test L2 Loss :  0.24207650661468505  inv_L_scale:  [1.0, 1.0]
Epoch :  7  Time:  1.691  Rel. Train L2 Loss :  0.16045859846803878  Rel. Test L2 Loss :  0.1546214520931244  Test L2 Loss :  0.22257957339286805  inv_L_scale:  [1.0, 1.0]
Epoch :  8  Time:  1.663  Rel. Train L2 Loss :  0.15751606716050043  Rel. Test L2 Loss :  0.15650060296058654  Test L2 Loss :  0.22563036203384398  inv_L_scale:  [1.0, 1.0]
Epoch :  9  Time:  1.679  Rel. Train L2 Loss :  0.1545360247294108  Rel. Test L2 Loss :  0.1544572401046753  Test L2 Loss :  0.22355401039123535  inv_L_scale:  [1.0, 1.0]
Epoch :  10  Time:  1.668  Rel. Train L2 Loss :  0.15355044841766358  Rel. Test L2 Loss :  0.1535913848876953  Test L2 Loss :  0.22063480138778688  inv_L_scale:  [1.0, 1.0]
Epoch :  11  Time:  1.72  Rel. Train L2 Loss :  0.14943366547425588  Rel. Test L2 Loss :  0.14708564877510072  Test L2 Loss :  0.21157095491886138  inv_L_scale:  [1.0, 1.0]
Epoch :  12  Time:  1.676  Rel. Train L2 Loss :  0.14871040933661991  Rel. Test L2 Loss :  0.14938459992408754  Test L2 Loss :  0.21487526893615722  inv_L_scale:  [1.0, 1.0]
Epoch :  13  Time:  1.678  Rel. Train L2 Loss :  0.14702893144554563  Rel. Test L2 Loss :  0.14598017811775207  Test L2 Loss :  0.21144849717617034  inv_L_scale:  [1.0, 1.0]
Epoch :  14  Time:  1.672  Rel. Train L2 Loss :  0.14665567100048066  Rel. Test L2 Loss :  0.14434465050697326  Test L2 Loss :  0.20909262895584108  inv_L_scale:  [1.0, 1.0]
Epoch :  15  Time:  1.678  Rel. Train L2 Loss :  0.14676817082696492  Rel. Test L2 Loss :  0.14431329250335692  Test L2 Loss :  0.20838711082935332  inv_L_scale:  [1.0, 1.0]
Epoch :  16  Time:  1.678  Rel. Train L2 Loss :  0.1431957192553414  Rel. Test L2 Loss :  0.14231423139572144  Test L2 Loss :  0.20645177781581878  inv_L_scale:  [1.0, 1.0]
Epoch :  17  Time:  1.685  Rel. Train L2 Loss :  0.14075253460142348  Rel. Test L2 Loss :  0.1410989099740982  Test L2 Loss :  0.2048483407497406  inv_L_scale:  [1.0, 1.0]
Epoch :  18  Time:  1.707  Rel. Train L2 Loss :  0.1419077887800005  Rel. Test L2 Loss :  0.14110180854797363  Test L2 Loss :  0.2038384807109833  inv_L_scale:  [1.0, 1.0]
Epoch :  19  Time:  1.712  Rel. Train L2 Loss :  0.14196211212211185  Rel. Test L2 Loss :  0.1394895339012146  Test L2 Loss :  0.2010010552406311  inv_L_scale:  [1.0, 1.0]
Epoch :  20  Time:  1.741  Rel. Train L2 Loss :  0.14015004422929553  Rel. Test L2 Loss :  0.14052756428718566  Test L2 Loss :  0.20347951591014862  inv_L_scale:  [1.0, 1.0]
Epoch :  21  Time:  1.695  Rel. Train L2 Loss :  0.13807593080732558  Rel. Test L2 Loss :  0.13731375575065613  Test L2 Loss :  0.19960394024848938  inv_L_scale:  [1.0, 1.0]
Epoch :  22  Time:  1.666  Rel. Train L2 Loss :  0.1390723979473114  Rel. Test L2 Loss :  0.1392261826992035  Test L2 Loss :  0.20154493808746338  inv_L_scale:  [1.0, 1.0]
Epoch :  23  Time:  1.705  Rel. Train L2 Loss :  0.13824013027879928  Rel. Test L2 Loss :  0.1350797075033188  Test L2 Loss :  0.19582208275794982  inv_L_scale:  [1.0, 1.0]
Epoch :  24  Time:  1.708  Rel. Train L2 Loss :  0.1370532245768441  Rel. Test L2 Loss :  0.1392194765806198  Test L2 Loss :  0.20100242733955384  inv_L_scale:  [1.0, 1.0]
Epoch :  25  Time:  1.676  Rel. Train L2 Loss :  0.13713284830252329  Rel. Test L2 Loss :  0.1372243982553482  Test L2 Loss :  0.19829354763031007  inv_L_scale:  [1.0, 1.0]
Epoch :  26  Time:  1.683  Rel. Train L2 Loss :  0.1365958312484953  Rel. Test L2 Loss :  0.13302038431167604  Test L2 Loss :  0.19257589519023896  inv_L_scale:  [1.0, 1.0]
Epoch :  27  Time:  1.664  Rel. Train L2 Loss :  0.13617157578468322  Rel. Test L2 Loss :  0.13499254047870635  Test L2 Loss :  0.19585086822509765  inv_L_scale:  [1.0, 1.0]
Epoch :  28  Time:  1.671  Rel. Train L2 Loss :  0.13523851964208816  Rel. Test L2 Loss :  0.13493369460105897  Test L2 Loss :  0.19540011942386626  inv_L_scale:  [1.0, 1.0]
Epoch :  29  Time:  1.693  Rel. Train L2 Loss :  0.13533986336655088  Rel. Test L2 Loss :  0.13258379995822905  Test L2 Loss :  0.19233487725257872  inv_L_scale:  [1.0, 1.0]
Epoch :  30  Time:  1.738  Rel. Train L2 Loss :  0.13679316282272339  Rel. Test L2 Loss :  0.1305996459722519  Test L2 Loss :  0.18972918927669524  inv_L_scale:  [1.0, 1.0]
Epoch :  31  Time:  1.678  Rel. Train L2 Loss :  0.13486172633038626  Rel. Test L2 Loss :  0.13721716165542602  Test L2 Loss :  0.19764393150806428  inv_L_scale:  [1.0, 1.0]
Epoch :  32  Time:  1.708  Rel. Train L2 Loss :  0.1358424864212672  Rel. Test L2 Loss :  0.13539673686027526  Test L2 Loss :  0.1965367841720581  inv_L_scale:  [1.0, 1.0]
Epoch :  33  Time:  1.669  Rel. Train L2 Loss :  0.1354297286272049  Rel. Test L2 Loss :  0.13408678352832795  Test L2 Loss :  0.1938411319255829  inv_L_scale:  [1.0, 1.0]
Epoch :  34  Time:  1.675  Rel. Train L2 Loss :  0.13522931608888838  Rel. Test L2 Loss :  0.1333945655822754  Test L2 Loss :  0.19288115859031676  inv_L_scale:  [1.0, 1.0]
Epoch :  35  Time:  1.685  Rel. Train L2 Loss :  0.13483992007043627  Rel. Test L2 Loss :  0.1321412181854248  Test L2 Loss :  0.19230637907981873  inv_L_scale:  [1.0, 1.0]
Epoch :  36  Time:  1.681  Rel. Train L2 Loss :  0.13414793782764012  Rel. Test L2 Loss :  0.1317918986082077  Test L2 Loss :  0.19178245902061464  inv_L_scale:  [1.0, 1.0]
Epoch :  37  Time:  1.682  Rel. Train L2 Loss :  0.13305130587683783  Rel. Test L2 Loss :  0.13193564891815185  Test L2 Loss :  0.19166605591773986  inv_L_scale:  [1.0, 1.0]
Epoch :  38  Time:  1.67  Rel. Train L2 Loss :  0.13421430077817706  Rel. Test L2 Loss :  0.13184048652648925  Test L2 Loss :  0.19156383156776427  inv_L_scale:  [1.0, 1.0]
Epoch :  39  Time:  1.677  Rel. Train L2 Loss :  0.13329895264572567  Rel. Test L2 Loss :  0.1280643481016159  Test L2 Loss :  0.1866463279724121  inv_L_scale:  [1.0, 1.0]
Epoch :  40  Time:  1.673  Rel. Train L2 Loss :  0.13410381780730354  Rel. Test L2 Loss :  0.13290468037128447  Test L2 Loss :  0.19256459772586823  inv_L_scale:  [1.0, 1.0]
Epoch :  41  Time:  1.684  Rel. Train L2 Loss :  0.13383318569925096  Rel. Test L2 Loss :  0.13037046134471894  Test L2 Loss :  0.1891135585308075  inv_L_scale:  [1.0, 1.0]
Epoch :  42  Time:  1.672  Rel. Train L2 Loss :  0.13351755135589174  Rel. Test L2 Loss :  0.13499372243881225  Test L2 Loss :  0.1946658807992935  inv_L_scale:  [1.0, 1.0]
Epoch :  43  Time:  1.674  Rel. Train L2 Loss :  0.1327860465976927  Rel. Test L2 Loss :  0.13302073299884795  Test L2 Loss :  0.19282573759555816  inv_L_scale:  [1.0, 1.0]
Epoch :  44  Time:  1.679  Rel. Train L2 Loss :  0.1324672938717736  Rel. Test L2 Loss :  0.1317718344926834  Test L2 Loss :  0.19135227918624878  inv_L_scale:  [1.0, 1.0]
Epoch :  45  Time:  1.726  Rel. Train L2 Loss :  0.13240728053781722  Rel. Test L2 Loss :  0.128722263276577  Test L2 Loss :  0.18683848440647124  inv_L_scale:  [1.0, 1.0]
Epoch :  46  Time:  1.665  Rel. Train L2 Loss :  0.13309161192841001  Rel. Test L2 Loss :  0.1321747735142708  Test L2 Loss :  0.192079496383667  inv_L_scale:  [1.0, 1.0]
Epoch :  47  Time:  1.676  Rel. Train L2 Loss :  0.13194613840844896  Rel. Test L2 Loss :  0.131256822347641  Test L2 Loss :  0.19047003030776977  inv_L_scale:  [1.0, 1.0]
Epoch :  48  Time:  1.664  Rel. Train L2 Loss :  0.13134336438443925  Rel. Test L2 Loss :  0.13033304154872893  Test L2 Loss :  0.18886313438415528  inv_L_scale:  [1.0, 1.0]
Epoch :  49  Time:  1.726  Rel. Train L2 Loss :  0.13214768846829733  Rel. Test L2 Loss :  0.13069787561893464  Test L2 Loss :  0.1891198468208313  inv_L_scale:  [1.0, 1.0]
Epoch :  50  Time:  1.71  Rel. Train L2 Loss :  0.131018923719724  Rel. Test L2 Loss :  0.13273687779903412  Test L2 Loss :  0.19235468447208404  inv_L_scale:  [1.0, 1.0]
Epoch :  51  Time:  1.683  Rel. Train L2 Loss :  0.13133788824081422  Rel. Test L2 Loss :  0.12982747256755828  Test L2 Loss :  0.18823497474193573  inv_L_scale:  [1.0, 1.0]
Epoch :  52  Time:  1.674  Rel. Train L2 Loss :  0.1301415350370937  Rel. Test L2 Loss :  0.12992954701185228  Test L2 Loss :  0.1890537214279175  inv_L_scale:  [1.0, 1.0]
Epoch :  53  Time:  1.695  Rel. Train L2 Loss :  0.13376121845510272  Rel. Test L2 Loss :  0.1287880364060402  Test L2 Loss :  0.18719018936157228  inv_L_scale:  [1.0, 1.0]
Epoch :  54  Time:  1.705  Rel. Train L2 Loss :  0.13061645060777663  Rel. Test L2 Loss :  0.12743226289749146  Test L2 Loss :  0.18593371033668518  inv_L_scale:  [1.0, 1.0]
Epoch :  55  Time:  1.667  Rel. Train L2 Loss :  0.1308518100447125  Rel. Test L2 Loss :  0.12978688180446624  Test L2 Loss :  0.18859490275382995  inv_L_scale:  [1.0, 1.0]
Epoch :  56  Time:  1.69  Rel. Train L2 Loss :  0.1315907707479265  Rel. Test L2 Loss :  0.130320383310318  Test L2 Loss :  0.18894995272159576  inv_L_scale:  [1.0, 1.0]
Epoch :  57  Time:  1.703  Rel. Train L2 Loss :  0.13121830072667864  Rel. Test L2 Loss :  0.130035942196846  Test L2 Loss :  0.1884362679719925  inv_L_scale:  [1.0, 1.0]
Epoch :  58  Time:  1.689  Rel. Train L2 Loss :  0.1305685650308927  Rel. Test L2 Loss :  0.12893108248710633  Test L2 Loss :  0.18713467955589294  inv_L_scale:  [1.0, 1.0]
Epoch :  59  Time:  1.695  Rel. Train L2 Loss :  0.13126498791906568  Rel. Test L2 Loss :  0.1275076997280121  Test L2 Loss :  0.1852378511428833  inv_L_scale:  [1.0, 1.0]
Epoch :  60  Time:  1.711  Rel. Train L2 Loss :  0.13084500710169475  Rel. Test L2 Loss :  0.12909780859947204  Test L2 Loss :  0.18730829715728758  inv_L_scale:  [1.0, 1.0]
Epoch :  61  Time:  1.687  Rel. Train L2 Loss :  0.13004451029830508  Rel. Test L2 Loss :  0.12764810860157014  Test L2 Loss :  0.18537893533706665  inv_L_scale:  [1.0, 1.0]
Epoch :  62  Time:  1.703  Rel. Train L2 Loss :  0.13077178306049772  Rel. Test L2 Loss :  0.12970145404338837  Test L2 Loss :  0.18922564566135405  inv_L_scale:  [1.0, 1.0]
Epoch :  63  Time:  1.69  Rel. Train L2 Loss :  0.1297384128305647  Rel. Test L2 Loss :  0.13151875674724578  Test L2 Loss :  0.19126794934272767  inv_L_scale:  [1.0, 1.0]
Epoch :  64  Time:  1.689  Rel. Train L2 Loss :  0.13168473872873518  Rel. Test L2 Loss :  0.13366810262203216  Test L2 Loss :  0.19340550363063813  inv_L_scale:  [1.0, 1.0]
Epoch :  65  Time:  1.705  Rel. Train L2 Loss :  0.1302329977353414  Rel. Test L2 Loss :  0.12819282978773117  Test L2 Loss :  0.18629478454589843  inv_L_scale:  [1.0, 1.0]
Epoch :  66  Time:  1.684  Rel. Train L2 Loss :  0.13016919871171315  Rel. Test L2 Loss :  0.12683821350336075  Test L2 Loss :  0.18391914308071136  inv_L_scale:  [1.0, 1.0]
Epoch :  67  Time:  1.725  Rel. Train L2 Loss :  0.1295872473716736  Rel. Test L2 Loss :  0.12890894025564192  Test L2 Loss :  0.1878744840621948  inv_L_scale:  [1.0, 1.0]
Epoch :  68  Time:  1.674  Rel. Train L2 Loss :  0.1306426508559121  Rel. Test L2 Loss :  0.1260340142250061  Test L2 Loss :  0.1834878671169281  inv_L_scale:  [1.0, 1.0]
Epoch :  69  Time:  1.67  Rel. Train L2 Loss :  0.1287942330704795  Rel. Test L2 Loss :  0.1296272248029709  Test L2 Loss :  0.18833414018154143  inv_L_scale:  [1.0, 1.0]
Epoch :  70  Time:  1.673  Rel. Train L2 Loss :  0.12952690263589223  Rel. Test L2 Loss :  0.12939889788627623  Test L2 Loss :  0.18820647418498992  inv_L_scale:  [1.0, 1.0]
Epoch :  71  Time:  1.718  Rel. Train L2 Loss :  0.1293962597515848  Rel. Test L2 Loss :  0.1273864832520485  Test L2 Loss :  0.18503944754600524  inv_L_scale:  [1.0, 1.0]
Epoch :  72  Time:  1.693  Rel. Train L2 Loss :  0.12800149738788605  Rel. Test L2 Loss :  0.1266149601340294  Test L2 Loss :  0.18423660159111022  inv_L_scale:  [1.0, 1.0]
Epoch :  73  Time:  1.713  Rel. Train L2 Loss :  0.12894457088576422  Rel. Test L2 Loss :  0.1271626317501068  Test L2 Loss :  0.18437474727630615  inv_L_scale:  [1.0, 1.0]
Epoch :  74  Time:  1.696  Rel. Train L2 Loss :  0.12919061528311834  Rel. Test L2 Loss :  0.127184476852417  Test L2 Loss :  0.18457306563854217  inv_L_scale:  [1.0, 1.0]
Epoch :  75  Time:  1.679  Rel. Train L2 Loss :  0.12866988215181563  Rel. Test L2 Loss :  0.12662237733602524  Test L2 Loss :  0.1840423262119293  inv_L_scale:  [1.0, 1.0]
Epoch :  76  Time:  1.682  Rel. Train L2 Loss :  0.12810999545786117  Rel. Test L2 Loss :  0.1282876744866371  Test L2 Loss :  0.18643500447273254  inv_L_scale:  [1.0, 1.0]
Epoch :  77  Time:  1.684  Rel. Train L2 Loss :  0.12793546577294668  Rel. Test L2 Loss :  0.1276774114370346  Test L2 Loss :  0.18553715646266938  inv_L_scale:  [1.0, 1.0]
Epoch :  78  Time:  1.671  Rel. Train L2 Loss :  0.12911669241057502  Rel. Test L2 Loss :  0.12616910845041274  Test L2 Loss :  0.1835905909538269  inv_L_scale:  [1.0, 1.0]
Epoch :  79  Time:  1.689  Rel. Train L2 Loss :  0.1286517937315835  Rel. Test L2 Loss :  0.129383944272995  Test L2 Loss :  0.18803323149681092  inv_L_scale:  [1.0, 1.0]
Epoch :  80  Time:  1.673  Rel. Train L2 Loss :  0.12876652095052932  Rel. Test L2 Loss :  0.12708954632282257  Test L2 Loss :  0.18523648083209993  inv_L_scale:  [1.0, 1.0]
Epoch :  81  Time:  1.678  Rel. Train L2 Loss :  0.1284290119012197  Rel. Test L2 Loss :  0.1322781276702881  Test L2 Loss :  0.1919369077682495  inv_L_scale:  [1.0, 1.0]
Epoch :  82  Time:  1.717  Rel. Train L2 Loss :  0.12882120735115477  Rel. Test L2 Loss :  0.12661567866802215  Test L2 Loss :  0.18409691691398622  inv_L_scale:  [1.0, 1.0]
Epoch :  83  Time:  1.681  Rel. Train L2 Loss :  0.12795656045277914  Rel. Test L2 Loss :  0.1302625823020935  Test L2 Loss :  0.18935187935829162  inv_L_scale:  [1.0, 1.0]
Epoch :  84  Time:  1.67  Rel. Train L2 Loss :  0.12751941743824216  Rel. Test L2 Loss :  0.12700157284736632  Test L2 Loss :  0.18485238671302795  inv_L_scale:  [1.0, 1.0]
Epoch :  85  Time:  1.681  Rel. Train L2 Loss :  0.12770568999979232  Rel. Test L2 Loss :  0.12470215201377868  Test L2 Loss :  0.18193820714950562  inv_L_scale:  [1.0, 1.0]
Epoch :  86  Time:  1.672  Rel. Train L2 Loss :  0.1281888735625479  Rel. Test L2 Loss :  0.12558215975761414  Test L2 Loss :  0.1827125608921051  inv_L_scale:  [1.0, 1.0]
Epoch :  87  Time:  1.673  Rel. Train L2 Loss :  0.12769415411684248  Rel. Test L2 Loss :  0.1250404930114746  Test L2 Loss :  0.18255117774009705  inv_L_scale:  [1.0, 1.0]
Epoch :  88  Time:  1.702  Rel. Train L2 Loss :  0.12691068132718406  Rel. Test L2 Loss :  0.12872798681259157  Test L2 Loss :  0.18680236101150513  inv_L_scale:  [1.0, 1.0]