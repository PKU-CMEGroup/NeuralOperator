Loading data from  ../../data/curve//pcno_curve_data_1_1_5_5_stokes.npz
(1000,) (1000, 1000, 1) (1000, 1000, 2)
use normalized raw measures
Casting to tensor
x_train shape torch.Size([900, 1000, 8]), y_train shape torch.Size([900, 1000, 1])
length of each dim:  tensor([6.6455335617065430, 6.6654777526855469])
kmax = 16
L = 14
geo_dims = [1, 2, 3, 4], num_grad = 3
In PCNO_train, ndims =  2
Epoch :  0  Time:  6.437  Rel. Train L2 Loss :  0.38009319464365643  Rel. Test L2 Loss :  0.24381035089492797  Test L2 Loss :  0.472421236038208  inv_L_scale:  [1.0, 1.0]
Epoch :  1  Time:  0.893  Rel. Train L2 Loss :  0.19604438702265423  Rel. Test L2 Loss :  0.15901949465274812  Test L2 Loss :  0.3037050330638886  inv_L_scale:  [1.0, 1.0]
Epoch :  2  Time:  0.895  Rel. Train L2 Loss :  0.13969563381539452  Rel. Test L2 Loss :  0.12906598687171936  Test L2 Loss :  0.23723813235759736  inv_L_scale:  [1.0, 1.0]
Epoch :  3  Time:  0.893  Rel. Train L2 Loss :  0.11857918838659923  Rel. Test L2 Loss :  0.11961100935935974  Test L2 Loss :  0.21973370552062987  inv_L_scale:  [1.0, 1.0]
Epoch :  4  Time:  0.894  Rel. Train L2 Loss :  0.10353625234630373  Rel. Test L2 Loss :  0.10107966005802155  Test L2 Loss :  0.18954916119575502  inv_L_scale:  [1.0, 1.0]
Epoch :  5  Time:  0.893  Rel. Train L2 Loss :  0.09178164958953858  Rel. Test L2 Loss :  0.0955523782968521  Test L2 Loss :  0.17595331490039826  inv_L_scale:  [1.0, 1.0]
Epoch :  6  Time:  0.893  Rel. Train L2 Loss :  0.08799098723464542  Rel. Test L2 Loss :  0.08707636803388595  Test L2 Loss :  0.1592326730489731  inv_L_scale:  [1.0, 1.0]
Epoch :  7  Time:  0.893  Rel. Train L2 Loss :  0.07898473107152515  Rel. Test L2 Loss :  0.08163326412439346  Test L2 Loss :  0.14822894275188447  inv_L_scale:  [1.0, 1.0]
Epoch :  8  Time:  0.893  Rel. Train L2 Loss :  0.07565930823485056  Rel. Test L2 Loss :  0.07785672396421432  Test L2 Loss :  0.14220342874526978  inv_L_scale:  [1.0, 1.0]
Epoch :  9  Time:  0.894  Rel. Train L2 Loss :  0.07245916181140476  Rel. Test L2 Loss :  0.08245612293481827  Test L2 Loss :  0.1516754686832428  inv_L_scale:  [1.0, 1.0]
Epoch :  10  Time:  0.893  Rel. Train L2 Loss :  0.07358892109658983  Rel. Test L2 Loss :  0.0768292337656021  Test L2 Loss :  0.13896217942237854  inv_L_scale:  [1.0, 1.0]
Epoch :  11  Time:  0.892  Rel. Train L2 Loss :  0.0653176110320621  Rel. Test L2 Loss :  0.07216905295848847  Test L2 Loss :  0.13074022829532622  inv_L_scale:  [1.0, 1.0]
Epoch :  12  Time:  0.893  Rel. Train L2 Loss :  0.06853139794535107  Rel. Test L2 Loss :  0.0825270789861679  Test L2 Loss :  0.15334951639175415  inv_L_scale:  [1.0, 1.0]
Epoch :  13  Time:  0.894  Rel. Train L2 Loss :  0.06331301867961883  Rel. Test L2 Loss :  0.06696029677987099  Test L2 Loss :  0.12092948347330093  inv_L_scale:  [1.0, 1.0]
Epoch :  14  Time:  0.894  Rel. Train L2 Loss :  0.06083240201075872  Rel. Test L2 Loss :  0.06430906683206558  Test L2 Loss :  0.11564936637878417  inv_L_scale:  [1.0, 1.0]
Epoch :  15  Time:  0.893  Rel. Train L2 Loss :  0.061000985768106246  Rel. Test L2 Loss :  0.0661403863132  Test L2 Loss :  0.11796625494956971  inv_L_scale:  [1.0, 1.0]
Epoch :  16  Time:  0.893  Rel. Train L2 Loss :  0.06059492462211185  Rel. Test L2 Loss :  0.06180025979876518  Test L2 Loss :  0.1121827495098114  inv_L_scale:  [1.0, 1.0]
Epoch :  17  Time:  0.893  Rel. Train L2 Loss :  0.05778676966826121  Rel. Test L2 Loss :  0.06125327318906784  Test L2 Loss :  0.10970584154129029  inv_L_scale:  [1.0, 1.0]
Epoch :  18  Time:  0.893  Rel. Train L2 Loss :  0.05590377714898851  Rel. Test L2 Loss :  0.06630666762590408  Test L2 Loss :  0.11965214878320694  inv_L_scale:  [1.0, 1.0]
Epoch :  19  Time:  0.892  Rel. Train L2 Loss :  0.05880528363916609  Rel. Test L2 Loss :  0.06040217876434326  Test L2 Loss :  0.10739854991436004  inv_L_scale:  [1.0, 1.0]
Epoch :  20  Time:  0.893  Rel. Train L2 Loss :  0.05448802242676417  Rel. Test L2 Loss :  0.05819909647107124  Test L2 Loss :  0.10405477732419968  inv_L_scale:  [1.0, 1.0]
Epoch :  21  Time:  0.893  Rel. Train L2 Loss :  0.05521343115303252  Rel. Test L2 Loss :  0.05604469433426857  Test L2 Loss :  0.10048412591218948  inv_L_scale:  [1.0, 1.0]
Epoch :  22  Time:  0.892  Rel. Train L2 Loss :  0.05247356275717417  Rel. Test L2 Loss :  0.05561770081520081  Test L2 Loss :  0.0991330736875534  inv_L_scale:  [1.0, 1.0]
Epoch :  23  Time:  0.895  Rel. Train L2 Loss :  0.052439644535382586  Rel. Test L2 Loss :  0.0544496987760067  Test L2 Loss :  0.09907157957553864  inv_L_scale:  [1.0, 1.0]
Epoch :  24  Time:  0.893  Rel. Train L2 Loss :  0.05145622144142787  Rel. Test L2 Loss :  0.0592688350379467  Test L2 Loss :  0.10772373348474502  inv_L_scale:  [1.0, 1.0]
Epoch :  25  Time:  0.893  Rel. Train L2 Loss :  0.05118484243750572  Rel. Test L2 Loss :  0.05186856985092163  Test L2 Loss :  0.092927266061306  inv_L_scale:  [1.0, 1.0]
Epoch :  26  Time:  0.892  Rel. Train L2 Loss :  0.05185527357790205  Rel. Test L2 Loss :  0.05596654281020164  Test L2 Loss :  0.09875030994415283  inv_L_scale:  [1.0, 1.0]
Epoch :  27  Time:  0.895  Rel. Train L2 Loss :  0.05004290574126773  Rel. Test L2 Loss :  0.053982978612184526  Test L2 Loss :  0.09662387430667878  inv_L_scale:  [1.0, 1.0]
Epoch :  28  Time:  0.893  Rel. Train L2 Loss :  0.04847890618774626  Rel. Test L2 Loss :  0.052316384315490724  Test L2 Loss :  0.09437094330787658  inv_L_scale:  [1.0, 1.0]
Epoch :  29  Time:  0.893  Rel. Train L2 Loss :  0.04868640098306868  Rel. Test L2 Loss :  0.05449567645788193  Test L2 Loss :  0.09752437680959701  inv_L_scale:  [1.0, 1.0]
Epoch :  30  Time:  0.894  Rel. Train L2 Loss :  0.0482860543164942  Rel. Test L2 Loss :  0.05565794050693512  Test L2 Loss :  0.09911638915538788  inv_L_scale:  [1.0, 1.0]
Epoch :  31  Time:  0.893  Rel. Train L2 Loss :  0.04889439534809854  Rel. Test L2 Loss :  0.056775243878364565  Test L2 Loss :  0.10147988706827164  inv_L_scale:  [1.0, 1.0]
Epoch :  32  Time:  0.893  Rel. Train L2 Loss :  0.048531771136654744  Rel. Test L2 Loss :  0.054639178514480594  Test L2 Loss :  0.09762471944093704  inv_L_scale:  [1.0, 1.0]
Epoch :  33  Time:  0.893  Rel. Train L2 Loss :  0.048575274695952735  Rel. Test L2 Loss :  0.05643470734357834  Test L2 Loss :  0.10087965309619903  inv_L_scale:  [1.0, 1.0]
Epoch :  34  Time:  0.893  Rel. Train L2 Loss :  0.048062064995368324  Rel. Test L2 Loss :  0.0516534449160099  Test L2 Loss :  0.09196534425020218  inv_L_scale:  [1.0, 1.0]
Epoch :  35  Time:  0.893  Rel. Train L2 Loss :  0.04746549295054542  Rel. Test L2 Loss :  0.052689851224422456  Test L2 Loss :  0.09267836809158325  inv_L_scale:  [1.0, 1.0]
Epoch :  36  Time:  0.893  Rel. Train L2 Loss :  0.04550490806500117  Rel. Test L2 Loss :  0.046932864487171176  Test L2 Loss :  0.0829793456196785  inv_L_scale:  [1.0, 1.0]
Epoch :  37  Time:  0.894  Rel. Train L2 Loss :  0.04639099758532312  Rel. Test L2 Loss :  0.047828623056411744  Test L2 Loss :  0.08515026986598968  inv_L_scale:  [1.0, 1.0]
Epoch :  38  Time:  0.893  Rel. Train L2 Loss :  0.045087823768456776  Rel. Test L2 Loss :  0.05076219767332077  Test L2 Loss :  0.09061425507068634  inv_L_scale:  [1.0, 1.0]
Epoch :  39  Time:  0.893  Rel. Train L2 Loss :  0.04924083135194249  Rel. Test L2 Loss :  0.04680006951093674  Test L2 Loss :  0.08406248450279236  inv_L_scale:  [1.0, 1.0]
Epoch :  40  Time:  0.893  Rel. Train L2 Loss :  0.04586441084742546  Rel. Test L2 Loss :  0.049399315863847736  Test L2 Loss :  0.08957631468772888  inv_L_scale:  [1.0, 1.0]
Epoch :  41  Time:  0.895  Rel. Train L2 Loss :  0.045508220824930404  Rel. Test L2 Loss :  0.04840684175491333  Test L2 Loss :  0.08688368797302246  inv_L_scale:  [1.0, 1.0]
Epoch :  42  Time:  0.894  Rel. Train L2 Loss :  0.04504501692122883  Rel. Test L2 Loss :  0.04589994609355927  Test L2 Loss :  0.08109050661325455  inv_L_scale:  [1.0, 1.0]
Epoch :  43  Time:  0.893  Rel. Train L2 Loss :  0.04310719927151998  Rel. Test L2 Loss :  0.04390242740511894  Test L2 Loss :  0.07894190847873687  inv_L_scale:  [1.0, 1.0]
Epoch :  44  Time:  0.893  Rel. Train L2 Loss :  0.042567600574758314  Rel. Test L2 Loss :  0.047653771787881855  Test L2 Loss :  0.08475499451160431  inv_L_scale:  [1.0, 1.0]
Epoch :  45  Time:  0.893  Rel. Train L2 Loss :  0.041995090809133315  Rel. Test L2 Loss :  0.0491787001490593  Test L2 Loss :  0.0872328907251358  inv_L_scale:  [1.0, 1.0]
Epoch :  46  Time:  0.892  Rel. Train L2 Loss :  0.045683036115434436  Rel. Test L2 Loss :  0.049740680754184724  Test L2 Loss :  0.08959685027599334  inv_L_scale:  [1.0, 1.0]
Epoch :  47  Time:  0.892  Rel. Train L2 Loss :  0.04259491970141729  Rel. Test L2 Loss :  0.04440842688083649  Test L2 Loss :  0.07925831019878388  inv_L_scale:  [1.0, 1.0]
Epoch :  48  Time:  0.892  Rel. Train L2 Loss :  0.04298289881812201  Rel. Test L2 Loss :  0.043151740133762356  Test L2 Loss :  0.07647150665521622  inv_L_scale:  [1.0, 1.0]
Epoch :  49  Time:  0.894  Rel. Train L2 Loss :  0.041933518946170804  Rel. Test L2 Loss :  0.042053335905075075  Test L2 Loss :  0.07538877755403518  inv_L_scale:  [1.0, 1.0]
Epoch :  50  Time:  0.892  Rel. Train L2 Loss :  0.04000493897332086  Rel. Test L2 Loss :  0.04146403864026069  Test L2 Loss :  0.07402281671762466  inv_L_scale:  [1.0, 1.0]
Epoch :  51  Time:  0.893  Rel. Train L2 Loss :  0.040309657471047505  Rel. Test L2 Loss :  0.04603182762861252  Test L2 Loss :  0.0822726845741272  inv_L_scale:  [1.0, 1.0]
Epoch :  52  Time:  0.892  Rel. Train L2 Loss :  0.04359029392401377  Rel. Test L2 Loss :  0.044617845118045805  Test L2 Loss :  0.07945613026618957  inv_L_scale:  [1.0, 1.0]
Epoch :  53  Time:  0.892  Rel. Train L2 Loss :  0.03926515577567948  Rel. Test L2 Loss :  0.047922081649303436  Test L2 Loss :  0.08721341073513031  inv_L_scale:  [1.0, 1.0]
Epoch :  54  Time:  0.894  Rel. Train L2 Loss :  0.0415762992699941  Rel. Test L2 Loss :  0.04491789162158966  Test L2 Loss :  0.0805518400669098  inv_L_scale:  [1.0, 1.0]
Epoch :  55  Time:  0.893  Rel. Train L2 Loss :  0.040176441421111424  Rel. Test L2 Loss :  0.047254602611064914  Test L2 Loss :  0.08665441572666169  inv_L_scale:  [1.0, 1.0]
Epoch :  56  Time:  0.892  Rel. Train L2 Loss :  0.03926938494046529  Rel. Test L2 Loss :  0.04119713768362999  Test L2 Loss :  0.07352300226688385  inv_L_scale:  [1.0, 1.0]
Epoch :  57  Time:  0.893  Rel. Train L2 Loss :  0.03985253817505307  Rel. Test L2 Loss :  0.040562142729759214  Test L2 Loss :  0.07196245878934861  inv_L_scale:  [1.0, 1.0]
Epoch :  58  Time:  0.893  Rel. Train L2 Loss :  0.038555321792761485  Rel. Test L2 Loss :  0.03994084626436233  Test L2 Loss :  0.07147201240062713  inv_L_scale:  [1.0, 1.0]
Epoch :  59  Time:  0.895  Rel. Train L2 Loss :  0.03872248210840755  Rel. Test L2 Loss :  0.04258603170514107  Test L2 Loss :  0.07594323635101319  inv_L_scale:  [1.0, 1.0]
Epoch :  60  Time:  0.892  Rel. Train L2 Loss :  0.03971155090464486  Rel. Test L2 Loss :  0.0432144396007061  Test L2 Loss :  0.07717559218406678  inv_L_scale:  [1.0, 1.0]
Epoch :  61  Time:  0.893  Rel. Train L2 Loss :  0.0399897878865401  Rel. Test L2 Loss :  0.04494391292333603  Test L2 Loss :  0.08081494927406312  inv_L_scale:  [1.0, 1.0]
Epoch :  62  Time:  0.892  Rel. Train L2 Loss :  0.038470323003000684  Rel. Test L2 Loss :  0.037927252054214475  Test L2 Loss :  0.06743574768304825  inv_L_scale:  [1.0, 1.0]
Epoch :  63  Time:  0.893  Rel. Train L2 Loss :  0.03847633754213651  Rel. Test L2 Loss :  0.04446020007133484  Test L2 Loss :  0.08233719885349274  inv_L_scale:  [1.0, 1.0]
Epoch :  64  Time:  0.892  Rel. Train L2 Loss :  0.03748945116996765  Rel. Test L2 Loss :  0.039034513533115385  Test L2 Loss :  0.06970161080360412  inv_L_scale:  [1.0, 1.0]
Epoch :  65  Time:  0.892  Rel. Train L2 Loss :  0.036701221846871905  Rel. Test L2 Loss :  0.043405119180679325  Test L2 Loss :  0.07870731145143509  inv_L_scale:  [1.0, 1.0]
Epoch :  66  Time:  0.892  Rel. Train L2 Loss :  0.03655795633792877  Rel. Test L2 Loss :  0.038291246145963666  Test L2 Loss :  0.06815369099378586  inv_L_scale:  [1.0, 1.0]
Epoch :  67  Time:  0.893  Rel. Train L2 Loss :  0.03743500587013033  Rel. Test L2 Loss :  0.04723073869943619  Test L2 Loss :  0.0850540840625763  inv_L_scale:  [1.0, 1.0]
Epoch :  68  Time:  0.892  Rel. Train L2 Loss :  0.03673915336529414  Rel. Test L2 Loss :  0.03691342182457447  Test L2 Loss :  0.06601662233471871  inv_L_scale:  [1.0, 1.0]
Epoch :  69  Time:  0.894  Rel. Train L2 Loss :  0.03723582617110676  Rel. Test L2 Loss :  0.03760840997099876  Test L2 Loss :  0.06825014680624009  inv_L_scale:  [1.0, 1.0]
Epoch :  70  Time:  0.893  Rel. Train L2 Loss :  0.033919485360383986  Rel. Test L2 Loss :  0.04275699481368065  Test L2 Loss :  0.0778654932975769  inv_L_scale:  [1.0, 1.0]
Epoch :  71  Time:  0.894  Rel. Train L2 Loss :  0.035717352165116206  Rel. Test L2 Loss :  0.034986413270235064  Test L2 Loss :  0.06268967747688294  inv_L_scale:  [1.0, 1.0]
Epoch :  72  Time:  0.892  Rel. Train L2 Loss :  0.03534406135479609  Rel. Test L2 Loss :  0.03834786266088486  Test L2 Loss :  0.0682633399963379  inv_L_scale:  [1.0, 1.0]
Epoch :  73  Time:  0.894  Rel. Train L2 Loss :  0.034605503198173314  Rel. Test L2 Loss :  0.03473116010427475  Test L2 Loss :  0.06311631590127945  inv_L_scale:  [1.0, 1.0]
Epoch :  74  Time:  0.893  Rel. Train L2 Loss :  0.03433494028117921  Rel. Test L2 Loss :  0.035219611898064614  Test L2 Loss :  0.062473444044589994  inv_L_scale:  [1.0, 1.0]
Epoch :  75  Time:  0.893  Rel. Train L2 Loss :  0.034423184014028975  Rel. Test L2 Loss :  0.03571772783994675  Test L2 Loss :  0.06402530699968338  inv_L_scale:  [1.0, 1.0]
Epoch :  76  Time:  0.892  Rel. Train L2 Loss :  0.034547133710649276  Rel. Test L2 Loss :  0.03299040272831917  Test L2 Loss :  0.058354003131389616  inv_L_scale:  [1.0, 1.0]
Epoch :  77  Time:  0.893  Rel. Train L2 Loss :  0.032668521362874244  Rel. Test L2 Loss :  0.03582733616232872  Test L2 Loss :  0.06358110025525093  inv_L_scale:  [1.0, 1.0]
Epoch :  78  Time:  0.892  Rel. Train L2 Loss :  0.03355650156736374  Rel. Test L2 Loss :  0.048181740939617156  Test L2 Loss :  0.08975171983242035  inv_L_scale:  [1.0, 1.0]
Epoch :  79  Time:  0.892  Rel. Train L2 Loss :  0.03493842420478662  Rel. Test L2 Loss :  0.036772389411926266  Test L2 Loss :  0.06534394562244415  inv_L_scale:  [1.0, 1.0]
Epoch :  80  Time:  0.892  Rel. Train L2 Loss :  0.032641769796609876  Rel. Test L2 Loss :  0.032987537980079654  Test L2 Loss :  0.05829320728778839  inv_L_scale:  [1.0, 1.0]
Epoch :  81  Time:  0.895  Rel. Train L2 Loss :  0.032888648874229855  Rel. Test L2 Loss :  0.041792386174201966  Test L2 Loss :  0.07592201679944992  inv_L_scale:  [1.0, 1.0]
Epoch :  82  Time:  0.893  Rel. Train L2 Loss :  0.03362423535850313  Rel. Test L2 Loss :  0.034399089515209196  Test L2 Loss :  0.061390438079833985  inv_L_scale:  [1.0, 1.0]
Epoch :  83  Time:  0.893  Rel. Train L2 Loss :  0.032633093198140464  Rel. Test L2 Loss :  0.04093915775418282  Test L2 Loss :  0.07334316819906235  inv_L_scale:  [1.0, 1.0]
Epoch :  84  Time:  0.893  Rel. Train L2 Loss :  0.031883358160654705  Rel. Test L2 Loss :  0.03345349282026291  Test L2 Loss :  0.0605803644657135  inv_L_scale:  [1.0, 1.0]
Epoch :  85  Time:  0.892  Rel. Train L2 Loss :  0.03173690742916531  Rel. Test L2 Loss :  0.04100992858409882  Test L2 Loss :  0.07452059328556061  inv_L_scale:  [1.0, 1.0]
Epoch :  86  Time:  0.892  Rel. Train L2 Loss :  0.032263125711017186  Rel. Test L2 Loss :  0.037992004752159116  Test L2 Loss :  0.06920332342386246  inv_L_scale:  [1.0, 1.0]
Epoch :  87  Time:  0.894  Rel. Train L2 Loss :  0.03200072387854258  Rel. Test L2 Loss :  0.03394008561968803  Test L2 Loss :  0.06038754343986511  inv_L_scale:  [1.0, 1.0]
Epoch :  88  Time:  0.893  Rel. Train L2 Loss :  0.03176358942356375  Rel. Test L2 Loss :  0.03511109344661236  Test L2 Loss :  0.06305718213319779  inv_L_scale:  [1.0, 1.0]
Epoch :  89  Time:  0.893  Rel. Train L2 Loss :  0.031039021114508313  Rel. Test L2 Loss :  0.03390567660331726  Test L2 Loss :  0.060790762305259705  inv_L_scale:  [1.0, 1.0]
Epoch :  90  Time:  0.892  Rel. Train L2 Loss :  0.03113437068131235  Rel. Test L2 Loss :  0.03415160894393921  Test L2 Loss :  0.0602472585439682  inv_L_scale:  [1.0, 1.0]
Epoch :  91  Time:  0.892  Rel. Train L2 Loss :  0.03195012690292465  Rel. Test L2 Loss :  0.03340325564146042  Test L2 Loss :  0.05927896589040756  inv_L_scale:  [1.0, 1.0]
Epoch :  92  Time:  0.893  Rel. Train L2 Loss :  0.030319866687059403  Rel. Test L2 Loss :  0.03680722646415233  Test L2 Loss :  0.06663333743810654  inv_L_scale:  [1.0, 1.0]
Epoch :  93  Time:  0.893  Rel. Train L2 Loss :  0.030561778280470107  Rel. Test L2 Loss :  0.032750030383467674  Test L2 Loss :  0.058904502689838406  inv_L_scale:  [1.0, 1.0]
Epoch :  94  Time:  0.892  Rel. Train L2 Loss :  0.030651333034038542  Rel. Test L2 Loss :  0.03248301491141319  Test L2 Loss :  0.057623887062072755  inv_L_scale:  [1.0, 1.0]
Epoch :  95  Time:  0.892  Rel. Train L2 Loss :  0.031505145422286454  Rel. Test L2 Loss :  0.03078730881214142  Test L2 Loss :  0.05514394551515579  inv_L_scale:  [1.0, 1.0]
Epoch :  96  Time:  0.893  Rel. Train L2 Loss :  0.02887280156215032  Rel. Test L2 Loss :  0.03430260054767132  Test L2 Loss :  0.06053238123655319  inv_L_scale:  [1.0, 1.0]
Epoch :  97  Time:  0.893  Rel. Train L2 Loss :  0.02992226105597284  Rel. Test L2 Loss :  0.038496302515268324  Test L2 Loss :  0.06910309821367264  inv_L_scale:  [1.0, 1.0]
Epoch :  98  Time:  0.892  Rel. Train L2 Loss :  0.029860095994340047  Rel. Test L2 Loss :  0.034947802647948265  Test L2 Loss :  0.06331639468669892  inv_L_scale:  [1.0, 1.0]
Epoch :  99  Time:  0.894  Rel. Train L2 Loss :  0.02896889675822523  Rel. Test L2 Loss :  0.032129742205142975  Test L2 Loss :  0.05787045255303383  inv_L_scale:  [1.0, 1.0]
Epoch :  100  Time:  0.892  Rel. Train L2 Loss :  0.029868998693095315  Rel. Test L2 Loss :  0.032738059759140015  Test L2 Loss :  0.05739565640687942  inv_L_scale:  [1.0, 1.0]
Epoch :  101  Time:  0.893  Rel. Train L2 Loss :  0.029886706355545255  Rel. Test L2 Loss :  0.028769595250487327  Test L2 Loss :  0.05157355308532715  inv_L_scale:  [1.0, 1.0]
Epoch :  102  Time:  0.892  Rel. Train L2 Loss :  0.02922513970070415  Rel. Test L2 Loss :  0.03321203857660294  Test L2 Loss :  0.05980466514825821  inv_L_scale:  [1.0, 1.0]
Epoch :  103  Time:  0.893  Rel. Train L2 Loss :  0.02823254432943132  Rel. Test L2 Loss :  0.028733848109841347  Test L2 Loss :  0.051179369688034056  inv_L_scale:  [1.0, 1.0]
Epoch :  104  Time:  0.891  Rel. Train L2 Loss :  0.0281332431650824  Rel. Test L2 Loss :  0.030298350900411605  Test L2 Loss :  0.053949889242649075  inv_L_scale:  [1.0, 1.0]
Epoch :  105  Time:  0.895  Rel. Train L2 Loss :  0.02771662823855877  Rel. Test L2 Loss :  0.0279020830988884  Test L2 Loss :  0.049973602890968326  inv_L_scale:  [1.0, 1.0]
Epoch :  106  Time:  0.892  Rel. Train L2 Loss :  0.028554850154452853  Rel. Test L2 Loss :  0.028785971254110337  Test L2 Loss :  0.050898415744304655  inv_L_scale:  [1.0, 1.0]
Epoch :  107  Time:  0.892  Rel. Train L2 Loss :  0.028299148198631073  Rel. Test L2 Loss :  0.02895466223359108  Test L2 Loss :  0.051503241658210755  inv_L_scale:  [1.0, 1.0]
Epoch :  108  Time:  0.893  Rel. Train L2 Loss :  0.027419932898547914  Rel. Test L2 Loss :  0.02914080984890461  Test L2 Loss :  0.05180942684412002  inv_L_scale:  [1.0, 1.0]
Epoch :  109  Time:  0.893  Rel. Train L2 Loss :  0.02685723986890581  Rel. Test L2 Loss :  0.034040882661938665  Test L2 Loss :  0.0612542399764061  inv_L_scale:  [1.0, 1.0]
Epoch :  110  Time:  0.893  Rel. Train L2 Loss :  0.0273320572078228  Rel. Test L2 Loss :  0.028939974755048753  Test L2 Loss :  0.05178938448429107  inv_L_scale:  [1.0, 1.0]
Epoch :  111  Time:  0.892  Rel. Train L2 Loss :  0.027457321162025133  Rel. Test L2 Loss :  0.03668469324707985  Test L2 Loss :  0.06689425617456436  inv_L_scale:  [1.0, 1.0]
Epoch :  112  Time:  0.892  Rel. Train L2 Loss :  0.02756257411506441  Rel. Test L2 Loss :  0.029424604177474976  Test L2 Loss :  0.052688895165920256  inv_L_scale:  [1.0, 1.0]
Epoch :  113  Time:  0.894  Rel. Train L2 Loss :  0.027339399672216838  Rel. Test L2 Loss :  0.02714903935790062  Test L2 Loss :  0.048267879486083985  inv_L_scale:  [1.0, 1.0]
Epoch :  114  Time:  0.893  Rel. Train L2 Loss :  0.026929100478688874  Rel. Test L2 Loss :  0.030387784987688064  Test L2 Loss :  0.05397491902112961  inv_L_scale:  [1.0, 1.0]
Epoch :  115  Time:  0.893  Rel. Train L2 Loss :  0.026932476941082212  Rel. Test L2 Loss :  0.027387657165527345  Test L2 Loss :  0.04889029175043106  inv_L_scale:  [1.0, 1.0]
Epoch :  116  Time:  0.893  Rel. Train L2 Loss :  0.026430024355649947  Rel. Test L2 Loss :  0.02981021247804165  Test L2 Loss :  0.05371575638651848  inv_L_scale:  [1.0, 1.0]
Epoch :  117  Time:  0.892  Rel. Train L2 Loss :  0.026595404065317577  Rel. Test L2 Loss :  0.026600984781980516  Test L2 Loss :  0.04681649565696716  inv_L_scale:  [1.0, 1.0]
Epoch :  118  Time:  0.893  Rel. Train L2 Loss :  0.02599804235001405  Rel. Test L2 Loss :  0.029107000082731246  Test L2 Loss :  0.051916826665401455  inv_L_scale:  [1.0, 1.0]
Epoch :  119  Time:  0.893  Rel. Train L2 Loss :  0.02669234636757109  Rel. Test L2 Loss :  0.034805047065019606  Test L2 Loss :  0.06410230189561844  inv_L_scale:  [1.0, 1.0]
Epoch :  120  Time:  0.893  Rel. Train L2 Loss :  0.027222349966565768  Rel. Test L2 Loss :  0.03164555057883263  Test L2 Loss :  0.05689711794257164  inv_L_scale:  [1.0, 1.0]
Epoch :  121  Time:  0.892  Rel. Train L2 Loss :  0.027418449322382608  Rel. Test L2 Loss :  0.026865674406290053  Test L2 Loss :  0.047774335741996764  inv_L_scale:  [1.0, 1.0]
Epoch :  122  Time:  0.893  Rel. Train L2 Loss :  0.025545114502310753  Rel. Test L2 Loss :  0.027665743604302406  Test L2 Loss :  0.049187460839748384  inv_L_scale:  [1.0, 1.0]
Epoch :  123  Time:  0.894  Rel. Train L2 Loss :  0.0264456524203221  Rel. Test L2 Loss :  0.027783185094594955  Test L2 Loss :  0.04898040786385536  inv_L_scale:  [1.0, 1.0]
Epoch :  124  Time:  0.892  Rel. Train L2 Loss :  0.026528106729189555  Rel. Test L2 Loss :  0.026722858995199203  Test L2 Loss :  0.04705886363983154  inv_L_scale:  [1.0, 1.0]
Epoch :  125  Time:  0.893  Rel. Train L2 Loss :  0.025341474066178003  Rel. Test L2 Loss :  0.02823602646589279  Test L2 Loss :  0.050643292665481565  inv_L_scale:  [1.0, 1.0]
Epoch :  126  Time:  0.893  Rel. Train L2 Loss :  0.026419426633252037  Rel. Test L2 Loss :  0.027269278019666672  Test L2 Loss :  0.048347634226083756  inv_L_scale:  [1.0, 1.0]
Epoch :  127  Time:  0.893  Rel. Train L2 Loss :  0.02641481402847502  Rel. Test L2 Loss :  0.0299285364151001  Test L2 Loss :  0.05326884627342224  inv_L_scale:  [1.0, 1.0]
Epoch :  128  Time:  0.893  Rel. Train L2 Loss :  0.025976037101613152  Rel. Test L2 Loss :  0.030284453257918356  Test L2 Loss :  0.05339174851775169  inv_L_scale:  [1.0, 1.0]
Epoch :  129  Time:  0.893  Rel. Train L2 Loss :  0.026055223080846998  Rel. Test L2 Loss :  0.028900172635912894  Test L2 Loss :  0.053117367625236514  inv_L_scale:  [1.0, 1.0]
Epoch :  130  Time:  0.892  Rel. Train L2 Loss :  0.025588852829403347  Rel. Test L2 Loss :  0.029472346901893615  Test L2 Loss :  0.0530830118060112  inv_L_scale:  [1.0, 1.0]
Epoch :  131  Time:  0.893  Rel. Train L2 Loss :  0.02491871376832326  Rel. Test L2 Loss :  0.03066943570971489  Test L2 Loss :  0.05467631354928017  inv_L_scale:  [1.0, 1.0]
Epoch :  132  Time:  0.892  Rel. Train L2 Loss :  0.025358218078811962  Rel. Test L2 Loss :  0.028470879793167113  Test L2 Loss :  0.050938018709421155  inv_L_scale:  [1.0, 1.0]
Epoch :  133  Time:  0.892  Rel. Train L2 Loss :  0.024923147302534844  Rel. Test L2 Loss :  0.024319989681243895  Test L2 Loss :  0.04309078231453896  inv_L_scale:  [1.0, 1.0]
Epoch :  134  Time:  0.893  Rel. Train L2 Loss :  0.025083572996987238  Rel. Test L2 Loss :  0.027463714703917504  Test L2 Loss :  0.04853796362876892  inv_L_scale:  [1.0, 1.0]
Epoch :  135  Time:  0.893  Rel. Train L2 Loss :  0.024915980158580674  Rel. Test L2 Loss :  0.024586575180292128  Test L2 Loss :  0.043653405457735064  inv_L_scale:  [1.0, 1.0]
Epoch :  136  Time:  0.895  Rel. Train L2 Loss :  0.024796143049995105  Rel. Test L2 Loss :  0.026478366255760194  Test L2 Loss :  0.046773476898670195  inv_L_scale:  [1.0, 1.0]
Epoch :  137  Time:  0.893  Rel. Train L2 Loss :  0.024434748672776754  Rel. Test L2 Loss :  0.025237732604146003  Test L2 Loss :  0.04451287686824799  inv_L_scale:  [1.0, 1.0]
Epoch :  138  Time:  0.892  Rel. Train L2 Loss :  0.02571973141696718  Rel. Test L2 Loss :  0.027675786241889  Test L2 Loss :  0.04958067685365677  inv_L_scale:  [1.0, 1.0]
Epoch :  139  Time:  0.892  Rel. Train L2 Loss :  0.02602254374159707  Rel. Test L2 Loss :  0.03445788212120533  Test L2 Loss :  0.06337672188878059  inv_L_scale:  [1.0, 1.0]
Epoch :  140  Time:  0.892  Rel. Train L2 Loss :  0.025429082297616534  Rel. Test L2 Loss :  0.02480904132127762  Test L2 Loss :  0.04407575368881225  inv_L_scale:  [1.0, 1.0]
Epoch :  141  Time:  0.892  Rel. Train L2 Loss :  0.025485926700962915  Rel. Test L2 Loss :  0.02522965580224991  Test L2 Loss :  0.04459322452545166  inv_L_scale:  [1.0, 1.0]
Epoch :  142  Time:  0.891  Rel. Train L2 Loss :  0.025238308956225714  Rel. Test L2 Loss :  0.027113792225718497  Test L2 Loss :  0.048390507996082306  inv_L_scale:  [1.0, 1.0]
Epoch :  143  Time:  0.891  Rel. Train L2 Loss :  0.02410946192840735  Rel. Test L2 Loss :  0.02592331565916538  Test L2 Loss :  0.04564961791038513  inv_L_scale:  [1.0, 1.0]
Epoch :  144  Time:  0.892  Rel. Train L2 Loss :  0.024280853445331256  Rel. Test L2 Loss :  0.02531980201601982  Test L2 Loss :  0.04488626852631569  inv_L_scale:  [1.0, 1.0]
Epoch :  145  Time:  0.892  Rel. Train L2 Loss :  0.024500241320994164  Rel. Test L2 Loss :  0.027714619114995002  Test L2 Loss :  0.04959751382470131  inv_L_scale:  [1.0, 1.0]
Epoch :  146  Time:  0.891  Rel. Train L2 Loss :  0.023312054442034828  Rel. Test L2 Loss :  0.02527579292654991  Test L2 Loss :  0.04491187989711762  inv_L_scale:  [1.0, 1.0]
Epoch :  147  Time:  0.891  Rel. Train L2 Loss :  0.02331781072749032  Rel. Test L2 Loss :  0.02418541818857193  Test L2 Loss :  0.04275321468710899  inv_L_scale:  [1.0, 1.0]
Epoch :  148  Time:  0.892  Rel. Train L2 Loss :  0.024040598024924597  Rel. Test L2 Loss :  0.02485335409641266  Test L2 Loss :  0.044192897975444796  inv_L_scale:  [1.0, 1.0]
Epoch :  149  Time:  0.892  Rel. Train L2 Loss :  0.02370143834915426  Rel. Test L2 Loss :  0.025602124631404877  Test L2 Loss :  0.0455996310710907  inv_L_scale:  [1.0, 1.0]
Epoch :  150  Time:  0.891  Rel. Train L2 Loss :  0.02325271665222115  Rel. Test L2 Loss :  0.026168708354234696  Test L2 Loss :  0.0468320569396019  inv_L_scale:  [1.0, 1.0]
Epoch :  151  Time:  0.891  Rel. Train L2 Loss :  0.023251751611630123  Rel. Test L2 Loss :  0.024576746970415116  Test L2 Loss :  0.04354279756546021  inv_L_scale:  [1.0, 1.0]
Epoch :  152  Time:  0.892  Rel. Train L2 Loss :  0.02403784318930573  Rel. Test L2 Loss :  0.0253119595348835  Test L2 Loss :  0.044626170843839644  inv_L_scale:  [1.0, 1.0]
Epoch :  153  Time:  0.892  Rel. Train L2 Loss :  0.023755141132407717  Rel. Test L2 Loss :  0.022938342243433  Test L2 Loss :  0.04079244911670685  inv_L_scale:  [1.0, 1.0]
Epoch :  154  Time:  0.891  Rel. Train L2 Loss :  0.023710489372412363  Rel. Test L2 Loss :  0.0221202090382576  Test L2 Loss :  0.03923199102282524  inv_L_scale:  [1.0, 1.0]
Epoch :  155  Time:  0.892  Rel. Train L2 Loss :  0.023880853396322992  Rel. Test L2 Loss :  0.023691948354244232  Test L2 Loss :  0.04217400819063186  inv_L_scale:  [1.0, 1.0]
Epoch :  156  Time:  0.891  Rel. Train L2 Loss :  0.023221797595421475  Rel. Test L2 Loss :  0.025604335218667985  Test L2 Loss :  0.04556106001138687  inv_L_scale:  [1.0, 1.0]
Epoch :  157  Time:  0.891  Rel. Train L2 Loss :  0.022768721216254763  Rel. Test L2 Loss :  0.02418290413916111  Test L2 Loss :  0.042838763147592544  inv_L_scale:  [1.0, 1.0]
Epoch :  158  Time:  0.891  Rel. Train L2 Loss :  0.022863141944011053  Rel. Test L2 Loss :  0.023397654071450235  Test L2 Loss :  0.04168805092573166  inv_L_scale:  [1.0, 1.0]
Epoch :  159  Time:  0.891  Rel. Train L2 Loss :  0.022465788573026658  Rel. Test L2 Loss :  0.02338387705385685  Test L2 Loss :  0.0412490251660347  inv_L_scale:  [1.0, 1.0]
Epoch :  160  Time:  0.89  Rel. Train L2 Loss :  0.022424977504544787  Rel. Test L2 Loss :  0.023083164989948272  Test L2 Loss :  0.04125893980264664  inv_L_scale:  [1.0, 1.0]
Epoch :  161  Time:  0.891  Rel. Train L2 Loss :  0.022275662674672073  Rel. Test L2 Loss :  0.024929289743304252  Test L2 Loss :  0.044453624337911606  inv_L_scale:  [1.0, 1.0]
Epoch :  162  Time:  0.893  Rel. Train L2 Loss :  0.02197616246011522  Rel. Test L2 Loss :  0.023964155465364456  Test L2 Loss :  0.04224513798952103  inv_L_scale:  [1.0, 1.0]
Epoch :  163  Time:  0.891  Rel. Train L2 Loss :  0.024021046037475267  Rel. Test L2 Loss :  0.026041385382413865  Test L2 Loss :  0.04676969200372696  inv_L_scale:  [1.0, 1.0]
Epoch :  164  Time:  0.891  Rel. Train L2 Loss :  0.02340435903933313  Rel. Test L2 Loss :  0.023344153463840486  Test L2 Loss :  0.041640696227550504  inv_L_scale:  [1.0, 1.0]
Epoch :  165  Time:  0.892  Rel. Train L2 Loss :  0.02250304461353355  Rel. Test L2 Loss :  0.023224486261606215  Test L2 Loss :  0.040923239290714265  inv_L_scale:  [1.0, 1.0]
Epoch :  166  Time:  0.891  Rel. Train L2 Loss :  0.023021116861038738  Rel. Test L2 Loss :  0.023065157309174536  Test L2 Loss :  0.04094623386859894  inv_L_scale:  [1.0, 1.0]
Epoch :  167  Time:  0.891  Rel. Train L2 Loss :  0.022455673722757235  Rel. Test L2 Loss :  0.02218311995267868  Test L2 Loss :  0.03910241588950157  inv_L_scale:  [1.0, 1.0]
Epoch :  168  Time:  0.891  Rel. Train L2 Loss :  0.022016367448700797  Rel. Test L2 Loss :  0.02538422405719757  Test L2 Loss :  0.04550910085439682  inv_L_scale:  [1.0, 1.0]
Epoch :  169  Time:  0.89  Rel. Train L2 Loss :  0.022229416759477722  Rel. Test L2 Loss :  0.022907771691679953  Test L2 Loss :  0.040725598931312564  inv_L_scale:  [1.0, 1.0]
Epoch :  170  Time:  0.891  Rel. Train L2 Loss :  0.0227692601746983  Rel. Test L2 Loss :  0.02348166152834892  Test L2 Loss :  0.041658586114645006  inv_L_scale:  [1.0, 1.0]
Epoch :  171  Time:  0.893  Rel. Train L2 Loss :  0.023204501618941626  Rel. Test L2 Loss :  0.025700893625617026  Test L2 Loss :  0.04694421753287315  inv_L_scale:  [1.0, 1.0]
Epoch :  172  Time:  0.893  Rel. Train L2 Loss :  0.024236928671598434  Rel. Test L2 Loss :  0.024397016763687135  Test L2 Loss :  0.04327958583831787  inv_L_scale:  [1.0, 1.0]
Epoch :  173  Time:  0.891  Rel. Train L2 Loss :  0.023853769252697627  Rel. Test L2 Loss :  0.027960249930620195  Test L2 Loss :  0.050145556777715684  inv_L_scale:  [1.0, 1.0]
Epoch :  174  Time:  0.891  Rel. Train L2 Loss :  0.02322226411766476  Rel. Test L2 Loss :  0.024236960411071776  Test L2 Loss :  0.04300842076539993  inv_L_scale:  [1.0, 1.0]
Epoch :  175  Time:  0.892  Rel. Train L2 Loss :  0.023066535227828557  Rel. Test L2 Loss :  0.02722107470035553  Test L2 Loss :  0.04836180806159973  inv_L_scale:  [1.0, 1.0]
Epoch :  176  Time:  0.89  Rel. Train L2 Loss :  0.0227150761998362  Rel. Test L2 Loss :  0.023964466974139214  Test L2 Loss :  0.04263034924864769  inv_L_scale:  [1.0, 1.0]
Epoch :  177  Time:  0.891  Rel. Train L2 Loss :  0.02205058455467224  Rel. Test L2 Loss :  0.026375500783324242  Test L2 Loss :  0.04735098704695702  inv_L_scale:  [1.0, 1.0]
Epoch :  178  Time:  0.891  Rel. Train L2 Loss :  0.022685538108150164  Rel. Test L2 Loss :  0.026130966544151306  Test L2 Loss :  0.047065485715866086  inv_L_scale:  [1.0, 1.0]
Epoch :  179  Time:  0.891  Rel. Train L2 Loss :  0.022247397742337652  Rel. Test L2 Loss :  0.021795192658901216  Test L2 Loss :  0.03848273575305939  inv_L_scale:  [1.0, 1.0]
Epoch :  180  Time:  0.891  Rel. Train L2 Loss :  0.021793732659684286  Rel. Test L2 Loss :  0.022764393165707587  Test L2 Loss :  0.04050156652927399  inv_L_scale:  [1.0, 1.0]
Epoch :  181  Time:  0.892  Rel. Train L2 Loss :  0.02153028847442733  Rel. Test L2 Loss :  0.027739000990986824  Test L2 Loss :  0.050832786560058595  inv_L_scale:  [1.0, 1.0]
Epoch :  182  Time:  0.891  Rel. Train L2 Loss :  0.02213114679273632  Rel. Test L2 Loss :  0.0257486791908741  Test L2 Loss :  0.046091072261333466  inv_L_scale:  [1.0, 1.0]
Epoch :  183  Time:  0.891  Rel. Train L2 Loss :  0.02201956173612012  Rel. Test L2 Loss :  0.02563840314745903  Test L2 Loss :  0.04653361737728119  inv_L_scale:  [1.0, 1.0]
Epoch :  184  Time:  0.891  Rel. Train L2 Loss :  0.021650329960717096  Rel. Test L2 Loss :  0.0217670813202858  Test L2 Loss :  0.0385069465637207  inv_L_scale:  [1.0, 1.0]
Epoch :  185  Time:  0.891  Rel. Train L2 Loss :  0.021388895023200245  Rel. Test L2 Loss :  0.02210540197789669  Test L2 Loss :  0.03947429120540619  inv_L_scale:  [1.0, 1.0]
Epoch :  186  Time:  0.89  Rel. Train L2 Loss :  0.02153497198389636  Rel. Test L2 Loss :  0.024218390882015228  Test L2 Loss :  0.043668555915355685  inv_L_scale:  [1.0, 1.0]
Epoch :  187  Time:  0.892  Rel. Train L2 Loss :  0.02192892709126075  Rel. Test L2 Loss :  0.022319028377532957  Test L2 Loss :  0.03954815611243248  inv_L_scale:  [1.0, 1.0]
Epoch :  188  Time:  0.892  Rel. Train L2 Loss :  0.020840019360184668  Rel. Test L2 Loss :  0.020872223749756814  Test L2 Loss :  0.03715881958603859  inv_L_scale:  [1.0, 1.0]
Epoch :  189  Time:  0.891  Rel. Train L2 Loss :  0.020678352754977015  Rel. Test L2 Loss :  0.02351555719971657  Test L2 Loss :  0.042372449338436126  inv_L_scale:  [1.0, 1.0]
Epoch :  190  Time:  0.891  Rel. Train L2 Loss :  0.02184401760498683  Rel. Test L2 Loss :  0.02209810309112072  Test L2 Loss :  0.03916799411177635  inv_L_scale:  [1.0, 1.0]
Epoch :  191  Time:  0.892  Rel. Train L2 Loss :  0.021220691750446954  Rel. Test L2 Loss :  0.021569521725177766  Test L2 Loss :  0.0383000460267067  inv_L_scale:  [1.0, 1.0]
Epoch :  192  Time:  0.892  Rel. Train L2 Loss :  0.021031111197339164  Rel. Test L2 Loss :  0.02583067037165165  Test L2 Loss :  0.04695875719189644  inv_L_scale:  [1.0, 1.0]
Epoch :  193  Time:  0.892  Rel. Train L2 Loss :  0.020927654951810835  Rel. Test L2 Loss :  0.023521038070321083  Test L2 Loss :  0.04173392742872238  inv_L_scale:  [1.0, 1.0]
Epoch :  194  Time:  0.891  Rel. Train L2 Loss :  0.022327637349565825  Rel. Test L2 Loss :  0.024954150691628457  Test L2 Loss :  0.04444478139281273  inv_L_scale:  [1.0, 1.0]
Epoch :  195  Time:  0.891  Rel. Train L2 Loss :  0.021530868899491098  Rel. Test L2 Loss :  0.02285842791199684  Test L2 Loss :  0.040723535269498824  inv_L_scale:  [1.0, 1.0]
Epoch :  196  Time:  0.891  Rel. Train L2 Loss :  0.021130125514335102  Rel. Test L2 Loss :  0.022105364948511123  Test L2 Loss :  0.03914023280143738  inv_L_scale:  [1.0, 1.0]
Epoch :  197  Time:  0.892  Rel. Train L2 Loss :  0.021204510008295378  Rel. Test L2 Loss :  0.024901548698544503  Test L2 Loss :  0.04425140768289566  inv_L_scale:  [1.0, 1.0]
Epoch :  198  Time:  0.89  Rel. Train L2 Loss :  0.022152401018473836  Rel. Test L2 Loss :  0.021801778748631477  Test L2 Loss :  0.03877815917134285  inv_L_scale:  [1.0, 1.0]
Epoch :  199  Time:  0.891  Rel. Train L2 Loss :  0.021254448468486467  Rel. Test L2 Loss :  0.02245283991098404  Test L2 Loss :  0.03984847664833069  inv_L_scale:  [1.0, 1.0]
Epoch :  200  Time:  0.893  Rel. Train L2 Loss :  0.02096181169980102  Rel. Test L2 Loss :  0.02141518086194992  Test L2 Loss :  0.03825617536902428  inv_L_scale:  [1.0, 1.0]
Epoch :  201  Time:  0.892  Rel. Train L2 Loss :  0.021225207034084533  Rel. Test L2 Loss :  0.02100317746400833  Test L2 Loss :  0.03712883055210114  inv_L_scale:  [1.0, 1.0]
Epoch :  202  Time:  0.891  Rel. Train L2 Loss :  0.020607093820969265  Rel. Test L2 Loss :  0.022579211443662643  Test L2 Loss :  0.03986211165785789  inv_L_scale:  [1.0, 1.0]
Epoch :  203  Time:  0.891  Rel. Train L2 Loss :  0.021354081937008433  Rel. Test L2 Loss :  0.026889528259634973  Test L2 Loss :  0.04820334315299988  inv_L_scale:  [1.0, 1.0]
Epoch :  204  Time:  0.891  Rel. Train L2 Loss :  0.021703783149520556  Rel. Test L2 Loss :  0.028261422365903854  Test L2 Loss :  0.05189132139086723  inv_L_scale:  [1.0, 1.0]
Epoch :  205  Time:  0.892  Rel. Train L2 Loss :  0.020990318631132442  Rel. Test L2 Loss :  0.02111824758350849  Test L2 Loss :  0.03733373314142227  inv_L_scale:  [1.0, 1.0]
Epoch :  206  Time:  0.891  Rel. Train L2 Loss :  0.020398875698447227  Rel. Test L2 Loss :  0.023151570707559587  Test L2 Loss :  0.04213743656873703  inv_L_scale:  [1.0, 1.0]
Epoch :  207  Time:  0.891  Rel. Train L2 Loss :  0.02061699425180753  Rel. Test L2 Loss :  0.021108728274703024  Test L2 Loss :  0.03733369037508964  inv_L_scale:  [1.0, 1.0]
Epoch :  208  Time:  0.891  Rel. Train L2 Loss :  0.019843641395370166  Rel. Test L2 Loss :  0.020398193821310997  Test L2 Loss :  0.03606662318110466  inv_L_scale:  [1.0, 1.0]
Epoch :  209  Time:  0.891  Rel. Train L2 Loss :  0.02062078341841698  Rel. Test L2 Loss :  0.02329602889716625  Test L2 Loss :  0.0420769077539444  inv_L_scale:  [1.0, 1.0]
Epoch :  210  Time:  0.891  Rel. Train L2 Loss :  0.02043531753950649  Rel. Test L2 Loss :  0.02052673704922199  Test L2 Loss :  0.03624938666820526  inv_L_scale:  [1.0, 1.0]
Epoch :  211  Time:  0.892  Rel. Train L2 Loss :  0.01989071140686671  Rel. Test L2 Loss :  0.022695289850234987  Test L2 Loss :  0.04084085196256638  inv_L_scale:  [1.0, 1.0]
Epoch :  212  Time:  0.892  Rel. Train L2 Loss :  0.01925805317858855  Rel. Test L2 Loss :  0.01965162567794323  Test L2 Loss :  0.03516437977552414  inv_L_scale:  [1.0, 1.0]
Epoch :  213  Time:  0.892  Rel. Train L2 Loss :  0.019864757905403773  Rel. Test L2 Loss :  0.02158413454890251  Test L2 Loss :  0.03838426649570465  inv_L_scale:  [1.0, 1.0]
Epoch :  214  Time:  0.892  Rel. Train L2 Loss :  0.019629814508888458  Rel. Test L2 Loss :  0.01928874455392361  Test L2 Loss :  0.03451753512024879  inv_L_scale:  [1.0, 1.0]
Epoch :  215  Time:  0.891  Rel. Train L2 Loss :  0.019741922401719625  Rel. Test L2 Loss :  0.02091975376009941  Test L2 Loss :  0.03674322694540024  inv_L_scale:  [1.0, 1.0]
Epoch :  216  Time:  0.891  Rel. Train L2 Loss :  0.019756093786822426  Rel. Test L2 Loss :  0.0217635203897953  Test L2 Loss :  0.038822278678417206  inv_L_scale:  [1.0, 1.0]
Epoch :  217  Time:  0.892  Rel. Train L2 Loss :  0.019481840688321324  Rel. Test L2 Loss :  0.020908925607800485  Test L2 Loss :  0.03712766408920288  inv_L_scale:  [1.0, 1.0]
Epoch :  218  Time:  0.891  Rel. Train L2 Loss :  0.019314762668477165  Rel. Test L2 Loss :  0.021484425663948058  Test L2 Loss :  0.03852721303701401  inv_L_scale:  [1.0, 1.0]
Epoch :  219  Time:  0.891  Rel. Train L2 Loss :  0.019454917800095346  Rel. Test L2 Loss :  0.02068846933543682  Test L2 Loss :  0.036476257890462875  inv_L_scale:  [1.0, 1.0]
Epoch :  220  Time:  0.891  Rel. Train L2 Loss :  0.01935694703625308  Rel. Test L2 Loss :  0.020076112300157548  Test L2 Loss :  0.03623102977871895  inv_L_scale:  [1.0, 1.0]
Epoch :  221  Time:  0.891  Rel. Train L2 Loss :  0.020042014925016297  Rel. Test L2 Loss :  0.019947985410690306  Test L2 Loss :  0.03561485260725021  inv_L_scale:  [1.0, 1.0]
Epoch :  222  Time:  0.891  Rel. Train L2 Loss :  0.019960929900407792  Rel. Test L2 Loss :  0.0234213325381279  Test L2 Loss :  0.042752650082111356  inv_L_scale:  [1.0, 1.0]
Epoch :  223  Time:  0.892  Rel. Train L2 Loss :  0.019524087897605368  Rel. Test L2 Loss :  0.02309450313448906  Test L2 Loss :  0.041480773091316224  inv_L_scale:  [1.0, 1.0]
Epoch :  224  Time:  0.891  Rel. Train L2 Loss :  0.01982215860651599  Rel. Test L2 Loss :  0.019486408233642578  Test L2 Loss :  0.03459919959306717  inv_L_scale:  [1.0, 1.0]
Epoch :  225  Time:  0.891  Rel. Train L2 Loss :  0.01951206666727861  Rel. Test L2 Loss :  0.021131564453244208  Test L2 Loss :  0.037736912369728086  inv_L_scale:  [1.0, 1.0]
Epoch :  226  Time:  0.891  Rel. Train L2 Loss :  0.019517664263645807  Rel. Test L2 Loss :  0.022234801799058915  Test L2 Loss :  0.03947777569293976  inv_L_scale:  [1.0, 1.0]
Epoch :  227  Time:  0.892  Rel. Train L2 Loss :  0.01962830920186308  Rel. Test L2 Loss :  0.01978809729218483  Test L2 Loss :  0.035354735255241396  inv_L_scale:  [1.0, 1.0]
Epoch :  228  Time:  0.891  Rel. Train L2 Loss :  0.01907844660182794  Rel. Test L2 Loss :  0.021020351350307463  Test L2 Loss :  0.037500926554203035  inv_L_scale:  [1.0, 1.0]
Epoch :  229  Time:  0.891  Rel. Train L2 Loss :  0.019345289626055293  Rel. Test L2 Loss :  0.021028387993574142  Test L2 Loss :  0.03719075918197632  inv_L_scale:  [1.0, 1.0]
Epoch :  230  Time:  0.891  Rel. Train L2 Loss :  0.01908879111210505  Rel. Test L2 Loss :  0.020891266167163847  Test L2 Loss :  0.037202946841716766  inv_L_scale:  [1.0, 1.0]
Epoch :  231  Time:  0.892  Rel. Train L2 Loss :  0.019192877834041912  Rel. Test L2 Loss :  0.020333841294050217  Test L2 Loss :  0.036028743386268616  inv_L_scale:  [1.0, 1.0]
Epoch :  232  Time:  0.892  Rel. Train L2 Loss :  0.020575273641281658  Rel. Test L2 Loss :  0.021449335515499116  Test L2 Loss :  0.0377888160943985  inv_L_scale:  [1.0, 1.0]
Epoch :  233  Time:  0.891  Rel. Train L2 Loss :  0.02011625034113725  Rel. Test L2 Loss :  0.02158928111195564  Test L2 Loss :  0.0381603667140007  inv_L_scale:  [1.0, 1.0]
Epoch :  234  Time:  0.892  Rel. Train L2 Loss :  0.01955572081108888  Rel. Test L2 Loss :  0.02065846584737301  Test L2 Loss :  0.03661156684160233  inv_L_scale:  [1.0, 1.0]
Epoch :  235  Time:  0.891  Rel. Train L2 Loss :  0.019135344616240925  Rel. Test L2 Loss :  0.01924855649471283  Test L2 Loss :  0.033968795388937  inv_L_scale:  [1.0, 1.0]
Epoch :  236  Time:  0.891  Rel. Train L2 Loss :  0.018831929481691784  Rel. Test L2 Loss :  0.01931991897523403  Test L2 Loss :  0.03403205707669258  inv_L_scale:  [1.0, 1.0]
Epoch :  237  Time:  0.891  Rel. Train L2 Loss :  0.0189929159068399  Rel. Test L2 Loss :  0.018948226645588876  Test L2 Loss :  0.03375544175505638  inv_L_scale:  [1.0, 1.0]
Epoch :  238  Time:  0.891  Rel. Train L2 Loss :  0.018184523632129034  Rel. Test L2 Loss :  0.01898239992558956  Test L2 Loss :  0.03371850669384003  inv_L_scale:  [1.0, 1.0]
Epoch :  239  Time:  0.892  Rel. Train L2 Loss :  0.019077508921424548  Rel. Test L2 Loss :  0.022130283266305922  Test L2 Loss :  0.039860003888607026  inv_L_scale:  [1.0, 1.0]
Epoch :  240  Time:  0.892  Rel. Train L2 Loss :  0.01928203714390596  Rel. Test L2 Loss :  0.019774076342582703  Test L2 Loss :  0.03501629337668419  inv_L_scale:  [1.0, 1.0]
Epoch :  241  Time:  0.891  Rel. Train L2 Loss :  0.01941305932071474  Rel. Test L2 Loss :  0.021347288489341736  Test L2 Loss :  0.038365148305892945  inv_L_scale:  [1.0, 1.0]
Epoch :  242  Time:  0.891  Rel. Train L2 Loss :  0.01879342946741316  Rel. Test L2 Loss :  0.02008663833141327  Test L2 Loss :  0.035576318353414536  inv_L_scale:  [1.0, 1.0]
Epoch :  243  Time:  0.891  Rel. Train L2 Loss :  0.01942658354010847  Rel. Test L2 Loss :  0.019951694011688233  Test L2 Loss :  0.03576675578951836  inv_L_scale:  [1.0, 1.0]
Epoch :  244  Time:  0.892  Rel. Train L2 Loss :  0.018950752251678044  Rel. Test L2 Loss :  0.019132776595652105  Test L2 Loss :  0.03399012722074986  inv_L_scale:  [1.0, 1.0]
Epoch :  245  Time:  0.891  Rel. Train L2 Loss :  0.018996635327736537  Rel. Test L2 Loss :  0.018973430208861827  Test L2 Loss :  0.03373701497912407  inv_L_scale:  [1.0, 1.0]
Epoch :  246  Time:  0.893  Rel. Train L2 Loss :  0.01889222488635116  Rel. Test L2 Loss :  0.020596550405025484  Test L2 Loss :  0.036627094447612765  inv_L_scale:  [1.0, 1.0]
Epoch :  247  Time:  0.891  Rel. Train L2 Loss :  0.0184476468546523  Rel. Test L2 Loss :  0.020862929821014405  Test L2 Loss :  0.037594260275363924  inv_L_scale:  [1.0, 1.0]
Epoch :  248  Time:  0.891  Rel. Train L2 Loss :  0.01827771897117297  Rel. Test L2 Loss :  0.020992294773459434  Test L2 Loss :  0.037197598367929456  inv_L_scale:  [1.0, 1.0]
Epoch :  249  Time:  0.891  Rel. Train L2 Loss :  0.018543463084432815  Rel. Test L2 Loss :  0.02070834517478943  Test L2 Loss :  0.03679454833269119  inv_L_scale:  [1.0, 1.0]
Epoch :  250  Time:  0.891  Rel. Train L2 Loss :  0.0190598852518532  Rel. Test L2 Loss :  0.019716550335288047  Test L2 Loss :  0.034823402762413025  inv_L_scale:  [1.0, 1.0]
Epoch :  251  Time:  0.891  Rel. Train L2 Loss :  0.018435234758589002  Rel. Test L2 Loss :  0.019212958365678788  Test L2 Loss :  0.03421028167009354  inv_L_scale:  [1.0, 1.0]
Epoch :  252  Time:  0.891  Rel. Train L2 Loss :  0.018322103694081306  Rel. Test L2 Loss :  0.01954569324851036  Test L2 Loss :  0.0345231382548809  inv_L_scale:  [1.0, 1.0]
Epoch :  253  Time:  0.892  Rel. Train L2 Loss :  0.018574947574072413  Rel. Test L2 Loss :  0.01912663720548153  Test L2 Loss :  0.033853827118873595  inv_L_scale:  [1.0, 1.0]
Epoch :  254  Time:  0.891  Rel. Train L2 Loss :  0.01863189946860075  Rel. Test L2 Loss :  0.019077216237783433  Test L2 Loss :  0.03399402901530266  inv_L_scale:  [1.0, 1.0]
Epoch :  255  Time:  0.891  Rel. Train L2 Loss :  0.018117500982350772  Rel. Test L2 Loss :  0.019815130233764647  Test L2 Loss :  0.03548858255147934  inv_L_scale:  [1.0, 1.0]
Epoch :  256  Time:  0.891  Rel. Train L2 Loss :  0.018381158452894952  Rel. Test L2 Loss :  0.018457114025950433  Test L2 Loss :  0.03267130888998508  inv_L_scale:  [1.0, 1.0]
Epoch :  257  Time:  0.891  Rel. Train L2 Loss :  0.018409501082367368  Rel. Test L2 Loss :  0.01937873922288418  Test L2 Loss :  0.03448006346821785  inv_L_scale:  [1.0, 1.0]
Epoch :  258  Time:  0.891  Rel. Train L2 Loss :  0.018479566491312452  Rel. Test L2 Loss :  0.019437237307429314  Test L2 Loss :  0.03434478923678398  inv_L_scale:  [1.0, 1.0]
Epoch :  259  Time:  0.892  Rel. Train L2 Loss :  0.018119543534186152  Rel. Test L2 Loss :  0.018353705331683158  Test L2 Loss :  0.032512905895709994  inv_L_scale:  [1.0, 1.0]
Epoch :  260  Time:  0.893  Rel. Train L2 Loss :  0.018319140051801998  Rel. Test L2 Loss :  0.018103876635432243  Test L2 Loss :  0.03206848673522472  inv_L_scale:  [1.0, 1.0]
Epoch :  261  Time:  0.891  Rel. Train L2 Loss :  0.01835205241623852  Rel. Test L2 Loss :  0.01876112975180149  Test L2 Loss :  0.033172292932868004  inv_L_scale:  [1.0, 1.0]
Epoch :  262  Time:  0.891  Rel. Train L2 Loss :  0.018253818187448714  Rel. Test L2 Loss :  0.01857064612209797  Test L2 Loss :  0.03287003129720688  inv_L_scale:  [1.0, 1.0]
Epoch :  263  Time:  0.891  Rel. Train L2 Loss :  0.018120330058866076  Rel. Test L2 Loss :  0.01794613979756832  Test L2 Loss :  0.03179455325007439  inv_L_scale:  [1.0, 1.0]
Epoch :  264  Time:  0.891  Rel. Train L2 Loss :  0.017648386276430554  Rel. Test L2 Loss :  0.022750016897916794  Test L2 Loss :  0.04144494265317917  inv_L_scale:  [1.0, 1.0]
Epoch :  265  Time:  0.892  Rel. Train L2 Loss :  0.017954907690485317  Rel. Test L2 Loss :  0.01942616395652294  Test L2 Loss :  0.03490990981459618  inv_L_scale:  [1.0, 1.0]
Epoch :  266  Time:  0.892  Rel. Train L2 Loss :  0.01841108190516631  Rel. Test L2 Loss :  0.01910184983164072  Test L2 Loss :  0.03401624299585819  inv_L_scale:  [1.0, 1.0]
Epoch :  267  Time:  0.891  Rel. Train L2 Loss :  0.018350832934180897  Rel. Test L2 Loss :  0.01891676627099514  Test L2 Loss :  0.03380674481391907  inv_L_scale:  [1.0, 1.0]
Epoch :  268  Time:  0.891  Rel. Train L2 Loss :  0.01796938476463159  Rel. Test L2 Loss :  0.01902699291706085  Test L2 Loss :  0.033777265399694445  inv_L_scale:  [1.0, 1.0]
Epoch :  269  Time:  0.892  Rel. Train L2 Loss :  0.017924238791068393  Rel. Test L2 Loss :  0.019238746836781503  Test L2 Loss :  0.03445412442088127  inv_L_scale:  [1.0, 1.0]
Epoch :  270  Time:  0.891  Rel. Train L2 Loss :  0.017985174680749574  Rel. Test L2 Loss :  0.018440424129366875  Test L2 Loss :  0.03274878904223442  inv_L_scale:  [1.0, 1.0]
Epoch :  271  Time:  0.891  Rel. Train L2 Loss :  0.017510457179612582  Rel. Test L2 Loss :  0.018104666322469713  Test L2 Loss :  0.03208881214261055  inv_L_scale:  [1.0, 1.0]
Epoch :  272  Time:  0.891  Rel. Train L2 Loss :  0.017558028507563803  Rel. Test L2 Loss :  0.019445959478616714  Test L2 Loss :  0.034226208552718164  inv_L_scale:  [1.0, 1.0]
Epoch :  273  Time:  0.891  Rel. Train L2 Loss :  0.017431340805358356  Rel. Test L2 Loss :  0.018245024755597115  Test L2 Loss :  0.03258096933364868  inv_L_scale:  [1.0, 1.0]
Epoch :  274  Time:  0.891  Rel. Train L2 Loss :  0.017895810678601264  Rel. Test L2 Loss :  0.02021562688052654  Test L2 Loss :  0.035507673770189284  inv_L_scale:  [1.0, 1.0]
Epoch :  275  Time:  0.892  Rel. Train L2 Loss :  0.018023005508714253  Rel. Test L2 Loss :  0.01890955924987793  Test L2 Loss :  0.03368784785270691  inv_L_scale:  [1.0, 1.0]
Epoch :  276  Time:  0.891  Rel. Train L2 Loss :  0.01799717088540395  Rel. Test L2 Loss :  0.018154669329524042  Test L2 Loss :  0.032205345034599306  inv_L_scale:  [1.0, 1.0]
Epoch :  277  Time:  0.891  Rel. Train L2 Loss :  0.017481151132120027  Rel. Test L2 Loss :  0.01851063720881939  Test L2 Loss :  0.033018565103411675  inv_L_scale:  [1.0, 1.0]
Epoch :  278  Time:  0.891  Rel. Train L2 Loss :  0.017418884990943802  Rel. Test L2 Loss :  0.019228279553353787  Test L2 Loss :  0.03425365626811981  inv_L_scale:  [1.0, 1.0]
Epoch :  279  Time:  0.891  Rel. Train L2 Loss :  0.017582297234071627  Rel. Test L2 Loss :  0.01905563734471798  Test L2 Loss :  0.03400474473834038  inv_L_scale:  [1.0, 1.0]
Epoch :  280  Time:  0.89  Rel. Train L2 Loss :  0.01757154141035345  Rel. Test L2 Loss :  0.018828961066901684  Test L2 Loss :  0.03365118600428105  inv_L_scale:  [1.0, 1.0]
Epoch :  281  Time:  0.891  Rel. Train L2 Loss :  0.017535852367679277  Rel. Test L2 Loss :  0.02130271792411804  Test L2 Loss :  0.03890793800354004  inv_L_scale:  [1.0, 1.0]
Epoch :  282  Time:  0.891  Rel. Train L2 Loss :  0.017599282637238502  Rel. Test L2 Loss :  0.019712819904088973  Test L2 Loss :  0.03535878986120224  inv_L_scale:  [1.0, 1.0]
Epoch :  283  Time:  0.892  Rel. Train L2 Loss :  0.017190316625767282  Rel. Test L2 Loss :  0.018300873190164567  Test L2 Loss :  0.03239202432334423  inv_L_scale:  [1.0, 1.0]
Epoch :  284  Time:  0.891  Rel. Train L2 Loss :  0.01698417712830835  Rel. Test L2 Loss :  0.017088194414973258  Test L2 Loss :  0.030286833196878433  inv_L_scale:  [1.0, 1.0]
Epoch :  285  Time:  0.891  Rel. Train L2 Loss :  0.016852456000116138  Rel. Test L2 Loss :  0.017814887613058092  Test L2 Loss :  0.03185191556811333  inv_L_scale:  [1.0, 1.0]
Epoch :  286  Time:  0.89  Rel. Train L2 Loss :  0.01707393234802617  Rel. Test L2 Loss :  0.01791131168603897  Test L2 Loss :  0.03185960717499256  inv_L_scale:  [1.0, 1.0]
Epoch :  287  Time:  0.89  Rel. Train L2 Loss :  0.017384091594980822  Rel. Test L2 Loss :  0.017152487561106683  Test L2 Loss :  0.030402371659874916  inv_L_scale:  [1.0, 1.0]
Epoch :  288  Time:  0.89  Rel. Train L2 Loss :  0.016692328225407334  Rel. Test L2 Loss :  0.01849433645606041  Test L2 Loss :  0.03323425456881523  inv_L_scale:  [1.0, 1.0]
Epoch :  289  Time:  0.89  Rel. Train L2 Loss :  0.017080967211061053  Rel. Test L2 Loss :  0.017844550609588623  Test L2 Loss :  0.03183847635984421  inv_L_scale:  [1.0, 1.0]
Epoch :  290  Time:  0.89  Rel. Train L2 Loss :  0.017100076691971885  Rel. Test L2 Loss :  0.018276928775012493  Test L2 Loss :  0.032335380613803866  inv_L_scale:  [1.0, 1.0]
Epoch :  291  Time:  0.89  Rel. Train L2 Loss :  0.016907407293717067  Rel. Test L2 Loss :  0.01921446979045868  Test L2 Loss :  0.0343508730828762  inv_L_scale:  [1.0, 1.0]
Epoch :  292  Time:  0.89  Rel. Train L2 Loss :  0.01698809544245402  Rel. Test L2 Loss :  0.017623739838600157  Test L2 Loss :  0.031297374591231344  inv_L_scale:  [1.0, 1.0]
Epoch :  293  Time:  0.89  Rel. Train L2 Loss :  0.016694699861109257  Rel. Test L2 Loss :  0.018471034169197084  Test L2 Loss :  0.03267807967960835  inv_L_scale:  [1.0, 1.0]
Epoch :  294  Time:  0.89  Rel. Train L2 Loss :  0.016687864172789786  Rel. Test L2 Loss :  0.01839409589767456  Test L2 Loss :  0.03265996322035789  inv_L_scale:  [1.0, 1.0]
Epoch :  295  Time:  0.891  Rel. Train L2 Loss :  0.017160440555049315  Rel. Test L2 Loss :  0.019610700309276582  Test L2 Loss :  0.035453768968582156  inv_L_scale:  [1.0, 1.0]
Epoch :  296  Time:  0.89  Rel. Train L2 Loss :  0.01724358105411132  Rel. Test L2 Loss :  0.01718355540186167  Test L2 Loss :  0.030523821264505386  inv_L_scale:  [1.0, 1.0]
Epoch :  297  Time:  0.89  Rel. Train L2 Loss :  0.016879711308413082  Rel. Test L2 Loss :  0.018219544366002084  Test L2 Loss :  0.0323491795361042  inv_L_scale:  [1.0, 1.0]
Epoch :  298  Time:  0.891  Rel. Train L2 Loss :  0.016446508181591827  Rel. Test L2 Loss :  0.01847099304199219  Test L2 Loss :  0.03309000223875046  inv_L_scale:  [1.0, 1.0]
Epoch :  299  Time:  0.89  Rel. Train L2 Loss :  0.016428276846806207  Rel. Test L2 Loss :  0.016574938371777533  Test L2 Loss :  0.029389336705207825  inv_L_scale:  [1.0, 1.0]
Epoch :  300  Time:  0.89  Rel. Train L2 Loss :  0.016503063614169755  Rel. Test L2 Loss :  0.017673264369368554  Test L2 Loss :  0.03131114438176155  inv_L_scale:  [1.0, 1.0]
Epoch :  301  Time:  0.892  Rel. Train L2 Loss :  0.016891505180133715  Rel. Test L2 Loss :  0.018100256621837615  Test L2 Loss :  0.032395687401294705  inv_L_scale:  [1.0, 1.0]
Epoch :  302  Time:  0.891  Rel. Train L2 Loss :  0.016910440491305457  Rel. Test L2 Loss :  0.018148586228489874  Test L2 Loss :  0.032480110302567484  inv_L_scale:  [1.0, 1.0]
Epoch :  303  Time:  0.891  Rel. Train L2 Loss :  0.016593969307012027  Rel. Test L2 Loss :  0.016967388167977333  Test L2 Loss :  0.030206216052174568  inv_L_scale:  [1.0, 1.0]
Epoch :  304  Time:  0.891  Rel. Train L2 Loss :  0.016636796866854032  Rel. Test L2 Loss :  0.017714733332395552  Test L2 Loss :  0.031445277854800224  inv_L_scale:  [1.0, 1.0]
Epoch :  305  Time:  0.892  Rel. Train L2 Loss :  0.016330247215098806  Rel. Test L2 Loss :  0.01733338415622711  Test L2 Loss :  0.030681778192520142  inv_L_scale:  [1.0, 1.0]
Epoch :  306  Time:  0.891  Rel. Train L2 Loss :  0.016423317239516313  Rel. Test L2 Loss :  0.016543908827006817  Test L2 Loss :  0.029431340619921684  inv_L_scale:  [1.0, 1.0]
Epoch :  307  Time:  0.891  Rel. Train L2 Loss :  0.015895420474310716  Rel. Test L2 Loss :  0.018399122878909113  Test L2 Loss :  0.032663914412260055  inv_L_scale:  [1.0, 1.0]
Epoch :  308  Time:  0.891  Rel. Train L2 Loss :  0.016517632380127906  Rel. Test L2 Loss :  0.01703798182308674  Test L2 Loss :  0.03027456931769848  inv_L_scale:  [1.0, 1.0]
Epoch :  309  Time:  0.891  Rel. Train L2 Loss :  0.015983327983154192  Rel. Test L2 Loss :  0.016735825687646866  Test L2 Loss :  0.029746019020676612  inv_L_scale:  [1.0, 1.0]
Epoch :  310  Time:  0.891  Rel. Train L2 Loss :  0.016264791480369037  Rel. Test L2 Loss :  0.017343833073973657  Test L2 Loss :  0.03107329361140728  inv_L_scale:  [1.0, 1.0]
Epoch :  311  Time:  0.891  Rel. Train L2 Loss :  0.016367682247526116  Rel. Test L2 Loss :  0.016939782537519932  Test L2 Loss :  0.03003762096166611  inv_L_scale:  [1.0, 1.0]
Epoch :  312  Time:  0.89  Rel. Train L2 Loss :  0.0163659677737289  Rel. Test L2 Loss :  0.017583905942738055  Test L2 Loss :  0.03106810376048088  inv_L_scale:  [1.0, 1.0]
Epoch :  313  Time:  0.891  Rel. Train L2 Loss :  0.01618293462528123  Rel. Test L2 Loss :  0.01730943076312542  Test L2 Loss :  0.030638019740581512  inv_L_scale:  [1.0, 1.0]
Epoch :  314  Time:  0.891  Rel. Train L2 Loss :  0.016128488290641042  Rel. Test L2 Loss :  0.016653017699718477  Test L2 Loss :  0.029383100420236587  inv_L_scale:  [1.0, 1.0]
Epoch :  315  Time:  0.891  Rel. Train L2 Loss :  0.01603247814708286  Rel. Test L2 Loss :  0.017716431878507136  Test L2 Loss :  0.03145202204585076  inv_L_scale:  [1.0, 1.0]
Epoch :  316  Time:  0.891  Rel. Train L2 Loss :  0.016336571011278365  Rel. Test L2 Loss :  0.016738494411110878  Test L2 Loss :  0.029793335199356077  inv_L_scale:  [1.0, 1.0]
Epoch :  317  Time:  0.893  Rel. Train L2 Loss :  0.01629531735761298  Rel. Test L2 Loss :  0.017621434926986694  Test L2 Loss :  0.03134253233671189  inv_L_scale:  [1.0, 1.0]
Epoch :  318  Time:  0.893  Rel. Train L2 Loss :  0.01621640640000502  Rel. Test L2 Loss :  0.016959609687328337  Test L2 Loss :  0.03002866081893444  inv_L_scale:  [1.0, 1.0]
Epoch :  319  Time:  0.891  Rel. Train L2 Loss :  0.01587101580368148  Rel. Test L2 Loss :  0.016837038174271582  Test L2 Loss :  0.029950319081544875  inv_L_scale:  [1.0, 1.0]
Epoch :  320  Time:  0.894  Rel. Train L2 Loss :  0.01585982382297516  Rel. Test L2 Loss :  0.016686070039868356  Test L2 Loss :  0.029439026415348055  inv_L_scale:  [1.0, 1.0]
Epoch :  321  Time:  0.894  Rel. Train L2 Loss :  0.015947586645682653  Rel. Test L2 Loss :  0.016318020522594453  Test L2 Loss :  0.02890757754445076  inv_L_scale:  [1.0, 1.0]
Epoch :  322  Time:  0.893  Rel. Train L2 Loss :  0.01593935739248991  Rel. Test L2 Loss :  0.016303890235722065  Test L2 Loss :  0.028760942816734313  inv_L_scale:  [1.0, 1.0]
Epoch :  323  Time:  0.896  Rel. Train L2 Loss :  0.015944742643170886  Rel. Test L2 Loss :  0.01729911394417286  Test L2 Loss :  0.03078414872288704  inv_L_scale:  [1.0, 1.0]
Epoch :  324  Time:  1.018  Rel. Train L2 Loss :  0.016170361696018112  Rel. Test L2 Loss :  0.01657243840396404  Test L2 Loss :  0.02950171984732151  inv_L_scale:  [1.0, 1.0]
Epoch :  325  Time:  0.891  Rel. Train L2 Loss :  0.01566039789054129  Rel. Test L2 Loss :  0.016565601974725723  Test L2 Loss :  0.029537775665521623  inv_L_scale:  [1.0, 1.0]
Epoch :  326  Time:  0.89  Rel. Train L2 Loss :  0.015355614158842299  Rel. Test L2 Loss :  0.017376541532576083  Test L2 Loss :  0.03085639886558056  inv_L_scale:  [1.0, 1.0]
Epoch :  327  Time:  0.891  Rel. Train L2 Loss :  0.015577821549442079  Rel. Test L2 Loss :  0.016791533082723617  Test L2 Loss :  0.02977809950709343  inv_L_scale:  [1.0, 1.0]
Epoch :  328  Time:  0.891  Rel. Train L2 Loss :  0.015653513450589445  Rel. Test L2 Loss :  0.01675536058843136  Test L2 Loss :  0.02984066441655159  inv_L_scale:  [1.0, 1.0]
Epoch :  329  Time:  0.891  Rel. Train L2 Loss :  0.015734598483476372  Rel. Test L2 Loss :  0.016925335377454758  Test L2 Loss :  0.029873716980218887  inv_L_scale:  [1.0, 1.0]
Epoch :  330  Time:  0.891  Rel. Train L2 Loss :  0.015743114435010485  Rel. Test L2 Loss :  0.017102288529276848  Test L2 Loss :  0.0305925752222538  inv_L_scale:  [1.0, 1.0]
Epoch :  331  Time:  0.892  Rel. Train L2 Loss :  0.015807719263765545  Rel. Test L2 Loss :  0.01636293336749077  Test L2 Loss :  0.029061887562274933  inv_L_scale:  [1.0, 1.0]
Epoch :  332  Time:  0.891  Rel. Train L2 Loss :  0.015483624413609504  Rel. Test L2 Loss :  0.016467691957950593  Test L2 Loss :  0.02919258803129196  inv_L_scale:  [1.0, 1.0]
Epoch :  333  Time:  0.892  Rel. Train L2 Loss :  0.015541402457488907  Rel. Test L2 Loss :  0.016335830688476563  Test L2 Loss :  0.029031458050012587  inv_L_scale:  [1.0, 1.0]
Epoch :  334  Time:  0.895  Rel. Train L2 Loss :  0.01528359141614702  Rel. Test L2 Loss :  0.01696046322584152  Test L2 Loss :  0.030151740312576295  inv_L_scale:  [1.0, 1.0]
Epoch :  335  Time:  1.037  Rel. Train L2 Loss :  0.015508414308230082  Rel. Test L2 Loss :  0.01728152308613062  Test L2 Loss :  0.030717099830508233  inv_L_scale:  [1.0, 1.0]
Epoch :  336  Time:  0.89  Rel. Train L2 Loss :  0.015417689354055457  Rel. Test L2 Loss :  0.01603678423911333  Test L2 Loss :  0.02846864700317383  inv_L_scale:  [1.0, 1.0]
Epoch :  337  Time:  0.892  Rel. Train L2 Loss :  0.01507554751303461  Rel. Test L2 Loss :  0.015850701965391636  Test L2 Loss :  0.028078843653202058  inv_L_scale:  [1.0, 1.0]
Epoch :  338  Time:  0.89  Rel. Train L2 Loss :  0.01537412215438154  Rel. Test L2 Loss :  0.017084511220455168  Test L2 Loss :  0.030426669120788574  inv_L_scale:  [1.0, 1.0]
Epoch :  339  Time:  0.891  Rel. Train L2 Loss :  0.015403567983044519  Rel. Test L2 Loss :  0.01595686621963978  Test L2 Loss :  0.028443194031715392  inv_L_scale:  [1.0, 1.0]
Epoch :  340  Time:  0.89  Rel. Train L2 Loss :  0.015250028148293494  Rel. Test L2 Loss :  0.017007512971758842  Test L2 Loss :  0.030261015892028807  inv_L_scale:  [1.0, 1.0]
Epoch :  341  Time:  0.891  Rel. Train L2 Loss :  0.015379664856526587  Rel. Test L2 Loss :  0.016647778823971747  Test L2 Loss :  0.02985083281993866  inv_L_scale:  [1.0, 1.0]
Epoch :  342  Time:  0.89  Rel. Train L2 Loss :  0.015268456306722428  Rel. Test L2 Loss :  0.016197203546762465  Test L2 Loss :  0.028637893199920654  inv_L_scale:  [1.0, 1.0]
Epoch :  343  Time:  0.891  Rel. Train L2 Loss :  0.015177499312493537  Rel. Test L2 Loss :  0.017012165486812593  Test L2 Loss :  0.030356951877474784  inv_L_scale:  [1.0, 1.0]
Epoch :  344  Time:  0.891  Rel. Train L2 Loss :  0.015283307466242048  Rel. Test L2 Loss :  0.015882944315671922  Test L2 Loss :  0.02801445722579956  inv_L_scale:  [1.0, 1.0]
Epoch :  345  Time:  0.89  Rel. Train L2 Loss :  0.01521967435048686  Rel. Test L2 Loss :  0.016153364703059198  Test L2 Loss :  0.028686848804354667  inv_L_scale:  [1.0, 1.0]
Epoch :  346  Time:  0.89  Rel. Train L2 Loss :  0.015017998764912287  Rel. Test L2 Loss :  0.015682851001620292  Test L2 Loss :  0.027798354625701904  inv_L_scale:  [1.0, 1.0]
Epoch :  347  Time:  0.891  Rel. Train L2 Loss :  0.014892175590826406  Rel. Test L2 Loss :  0.01591371327638626  Test L2 Loss :  0.028176840394735336  inv_L_scale:  [1.0, 1.0]
Epoch :  348  Time:  0.891  Rel. Train L2 Loss :  0.014891358804371622  Rel. Test L2 Loss :  0.015864821262657643  Test L2 Loss :  0.02818643383681774  inv_L_scale:  [1.0, 1.0]
Epoch :  349  Time:  0.891  Rel. Train L2 Loss :  0.01490613393485546  Rel. Test L2 Loss :  0.01649212196469307  Test L2 Loss :  0.029057291001081467  inv_L_scale:  [1.0, 1.0]
Epoch :  350  Time:  0.891  Rel. Train L2 Loss :  0.01530309087700314  Rel. Test L2 Loss :  0.016247436553239823  Test L2 Loss :  0.02890478491783142  inv_L_scale:  [1.0, 1.0]
Epoch :  351  Time:  0.89  Rel. Train L2 Loss :  0.014983708428012001  Rel. Test L2 Loss :  0.016585647463798522  Test L2 Loss :  0.02942924953997135  inv_L_scale:  [1.0, 1.0]
Epoch :  352  Time:  0.89  Rel. Train L2 Loss :  0.015236018920938173  Rel. Test L2 Loss :  0.01588720388710499  Test L2 Loss :  0.02810906395316124  inv_L_scale:  [1.0, 1.0]
Epoch :  353  Time:  0.891  Rel. Train L2 Loss :  0.015491233418385188  Rel. Test L2 Loss :  0.01650267846882343  Test L2 Loss :  0.0292727167904377  inv_L_scale:  [1.0, 1.0]
Epoch :  354  Time:  0.891  Rel. Train L2 Loss :  0.014922944015512864  Rel. Test L2 Loss :  0.015831839218735697  Test L2 Loss :  0.027998619824647904  inv_L_scale:  [1.0, 1.0]
Epoch :  355  Time:  0.891  Rel. Train L2 Loss :  0.01509694657391972  Rel. Test L2 Loss :  0.015963495671749116  Test L2 Loss :  0.028362424224615098  inv_L_scale:  [1.0, 1.0]
Epoch :  356  Time:  0.891  Rel. Train L2 Loss :  0.014699502992961142  Rel. Test L2 Loss :  0.015554106868803501  Test L2 Loss :  0.027736554071307182  inv_L_scale:  [1.0, 1.0]
Epoch :  357  Time:  0.891  Rel. Train L2 Loss :  0.014730310555961397  Rel. Test L2 Loss :  0.01570823885500431  Test L2 Loss :  0.027799377143383028  inv_L_scale:  [1.0, 1.0]
Epoch :  358  Time:  0.891  Rel. Train L2 Loss :  0.014702564146783616  Rel. Test L2 Loss :  0.015919193252921106  Test L2 Loss :  0.02824255660176277  inv_L_scale:  [1.0, 1.0]
Epoch :  359  Time:  0.891  Rel. Train L2 Loss :  0.01470063130888674  Rel. Test L2 Loss :  0.016319896802306177  Test L2 Loss :  0.028874823302030565  inv_L_scale:  [1.0, 1.0]
Epoch :  360  Time:  0.891  Rel. Train L2 Loss :  0.014614441601766481  Rel. Test L2 Loss :  0.01685778930783272  Test L2 Loss :  0.030015487968921662  inv_L_scale:  [1.0, 1.0]
Epoch :  361  Time:  0.891  Rel. Train L2 Loss :  0.014622454014089372  Rel. Test L2 Loss :  0.015381393730640411  Test L2 Loss :  0.02733925499022007  inv_L_scale:  [1.0, 1.0]
Epoch :  362  Time:  0.891  Rel. Train L2 Loss :  0.014459265164203114  Rel. Test L2 Loss :  0.01624824892729521  Test L2 Loss :  0.028858560174703597  inv_L_scale:  [1.0, 1.0]
Epoch :  363  Time:  0.892  Rel. Train L2 Loss :  0.014610659215185378  Rel. Test L2 Loss :  0.015784412063658236  Test L2 Loss :  0.028017264008522034  inv_L_scale:  [1.0, 1.0]
Epoch :  364  Time:  0.891  Rel. Train L2 Loss :  0.014543518212934335  Rel. Test L2 Loss :  0.01621817659586668  Test L2 Loss :  0.028850942254066467  inv_L_scale:  [1.0, 1.0]
Epoch :  365  Time:  0.891  Rel. Train L2 Loss :  0.014620869043800565  Rel. Test L2 Loss :  0.015460478253662585  Test L2 Loss :  0.027418092340230942  inv_L_scale:  [1.0, 1.0]
Epoch :  366  Time:  0.892  Rel. Train L2 Loss :  0.014342049070530468  Rel. Test L2 Loss :  0.015536735989153385  Test L2 Loss :  0.02764750421047211  inv_L_scale:  [1.0, 1.0]
Epoch :  367  Time:  0.891  Rel. Train L2 Loss :  0.014395024540523688  Rel. Test L2 Loss :  0.015411447435617447  Test L2 Loss :  0.027258572429418565  inv_L_scale:  [1.0, 1.0]
Epoch :  368  Time:  0.891  Rel. Train L2 Loss :  0.014361998380886185  Rel. Test L2 Loss :  0.01567063607275486  Test L2 Loss :  0.027801665589213372  inv_L_scale:  [1.0, 1.0]
Epoch :  369  Time:  0.891  Rel. Train L2 Loss :  0.0143252608511183  Rel. Test L2 Loss :  0.015502782315015793  Test L2 Loss :  0.027602706179022787  inv_L_scale:  [1.0, 1.0]
Epoch :  370  Time:  0.891  Rel. Train L2 Loss :  0.014211512551539475  Rel. Test L2 Loss :  0.015027371793985366  Test L2 Loss :  0.02659827321767807  inv_L_scale:  [1.0, 1.0]
Epoch :  371  Time:  0.89  Rel. Train L2 Loss :  0.014257784059478177  Rel. Test L2 Loss :  0.015021273009479046  Test L2 Loss :  0.026560570299625396  inv_L_scale:  [1.0, 1.0]
Epoch :  372  Time:  0.891  Rel. Train L2 Loss :  0.014177872786919276  Rel. Test L2 Loss :  0.0154915738850832  Test L2 Loss :  0.027643935456871986  inv_L_scale:  [1.0, 1.0]
Epoch :  373  Time:  0.891  Rel. Train L2 Loss :  0.014111986623870003  Rel. Test L2 Loss :  0.015304533988237381  Test L2 Loss :  0.027229129523038863  inv_L_scale:  [1.0, 1.0]
Epoch :  374  Time:  0.891  Rel. Train L2 Loss :  0.014302645665076044  Rel. Test L2 Loss :  0.015355413407087326  Test L2 Loss :  0.027151308730244638  inv_L_scale:  [1.0, 1.0]
Epoch :  375  Time:  0.891  Rel. Train L2 Loss :  0.014129816628992558  Rel. Test L2 Loss :  0.014885932207107544  Test L2 Loss :  0.026369883567094802  inv_L_scale:  [1.0, 1.0]
Epoch :  376  Time:  0.891  Rel. Train L2 Loss :  0.014234570186171266  Rel. Test L2 Loss :  0.015463290847837924  Test L2 Loss :  0.02761162169277668  inv_L_scale:  [1.0, 1.0]
Epoch :  377  Time:  0.891  Rel. Train L2 Loss :  0.014210591357615258  Rel. Test L2 Loss :  0.015102921798825265  Test L2 Loss :  0.026758937835693358  inv_L_scale:  [1.0, 1.0]
Epoch :  378  Time:  0.891  Rel. Train L2 Loss :  0.014044580604467127  Rel. Test L2 Loss :  0.015131565667688847  Test L2 Loss :  0.026887006089091302  inv_L_scale:  [1.0, 1.0]
Epoch :  379  Time:  0.891  Rel. Train L2 Loss :  0.014012535454498397  Rel. Test L2 Loss :  0.01537627398967743  Test L2 Loss :  0.027293152064085006  inv_L_scale:  [1.0, 1.0]
Epoch :  380  Time:  0.891  Rel. Train L2 Loss :  0.014060010458860132  Rel. Test L2 Loss :  0.015130122750997543  Test L2 Loss :  0.026691510900855066  inv_L_scale:  [1.0, 1.0]
Epoch :  381  Time:  0.891  Rel. Train L2 Loss :  0.014111223071813584  Rel. Test L2 Loss :  0.01497401736676693  Test L2 Loss :  0.026502077728509904  inv_L_scale:  [1.0, 1.0]
Epoch :  382  Time:  0.891  Rel. Train L2 Loss :  0.014177979247437583  Rel. Test L2 Loss :  0.01520729161798954  Test L2 Loss :  0.026947218999266623  inv_L_scale:  [1.0, 1.0]
Epoch :  383  Time:  0.891  Rel. Train L2 Loss :  0.014070075096355545  Rel. Test L2 Loss :  0.014945080541074275  Test L2 Loss :  0.02648104727268219  inv_L_scale:  [1.0, 1.0]
Epoch :  384  Time:  0.893  Rel. Train L2 Loss :  0.013998700020213922  Rel. Test L2 Loss :  0.01497721679508686  Test L2 Loss :  0.026611809730529786  inv_L_scale:  [1.0, 1.0]
Epoch :  385  Time:  0.891  Rel. Train L2 Loss :  0.013907114850978057  Rel. Test L2 Loss :  0.014749799892306327  Test L2 Loss :  0.026228339225053788  inv_L_scale:  [1.0, 1.0]
Epoch :  386  Time:  0.891  Rel. Train L2 Loss :  0.013814043427507083  Rel. Test L2 Loss :  0.01497191246598959  Test L2 Loss :  0.026600782573223115  inv_L_scale:  [1.0, 1.0]
Epoch :  387  Time:  0.892  Rel. Train L2 Loss :  0.013782668502794372  Rel. Test L2 Loss :  0.014792754873633384  Test L2 Loss :  0.02628523126244545  inv_L_scale:  [1.0, 1.0]
Epoch :  388  Time:  0.891  Rel. Train L2 Loss :  0.013867058157920838  Rel. Test L2 Loss :  0.014810109846293926  Test L2 Loss :  0.026195676401257514  inv_L_scale:  [1.0, 1.0]
Epoch :  389  Time:  0.891  Rel. Train L2 Loss :  0.01390137441870239  Rel. Test L2 Loss :  0.01491283357143402  Test L2 Loss :  0.02647115021944046  inv_L_scale:  [1.0, 1.0]
Epoch :  390  Time:  0.891  Rel. Train L2 Loss :  0.013864510154558553  Rel. Test L2 Loss :  0.014920332282781602  Test L2 Loss :  0.026477305740118025  inv_L_scale:  [1.0, 1.0]
Epoch :  391  Time:  0.891  Rel. Train L2 Loss :  0.013823196672730976  Rel. Test L2 Loss :  0.014753179401159286  Test L2 Loss :  0.02611123740673065  inv_L_scale:  [1.0, 1.0]
Epoch :  392  Time:  0.891  Rel. Train L2 Loss :  0.013937049176957872  Rel. Test L2 Loss :  0.014822986349463463  Test L2 Loss :  0.02625944100320339  inv_L_scale:  [1.0, 1.0]
Epoch :  393  Time:  0.891  Rel. Train L2 Loss :  0.013781317029562262  Rel. Test L2 Loss :  0.015009451024234295  Test L2 Loss :  0.02665132388472557  inv_L_scale:  [1.0, 1.0]
Epoch :  394  Time:  0.891  Rel. Train L2 Loss :  0.013693742127054268  Rel. Test L2 Loss :  0.014624495208263397  Test L2 Loss :  0.025926293805241585  inv_L_scale:  [1.0, 1.0]
Epoch :  395  Time:  0.892  Rel. Train L2 Loss :  0.013767326631479794  Rel. Test L2 Loss :  0.015071350447833538  Test L2 Loss :  0.026637359410524367  inv_L_scale:  [1.0, 1.0]
Epoch :  396  Time:  0.891  Rel. Train L2 Loss :  0.013833413910534647  Rel. Test L2 Loss :  0.014653593003749847  Test L2 Loss :  0.02589547112584114  inv_L_scale:  [1.0, 1.0]
Epoch :  397  Time:  0.891  Rel. Train L2 Loss :  0.013610751521256235  Rel. Test L2 Loss :  0.014603341184556484  Test L2 Loss :  0.025926915630698204  inv_L_scale:  [1.0, 1.0]
Epoch :  398  Time:  0.891  Rel. Train L2 Loss :  0.013539445238808791  Rel. Test L2 Loss :  0.014838138110935688  Test L2 Loss :  0.026303906440734864  inv_L_scale:  [1.0, 1.0]
Epoch :  399  Time:  0.892  Rel. Train L2 Loss :  0.013561231684353617  Rel. Test L2 Loss :  0.014748730398714542  Test L2 Loss :  0.026062075793743134  inv_L_scale:  [1.0, 1.0]
Epoch :  400  Time:  0.891  Rel. Train L2 Loss :  0.013613191503617499  Rel. Test L2 Loss :  0.014709262549877167  Test L2 Loss :  0.026067804321646692  inv_L_scale:  [1.0, 1.0]
Epoch :  401  Time:  0.892  Rel. Train L2 Loss :  0.013490434690482087  Rel. Test L2 Loss :  0.01449937254190445  Test L2 Loss :  0.025763388201594354  inv_L_scale:  [1.0, 1.0]
Epoch :  402  Time:  0.891  Rel. Train L2 Loss :  0.013417855352163315  Rel. Test L2 Loss :  0.014857603013515472  Test L2 Loss :  0.026328320205211638  inv_L_scale:  [1.0, 1.0]
Epoch :  403  Time:  0.891  Rel. Train L2 Loss :  0.013557075295183393  Rel. Test L2 Loss :  0.01442380778491497  Test L2 Loss :  0.02557668536901474  inv_L_scale:  [1.0, 1.0]
Epoch :  404  Time:  0.891  Rel. Train L2 Loss :  0.013410566589898533  Rel. Test L2 Loss :  0.015006822273135186  Test L2 Loss :  0.02686385713517666  inv_L_scale:  [1.0, 1.0]
Epoch :  405  Time:  0.895  Rel. Train L2 Loss :  0.013554447384344206  Rel. Test L2 Loss :  0.014406949654221535  Test L2 Loss :  0.025468968972563743  inv_L_scale:  [1.0, 1.0]
Epoch :  406  Time:  0.892  Rel. Train L2 Loss :  0.013399948924779892  Rel. Test L2 Loss :  0.014543882086873055  Test L2 Loss :  0.02576837293803692  inv_L_scale:  [1.0, 1.0]
Epoch :  407  Time:  0.891  Rel. Train L2 Loss :  0.013410212248563766  Rel. Test L2 Loss :  0.014437776356935501  Test L2 Loss :  0.025589414313435553  inv_L_scale:  [1.0, 1.0]
Epoch :  408  Time:  0.892  Rel. Train L2 Loss :  0.013326619358526335  Rel. Test L2 Loss :  0.014415414892137051  Test L2 Loss :  0.02547434836626053  inv_L_scale:  [1.0, 1.0]
Epoch :  409  Time:  0.891  Rel. Train L2 Loss :  0.013367879895700348  Rel. Test L2 Loss :  0.014563700184226036  Test L2 Loss :  0.02580313190817833  inv_L_scale:  [1.0, 1.0]
Epoch :  410  Time:  0.89  Rel. Train L2 Loss :  0.013383657559752465  Rel. Test L2 Loss :  0.014550126940011978  Test L2 Loss :  0.02576406829059124  inv_L_scale:  [1.0, 1.0]
Epoch :  411  Time:  0.891  Rel. Train L2 Loss :  0.013316953293979169  Rel. Test L2 Loss :  0.01426532857120037  Test L2 Loss :  0.025312051251530646  inv_L_scale:  [1.0, 1.0]
Epoch :  412  Time:  0.891  Rel. Train L2 Loss :  0.013313347424070041  Rel. Test L2 Loss :  0.014312244951725006  Test L2 Loss :  0.025337316244840622  inv_L_scale:  [1.0, 1.0]
Epoch :  413  Time:  0.891  Rel. Train L2 Loss :  0.013244941975507471  Rel. Test L2 Loss :  0.014402756951749324  Test L2 Loss :  0.025536377876996995  inv_L_scale:  [1.0, 1.0]
Epoch :  414  Time:  0.891  Rel. Train L2 Loss :  0.01315499788357152  Rel. Test L2 Loss :  0.014362050257623195  Test L2 Loss :  0.02542811691761017  inv_L_scale:  [1.0, 1.0]
Epoch :  415  Time:  0.891  Rel. Train L2 Loss :  0.013219757551948229  Rel. Test L2 Loss :  0.014378762468695641  Test L2 Loss :  0.02548272430896759  inv_L_scale:  [1.0, 1.0]
Epoch :  416  Time:  0.891  Rel. Train L2 Loss :  0.01318329276310073  Rel. Test L2 Loss :  0.014240439608693123  Test L2 Loss :  0.025160017609596252  inv_L_scale:  [1.0, 1.0]
Epoch :  417  Time:  0.891  Rel. Train L2 Loss :  0.013113891043596797  Rel. Test L2 Loss :  0.014376000203192234  Test L2 Loss :  0.025520515888929368  inv_L_scale:  [1.0, 1.0]
Epoch :  418  Time:  0.892  Rel. Train L2 Loss :  0.013201012801792887  Rel. Test L2 Loss :  0.01420624241232872  Test L2 Loss :  0.025215630978345872  inv_L_scale:  [1.0, 1.0]
Epoch :  419  Time:  0.892  Rel. Train L2 Loss :  0.013132450580596923  Rel. Test L2 Loss :  0.01435381941497326  Test L2 Loss :  0.02533794805407524  inv_L_scale:  [1.0, 1.0]
Epoch :  420  Time:  0.891  Rel. Train L2 Loss :  0.013090748534434371  Rel. Test L2 Loss :  0.014127022475004197  Test L2 Loss :  0.025083441883325577  inv_L_scale:  [1.0, 1.0]
Epoch :  421  Time:  0.892  Rel. Train L2 Loss :  0.013047735633121596  Rel. Test L2 Loss :  0.014290927164256572  Test L2 Loss :  0.02525071144104004  inv_L_scale:  [1.0, 1.0]
Epoch :  422  Time:  0.891  Rel. Train L2 Loss :  0.013111537885334756  Rel. Test L2 Loss :  0.014314092099666595  Test L2 Loss :  0.02535632312297821  inv_L_scale:  [1.0, 1.0]
Epoch :  423  Time:  0.891  Rel. Train L2 Loss :  0.013034360487427976  Rel. Test L2 Loss :  0.014247820600867272  Test L2 Loss :  0.025263530015945435  inv_L_scale:  [1.0, 1.0]
Epoch :  424  Time:  0.891  Rel. Train L2 Loss :  0.013043118806348907  Rel. Test L2 Loss :  0.014113412722945213  Test L2 Loss :  0.024959247559309006  inv_L_scale:  [1.0, 1.0]
Epoch :  425  Time:  0.891  Rel. Train L2 Loss :  0.012966644221709834  Rel. Test L2 Loss :  0.014171218164265156  Test L2 Loss :  0.02512204200029373  inv_L_scale:  [1.0, 1.0]
Epoch :  426  Time:  0.891  Rel. Train L2 Loss :  0.013007375738686985  Rel. Test L2 Loss :  0.014058396071195602  Test L2 Loss :  0.02490545779466629  inv_L_scale:  [1.0, 1.0]
Epoch :  427  Time:  0.892  Rel. Train L2 Loss :  0.012960553392767906  Rel. Test L2 Loss :  0.01417934812605381  Test L2 Loss :  0.02513562448322773  inv_L_scale:  [1.0, 1.0]
Epoch :  428  Time:  0.892  Rel. Train L2 Loss :  0.01299531256986989  Rel. Test L2 Loss :  0.014129020981490612  Test L2 Loss :  0.025005325376987457  inv_L_scale:  [1.0, 1.0]
Epoch :  429  Time:  0.891  Rel. Train L2 Loss :  0.012971141040325165  Rel. Test L2 Loss :  0.014135158509016038  Test L2 Loss :  0.02499969258904457  inv_L_scale:  [1.0, 1.0]
Epoch :  430  Time:  0.89  Rel. Train L2 Loss :  0.013019821093314224  Rel. Test L2 Loss :  0.01439830794930458  Test L2 Loss :  0.025650437772274017  inv_L_scale:  [1.0, 1.0]
Epoch :  431  Time:  0.89  Rel. Train L2 Loss :  0.013013867760698001  Rel. Test L2 Loss :  0.013988026082515717  Test L2 Loss :  0.024800054132938384  inv_L_scale:  [1.0, 1.0]
Epoch :  432  Time:  0.89  Rel. Train L2 Loss :  0.013013002044624753  Rel. Test L2 Loss :  0.014204650111496448  Test L2 Loss :  0.025185438096523283  inv_L_scale:  [1.0, 1.0]
Epoch :  433  Time:  0.891  Rel. Train L2 Loss :  0.012951838730110063  Rel. Test L2 Loss :  0.014024980925023555  Test L2 Loss :  0.024814648926258086  inv_L_scale:  [1.0, 1.0]
Epoch :  434  Time:  0.89  Rel. Train L2 Loss :  0.012921780542367034  Rel. Test L2 Loss :  0.0140737684071064  Test L2 Loss :  0.024926271364092825  inv_L_scale:  [1.0, 1.0]
Epoch :  435  Time:  0.892  Rel. Train L2 Loss :  0.012911926483114561  Rel. Test L2 Loss :  0.014066670313477516  Test L2 Loss :  0.02489796668291092  inv_L_scale:  [1.0, 1.0]
Epoch :  436  Time:  0.89  Rel. Train L2 Loss :  0.012866257694032457  Rel. Test L2 Loss :  0.014022624678909778  Test L2 Loss :  0.02485227182507515  inv_L_scale:  [1.0, 1.0]
Epoch :  437  Time:  0.89  Rel. Train L2 Loss :  0.012836101849873861  Rel. Test L2 Loss :  0.013992501124739647  Test L2 Loss :  0.024789106994867326  inv_L_scale:  [1.0, 1.0]
Epoch :  438  Time:  0.891  Rel. Train L2 Loss :  0.012811288759112359  Rel. Test L2 Loss :  0.014274698495864869  Test L2 Loss :  0.02534089595079422  inv_L_scale:  [1.0, 1.0]
Epoch :  439  Time:  0.891  Rel. Train L2 Loss :  0.012868679985404015  Rel. Test L2 Loss :  0.014186520427465439  Test L2 Loss :  0.0251299349963665  inv_L_scale:  [1.0, 1.0]
Epoch :  440  Time:  0.889  Rel. Train L2 Loss :  0.012786091681983736  Rel. Test L2 Loss :  0.014045350924134255  Test L2 Loss :  0.024872201159596444  inv_L_scale:  [1.0, 1.0]
Epoch :  441  Time:  0.89  Rel. Train L2 Loss :  0.012764777835044596  Rel. Test L2 Loss :  0.013959180787205696  Test L2 Loss :  0.02474308654665947  inv_L_scale:  [1.0, 1.0]
Epoch :  442  Time:  0.888  Rel. Train L2 Loss :  0.012764001128574213  Rel. Test L2 Loss :  0.014015046581625938  Test L2 Loss :  0.024821285530924796  inv_L_scale:  [1.0, 1.0]
Epoch :  443  Time:  0.89  Rel. Train L2 Loss :  0.012735667357014285  Rel. Test L2 Loss :  0.014005397632718086  Test L2 Loss :  0.024795478954911233  inv_L_scale:  [1.0, 1.0]
Epoch :  444  Time:  0.89  Rel. Train L2 Loss :  0.012774446734951601  Rel. Test L2 Loss :  0.014008897878229619  Test L2 Loss :  0.024798416793346406  inv_L_scale:  [1.0, 1.0]
Epoch :  445  Time:  0.89  Rel. Train L2 Loss :  0.012734882198274136  Rel. Test L2 Loss :  0.014032298475503921  Test L2 Loss :  0.02480448633432388  inv_L_scale:  [1.0, 1.0]
Epoch :  446  Time:  0.89  Rel. Train L2 Loss :  0.012742312620911333  Rel. Test L2 Loss :  0.014118587225675583  Test L2 Loss :  0.024975815564394  inv_L_scale:  [1.0, 1.0]
Epoch :  447  Time:  0.89  Rel. Train L2 Loss :  0.012726783284710514  Rel. Test L2 Loss :  0.013951180055737495  Test L2 Loss :  0.024692171812057497  inv_L_scale:  [1.0, 1.0]
Epoch :  448  Time:  0.89  Rel. Train L2 Loss :  0.012678787555131648  Rel. Test L2 Loss :  0.01397623248398304  Test L2 Loss :  0.02477223813533783  inv_L_scale:  [1.0, 1.0]
Epoch :  449  Time:  0.89  Rel. Train L2 Loss :  0.012685101541380087  Rel. Test L2 Loss :  0.01402618583291769  Test L2 Loss :  0.024849967435002326  inv_L_scale:  [1.0, 1.0]
Epoch :  450  Time:  0.89  Rel. Train L2 Loss :  0.012684266281624635  Rel. Test L2 Loss :  0.013896285742521285  Test L2 Loss :  0.024624253138899804  inv_L_scale:  [1.0, 1.0]
Epoch :  451  Time:  0.89  Rel. Train L2 Loss :  0.01266646049088902  Rel. Test L2 Loss :  0.013921906352043151  Test L2 Loss :  0.02465867042541504  inv_L_scale:  [1.0, 1.0]
Epoch :  452  Time:  0.892  Rel. Train L2 Loss :  0.01265002808223168  Rel. Test L2 Loss :  0.013935078121721744  Test L2 Loss :  0.02468084394931793  inv_L_scale:  [1.0, 1.0]
Epoch :  453  Time:  0.892  Rel. Train L2 Loss :  0.012643703267806106  Rel. Test L2 Loss :  0.013950652629137038  Test L2 Loss :  0.024731512814760208  inv_L_scale:  [1.0, 1.0]
Epoch :  454  Time:  0.891  Rel. Train L2 Loss :  0.012643353628615538  Rel. Test L2 Loss :  0.01398100569844246  Test L2 Loss :  0.024749209582805635  inv_L_scale:  [1.0, 1.0]
Epoch :  455  Time:  0.891  Rel. Train L2 Loss :  0.012610074774258666  Rel. Test L2 Loss :  0.013939934819936751  Test L2 Loss :  0.024663594514131547  inv_L_scale:  [1.0, 1.0]
Epoch :  456  Time:  0.89  Rel. Train L2 Loss :  0.012603209080795447  Rel. Test L2 Loss :  0.013872158378362656  Test L2 Loss :  0.024586431086063384  inv_L_scale:  [1.0, 1.0]
Epoch :  457  Time:  0.89  Rel. Train L2 Loss :  0.012577320051689943  Rel. Test L2 Loss :  0.013920910246670247  Test L2 Loss :  0.024636453986167907  inv_L_scale:  [1.0, 1.0]
Epoch :  458  Time:  0.89  Rel. Train L2 Loss :  0.012589583997097281  Rel. Test L2 Loss :  0.013906133435666561  Test L2 Loss :  0.024614234045147895  inv_L_scale:  [1.0, 1.0]
Epoch :  459  Time:  0.891  Rel. Train L2 Loss :  0.01256849275281032  Rel. Test L2 Loss :  0.013874097019433975  Test L2 Loss :  0.024565046280622484  inv_L_scale:  [1.0, 1.0]
Epoch :  460  Time:  0.891  Rel. Train L2 Loss :  0.012560744196590451  Rel. Test L2 Loss :  0.013980542942881584  Test L2 Loss :  0.024715504944324493  inv_L_scale:  [1.0, 1.0]
Epoch :  461  Time:  0.891  Rel. Train L2 Loss :  0.012610725632144345  Rel. Test L2 Loss :  0.013985083997249603  Test L2 Loss :  0.02473805010318756  inv_L_scale:  [1.0, 1.0]
Epoch :  462  Time:  0.89  Rel. Train L2 Loss :  0.012570269095400969  Rel. Test L2 Loss :  0.013945089057087898  Test L2 Loss :  0.024705307632684706  inv_L_scale:  [1.0, 1.0]
Epoch :  463  Time:  0.89  Rel. Train L2 Loss :  0.012542120375567012  Rel. Test L2 Loss :  0.013897116929292679  Test L2 Loss :  0.02459308981895447  inv_L_scale:  [1.0, 1.0]
Epoch :  464  Time:  0.891  Rel. Train L2 Loss :  0.012514304895367888  Rel. Test L2 Loss :  0.01394430510699749  Test L2 Loss :  0.024708883166313172  inv_L_scale:  [1.0, 1.0]
Epoch :  465  Time:  0.891  Rel. Train L2 Loss :  0.012540494033859836  Rel. Test L2 Loss :  0.013938605561852455  Test L2 Loss :  0.024748029187321663  inv_L_scale:  [1.0, 1.0]
Epoch :  466  Time:  0.89  Rel. Train L2 Loss :  0.012514967111249765  Rel. Test L2 Loss :  0.013868981711566449  Test L2 Loss :  0.024564009085297586  inv_L_scale:  [1.0, 1.0]
Epoch :  467  Time:  0.891  Rel. Train L2 Loss :  0.012511826169987519  Rel. Test L2 Loss :  0.013876248374581337  Test L2 Loss :  0.02455594450235367  inv_L_scale:  [1.0, 1.0]
Epoch :  468  Time:  0.89  Rel. Train L2 Loss :  0.012493076655599806  Rel. Test L2 Loss :  0.01391206655651331  Test L2 Loss :  0.024646586179733275  inv_L_scale:  [1.0, 1.0]
Epoch :  469  Time:  0.891  Rel. Train L2 Loss :  0.012481439258489343  Rel. Test L2 Loss :  0.013864468410611152  Test L2 Loss :  0.024545528292655945  inv_L_scale:  [1.0, 1.0]
Epoch :  470  Time:  0.891  Rel. Train L2 Loss :  0.012485106986843877  Rel. Test L2 Loss :  0.013917953670024873  Test L2 Loss :  0.024635688066482545  inv_L_scale:  [1.0, 1.0]
Epoch :  471  Time:  0.891  Rel. Train L2 Loss :  0.012471695608562894  Rel. Test L2 Loss :  0.013885639607906342  Test L2 Loss :  0.02457076631486416  inv_L_scale:  [1.0, 1.0]
Epoch :  472  Time:  0.891  Rel. Train L2 Loss :  0.012466498890684711  Rel. Test L2 Loss :  0.013884927742183209  Test L2 Loss :  0.02457867354154587  inv_L_scale:  [1.0, 1.0]
Epoch :  473  Time:  0.891  Rel. Train L2 Loss :  0.012456023684806293  Rel. Test L2 Loss :  0.013883176818490028  Test L2 Loss :  0.02457756131887436  inv_L_scale:  [1.0, 1.0]
Epoch :  474  Time:  0.891  Rel. Train L2 Loss :  0.012442482225596905  Rel. Test L2 Loss :  0.013833054006099701  Test L2 Loss :  0.024488582164049148  inv_L_scale:  [1.0, 1.0]
Epoch :  475  Time:  0.891  Rel. Train L2 Loss :  0.01244479491478867  Rel. Test L2 Loss :  0.01383959736675024  Test L2 Loss :  0.02450174033641815  inv_L_scale:  [1.0, 1.0]
Epoch :  476  Time:  0.891  Rel. Train L2 Loss :  0.012433606932560603  Rel. Test L2 Loss :  0.013878715448081494  Test L2 Loss :  0.02455656513571739  inv_L_scale:  [1.0, 1.0]
Epoch :  477  Time:  0.891  Rel. Train L2 Loss :  0.012431644561390082  Rel. Test L2 Loss :  0.01383087657392025  Test L2 Loss :  0.024471849277615546  inv_L_scale:  [1.0, 1.0]
Epoch :  478  Time:  0.891  Rel. Train L2 Loss :  0.012419823739263746  Rel. Test L2 Loss :  0.013845001943409443  Test L2 Loss :  0.024500927403569222  inv_L_scale:  [1.0, 1.0]
Epoch :  479  Time:  0.891  Rel. Train L2 Loss :  0.012415017676022318  Rel. Test L2 Loss :  0.013822349384427071  Test L2 Loss :  0.024461822807788847  inv_L_scale:  [1.0, 1.0]
Epoch :  480  Time:  0.891  Rel. Train L2 Loss :  0.012417493971685569  Rel. Test L2 Loss :  0.013830566257238388  Test L2 Loss :  0.024478386789560318  inv_L_scale:  [1.0, 1.0]
Epoch :  481  Time:  0.89  Rel. Train L2 Loss :  0.012408580891788005  Rel. Test L2 Loss :  0.013854333758354187  Test L2 Loss :  0.024522782117128373  inv_L_scale:  [1.0, 1.0]
Epoch :  482  Time:  0.89  Rel. Train L2 Loss :  0.012405635619329081  Rel. Test L2 Loss :  0.013833353221416473  Test L2 Loss :  0.024480593279004096  inv_L_scale:  [1.0, 1.0]
Epoch :  483  Time:  0.891  Rel. Train L2 Loss :  0.012405701813598473  Rel. Test L2 Loss :  0.013842697404325009  Test L2 Loss :  0.024497515186667443  inv_L_scale:  [1.0, 1.0]
Epoch :  484  Time:  0.89  Rel. Train L2 Loss :  0.012401808210545116  Rel. Test L2 Loss :  0.0138457640260458  Test L2 Loss :  0.024509145021438597  inv_L_scale:  [1.0, 1.0]
Epoch :  485  Time:  0.891  Rel. Train L2 Loss :  0.012391572863691382  Rel. Test L2 Loss :  0.013820120766758918  Test L2 Loss :  0.02446340948343277  inv_L_scale:  [1.0, 1.0]
Epoch :  486  Time:  0.892  Rel. Train L2 Loss :  0.012394948171244728  Rel. Test L2 Loss :  0.013834444060921668  Test L2 Loss :  0.024487721771001815  inv_L_scale:  [1.0, 1.0]
Epoch :  487  Time:  0.892  Rel. Train L2 Loss :  0.012386961140566402  Rel. Test L2 Loss :  0.013834844008088112  Test L2 Loss :  0.024482660815119742  inv_L_scale:  [1.0, 1.0]
Epoch :  488  Time:  0.891  Rel. Train L2 Loss :  0.012381627981861432  Rel. Test L2 Loss :  0.013829330801963807  Test L2 Loss :  0.024477498531341554  inv_L_scale:  [1.0, 1.0]
Epoch :  489  Time:  0.891  Rel. Train L2 Loss :  0.012380065880715847  Rel. Test L2 Loss :  0.013834072574973107  Test L2 Loss :  0.02448077708482742  inv_L_scale:  [1.0, 1.0]
Epoch :  490  Time:  0.891  Rel. Train L2 Loss :  0.012374627995822165  Rel. Test L2 Loss :  0.01382708366960287  Test L2 Loss :  0.024471368491649628  inv_L_scale:  [1.0, 1.0]
Epoch :  491  Time:  0.891  Rel. Train L2 Loss :  0.012373952468236287  Rel. Test L2 Loss :  0.013833233676850796  Test L2 Loss :  0.02448004700243473  inv_L_scale:  [1.0, 1.0]
Epoch :  492  Time:  0.891  Rel. Train L2 Loss :  0.012371608602503935  Rel. Test L2 Loss :  0.013826775327324868  Test L2 Loss :  0.024473324567079544  inv_L_scale:  [1.0, 1.0]
Epoch :  493  Time:  0.891  Rel. Train L2 Loss :  0.012369578729073207  Rel. Test L2 Loss :  0.0138217793405056  Test L2 Loss :  0.024460699260234833  inv_L_scale:  [1.0, 1.0]
Epoch :  494  Time:  0.889  Rel. Train L2 Loss :  0.01237045805901289  Rel. Test L2 Loss :  0.01383395217359066  Test L2 Loss :  0.02448882654309273  inv_L_scale:  [1.0, 1.0]
Epoch :  495  Time:  0.892  Rel. Train L2 Loss :  0.012369439063800705  Rel. Test L2 Loss :  0.01380865503102541  Test L2 Loss :  0.024446863383054733  inv_L_scale:  [1.0, 1.0]
Epoch :  496  Time:  0.892  Rel. Train L2 Loss :  0.01236414279995693  Rel. Test L2 Loss :  0.01382327377796173  Test L2 Loss :  0.024458046182990075  inv_L_scale:  [1.0, 1.0]
Epoch :  497  Time:  0.891  Rel. Train L2 Loss :  0.012364684037036366  Rel. Test L2 Loss :  0.013828108981251717  Test L2 Loss :  0.02446595847606659  inv_L_scale:  [1.0, 1.0]
Epoch :  498  Time:  0.89  Rel. Train L2 Loss :  0.012369525527788533  Rel. Test L2 Loss :  0.013822313770651818  Test L2 Loss :  0.024462022855877875  inv_L_scale:  [1.0, 1.0]
Epoch :  499  Time:  0.891  Rel. Train L2 Loss :  0.012365614916715357  Rel. Test L2 Loss :  0.013816497214138508  Test L2 Loss :  0.02445197992026806  inv_L_scale:  [1.0, 1.0]
