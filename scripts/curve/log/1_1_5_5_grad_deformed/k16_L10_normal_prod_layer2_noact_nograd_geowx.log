(1000,) (1000, 1000, 1) (1000, 1000, 2)
use normalized raw measures
Casting to tensor
x_train shape torch.Size([900, 1000, 8]), y_train shape torch.Size([900, 1000, 1])
length of each dim:  tensor([6.5573987960815430, 6.1420288085937500])
kmax = 16
L = 10
use cube modes, scale = 0 (544, 2, 1)
geo_dims = [1, 2, 5, 6]
In PCNO_train, ndims =  2
Epoch :  0  Time:  1.748  Rel. Train L2 Loss :  0.5902896342012617  Rel. Test L2 Loss :  0.4869431447982788  Test L2 Loss :  0.7083314800262451  inv_L_scale:  [1.0, 1.0]
Epoch :  1  Time:  1.118  Rel. Train L2 Loss :  0.40738891376389397  Rel. Test L2 Loss :  0.34185367584228515  Test L2 Loss :  0.4931187903881073  inv_L_scale:  [1.0, 1.0]
Epoch :  2  Time:  1.133  Rel. Train L2 Loss :  0.2901514947414398  Rel. Test L2 Loss :  0.25410227417945863  Test L2 Loss :  0.3613628578186035  inv_L_scale:  [1.0, 1.0]
Epoch :  3  Time:  1.131  Rel. Train L2 Loss :  0.2193523903687795  Rel. Test L2 Loss :  0.19625624299049377  Test L2 Loss :  0.27958563089370725  inv_L_scale:  [1.0, 1.0]
Epoch :  4  Time:  1.16  Rel. Train L2 Loss :  0.17561581167909834  Rel. Test L2 Loss :  0.16746011555194854  Test L2 Loss :  0.23723085343837738  inv_L_scale:  [1.0, 1.0]
Epoch :  5  Time:  1.145  Rel. Train L2 Loss :  0.15810611950026618  Rel. Test L2 Loss :  0.15781318724155427  Test L2 Loss :  0.224389671087265  inv_L_scale:  [1.0, 1.0]
Epoch :  6  Time:  1.137  Rel. Train L2 Loss :  0.13988590472274356  Rel. Test L2 Loss :  0.13107616007328032  Test L2 Loss :  0.18724527478218078  inv_L_scale:  [1.0, 1.0]
Epoch :  7  Time:  1.142  Rel. Train L2 Loss :  0.12551029556327395  Rel. Test L2 Loss :  0.12023929238319397  Test L2 Loss :  0.1708264493942261  inv_L_scale:  [1.0, 1.0]
Epoch :  8  Time:  1.183  Rel. Train L2 Loss :  0.11882899118794335  Rel. Test L2 Loss :  0.11728290975093841  Test L2 Loss :  0.16724822640419007  inv_L_scale:  [1.0, 1.0]
Epoch :  9  Time:  1.179  Rel. Train L2 Loss :  0.11338992771175173  Rel. Test L2 Loss :  0.11109289348125458  Test L2 Loss :  0.15809872031211852  inv_L_scale:  [1.0, 1.0]
Epoch :  10  Time:  1.127  Rel. Train L2 Loss :  0.10757743408282598  Rel. Test L2 Loss :  0.10539374530315399  Test L2 Loss :  0.14983785510063172  inv_L_scale:  [1.0, 1.0]
Epoch :  11  Time:  1.127  Rel. Train L2 Loss :  0.1022173175546858  Rel. Test L2 Loss :  0.10757746398448945  Test L2 Loss :  0.15283797383308412  inv_L_scale:  [1.0, 1.0]
Epoch :  12  Time:  1.142  Rel. Train L2 Loss :  0.1013310765226682  Rel. Test L2 Loss :  0.10443255066871643  Test L2 Loss :  0.14881815910339355  inv_L_scale:  [1.0, 1.0]
Epoch :  13  Time:  1.126  Rel. Train L2 Loss :  0.09927600095669428  Rel. Test L2 Loss :  0.10052051454782486  Test L2 Loss :  0.14326654732227326  inv_L_scale:  [1.0, 1.0]
Epoch :  14  Time:  1.126  Rel. Train L2 Loss :  0.09476010577546226  Rel. Test L2 Loss :  0.09491347312927247  Test L2 Loss :  0.13517520427703858  inv_L_scale:  [1.0, 1.0]
Epoch :  15  Time:  1.119  Rel. Train L2 Loss :  0.0919370381699668  Rel. Test L2 Loss :  0.0921489554643631  Test L2 Loss :  0.1315583562850952  inv_L_scale:  [1.0, 1.0]
Epoch :  16  Time:  1.118  Rel. Train L2 Loss :  0.0903245531850391  Rel. Test L2 Loss :  0.08958245247602463  Test L2 Loss :  0.1279776382446289  inv_L_scale:  [1.0, 1.0]
Epoch :  17  Time:  1.184  Rel. Train L2 Loss :  0.0898353625006146  Rel. Test L2 Loss :  0.0903709352016449  Test L2 Loss :  0.12899959981441497  inv_L_scale:  [1.0, 1.0]
Epoch :  18  Time:  1.132  Rel. Train L2 Loss :  0.08723498687148094  Rel. Test L2 Loss :  0.0857397699356079  Test L2 Loss :  0.12213706970214844  inv_L_scale:  [1.0, 1.0]
Epoch :  19  Time:  1.123  Rel. Train L2 Loss :  0.08522851487000783  Rel. Test L2 Loss :  0.0863056719303131  Test L2 Loss :  0.12312323033809662  inv_L_scale:  [1.0, 1.0]
Epoch :  20  Time:  1.117  Rel. Train L2 Loss :  0.08522358235385682  Rel. Test L2 Loss :  0.08622824788093567  Test L2 Loss :  0.12273698329925536  inv_L_scale:  [1.0, 1.0]
Epoch :  21  Time:  1.131  Rel. Train L2 Loss :  0.08457295831706789  Rel. Test L2 Loss :  0.08508021861314774  Test L2 Loss :  0.12168552100658417  inv_L_scale:  [1.0, 1.0]
Epoch :  22  Time:  1.218  Rel. Train L2 Loss :  0.0833455075820287  Rel. Test L2 Loss :  0.08550663232803345  Test L2 Loss :  0.1230753567814827  inv_L_scale:  [1.0, 1.0]
Epoch :  23  Time:  1.2  Rel. Train L2 Loss :  0.08394011027283138  Rel. Test L2 Loss :  0.08535269558429719  Test L2 Loss :  0.12269547641277313  inv_L_scale:  [1.0, 1.0]
Epoch :  24  Time:  1.123  Rel. Train L2 Loss :  0.08251843604776594  Rel. Test L2 Loss :  0.08222513258457184  Test L2 Loss :  0.11762373328208924  inv_L_scale:  [1.0, 1.0]
Epoch :  25  Time:  1.15  Rel. Train L2 Loss :  0.08186778898040453  Rel. Test L2 Loss :  0.08044552266597747  Test L2 Loss :  0.1152647402882576  inv_L_scale:  [1.0, 1.0]
Epoch :  26  Time:  1.12  Rel. Train L2 Loss :  0.08113796446058485  Rel. Test L2 Loss :  0.08130311161279678  Test L2 Loss :  0.1166138756275177  inv_L_scale:  [1.0, 1.0]
Epoch :  27  Time:  1.117  Rel. Train L2 Loss :  0.07897539569271936  Rel. Test L2 Loss :  0.08127180188894272  Test L2 Loss :  0.11665013283491135  inv_L_scale:  [1.0, 1.0]
Epoch :  28  Time:  1.111  Rel. Train L2 Loss :  0.08037216590510474  Rel. Test L2 Loss :  0.08120485991239548  Test L2 Loss :  0.11617733657360077  inv_L_scale:  [1.0, 1.0]
Epoch :  29  Time:  1.109  Rel. Train L2 Loss :  0.07831859237617916  Rel. Test L2 Loss :  0.08187226563692093  Test L2 Loss :  0.11823258697986602  inv_L_scale:  [1.0, 1.0]
Epoch :  30  Time:  1.112  Rel. Train L2 Loss :  0.07968606309758293  Rel. Test L2 Loss :  0.08429220378398895  Test L2 Loss :  0.12127589344978333  inv_L_scale:  [1.0, 1.0]
Epoch :  31  Time:  1.11  Rel. Train L2 Loss :  0.07836836520168516  Rel. Test L2 Loss :  0.07977916061878204  Test L2 Loss :  0.11454100012779236  inv_L_scale:  [1.0, 1.0]
Epoch :  32  Time:  1.139  Rel. Train L2 Loss :  0.0781227754553159  Rel. Test L2 Loss :  0.08557286083698273  Test L2 Loss :  0.12236286759376526  inv_L_scale:  [1.0, 1.0]
Epoch :  33  Time:  1.111  Rel. Train L2 Loss :  0.07780488868554433  Rel. Test L2 Loss :  0.07647985696792603  Test L2 Loss :  0.10945698618888855  inv_L_scale:  [1.0, 1.0]
Epoch :  34  Time:  1.116  Rel. Train L2 Loss :  0.0770848007996877  Rel. Test L2 Loss :  0.07815406054258346  Test L2 Loss :  0.11234549164772034  inv_L_scale:  [1.0, 1.0]
Epoch :  35  Time:  1.113  Rel. Train L2 Loss :  0.07607527643442154  Rel. Test L2 Loss :  0.075630804002285  Test L2 Loss :  0.10882390350103378  inv_L_scale:  [1.0, 1.0]
Epoch :  36  Time:  1.108  Rel. Train L2 Loss :  0.07916008565160963  Rel. Test L2 Loss :  0.07673521041870117  Test L2 Loss :  0.11026217967271805  inv_L_scale:  [1.0, 1.0]
Epoch :  37  Time:  1.11  Rel. Train L2 Loss :  0.07512953062852223  Rel. Test L2 Loss :  0.07493098556995392  Test L2 Loss :  0.10741316765546799  inv_L_scale:  [1.0, 1.0]
Epoch :  38  Time:  1.111  Rel. Train L2 Loss :  0.07378299918439653  Rel. Test L2 Loss :  0.07813173294067383  Test L2 Loss :  0.11165831804275513  inv_L_scale:  [1.0, 1.0]
Epoch :  39  Time:  1.116  Rel. Train L2 Loss :  0.0756267789999644  Rel. Test L2 Loss :  0.07696660876274108  Test L2 Loss :  0.11059333443641663  inv_L_scale:  [1.0, 1.0]
Epoch :  40  Time:  1.145  Rel. Train L2 Loss :  0.07441240837176641  Rel. Test L2 Loss :  0.07779796212911606  Test L2 Loss :  0.1118997299671173  inv_L_scale:  [1.0, 1.0]
Epoch :  41  Time:  1.126  Rel. Train L2 Loss :  0.07551601777474086  Rel. Test L2 Loss :  0.0735564050078392  Test L2 Loss :  0.10563474178314208  inv_L_scale:  [1.0, 1.0]
Epoch :  42  Time:  1.188  Rel. Train L2 Loss :  0.07410732355382707  Rel. Test L2 Loss :  0.07420121937990189  Test L2 Loss :  0.10670723170042037  inv_L_scale:  [1.0, 1.0]
Epoch :  43  Time:  1.136  Rel. Train L2 Loss :  0.07242807908190621  Rel. Test L2 Loss :  0.07706342160701751  Test L2 Loss :  0.11064506441354752  inv_L_scale:  [1.0, 1.0]
Epoch :  44  Time:  1.112  Rel. Train L2 Loss :  0.0736017022199101  Rel. Test L2 Loss :  0.07545472711324691  Test L2 Loss :  0.10867420196533203  inv_L_scale:  [1.0, 1.0]
Epoch :  45  Time:  1.121  Rel. Train L2 Loss :  0.07330600122610728  Rel. Test L2 Loss :  0.07487395375967026  Test L2 Loss :  0.1074586582183838  inv_L_scale:  [1.0, 1.0]
Epoch :  46  Time:  1.16  Rel. Train L2 Loss :  0.07376906438006295  Rel. Test L2 Loss :  0.0745826268196106  Test L2 Loss :  0.10738203018903732  inv_L_scale:  [1.0, 1.0]
Epoch :  47  Time:  1.129  Rel. Train L2 Loss :  0.07323527975214852  Rel. Test L2 Loss :  0.07376897633075714  Test L2 Loss :  0.10686093807220459  inv_L_scale:  [1.0, 1.0]
Epoch :  48  Time:  1.145  Rel. Train L2 Loss :  0.07399130009942585  Rel. Test L2 Loss :  0.0742775559425354  Test L2 Loss :  0.1061222842335701  inv_L_scale:  [1.0, 1.0]
Epoch :  49  Time:  1.14  Rel. Train L2 Loss :  0.07307334572076797  Rel. Test L2 Loss :  0.07065101236104965  Test L2 Loss :  0.10153147906064987  inv_L_scale:  [1.0, 1.0]
Epoch :  50  Time:  1.139  Rel. Train L2 Loss :  0.07319439315133625  Rel. Test L2 Loss :  0.07133374482393265  Test L2 Loss :  0.1024877941608429  inv_L_scale:  [1.0, 1.0]
Epoch :  51  Time:  1.136  Rel. Train L2 Loss :  0.07105301605330573  Rel. Test L2 Loss :  0.07551151514053345  Test L2 Loss :  0.1078826504945755  inv_L_scale:  [1.0, 1.0]
Epoch :  52  Time:  1.167  Rel. Train L2 Loss :  0.0743031914697753  Rel. Test L2 Loss :  0.07260271787643433  Test L2 Loss :  0.10441178947687149  inv_L_scale:  [1.0, 1.0]
Epoch :  53  Time:  1.194  Rel. Train L2 Loss :  0.0719745082490974  Rel. Test L2 Loss :  0.07537182152271271  Test L2 Loss :  0.10869097709655762  inv_L_scale:  [1.0, 1.0]
Epoch :  54  Time:  1.136  Rel. Train L2 Loss :  0.07130060911178589  Rel. Test L2 Loss :  0.0725089168548584  Test L2 Loss :  0.10477176815271377  inv_L_scale:  [1.0, 1.0]
Epoch :  55  Time:  1.122  Rel. Train L2 Loss :  0.07136078023248249  Rel. Test L2 Loss :  0.07787219583988189  Test L2 Loss :  0.11159472107887268  inv_L_scale:  [1.0, 1.0]
Epoch :  56  Time:  1.166  Rel. Train L2 Loss :  0.07125064651171366  Rel. Test L2 Loss :  0.07298775732517243  Test L2 Loss :  0.10469681650400162  inv_L_scale:  [1.0, 1.0]
Epoch :  57  Time:  1.186  Rel. Train L2 Loss :  0.07093953425685565  Rel. Test L2 Loss :  0.07110785156488418  Test L2 Loss :  0.10203536212444306  inv_L_scale:  [1.0, 1.0]
Epoch :  58  Time:  1.129  Rel. Train L2 Loss :  0.07031247191958957  Rel. Test L2 Loss :  0.07452532917261123  Test L2 Loss :  0.10669400870800018  inv_L_scale:  [1.0, 1.0]
Epoch :  59  Time:  1.113  Rel. Train L2 Loss :  0.07058512116471927  Rel. Test L2 Loss :  0.0698756730556488  Test L2 Loss :  0.10084503352642059  inv_L_scale:  [1.0, 1.0]
Epoch :  60  Time:  1.133  Rel. Train L2 Loss :  0.07017571896314621  Rel. Test L2 Loss :  0.07253151327371597  Test L2 Loss :  0.10467308193445206  inv_L_scale:  [1.0, 1.0]
Epoch :  61  Time:  1.152  Rel. Train L2 Loss :  0.07055823538038465  Rel. Test L2 Loss :  0.07178857058286667  Test L2 Loss :  0.10287302494049072  inv_L_scale:  [1.0, 1.0]
Epoch :  62  Time:  1.113  Rel. Train L2 Loss :  0.07002090752124786  Rel. Test L2 Loss :  0.07075155466794968  Test L2 Loss :  0.10180281192064285  inv_L_scale:  [1.0, 1.0]
Epoch :  63  Time:  1.18  Rel. Train L2 Loss :  0.07008756604459551  Rel. Test L2 Loss :  0.07011813223361969  Test L2 Loss :  0.10108463048934936  inv_L_scale:  [1.0, 1.0]
Epoch :  64  Time:  1.123  Rel. Train L2 Loss :  0.0705015464954906  Rel. Test L2 Loss :  0.07283920794725418  Test L2 Loss :  0.10476557672023773  inv_L_scale:  [1.0, 1.0]
Epoch :  65  Time:  1.117  Rel. Train L2 Loss :  0.07023365709516738  Rel. Test L2 Loss :  0.07362286329269409  Test L2 Loss :  0.10592847228050233  inv_L_scale:  [1.0, 1.0]
Epoch :  66  Time:  1.118  Rel. Train L2 Loss :  0.07053082704544067  Rel. Test L2 Loss :  0.07538758218288422  Test L2 Loss :  0.10834360897541045  inv_L_scale:  [1.0, 1.0]
Epoch :  67  Time:  1.151  Rel. Train L2 Loss :  0.06990285962820053  Rel. Test L2 Loss :  0.07229942232370376  Test L2 Loss :  0.10382921218872071  inv_L_scale:  [1.0, 1.0]
Epoch :  68  Time:  1.134  Rel. Train L2 Loss :  0.06946843134032356  Rel. Test L2 Loss :  0.07172737002372742  Test L2 Loss :  0.10338904440402985  inv_L_scale:  [1.0, 1.0]
Epoch :  69  Time:  1.128  Rel. Train L2 Loss :  0.0694624039861891  Rel. Test L2 Loss :  0.07067908465862274  Test L2 Loss :  0.10209299445152283  inv_L_scale:  [1.0, 1.0]
Epoch :  70  Time:  1.122  Rel. Train L2 Loss :  0.06914092865255143  Rel. Test L2 Loss :  0.07264803737401962  Test L2 Loss :  0.10435566276311875  inv_L_scale:  [1.0, 1.0]
Epoch :  71  Time:  1.18  Rel. Train L2 Loss :  0.06937598284747866  Rel. Test L2 Loss :  0.07202971160411835  Test L2 Loss :  0.10359107732772826  inv_L_scale:  [1.0, 1.0]
Epoch :  72  Time:  1.201  Rel. Train L2 Loss :  0.06865406887398826  Rel. Test L2 Loss :  0.06807839393615722  Test L2 Loss :  0.09864122271537781  inv_L_scale:  [1.0, 1.0]
Epoch :  73  Time:  1.134  Rel. Train L2 Loss :  0.06868316459986899  Rel. Test L2 Loss :  0.07223457336425781  Test L2 Loss :  0.10348185777664184  inv_L_scale:  [1.0, 1.0]
Epoch :  74  Time:  1.113  Rel. Train L2 Loss :  0.06783943861722946  Rel. Test L2 Loss :  0.07068023413419723  Test L2 Loss :  0.10155317068099975  inv_L_scale:  [1.0, 1.0]
Epoch :  75  Time:  1.128  Rel. Train L2 Loss :  0.0678402287264665  Rel. Test L2 Loss :  0.06958739131689072  Test L2 Loss :  0.10024887442588806  inv_L_scale:  [1.0, 1.0]
Epoch :  76  Time:  1.14  Rel. Train L2 Loss :  0.06814189202255673  Rel. Test L2 Loss :  0.07167093783617019  Test L2 Loss :  0.10359039664268493  inv_L_scale:  [1.0, 1.0]
Epoch :  77  Time:  1.134  Rel. Train L2 Loss :  0.06826158089770211  Rel. Test L2 Loss :  0.0745309630036354  Test L2 Loss :  0.10698273688554764  inv_L_scale:  [1.0, 1.0]
Epoch :  78  Time:  1.119  Rel. Train L2 Loss :  0.06907531284623676  Rel. Test L2 Loss :  0.06800459682941437  Test L2 Loss :  0.09860634893178939  inv_L_scale:  [1.0, 1.0]
Epoch :  79  Time:  1.139  Rel. Train L2 Loss :  0.06763214008675682  Rel. Test L2 Loss :  0.07165148288011551  Test L2 Loss :  0.10376405417919159  inv_L_scale:  [1.0, 1.0]
Epoch :  80  Time:  1.126  Rel. Train L2 Loss :  0.06763080891635682  Rel. Test L2 Loss :  0.06854841738939285  Test L2 Loss :  0.09860338389873505  inv_L_scale:  [1.0, 1.0]
Epoch :  81  Time:  1.125  Rel. Train L2 Loss :  0.06700457602739335  Rel. Test L2 Loss :  0.07038174390792847  Test L2 Loss :  0.10092542499303818  inv_L_scale:  [1.0, 1.0]
Epoch :  82  Time:  1.128  Rel. Train L2 Loss :  0.0668566704624229  Rel. Test L2 Loss :  0.07058683425188064  Test L2 Loss :  0.10142794400453567  inv_L_scale:  [1.0, 1.0]
Epoch :  83  Time:  1.138  Rel. Train L2 Loss :  0.0676883449819353  Rel. Test L2 Loss :  0.07047710299491883  Test L2 Loss :  0.1025087434053421  inv_L_scale:  [1.0, 1.0]
Epoch :  84  Time:  1.115  Rel. Train L2 Loss :  0.06777617077032726  Rel. Test L2 Loss :  0.07118149429559707  Test L2 Loss :  0.10256174623966217  inv_L_scale:  [1.0, 1.0]
Epoch :  85  Time:  1.111  Rel. Train L2 Loss :  0.07096233106321759  Rel. Test L2 Loss :  0.07150823295116425  Test L2 Loss :  0.10282993137836456  inv_L_scale:  [1.0, 1.0]
Epoch :  86  Time:  1.118  Rel. Train L2 Loss :  0.06734085392620828  Rel. Test L2 Loss :  0.06960667133331298  Test L2 Loss :  0.10064410626888275  inv_L_scale:  [1.0, 1.0]
Epoch :  87  Time:  1.145  Rel. Train L2 Loss :  0.06643114083343082  Rel. Test L2 Loss :  0.06945457220077515  Test L2 Loss :  0.10001699566841125  inv_L_scale:  [1.0, 1.0]
Epoch :  88  Time:  1.126  Rel. Train L2 Loss :  0.06756787584887611  Rel. Test L2 Loss :  0.067254296541214  Test L2 Loss :  0.09703654050827026  inv_L_scale:  [1.0, 1.0]
Epoch :  89  Time:  1.112  Rel. Train L2 Loss :  0.06645119388898214  Rel. Test L2 Loss :  0.06889416545629501  Test L2 Loss :  0.09961609303951263  inv_L_scale:  [1.0, 1.0]
Epoch :  90  Time:  1.113  Rel. Train L2 Loss :  0.06738490902715259  Rel. Test L2 Loss :  0.0686823782324791  Test L2 Loss :  0.09930229246616364  inv_L_scale:  [1.0, 1.0]
Epoch :  91  Time:  1.116  Rel. Train L2 Loss :  0.06671267141898474  Rel. Test L2 Loss :  0.06677339792251587  Test L2 Loss :  0.09664153784513474  inv_L_scale:  [1.0, 1.0]
Epoch :  92  Time:  1.117  Rel. Train L2 Loss :  0.06743300063742531  Rel. Test L2 Loss :  0.06713700950145722  Test L2 Loss :  0.09687218129634857  inv_L_scale:  [1.0, 1.0]
Epoch :  93  Time:  1.135  Rel. Train L2 Loss :  0.06622750928004582  Rel. Test L2 Loss :  0.06794431686401367  Test L2 Loss :  0.09825285285711288  inv_L_scale:  [1.0, 1.0]
Epoch :  94  Time:  1.133  Rel. Train L2 Loss :  0.06539024997088644  Rel. Test L2 Loss :  0.06713665723800659  Test L2 Loss :  0.09686658859252929  inv_L_scale:  [1.0, 1.0]
Epoch :  95  Time:  1.115  Rel. Train L2 Loss :  0.06596451143423716  Rel. Test L2 Loss :  0.06795469790697098  Test L2 Loss :  0.09806718409061432  inv_L_scale:  [1.0, 1.0]
Epoch :  96  Time:  1.112  Rel. Train L2 Loss :  0.06606654036376211  Rel. Test L2 Loss :  0.06777660012245178  Test L2 Loss :  0.09834536164999008  inv_L_scale:  [1.0, 1.0]
Epoch :  97  Time:  1.127  Rel. Train L2 Loss :  0.06546893364853329  Rel. Test L2 Loss :  0.06726490288972854  Test L2 Loss :  0.09748659193515778  inv_L_scale:  [1.0, 1.0]
Epoch :  98  Time:  1.117  Rel. Train L2 Loss :  0.06573924465311898  Rel. Test L2 Loss :  0.06620907783508301  Test L2 Loss :  0.09560078203678131  inv_L_scale:  [1.0, 1.0]
Epoch :  99  Time:  1.161  Rel. Train L2 Loss :  0.06506985995504591  Rel. Test L2 Loss :  0.06682099550962448  Test L2 Loss :  0.09698767244815826  inv_L_scale:  [1.0, 1.0]
Epoch :  100  Time:  1.144  Rel. Train L2 Loss :  0.06500067555242114  Rel. Test L2 Loss :  0.06530735462903976  Test L2 Loss :  0.09458616942167282  inv_L_scale:  [1.0, 1.0]
Epoch :  101  Time:  1.134  Rel. Train L2 Loss :  0.06665352798170514  Rel. Test L2 Loss :  0.06675878256559371  Test L2 Loss :  0.0961932983994484  inv_L_scale:  [1.0, 1.0]
Epoch :  102  Time:  1.118  Rel. Train L2 Loss :  0.0650263210799959  Rel. Test L2 Loss :  0.06814291208982468  Test L2 Loss :  0.09792515128850937  inv_L_scale:  [1.0, 1.0]
Epoch :  103  Time:  1.165  Rel. Train L2 Loss :  0.06487429867188135  Rel. Test L2 Loss :  0.06876351654529572  Test L2 Loss :  0.0994477853178978  inv_L_scale:  [1.0, 1.0]
Epoch :  104  Time:  1.134  Rel. Train L2 Loss :  0.06475326145688692  Rel. Test L2 Loss :  0.06634992688894271  Test L2 Loss :  0.09582360923290252  inv_L_scale:  [1.0, 1.0]
Epoch :  105  Time:  1.119  Rel. Train L2 Loss :  0.06841560539272096  Rel. Test L2 Loss :  0.06768168091773986  Test L2 Loss :  0.0979276168346405  inv_L_scale:  [1.0, 1.0]
Epoch :  106  Time:  1.163  Rel. Train L2 Loss :  0.06556949017776384  Rel. Test L2 Loss :  0.06706415861845016  Test L2 Loss :  0.09709400057792664  inv_L_scale:  [1.0, 1.0]
Epoch :  107  Time:  1.12  Rel. Train L2 Loss :  0.06541819216476547  Rel. Test L2 Loss :  0.06888798534870148  Test L2 Loss :  0.09930568009614944  inv_L_scale:  [1.0, 1.0]
Epoch :  108  Time:  1.114  Rel. Train L2 Loss :  0.06434159904718399  Rel. Test L2 Loss :  0.0657611522078514  Test L2 Loss :  0.09494134068489074  inv_L_scale:  [1.0, 1.0]
Epoch :  109  Time:  1.11  Rel. Train L2 Loss :  0.06360668773452441  Rel. Test L2 Loss :  0.06867974966764451  Test L2 Loss :  0.09849113941192628  inv_L_scale:  [1.0, 1.0]
Epoch :  110  Time:  1.112  Rel. Train L2 Loss :  0.0650428291161855  Rel. Test L2 Loss :  0.07522592693567276  Test L2 Loss :  0.1077898868918419  inv_L_scale:  [1.0, 1.0]
Epoch :  111  Time:  1.113  Rel. Train L2 Loss :  0.06506665743059582  Rel. Test L2 Loss :  0.06453764528036117  Test L2 Loss :  0.09330173492431641  inv_L_scale:  [1.0, 1.0]
Epoch :  112  Time:  1.11  Rel. Train L2 Loss :  0.06438929085930188  Rel. Test L2 Loss :  0.06478746682405472  Test L2 Loss :  0.09405044198036194  inv_L_scale:  [1.0, 1.0]
Epoch :  113  Time:  1.111  Rel. Train L2 Loss :  0.0641875695851114  Rel. Test L2 Loss :  0.06671545624732972  Test L2 Loss :  0.09615020543336868  inv_L_scale:  [1.0, 1.0]
Epoch :  114  Time:  1.115  Rel. Train L2 Loss :  0.06382166696919335  Rel. Test L2 Loss :  0.06889099299907685  Test L2 Loss :  0.09869063764810562  inv_L_scale:  [1.0, 1.0]
Epoch :  115  Time:  1.111  Rel. Train L2 Loss :  0.06397067884604137  Rel. Test L2 Loss :  0.06757744193077088  Test L2 Loss :  0.09750464618206024  inv_L_scale:  [1.0, 1.0]
Epoch :  116  Time:  1.114  Rel. Train L2 Loss :  0.06469102044900259  Rel. Test L2 Loss :  0.06735947489738464  Test L2 Loss :  0.09701538652181625  inv_L_scale:  [1.0, 1.0]
Epoch :  117  Time:  1.137  Rel. Train L2 Loss :  0.06456631784637769  Rel. Test L2 Loss :  0.06549293965101242  Test L2 Loss :  0.09464956521987915  inv_L_scale:  [1.0, 1.0]
Epoch :  118  Time:  1.119  Rel. Train L2 Loss :  0.06422454837295744  Rel. Test L2 Loss :  0.06395654767751693  Test L2 Loss :  0.09257261127233506  inv_L_scale:  [1.0, 1.0]
Epoch :  119  Time:  1.11  Rel. Train L2 Loss :  0.06426057956284947  Rel. Test L2 Loss :  0.06421572834253311  Test L2 Loss :  0.0929754301905632  inv_L_scale:  [1.0, 1.0]
Epoch :  120  Time:  1.113  Rel. Train L2 Loss :  0.06291130181815889  Rel. Test L2 Loss :  0.06332518488168716  Test L2 Loss :  0.09165617734193802  inv_L_scale:  [1.0, 1.0]
Epoch :  121  Time:  1.11  Rel. Train L2 Loss :  0.0632589561243852  Rel. Test L2 Loss :  0.0701934090256691  Test L2 Loss :  0.10132861852645875  inv_L_scale:  [1.0, 1.0]
Epoch :  122  Time:  1.109  Rel. Train L2 Loss :  0.06338276161087884  Rel. Test L2 Loss :  0.06621002823114396  Test L2 Loss :  0.09576934516429901  inv_L_scale:  [1.0, 1.0]
Epoch :  123  Time:  1.108  Rel. Train L2 Loss :  0.06307295229699876  Rel. Test L2 Loss :  0.06318520992994309  Test L2 Loss :  0.09156219810247421  inv_L_scale:  [1.0, 1.0]
Epoch :  124  Time:  1.143  Rel. Train L2 Loss :  0.06320328311787711  Rel. Test L2 Loss :  0.06635264068841934  Test L2 Loss :  0.09548109948635101  inv_L_scale:  [1.0, 1.0]
Epoch :  125  Time:  1.124  Rel. Train L2 Loss :  0.06303094148635864  Rel. Test L2 Loss :  0.0665837761759758  Test L2 Loss :  0.0964781904220581  inv_L_scale:  [1.0, 1.0]
Epoch :  126  Time:  1.115  Rel. Train L2 Loss :  0.06345333367586135  Rel. Test L2 Loss :  0.06371871799230576  Test L2 Loss :  0.09234115719795227  inv_L_scale:  [1.0, 1.0]
Epoch :  127  Time:  1.14  Rel. Train L2 Loss :  0.06381097661124335  Rel. Test L2 Loss :  0.06411532789468766  Test L2 Loss :  0.09276566684246063  inv_L_scale:  [1.0, 1.0]
Epoch :  128  Time:  1.125  Rel. Train L2 Loss :  0.0631543029844761  Rel. Test L2 Loss :  0.06396986126899719  Test L2 Loss :  0.09253834784030915  inv_L_scale:  [1.0, 1.0]
Epoch :  129  Time:  1.114  Rel. Train L2 Loss :  0.062568502475818  Rel. Test L2 Loss :  0.06715756565332413  Test L2 Loss :  0.09695731163024902  inv_L_scale:  [1.0, 1.0]
Epoch :  130  Time:  1.112  Rel. Train L2 Loss :  0.06418991261058384  Rel. Test L2 Loss :  0.06608457446098327  Test L2 Loss :  0.09553643971681595  inv_L_scale:  [1.0, 1.0]
Epoch :  131  Time:  1.109  Rel. Train L2 Loss :  0.06262390835417642  Rel. Test L2 Loss :  0.0654625016450882  Test L2 Loss :  0.09432779014110565  inv_L_scale:  [1.0, 1.0]
Epoch :  132  Time:  1.114  Rel. Train L2 Loss :  0.0652880405055152  Rel. Test L2 Loss :  0.06490123599767685  Test L2 Loss :  0.09376591295003892  inv_L_scale:  [1.0, 1.0]
Epoch :  133  Time:  1.111  Rel. Train L2 Loss :  0.062249159349335566  Rel. Test L2 Loss :  0.0629795402288437  Test L2 Loss :  0.09075725674629212  inv_L_scale:  [1.0, 1.0]
Epoch :  134  Time:  1.111  Rel. Train L2 Loss :  0.062141802145375145  Rel. Test L2 Loss :  0.06348159492015838  Test L2 Loss :  0.09199073851108551  inv_L_scale:  [1.0, 1.0]
Epoch :  135  Time:  1.109  Rel. Train L2 Loss :  0.06304126070605384  Rel. Test L2 Loss :  0.06582969978451729  Test L2 Loss :  0.09487774491310119  inv_L_scale:  [1.0, 1.0]
Epoch :  136  Time:  1.132  Rel. Train L2 Loss :  0.06284002946482764  Rel. Test L2 Loss :  0.06375673592090607  Test L2 Loss :  0.09222061216831207  inv_L_scale:  [1.0, 1.0]
Epoch :  137  Time:  1.111  Rel. Train L2 Loss :  0.062176170316007404  Rel. Test L2 Loss :  0.06522346198558808  Test L2 Loss :  0.09425155580043793  inv_L_scale:  [1.0, 1.0]
Epoch :  138  Time:  1.115  Rel. Train L2 Loss :  0.06361413790120019  Rel. Test L2 Loss :  0.06423784345388413  Test L2 Loss :  0.09284952729940414  inv_L_scale:  [1.0, 1.0]
Epoch :  139  Time:  1.157  Rel. Train L2 Loss :  0.061955207304822076  Rel. Test L2 Loss :  0.06304936379194259  Test L2 Loss :  0.09136777192354202  inv_L_scale:  [1.0, 1.0]
Epoch :  140  Time:  1.161  Rel. Train L2 Loss :  0.06195856614245309  Rel. Test L2 Loss :  0.06705499947071075  Test L2 Loss :  0.09696341216564179  inv_L_scale:  [1.0, 1.0]
Epoch :  141  Time:  1.128  Rel. Train L2 Loss :  0.0658377965953615  Rel. Test L2 Loss :  0.06494187325239181  Test L2 Loss :  0.0939216250181198  inv_L_scale:  [1.0, 1.0]
Epoch :  142  Time:  1.114  Rel. Train L2 Loss :  0.061900767121050096  Rel. Test L2 Loss :  0.06398245662450791  Test L2 Loss :  0.09210331052541733  inv_L_scale:  [1.0, 1.0]
Epoch :  143  Time:  1.118  Rel. Train L2 Loss :  0.062226794825659855  Rel. Test L2 Loss :  0.06510328948497772  Test L2 Loss :  0.09421114563941956  inv_L_scale:  [1.0, 1.0]
Epoch :  144  Time:  1.113  Rel. Train L2 Loss :  0.06220869008037779  Rel. Test L2 Loss :  0.06227454721927643  Test L2 Loss :  0.09026369690895081  inv_L_scale:  [1.0, 1.0]
Epoch :  145  Time:  1.113  Rel. Train L2 Loss :  0.06219713999165429  Rel. Test L2 Loss :  0.06254741042852402  Test L2 Loss :  0.09060139447450638  inv_L_scale:  [1.0, 1.0]
Epoch :  146  Time:  1.111  Rel. Train L2 Loss :  0.06177372417516178  Rel. Test L2 Loss :  0.06434098154306411  Test L2 Loss :  0.09333428740501404  inv_L_scale:  [1.0, 1.0]
Epoch :  147  Time:  1.114  Rel. Train L2 Loss :  0.0614826709859901  Rel. Test L2 Loss :  0.06517102032899856  Test L2 Loss :  0.09454682469367981  inv_L_scale:  [1.0, 1.0]
Epoch :  148  Time:  1.127  Rel. Train L2 Loss :  0.06186028513643477  Rel. Test L2 Loss :  0.06400690644979477  Test L2 Loss :  0.09304037243127823  inv_L_scale:  [1.0, 1.0]
Epoch :  149  Time:  1.114  Rel. Train L2 Loss :  0.06185425991813342  Rel. Test L2 Loss :  0.06287852019071578  Test L2 Loss :  0.0910539424419403  inv_L_scale:  [1.0, 1.0]
Epoch :  150  Time:  1.109  Rel. Train L2 Loss :  0.06143568833669027  Rel. Test L2 Loss :  0.06283115342259407  Test L2 Loss :  0.09136247128248215  inv_L_scale:  [1.0, 1.0]
Epoch :  151  Time:  1.112  Rel. Train L2 Loss :  0.06219859974251853  Rel. Test L2 Loss :  0.06255958765745163  Test L2 Loss :  0.09046700775623322  inv_L_scale:  [1.0, 1.0]
Epoch :  152  Time:  1.116  Rel. Train L2 Loss :  0.06126592801676856  Rel. Test L2 Loss :  0.06268498897552491  Test L2 Loss :  0.09054120659828185  inv_L_scale:  [1.0, 1.0]
Epoch :  153  Time:  1.151  Rel. Train L2 Loss :  0.061300613946384856  Rel. Test L2 Loss :  0.06283441454172134  Test L2 Loss :  0.09109369248151779  inv_L_scale:  [1.0, 1.0]
Epoch :  154  Time:  1.139  Rel. Train L2 Loss :  0.06069869187143114  Rel. Test L2 Loss :  0.0658096906542778  Test L2 Loss :  0.09480813503265381  inv_L_scale:  [1.0, 1.0]
Epoch :  155  Time:  1.124  Rel. Train L2 Loss :  0.06310908459954792  Rel. Test L2 Loss :  0.06463704615831375  Test L2 Loss :  0.09414511144161225  inv_L_scale:  [1.0, 1.0]
Epoch :  156  Time:  1.112  Rel. Train L2 Loss :  0.060922497246000504  Rel. Test L2 Loss :  0.06319221287965775  Test L2 Loss :  0.09152501940727234  inv_L_scale:  [1.0, 1.0]
Epoch :  157  Time:  1.112  Rel. Train L2 Loss :  0.061198598113324905  Rel. Test L2 Loss :  0.06240061163902283  Test L2 Loss :  0.0903735727071762  inv_L_scale:  [1.0, 1.0]
Epoch :  158  Time:  1.114  Rel. Train L2 Loss :  0.06030972884760963  Rel. Test L2 Loss :  0.06465073227882386  Test L2 Loss :  0.09362853586673736  inv_L_scale:  [1.0, 1.0]
Epoch :  159  Time:  1.154  Rel. Train L2 Loss :  0.06163407544294993  Rel. Test L2 Loss :  0.06385885521769524  Test L2 Loss :  0.09270171105861663  inv_L_scale:  [1.0, 1.0]
Epoch :  160  Time:  1.225  Rel. Train L2 Loss :  0.06148500454094675  Rel. Test L2 Loss :  0.06236849993467331  Test L2 Loss :  0.09034319221973419  inv_L_scale:  [1.0, 1.0]
Epoch :  161  Time:  1.145  Rel. Train L2 Loss :  0.06046909385257297  Rel. Test L2 Loss :  0.06234417766332626  Test L2 Loss :  0.090113565325737  inv_L_scale:  [1.0, 1.0]
Epoch :  162  Time:  1.146  Rel. Train L2 Loss :  0.06111079686217838  Rel. Test L2 Loss :  0.06169332802295685  Test L2 Loss :  0.0894589078426361  inv_L_scale:  [1.0, 1.0]
Epoch :  163  Time:  1.119  Rel. Train L2 Loss :  0.0606739755305979  Rel. Test L2 Loss :  0.061348763704299925  Test L2 Loss :  0.08920953124761581  inv_L_scale:  [1.0, 1.0]
Epoch :  164  Time:  1.119  Rel. Train L2 Loss :  0.06062324658036232  Rel. Test L2 Loss :  0.062151726186275486  Test L2 Loss :  0.09002804338932037  inv_L_scale:  [1.0, 1.0]
Epoch :  165  Time:  1.112  Rel. Train L2 Loss :  0.06130651199155383  Rel. Test L2 Loss :  0.06199037402868271  Test L2 Loss :  0.08987382590770722  inv_L_scale:  [1.0, 1.0]
Epoch :  166  Time:  1.109  Rel. Train L2 Loss :  0.061230978104803296  Rel. Test L2 Loss :  0.06336060076951981  Test L2 Loss :  0.09192034810781478  inv_L_scale:  [1.0, 1.0]
Epoch :  167  Time:  1.134  Rel. Train L2 Loss :  0.060564745201004876  Rel. Test L2 Loss :  0.06240873694419861  Test L2 Loss :  0.08993798732757569  inv_L_scale:  [1.0, 1.0]
Epoch :  168  Time:  1.116  Rel. Train L2 Loss :  0.060567639006508724  Rel. Test L2 Loss :  0.06259381145238876  Test L2 Loss :  0.0906483507156372  inv_L_scale:  [1.0, 1.0]
Epoch :  169  Time:  1.116  Rel. Train L2 Loss :  0.060633702509933045  Rel. Test L2 Loss :  0.062432644963264464  Test L2 Loss :  0.09017608642578125  inv_L_scale:  [1.0, 1.0]
Epoch :  170  Time:  1.144  Rel. Train L2 Loss :  0.06060939374897215  Rel. Test L2 Loss :  0.06528385728597641  Test L2 Loss :  0.09485413849353791  inv_L_scale:  [1.0, 1.0]
Epoch :  171  Time:  1.142  Rel. Train L2 Loss :  0.06052667111158371  Rel. Test L2 Loss :  0.06242675870656967  Test L2 Loss :  0.09053955227136612  inv_L_scale:  [1.0, 1.0]
Epoch :  172  Time:  1.114  Rel. Train L2 Loss :  0.06075735287533866  Rel. Test L2 Loss :  0.0621583890914917  Test L2 Loss :  0.09035694003105163  inv_L_scale:  [1.0, 1.0]
Epoch :  173  Time:  1.118  Rel. Train L2 Loss :  0.06104136563009686  Rel. Test L2 Loss :  0.06189410433173179  Test L2 Loss :  0.08937082052230835  inv_L_scale:  [1.0, 1.0]
Epoch :  174  Time:  1.114  Rel. Train L2 Loss :  0.060406489107343884  Rel. Test L2 Loss :  0.061636273860931394  Test L2 Loss :  0.08929592907428742  inv_L_scale:  [1.0, 1.0]
Epoch :  175  Time:  1.144  Rel. Train L2 Loss :  0.06090621421734492  Rel. Test L2 Loss :  0.061740860790014264  Test L2 Loss :  0.08954803973436355  inv_L_scale:  [1.0, 1.0]
Epoch :  176  Time:  1.141  Rel. Train L2 Loss :  0.05965903533829583  Rel. Test L2 Loss :  0.06238757640123367  Test L2 Loss :  0.0900898802280426  inv_L_scale:  [1.0, 1.0]
Epoch :  177  Time:  1.161  Rel. Train L2 Loss :  0.06021781371699439  Rel. Test L2 Loss :  0.06197631001472473  Test L2 Loss :  0.08957427948713302  inv_L_scale:  [1.0, 1.0]
Epoch :  178  Time:  1.151  Rel. Train L2 Loss :  0.06089635007911258  Rel. Test L2 Loss :  0.06177952975034714  Test L2 Loss :  0.08967309027910232  inv_L_scale:  [1.0, 1.0]
Epoch :  179  Time:  1.17  Rel. Train L2 Loss :  0.05981318586402469  Rel. Test L2 Loss :  0.06251855552196503  Test L2 Loss :  0.09093937814235688  inv_L_scale:  [1.0, 1.0]
Epoch :  180  Time:  1.148  Rel. Train L2 Loss :  0.06038216975000169  Rel. Test L2 Loss :  0.062355409860610965  Test L2 Loss :  0.09030144721269608  inv_L_scale:  [1.0, 1.0]
Epoch :  181  Time:  1.108  Rel. Train L2 Loss :  0.06021472705735101  Rel. Test L2 Loss :  0.062425779402256014  Test L2 Loss :  0.0904576027393341  inv_L_scale:  [1.0, 1.0]
Epoch :  182  Time:  1.115  Rel. Train L2 Loss :  0.05973574082056681  Rel. Test L2 Loss :  0.06025070488452911  Test L2 Loss :  0.08753576010465622  inv_L_scale:  [1.0, 1.0]
Epoch :  183  Time:  1.149  Rel. Train L2 Loss :  0.059610865265131  Rel. Test L2 Loss :  0.06273299872875214  Test L2 Loss :  0.09071127414703369  inv_L_scale:  [1.0, 1.0]
Epoch :  184  Time:  1.159  Rel. Train L2 Loss :  0.060030831231011286  Rel. Test L2 Loss :  0.061878543496131894  Test L2 Loss :  0.08930477887392044  inv_L_scale:  [1.0, 1.0]
Epoch :  185  Time:  1.178  Rel. Train L2 Loss :  0.06011837869882584  Rel. Test L2 Loss :  0.06432188987731934  Test L2 Loss :  0.09307073652744294  inv_L_scale:  [1.0, 1.0]
Epoch :  186  Time:  1.159  Rel. Train L2 Loss :  0.059739065567652384  Rel. Test L2 Loss :  0.06278563603758812  Test L2 Loss :  0.09073616325855255  inv_L_scale:  [1.0, 1.0]
Epoch :  187  Time:  1.125  Rel. Train L2 Loss :  0.05986612896124522  Rel. Test L2 Loss :  0.06093768805265427  Test L2 Loss :  0.08835686087608337  inv_L_scale:  [1.0, 1.0]
Epoch :  188  Time:  1.112  Rel. Train L2 Loss :  0.05994170900848177  Rel. Test L2 Loss :  0.06226344585418701  Test L2 Loss :  0.09009890526533126  inv_L_scale:  [1.0, 1.0]
Epoch :  189  Time:  1.173  Rel. Train L2 Loss :  0.0594384828209877  Rel. Test L2 Loss :  0.06163769021630287  Test L2 Loss :  0.08935113847255707  inv_L_scale:  [1.0, 1.0]
Epoch :  190  Time:  1.142  Rel. Train L2 Loss :  0.05945105587442716  Rel. Test L2 Loss :  0.06263360500335693  Test L2 Loss :  0.09087582290172577  inv_L_scale:  [1.0, 1.0]
Epoch :  191  Time:  1.141  Rel. Train L2 Loss :  0.05945489452944862  Rel. Test L2 Loss :  0.06164259105920791  Test L2 Loss :  0.0894381383061409  inv_L_scale:  [1.0, 1.0]
Epoch :  192  Time:  1.132  Rel. Train L2 Loss :  0.059030408991707695  Rel. Test L2 Loss :  0.06099228098988533  Test L2 Loss :  0.08864435136318206  inv_L_scale:  [1.0, 1.0]
Epoch :  193  Time:  1.122  Rel. Train L2 Loss :  0.06022168421083027  Rel. Test L2 Loss :  0.0634445971250534  Test L2 Loss :  0.09188772320747375  inv_L_scale:  [1.0, 1.0]
Epoch :  194  Time:  1.111  Rel. Train L2 Loss :  0.059225050111611686  Rel. Test L2 Loss :  0.06155987590551376  Test L2 Loss :  0.089128557741642  inv_L_scale:  [1.0, 1.0]
Epoch :  195  Time:  1.115  Rel. Train L2 Loss :  0.05907208134730657  Rel. Test L2 Loss :  0.06034997284412384  Test L2 Loss :  0.08752561450004577  inv_L_scale:  [1.0, 1.0]
Epoch :  196  Time:  1.112  Rel. Train L2 Loss :  0.058979644543594785  Rel. Test L2 Loss :  0.06072028800845146  Test L2 Loss :  0.08796595573425293  inv_L_scale:  [1.0, 1.0]
Epoch :  197  Time:  1.114  Rel. Train L2 Loss :  0.05946745617522134  Rel. Test L2 Loss :  0.06348431527614594  Test L2 Loss :  0.09226223945617676  inv_L_scale:  [1.0, 1.0]
Epoch :  198  Time:  1.119  Rel. Train L2 Loss :  0.05940943916638692  Rel. Test L2 Loss :  0.061871711760759354  Test L2 Loss :  0.09020697832107544  inv_L_scale:  [1.0, 1.0]
Epoch :  199  Time:  1.113  Rel. Train L2 Loss :  0.05939502330289947  Rel. Test L2 Loss :  0.06375573351979255  Test L2 Loss :  0.09189240992069245  inv_L_scale:  [1.0, 1.0]
Epoch :  200  Time:  1.114  Rel. Train L2 Loss :  0.059009011818303  Rel. Test L2 Loss :  0.060445643067359923  Test L2 Loss :  0.08750993967056274  inv_L_scale:  [1.0, 1.0]
Epoch :  201  Time:  1.113  Rel. Train L2 Loss :  0.05881964299413893  Rel. Test L2 Loss :  0.06197561949491501  Test L2 Loss :  0.08936847329139709  inv_L_scale:  [1.0, 1.0]
Epoch :  202  Time:  1.112  Rel. Train L2 Loss :  0.05953596346908145  Rel. Test L2 Loss :  0.06077788531780243  Test L2 Loss :  0.08805643916130065  inv_L_scale:  [1.0, 1.0]
Epoch :  203  Time:  1.112  Rel. Train L2 Loss :  0.059286233650313484  Rel. Test L2 Loss :  0.06177846223115921  Test L2 Loss :  0.0900139194726944  inv_L_scale:  [1.0, 1.0]
Epoch :  204  Time:  1.135  Rel. Train L2 Loss :  0.05903587821457121  Rel. Test L2 Loss :  0.0627250936627388  Test L2 Loss :  0.09055848956108094  inv_L_scale:  [1.0, 1.0]
Epoch :  205  Time:  1.188  Rel. Train L2 Loss :  0.0597237505349848  Rel. Test L2 Loss :  0.060645616203546526  Test L2 Loss :  0.08800041049718857  inv_L_scale:  [1.0, 1.0]
Epoch :  206  Time:  1.183  Rel. Train L2 Loss :  0.05892088732785649  Rel. Test L2 Loss :  0.06172335684299469  Test L2 Loss :  0.08939219415187835  inv_L_scale:  [1.0, 1.0]
Epoch :  207  Time:  1.157  Rel. Train L2 Loss :  0.05891744209660424  Rel. Test L2 Loss :  0.060749565958976744  Test L2 Loss :  0.0877754682302475  inv_L_scale:  [1.0, 1.0]
Epoch :  208  Time:  1.113  Rel. Train L2 Loss :  0.0584673042760955  Rel. Test L2 Loss :  0.060640471875667575  Test L2 Loss :  0.08772145360708236  inv_L_scale:  [1.0, 1.0]
Epoch :  209  Time:  1.109  Rel. Train L2 Loss :  0.05847240265872743  Rel. Test L2 Loss :  0.06351437091827393  Test L2 Loss :  0.09162737965583802  inv_L_scale:  [1.0, 1.0]
Epoch :  210  Time:  1.107  Rel. Train L2 Loss :  0.058616899847984315  Rel. Test L2 Loss :  0.06024528563022614  Test L2 Loss :  0.08750165909528733  inv_L_scale:  [1.0, 1.0]
Epoch :  211  Time:  1.107  Rel. Train L2 Loss :  0.05921595424413681  Rel. Test L2 Loss :  0.0612323959171772  Test L2 Loss :  0.08908090353012085  inv_L_scale:  [1.0, 1.0]
Epoch :  212  Time:  1.121  Rel. Train L2 Loss :  0.05848016248808967  Rel. Test L2 Loss :  0.060686476826667786  Test L2 Loss :  0.08769210398197175  inv_L_scale:  [1.0, 1.0]
Epoch :  213  Time:  1.12  Rel. Train L2 Loss :  0.0582139852643013  Rel. Test L2 Loss :  0.061108242571353916  Test L2 Loss :  0.08833148002624512  inv_L_scale:  [1.0, 1.0]
Epoch :  214  Time:  1.113  Rel. Train L2 Loss :  0.05933771941396925  Rel. Test L2 Loss :  0.05948935121297836  Test L2 Loss :  0.08639784067869187  inv_L_scale:  [1.0, 1.0]
Epoch :  215  Time:  1.107  Rel. Train L2 Loss :  0.058441196646955275  Rel. Test L2 Loss :  0.06132664546370506  Test L2 Loss :  0.08883796751499176  inv_L_scale:  [1.0, 1.0]
Epoch :  216  Time:  1.123  Rel. Train L2 Loss :  0.058106211490101284  Rel. Test L2 Loss :  0.06075661808252335  Test L2 Loss :  0.0877215725183487  inv_L_scale:  [1.0, 1.0]
Epoch :  217  Time:  1.116  Rel. Train L2 Loss :  0.05903317072325283  Rel. Test L2 Loss :  0.06198633417487145  Test L2 Loss :  0.08958694696426392  inv_L_scale:  [1.0, 1.0]
Epoch :  218  Time:  1.112  Rel. Train L2 Loss :  0.058095661401748655  Rel. Test L2 Loss :  0.058796394467353824  Test L2 Loss :  0.08536312639713288  inv_L_scale:  [1.0, 1.0]
Epoch :  219  Time:  1.11  Rel. Train L2 Loss :  0.05832406259245343  Rel. Test L2 Loss :  0.06205464452505112  Test L2 Loss :  0.08969848752021789  inv_L_scale:  [1.0, 1.0]
Epoch :  220  Time:  1.109  Rel. Train L2 Loss :  0.05824968232048883  Rel. Test L2 Loss :  0.060091813802719114  Test L2 Loss :  0.08719668358564377  inv_L_scale:  [1.0, 1.0]
Epoch :  221  Time:  1.108  Rel. Train L2 Loss :  0.05815384584996435  Rel. Test L2 Loss :  0.05921430438756943  Test L2 Loss :  0.08582960784435273  inv_L_scale:  [1.0, 1.0]
Epoch :  222  Time:  1.113  Rel. Train L2 Loss :  0.05820509430434969  Rel. Test L2 Loss :  0.06047373428940773  Test L2 Loss :  0.08764065980911255  inv_L_scale:  [1.0, 1.0]
Epoch :  223  Time:  1.127  Rel. Train L2 Loss :  0.0585648675262928  Rel. Test L2 Loss :  0.060262169241905215  Test L2 Loss :  0.08763851284980774  inv_L_scale:  [1.0, 1.0]
Epoch :  224  Time:  1.112  Rel. Train L2 Loss :  0.05842606122295062  Rel. Test L2 Loss :  0.059646286517381665  Test L2 Loss :  0.08660578310489654  inv_L_scale:  [1.0, 1.0]
Epoch :  225  Time:  1.11  Rel. Train L2 Loss :  0.05747562237911754  Rel. Test L2 Loss :  0.06002562284469604  Test L2 Loss :  0.08737155079841613  inv_L_scale:  [1.0, 1.0]
Epoch :  226  Time:  1.11  Rel. Train L2 Loss :  0.059653440051608615  Rel. Test L2 Loss :  0.06163856223225594  Test L2 Loss :  0.0895598977804184  inv_L_scale:  [1.0, 1.0]
Epoch :  227  Time:  1.161  Rel. Train L2 Loss :  0.058982239431805084  Rel. Test L2 Loss :  0.05953050687909126  Test L2 Loss :  0.08646423399448394  inv_L_scale:  [1.0, 1.0]
Epoch :  228  Time:  1.113  Rel. Train L2 Loss :  0.057324396951331034  Rel. Test L2 Loss :  0.06026878714561462  Test L2 Loss :  0.08731361091136933  inv_L_scale:  [1.0, 1.0]
Epoch :  229  Time:  1.107  Rel. Train L2 Loss :  0.05745417517092493  Rel. Test L2 Loss :  0.059846615493297575  Test L2 Loss :  0.08677480340003968  inv_L_scale:  [1.0, 1.0]
Epoch :  230  Time:  1.107  Rel. Train L2 Loss :  0.057805238631036544  Rel. Test L2 Loss :  0.061133347004652026  Test L2 Loss :  0.0886416655778885  inv_L_scale:  [1.0, 1.0]
Epoch :  231  Time:  1.117  Rel. Train L2 Loss :  0.058796098000473446  Rel. Test L2 Loss :  0.06171047002077103  Test L2 Loss :  0.08930504620075226  inv_L_scale:  [1.0, 1.0]
Epoch :  232  Time:  1.143  Rel. Train L2 Loss :  0.05792394078440136  Rel. Test L2 Loss :  0.05916161477565765  Test L2 Loss :  0.08589414715766906  inv_L_scale:  [1.0, 1.0]
Epoch :  233  Time:  1.137  Rel. Train L2 Loss :  0.057542841070228154  Rel. Test L2 Loss :  0.05892583340406418  Test L2 Loss :  0.08548817336559296  inv_L_scale:  [1.0, 1.0]
Epoch :  234  Time:  1.115  Rel. Train L2 Loss :  0.057417923890882065  Rel. Test L2 Loss :  0.06341556996107102  Test L2 Loss :  0.09199081569910049  inv_L_scale:  [1.0, 1.0]
Epoch :  235  Time:  1.113  Rel. Train L2 Loss :  0.058018148475223116  Rel. Test L2 Loss :  0.05921715781092644  Test L2 Loss :  0.08567079305648803  inv_L_scale:  [1.0, 1.0]
Epoch :  236  Time:  1.111  Rel. Train L2 Loss :  0.05713624022073216  Rel. Test L2 Loss :  0.058021217584609985  Test L2 Loss :  0.08412074208259583  inv_L_scale:  [1.0, 1.0]
Epoch :  237  Time:  1.119  Rel. Train L2 Loss :  0.05767076460851563  Rel. Test L2 Loss :  0.05962305679917335  Test L2 Loss :  0.08658907383680343  inv_L_scale:  [1.0, 1.0]
Epoch :  238  Time:  1.113  Rel. Train L2 Loss :  0.05720111452870899  Rel. Test L2 Loss :  0.060234893411397934  Test L2 Loss :  0.08734071135520935  inv_L_scale:  [1.0, 1.0]
Epoch :  239  Time:  1.108  Rel. Train L2 Loss :  0.05762642814053429  Rel. Test L2 Loss :  0.0589370122551918  Test L2 Loss :  0.08570877850055694  inv_L_scale:  [1.0, 1.0]
Epoch :  240  Time:  1.11  Rel. Train L2 Loss :  0.05697581234905455  Rel. Test L2 Loss :  0.058897201418876645  Test L2 Loss :  0.0852121376991272  inv_L_scale:  [1.0, 1.0]
Epoch :  241  Time:  1.112  Rel. Train L2 Loss :  0.05737421792414453  Rel. Test L2 Loss :  0.060272318124771115  Test L2 Loss :  0.08685926914215088  inv_L_scale:  [1.0, 1.0]
Epoch :  242  Time:  1.11  Rel. Train L2 Loss :  0.05752217632200983  Rel. Test L2 Loss :  0.059693554788827895  Test L2 Loss :  0.08636640131473541  inv_L_scale:  [1.0, 1.0]
Epoch :  243  Time:  1.109  Rel. Train L2 Loss :  0.058229611333873534  Rel. Test L2 Loss :  0.060023353099823  Test L2 Loss :  0.08742961555719375  inv_L_scale:  [1.0, 1.0]
Epoch :  244  Time:  1.111  Rel. Train L2 Loss :  0.058324278328153824  Rel. Test L2 Loss :  0.058957555443048475  Test L2 Loss :  0.08547337472438812  inv_L_scale:  [1.0, 1.0]
Epoch :  245  Time:  1.109  Rel. Train L2 Loss :  0.056972787115308975  Rel. Test L2 Loss :  0.05949114546179771  Test L2 Loss :  0.08638287216424942  inv_L_scale:  [1.0, 1.0]
Epoch :  246  Time:  1.109  Rel. Train L2 Loss :  0.05693031228250928  Rel. Test L2 Loss :  0.05930251657962799  Test L2 Loss :  0.08578081846237183  inv_L_scale:  [1.0, 1.0]
Epoch :  247  Time:  1.112  Rel. Train L2 Loss :  0.05705322972602314  Rel. Test L2 Loss :  0.060589486956596376  Test L2 Loss :  0.08744999378919602  inv_L_scale:  [1.0, 1.0]
Epoch :  248  Time:  1.111  Rel. Train L2 Loss :  0.05689907549156083  Rel. Test L2 Loss :  0.05973262727260589  Test L2 Loss :  0.08658093512058258  inv_L_scale:  [1.0, 1.0]
Epoch :  249  Time:  1.109  Rel. Train L2 Loss :  0.05735455807712343  Rel. Test L2 Loss :  0.059165549278259275  Test L2 Loss :  0.08554666817188263  inv_L_scale:  [1.0, 1.0]
Epoch :  250  Time:  1.125  Rel. Train L2 Loss :  0.05722801695267359  Rel. Test L2 Loss :  0.05892015814781189  Test L2 Loss :  0.08544969707727432  inv_L_scale:  [1.0, 1.0]
Epoch :  251  Time:  1.114  Rel. Train L2 Loss :  0.05703211921784613  Rel. Test L2 Loss :  0.05780030995607376  Test L2 Loss :  0.08373154789209365  inv_L_scale:  [1.0, 1.0]
Epoch :  252  Time:  1.108  Rel. Train L2 Loss :  0.0567305696507295  Rel. Test L2 Loss :  0.05884143218398094  Test L2 Loss :  0.08545334577560425  inv_L_scale:  [1.0, 1.0]
Epoch :  253  Time:  1.11  Rel. Train L2 Loss :  0.05667818420463138  Rel. Test L2 Loss :  0.061005615293979645  Test L2 Loss :  0.08854989647865295  inv_L_scale:  [1.0, 1.0]
Epoch :  254  Time:  1.11  Rel. Train L2 Loss :  0.056984409888585406  Rel. Test L2 Loss :  0.059057339429855346  Test L2 Loss :  0.08562669247388839  inv_L_scale:  [1.0, 1.0]
Epoch :  255  Time:  1.109  Rel. Train L2 Loss :  0.05723721742630005  Rel. Test L2 Loss :  0.05878484457731247  Test L2 Loss :  0.08495946645736695  inv_L_scale:  [1.0, 1.0]
Epoch :  256  Time:  1.107  Rel. Train L2 Loss :  0.056277795169088575  Rel. Test L2 Loss :  0.05961156100034714  Test L2 Loss :  0.08652110934257508  inv_L_scale:  [1.0, 1.0]
Epoch :  257  Time:  1.11  Rel. Train L2 Loss :  0.05685118350717756  Rel. Test L2 Loss :  0.0606921124458313  Test L2 Loss :  0.08783748745918274  inv_L_scale:  [1.0, 1.0]
Epoch :  258  Time:  1.109  Rel. Train L2 Loss :  0.056696068429284624  Rel. Test L2 Loss :  0.05883152887225151  Test L2 Loss :  0.08530863136053085  inv_L_scale:  [1.0, 1.0]
Epoch :  259  Time:  1.11  Rel. Train L2 Loss :  0.05695626657870081  Rel. Test L2 Loss :  0.05880349338054657  Test L2 Loss :  0.08530735552310943  inv_L_scale:  [1.0, 1.0]
Epoch :  260  Time:  1.109  Rel. Train L2 Loss :  0.056667157842053305  Rel. Test L2 Loss :  0.05887215808033943  Test L2 Loss :  0.08567446887493134  inv_L_scale:  [1.0, 1.0]
Epoch :  261  Time:  1.111  Rel. Train L2 Loss :  0.05735669258568022  Rel. Test L2 Loss :  0.058662229031324384  Test L2 Loss :  0.08496177107095719  inv_L_scale:  [1.0, 1.0]
Epoch :  262  Time:  1.114  Rel. Train L2 Loss :  0.05619153067469597  Rel. Test L2 Loss :  0.058499857932329175  Test L2 Loss :  0.08465640634298324  inv_L_scale:  [1.0, 1.0]
Epoch :  263  Time:  1.109  Rel. Train L2 Loss :  0.056295540332794186  Rel. Test L2 Loss :  0.05903874158859253  Test L2 Loss :  0.08550145626068115  inv_L_scale:  [1.0, 1.0]
Epoch :  264  Time:  1.116  Rel. Train L2 Loss :  0.05584577725993262  Rel. Test L2 Loss :  0.05890552252531052  Test L2 Loss :  0.08527905106544495  inv_L_scale:  [1.0, 1.0]
Epoch :  265  Time:  1.136  Rel. Train L2 Loss :  0.05608666807413101  Rel. Test L2 Loss :  0.05884598433971405  Test L2 Loss :  0.08513488322496414  inv_L_scale:  [1.0, 1.0]
Epoch :  266  Time:  1.108  Rel. Train L2 Loss :  0.056252674145831  Rel. Test L2 Loss :  0.05815040498971939  Test L2 Loss :  0.08424501419067383  inv_L_scale:  [1.0, 1.0]
Epoch :  267  Time:  1.124  Rel. Train L2 Loss :  0.05655544160140885  Rel. Test L2 Loss :  0.05957000657916069  Test L2 Loss :  0.08646495997905732  inv_L_scale:  [1.0, 1.0]
Epoch :  268  Time:  1.159  Rel. Train L2 Loss :  0.05609178177184529  Rel. Test L2 Loss :  0.057503430545330046  Test L2 Loss :  0.08358043491840363  inv_L_scale:  [1.0, 1.0]
Epoch :  269  Time:  1.131  Rel. Train L2 Loss :  0.05588572253783544  Rel. Test L2 Loss :  0.05942180991172791  Test L2 Loss :  0.08631655931472779  inv_L_scale:  [1.0, 1.0]
Epoch :  270  Time:  1.109  Rel. Train L2 Loss :  0.05622227301200231  Rel. Test L2 Loss :  0.059719633013010025  Test L2 Loss :  0.0866511595249176  inv_L_scale:  [1.0, 1.0]
Epoch :  271  Time:  1.109  Rel. Train L2 Loss :  0.056222048501173655  Rel. Test L2 Loss :  0.058698270618915555  Test L2 Loss :  0.08492144525051117  inv_L_scale:  [1.0, 1.0]
Epoch :  272  Time:  1.108  Rel. Train L2 Loss :  0.056067474881807966  Rel. Test L2 Loss :  0.058192404359579085  Test L2 Loss :  0.08464046120643616  inv_L_scale:  [1.0, 1.0]
Epoch :  273  Time:  1.111  Rel. Train L2 Loss :  0.05618262377050188  Rel. Test L2 Loss :  0.057039760649204255  Test L2 Loss :  0.08284030348062515  inv_L_scale:  [1.0, 1.0]
Epoch :  274  Time:  1.112  Rel. Train L2 Loss :  0.05597832977771759  Rel. Test L2 Loss :  0.057979110330343246  Test L2 Loss :  0.08410063117742539  inv_L_scale:  [1.0, 1.0]
Epoch :  275  Time:  1.121  Rel. Train L2 Loss :  0.05580279709564315  Rel. Test L2 Loss :  0.05696792513132096  Test L2 Loss :  0.08273445904254913  inv_L_scale:  [1.0, 1.0]
Epoch :  276  Time:  1.13  Rel. Train L2 Loss :  0.05566771696011225  Rel. Test L2 Loss :  0.05794345855712891  Test L2 Loss :  0.08427159041166306  inv_L_scale:  [1.0, 1.0]
Epoch :  277  Time:  1.127  Rel. Train L2 Loss :  0.05568136841058731  Rel. Test L2 Loss :  0.05760597601532936  Test L2 Loss :  0.08373627752065659  inv_L_scale:  [1.0, 1.0]
Epoch :  278  Time:  1.114  Rel. Train L2 Loss :  0.05598822994364633  Rel. Test L2 Loss :  0.05723958313465118  Test L2 Loss :  0.08308585792779923  inv_L_scale:  [1.0, 1.0]
Epoch :  279  Time:  1.108  Rel. Train L2 Loss :  0.0556034807033009  Rel. Test L2 Loss :  0.057617085576057436  Test L2 Loss :  0.08379267573356629  inv_L_scale:  [1.0, 1.0]







