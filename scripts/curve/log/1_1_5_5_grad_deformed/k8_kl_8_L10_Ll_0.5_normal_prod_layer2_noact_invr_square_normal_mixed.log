(1000,) (1000, 1000, 1) (1000, 1000, 2)
use normalized raw measures
Preprocessing data : computing close_node_pairs
100%|█████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:15<00:00, 63.22it/s] 
maximum number of close node pairs is  10000
Casting to tensor
x train:torch.Size([900, 1000, 8]), y train:torch.Size([900, 1000, 1]), x test:torch.Size([100, 1000, 8]), y test:torch.Size([100, 1000, 1])
length of each dim:  tensor([6.5573987960815430, 6.1420288085937500])
kmax = 8, kmax_local = 8
L =  10  L_local =  0.5
In PCNO_train, ndims =  2
Epoch :  0  Time:  2.205  Rel. Train L2 Loss :  0.5123071347342597  Rel. Test L2 Loss :  0.36504116773605344  Test L2 Loss :  0.5255418908596039  inv_L_scale:  [1.0, 1.0]
Epoch :  1  Time:  1.854  Rel. Train L2 Loss :  0.30147891998291015  Rel. Test L2 Loss :  0.25803795099258425  Test L2 Loss :  0.3681950521469116  inv_L_scale:  [1.0, 1.0]
Epoch :  2  Time:  1.807  Rel. Train L2 Loss :  0.22325218260288238  Rel. Test L2 Loss :  0.2001662403345108  Test L2 Loss :  0.28768049001693724  inv_L_scale:  [1.0, 1.0]
Epoch :  3  Time:  1.822  Rel. Train L2 Loss :  0.19223711603217655  Rel. Test L2 Loss :  0.1821896928548813  Test L2 Loss :  0.26141539216041565  inv_L_scale:  [1.0, 1.0]
Epoch :  4  Time:  1.898  Rel. Train L2 Loss :  0.17856161885791355  Rel. Test L2 Loss :  0.16505732893943786  Test L2 Loss :  0.23786312818527222  inv_L_scale:  [1.0, 1.0]
Epoch :  5  Time:  1.82  Rel. Train L2 Loss :  0.16899352139896817  Rel. Test L2 Loss :  0.16403515338897706  Test L2 Loss :  0.23598595917224885  inv_L_scale:  [1.0, 1.0]
Epoch :  6  Time:  1.829  Rel. Train L2 Loss :  0.16141508705086177  Rel. Test L2 Loss :  0.16839605331420898  Test L2 Loss :  0.24228169441223144  inv_L_scale:  [1.0, 1.0]
Epoch :  7  Time:  1.818  Rel. Train L2 Loss :  0.1623799388276206  Rel. Test L2 Loss :  0.1543418598175049  Test L2 Loss :  0.22174164772033692  inv_L_scale:  [1.0, 1.0]
Epoch :  8  Time:  1.824  Rel. Train L2 Loss :  0.15476938227812448  Rel. Test L2 Loss :  0.14939900517463683  Test L2 Loss :  0.21542063474655151  inv_L_scale:  [1.0, 1.0]
Epoch :  9  Time:  1.845  Rel. Train L2 Loss :  0.15233259114954206  Rel. Test L2 Loss :  0.1476246076822281  Test L2 Loss :  0.21332565307617188  inv_L_scale:  [1.0, 1.0]
Epoch :  10  Time:  1.829  Rel. Train L2 Loss :  0.14976376828220156  Rel. Test L2 Loss :  0.15043748974800109  Test L2 Loss :  0.21609582066535948  inv_L_scale:  [1.0, 1.0]
Epoch :  11  Time:  1.828  Rel. Train L2 Loss :  0.14837566547923617  Rel. Test L2 Loss :  0.14692140877246856  Test L2 Loss :  0.21223199009895324  inv_L_scale:  [1.0, 1.0]
Epoch :  12  Time:  1.853  Rel. Train L2 Loss :  0.14979377541277145  Rel. Test L2 Loss :  0.150729723572731  Test L2 Loss :  0.21728270173072814  inv_L_scale:  [1.0, 1.0]
Epoch :  13  Time:  1.837  Rel. Train L2 Loss :  0.14524492250548468  Rel. Test L2 Loss :  0.1429322838783264  Test L2 Loss :  0.2057452368736267  inv_L_scale:  [1.0, 1.0]
Epoch :  14  Time:  1.853  Rel. Train L2 Loss :  0.1447353599468867  Rel. Test L2 Loss :  0.1429772734642029  Test L2 Loss :  0.20705000996589662  inv_L_scale:  [1.0, 1.0]
Epoch :  15  Time:  1.86  Rel. Train L2 Loss :  0.14362483468320636  Rel. Test L2 Loss :  0.1418508118391037  Test L2 Loss :  0.20379331946372986  inv_L_scale:  [1.0, 1.0]
Epoch :  16  Time:  1.823  Rel. Train L2 Loss :  0.14253203607267803  Rel. Test L2 Loss :  0.14029814779758454  Test L2 Loss :  0.20262712061405183  inv_L_scale:  [1.0, 1.0]
Epoch :  17  Time:  1.824  Rel. Train L2 Loss :  0.1413037583563063  Rel. Test L2 Loss :  0.13747188031673432  Test L2 Loss :  0.19954374969005584  inv_L_scale:  [1.0, 1.0]
Epoch :  18  Time:  1.875  Rel. Train L2 Loss :  0.14169527577029334  Rel. Test L2 Loss :  0.13780716180801392  Test L2 Loss :  0.19916584968566894  inv_L_scale:  [1.0, 1.0]
Epoch :  19  Time:  1.829  Rel. Train L2 Loss :  0.1379872237311469  Rel. Test L2 Loss :  0.1375076550245285  Test L2 Loss :  0.1991659390926361  inv_L_scale:  [1.0, 1.0]
Epoch :  20  Time:  1.82  Rel. Train L2 Loss :  0.13939656019210817  Rel. Test L2 Loss :  0.13883160293102265  Test L2 Loss :  0.2005411469936371  inv_L_scale:  [1.0, 1.0]
Epoch :  21  Time:  1.819  Rel. Train L2 Loss :  0.1381489924589793  Rel. Test L2 Loss :  0.13760362982749938  Test L2 Loss :  0.1992542988061905  inv_L_scale:  [1.0, 1.0]
Epoch :  22  Time:  1.812  Rel. Train L2 Loss :  0.13809416009320152  Rel. Test L2 Loss :  0.13966570138931275  Test L2 Loss :  0.2020666491985321  inv_L_scale:  [1.0, 1.0]
Epoch :  23  Time:  1.85  Rel. Train L2 Loss :  0.1380788126256731  Rel. Test L2 Loss :  0.15009329259395598  Test L2 Loss :  0.21704463720321654  inv_L_scale:  [1.0, 1.0]
Epoch :  24  Time:  1.824  Rel. Train L2 Loss :  0.13802282412846884  Rel. Test L2 Loss :  0.1376885277032852  Test L2 Loss :  0.19975456476211548  inv_L_scale:  [1.0, 1.0]
Epoch :  25  Time:  1.825  Rel. Train L2 Loss :  0.13695131368107266  Rel. Test L2 Loss :  0.1356862884759903  Test L2 Loss :  0.19645914196968078  inv_L_scale:  [1.0, 1.0]
Epoch :  26  Time:  1.827  Rel. Train L2 Loss :  0.13636117584175533  Rel. Test L2 Loss :  0.13419489979743957  Test L2 Loss :  0.19385595738887787  inv_L_scale:  [1.0, 1.0]
Epoch :  27  Time:  1.824  Rel. Train L2 Loss :  0.13544282807244196  Rel. Test L2 Loss :  0.13786121904850007  Test L2 Loss :  0.19927104949951172  inv_L_scale:  [1.0, 1.0]
Epoch :  28  Time:  1.836  Rel. Train L2 Loss :  0.13634700152609083  Rel. Test L2 Loss :  0.1333420217037201  Test L2 Loss :  0.1937875998020172  inv_L_scale:  [1.0, 1.0]
Epoch :  29  Time:  1.835  Rel. Train L2 Loss :  0.1363289323117998  Rel. Test L2 Loss :  0.13568352282047272  Test L2 Loss :  0.1961215192079544  inv_L_scale:  [1.0, 1.0]
Epoch :  30  Time:  1.82  Rel. Train L2 Loss :  0.13593554003371133  Rel. Test L2 Loss :  0.13194468289613723  Test L2 Loss :  0.1911662018299103  inv_L_scale:  [1.0, 1.0]
Epoch :  31  Time:  1.82  Rel. Train L2 Loss :  0.13478896180788677  Rel. Test L2 Loss :  0.13379958152770996  Test L2 Loss :  0.19470967054367067  inv_L_scale:  [1.0, 1.0]
Epoch :  32  Time:  1.82  Rel. Train L2 Loss :  0.13774479627609254  Rel. Test L2 Loss :  0.1339224922657013  Test L2 Loss :  0.19412859320640563  inv_L_scale:  [1.0, 1.0]
Epoch :  33  Time:  1.831  Rel. Train L2 Loss :  0.1352000504732132  Rel. Test L2 Loss :  0.13491069078445433  Test L2 Loss :  0.19492753505706786  inv_L_scale:  [1.0, 1.0]
Epoch :  34  Time:  1.825  Rel. Train L2 Loss :  0.13570375114679337  Rel. Test L2 Loss :  0.13507860779762268  Test L2 Loss :  0.1971389591693878  inv_L_scale:  [1.0, 1.0]
Epoch :  35  Time:  1.835  Rel. Train L2 Loss :  0.13431885222593942  Rel. Test L2 Loss :  0.13349085211753844  Test L2 Loss :  0.19371213793754577  inv_L_scale:  [1.0, 1.0]
Epoch :  36  Time:  1.821  Rel. Train L2 Loss :  0.13440753009584214  Rel. Test L2 Loss :  0.13176258385181427  Test L2 Loss :  0.19122956037521363  inv_L_scale:  [1.0, 1.0]
Epoch :  37  Time:  1.831  Rel. Train L2 Loss :  0.1333014484246572  Rel. Test L2 Loss :  0.13384423196315764  Test L2 Loss :  0.19369207084178924  inv_L_scale:  [1.0, 1.0]
Epoch :  38  Time:  1.885  Rel. Train L2 Loss :  0.1334573354985979  Rel. Test L2 Loss :  0.13554680705070496  Test L2 Loss :  0.19629742801189423  inv_L_scale:  [1.0, 1.0]
Epoch :  39  Time:  1.822  Rel. Train L2 Loss :  0.1336573521958457  Rel. Test L2 Loss :  0.1322874218225479  Test L2 Loss :  0.19179256796836852  inv_L_scale:  [1.0, 1.0]
Epoch :  40  Time:  1.818  Rel. Train L2 Loss :  0.1328396229611503  Rel. Test L2 Loss :  0.1312533038854599  Test L2 Loss :  0.1904631733894348  inv_L_scale:  [1.0, 1.0]
Epoch :  41  Time:  1.82  Rel. Train L2 Loss :  0.13253471189075047  Rel. Test L2 Loss :  0.1357330334186554  Test L2 Loss :  0.19605518460273744  inv_L_scale:  [1.0, 1.0]
Epoch :  42  Time:  1.823  Rel. Train L2 Loss :  0.1325676339864731  Rel. Test L2 Loss :  0.1312838089466095  Test L2 Loss :  0.1904643315076828  inv_L_scale:  [1.0, 1.0]
Epoch :  43  Time:  1.82  Rel. Train L2 Loss :  0.13210128433174556  Rel. Test L2 Loss :  0.13003098726272583  Test L2 Loss :  0.18857088327407837  inv_L_scale:  [1.0, 1.0]
Epoch :  44  Time:  1.847  Rel. Train L2 Loss :  0.13344569365183512  Rel. Test L2 Loss :  0.13254956483840943  Test L2 Loss :  0.19208294451236724  inv_L_scale:  [1.0, 1.0]
Epoch :  45  Time:  1.827  Rel. Train L2 Loss :  0.13291917115449906  Rel. Test L2 Loss :  0.1285693246126175  Test L2 Loss :  0.18687588691711426  inv_L_scale:  [1.0, 1.0]
Epoch :  46  Time:  1.83  Rel. Train L2 Loss :  0.13273032274511126  Rel. Test L2 Loss :  0.13457311749458312  Test L2 Loss :  0.19480077266693116  inv_L_scale:  [1.0, 1.0]
Epoch :  47  Time:  1.839  Rel. Train L2 Loss :  0.13293723152743445  Rel. Test L2 Loss :  0.12985214173793794  Test L2 Loss :  0.18916152358055116  inv_L_scale:  [1.0, 1.0]
Epoch :  48  Time:  1.825  Rel. Train L2 Loss :  0.13176403340366152  Rel. Test L2 Loss :  0.13308267533779145  Test L2 Loss :  0.19296600937843322  inv_L_scale:  [1.0, 1.0]
Epoch :  49  Time:  1.849  Rel. Train L2 Loss :  0.13243326885832682  Rel. Test L2 Loss :  0.1282404789328575  Test L2 Loss :  0.18644922375679016  inv_L_scale:  [1.0, 1.0]
Epoch :  50  Time:  1.839  Rel. Train L2 Loss :  0.13177790820598603  Rel. Test L2 Loss :  0.12862746477127074  Test L2 Loss :  0.18738215565681457  inv_L_scale:  [1.0, 1.0]
Epoch :  51  Time:  1.848  Rel. Train L2 Loss :  0.1320835248629252  Rel. Test L2 Loss :  0.13650345742702485  Test L2 Loss :  0.19779594838619233  inv_L_scale:  [1.0, 1.0]
Epoch :  52  Time:  1.831  Rel. Train L2 Loss :  0.13242652893066406  Rel. Test L2 Loss :  0.13018253564834595  Test L2 Loss :  0.18927136898040772  inv_L_scale:  [1.0, 1.0]
Epoch :  53  Time:  1.844  Rel. Train L2 Loss :  0.13135678701930575  Rel. Test L2 Loss :  0.13283102393150328  Test L2 Loss :  0.19413572192192077  inv_L_scale:  [1.0, 1.0]
Epoch :  54  Time:  1.865  Rel. Train L2 Loss :  0.1322244492173195  Rel. Test L2 Loss :  0.13330652177333832  Test L2 Loss :  0.1936020475625992  inv_L_scale:  [1.0, 1.0]
Epoch :  55  Time:  1.84  Rel. Train L2 Loss :  0.13122712383667628  Rel. Test L2 Loss :  0.13027104258537292  Test L2 Loss :  0.1891983336210251  inv_L_scale:  [1.0, 1.0]
Epoch :  56  Time:  1.847  Rel. Train L2 Loss :  0.13165345205201043  Rel. Test L2 Loss :  0.13116668224334715  Test L2 Loss :  0.1906443202495575  inv_L_scale:  [1.0, 1.0]
Epoch :  57  Time:  1.837  Rel. Train L2 Loss :  0.13152991265058517  Rel. Test L2 Loss :  0.12745793163776398  Test L2 Loss :  0.18528878092765808  inv_L_scale:  [1.0, 1.0]
Epoch :  58  Time:  1.837  Rel. Train L2 Loss :  0.13059682150681814  Rel. Test L2 Loss :  0.12960272252559663  Test L2 Loss :  0.1881759399175644  inv_L_scale:  [1.0, 1.0]