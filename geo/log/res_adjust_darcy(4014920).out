data_in.shape: (1324, 421, 421)
data_out.shape (1324, 421, 421)
x_train.shape:  (1000, 44521, 5)
y_train.shape:  (1000, 44521, 1)
In GeoFNO_train, ndim =  2
Epoch :  0  Rel. Train L2 Loss :  0.16982870694994925  Rel. Test L2 Loss :  0.0714938873052597  Test L2 Loss :  0.00048665442038327457  Time :  48.087066411972046  L:  [0.9933367371559143, 0.9953781962394714]
Epoch :  1  Rel. Train L2 Loss :  0.06757373023033142  Rel. Test L2 Loss :  0.05397936835885048  Test L2 Loss :  0.0003675235190894455  Time :  44.903867959976196  L:  [0.9973134994506836, 0.9991405010223389]
Epoch :  2  Rel. Train L2 Loss :  0.04553190818428993  Rel. Test L2 Loss :  0.03814027398824692  Test L2 Loss :  0.000256366161047481  Time :  44.83780527114868  L:  [1.0000396966934204, 1.0015811920166016]
Epoch :  3  Rel. Train L2 Loss :  0.03831028752028942  Rel. Test L2 Loss :  0.03476201094686985  Test L2 Loss :  0.00023512208892498165  Time :  44.89297866821289  L:  [1.0012097358703613, 1.0025137662887573]
Epoch :  4  Rel. Train L2 Loss :  0.034884191155433654  Rel. Test L2 Loss :  0.03603608086705208  Test L2 Loss :  0.00024165398557670414  Time :  45.066261529922485  L:  [1.0030537843704224, 1.0047931671142578]
Epoch :  5  Rel. Train L2 Loss :  0.028011986956000327  Rel. Test L2 Loss :  0.027348565384745598  Test L2 Loss :  0.00018410389369819314  Time :  44.984347105026245  L:  [1.0045475959777832, 1.0070284605026245]
Epoch :  6  Rel. Train L2 Loss :  0.026709910988807678  Rel. Test L2 Loss :  0.028841499090194702  Test L2 Loss :  0.00019869437557645141  Time :  44.94482111930847  L:  [1.0058684349060059, 1.0085365772247314]
Epoch :  7  Rel. Train L2 Loss :  0.025712552949786187  Rel. Test L2 Loss :  0.024292844608426095  Test L2 Loss :  0.0001646333042299375  Time :  45.07970905303955  L:  [1.0075750350952148, 1.0101048946380615]
Epoch :  8  Rel. Train L2 Loss :  0.02171510025858879  Rel. Test L2 Loss :  0.023568991869688034  Test L2 Loss :  0.0001586406584829092  Time :  45.16417145729065  L:  [1.0090068578720093, 1.0112253427505493]
Epoch :  9  Rel. Train L2 Loss :  0.021662917867302893  Rel. Test L2 Loss :  0.025484874024987222  Test L2 Loss :  0.00017436745285522192  Time :  44.979923248291016  L:  [1.0099903345108032, 1.0123858451843262]
Epoch :  10  Rel. Train L2 Loss :  0.02046214883029461  Rel. Test L2 Loss :  0.023755457997322083  Test L2 Loss :  0.0001600439421599731  Time :  44.99981951713562  L:  [1.0111454725265503, 1.0137261152267456]
Epoch :  11  Rel. Train L2 Loss :  0.018812565825879573  Rel. Test L2 Loss :  0.018247223719954492  Test L2 Loss :  0.00012338628788711504  Time :  45.191304445266724  L:  [1.0123389959335327, 1.0146851539611816]
Epoch :  12  Rel. Train L2 Loss :  0.020738643750548364  Rel. Test L2 Loss :  0.024969214648008345  Test L2 Loss :  0.0001683935453183949  Time :  45.08936142921448  L:  [1.0130023956298828, 1.015641689300537]
Epoch :  13  Rel. Train L2 Loss :  0.020361177064478396  Rel. Test L2 Loss :  0.019929818660020828  Test L2 Loss :  0.00013466650299960746  Time :  45.00675845146179  L:  [1.0136507749557495, 1.0156090259552002]
Epoch :  14  Rel. Train L2 Loss :  0.018524137057363988  Rel. Test L2 Loss :  0.021864428147673608  Test L2 Loss :  0.000147580910124816  Time :  45.094587326049805  L:  [1.0142890214920044, 1.0164594650268555]
Epoch :  15  Rel. Train L2 Loss :  0.019398230500519274  Rel. Test L2 Loss :  0.019489944353699683  Test L2 Loss :  0.00013208382646553218  Time :  45.142149925231934  L:  [1.0147160291671753, 1.0167182683944702]
Epoch :  16  Rel. Train L2 Loss :  0.0188988174572587  Rel. Test L2 Loss :  0.024339293986558916  Test L2 Loss :  0.00016370995726902037  Time :  45.12540626525879  L:  [1.015521764755249, 1.0169905424118042]
Epoch :  17  Rel. Train L2 Loss :  0.02103705897927284  Rel. Test L2 Loss :  0.020434323996305466  Test L2 Loss :  0.00013784921902697532  Time :  45.06344962120056  L:  [1.0158207416534424, 1.0174566507339478]
Epoch :  18  Rel. Train L2 Loss :  0.018151398144662382  Rel. Test L2 Loss :  0.021414570659399033  Test L2 Loss :  0.00014610848244046794  Time :  45.11147499084473  L:  [1.0160514116287231, 1.0181055068969727]
Epoch :  19  Rel. Train L2 Loss :  0.017925709821283817  Rel. Test L2 Loss :  0.01607193037867546  Test L2 Loss :  0.00010873880790313706  Time :  45.19730472564697  L:  [1.016828179359436, 1.0180777311325073]
Epoch :  20  Rel. Train L2 Loss :  0.015493080385029317  Rel. Test L2 Loss :  0.01749663408845663  Test L2 Loss :  0.00011789478798164054  Time :  45.209248065948486  L:  [1.0173627138137817, 1.0186264514923096]
/var/spool/slurmd/job4014920/slurm_script: line 11: 4024032 Killed                  python test_adjust_darcy.py
slurmstepd: error: Detected 1 oom_kill event in StepId=4014920.batch. Some of the step tasks have been OOM Killed.
