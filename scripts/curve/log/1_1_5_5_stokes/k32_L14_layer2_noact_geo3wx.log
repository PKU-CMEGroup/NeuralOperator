Loading data from  ../../data/curve//pcno_curve_data_1_1_5_5_stokes.npz
(1000,) (1000, 1000, 1) (1000, 1000, 2)
use normalized raw measures
Casting to tensor
x_train shape torch.Size([900, 1000, 6]), y_train shape torch.Size([900, 1000, 1])
length of each dim:  tensor([6.6455335617065430, 6.6654777526855469])
kmax = 32
L = 14
geo_dims = [1, 2, 3, 4], num_grad = 3
In PCNO_train, ndims =  2
Epoch :  0  Time:  9.85  Rel. Train L2 Loss :  0.5581724882125855  Rel. Test L2 Loss :  0.29820964992046356  Test L2 Loss :  0.5609422445297241  inv_L_scale:  [1.0, 1.0]
Epoch :  1  Time:  2.754  Rel. Train L2 Loss :  0.25294838309288026  Rel. Test L2 Loss :  0.22239437222480773  Test L2 Loss :  0.41280967712402344  inv_L_scale:  [1.0, 1.0]
Epoch :  2  Time:  2.753  Rel. Train L2 Loss :  0.19246676915221744  Rel. Test L2 Loss :  0.16627080976963043  Test L2 Loss :  0.3105334782600403  inv_L_scale:  [1.0, 1.0]
Epoch :  3  Time:  2.752  Rel. Train L2 Loss :  0.15386961738268534  Rel. Test L2 Loss :  0.13879007041454317  Test L2 Loss :  0.2610024046897888  inv_L_scale:  [1.0, 1.0]
Epoch :  4  Time:  2.753  Rel. Train L2 Loss :  0.13810024599234264  Rel. Test L2 Loss :  0.13387467175722123  Test L2 Loss :  0.25002780437469485  inv_L_scale:  [1.0, 1.0]
Epoch :  5  Time:  2.75  Rel. Train L2 Loss :  0.11438585013151169  Rel. Test L2 Loss :  0.12243808925151825  Test L2 Loss :  0.2272093415260315  inv_L_scale:  [1.0, 1.0]
Epoch :  6  Time:  2.749  Rel. Train L2 Loss :  0.10503453314304352  Rel. Test L2 Loss :  0.10075274229049683  Test L2 Loss :  0.18775688350200653  inv_L_scale:  [1.0, 1.0]
Epoch :  7  Time:  2.751  Rel. Train L2 Loss :  0.09780838251113892  Rel. Test L2 Loss :  0.09823940277099609  Test L2 Loss :  0.1852285873889923  inv_L_scale:  [1.0, 1.0]
Epoch :  8  Time:  2.752  Rel. Train L2 Loss :  0.09163266526328193  Rel. Test L2 Loss :  0.09197801232337952  Test L2 Loss :  0.1697029960155487  inv_L_scale:  [1.0, 1.0]
Epoch :  9  Time:  2.75  Rel. Train L2 Loss :  0.08747529096073574  Rel. Test L2 Loss :  0.0911849558353424  Test L2 Loss :  0.16909891724586487  inv_L_scale:  [1.0, 1.0]
Epoch :  10  Time:  2.751  Rel. Train L2 Loss :  0.08297704746325811  Rel. Test L2 Loss :  0.08881797403097152  Test L2 Loss :  0.16399909377098085  inv_L_scale:  [1.0, 1.0]
Epoch :  11  Time:  2.751  Rel. Train L2 Loss :  0.07808126303884719  Rel. Test L2 Loss :  0.09132188081741333  Test L2 Loss :  0.1661787736415863  inv_L_scale:  [1.0, 1.0]
Epoch :  12  Time:  2.752  Rel. Train L2 Loss :  0.07682051463259591  Rel. Test L2 Loss :  0.08868825078010559  Test L2 Loss :  0.16150182485580444  inv_L_scale:  [1.0, 1.0]
Epoch :  13  Time:  2.75  Rel. Train L2 Loss :  0.07437211092975404  Rel. Test L2 Loss :  0.08392277389764785  Test L2 Loss :  0.15123810827732087  inv_L_scale:  [1.0, 1.0]
Epoch :  14  Time:  2.749  Rel. Train L2 Loss :  0.07125697319706281  Rel. Test L2 Loss :  0.07419616103172302  Test L2 Loss :  0.13629211544990538  inv_L_scale:  [1.0, 1.0]
Epoch :  15  Time:  2.75  Rel. Train L2 Loss :  0.06634683526224561  Rel. Test L2 Loss :  0.06747053503990173  Test L2 Loss :  0.12460461616516114  inv_L_scale:  [1.0, 1.0]
Epoch :  16  Time:  2.75  Rel. Train L2 Loss :  0.06390135761764315  Rel. Test L2 Loss :  0.08500321745872498  Test L2 Loss :  0.16270912945270538  inv_L_scale:  [1.0, 1.0]
Epoch :  17  Time:  2.751  Rel. Train L2 Loss :  0.0648262447449896  Rel. Test L2 Loss :  0.07209562212228775  Test L2 Loss :  0.13043057918548584  inv_L_scale:  [1.0, 1.0]
Epoch :  18  Time:  2.755  Rel. Train L2 Loss :  0.06237832225031323  Rel. Test L2 Loss :  0.05932434812188148  Test L2 Loss :  0.10862055242061615  inv_L_scale:  [1.0, 1.0]
Epoch :  19  Time:  2.752  Rel. Train L2 Loss :  0.05924409010344082  Rel. Test L2 Loss :  0.06699276462197304  Test L2 Loss :  0.1220557713508606  inv_L_scale:  [1.0, 1.0]
Epoch :  20  Time:  2.751  Rel. Train L2 Loss :  0.05723849581347572  Rel. Test L2 Loss :  0.06547057017683983  Test L2 Loss :  0.11909950971603393  inv_L_scale:  [1.0, 1.0]
Epoch :  21  Time:  2.752  Rel. Train L2 Loss :  0.05654903541008632  Rel. Test L2 Loss :  0.058451913744211194  Test L2 Loss :  0.1060845947265625  inv_L_scale:  [1.0, 1.0]
Epoch :  22  Time:  2.752  Rel. Train L2 Loss :  0.05394700583484438  Rel. Test L2 Loss :  0.05864957317709923  Test L2 Loss :  0.10729451417922974  inv_L_scale:  [1.0, 1.0]
Epoch :  23  Time:  2.751  Rel. Train L2 Loss :  0.05547523554828432  Rel. Test L2 Loss :  0.05988866195082664  Test L2 Loss :  0.10947215408086777  inv_L_scale:  [1.0, 1.0]
Epoch :  24  Time:  2.75  Rel. Train L2 Loss :  0.05516660248239835  Rel. Test L2 Loss :  0.06043137639760971  Test L2 Loss :  0.11065667241811752  inv_L_scale:  [1.0, 1.0]
Epoch :  25  Time:  2.75  Rel. Train L2 Loss :  0.05309916082355711  Rel. Test L2 Loss :  0.06922768354415894  Test L2 Loss :  0.12597623646259307  inv_L_scale:  [1.0, 1.0]
Epoch :  26  Time:  2.749  Rel. Train L2 Loss :  0.05175737867752711  Rel. Test L2 Loss :  0.05682338625192642  Test L2 Loss :  0.10315332293510437  inv_L_scale:  [1.0, 1.0]
Epoch :  27  Time:  2.749  Rel. Train L2 Loss :  0.051661335246430504  Rel. Test L2 Loss :  0.06672250419855118  Test L2 Loss :  0.12391558408737183  inv_L_scale:  [1.0, 1.0]
Epoch :  28  Time:  2.749  Rel. Train L2 Loss :  0.05226924000514878  Rel. Test L2 Loss :  0.05519067332148552  Test L2 Loss :  0.09949067682027816  inv_L_scale:  [1.0, 1.0]
Epoch :  29  Time:  2.75  Rel. Train L2 Loss :  0.052521197862095303  Rel. Test L2 Loss :  0.054852744340896605  Test L2 Loss :  0.09931392937898637  inv_L_scale:  [1.0, 1.0]
Epoch :  30  Time:  2.751  Rel. Train L2 Loss :  0.049510758469502134  Rel. Test L2 Loss :  0.054834492802619934  Test L2 Loss :  0.09935765236616134  inv_L_scale:  [1.0, 1.0]
Epoch :  31  Time:  2.749  Rel. Train L2 Loss :  0.04733708322048187  Rel. Test L2 Loss :  0.05017848610877991  Test L2 Loss :  0.09085491418838501  inv_L_scale:  [1.0, 1.0]
Epoch :  32  Time:  2.752  Rel. Train L2 Loss :  0.04606784459617403  Rel. Test L2 Loss :  0.05438241630792618  Test L2 Loss :  0.1014117532968521  inv_L_scale:  [1.0, 1.0]
Epoch :  33  Time:  2.75  Rel. Train L2 Loss :  0.04915245395567682  Rel. Test L2 Loss :  0.05730849027633667  Test L2 Loss :  0.10590560734272003  inv_L_scale:  [1.0, 1.0]
Epoch :  34  Time:  2.751  Rel. Train L2 Loss :  0.04699403590626187  Rel. Test L2 Loss :  0.051295537948608395  Test L2 Loss :  0.09350172340869904  inv_L_scale:  [1.0, 1.0]
Epoch :  35  Time:  2.751  Rel. Train L2 Loss :  0.04470909419986937  Rel. Test L2 Loss :  0.05511854976415634  Test L2 Loss :  0.10422061502933502  inv_L_scale:  [1.0, 1.0]
Epoch :  36  Time:  2.75  Rel. Train L2 Loss :  0.04702886088026895  Rel. Test L2 Loss :  0.05869562789797783  Test L2 Loss :  0.10668013274669647  inv_L_scale:  [1.0, 1.0]
Epoch :  37  Time:  2.748  Rel. Train L2 Loss :  0.04618227375878228  Rel. Test L2 Loss :  0.05605572819709778  Test L2 Loss :  0.10516283094882965  inv_L_scale:  [1.0, 1.0]
Epoch :  38  Time:  2.749  Rel. Train L2 Loss :  0.045941204643911784  Rel. Test L2 Loss :  0.04658631667494774  Test L2 Loss :  0.08437621414661407  inv_L_scale:  [1.0, 1.0]
Epoch :  39  Time:  2.75  Rel. Train L2 Loss :  0.04649848113457362  Rel. Test L2 Loss :  0.048969168365001675  Test L2 Loss :  0.088501695394516  inv_L_scale:  [1.0, 1.0]
Epoch :  40  Time:  2.748  Rel. Train L2 Loss :  0.04481760993599892  Rel. Test L2 Loss :  0.048124165534973146  Test L2 Loss :  0.08687069416046142  inv_L_scale:  [1.0, 1.0]
Epoch :  41  Time:  2.749  Rel. Train L2 Loss :  0.04266991544100973  Rel. Test L2 Loss :  0.05023561775684357  Test L2 Loss :  0.08970530211925506  inv_L_scale:  [1.0, 1.0]
Epoch :  42  Time:  2.748  Rel. Train L2 Loss :  0.042835895915826164  Rel. Test L2 Loss :  0.06315320283174515  Test L2 Loss :  0.11801315307617187  inv_L_scale:  [1.0, 1.0]
Epoch :  43  Time:  2.749  Rel. Train L2 Loss :  0.04543605031238662  Rel. Test L2 Loss :  0.046115190535783765  Test L2 Loss :  0.08365724384784698  inv_L_scale:  [1.0, 1.0]
Epoch :  44  Time:  2.75  Rel. Train L2 Loss :  0.04363007128238678  Rel. Test L2 Loss :  0.04920613244175911  Test L2 Loss :  0.08776646316051483  inv_L_scale:  [1.0, 1.0]
Epoch :  45  Time:  2.748  Rel. Train L2 Loss :  0.04163308062487178  Rel. Test L2 Loss :  0.04840647220611572  Test L2 Loss :  0.08638984650373459  inv_L_scale:  [1.0, 1.0]
Epoch :  46  Time:  2.749  Rel. Train L2 Loss :  0.0422441256708569  Rel. Test L2 Loss :  0.06683754146099091  Test L2 Loss :  0.12274221837520599  inv_L_scale:  [1.0, 1.0]
Epoch :  47  Time:  2.748  Rel. Train L2 Loss :  0.04557436754306157  Rel. Test L2 Loss :  0.04284348726272583  Test L2 Loss :  0.07739478886127472  inv_L_scale:  [1.0, 1.0]
Epoch :  48  Time:  2.748  Rel. Train L2 Loss :  0.03955838385555479  Rel. Test L2 Loss :  0.05574247524142265  Test L2 Loss :  0.10487139463424683  inv_L_scale:  [1.0, 1.0]
Epoch :  49  Time:  2.748  Rel. Train L2 Loss :  0.04304841134283278  Rel. Test L2 Loss :  0.04132907524704933  Test L2 Loss :  0.07446296066045761  inv_L_scale:  [1.0, 1.0]
Epoch :  50  Time:  2.749  Rel. Train L2 Loss :  0.038660299463404546  Rel. Test L2 Loss :  0.041404305696487426  Test L2 Loss :  0.07585742473602294  inv_L_scale:  [1.0, 1.0]
Epoch :  51  Time:  2.749  Rel. Train L2 Loss :  0.03982909537023968  Rel. Test L2 Loss :  0.041477906852960586  Test L2 Loss :  0.07470371752977371  inv_L_scale:  [1.0, 1.0]
Epoch :  52  Time:  2.748  Rel. Train L2 Loss :  0.039970757878488965  Rel. Test L2 Loss :  0.05026246577501297  Test L2 Loss :  0.09470917165279388  inv_L_scale:  [1.0, 1.0]
Epoch :  53  Time:  2.747  Rel. Train L2 Loss :  0.041080165555079776  Rel. Test L2 Loss :  0.044445910602807996  Test L2 Loss :  0.07988494515419006  inv_L_scale:  [1.0, 1.0]
Epoch :  54  Time:  2.748  Rel. Train L2 Loss :  0.039036321077081895  Rel. Test L2 Loss :  0.042857382893562314  Test L2 Loss :  0.07871721506118774  inv_L_scale:  [1.0, 1.0]
Epoch :  55  Time:  2.748  Rel. Train L2 Loss :  0.037236798720227345  Rel. Test L2 Loss :  0.047416936159133914  Test L2 Loss :  0.08443182647228241  inv_L_scale:  [1.0, 1.0]
Epoch :  56  Time:  2.748  Rel. Train L2 Loss :  0.037113275163703496  Rel. Test L2 Loss :  0.04634416848421097  Test L2 Loss :  0.08546033412218094  inv_L_scale:  [1.0, 1.0]
Epoch :  57  Time:  2.75  Rel. Train L2 Loss :  0.038552947789430615  Rel. Test L2 Loss :  0.04218693971633911  Test L2 Loss :  0.0776996898651123  inv_L_scale:  [1.0, 1.0]
Epoch :  58  Time:  2.75  Rel. Train L2 Loss :  0.0360119693643517  Rel. Test L2 Loss :  0.04211809664964676  Test L2 Loss :  0.07605562269687653  inv_L_scale:  [1.0, 1.0]
Epoch :  59  Time:  2.748  Rel. Train L2 Loss :  0.03840821217331621  Rel. Test L2 Loss :  0.03854882463812828  Test L2 Loss :  0.06950927436351777  inv_L_scale:  [1.0, 1.0]
Epoch :  60  Time:  2.748  Rel. Train L2 Loss :  0.03651074339946111  Rel. Test L2 Loss :  0.041655964851379394  Test L2 Loss :  0.07530059367418289  inv_L_scale:  [1.0, 1.0]
Epoch :  61  Time:  2.748  Rel. Train L2 Loss :  0.03619405965010325  Rel. Test L2 Loss :  0.03720807388424873  Test L2 Loss :  0.06721058756113052  inv_L_scale:  [1.0, 1.0]
Epoch :  62  Time:  2.748  Rel. Train L2 Loss :  0.036211877928839786  Rel. Test L2 Loss :  0.03832342520356178  Test L2 Loss :  0.06976420074701309  inv_L_scale:  [1.0, 1.0]
Epoch :  63  Time:  2.748  Rel. Train L2 Loss :  0.03412543854779667  Rel. Test L2 Loss :  0.041155106127262114  Test L2 Loss :  0.07386010736227036  inv_L_scale:  [1.0, 1.0]
Epoch :  64  Time:  2.748  Rel. Train L2 Loss :  0.035188559277190105  Rel. Test L2 Loss :  0.036577780246734616  Test L2 Loss :  0.06580818235874177  inv_L_scale:  [1.0, 1.0]
Epoch :  65  Time:  2.748  Rel. Train L2 Loss :  0.0350788261824184  Rel. Test L2 Loss :  0.036183260828256604  Test L2 Loss :  0.06716726541519165  inv_L_scale:  [1.0, 1.0]
Epoch :  66  Time:  2.748  Rel. Train L2 Loss :  0.03333505622214741  Rel. Test L2 Loss :  0.03885128900408745  Test L2 Loss :  0.06984991520643234  inv_L_scale:  [1.0, 1.0]
Epoch :  67  Time:  2.75  Rel. Train L2 Loss :  0.03351008140378528  Rel. Test L2 Loss :  0.038040466606616974  Test L2 Loss :  0.06848321169614792  inv_L_scale:  [1.0, 1.0]
Epoch :  68  Time:  2.748  Rel. Train L2 Loss :  0.03312484230432246  Rel. Test L2 Loss :  0.037542951107025144  Test L2 Loss :  0.06738432526588439  inv_L_scale:  [1.0, 1.0]
Epoch :  69  Time:  2.747  Rel. Train L2 Loss :  0.03366582739684317  Rel. Test L2 Loss :  0.03587247118353844  Test L2 Loss :  0.06474599778652192  inv_L_scale:  [1.0, 1.0]
Epoch :  70  Time:  2.746  Rel. Train L2 Loss :  0.031985227275225854  Rel. Test L2 Loss :  0.03732917979359627  Test L2 Loss :  0.06712291806936264  inv_L_scale:  [1.0, 1.0]
Epoch :  71  Time:  2.747  Rel. Train L2 Loss :  0.03260569567481677  Rel. Test L2 Loss :  0.04298454374074936  Test L2 Loss :  0.0766292554140091  inv_L_scale:  [1.0, 1.0]
Epoch :  72  Time:  2.746  Rel. Train L2 Loss :  0.03392563311590089  Rel. Test L2 Loss :  0.038329472690820696  Test L2 Loss :  0.06933556705713272  inv_L_scale:  [1.0, 1.0]
Epoch :  73  Time:  2.747  Rel. Train L2 Loss :  0.03341113406750891  Rel. Test L2 Loss :  0.03361375831067562  Test L2 Loss :  0.06086922004818916  inv_L_scale:  [1.0, 1.0]
Epoch :  74  Time:  2.745  Rel. Train L2 Loss :  0.030635754714409512  Rel. Test L2 Loss :  0.035713108032941816  Test L2 Loss :  0.0644762772321701  inv_L_scale:  [1.0, 1.0]
Epoch :  75  Time:  2.747  Rel. Train L2 Loss :  0.03268500041630533  Rel. Test L2 Loss :  0.038186125010252  Test L2 Loss :  0.06987477719783783  inv_L_scale:  [1.0, 1.0]
Epoch :  76  Time:  2.746  Rel. Train L2 Loss :  0.031080956442488563  Rel. Test L2 Loss :  0.037446136623620986  Test L2 Loss :  0.06754702880978584  inv_L_scale:  [1.0, 1.0]
Epoch :  77  Time:  2.746  Rel. Train L2 Loss :  0.03214333447317282  Rel. Test L2 Loss :  0.0350289836525917  Test L2 Loss :  0.0629926186800003  inv_L_scale:  [1.0, 1.0]
Epoch :  78  Time:  2.747  Rel. Train L2 Loss :  0.030059218125210868  Rel. Test L2 Loss :  0.03302440002560616  Test L2 Loss :  0.06079895377159119  inv_L_scale:  [1.0, 1.0]
Epoch :  79  Time:  2.746  Rel. Train L2 Loss :  0.029568553186125224  Rel. Test L2 Loss :  0.029467603340744972  Test L2 Loss :  0.053413436710834504  inv_L_scale:  [1.0, 1.0]
Epoch :  80  Time:  2.747  Rel. Train L2 Loss :  0.028420562363333172  Rel. Test L2 Loss :  0.033860243111848834  Test L2 Loss :  0.06324515223503113  inv_L_scale:  [1.0, 1.0]
Epoch :  81  Time:  2.746  Rel. Train L2 Loss :  0.02811024425758256  Rel. Test L2 Loss :  0.032785933017730716  Test L2 Loss :  0.05915512830018997  inv_L_scale:  [1.0, 1.0]
Epoch :  82  Time:  2.748  Rel. Train L2 Loss :  0.031119677523771924  Rel. Test L2 Loss :  0.03198624685406685  Test L2 Loss :  0.05747590705752373  inv_L_scale:  [1.0, 1.0]
Epoch :  83  Time:  2.748  Rel. Train L2 Loss :  0.027793843961424296  Rel. Test L2 Loss :  0.03321326084434986  Test L2 Loss :  0.0618214650452137  inv_L_scale:  [1.0, 1.0]
Epoch :  84  Time:  2.747  Rel. Train L2 Loss :  0.029522643735011418  Rel. Test L2 Loss :  0.033568531125783924  Test L2 Loss :  0.06022141739726067  inv_L_scale:  [1.0, 1.0]
Epoch :  85  Time:  2.747  Rel. Train L2 Loss :  0.027355360156959958  Rel. Test L2 Loss :  0.030343250930309297  Test L2 Loss :  0.054905306994915005  inv_L_scale:  [1.0, 1.0]
Epoch :  86  Time:  2.747  Rel. Train L2 Loss :  0.02805574400557412  Rel. Test L2 Loss :  0.0337641703337431  Test L2 Loss :  0.060650031566619876  inv_L_scale:  [1.0, 1.0]
Epoch :  87  Time:  2.749  Rel. Train L2 Loss :  0.028206735965278413  Rel. Test L2 Loss :  0.029497618824243545  Test L2 Loss :  0.05383572697639465  inv_L_scale:  [1.0, 1.0]
Epoch :  88  Time:  2.749  Rel. Train L2 Loss :  0.027519862353801727  Rel. Test L2 Loss :  0.03685760870575905  Test L2 Loss :  0.0669055125117302  inv_L_scale:  [1.0, 1.0]
Epoch :  89  Time:  2.747  Rel. Train L2 Loss :  0.026856278768844076  Rel. Test L2 Loss :  0.028280983343720437  Test L2 Loss :  0.051867313981056214  inv_L_scale:  [1.0, 1.0]
Epoch :  90  Time:  2.748  Rel. Train L2 Loss :  0.026802519857883452  Rel. Test L2 Loss :  0.02556433603167534  Test L2 Loss :  0.04680932402610779  inv_L_scale:  [1.0, 1.0]
Epoch :  91  Time:  2.748  Rel. Train L2 Loss :  0.025244859870937136  Rel. Test L2 Loss :  0.027854502201080322  Test L2 Loss :  0.050619563460350035  inv_L_scale:  [1.0, 1.0]
Epoch :  92  Time:  2.746  Rel. Train L2 Loss :  0.02605303125249015  Rel. Test L2 Loss :  0.02758964478969574  Test L2 Loss :  0.05000532701611519  inv_L_scale:  [1.0, 1.0]
Epoch :  93  Time:  2.747  Rel. Train L2 Loss :  0.02579728820257717  Rel. Test L2 Loss :  0.02636873200535774  Test L2 Loss :  0.04776406288146973  inv_L_scale:  [1.0, 1.0]
Epoch :  94  Time:  2.747  Rel. Train L2 Loss :  0.02484554226199786  Rel. Test L2 Loss :  0.02705606922507286  Test L2 Loss :  0.048489710986614226  inv_L_scale:  [1.0, 1.0]
Epoch :  95  Time:  2.747  Rel. Train L2 Loss :  0.026189138409164217  Rel. Test L2 Loss :  0.029233871102333067  Test L2 Loss :  0.053011385202407835  inv_L_scale:  [1.0, 1.0]
Epoch :  96  Time:  2.748  Rel. Train L2 Loss :  0.024750638132294018  Rel. Test L2 Loss :  0.02864424206316471  Test L2 Loss :  0.052018231749534606  inv_L_scale:  [1.0, 1.0]
Epoch :  97  Time:  2.747  Rel. Train L2 Loss :  0.02414779044687748  Rel. Test L2 Loss :  0.029152691066265106  Test L2 Loss :  0.05289894789457321  inv_L_scale:  [1.0, 1.0]
Epoch :  98  Time:  2.747  Rel. Train L2 Loss :  0.024835774103800456  Rel. Test L2 Loss :  0.03501254044473171  Test L2 Loss :  0.06509980738162995  inv_L_scale:  [1.0, 1.0]
Epoch :  99  Time:  2.747  Rel. Train L2 Loss :  0.025493158515956668  Rel. Test L2 Loss :  0.026799572184681892  Test L2 Loss :  0.04794499978423119  inv_L_scale:  [1.0, 1.0]
Epoch :  100  Time:  2.744  Rel. Train L2 Loss :  0.025346623145871692  Rel. Test L2 Loss :  0.028984477370977403  Test L2 Loss :  0.053129646182060244  inv_L_scale:  [1.0, 1.0]
Epoch :  101  Time:  2.746  Rel. Train L2 Loss :  0.02526160673962699  Rel. Test L2 Loss :  0.02656237632036209  Test L2 Loss :  0.04903092190623284  inv_L_scale:  [1.0, 1.0]
Epoch :  102  Time:  2.745  Rel. Train L2 Loss :  0.02348471944530805  Rel. Test L2 Loss :  0.025441243350505828  Test L2 Loss :  0.04643475294113159  inv_L_scale:  [1.0, 1.0]
Epoch :  103  Time:  2.744  Rel. Train L2 Loss :  0.022569407439894145  Rel. Test L2 Loss :  0.023986470699310303  Test L2 Loss :  0.04355708241462707  inv_L_scale:  [1.0, 1.0]
Epoch :  104  Time:  2.744  Rel. Train L2 Loss :  0.023387674540281296  Rel. Test L2 Loss :  0.026278057098388673  Test L2 Loss :  0.04748229518532753  inv_L_scale:  [1.0, 1.0]
Epoch :  105  Time:  2.743  Rel. Train L2 Loss :  0.023602380868461396  Rel. Test L2 Loss :  0.026928690299391746  Test L2 Loss :  0.048847562968730926  inv_L_scale:  [1.0, 1.0]
Epoch :  106  Time:  2.744  Rel. Train L2 Loss :  0.023310362133714888  Rel. Test L2 Loss :  0.024985905289649963  Test L2 Loss :  0.04506648778915405  inv_L_scale:  [1.0, 1.0]
Epoch :  107  Time:  2.742  Rel. Train L2 Loss :  0.022952762668331465  Rel. Test L2 Loss :  0.025523718371987344  Test L2 Loss :  0.046410423666238786  inv_L_scale:  [1.0, 1.0]
Epoch :  108  Time:  2.743  Rel. Train L2 Loss :  0.023115437693066065  Rel. Test L2 Loss :  0.02884327754378319  Test L2 Loss :  0.05248490571975708  inv_L_scale:  [1.0, 1.0]
Epoch :  109  Time:  2.743  Rel. Train L2 Loss :  0.02283596680396133  Rel. Test L2 Loss :  0.02775819204747677  Test L2 Loss :  0.05092970848083496  inv_L_scale:  [1.0, 1.0]
Epoch :  110  Time:  2.743  Rel. Train L2 Loss :  0.02233867725564374  Rel. Test L2 Loss :  0.02155239835381508  Test L2 Loss :  0.039130735248327254  inv_L_scale:  [1.0, 1.0]
Epoch :  111  Time:  2.743  Rel. Train L2 Loss :  0.020789677939481204  Rel. Test L2 Loss :  0.02507679209113121  Test L2 Loss :  0.04516598716378212  inv_L_scale:  [1.0, 1.0]
Epoch :  112  Time:  2.743  Rel. Train L2 Loss :  0.021726696143547695  Rel. Test L2 Loss :  0.023771027624607085  Test L2 Loss :  0.04433867752552032  inv_L_scale:  [1.0, 1.0]
Epoch :  113  Time:  2.743  Rel. Train L2 Loss :  0.02117066433860196  Rel. Test L2 Loss :  0.026315342634916306  Test L2 Loss :  0.04775142639875412  inv_L_scale:  [1.0, 1.0]
Epoch :  114  Time:  2.743  Rel. Train L2 Loss :  0.021499146430028808  Rel. Test L2 Loss :  0.024914810210466386  Test L2 Loss :  0.045675932466983794  inv_L_scale:  [1.0, 1.0]
Epoch :  115  Time:  2.743  Rel. Train L2 Loss :  0.021526352614164353  Rel. Test L2 Loss :  0.025301671773195266  Test L2 Loss :  0.04629034280776977  inv_L_scale:  [1.0, 1.0]
Epoch :  116  Time:  2.743  Rel. Train L2 Loss :  0.021585091228286425  Rel. Test L2 Loss :  0.023842174932360648  Test L2 Loss :  0.04305588960647583  inv_L_scale:  [1.0, 1.0]
Epoch :  117  Time:  2.742  Rel. Train L2 Loss :  0.0202502132124371  Rel. Test L2 Loss :  0.025845650136470794  Test L2 Loss :  0.04689969837665558  inv_L_scale:  [1.0, 1.0]
Epoch :  118  Time:  2.742  Rel. Train L2 Loss :  0.021475665180219546  Rel. Test L2 Loss :  0.026056414917111397  Test L2 Loss :  0.048292481452226636  inv_L_scale:  [1.0, 1.0]
Epoch :  119  Time:  2.742  Rel. Train L2 Loss :  0.020346830214063326  Rel. Test L2 Loss :  0.022051025927066804  Test L2 Loss :  0.040059813857078554  inv_L_scale:  [1.0, 1.0]
Epoch :  120  Time:  2.745  Rel. Train L2 Loss :  0.020549352359440592  Rel. Test L2 Loss :  0.026103628277778627  Test L2 Loss :  0.04833416819572449  inv_L_scale:  [1.0, 1.0]
Epoch :  121  Time:  2.744  Rel. Train L2 Loss :  0.021280312140782673  Rel. Test L2 Loss :  0.028620479702949522  Test L2 Loss :  0.053793383836746214  inv_L_scale:  [1.0, 1.0]
Epoch :  122  Time:  2.744  Rel. Train L2 Loss :  0.020973055511713027  Rel. Test L2 Loss :  0.023393205255270003  Test L2 Loss :  0.04288902923464775  inv_L_scale:  [1.0, 1.0]
Epoch :  123  Time:  2.745  Rel. Train L2 Loss :  0.020321200605895783  Rel. Test L2 Loss :  0.021185537874698637  Test L2 Loss :  0.038186300992965695  inv_L_scale:  [1.0, 1.0]
Epoch :  124  Time:  2.742  Rel. Train L2 Loss :  0.01937744771440824  Rel. Test L2 Loss :  0.02150214433670044  Test L2 Loss :  0.03882086142897606  inv_L_scale:  [1.0, 1.0]
Epoch :  125  Time:  2.744  Rel. Train L2 Loss :  0.020417729773455195  Rel. Test L2 Loss :  0.029474001973867417  Test L2 Loss :  0.054261186718940736  inv_L_scale:  [1.0, 1.0]
Epoch :  126  Time:  2.743  Rel. Train L2 Loss :  0.020163931490646467  Rel. Test L2 Loss :  0.021459871083498002  Test L2 Loss :  0.03903092384338379  inv_L_scale:  [1.0, 1.0]
Epoch :  127  Time:  2.743  Rel. Train L2 Loss :  0.019406304094526504  Rel. Test L2 Loss :  0.02201496288180351  Test L2 Loss :  0.040318438410758974  inv_L_scale:  [1.0, 1.0]
Epoch :  128  Time:  2.742  Rel. Train L2 Loss :  0.019571443357401425  Rel. Test L2 Loss :  0.024501927942037583  Test L2 Loss :  0.044377438873052594  inv_L_scale:  [1.0, 1.0]
Epoch :  129  Time:  2.742  Rel. Train L2 Loss :  0.020485664043161603  Rel. Test L2 Loss :  0.02246356412768364  Test L2 Loss :  0.04184880584478378  inv_L_scale:  [1.0, 1.0]
Epoch :  130  Time:  2.743  Rel. Train L2 Loss :  0.019329498526122833  Rel. Test L2 Loss :  0.022875776588916777  Test L2 Loss :  0.041480665802955625  inv_L_scale:  [1.0, 1.0]
Epoch :  131  Time:  2.743  Rel. Train L2 Loss :  0.01928944474293126  Rel. Test L2 Loss :  0.02367061510682106  Test L2 Loss :  0.042525379955768584  inv_L_scale:  [1.0, 1.0]
Epoch :  132  Time:  2.743  Rel. Train L2 Loss :  0.0197378156416946  Rel. Test L2 Loss :  0.02510847106575966  Test L2 Loss :  0.04539455950260162  inv_L_scale:  [1.0, 1.0]
Epoch :  133  Time:  2.807  Rel. Train L2 Loss :  0.018949691562188998  Rel. Test L2 Loss :  0.02586741030216217  Test L2 Loss :  0.04849131047725677  inv_L_scale:  [1.0, 1.0]
Epoch :  134  Time:  3.529  Rel. Train L2 Loss :  0.01917723134987884  Rel. Test L2 Loss :  0.022130925059318542  Test L2 Loss :  0.03993797957897186  inv_L_scale:  [1.0, 1.0]
Epoch :  135  Time:  6.036  Rel. Train L2 Loss :  0.018626058797041576  Rel. Test L2 Loss :  0.02199485629796982  Test L2 Loss :  0.03956629142165184  inv_L_scale:  [1.0, 1.0]
Epoch :  136  Time:  13.706  Rel. Train L2 Loss :  0.018475813795295025  Rel. Test L2 Loss :  0.018148285523056983  Test L2 Loss :  0.03334315463900566  inv_L_scale:  [1.0, 1.0]
Epoch :  137  Time:  2.746  Rel. Train L2 Loss :  0.018470644603172937  Rel. Test L2 Loss :  0.020936149954795837  Test L2 Loss :  0.037570084780454635  inv_L_scale:  [1.0, 1.0]
Epoch :  138  Time:  2.742  Rel. Train L2 Loss :  0.019030487197968696  Rel. Test L2 Loss :  0.02082763150334358  Test L2 Loss :  0.037835725247859955  inv_L_scale:  [1.0, 1.0]
Epoch :  139  Time:  2.743  Rel. Train L2 Loss :  0.018213833644986153  Rel. Test L2 Loss :  0.02192244976758957  Test L2 Loss :  0.039807907938957214  inv_L_scale:  [1.0, 1.0]
Epoch :  140  Time:  2.744  Rel. Train L2 Loss :  0.017671166410048803  Rel. Test L2 Loss :  0.024365379363298415  Test L2 Loss :  0.044411486387252806  inv_L_scale:  [1.0, 1.0]
Epoch :  141  Time:  2.742  Rel. Train L2 Loss :  0.019500857152872614  Rel. Test L2 Loss :  0.01925152972340584  Test L2 Loss :  0.03498581767082214  inv_L_scale:  [1.0, 1.0]
Epoch :  142  Time:  2.743  Rel. Train L2 Loss :  0.017789537409941356  Rel. Test L2 Loss :  0.02063464656472206  Test L2 Loss :  0.03814697623252869  inv_L_scale:  [1.0, 1.0]
Epoch :  143  Time:  2.742  Rel. Train L2 Loss :  0.01822045666890012  Rel. Test L2 Loss :  0.021810472682118415  Test L2 Loss :  0.039230639040470125  inv_L_scale:  [1.0, 1.0]
Epoch :  144  Time:  2.742  Rel. Train L2 Loss :  0.018668759771519237  Rel. Test L2 Loss :  0.02588904947042465  Test L2 Loss :  0.046984967589378354  inv_L_scale:  [1.0, 1.0]
Epoch :  145  Time:  2.745  Rel. Train L2 Loss :  0.018146189376711846  Rel. Test L2 Loss :  0.019234241098165513  Test L2 Loss :  0.03480743452906609  inv_L_scale:  [1.0, 1.0]
Epoch :  146  Time:  2.743  Rel. Train L2 Loss :  0.018101205883754624  Rel. Test L2 Loss :  0.01890114489942789  Test L2 Loss :  0.03417441934347153  inv_L_scale:  [1.0, 1.0]
Epoch :  147  Time:  2.743  Rel. Train L2 Loss :  0.018493299682935078  Rel. Test L2 Loss :  0.023222455978393553  Test L2 Loss :  0.041810320019721986  inv_L_scale:  [1.0, 1.0]
Epoch :  148  Time:  2.742  Rel. Train L2 Loss :  0.018308007104529275  Rel. Test L2 Loss :  0.027478719800710677  Test L2 Loss :  0.05213299334049225  inv_L_scale:  [1.0, 1.0]
Epoch :  149  Time:  2.741  Rel. Train L2 Loss :  0.017603423049052557  Rel. Test L2 Loss :  0.02426003098487854  Test L2 Loss :  0.044091651290655134  inv_L_scale:  [1.0, 1.0]
Epoch :  150  Time:  2.74  Rel. Train L2 Loss :  0.016722675379779603  Rel. Test L2 Loss :  0.02215805135667324  Test L2 Loss :  0.04093448668718338  inv_L_scale:  [1.0, 1.0]
Epoch :  151  Time:  2.738  Rel. Train L2 Loss :  0.01674449752602312  Rel. Test L2 Loss :  0.01741995058953762  Test L2 Loss :  0.03185734733939171  inv_L_scale:  [1.0, 1.0]
Epoch :  152  Time:  2.736  Rel. Train L2 Loss :  0.017177771056691805  Rel. Test L2 Loss :  0.018224803358316423  Test L2 Loss :  0.03301252916455269  inv_L_scale:  [1.0, 1.0]
Epoch :  153  Time:  3.708  Rel. Train L2 Loss :  0.01702227240635289  Rel. Test L2 Loss :  0.02028398334980011  Test L2 Loss :  0.03673597142100334  inv_L_scale:  [1.0, 1.0]
Epoch :  154  Time:  2.739  Rel. Train L2 Loss :  0.017130496717161603  Rel. Test L2 Loss :  0.020565796792507172  Test L2 Loss :  0.03713959470391273  inv_L_scale:  [1.0, 1.0]
Epoch :  155  Time:  11.291  Rel. Train L2 Loss :  0.016765938732359143  Rel. Test L2 Loss :  0.020165629237890243  Test L2 Loss :  0.03637030333280564  inv_L_scale:  [1.0, 1.0]
Epoch :  156  Time:  2.856  Rel. Train L2 Loss :  0.01671620287001133  Rel. Test L2 Loss :  0.02464832440018654  Test L2 Loss :  0.04592878177762032  inv_L_scale:  [1.0, 1.0]
Epoch :  157  Time:  2.742  Rel. Train L2 Loss :  0.017351758753259977  Rel. Test L2 Loss :  0.0203858707845211  Test L2 Loss :  0.037487638890743254  inv_L_scale:  [1.0, 1.0]
Epoch :  158  Time:  2.741  Rel. Train L2 Loss :  0.01731353331771162  Rel. Test L2 Loss :  0.019388960972428322  Test L2 Loss :  0.035874000191688536  inv_L_scale:  [1.0, 1.0]
Epoch :  159  Time:  2.74  Rel. Train L2 Loss :  0.016285722528894743  Rel. Test L2 Loss :  0.019267637729644776  Test L2 Loss :  0.03523564144968987  inv_L_scale:  [1.0, 1.0]
Epoch :  160  Time:  2.741  Rel. Train L2 Loss :  0.015929809494151008  Rel. Test L2 Loss :  0.024800156950950624  Test L2 Loss :  0.04527147695422173  inv_L_scale:  [1.0, 1.0]
Epoch :  161  Time:  2.741  Rel. Train L2 Loss :  0.016320626272095573  Rel. Test L2 Loss :  0.017091271504759788  Test L2 Loss :  0.031403590589761735  inv_L_scale:  [1.0, 1.0]
Epoch :  162  Time:  2.74  Rel. Train L2 Loss :  0.015915677323937415  Rel. Test L2 Loss :  0.018192550987005233  Test L2 Loss :  0.032888150215148924  inv_L_scale:  [1.0, 1.0]
Epoch :  163  Time:  2.74  Rel. Train L2 Loss :  0.01591297929485639  Rel. Test L2 Loss :  0.018283624425530432  Test L2 Loss :  0.03349273309111595  inv_L_scale:  [1.0, 1.0]
Epoch :  164  Time:  2.741  Rel. Train L2 Loss :  0.016027045825289354  Rel. Test L2 Loss :  0.016843691058456896  Test L2 Loss :  0.030707253664731978  inv_L_scale:  [1.0, 1.0]
Epoch :  165  Time:  2.741  Rel. Train L2 Loss :  0.016173831108543608  Rel. Test L2 Loss :  0.017923026643693447  Test L2 Loss :  0.032453280985355375  inv_L_scale:  [1.0, 1.0]
Epoch :  166  Time:  2.747  Rel. Train L2 Loss :  0.017384493495855066  Rel. Test L2 Loss :  0.019134327620267868  Test L2 Loss :  0.034243767708539964  inv_L_scale:  [1.0, 1.0]
Epoch :  167  Time:  2.74  Rel. Train L2 Loss :  0.015297893082929982  Rel. Test L2 Loss :  0.01740912064909935  Test L2 Loss :  0.031723017543554305  inv_L_scale:  [1.0, 1.0]
Epoch :  168  Time:  2.74  Rel. Train L2 Loss :  0.015608935716251533  Rel. Test L2 Loss :  0.020119429901242256  Test L2 Loss :  0.036139586567878725  inv_L_scale:  [1.0, 1.0]
Epoch :  169  Time:  2.74  Rel. Train L2 Loss :  0.0151352130373319  Rel. Test L2 Loss :  0.01802985779941082  Test L2 Loss :  0.033948185592889785  inv_L_scale:  [1.0, 1.0]
Epoch :  170  Time:  2.965  Rel. Train L2 Loss :  0.016723520449466175  Rel. Test L2 Loss :  0.02229113072156906  Test L2 Loss :  0.04041776239871979  inv_L_scale:  [1.0, 1.0]
Epoch :  171  Time:  2.742  Rel. Train L2 Loss :  0.016274423181182808  Rel. Test L2 Loss :  0.018595728650689126  Test L2 Loss :  0.03371468171477318  inv_L_scale:  [1.0, 1.0]
Epoch :  172  Time:  11.445  Rel. Train L2 Loss :  0.01518667757511139  Rel. Test L2 Loss :  0.01920208342373371  Test L2 Loss :  0.0350491438806057  inv_L_scale:  [1.0, 1.0]
Epoch :  173  Time:  2.838  Rel. Train L2 Loss :  0.015533804554078314  Rel. Test L2 Loss :  0.0166054168343544  Test L2 Loss :  0.030175012648105622  inv_L_scale:  [1.0, 1.0]
Epoch :  174  Time:  2.751  Rel. Train L2 Loss :  0.014997456603580052  Rel. Test L2 Loss :  0.016494879387319087  Test L2 Loss :  0.029843689650297166  inv_L_scale:  [1.0, 1.0]
Epoch :  175  Time:  2.742  Rel. Train L2 Loss :  0.01566223913596736  Rel. Test L2 Loss :  0.01956685893237591  Test L2 Loss :  0.03566837444901466  inv_L_scale:  [1.0, 1.0]
Epoch :  176  Time:  2.741  Rel. Train L2 Loss :  0.01579126408116685  Rel. Test L2 Loss :  0.01677029252052307  Test L2 Loss :  0.030326449126005173  inv_L_scale:  [1.0, 1.0]
Epoch :  177  Time:  2.741  Rel. Train L2 Loss :  0.015334178457657496  Rel. Test L2 Loss :  0.01670631766319275  Test L2 Loss :  0.0306405608355999  inv_L_scale:  [1.0, 1.0]
Epoch :  178  Time:  2.742  Rel. Train L2 Loss :  0.015041228450006909  Rel. Test L2 Loss :  0.016248510032892228  Test L2 Loss :  0.029308207780122757  inv_L_scale:  [1.0, 1.0]
Epoch :  179  Time:  2.741  Rel. Train L2 Loss :  0.014657700483997662  Rel. Test L2 Loss :  0.01707595359534025  Test L2 Loss :  0.0313021232932806  inv_L_scale:  [1.0, 1.0]
Epoch :  180  Time:  2.742  Rel. Train L2 Loss :  0.014437081408169534  Rel. Test L2 Loss :  0.016997417770326137  Test L2 Loss :  0.030794310569763183  inv_L_scale:  [1.0, 1.0]
Epoch :  181  Time:  2.74  Rel. Train L2 Loss :  0.015094002708792686  Rel. Test L2 Loss :  0.016372612714767455  Test L2 Loss :  0.029857725203037262  inv_L_scale:  [1.0, 1.0]
Epoch :  182  Time:  2.739  Rel. Train L2 Loss :  0.015075904896689786  Rel. Test L2 Loss :  0.018818266689777374  Test L2 Loss :  0.03424909010529518  inv_L_scale:  [1.0, 1.0]
Epoch :  183  Time:  2.74  Rel. Train L2 Loss :  0.016030050582355924  Rel. Test L2 Loss :  0.017531432621181012  Test L2 Loss :  0.03231947600841522  inv_L_scale:  [1.0, 1.0]
Epoch :  184  Time:  2.742  Rel. Train L2 Loss :  0.015034693090452089  Rel. Test L2 Loss :  0.02200674295425415  Test L2 Loss :  0.04103891730308533  inv_L_scale:  [1.0, 1.0]
Epoch :  185  Time:  2.741  Rel. Train L2 Loss :  0.014836566493742995  Rel. Test L2 Loss :  0.016548684127628804  Test L2 Loss :  0.03000453993678093  inv_L_scale:  [1.0, 1.0]
Epoch :  186  Time:  2.739  Rel. Train L2 Loss :  0.014781047904656994  Rel. Test L2 Loss :  0.015673909336328506  Test L2 Loss :  0.028386793658137323  inv_L_scale:  [1.0, 1.0]
Epoch :  187  Time:  2.738  Rel. Train L2 Loss :  0.014376021275917689  Rel. Test L2 Loss :  0.020757065415382386  Test L2 Loss :  0.03869904711842537  inv_L_scale:  [1.0, 1.0]
Epoch :  188  Time:  2.741  Rel. Train L2 Loss :  0.015344891647497813  Rel. Test L2 Loss :  0.016265539601445198  Test L2 Loss :  0.029873432740569115  inv_L_scale:  [1.0, 1.0]
Epoch :  189  Time:  2.741  Rel. Train L2 Loss :  0.014175592040022214  Rel. Test L2 Loss :  0.01725075490772724  Test L2 Loss :  0.031339136213064195  inv_L_scale:  [1.0, 1.0]
Epoch :  190  Time:  2.741  Rel. Train L2 Loss :  0.01477961600654655  Rel. Test L2 Loss :  0.01649542510509491  Test L2 Loss :  0.02968894727528095  inv_L_scale:  [1.0, 1.0]
Epoch :  191  Time:  2.74  Rel. Train L2 Loss :  0.01488315198984411  Rel. Test L2 Loss :  0.02446706473827362  Test L2 Loss :  0.04480401903390884  inv_L_scale:  [1.0, 1.0]
Epoch :  192  Time:  2.741  Rel. Train L2 Loss :  0.015096126389172342  Rel. Test L2 Loss :  0.015227060616016388  Test L2 Loss :  0.02767258435487747  inv_L_scale:  [1.0, 1.0]
Epoch :  193  Time:  2.741  Rel. Train L2 Loss :  0.013717924339903726  Rel. Test L2 Loss :  0.019864905551075937  Test L2 Loss :  0.03663223505020142  inv_L_scale:  [1.0, 1.0]
Epoch :  194  Time:  2.74  Rel. Train L2 Loss :  0.014620011589593357  Rel. Test L2 Loss :  0.016955121159553527  Test L2 Loss :  0.030701162070035936  inv_L_scale:  [1.0, 1.0]
Epoch :  195  Time:  2.74  Rel. Train L2 Loss :  0.013969876762065623  Rel. Test L2 Loss :  0.015695030465722085  Test L2 Loss :  0.028597876653075217  inv_L_scale:  [1.0, 1.0]
Epoch :  196  Time:  2.739  Rel. Train L2 Loss :  0.013857093999783198  Rel. Test L2 Loss :  0.015620688535273075  Test L2 Loss :  0.028499242067337036  inv_L_scale:  [1.0, 1.0]
Epoch :  197  Time:  3.055  Rel. Train L2 Loss :  0.013336778523193465  Rel. Test L2 Loss :  0.01701159566640854  Test L2 Loss :  0.03150579757988453  inv_L_scale:  [1.0, 1.0]
Epoch :  198  Time:  12.695  Rel. Train L2 Loss :  0.013422041336695353  Rel. Test L2 Loss :  0.019949873983860014  Test L2 Loss :  0.03636223703622818  inv_L_scale:  [1.0, 1.0]
Epoch :  199  Time:  3.662  Rel. Train L2 Loss :  0.01353145764519771  Rel. Test L2 Loss :  0.01475228115916252  Test L2 Loss :  0.0269041795283556  inv_L_scale:  [1.0, 1.0]
Epoch :  200  Time:  2.739  Rel. Train L2 Loss :  0.013801068406965997  Rel. Test L2 Loss :  0.014375264272093773  Test L2 Loss :  0.02609529599547386  inv_L_scale:  [1.0, 1.0]
Epoch :  201  Time:  2.738  Rel. Train L2 Loss :  0.01356019561075502  Rel. Test L2 Loss :  0.016838308051228525  Test L2 Loss :  0.030444463416934013  inv_L_scale:  [1.0, 1.0]
Epoch :  202  Time:  2.734  Rel. Train L2 Loss :  0.014410528830356067  Rel. Test L2 Loss :  0.016527734845876694  Test L2 Loss :  0.02999737739562988  inv_L_scale:  [1.0, 1.0]
Epoch :  203  Time:  2.735  Rel. Train L2 Loss :  0.013537770451770889  Rel. Test L2 Loss :  0.015829714499413967  Test L2 Loss :  0.02889313958585262  inv_L_scale:  [1.0, 1.0]
Epoch :  204  Time:  2.735  Rel. Train L2 Loss :  0.013010781407356262  Rel. Test L2 Loss :  0.01676704555749893  Test L2 Loss :  0.030485029965639114  inv_L_scale:  [1.0, 1.0]
Epoch :  205  Time:  2.733  Rel. Train L2 Loss :  0.013105011305047405  Rel. Test L2 Loss :  0.014530047439038754  Test L2 Loss :  0.02667536921799183  inv_L_scale:  [1.0, 1.0]
Epoch :  206  Time:  2.733  Rel. Train L2 Loss :  0.013908291591538323  Rel. Test L2 Loss :  0.015488586127758027  Test L2 Loss :  0.028673137798905374  inv_L_scale:  [1.0, 1.0]
Epoch :  207  Time:  2.733  Rel. Train L2 Loss :  0.013456139821145269  Rel. Test L2 Loss :  0.015298280641436577  Test L2 Loss :  0.027844161316752433  inv_L_scale:  [1.0, 1.0]
Epoch :  208  Time:  2.733  Rel. Train L2 Loss :  0.013547382785214317  Rel. Test L2 Loss :  0.017250267639756203  Test L2 Loss :  0.032275000661611555  inv_L_scale:  [1.0, 1.0]
Epoch :  209  Time:  2.733  Rel. Train L2 Loss :  0.013229126118951374  Rel. Test L2 Loss :  0.015129293501377105  Test L2 Loss :  0.027542458772659303  inv_L_scale:  [1.0, 1.0]
Epoch :  210  Time:  2.734  Rel. Train L2 Loss :  0.013312543845838971  Rel. Test L2 Loss :  0.01643601421266794  Test L2 Loss :  0.029886255413293837  inv_L_scale:  [1.0, 1.0]
Epoch :  211  Time:  2.733  Rel. Train L2 Loss :  0.013457055820359123  Rel. Test L2 Loss :  0.015116816945374012  Test L2 Loss :  0.02787735693156719  inv_L_scale:  [1.0, 1.0]
Epoch :  212  Time:  2.733  Rel. Train L2 Loss :  0.013131278103424442  Rel. Test L2 Loss :  0.01702776174992323  Test L2 Loss :  0.03071805849671364  inv_L_scale:  [1.0, 1.0]
Epoch :  213  Time:  2.733  Rel. Train L2 Loss :  0.013143340879016452  Rel. Test L2 Loss :  0.01657880648970604  Test L2 Loss :  0.030902193635702135  inv_L_scale:  [1.0, 1.0]
Epoch :  214  Time:  2.734  Rel. Train L2 Loss :  0.013045052306519615  Rel. Test L2 Loss :  0.01423154205083847  Test L2 Loss :  0.02589609280228615  inv_L_scale:  [1.0, 1.0]
Epoch :  215  Time:  2.733  Rel. Train L2 Loss :  0.01275460691915618  Rel. Test L2 Loss :  0.01709338992834091  Test L2 Loss :  0.031103970482945442  inv_L_scale:  [1.0, 1.0]
Epoch :  216  Time:  2.921  Rel. Train L2 Loss :  0.012818761078847779  Rel. Test L2 Loss :  0.013693074025213718  Test L2 Loss :  0.024947919473052024  inv_L_scale:  [1.0, 1.0]
Epoch :  217  Time:  12.839  Rel. Train L2 Loss :  0.012975626248452398  Rel. Test L2 Loss :  0.015191640965640544  Test L2 Loss :  0.027704595029354094  inv_L_scale:  [1.0, 1.0]
Epoch :  218  Time:  2.747  Rel. Train L2 Loss :  0.013244771750436889  Rel. Test L2 Loss :  0.016234555877745152  Test L2 Loss :  0.02965255334973335  inv_L_scale:  [1.0, 1.0]
Epoch :  219  Time:  2.731  Rel. Train L2 Loss :  0.012621737668911616  Rel. Test L2 Loss :  0.020300061106681824  Test L2 Loss :  0.037789316773414613  inv_L_scale:  [1.0, 1.0]
Epoch :  220  Time:  2.73  Rel. Train L2 Loss :  0.012770087180866136  Rel. Test L2 Loss :  0.013014874309301377  Test L2 Loss :  0.02382032200694084  inv_L_scale:  [1.0, 1.0]
Epoch :  221  Time:  2.731  Rel. Train L2 Loss :  0.012194597439633475  Rel. Test L2 Loss :  0.014404299259185792  Test L2 Loss :  0.026280222982168196  inv_L_scale:  [1.0, 1.0]
Epoch :  222  Time:  2.73  Rel. Train L2 Loss :  0.013049598096145525  Rel. Test L2 Loss :  0.015173738673329353  Test L2 Loss :  0.027785505205392837  inv_L_scale:  [1.0, 1.0]
Epoch :  223  Time:  2.731  Rel. Train L2 Loss :  0.012565609425720242  Rel. Test L2 Loss :  0.015288016125559807  Test L2 Loss :  0.028283872455358506  inv_L_scale:  [1.0, 1.0]
Epoch :  224  Time:  2.729  Rel. Train L2 Loss :  0.012495223333438237  Rel. Test L2 Loss :  0.015376272611320019  Test L2 Loss :  0.027775240540504457  inv_L_scale:  [1.0, 1.0]
Epoch :  225  Time:  2.79  Rel. Train L2 Loss :  0.012351645247803794  Rel. Test L2 Loss :  0.015290311202406884  Test L2 Loss :  0.027859494388103485  inv_L_scale:  [1.0, 1.0]
Epoch :  226  Time:  2.729  Rel. Train L2 Loss :  0.013086716081533167  Rel. Test L2 Loss :  0.015071912705898284  Test L2 Loss :  0.028029873818159103  inv_L_scale:  [1.0, 1.0]
Epoch :  227  Time:  2.73  Rel. Train L2 Loss :  0.012504990175366403  Rel. Test L2 Loss :  0.013183386549353599  Test L2 Loss :  0.024090219736099244  inv_L_scale:  [1.0, 1.0]
Epoch :  228  Time:  2.729  Rel. Train L2 Loss :  0.013317753171755207  Rel. Test L2 Loss :  0.01564905121922493  Test L2 Loss :  0.02849106825888157  inv_L_scale:  [1.0, 1.0]
Epoch :  229  Time:  2.729  Rel. Train L2 Loss :  0.01298892815079954  Rel. Test L2 Loss :  0.014881219491362572  Test L2 Loss :  0.027267246767878534  inv_L_scale:  [1.0, 1.0]
Epoch :  230  Time:  2.73  Rel. Train L2 Loss :  0.012093592695891857  Rel. Test L2 Loss :  0.013297824859619141  Test L2 Loss :  0.024554804041981695  inv_L_scale:  [1.0, 1.0]
Epoch :  231  Time:  2.729  Rel. Train L2 Loss :  0.011729935109615326  Rel. Test L2 Loss :  0.014192548058927059  Test L2 Loss :  0.02605015642940998  inv_L_scale:  [1.0, 1.0]
Epoch :  232  Time:  2.729  Rel. Train L2 Loss :  0.011955665184391869  Rel. Test L2 Loss :  0.013427497819066048  Test L2 Loss :  0.02480491027235985  inv_L_scale:  [1.0, 1.0]
Epoch :  233  Time:  2.73  Rel. Train L2 Loss :  0.011990319755342272  Rel. Test L2 Loss :  0.01334689289331436  Test L2 Loss :  0.024210569858551027  inv_L_scale:  [1.0, 1.0]
Epoch :  234  Time:  2.729  Rel. Train L2 Loss :  0.012097234254082044  Rel. Test L2 Loss :  0.014116623848676681  Test L2 Loss :  0.025779967904090883  inv_L_scale:  [1.0, 1.0]
Epoch :  235  Time:  2.729  Rel. Train L2 Loss :  0.012378066463602913  Rel. Test L2 Loss :  0.014269075393676757  Test L2 Loss :  0.026411991268396377  inv_L_scale:  [1.0, 1.0]
Epoch :  236  Time:  2.729  Rel. Train L2 Loss :  0.01169431758009725  Rel. Test L2 Loss :  0.013440586626529694  Test L2 Loss :  0.02456515297293663  inv_L_scale:  [1.0, 1.0]
Epoch :  237  Time:  3.199  Rel. Train L2 Loss :  0.012118226053814093  Rel. Test L2 Loss :  0.014063719436526298  Test L2 Loss :  0.02535236805677414  inv_L_scale:  [1.0, 1.0]
Epoch :  238  Time:  2.876  Rel. Train L2 Loss :  0.011600599839455552  Rel. Test L2 Loss :  0.013156197741627693  Test L2 Loss :  0.024162258952856064  inv_L_scale:  [1.0, 1.0]
Epoch :  239  Time:  2.731  Rel. Train L2 Loss :  0.01216570034623146  Rel. Test L2 Loss :  0.013740877881646156  Test L2 Loss :  0.02510973498225212  inv_L_scale:  [1.0, 1.0]
Epoch :  240  Time:  2.73  Rel. Train L2 Loss :  0.011425746956633197  Rel. Test L2 Loss :  0.018323985785245897  Test L2 Loss :  0.033744858652353285  inv_L_scale:  [1.0, 1.0]
Epoch :  241  Time:  2.731  Rel. Train L2 Loss :  0.011851329298483001  Rel. Test L2 Loss :  0.012852828726172447  Test L2 Loss :  0.02368470385670662  inv_L_scale:  [1.0, 1.0]
Epoch :  242  Time:  2.731  Rel. Train L2 Loss :  0.011927056921025117  Rel. Test L2 Loss :  0.014445197954773902  Test L2 Loss :  0.026934196799993516  inv_L_scale:  [1.0, 1.0]
Epoch :  243  Time:  2.731  Rel. Train L2 Loss :  0.01184828158054087  Rel. Test L2 Loss :  0.012342095002532005  Test L2 Loss :  0.022685435116291047  inv_L_scale:  [1.0, 1.0]
Epoch :  244  Time:  2.73  Rel. Train L2 Loss :  0.011435018595721987  Rel. Test L2 Loss :  0.012788365110754967  Test L2 Loss :  0.023575029149651528  inv_L_scale:  [1.0, 1.0]
Epoch :  245  Time:  2.73  Rel. Train L2 Loss :  0.011192360665235254  Rel. Test L2 Loss :  0.01305628914386034  Test L2 Loss :  0.023866677954792977  inv_L_scale:  [1.0, 1.0]
Epoch :  246  Time:  2.73  Rel. Train L2 Loss :  0.010808427275882828  Rel. Test L2 Loss :  0.015219458788633346  Test L2 Loss :  0.027924994006752968  inv_L_scale:  [1.0, 1.0]
Epoch :  247  Time:  3.419  Rel. Train L2 Loss :  0.011401129567788706  Rel. Test L2 Loss :  0.013738467842340469  Test L2 Loss :  0.025004868432879447  inv_L_scale:  [1.0, 1.0]
Epoch :  248  Time:  5.853  Rel. Train L2 Loss :  0.011702459243436655  Rel. Test L2 Loss :  0.012752314023673534  Test L2 Loss :  0.023528417721390724  inv_L_scale:  [1.0, 1.0]
Epoch :  249  Time:  2.731  Rel. Train L2 Loss :  0.01137896455410454  Rel. Test L2 Loss :  0.012211010158061981  Test L2 Loss :  0.022271453887224197  inv_L_scale:  [1.0, 1.0]
Epoch :  250  Time:  2.73  Rel. Train L2 Loss :  0.010871790068017112  Rel. Test L2 Loss :  0.014021726958453655  Test L2 Loss :  0.02627124756574631  inv_L_scale:  [1.0, 1.0]
Epoch :  251  Time:  2.73  Rel. Train L2 Loss :  0.011500972534219424  Rel. Test L2 Loss :  0.012714993879199029  Test L2 Loss :  0.023362598642706872  inv_L_scale:  [1.0, 1.0]
Epoch :  252  Time:  2.73  Rel. Train L2 Loss :  0.011342057863043414  Rel. Test L2 Loss :  0.01253127608448267  Test L2 Loss :  0.02264183059334755  inv_L_scale:  [1.0, 1.0]
Epoch :  253  Time:  2.73  Rel. Train L2 Loss :  0.011162249977803892  Rel. Test L2 Loss :  0.012761824242770671  Test L2 Loss :  0.02341902658343315  inv_L_scale:  [1.0, 1.0]
Epoch :  254  Time:  2.729  Rel. Train L2 Loss :  0.01099589180201292  Rel. Test L2 Loss :  0.012391464561223984  Test L2 Loss :  0.022675324901938437  inv_L_scale:  [1.0, 1.0]
Epoch :  255  Time:  2.729  Rel. Train L2 Loss :  0.01109232342077626  Rel. Test L2 Loss :  0.012773656696081161  Test L2 Loss :  0.02367860659956932  inv_L_scale:  [1.0, 1.0]
Epoch :  256  Time:  2.73  Rel. Train L2 Loss :  0.010962119570208921  Rel. Test L2 Loss :  0.01361439548432827  Test L2 Loss :  0.025327568277716636  inv_L_scale:  [1.0, 1.0]
Epoch :  257  Time:  2.731  Rel. Train L2 Loss :  0.011170195212794675  Rel. Test L2 Loss :  0.012724740207195282  Test L2 Loss :  0.023235061168670655  inv_L_scale:  [1.0, 1.0]
Epoch :  258  Time:  2.73  Rel. Train L2 Loss :  0.0108943200773663  Rel. Test L2 Loss :  0.013180919587612153  Test L2 Loss :  0.02397012837231159  inv_L_scale:  [1.0, 1.0]
Epoch :  259  Time:  2.73  Rel. Train L2 Loss :  0.010729099909464518  Rel. Test L2 Loss :  0.012532776892185212  Test L2 Loss :  0.022909247800707817  inv_L_scale:  [1.0, 1.0]
Epoch :  260  Time:  2.729  Rel. Train L2 Loss :  0.010950992070138454  Rel. Test L2 Loss :  0.012165871635079383  Test L2 Loss :  0.022308686524629594  inv_L_scale:  [1.0, 1.0]
Epoch :  261  Time:  2.73  Rel. Train L2 Loss :  0.010400256059235996  Rel. Test L2 Loss :  0.012473391443490982  Test L2 Loss :  0.022736180275678634  inv_L_scale:  [1.0, 1.0]
Epoch :  262  Time:  2.731  Rel. Train L2 Loss :  0.010360890390972296  Rel. Test L2 Loss :  0.01168456707149744  Test L2 Loss :  0.021447392255067824  inv_L_scale:  [1.0, 1.0]
Epoch :  263  Time:  2.771  Rel. Train L2 Loss :  0.010198172368109226  Rel. Test L2 Loss :  0.011751774325966835  Test L2 Loss :  0.02149466872215271  inv_L_scale:  [1.0, 1.0]
Epoch :  264  Time:  5.919  Rel. Train L2 Loss :  0.010677639332910379  Rel. Test L2 Loss :  0.012930731102824212  Test L2 Loss :  0.023701043576002122  inv_L_scale:  [1.0, 1.0]
Epoch :  265  Time:  6.512  Rel. Train L2 Loss :  0.010713003381258912  Rel. Test L2 Loss :  0.012601727247238159  Test L2 Loss :  0.02280143342912197  inv_L_scale:  [1.0, 1.0]
Epoch :  266  Time:  2.763  Rel. Train L2 Loss :  0.010508971396419736  Rel. Test L2 Loss :  0.012980262190103531  Test L2 Loss :  0.024050332903862  inv_L_scale:  [1.0, 1.0]
Epoch :  267  Time:  2.731  Rel. Train L2 Loss :  0.010409203668435415  Rel. Test L2 Loss :  0.01169353075325489  Test L2 Loss :  0.021232549995183946  inv_L_scale:  [1.0, 1.0]
Epoch :  268  Time:  2.731  Rel. Train L2 Loss :  0.009781096445189583  Rel. Test L2 Loss :  0.012776523903012276  Test L2 Loss :  0.02324761688709259  inv_L_scale:  [1.0, 1.0]
Epoch :  269  Time:  2.731  Rel. Train L2 Loss :  0.010461688646011883  Rel. Test L2 Loss :  0.011732561141252517  Test L2 Loss :  0.021513394787907602  inv_L_scale:  [1.0, 1.0]
Epoch :  270  Time:  2.731  Rel. Train L2 Loss :  0.010225285105407237  Rel. Test L2 Loss :  0.011457054615020753  Test L2 Loss :  0.021003527343273164  inv_L_scale:  [1.0, 1.0]
Epoch :  271  Time:  2.731  Rel. Train L2 Loss :  0.010723103284835816  Rel. Test L2 Loss :  0.013992305397987365  Test L2 Loss :  0.025897643864154815  inv_L_scale:  [1.0, 1.0]
Epoch :  272  Time:  2.754  Rel. Train L2 Loss :  0.010633715995483928  Rel. Test L2 Loss :  0.014446144364774227  Test L2 Loss :  0.027362820506095887  inv_L_scale:  [1.0, 1.0]
Epoch :  273  Time:  2.73  Rel. Train L2 Loss :  0.01077024353047212  Rel. Test L2 Loss :  0.01197265762835741  Test L2 Loss :  0.0220630656927824  inv_L_scale:  [1.0, 1.0]
Epoch :  274  Time:  2.729  Rel. Train L2 Loss :  0.010158112078077264  Rel. Test L2 Loss :  0.012089033350348473  Test L2 Loss :  0.022243127822875977  inv_L_scale:  [1.0, 1.0]
Epoch :  275  Time:  2.729  Rel. Train L2 Loss :  0.010540851391851902  Rel. Test L2 Loss :  0.013811192512512206  Test L2 Loss :  0.025057184398174285  inv_L_scale:  [1.0, 1.0]
Epoch :  276  Time:  2.761  Rel. Train L2 Loss :  0.010327348303463725  Rel. Test L2 Loss :  0.012321454733610153  Test L2 Loss :  0.022566092014312745  inv_L_scale:  [1.0, 1.0]
Epoch :  277  Time:  2.733  Rel. Train L2 Loss :  0.010395342504812612  Rel. Test L2 Loss :  0.012961645796895026  Test L2 Loss :  0.02379762753844261  inv_L_scale:  [1.0, 1.0]
Epoch :  278  Time:  2.73  Rel. Train L2 Loss :  0.01025743011592163  Rel. Test L2 Loss :  0.011969020143151283  Test L2 Loss :  0.02192897319793701  inv_L_scale:  [1.0, 1.0]
Epoch :  279  Time:  2.763  Rel. Train L2 Loss :  0.01002668901036183  Rel. Test L2 Loss :  0.012409958839416504  Test L2 Loss :  0.022768340706825256  inv_L_scale:  [1.0, 1.0]
Epoch :  280  Time:  2.733  Rel. Train L2 Loss :  0.00999615519411034  Rel. Test L2 Loss :  0.01144482173025608  Test L2 Loss :  0.021122058629989626  inv_L_scale:  [1.0, 1.0]
Epoch :  281  Time:  2.73  Rel. Train L2 Loss :  0.01014030810031626  Rel. Test L2 Loss :  0.011320318281650543  Test L2 Loss :  0.020754402726888655  inv_L_scale:  [1.0, 1.0]
Epoch :  282  Time:  2.731  Rel. Train L2 Loss :  0.010136247852610218  Rel. Test L2 Loss :  0.01159351535141468  Test L2 Loss :  0.02120280347764492  inv_L_scale:  [1.0, 1.0]
Epoch :  283  Time:  2.84  Rel. Train L2 Loss :  0.00979061581608322  Rel. Test L2 Loss :  0.011303679384291172  Test L2 Loss :  0.02078054368495941  inv_L_scale:  [1.0, 1.0]
Epoch :  284  Time:  12.122  Rel. Train L2 Loss :  0.0095194346167975  Rel. Test L2 Loss :  0.011086695939302444  Test L2 Loss :  0.02032429739832878  inv_L_scale:  [1.0, 1.0]
Epoch :  285  Time:  2.782  Rel. Train L2 Loss :  0.009666324427558316  Rel. Test L2 Loss :  0.011092212125658989  Test L2 Loss :  0.020375003665685655  inv_L_scale:  [1.0, 1.0]
Epoch :  286  Time:  2.73  Rel. Train L2 Loss :  0.009618049454357888  Rel. Test L2 Loss :  0.010808305256068707  Test L2 Loss :  0.019694069772958754  inv_L_scale:  [1.0, 1.0]
Epoch :  287  Time:  2.73  Rel. Train L2 Loss :  0.009458981139792336  Rel. Test L2 Loss :  0.011068646460771561  Test L2 Loss :  0.020314360707998275  inv_L_scale:  [1.0, 1.0]
Epoch :  288  Time:  2.729  Rel. Train L2 Loss :  0.010320512880053785  Rel. Test L2 Loss :  0.011425021402537823  Test L2 Loss :  0.020837167724967003  inv_L_scale:  [1.0, 1.0]
Epoch :  289  Time:  2.729  Rel. Train L2 Loss :  0.009886539499792788  Rel. Test L2 Loss :  0.013379785940051079  Test L2 Loss :  0.024798415154218673  inv_L_scale:  [1.0, 1.0]
Epoch :  290  Time:  2.729  Rel. Train L2 Loss :  0.009556026698814498  Rel. Test L2 Loss :  0.010166673511266709  Test L2 Loss :  0.018677140399813653  inv_L_scale:  [1.0, 1.0]
Epoch :  291  Time:  2.963  Rel. Train L2 Loss :  0.009197436357951826  Rel. Test L2 Loss :  0.011312403194606304  Test L2 Loss :  0.020696864500641822  inv_L_scale:  [1.0, 1.0]
Epoch :  292  Time:  2.73  Rel. Train L2 Loss :  0.009358163370440403  Rel. Test L2 Loss :  0.010796357505023479  Test L2 Loss :  0.019860233142971993  inv_L_scale:  [1.0, 1.0]
Epoch :  293  Time:  2.729  Rel. Train L2 Loss :  0.009384181458089086  Rel. Test L2 Loss :  0.010488073378801345  Test L2 Loss :  0.01918098844587803  inv_L_scale:  [1.0, 1.0]
Epoch :  294  Time:  2.729  Rel. Train L2 Loss :  0.00922258370452457  Rel. Test L2 Loss :  0.011940857172012329  Test L2 Loss :  0.021955815851688387  inv_L_scale:  [1.0, 1.0]
Epoch :  295  Time:  2.863  Rel. Train L2 Loss :  0.009283072505560186  Rel. Test L2 Loss :  0.010764582008123398  Test L2 Loss :  0.019557859152555465  inv_L_scale:  [1.0, 1.0]
Epoch :  296  Time:  2.729  Rel. Train L2 Loss :  0.009081390495929454  Rel. Test L2 Loss :  0.010978689044713974  Test L2 Loss :  0.02001212678849697  inv_L_scale:  [1.0, 1.0]
Epoch :  297  Time:  2.731  Rel. Train L2 Loss :  0.009104846749040815  Rel. Test L2 Loss :  0.010036629289388657  Test L2 Loss :  0.018434003293514252  inv_L_scale:  [1.0, 1.0]
Epoch :  298  Time:  2.819  Rel. Train L2 Loss :  0.009084183735152086  Rel. Test L2 Loss :  0.010202889442443847  Test L2 Loss :  0.018763019293546675  inv_L_scale:  [1.0, 1.0]
Epoch :  299  Time:  3.157  Rel. Train L2 Loss :  0.009524695355859068  Rel. Test L2 Loss :  0.011157941967248917  Test L2 Loss :  0.0207062778621912  inv_L_scale:  [1.0, 1.0]
Epoch :  300  Time:  13.167  Rel. Train L2 Loss :  0.009062208322187265  Rel. Test L2 Loss :  0.010331388413906097  Test L2 Loss :  0.018878712430596353  inv_L_scale:  [1.0, 1.0]
Epoch :  301  Time:  2.733  Rel. Train L2 Loss :  0.008771392359501785  Rel. Test L2 Loss :  0.010180788561701775  Test L2 Loss :  0.01868884690105915  inv_L_scale:  [1.0, 1.0]
Epoch :  302  Time:  2.733  Rel. Train L2 Loss :  0.008772316558493509  Rel. Test L2 Loss :  0.01056977964937687  Test L2 Loss :  0.019379228726029395  inv_L_scale:  [1.0, 1.0]
Epoch :  303  Time:  2.752  Rel. Train L2 Loss :  0.008949747280114226  Rel. Test L2 Loss :  0.009959243088960647  Test L2 Loss :  0.018359924107789992  inv_L_scale:  [1.0, 1.0]
Epoch :  304  Time:  2.731  Rel. Train L2 Loss :  0.008734768293797969  Rel. Test L2 Loss :  0.010001776814460754  Test L2 Loss :  0.018353594839572905  inv_L_scale:  [1.0, 1.0]
Epoch :  305  Time:  2.731  Rel. Train L2 Loss :  0.008839348923001025  Rel. Test L2 Loss :  0.010497754812240601  Test L2 Loss :  0.019295314103364946  inv_L_scale:  [1.0, 1.0]
Epoch :  306  Time:  2.731  Rel. Train L2 Loss :  0.008815638766520553  Rel. Test L2 Loss :  0.01067924402654171  Test L2 Loss :  0.01967430308461189  inv_L_scale:  [1.0, 1.0]
Epoch :  307  Time:  2.731  Rel. Train L2 Loss :  0.008760772434373697  Rel. Test L2 Loss :  0.010867638699710368  Test L2 Loss :  0.019959172010421754  inv_L_scale:  [1.0, 1.0]
Epoch :  308  Time:  2.731  Rel. Train L2 Loss :  0.009072407219145033  Rel. Test L2 Loss :  0.010361843705177308  Test L2 Loss :  0.019059954658150673  inv_L_scale:  [1.0, 1.0]
Epoch :  309  Time:  2.731  Rel. Train L2 Loss :  0.009035355686727498  Rel. Test L2 Loss :  0.01031625609844923  Test L2 Loss :  0.01886191189289093  inv_L_scale:  [1.0, 1.0]
Epoch :  310  Time:  2.73  Rel. Train L2 Loss :  0.008718679928117328  Rel. Test L2 Loss :  0.010044007897377014  Test L2 Loss :  0.018400964960455894  inv_L_scale:  [1.0, 1.0]
Epoch :  311  Time:  2.73  Rel. Train L2 Loss :  0.008788426187303331  Rel. Test L2 Loss :  0.009965474717319012  Test L2 Loss :  0.01830063320696354  inv_L_scale:  [1.0, 1.0]
Epoch :  312  Time:  2.73  Rel. Train L2 Loss :  0.008891194963620768  Rel. Test L2 Loss :  0.011208542175590992  Test L2 Loss :  0.020747092068195343  inv_L_scale:  [1.0, 1.0]
Epoch :  313  Time:  2.729  Rel. Train L2 Loss :  0.008825548080106577  Rel. Test L2 Loss :  0.009648088850080967  Test L2 Loss :  0.017736543715000153  inv_L_scale:  [1.0, 1.0]
Epoch :  314  Time:  2.73  Rel. Train L2 Loss :  0.008411736807061566  Rel. Test L2 Loss :  0.010069129168987273  Test L2 Loss :  0.018607255518436432  inv_L_scale:  [1.0, 1.0]
Epoch :  315  Time:  12.253  Rel. Train L2 Loss :  0.008549500538243188  Rel. Test L2 Loss :  0.009914231151342393  Test L2 Loss :  0.018162158876657487  inv_L_scale:  [1.0, 1.0]
Epoch :  316  Time:  3.099  Rel. Train L2 Loss :  0.008649825687623687  Rel. Test L2 Loss :  0.010297728404402733  Test L2 Loss :  0.019104873985052107  inv_L_scale:  [1.0, 1.0]
Epoch :  317  Time:  2.739  Rel. Train L2 Loss :  0.008539244387712744  Rel. Test L2 Loss :  0.009670962877571583  Test L2 Loss :  0.01765135124325752  inv_L_scale:  [1.0, 1.0]
Epoch :  318  Time:  2.738  Rel. Train L2 Loss :  0.008706558665467634  Rel. Test L2 Loss :  0.010337063148617744  Test L2 Loss :  0.01902334563434124  inv_L_scale:  [1.0, 1.0]
Epoch :  319  Time:  2.738  Rel. Train L2 Loss :  0.008608801170355744  Rel. Test L2 Loss :  0.009517981298267841  Test L2 Loss :  0.017373105213046074  inv_L_scale:  [1.0, 1.0]
Epoch :  320  Time:  2.739  Rel. Train L2 Loss :  0.008354103817707962  Rel. Test L2 Loss :  0.00979635063558817  Test L2 Loss :  0.01792771928012371  inv_L_scale:  [1.0, 1.0]
Epoch :  321  Time:  2.74  Rel. Train L2 Loss :  0.00826819153709544  Rel. Test L2 Loss :  0.009659456238150597  Test L2 Loss :  0.01766535885632038  inv_L_scale:  [1.0, 1.0]
Epoch :  322  Time:  2.74  Rel. Train L2 Loss :  0.008184769170151816  Rel. Test L2 Loss :  0.009574624858796597  Test L2 Loss :  0.017479602545499802  inv_L_scale:  [1.0, 1.0]
Epoch :  323  Time:  2.74  Rel. Train L2 Loss :  0.008265733193192216  Rel. Test L2 Loss :  0.010222243890166283  Test L2 Loss :  0.018535805493593217  inv_L_scale:  [1.0, 1.0]
Epoch :  324  Time:  2.741  Rel. Train L2 Loss :  0.008180617112666369  Rel. Test L2 Loss :  0.009942988157272339  Test L2 Loss :  0.018123954236507415  inv_L_scale:  [1.0, 1.0]
Epoch :  325  Time:  2.742  Rel. Train L2 Loss :  0.008149154173831144  Rel. Test L2 Loss :  0.010209569446742535  Test L2 Loss :  0.018723706528544427  inv_L_scale:  [1.0, 1.0]
Epoch :  326  Time:  2.789  Rel. Train L2 Loss :  0.008069986630645063  Rel. Test L2 Loss :  0.00921493485569954  Test L2 Loss :  0.016915006563067436  inv_L_scale:  [1.0, 1.0]
Epoch :  327  Time:  2.741  Rel. Train L2 Loss :  0.008179788336985641  Rel. Test L2 Loss :  0.010222493633627892  Test L2 Loss :  0.0188187525421381  inv_L_scale:  [1.0, 1.0]
Epoch :  328  Time:  2.74  Rel. Train L2 Loss :  0.008285377495404747  Rel. Test L2 Loss :  0.009141160920262337  Test L2 Loss :  0.01677515506744385  inv_L_scale:  [1.0, 1.0]
Epoch :  329  Time:  2.741  Rel. Train L2 Loss :  0.00799329437315464  Rel. Test L2 Loss :  0.009342103078961373  Test L2 Loss :  0.01713422082364559  inv_L_scale:  [1.0, 1.0]
Epoch :  330  Time:  2.741  Rel. Train L2 Loss :  0.00839792526844475  Rel. Test L2 Loss :  0.009517151117324828  Test L2 Loss :  0.017489644661545754  inv_L_scale:  [1.0, 1.0]
Epoch :  331  Time:  2.741  Rel. Train L2 Loss :  0.008269653767347335  Rel. Test L2 Loss :  0.009653533995151519  Test L2 Loss :  0.01767419256269932  inv_L_scale:  [1.0, 1.0]
Epoch :  332  Time:  2.741  Rel. Train L2 Loss :  0.008059938235415353  Rel. Test L2 Loss :  0.009629199653863907  Test L2 Loss :  0.01769635424017906  inv_L_scale:  [1.0, 1.0]
Epoch :  333  Time:  2.753  Rel. Train L2 Loss :  0.008066007788810465  Rel. Test L2 Loss :  0.009758777804672719  Test L2 Loss :  0.01793064408004284  inv_L_scale:  [1.0, 1.0]
Epoch :  334  Time:  12.419  Rel. Train L2 Loss :  0.008228942735327614  Rel. Test L2 Loss :  0.008991564232856035  Test L2 Loss :  0.016367797665297987  inv_L_scale:  [1.0, 1.0]
Epoch :  335  Time:  3.737  Rel. Train L2 Loss :  0.007976998931003941  Rel. Test L2 Loss :  0.00920021377503872  Test L2 Loss :  0.016893759071826935  inv_L_scale:  [1.0, 1.0]
Epoch :  336  Time:  2.744  Rel. Train L2 Loss :  0.00787841690911187  Rel. Test L2 Loss :  0.009209740906953812  Test L2 Loss :  0.01683721512556076  inv_L_scale:  [1.0, 1.0]
Epoch :  337  Time:  2.742  Rel. Train L2 Loss :  0.007970318790111277  Rel. Test L2 Loss :  0.0093978501111269  Test L2 Loss :  0.017464632615447045  inv_L_scale:  [1.0, 1.0]
Epoch :  338  Time:  2.742  Rel. Train L2 Loss :  0.007714182945589224  Rel. Test L2 Loss :  0.009733994454145432  Test L2 Loss :  0.018105473294854166  inv_L_scale:  [1.0, 1.0]
Epoch :  339  Time:  2.742  Rel. Train L2 Loss :  0.007874032105836603  Rel. Test L2 Loss :  0.0090641113743186  Test L2 Loss :  0.016636334881186484  inv_L_scale:  [1.0, 1.0]
Epoch :  340  Time:  2.742  Rel. Train L2 Loss :  0.0077351649146940975  Rel. Test L2 Loss :  0.008866899870336056  Test L2 Loss :  0.016145698130130767  inv_L_scale:  [1.0, 1.0]
Epoch :  341  Time:  2.744  Rel. Train L2 Loss :  0.007822967401395242  Rel. Test L2 Loss :  0.008633499443531036  Test L2 Loss :  0.015903676897287368  inv_L_scale:  [1.0, 1.0]
Epoch :  342  Time:  2.742  Rel. Train L2 Loss :  0.007580283847120073  Rel. Test L2 Loss :  0.00935390718281269  Test L2 Loss :  0.017243072539567948  inv_L_scale:  [1.0, 1.0]
Epoch :  343  Time:  2.742  Rel. Train L2 Loss :  0.007558424158228768  Rel. Test L2 Loss :  0.009140322171151637  Test L2 Loss :  0.016681090891361237  inv_L_scale:  [1.0, 1.0]
Epoch :  344  Time:  2.741  Rel. Train L2 Loss :  0.007524624795963367  Rel. Test L2 Loss :  0.009241233244538308  Test L2 Loss :  0.016831295937299727  inv_L_scale:  [1.0, 1.0]
Epoch :  345  Time:  2.741  Rel. Train L2 Loss :  0.007778057211803065  Rel. Test L2 Loss :  0.009726435095071793  Test L2 Loss :  0.01802767626941204  inv_L_scale:  [1.0, 1.0]
Epoch :  346  Time:  2.742  Rel. Train L2 Loss :  0.0076326783808569115  Rel. Test L2 Loss :  0.008730374723672867  Test L2 Loss :  0.015973984785377978  inv_L_scale:  [1.0, 1.0]
Epoch :  347  Time:  2.741  Rel. Train L2 Loss :  0.007457124708841244  Rel. Test L2 Loss :  0.008908091150224208  Test L2 Loss :  0.016499761268496515  inv_L_scale:  [1.0, 1.0]
Epoch :  348  Time:  2.742  Rel. Train L2 Loss :  0.00747879589183463  Rel. Test L2 Loss :  0.009158050678670406  Test L2 Loss :  0.01673464126884937  inv_L_scale:  [1.0, 1.0]
Epoch :  349  Time:  2.741  Rel. Train L2 Loss :  0.007633847503198518  Rel. Test L2 Loss :  0.009464690089225769  Test L2 Loss :  0.017174088507890702  inv_L_scale:  [1.0, 1.0]
Epoch :  350  Time:  2.742  Rel. Train L2 Loss :  0.007728040027949545  Rel. Test L2 Loss :  0.008554344549775123  Test L2 Loss :  0.01581108517944813  inv_L_scale:  [1.0, 1.0]
Epoch :  351  Time:  2.741  Rel. Train L2 Loss :  0.007316582339505355  Rel. Test L2 Loss :  0.008779520057141782  Test L2 Loss :  0.016102917194366455  inv_L_scale:  [1.0, 1.0]
Epoch :  352  Time:  5.049  Rel. Train L2 Loss :  0.0073849482047888965  Rel. Test L2 Loss :  0.00891790509223938  Test L2 Loss :  0.016315100789070128  inv_L_scale:  [1.0, 1.0]
Epoch :  353  Time:  2.743  Rel. Train L2 Loss :  0.007468120720651414  Rel. Test L2 Loss :  0.008714505173265934  Test L2 Loss :  0.016064696311950684  inv_L_scale:  [1.0, 1.0]
Epoch :  354  Time:  2.74  Rel. Train L2 Loss :  0.00748227257695463  Rel. Test L2 Loss :  0.0087527871504426  Test L2 Loss :  0.01601560991257429  inv_L_scale:  [1.0, 1.0]
Epoch :  355  Time:  2.741  Rel. Train L2 Loss :  0.007386684918569194  Rel. Test L2 Loss :  0.008422417789697647  Test L2 Loss :  0.015500017367303371  inv_L_scale:  [1.0, 1.0]
Epoch :  356  Time:  2.741  Rel. Train L2 Loss :  0.007184117316371865  Rel. Test L2 Loss :  0.008959087878465652  Test L2 Loss :  0.016662238538265227  inv_L_scale:  [1.0, 1.0]
Epoch :  357  Time:  2.74  Rel. Train L2 Loss :  0.007377610893713103  Rel. Test L2 Loss :  0.009042625911533833  Test L2 Loss :  0.01660309188067913  inv_L_scale:  [1.0, 1.0]
Epoch :  358  Time:  2.74  Rel. Train L2 Loss :  0.007421839928461446  Rel. Test L2 Loss :  0.008557653650641442  Test L2 Loss :  0.015759609937667847  inv_L_scale:  [1.0, 1.0]
Epoch :  359  Time:  2.74  Rel. Train L2 Loss :  0.007190332350631555  Rel. Test L2 Loss :  0.008614686094224453  Test L2 Loss :  0.015801880806684494  inv_L_scale:  [1.0, 1.0]
Epoch :  360  Time:  2.74  Rel. Train L2 Loss :  0.007261320818215609  Rel. Test L2 Loss :  0.00829392697662115  Test L2 Loss :  0.01520269714295864  inv_L_scale:  [1.0, 1.0]
Epoch :  361  Time:  2.742  Rel. Train L2 Loss :  0.0072796786059108045  Rel. Test L2 Loss :  0.008603231757879257  Test L2 Loss :  0.01566945366561413  inv_L_scale:  [1.0, 1.0]
Epoch :  362  Time:  2.74  Rel. Train L2 Loss :  0.007037220551735825  Rel. Test L2 Loss :  0.008500556014478206  Test L2 Loss :  0.015546140633523465  inv_L_scale:  [1.0, 1.0]
Epoch :  363  Time:  2.74  Rel. Train L2 Loss :  0.007614674145976702  Rel. Test L2 Loss :  0.008611098527908326  Test L2 Loss :  0.01573135644197464  inv_L_scale:  [1.0, 1.0]
Epoch :  364  Time:  2.739  Rel. Train L2 Loss :  0.007329839910897943  Rel. Test L2 Loss :  0.00846325296908617  Test L2 Loss :  0.015496700890362263  inv_L_scale:  [1.0, 1.0]
Epoch :  365  Time:  2.739  Rel. Train L2 Loss :  0.007100398329397043  Rel. Test L2 Loss :  0.00875899787992239  Test L2 Loss :  0.016200684681534766  inv_L_scale:  [1.0, 1.0]
Epoch :  366  Time:  2.74  Rel. Train L2 Loss :  0.007131525286369854  Rel. Test L2 Loss :  0.008206561878323556  Test L2 Loss :  0.015046245753765106  inv_L_scale:  [1.0, 1.0]
Epoch :  367  Time:  2.74  Rel. Train L2 Loss :  0.006907537140780025  Rel. Test L2 Loss :  0.008460107184946537  Test L2 Loss :  0.015536369606852531  inv_L_scale:  [1.0, 1.0]
Epoch :  368  Time:  2.817  Rel. Train L2 Loss :  0.00693116712073485  Rel. Test L2 Loss :  0.00802214914932847  Test L2 Loss :  0.014706231728196144  inv_L_scale:  [1.0, 1.0]
Epoch :  369  Time:  2.739  Rel. Train L2 Loss :  0.00699673710597886  Rel. Test L2 Loss :  0.008373960852622986  Test L2 Loss :  0.015476223751902581  inv_L_scale:  [1.0, 1.0]
Epoch :  370  Time:  2.74  Rel. Train L2 Loss :  0.006901313869489564  Rel. Test L2 Loss :  0.008451185524463653  Test L2 Loss :  0.015540246516466141  inv_L_scale:  [1.0, 1.0]
Epoch :  371  Time:  12.89  Rel. Train L2 Loss :  0.006924264505505562  Rel. Test L2 Loss :  0.008283883165568114  Test L2 Loss :  0.015236095711588859  inv_L_scale:  [1.0, 1.0]
Epoch :  372  Time:  2.745  Rel. Train L2 Loss :  0.006867574623061551  Rel. Test L2 Loss :  0.008399193473160267  Test L2 Loss :  0.015392577648162842  inv_L_scale:  [1.0, 1.0]
Epoch :  373  Time:  2.739  Rel. Train L2 Loss :  0.006937388160990344  Rel. Test L2 Loss :  0.008318913951516151  Test L2 Loss :  0.015145965553820133  inv_L_scale:  [1.0, 1.0]
Epoch :  374  Time:  2.739  Rel. Train L2 Loss :  0.006931895688176155  Rel. Test L2 Loss :  0.00827727308496833  Test L2 Loss :  0.01519322942942381  inv_L_scale:  [1.0, 1.0]
Epoch :  375  Time:  2.738  Rel. Train L2 Loss :  0.006797977857705619  Rel. Test L2 Loss :  0.00794275002554059  Test L2 Loss :  0.014502349309623241  inv_L_scale:  [1.0, 1.0]
Epoch :  376  Time:  2.739  Rel. Train L2 Loss :  0.00680993659214841  Rel. Test L2 Loss :  0.00813118152320385  Test L2 Loss :  0.014918174371123314  inv_L_scale:  [1.0, 1.0]
Epoch :  377  Time:  2.738  Rel. Train L2 Loss :  0.006877324506640434  Rel. Test L2 Loss :  0.008101079519838095  Test L2 Loss :  0.014892841801047324  inv_L_scale:  [1.0, 1.0]
Epoch :  378  Time:  2.784  Rel. Train L2 Loss :  0.0067832429479393695  Rel. Test L2 Loss :  0.008084564562886953  Test L2 Loss :  0.014854507856070995  inv_L_scale:  [1.0, 1.0]
Epoch :  379  Time:  2.737  Rel. Train L2 Loss :  0.006634097130348285  Rel. Test L2 Loss :  0.0077349326759576795  Test L2 Loss :  0.014195333942770958  inv_L_scale:  [1.0, 1.0]
Epoch :  380  Time:  2.738  Rel. Train L2 Loss :  0.006655856166034937  Rel. Test L2 Loss :  0.007957131639122962  Test L2 Loss :  0.014589114040136337  inv_L_scale:  [1.0, 1.0]
Epoch :  381  Time:  2.737  Rel. Train L2 Loss :  0.006673405758208698  Rel. Test L2 Loss :  0.008034387677907944  Test L2 Loss :  0.014711184613406657  inv_L_scale:  [1.0, 1.0]
Epoch :  382  Time:  2.761  Rel. Train L2 Loss :  0.006666497811675071  Rel. Test L2 Loss :  0.008053748607635499  Test L2 Loss :  0.0148856121301651  inv_L_scale:  [1.0, 1.0]
Epoch :  383  Time:  2.738  Rel. Train L2 Loss :  0.006885654582745499  Rel. Test L2 Loss :  0.008195675201714039  Test L2 Loss :  0.014987604506313802  inv_L_scale:  [1.0, 1.0]
Epoch :  384  Time:  2.737  Rel. Train L2 Loss :  0.006877733050949044  Rel. Test L2 Loss :  0.00798940185457468  Test L2 Loss :  0.014618014246225356  inv_L_scale:  [1.0, 1.0]
Epoch :  385  Time:  3.21  Rel. Train L2 Loss :  0.006759127782036861  Rel. Test L2 Loss :  0.008029414862394333  Test L2 Loss :  0.014721596650779246  inv_L_scale:  [1.0, 1.0]
Epoch :  386  Time:  2.738  Rel. Train L2 Loss :  0.0067175464228623446  Rel. Test L2 Loss :  0.007835250478237868  Test L2 Loss :  0.014400279074907303  inv_L_scale:  [1.0, 1.0]
Epoch :  387  Time:  2.738  Rel. Train L2 Loss :  0.006610217582848337  Rel. Test L2 Loss :  0.008109263312071562  Test L2 Loss :  0.014970760308206082  inv_L_scale:  [1.0, 1.0]
Epoch :  388  Time:  11.259  Rel. Train L2 Loss :  0.006649970064560572  Rel. Test L2 Loss :  0.00820559723302722  Test L2 Loss :  0.01507822286337614  inv_L_scale:  [1.0, 1.0]
Epoch :  389  Time:  3.777  Rel. Train L2 Loss :  0.0065765548456046315  Rel. Test L2 Loss :  0.007735607251524925  Test L2 Loss :  0.01410895559936762  inv_L_scale:  [1.0, 1.0]
Epoch :  390  Time:  2.732  Rel. Train L2 Loss :  0.0065906187478039  Rel. Test L2 Loss :  0.007769534029066562  Test L2 Loss :  0.014277047887444496  inv_L_scale:  [1.0, 1.0]
Epoch :  391  Time:  2.732  Rel. Train L2 Loss :  0.006713546759759386  Rel. Test L2 Loss :  0.007936197072267533  Test L2 Loss :  0.014571872539818287  inv_L_scale:  [1.0, 1.0]
Epoch :  392  Time:  2.732  Rel. Train L2 Loss :  0.0065578464211689105  Rel. Test L2 Loss :  0.007954784370958805  Test L2 Loss :  0.014646690413355827  inv_L_scale:  [1.0, 1.0]
Epoch :  393  Time:  2.732  Rel. Train L2 Loss :  0.006478327684518364  Rel. Test L2 Loss :  0.007670636586844921  Test L2 Loss :  0.014038293436169625  inv_L_scale:  [1.0, 1.0]
Epoch :  394  Time:  2.732  Rel. Train L2 Loss :  0.0065260205811096565  Rel. Test L2 Loss :  0.007609322965145111  Test L2 Loss :  0.014010789580643177  inv_L_scale:  [1.0, 1.0]
Epoch :  395  Time:  2.734  Rel. Train L2 Loss :  0.0064688341319561  Rel. Test L2 Loss :  0.007669862359762192  Test L2 Loss :  0.014033678621053695  inv_L_scale:  [1.0, 1.0]
Epoch :  396  Time:  2.732  Rel. Train L2 Loss :  0.006412304093440374  Rel. Test L2 Loss :  0.007596629001200199  Test L2 Loss :  0.013890024237334729  inv_L_scale:  [1.0, 1.0]
Epoch :  397  Time:  2.732  Rel. Train L2 Loss :  0.006458972011589342  Rel. Test L2 Loss :  0.007846929989755154  Test L2 Loss :  0.01440708439797163  inv_L_scale:  [1.0, 1.0]
Epoch :  398  Time:  2.732  Rel. Train L2 Loss :  0.006350536116709312  Rel. Test L2 Loss :  0.007693617269396782  Test L2 Loss :  0.014047059714794159  inv_L_scale:  [1.0, 1.0]
Epoch :  399  Time:  2.732  Rel. Train L2 Loss :  0.006317249755892489  Rel. Test L2 Loss :  0.007574142292141915  Test L2 Loss :  0.013929154090583325  inv_L_scale:  [1.0, 1.0]
Epoch :  400  Time:  2.734  Rel. Train L2 Loss :  0.006357180554833677  Rel. Test L2 Loss :  0.007653642501682043  Test L2 Loss :  0.014000051617622376  inv_L_scale:  [1.0, 1.0]
Epoch :  401  Time:  2.732  Rel. Train L2 Loss :  0.006371044183356894  Rel. Test L2 Loss :  0.007594077475368976  Test L2 Loss :  0.013963393308222294  inv_L_scale:  [1.0, 1.0]
Epoch :  402  Time:  2.732  Rel. Train L2 Loss :  0.0063270312092370455  Rel. Test L2 Loss :  0.007429995648562908  Test L2 Loss :  0.013654203973710538  inv_L_scale:  [1.0, 1.0]
Epoch :  403  Time:  2.731  Rel. Train L2 Loss :  0.0062254402196655675  Rel. Test L2 Loss :  0.007393438257277012  Test L2 Loss :  0.013580913618206979  inv_L_scale:  [1.0, 1.0]
Epoch :  404  Time:  2.732  Rel. Train L2 Loss :  0.006295838455359141  Rel. Test L2 Loss :  0.007494213972240687  Test L2 Loss :  0.013706179447472095  inv_L_scale:  [1.0, 1.0]
Epoch :  405  Time:  3.359  Rel. Train L2 Loss :  0.006219545944283406  Rel. Test L2 Loss :  0.007610961496829986  Test L2 Loss :  0.013930616825819015  inv_L_scale:  [1.0, 1.0]
Epoch :  406  Time:  13.707  Rel. Train L2 Loss :  0.006232887595478032  Rel. Test L2 Loss :  0.007475842535495758  Test L2 Loss :  0.013741826489567757  inv_L_scale:  [1.0, 1.0]
Epoch :  407  Time:  2.812  Rel. Train L2 Loss :  0.006398992863380247  Rel. Test L2 Loss :  0.007429676167666912  Test L2 Loss :  0.01359777271747589  inv_L_scale:  [1.0, 1.0]
Epoch :  408  Time:  2.735  Rel. Train L2 Loss :  0.006188130043447018  Rel. Test L2 Loss :  0.007450446151196956  Test L2 Loss :  0.013637452311813831  inv_L_scale:  [1.0, 1.0]
Epoch :  409  Time:  3.066  Rel. Train L2 Loss :  0.006247879227416383  Rel. Test L2 Loss :  0.007545468658208847  Test L2 Loss :  0.013798240721225739  inv_L_scale:  [1.0, 1.0]
Epoch :  410  Time:  2.748  Rel. Train L2 Loss :  0.006208126549091604  Rel. Test L2 Loss :  0.007390412613749504  Test L2 Loss :  0.01357379425317049  inv_L_scale:  [1.0, 1.0]
Epoch :  411  Time:  2.735  Rel. Train L2 Loss :  0.00608844750871261  Rel. Test L2 Loss :  0.007359333895146846  Test L2 Loss :  0.013527779169380664  inv_L_scale:  [1.0, 1.0]
Epoch :  412  Time:  2.735  Rel. Train L2 Loss :  0.006138229434274965  Rel. Test L2 Loss :  0.0076155726052820685  Test L2 Loss :  0.013998898714780807  inv_L_scale:  [1.0, 1.0]
Epoch :  413  Time:  2.947  Rel. Train L2 Loss :  0.006140376288029882  Rel. Test L2 Loss :  0.0073843329958617684  Test L2 Loss :  0.01353092521429062  inv_L_scale:  [1.0, 1.0]
Epoch :  414  Time:  2.736  Rel. Train L2 Loss :  0.00610247355989284  Rel. Test L2 Loss :  0.007378802634775639  Test L2 Loss :  0.013514251932501792  inv_L_scale:  [1.0, 1.0]
Epoch :  415  Time:  2.738  Rel. Train L2 Loss :  0.006089675966650248  Rel. Test L2 Loss :  0.00742359172552824  Test L2 Loss :  0.013527438268065453  inv_L_scale:  [1.0, 1.0]
Epoch :  416  Time:  2.736  Rel. Train L2 Loss :  0.00607176245500644  Rel. Test L2 Loss :  0.0076913943141698835  Test L2 Loss :  0.014197879135608674  inv_L_scale:  [1.0, 1.0]
Epoch :  417  Time:  4.412  Rel. Train L2 Loss :  0.006139951097882456  Rel. Test L2 Loss :  0.007278127316385508  Test L2 Loss :  0.013297651745378971  inv_L_scale:  [1.0, 1.0]
Epoch :  418  Time:  2.737  Rel. Train L2 Loss :  0.006062031038519409  Rel. Test L2 Loss :  0.007294218093156815  Test L2 Loss :  0.013375645279884338  inv_L_scale:  [1.0, 1.0]
Epoch :  419  Time:  2.737  Rel. Train L2 Loss :  0.006032292890465922  Rel. Test L2 Loss :  0.007278837449848652  Test L2 Loss :  0.013327479176223279  inv_L_scale:  [1.0, 1.0]
Epoch :  420  Time:  3.243  Rel. Train L2 Loss :  0.00603292468107409  Rel. Test L2 Loss :  0.007301273085176945  Test L2 Loss :  0.013407571092247963  inv_L_scale:  [1.0, 1.0]
Epoch :  421  Time:  11.672  Rel. Train L2 Loss :  0.0060699128607908884  Rel. Test L2 Loss :  0.007274983897805214  Test L2 Loss :  0.013360038995742798  inv_L_scale:  [1.0, 1.0]
Epoch :  422  Time:  2.923  Rel. Train L2 Loss :  0.006001910443107287  Rel. Test L2 Loss :  0.007265131622552871  Test L2 Loss :  0.01329001396894455  inv_L_scale:  [1.0, 1.0]
Epoch :  423  Time:  2.734  Rel. Train L2 Loss :  0.005982913016859028  Rel. Test L2 Loss :  0.007267325595021248  Test L2 Loss :  0.013316796272993087  inv_L_scale:  [1.0, 1.0]
Epoch :  424  Time:  2.733  Rel. Train L2 Loss :  0.006025828905403614  Rel. Test L2 Loss :  0.007285780552774668  Test L2 Loss :  0.013346122428774834  inv_L_scale:  [1.0, 1.0]
Epoch :  425  Time:  2.933  Rel. Train L2 Loss :  0.006000556293874979  Rel. Test L2 Loss :  0.007216225396841764  Test L2 Loss :  0.013240756392478943  inv_L_scale:  [1.0, 1.0]
Epoch :  426  Time:  2.731  Rel. Train L2 Loss :  0.005969050166507562  Rel. Test L2 Loss :  0.007259418703615666  Test L2 Loss :  0.013264207616448403  inv_L_scale:  [1.0, 1.0]
Epoch :  427  Time:  2.731  Rel. Train L2 Loss :  0.0059184074588119985  Rel. Test L2 Loss :  0.0071159547194838526  Test L2 Loss :  0.013059952333569526  inv_L_scale:  [1.0, 1.0]
Epoch :  428  Time:  2.731  Rel. Train L2 Loss :  0.0059197572287586  Rel. Test L2 Loss :  0.007199269011616707  Test L2 Loss :  0.013183956891298294  inv_L_scale:  [1.0, 1.0]
Epoch :  429  Time:  2.731  Rel. Train L2 Loss :  0.005920159698774417  Rel. Test L2 Loss :  0.007287269607186318  Test L2 Loss :  0.013347166068851947  inv_L_scale:  [1.0, 1.0]
Epoch :  430  Time:  2.731  Rel. Train L2 Loss :  0.005908336345520284  Rel. Test L2 Loss :  0.007195624951273203  Test L2 Loss :  0.013176025226712226  inv_L_scale:  [1.0, 1.0]
Epoch :  431  Time:  2.73  Rel. Train L2 Loss :  0.0058932605509956675  Rel. Test L2 Loss :  0.0071528243646025655  Test L2 Loss :  0.013092039898037911  inv_L_scale:  [1.0, 1.0]
Epoch :  432  Time:  2.731  Rel. Train L2 Loss :  0.0058855702645248835  Rel. Test L2 Loss :  0.007382034305483103  Test L2 Loss :  0.013521208502352238  inv_L_scale:  [1.0, 1.0]
Epoch :  433  Time:  2.731  Rel. Train L2 Loss :  0.005877947287840976  Rel. Test L2 Loss :  0.007157627735286951  Test L2 Loss :  0.013086203522980212  inv_L_scale:  [1.0, 1.0]
Epoch :  434  Time:  2.732  Rel. Train L2 Loss :  0.005831826616906457  Rel. Test L2 Loss :  0.007154943980276584  Test L2 Loss :  0.013110066279768944  inv_L_scale:  [1.0, 1.0]
Epoch :  435  Time:  2.731  Rel. Train L2 Loss :  0.0058444518720110255  Rel. Test L2 Loss :  0.007117045670747757  Test L2 Loss :  0.013043527752161025  inv_L_scale:  [1.0, 1.0]
Epoch :  436  Time:  4.017  Rel. Train L2 Loss :  0.005857883623490731  Rel. Test L2 Loss :  0.007133602127432823  Test L2 Loss :  0.01308024924248457  inv_L_scale:  [1.0, 1.0]
Epoch :  437  Time:  12.41  Rel. Train L2 Loss :  0.005834360346198082  Rel. Test L2 Loss :  0.0071295926347374914  Test L2 Loss :  0.013061903789639473  inv_L_scale:  [1.0, 1.0]
Epoch :  438  Time:  2.803  Rel. Train L2 Loss :  0.005825712500760953  Rel. Test L2 Loss :  0.007072432264685631  Test L2 Loss :  0.012982291281223296  inv_L_scale:  [1.0, 1.0]
Epoch :  439  Time:  2.737  Rel. Train L2 Loss :  0.005800944343209266  Rel. Test L2 Loss :  0.007093879915773868  Test L2 Loss :  0.013006939962506294  inv_L_scale:  [1.0, 1.0]
Epoch :  440  Time:  2.736  Rel. Train L2 Loss :  0.005833113189372752  Rel. Test L2 Loss :  0.007095048129558563  Test L2 Loss :  0.012998226433992385  inv_L_scale:  [1.0, 1.0]
Epoch :  441  Time:  2.736  Rel. Train L2 Loss :  0.005808864587710964  Rel. Test L2 Loss :  0.007072852849960327  Test L2 Loss :  0.01294254295527935  inv_L_scale:  [1.0, 1.0]
Epoch :  442  Time:  2.736  Rel. Train L2 Loss :  0.005761715847377976  Rel. Test L2 Loss :  0.007077622674405575  Test L2 Loss :  0.012954686358571053  inv_L_scale:  [1.0, 1.0]
Epoch :  443  Time:  2.882  Rel. Train L2 Loss :  0.005767440307471487  Rel. Test L2 Loss :  0.00709696564823389  Test L2 Loss :  0.013016560450196266  inv_L_scale:  [1.0, 1.0]
Epoch :  444  Time:  2.736  Rel. Train L2 Loss :  0.005745361379037301  Rel. Test L2 Loss :  0.007062639892101288  Test L2 Loss :  0.012914952151477336  inv_L_scale:  [1.0, 1.0]
Epoch :  445  Time:  2.734  Rel. Train L2 Loss :  0.005760319324003326  Rel. Test L2 Loss :  0.007011053431779146  Test L2 Loss :  0.012863858491182328  inv_L_scale:  [1.0, 1.0]
Epoch :  446  Time:  2.733  Rel. Train L2 Loss :  0.00575277952891257  Rel. Test L2 Loss :  0.007047063745558262  Test L2 Loss :  0.012920428663492203  inv_L_scale:  [1.0, 1.0]
Epoch :  447  Time:  3.079  Rel. Train L2 Loss :  0.0057416382369895776  Rel. Test L2 Loss :  0.007027341313660145  Test L2 Loss :  0.012880650274455547  inv_L_scale:  [1.0, 1.0]
Epoch :  448  Time:  2.735  Rel. Train L2 Loss :  0.00575588457700279  Rel. Test L2 Loss :  0.007064453363418579  Test L2 Loss :  0.012914488427340984  inv_L_scale:  [1.0, 1.0]
Epoch :  449  Time:  2.735  Rel. Train L2 Loss :  0.005747617882572943  Rel. Test L2 Loss :  0.007017788104712963  Test L2 Loss :  0.012858327627182007  inv_L_scale:  [1.0, 1.0]
Epoch :  450  Time:  2.736  Rel. Train L2 Loss :  0.005722944893770747  Rel. Test L2 Loss :  0.007017082422971725  Test L2 Loss :  0.012857081145048141  inv_L_scale:  [1.0, 1.0]
Epoch :  451  Time:  2.824  Rel. Train L2 Loss :  0.005708007485502296  Rel. Test L2 Loss :  0.006998404525220394  Test L2 Loss :  0.012841312810778618  inv_L_scale:  [1.0, 1.0]
Epoch :  452  Time:  2.736  Rel. Train L2 Loss :  0.005706534644381867  Rel. Test L2 Loss :  0.007018318176269531  Test L2 Loss :  0.012893729582428933  inv_L_scale:  [1.0, 1.0]
Epoch :  453  Time:  2.735  Rel. Train L2 Loss :  0.005690212616076072  Rel. Test L2 Loss :  0.0070191845297813416  Test L2 Loss :  0.012851521372795105  inv_L_scale:  [1.0, 1.0]
Epoch :  454  Time:  2.983  Rel. Train L2 Loss :  0.005685335269404782  Rel. Test L2 Loss :  0.006984192598611117  Test L2 Loss :  0.012805158384144305  inv_L_scale:  [1.0, 1.0]
Epoch :  455  Time:  2.8  Rel. Train L2 Loss :  0.005688389380358988  Rel. Test L2 Loss :  0.006963132694363594  Test L2 Loss :  0.01276862420141697  inv_L_scale:  [1.0, 1.0]
Epoch :  456  Time:  2.863  Rel. Train L2 Loss :  0.005667116192893849  Rel. Test L2 Loss :  0.00694744423031807  Test L2 Loss :  0.012747559994459152  inv_L_scale:  [1.0, 1.0]
Epoch :  457  Time:  13.889  Rel. Train L2 Loss :  0.005659421818951765  Rel. Test L2 Loss :  0.0069353519007563594  Test L2 Loss :  0.012723394185304642  inv_L_scale:  [1.0, 1.0]
Epoch :  458  Time:  2.734  Rel. Train L2 Loss :  0.005658946051779721  Rel. Test L2 Loss :  0.006900027170777321  Test L2 Loss :  0.012658422701060773  inv_L_scale:  [1.0, 1.0]
Epoch :  459  Time:  2.731  Rel. Train L2 Loss :  0.005645618062052462  Rel. Test L2 Loss :  0.0069262562692165375  Test L2 Loss :  0.012695688605308533  inv_L_scale:  [1.0, 1.0]
Epoch :  460  Time:  2.731  Rel. Train L2 Loss :  0.005628766965948873  Rel. Test L2 Loss :  0.006910384446382522  Test L2 Loss :  0.012668099701404572  inv_L_scale:  [1.0, 1.0]
Epoch :  461  Time:  2.73  Rel. Train L2 Loss :  0.0056289478412104976  Rel. Test L2 Loss :  0.0069360131584107875  Test L2 Loss :  0.012714163698256016  inv_L_scale:  [1.0, 1.0]
Epoch :  462  Time:  2.731  Rel. Train L2 Loss :  0.005612912060072025  Rel. Test L2 Loss :  0.00693472433835268  Test L2 Loss :  0.012709045112133025  inv_L_scale:  [1.0, 1.0]
Epoch :  463  Time:  2.731  Rel. Train L2 Loss :  0.005609264976034561  Rel. Test L2 Loss :  0.00692508589476347  Test L2 Loss :  0.012687141038477422  inv_L_scale:  [1.0, 1.0]
Epoch :  464  Time:  2.731  Rel. Train L2 Loss :  0.005602574518157376  Rel. Test L2 Loss :  0.006921696420758963  Test L2 Loss :  0.01268974781036377  inv_L_scale:  [1.0, 1.0]
Epoch :  465  Time:  2.731  Rel. Train L2 Loss :  0.005600418212513129  Rel. Test L2 Loss :  0.0069032242149114605  Test L2 Loss :  0.012653347849845887  inv_L_scale:  [1.0, 1.0]
Epoch :  466  Time:  2.73  Rel. Train L2 Loss :  0.005607055705040693  Rel. Test L2 Loss :  0.0069055985286831855  Test L2 Loss :  0.012654117085039615  inv_L_scale:  [1.0, 1.0]
Epoch :  467  Time:  2.73  Rel. Train L2 Loss :  0.00559733138523168  Rel. Test L2 Loss :  0.006906908005475998  Test L2 Loss :  0.012661043480038643  inv_L_scale:  [1.0, 1.0]
Epoch :  468  Time:  2.731  Rel. Train L2 Loss :  0.005595862047953738  Rel. Test L2 Loss :  0.006887913383543491  Test L2 Loss :  0.01262395665049553  inv_L_scale:  [1.0, 1.0]
Epoch :  469  Time:  2.73  Rel. Train L2 Loss :  0.005580341898732715  Rel. Test L2 Loss :  0.00689394686371088  Test L2 Loss :  0.012629299014806748  inv_L_scale:  [1.0, 1.0]
Epoch :  470  Time:  2.731  Rel. Train L2 Loss :  0.0055735388894875846  Rel. Test L2 Loss :  0.006893513426184654  Test L2 Loss :  0.01264461562037468  inv_L_scale:  [1.0, 1.0]
Epoch :  471  Time:  3.911  Rel. Train L2 Loss :  0.005564229885737101  Rel. Test L2 Loss :  0.006889827102422714  Test L2 Loss :  0.01262127310037613  inv_L_scale:  [1.0, 1.0]
Epoch :  472  Time:  6.228  Rel. Train L2 Loss :  0.005564781686084138  Rel. Test L2 Loss :  0.006877527348697185  Test L2 Loss :  0.012600926980376244  inv_L_scale:  [1.0, 1.0]
Epoch :  473  Time:  5.379  Rel. Train L2 Loss :  0.005558979821701845  Rel. Test L2 Loss :  0.006890104003250599  Test L2 Loss :  0.012652360685169697  inv_L_scale:  [1.0, 1.0]
Epoch :  474  Time:  7.551  Rel. Train L2 Loss :  0.005561083793226215  Rel. Test L2 Loss :  0.006855324115604162  Test L2 Loss :  0.012567171715199948  inv_L_scale:  [1.0, 1.0]
Epoch :  475  Time:  2.744  Rel. Train L2 Loss :  0.00556397202424705  Rel. Test L2 Loss :  0.006882620081305504  Test L2 Loss :  0.012616042122244835  inv_L_scale:  [1.0, 1.0]
Epoch :  476  Time:  2.742  Rel. Train L2 Loss :  0.005552409154673418  Rel. Test L2 Loss :  0.006870929934084415  Test L2 Loss :  0.012592291347682477  inv_L_scale:  [1.0, 1.0]
Epoch :  477  Time:  2.742  Rel. Train L2 Loss :  0.005543818732516633  Rel. Test L2 Loss :  0.006863957978785038  Test L2 Loss :  0.012584330327808858  inv_L_scale:  [1.0, 1.0]
Epoch :  478  Time:  2.74  Rel. Train L2 Loss :  0.005541145039929284  Rel. Test L2 Loss :  0.006858168542385102  Test L2 Loss :  0.012573621198534966  inv_L_scale:  [1.0, 1.0]
Epoch :  479  Time:  2.741  Rel. Train L2 Loss :  0.0055403969250619415  Rel. Test L2 Loss :  0.00684704827144742  Test L2 Loss :  0.01255303155630827  inv_L_scale:  [1.0, 1.0]
Epoch :  480  Time:  2.739  Rel. Train L2 Loss :  0.005533016696572304  Rel. Test L2 Loss :  0.00684532118961215  Test L2 Loss :  0.012552858665585517  inv_L_scale:  [1.0, 1.0]
Epoch :  481  Time:  2.739  Rel. Train L2 Loss :  0.005528904712862439  Rel. Test L2 Loss :  0.006849549505859614  Test L2 Loss :  0.012557443752884865  inv_L_scale:  [1.0, 1.0]
Epoch :  482  Time:  2.74  Rel. Train L2 Loss :  0.00552406825332178  Rel. Test L2 Loss :  0.0068540115654468535  Test L2 Loss :  0.012563910409808159  inv_L_scale:  [1.0, 1.0]
Epoch :  483  Time:  2.74  Rel. Train L2 Loss :  0.005520663898852136  Rel. Test L2 Loss :  0.0068455936573445795  Test L2 Loss :  0.012554937563836575  inv_L_scale:  [1.0, 1.0]
Epoch :  484  Time:  2.74  Rel. Train L2 Loss :  0.005519546684291628  Rel. Test L2 Loss :  0.006854667998850345  Test L2 Loss :  0.012564293928444386  inv_L_scale:  [1.0, 1.0]
Epoch :  485  Time:  2.74  Rel. Train L2 Loss :  0.00551662887343102  Rel. Test L2 Loss :  0.006847805380821228  Test L2 Loss :  0.01255783013999462  inv_L_scale:  [1.0, 1.0]
Epoch :  486  Time:  2.74  Rel. Train L2 Loss :  0.005516465653975805  Rel. Test L2 Loss :  0.006848644651472569  Test L2 Loss :  0.012553948238492011  inv_L_scale:  [1.0, 1.0]
Epoch :  487  Time:  12.731  Rel. Train L2 Loss :  0.005511212680074904  Rel. Test L2 Loss :  0.006842370256781578  Test L2 Loss :  0.01254197008907795  inv_L_scale:  [1.0, 1.0]
Epoch :  488  Time:  4.029  Rel. Train L2 Loss :  0.005508445470283429  Rel. Test L2 Loss :  0.0068612323328852655  Test L2 Loss :  0.012577692233026027  inv_L_scale:  [1.0, 1.0]
Epoch :  489  Time:  2.736  Rel. Train L2 Loss :  0.00550759586195151  Rel. Test L2 Loss :  0.006849486157298088  Test L2 Loss :  0.012559090666472912  inv_L_scale:  [1.0, 1.0]
Epoch :  490  Time:  2.737  Rel. Train L2 Loss :  0.005507743234435717  Rel. Test L2 Loss :  0.0068471522629261015  Test L2 Loss :  0.012554093711078167  inv_L_scale:  [1.0, 1.0]
Epoch :  491  Time:  2.737  Rel. Train L2 Loss :  0.0055054819956421855  Rel. Test L2 Loss :  0.006849084235727787  Test L2 Loss :  0.012553271353244782  inv_L_scale:  [1.0, 1.0]
Epoch :  492  Time:  2.887  Rel. Train L2 Loss :  0.005502879257417387  Rel. Test L2 Loss :  0.00684162974357605  Test L2 Loss :  0.012539771273732186  inv_L_scale:  [1.0, 1.0]
Epoch :  493  Time:  2.737  Rel. Train L2 Loss :  0.005502909782032172  Rel. Test L2 Loss :  0.00684048755094409  Test L2 Loss :  0.012546310350298882  inv_L_scale:  [1.0, 1.0]
Epoch :  494  Time:  2.737  Rel. Train L2 Loss :  0.005500124555288089  Rel. Test L2 Loss :  0.006840255055576563  Test L2 Loss :  0.01254329390823841  inv_L_scale:  [1.0, 1.0]
Epoch :  495  Time:  2.845  Rel. Train L2 Loss :  0.005498520135879517  Rel. Test L2 Loss :  0.006843017563223839  Test L2 Loss :  0.012543859891593456  inv_L_scale:  [1.0, 1.0]
Epoch :  496  Time:  2.737  Rel. Train L2 Loss :  0.005497299014694161  Rel. Test L2 Loss :  0.00685482319444418  Test L2 Loss :  0.012558571919798851  inv_L_scale:  [1.0, 1.0]
Epoch :  497  Time:  2.736  Rel. Train L2 Loss :  0.00549898308598333  Rel. Test L2 Loss :  0.006842864900827408  Test L2 Loss :  0.012545726746320724  inv_L_scale:  [1.0, 1.0]
Epoch :  498  Time:  2.737  Rel. Train L2 Loss :  0.005496323801991013  Rel. Test L2 Loss :  0.006843612492084503  Test L2 Loss :  0.012543427646160126  inv_L_scale:  [1.0, 1.0]
Epoch :  499  Time:  2.736  Rel. Train L2 Loss :  0.005499136859758033  Rel. Test L2 Loss :  0.00684555884450674  Test L2 Loss :  0.012547132894396781  inv_L_scale:  [1.0, 1.0]
