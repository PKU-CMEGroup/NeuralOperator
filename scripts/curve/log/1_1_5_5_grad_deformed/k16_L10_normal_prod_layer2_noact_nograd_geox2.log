(1000,) (1000, 1000, 1) (1000, 1000, 2)
use normalized raw measures
Casting to tensor
x_train shape torch.Size([900, 1000, 8]), y_train shape torch.Size([900, 1000, 1])
length of each dim:  tensor([6.5573987960815430, 6.1420288085937500])
kmax = 16
L = 10
geo_dims = [1, 2, 5, 6]
In PCNO_train, ndims =  2
Epoch :  0  Time:  7.786  Rel. Train L2 Loss :  0.5852534753746457  Rel. Test L2 Loss :  0.4843638515472412  Test L2 Loss :  0.7005675268173218  inv_L_scale:  [1.0, 1.0]
Epoch :  1  Time:  0.867  Rel. Train L2 Loss :  0.40210027111901175  Rel. Test L2 Loss :  0.33444216966629026  Test L2 Loss :  0.48139029622077945  inv_L_scale:  [1.0, 1.0]
Epoch :  2  Time:  0.868  Rel. Train L2 Loss :  0.2834829734431373  Rel. Test L2 Loss :  0.24707542419433592  Test L2 Loss :  0.3491536772251129  inv_L_scale:  [1.0, 1.0]
Epoch :  3  Time:  0.864  Rel. Train L2 Loss :  0.21321703023380703  Rel. Test L2 Loss :  0.18996035814285278  Test L2 Loss :  0.27091411232948304  inv_L_scale:  [1.0, 1.0]
Epoch :  4  Time:  0.867  Rel. Train L2 Loss :  0.17042686820030212  Rel. Test L2 Loss :  0.16336074352264404  Test L2 Loss :  0.23158539414405824  inv_L_scale:  [1.0, 1.0]
Epoch :  5  Time:  0.865  Rel. Train L2 Loss :  0.1542323115799162  Rel. Test L2 Loss :  0.1512182193994522  Test L2 Loss :  0.21515329480171203  inv_L_scale:  [1.0, 1.0]
Epoch :  6  Time:  0.865  Rel. Train L2 Loss :  0.1368431227074729  Rel. Test L2 Loss :  0.13034480929374695  Test L2 Loss :  0.185801962018013  inv_L_scale:  [1.0, 1.0]
Epoch :  7  Time:  0.866  Rel. Train L2 Loss :  0.12646123124493494  Rel. Test L2 Loss :  0.12334430932998658  Test L2 Loss :  0.1750005567073822  inv_L_scale:  [1.0, 1.0]
Epoch :  8  Time:  0.865  Rel. Train L2 Loss :  0.11929038186868032  Rel. Test L2 Loss :  0.11678857684135437  Test L2 Loss :  0.1670166665315628  inv_L_scale:  [1.0, 1.0]
Epoch :  9  Time:  0.865  Rel. Train L2 Loss :  0.11296855466233359  Rel. Test L2 Loss :  0.11320383667945862  Test L2 Loss :  0.16100505590438843  inv_L_scale:  [1.0, 1.0]
Epoch :  10  Time:  0.865  Rel. Train L2 Loss :  0.10771856569581562  Rel. Test L2 Loss :  0.10845401048660279  Test L2 Loss :  0.1544259476661682  inv_L_scale:  [1.0, 1.0]
Epoch :  11  Time:  0.865  Rel. Train L2 Loss :  0.1041779336002138  Rel. Test L2 Loss :  0.10769079387187958  Test L2 Loss :  0.15329185605049134  inv_L_scale:  [1.0, 1.0]
Epoch :  12  Time:  0.865  Rel. Train L2 Loss :  0.10218715714083777  Rel. Test L2 Loss :  0.10497649192810059  Test L2 Loss :  0.1498964709043503  inv_L_scale:  [1.0, 1.0]
Epoch :  13  Time:  0.868  Rel. Train L2 Loss :  0.09978383537795808  Rel. Test L2 Loss :  0.10317155659198761  Test L2 Loss :  0.14671135902404786  inv_L_scale:  [1.0, 1.0]
Epoch :  14  Time:  0.866  Rel. Train L2 Loss :  0.09670816673172845  Rel. Test L2 Loss :  0.09835922598838806  Test L2 Loss :  0.1404959273338318  inv_L_scale:  [1.0, 1.0]
Epoch :  15  Time:  0.865  Rel. Train L2 Loss :  0.09391411383946736  Rel. Test L2 Loss :  0.09450621932744979  Test L2 Loss :  0.13516674935817719  inv_L_scale:  [1.0, 1.0]
Epoch :  16  Time:  0.866  Rel. Train L2 Loss :  0.09117540107833015  Rel. Test L2 Loss :  0.09207277238368988  Test L2 Loss :  0.13160787284374237  inv_L_scale:  [1.0, 1.0]
Epoch :  17  Time:  0.865  Rel. Train L2 Loss :  0.09058050956990983  Rel. Test L2 Loss :  0.09217886865139008  Test L2 Loss :  0.13171325445175172  inv_L_scale:  [1.0, 1.0]
Epoch :  18  Time:  0.865  Rel. Train L2 Loss :  0.08809959517584906  Rel. Test L2 Loss :  0.08462568461894988  Test L2 Loss :  0.12092039167881012  inv_L_scale:  [1.0, 1.0]
Epoch :  19  Time:  0.865  Rel. Train L2 Loss :  0.08589176797204548  Rel. Test L2 Loss :  0.0921216744184494  Test L2 Loss :  0.13139970242977142  inv_L_scale:  [1.0, 1.0]
Epoch :  20  Time:  0.866  Rel. Train L2 Loss :  0.08707034276591406  Rel. Test L2 Loss :  0.08652789175510406  Test L2 Loss :  0.12369691759347916  inv_L_scale:  [1.0, 1.0]
Epoch :  21  Time:  0.865  Rel. Train L2 Loss :  0.08511246456040276  Rel. Test L2 Loss :  0.08671660512685776  Test L2 Loss :  0.12481306821107864  inv_L_scale:  [1.0, 1.0]
Epoch :  22  Time:  0.864  Rel. Train L2 Loss :  0.0851712429523468  Rel. Test L2 Loss :  0.08703639209270478  Test L2 Loss :  0.12460665345191956  inv_L_scale:  [1.0, 1.0]
Epoch :  23  Time:  0.866  Rel. Train L2 Loss :  0.08513455036613676  Rel. Test L2 Loss :  0.08495222747325898  Test L2 Loss :  0.12164000064134597  inv_L_scale:  [1.0, 1.0]
Epoch :  24  Time:  0.865  Rel. Train L2 Loss :  0.0815938659509023  Rel. Test L2 Loss :  0.08236616879701614  Test L2 Loss :  0.11796002060174943  inv_L_scale:  [1.0, 1.0]
Epoch :  25  Time:  0.865  Rel. Train L2 Loss :  0.08217954251501296  Rel. Test L2 Loss :  0.08198667258024216  Test L2 Loss :  0.11754859745502472  inv_L_scale:  [1.0, 1.0]
Epoch :  26  Time:  0.865  Rel. Train L2 Loss :  0.08131546699338489  Rel. Test L2 Loss :  0.08262206882238388  Test L2 Loss :  0.11848535478115081  inv_L_scale:  [1.0, 1.0]
Epoch :  27  Time:  0.869  Rel. Train L2 Loss :  0.08059727532996072  Rel. Test L2 Loss :  0.08156021595001221  Test L2 Loss :  0.11733119755983352  inv_L_scale:  [1.0, 1.0]
Epoch :  28  Time:  0.865  Rel. Train L2 Loss :  0.08023280309306251  Rel. Test L2 Loss :  0.0822199273109436  Test L2 Loss :  0.11784634381532669  inv_L_scale:  [1.0, 1.0]
Epoch :  29  Time:  0.865  Rel. Train L2 Loss :  0.07858382708496518  Rel. Test L2 Loss :  0.08109278410673142  Test L2 Loss :  0.11657442957162857  inv_L_scale:  [1.0, 1.0]
Epoch :  30  Time:  0.865  Rel. Train L2 Loss :  0.07869843261109458  Rel. Test L2 Loss :  0.08169089496135712  Test L2 Loss :  0.11747439205646515  inv_L_scale:  [1.0, 1.0]
Epoch :  31  Time:  0.866  Rel. Train L2 Loss :  0.07714130186372332  Rel. Test L2 Loss :  0.07926137119531632  Test L2 Loss :  0.1140533059835434  inv_L_scale:  [1.0, 1.0]
Epoch :  32  Time:  0.865  Rel. Train L2 Loss :  0.0777870621614986  Rel. Test L2 Loss :  0.08876931577920914  Test L2 Loss :  0.12690443336963653  inv_L_scale:  [1.0, 1.0]
Epoch :  33  Time:  0.865  Rel. Train L2 Loss :  0.07791001677513122  Rel. Test L2 Loss :  0.07706702828407287  Test L2 Loss :  0.11040868192911148  inv_L_scale:  [1.0, 1.0]
Epoch :  34  Time:  0.866  Rel. Train L2 Loss :  0.07773581918742922  Rel. Test L2 Loss :  0.07784801959991455  Test L2 Loss :  0.11147517323493958  inv_L_scale:  [1.0, 1.0]
Epoch :  35  Time:  0.865  Rel. Train L2 Loss :  0.07592180536852942  Rel. Test L2 Loss :  0.07846474409103393  Test L2 Loss :  0.11289434731006623  inv_L_scale:  [1.0, 1.0]
Epoch :  36  Time:  0.865  Rel. Train L2 Loss :  0.0789619787534078  Rel. Test L2 Loss :  0.07762205600738525  Test L2 Loss :  0.11129840552806854  inv_L_scale:  [1.0, 1.0]
Epoch :  37  Time:  0.865  Rel. Train L2 Loss :  0.07536376764376958  Rel. Test L2 Loss :  0.0768791401386261  Test L2 Loss :  0.11032595723867417  inv_L_scale:  [1.0, 1.0]
Epoch :  38  Time:  0.866  Rel. Train L2 Loss :  0.07561787562237846  Rel. Test L2 Loss :  0.07617859184741974  Test L2 Loss :  0.10907225012779236  inv_L_scale:  [1.0, 1.0]
Epoch :  39  Time:  0.865  Rel. Train L2 Loss :  0.07521694506208101  Rel. Test L2 Loss :  0.07654873669147491  Test L2 Loss :  0.11029746115207673  inv_L_scale:  [1.0, 1.0]
Epoch :  40  Time:  0.865  Rel. Train L2 Loss :  0.07379992226759592  Rel. Test L2 Loss :  0.07701212882995606  Test L2 Loss :  0.11093445032835007  inv_L_scale:  [1.0, 1.0]
Epoch :  41  Time:  0.865  Rel. Train L2 Loss :  0.0754032653901312  Rel. Test L2 Loss :  0.07367548525333405  Test L2 Loss :  0.10595659226179123  inv_L_scale:  [1.0, 1.0]
Epoch :  42  Time:  0.865  Rel. Train L2 Loss :  0.0737676269809405  Rel. Test L2 Loss :  0.07267453372478486  Test L2 Loss :  0.10464022397994995  inv_L_scale:  [1.0, 1.0]
Epoch :  43  Time:  0.868  Rel. Train L2 Loss :  0.07211782313055462  Rel. Test L2 Loss :  0.07826092153787613  Test L2 Loss :  0.11238979995250702  inv_L_scale:  [1.0, 1.0]
Epoch :  44  Time:  0.866  Rel. Train L2 Loss :  0.0740935699807273  Rel. Test L2 Loss :  0.07471507787704468  Test L2 Loss :  0.10742749869823456  inv_L_scale:  [1.0, 1.0]
Epoch :  45  Time:  0.865  Rel. Train L2 Loss :  0.07322581907113393  Rel. Test L2 Loss :  0.07530569195747376  Test L2 Loss :  0.10847197592258453  inv_L_scale:  [1.0, 1.0]
Epoch :  46  Time:  0.865  Rel. Train L2 Loss :  0.07354504615068436  Rel. Test L2 Loss :  0.07474980980157853  Test L2 Loss :  0.10772190421819687  inv_L_scale:  [1.0, 1.0]
Epoch :  47  Time:  0.865  Rel. Train L2 Loss :  0.07298558046420416  Rel. Test L2 Loss :  0.07356118202209473  Test L2 Loss :  0.10682541847229005  inv_L_scale:  [1.0, 1.0]
Epoch :  48  Time:  0.864  Rel. Train L2 Loss :  0.07377971722020044  Rel. Test L2 Loss :  0.07430574685335159  Test L2 Loss :  0.10628236979246139  inv_L_scale:  [1.0, 1.0]
Epoch :  49  Time:  0.865  Rel. Train L2 Loss :  0.07247370517916149  Rel. Test L2 Loss :  0.07105062574148178  Test L2 Loss :  0.1020111671090126  inv_L_scale:  [1.0, 1.0]
Epoch :  50  Time:  0.864  Rel. Train L2 Loss :  0.0730523822704951  Rel. Test L2 Loss :  0.07199959188699723  Test L2 Loss :  0.10397657305002213  inv_L_scale:  [1.0, 1.0]
Epoch :  51  Time:  0.865  Rel. Train L2 Loss :  0.07120726022455427  Rel. Test L2 Loss :  0.07486793279647827  Test L2 Loss :  0.10742524862289429  inv_L_scale:  [1.0, 1.0]
Epoch :  52  Time:  0.866  Rel. Train L2 Loss :  0.0742945114771525  Rel. Test L2 Loss :  0.0736717376112938  Test L2 Loss :  0.10599784791469574  inv_L_scale:  [1.0, 1.0]
Epoch :  53  Time:  0.865  Rel. Train L2 Loss :  0.07178953438997268  Rel. Test L2 Loss :  0.07543212205171584  Test L2 Loss :  0.10839164853096009  inv_L_scale:  [1.0, 1.0]
Epoch :  54  Time:  0.865  Rel. Train L2 Loss :  0.07161783340904448  Rel. Test L2 Loss :  0.07419077515602111  Test L2 Loss :  0.10718904435634613  inv_L_scale:  [1.0, 1.0]
Epoch :  55  Time:  0.865  Rel. Train L2 Loss :  0.07094752997159957  Rel. Test L2 Loss :  0.07917755424976348  Test L2 Loss :  0.11307730942964554  inv_L_scale:  [1.0, 1.0]
Epoch :  56  Time:  0.865  Rel. Train L2 Loss :  0.07206654081741969  Rel. Test L2 Loss :  0.07415136754512787  Test L2 Loss :  0.10626650899648667  inv_L_scale:  [1.0, 1.0]
Epoch :  57  Time:  0.866  Rel. Train L2 Loss :  0.07061017218563292  Rel. Test L2 Loss :  0.07087206542491913  Test L2 Loss :  0.10183614790439606  inv_L_scale:  [1.0, 1.0]
Epoch :  58  Time:  0.865  Rel. Train L2 Loss :  0.07019057091739443  Rel. Test L2 Loss :  0.07174490690231324  Test L2 Loss :  0.10274366378784179  inv_L_scale:  [1.0, 1.0]
Epoch :  59  Time:  0.865  Rel. Train L2 Loss :  0.07011732270320256  Rel. Test L2 Loss :  0.07112686663866043  Test L2 Loss :  0.10239786356687545  inv_L_scale:  [1.0, 1.0]
Epoch :  60  Time:  0.865  Rel. Train L2 Loss :  0.06987377358807458  Rel. Test L2 Loss :  0.07125616550445557  Test L2 Loss :  0.10255394041538239  inv_L_scale:  [1.0, 1.0]
Epoch :  61  Time:  0.865  Rel. Train L2 Loss :  0.06961093988683488  Rel. Test L2 Loss :  0.07044932246208191  Test L2 Loss :  0.10111221164464951  inv_L_scale:  [1.0, 1.0]
Epoch :  62  Time:  0.865  Rel. Train L2 Loss :  0.07337687628136741  Rel. Test L2 Loss :  0.0725780576467514  Test L2 Loss :  0.10433110117912292  inv_L_scale:  [1.0, 1.0]
Epoch :  63  Time:  0.869  Rel. Train L2 Loss :  0.06988472233215968  Rel. Test L2 Loss :  0.07108170419931412  Test L2 Loss :  0.10248832821846009  inv_L_scale:  [1.0, 1.0]
Epoch :  64  Time:  0.865  Rel. Train L2 Loss :  0.07063284400436613  Rel. Test L2 Loss :  0.07122419446706772  Test L2 Loss :  0.10235671281814575  inv_L_scale:  [1.0, 1.0]
Epoch :  65  Time:  0.865  Rel. Train L2 Loss :  0.06944655292563968  Rel. Test L2 Loss :  0.07197074741125106  Test L2 Loss :  0.10337994933128357  inv_L_scale:  [1.0, 1.0]
Epoch :  66  Time:  0.865  Rel. Train L2 Loss :  0.07101022428936428  Rel. Test L2 Loss :  0.07487010926008225  Test L2 Loss :  0.10757854044437408  inv_L_scale:  [1.0, 1.0]
Epoch :  67  Time:  0.865  Rel. Train L2 Loss :  0.07089123315281338  Rel. Test L2 Loss :  0.07354300528764725  Test L2 Loss :  0.1058553260564804  inv_L_scale:  [1.0, 1.0]
Epoch :  68  Time:  0.865  Rel. Train L2 Loss :  0.07032644579807917  Rel. Test L2 Loss :  0.07033082485198974  Test L2 Loss :  0.101127170920372  inv_L_scale:  [1.0, 1.0]
Epoch :  69  Time:  0.865  Rel. Train L2 Loss :  0.06914983279175228  Rel. Test L2 Loss :  0.07187966108322144  Test L2 Loss :  0.10350180208683014  inv_L_scale:  [1.0, 1.0]
Epoch :  70  Time:  0.865  Rel. Train L2 Loss :  0.06931171443727281  Rel. Test L2 Loss :  0.07538343638181687  Test L2 Loss :  0.1083194637298584  inv_L_scale:  [1.0, 1.0]
Epoch :  71  Time:  0.865  Rel. Train L2 Loss :  0.06985403137074576  Rel. Test L2 Loss :  0.07090523809194565  Test L2 Loss :  0.10234642446041108  inv_L_scale:  [1.0, 1.0]
Epoch :  72  Time:  0.865  Rel. Train L2 Loss :  0.06817587761415375  Rel. Test L2 Loss :  0.06715703010559082  Test L2 Loss :  0.09688656538724899  inv_L_scale:  [1.0, 1.0]
Epoch :  73  Time:  0.865  Rel. Train L2 Loss :  0.06808362305164337  Rel. Test L2 Loss :  0.0745860955119133  Test L2 Loss :  0.10680235058069229  inv_L_scale:  [1.0, 1.0]
Epoch :  74  Time:  0.866  Rel. Train L2 Loss :  0.06768484456671608  Rel. Test L2 Loss :  0.06930957734584808  Test L2 Loss :  0.09978898704051971  inv_L_scale:  [1.0, 1.0]
Epoch :  75  Time:  0.865  Rel. Train L2 Loss :  0.06805317064126333  Rel. Test L2 Loss :  0.06848876357078552  Test L2 Loss :  0.0984935474395752  inv_L_scale:  [1.0, 1.0]
Epoch :  76  Time:  0.865  Rel. Train L2 Loss :  0.0685981994536188  Rel. Test L2 Loss :  0.07158545374870301  Test L2 Loss :  0.1034408724308014  inv_L_scale:  [1.0, 1.0]
Epoch :  77  Time:  0.865  Rel. Train L2 Loss :  0.0693373222483529  Rel. Test L2 Loss :  0.0672623324394226  Test L2 Loss :  0.09700955867767334  inv_L_scale:  [1.0, 1.0]
Epoch :  78  Time:  0.865  Rel. Train L2 Loss :  0.0680830493900511  Rel. Test L2 Loss :  0.06827644914388657  Test L2 Loss :  0.09870703756809235  inv_L_scale:  [1.0, 1.0]
Epoch :  79  Time:  0.866  Rel. Train L2 Loss :  0.06961338407463498  Rel. Test L2 Loss :  0.06917290329933166  Test L2 Loss :  0.09970879316329956  inv_L_scale:  [1.0, 1.0]
Epoch :  80  Time:  0.866  Rel. Train L2 Loss :  0.06724897623062134  Rel. Test L2 Loss :  0.0670495069026947  Test L2 Loss :  0.09646062910556794  inv_L_scale:  [1.0, 1.0]
Epoch :  81  Time:  0.865  Rel. Train L2 Loss :  0.06677040189504624  Rel. Test L2 Loss :  0.06861070543527603  Test L2 Loss :  0.09864797323942184  inv_L_scale:  [1.0, 1.0]
Epoch :  82  Time:  0.865  Rel. Train L2 Loss :  0.06755102008581161  Rel. Test L2 Loss :  0.07059386938810348  Test L2 Loss :  0.10127846270799637  inv_L_scale:  [1.0, 1.0]
Epoch :  83  Time:  0.865  Rel. Train L2 Loss :  0.06868845721085866  Rel. Test L2 Loss :  0.06909080237150192  Test L2 Loss :  0.09993603229522705  inv_L_scale:  [1.0, 1.0]
Epoch :  84  Time:  0.865  Rel. Train L2 Loss :  0.06818328420321147  Rel. Test L2 Loss :  0.07180865168571472  Test L2 Loss :  0.10325427770614624  inv_L_scale:  [1.0, 1.0]
Epoch :  85  Time:  0.867  Rel. Train L2 Loss :  0.06842916710509195  Rel. Test L2 Loss :  0.06946893364191055  Test L2 Loss :  0.09996626406908035  inv_L_scale:  [1.0, 1.0]
Epoch :  86  Time:  0.866  Rel. Train L2 Loss :  0.06647176974349552  Rel. Test L2 Loss :  0.06880537658929825  Test L2 Loss :  0.09937680125236512  inv_L_scale:  [1.0, 1.0]
Epoch :  87  Time:  0.865  Rel. Train L2 Loss :  0.0667770023809539  Rel. Test L2 Loss :  0.06859728276729583  Test L2 Loss :  0.09898001730442046  inv_L_scale:  [1.0, 1.0]
Epoch :  88  Time:  0.865  Rel. Train L2 Loss :  0.06707437068223954  Rel. Test L2 Loss :  0.06700428962707519  Test L2 Loss :  0.09644028663635254  inv_L_scale:  [1.0, 1.0]
Epoch :  89  Time:  0.865  Rel. Train L2 Loss :  0.06612110108137131  Rel. Test L2 Loss :  0.06847080022096634  Test L2 Loss :  0.0987934747338295  inv_L_scale:  [1.0, 1.0]
Epoch :  90  Time:  0.865  Rel. Train L2 Loss :  0.06694589780436622  Rel. Test L2 Loss :  0.0690881222486496  Test L2 Loss :  0.10026081800460815  inv_L_scale:  [1.0, 1.0]
Epoch :  91  Time:  0.865  Rel. Train L2 Loss :  0.06718248456716537  Rel. Test L2 Loss :  0.06777774214744568  Test L2 Loss :  0.09807415068149566  inv_L_scale:  [1.0, 1.0]
Epoch :  92  Time:  0.865  Rel. Train L2 Loss :  0.06616046643919415  Rel. Test L2 Loss :  0.06644627958536148  Test L2 Loss :  0.09559966742992401  inv_L_scale:  [1.0, 1.0]
Epoch :  93  Time:  0.865  Rel. Train L2 Loss :  0.06627398285600875  Rel. Test L2 Loss :  0.06828932464122772  Test L2 Loss :  0.09856208771467209  inv_L_scale:  [1.0, 1.0]
Epoch :  94  Time:  0.864  Rel. Train L2 Loss :  0.0661397773689694  Rel. Test L2 Loss :  0.06576204925775528  Test L2 Loss :  0.09468723624944687  inv_L_scale:  [1.0, 1.0]
Epoch :  95  Time:  0.864  Rel. Train L2 Loss :  0.06638149988320138  Rel. Test L2 Loss :  0.06798255711793899  Test L2 Loss :  0.09813168376684189  inv_L_scale:  [1.0, 1.0]
Epoch :  96  Time:  0.863  Rel. Train L2 Loss :  0.06637026728855239  Rel. Test L2 Loss :  0.06671267211437225  Test L2 Loss :  0.09634701073169709  inv_L_scale:  [1.0, 1.0]
Epoch :  97  Time:  0.863  Rel. Train L2 Loss :  0.06587245911359788  Rel. Test L2 Loss :  0.06667390823364258  Test L2 Loss :  0.09632491111755372  inv_L_scale:  [1.0, 1.0]
Epoch :  98  Time:  0.863  Rel. Train L2 Loss :  0.06529812945259941  Rel. Test L2 Loss :  0.06697610825300217  Test L2 Loss :  0.09665445297956467  inv_L_scale:  [1.0, 1.0]
Epoch :  99  Time:  0.863  Rel. Train L2 Loss :  0.06619575225644642  Rel. Test L2 Loss :  0.06682949215173721  Test L2 Loss :  0.09706061333417892  inv_L_scale:  [1.0, 1.0]
Epoch :  100  Time:  0.865  Rel. Train L2 Loss :  0.06505491627587212  Rel. Test L2 Loss :  0.06605826914310456  Test L2 Loss :  0.09523712784051895  inv_L_scale:  [1.0, 1.0]
Epoch :  101  Time:  0.864  Rel. Train L2 Loss :  0.06480532189210256  Rel. Test L2 Loss :  0.06572536647319793  Test L2 Loss :  0.09464789688587188  inv_L_scale:  [1.0, 1.0]
Epoch :  102  Time:  0.864  Rel. Train L2 Loss :  0.06519676682021883  Rel. Test L2 Loss :  0.06774787813425064  Test L2 Loss :  0.09763922870159149  inv_L_scale:  [1.0, 1.0]
Epoch :  103  Time:  0.864  Rel. Train L2 Loss :  0.06523237645626068  Rel. Test L2 Loss :  0.06864645689725876  Test L2 Loss :  0.09920553356409073  inv_L_scale:  [1.0, 1.0]
Epoch :  104  Time:  0.864  Rel. Train L2 Loss :  0.0675490622387992  Rel. Test L2 Loss :  0.0671377894282341  Test L2 Loss :  0.09643114358186722  inv_L_scale:  [1.0, 1.0]
Epoch :  105  Time:  0.864  Rel. Train L2 Loss :  0.06472706955340174  Rel. Test L2 Loss :  0.06540419101715088  Test L2 Loss :  0.09455351710319519  inv_L_scale:  [1.0, 1.0]
Epoch :  106  Time:  0.865  Rel. Train L2 Loss :  0.06465431266360813  Rel. Test L2 Loss :  0.06745113909244538  Test L2 Loss :  0.09739062488079071  inv_L_scale:  [1.0, 1.0]
Epoch :  107  Time:  0.865  Rel. Train L2 Loss :  0.0647870538963212  Rel. Test L2 Loss :  0.06816361039876938  Test L2 Loss :  0.09798900216817856  inv_L_scale:  [1.0, 1.0]
Epoch :  108  Time:  0.864  Rel. Train L2 Loss :  0.06459082848495908  Rel. Test L2 Loss :  0.06469255566596985  Test L2 Loss :  0.0934489893913269  inv_L_scale:  [1.0, 1.0]
Epoch :  109  Time:  0.864  Rel. Train L2 Loss :  0.06362669779194725  Rel. Test L2 Loss :  0.06920083194971084  Test L2 Loss :  0.09922433674335479  inv_L_scale:  [1.0, 1.0]
Epoch :  110  Time:  0.865  Rel. Train L2 Loss :  0.06454766478803423  Rel. Test L2 Loss :  0.07036180287599564  Test L2 Loss :  0.10132905960083008  inv_L_scale:  [1.0, 1.0]
Epoch :  111  Time:  0.864  Rel. Train L2 Loss :  0.06425192245178753  Rel. Test L2 Loss :  0.0666139268875122  Test L2 Loss :  0.09609997928142548  inv_L_scale:  [1.0, 1.0]
Epoch :  112  Time:  0.864  Rel. Train L2 Loss :  0.06400419874323739  Rel. Test L2 Loss :  0.06530793964862823  Test L2 Loss :  0.09466449499130249  inv_L_scale:  [1.0, 1.0]
Epoch :  113  Time:  0.864  Rel. Train L2 Loss :  0.06413908892207676  Rel. Test L2 Loss :  0.06846094369888306  Test L2 Loss :  0.09842358767986298  inv_L_scale:  [1.0, 1.0]
Epoch :  114  Time:  0.867  Rel. Train L2 Loss :  0.06392649094263712  Rel. Test L2 Loss :  0.0705399689078331  Test L2 Loss :  0.1008153122663498  inv_L_scale:  [1.0, 1.0]
Epoch :  115  Time:  0.866  Rel. Train L2 Loss :  0.06466227988402048  Rel. Test L2 Loss :  0.06662300825119019  Test L2 Loss :  0.09603688418865204  inv_L_scale:  [1.0, 1.0]
Epoch :  116  Time:  0.865  Rel. Train L2 Loss :  0.06349111805359522  Rel. Test L2 Loss :  0.06666416555643082  Test L2 Loss :  0.09603329360485077  inv_L_scale:  [1.0, 1.0]
Epoch :  117  Time:  0.865  Rel. Train L2 Loss :  0.06457179062896305  Rel. Test L2 Loss :  0.06386546105146408  Test L2 Loss :  0.0922185206413269  inv_L_scale:  [1.0, 1.0]
Epoch :  118  Time:  0.864  Rel. Train L2 Loss :  0.06415967545575565  Rel. Test L2 Loss :  0.06413182824850082  Test L2 Loss :  0.09274485886096955  inv_L_scale:  [1.0, 1.0]
Epoch :  119  Time:  0.865  Rel. Train L2 Loss :  0.06427246471246084  Rel. Test L2 Loss :  0.06437270388007164  Test L2 Loss :  0.09287218630313873  inv_L_scale:  [1.0, 1.0]
Epoch :  120  Time:  0.865  Rel. Train L2 Loss :  0.0635952439904213  Rel. Test L2 Loss :  0.06514551848173142  Test L2 Loss :  0.09409261763095855  inv_L_scale:  [1.0, 1.0]
Epoch :  121  Time:  0.865  Rel. Train L2 Loss :  0.06625300801462597  Rel. Test L2 Loss :  0.06924170225858689  Test L2 Loss :  0.0999586671590805  inv_L_scale:  [1.0, 1.0]
Epoch :  122  Time:  0.865  Rel. Train L2 Loss :  0.06348041610585319  Rel. Test L2 Loss :  0.0652524209022522  Test L2 Loss :  0.09417212218046188  inv_L_scale:  [1.0, 1.0]
Epoch :  123  Time:  0.865  Rel. Train L2 Loss :  0.0626214063498709  Rel. Test L2 Loss :  0.06386589467525482  Test L2 Loss :  0.09230157077312469  inv_L_scale:  [1.0, 1.0]
Epoch :  124  Time:  0.864  Rel. Train L2 Loss :  0.06337119708458583  Rel. Test L2 Loss :  0.06681294739246368  Test L2 Loss :  0.09610513210296631  inv_L_scale:  [1.0, 1.0]
Epoch :  125  Time:  0.865  Rel. Train L2 Loss :  0.06347627176178826  Rel. Test L2 Loss :  0.06555930703878403  Test L2 Loss :  0.09483982652425765  inv_L_scale:  [1.0, 1.0]
Epoch :  126  Time:  0.865  Rel. Train L2 Loss :  0.06353123098611832  Rel. Test L2 Loss :  0.06363424360752105  Test L2 Loss :  0.09193197369575501  inv_L_scale:  [1.0, 1.0]
Epoch :  127  Time:  0.864  Rel. Train L2 Loss :  0.06357038716475169  Rel. Test L2 Loss :  0.06534428924322128  Test L2 Loss :  0.09427664816379547  inv_L_scale:  [1.0, 1.0]
Epoch :  128  Time:  0.865  Rel. Train L2 Loss :  0.06332005790538257  Rel. Test L2 Loss :  0.06396306484937668  Test L2 Loss :  0.09249376267194748  inv_L_scale:  [1.0, 1.0]
Epoch :  129  Time:  0.865  Rel. Train L2 Loss :  0.06235785196224848  Rel. Test L2 Loss :  0.06411230117082596  Test L2 Loss :  0.092596395611763  inv_L_scale:  [1.0, 1.0]
Epoch :  130  Time:  0.866  Rel. Train L2 Loss :  0.062902183731397  Rel. Test L2 Loss :  0.06593397110700608  Test L2 Loss :  0.09493668854236603  inv_L_scale:  [1.0, 1.0]
Epoch :  131  Time:  0.864  Rel. Train L2 Loss :  0.0629629734158516  Rel. Test L2 Loss :  0.06430000901222228  Test L2 Loss :  0.09267052948474884  inv_L_scale:  [1.0, 1.0]
Epoch :  132  Time:  0.865  Rel. Train L2 Loss :  0.06235596630308363  Rel. Test L2 Loss :  0.06507131189107895  Test L2 Loss :  0.09400479555130005  inv_L_scale:  [1.0, 1.0]
Epoch :  133  Time:  0.864  Rel. Train L2 Loss :  0.06275360461738375  Rel. Test L2 Loss :  0.06305071964859962  Test L2 Loss :  0.09088810592889786  inv_L_scale:  [1.0, 1.0]
Epoch :  134  Time:  0.865  Rel. Train L2 Loss :  0.06288105835517248  Rel. Test L2 Loss :  0.06391089737415313  Test L2 Loss :  0.09235776662826538  inv_L_scale:  [1.0, 1.0]
Epoch :  135  Time:  0.865  Rel. Train L2 Loss :  0.06264972395367092  Rel. Test L2 Loss :  0.06568275898694992  Test L2 Loss :  0.09430500388145446  inv_L_scale:  [1.0, 1.0]
Epoch :  136  Time:  0.864  Rel. Train L2 Loss :  0.06306958478358057  Rel. Test L2 Loss :  0.06435550302267075  Test L2 Loss :  0.09307347238063812  inv_L_scale:  [1.0, 1.0]
Epoch :  137  Time:  0.864  Rel. Train L2 Loss :  0.0624894372622172  Rel. Test L2 Loss :  0.06532717525959014  Test L2 Loss :  0.09458519071340561  inv_L_scale:  [1.0, 1.0]
Epoch :  138  Time:  0.865  Rel. Train L2 Loss :  0.062447542879316545  Rel. Test L2 Loss :  0.065581336915493  Test L2 Loss :  0.09449585735797882  inv_L_scale:  [1.0, 1.0]
Epoch :  139  Time:  0.865  Rel. Train L2 Loss :  0.06220910870366626  Rel. Test L2 Loss :  0.06372951805591583  Test L2 Loss :  0.09210747063159942  inv_L_scale:  [1.0, 1.0]
Epoch :  140  Time:  0.864  Rel. Train L2 Loss :  0.062038847472932604  Rel. Test L2 Loss :  0.06613150984048843  Test L2 Loss :  0.09534454733133316  inv_L_scale:  [1.0, 1.0]
Epoch :  141  Time:  0.865  Rel. Train L2 Loss :  0.06248708645502726  Rel. Test L2 Loss :  0.06396685391664506  Test L2 Loss :  0.09218854576349259  inv_L_scale:  [1.0, 1.0]
Epoch :  142  Time:  0.864  Rel. Train L2 Loss :  0.06199656443463431  Rel. Test L2 Loss :  0.06455176860094071  Test L2 Loss :  0.09276986956596374  inv_L_scale:  [1.0, 1.0]
Epoch :  143  Time:  0.864  Rel. Train L2 Loss :  0.06204940279324849  Rel. Test L2 Loss :  0.0631296506524086  Test L2 Loss :  0.0911888426542282  inv_L_scale:  [1.0, 1.0]
Epoch :  144  Time:  0.864  Rel. Train L2 Loss :  0.062305212053987716  Rel. Test L2 Loss :  0.06213954895734787  Test L2 Loss :  0.09004119634628296  inv_L_scale:  [1.0, 1.0]
Epoch :  145  Time:  0.864  Rel. Train L2 Loss :  0.062418137490749356  Rel. Test L2 Loss :  0.06236250311136246  Test L2 Loss :  0.08995614379644394  inv_L_scale:  [1.0, 1.0]
Epoch :  146  Time:  0.864  Rel. Train L2 Loss :  0.061629017459021676  Rel. Test L2 Loss :  0.06402785539627075  Test L2 Loss :  0.09270829677581788  inv_L_scale:  [1.0, 1.0]
Epoch :  147  Time:  0.867  Rel. Train L2 Loss :  0.06239485854903857  Rel. Test L2 Loss :  0.06406700849533081  Test L2 Loss :  0.0925111785531044  inv_L_scale:  [1.0, 1.0]
Epoch :  148  Time:  0.867  Rel. Train L2 Loss :  0.061557335009177525  Rel. Test L2 Loss :  0.06370158463716508  Test L2 Loss :  0.09220989197492599  inv_L_scale:  [1.0, 1.0]
Epoch :  149  Time:  0.865  Rel. Train L2 Loss :  0.061432271665996976  Rel. Test L2 Loss :  0.06290272146463394  Test L2 Loss :  0.09113652229309083  inv_L_scale:  [1.0, 1.0]
Epoch :  150  Time:  0.865  Rel. Train L2 Loss :  0.061202967216571175  Rel. Test L2 Loss :  0.06222311347723007  Test L2 Loss :  0.0901502764225006  inv_L_scale:  [1.0, 1.0]
Epoch :  151  Time:  0.871  Rel. Train L2 Loss :  0.061337588214211994  Rel. Test L2 Loss :  0.06409336730837822  Test L2 Loss :  0.09250783294439316  inv_L_scale:  [1.0, 1.0]
Epoch :  152  Time:  0.894  Rel. Train L2 Loss :  0.06247331400712331  Rel. Test L2 Loss :  0.06364865750074386  Test L2 Loss :  0.09194958627223969  inv_L_scale:  [1.0, 1.0]
Epoch :  153  Time:  0.904  Rel. Train L2 Loss :  0.06346122966872321  Rel. Test L2 Loss :  0.06594354331493378  Test L2 Loss :  0.09526002407073975  inv_L_scale:  [1.0, 1.0]
Epoch :  154  Time:  0.907  Rel. Train L2 Loss :  0.06100719614161385  Rel. Test L2 Loss :  0.06570956379175186  Test L2 Loss :  0.09464889734983445  inv_L_scale:  [1.0, 1.0]
Epoch :  155  Time:  0.907  Rel. Train L2 Loss :  0.061041357616583504  Rel. Test L2 Loss :  0.06311423808336258  Test L2 Loss :  0.09155983656644821  inv_L_scale:  [1.0, 1.0]
Epoch :  156  Time:  0.908  Rel. Train L2 Loss :  0.060674883127212524  Rel. Test L2 Loss :  0.0639674374461174  Test L2 Loss :  0.09241365730762481  inv_L_scale:  [1.0, 1.0]
Epoch :  157  Time:  0.906  Rel. Train L2 Loss :  0.06161842667394214  Rel. Test L2 Loss :  0.06306671440601348  Test L2 Loss :  0.09103378653526306  inv_L_scale:  [1.0, 1.0]
Epoch :  158  Time:  0.906  Rel. Train L2 Loss :  0.061014729522996476  Rel. Test L2 Loss :  0.06439101964235305  Test L2 Loss :  0.09312966138124466  inv_L_scale:  [1.0, 1.0]
Epoch :  159  Time:  0.902  Rel. Train L2 Loss :  0.061419493357340496  Rel. Test L2 Loss :  0.0642964619398117  Test L2 Loss :  0.09321613609790802  inv_L_scale:  [1.0, 1.0]
Epoch :  160  Time:  0.905  Rel. Train L2 Loss :  0.06141837060451508  Rel. Test L2 Loss :  0.06436894416809082  Test L2 Loss :  0.09312248766422272  inv_L_scale:  [1.0, 1.0]
Epoch :  161  Time:  0.905  Rel. Train L2 Loss :  0.06107698068022728  Rel. Test L2 Loss :  0.07467680215835572  Test L2 Loss :  0.10782041311264039  inv_L_scale:  [1.0, 1.0]
Epoch :  162  Time:  0.906  Rel. Train L2 Loss :  0.0625176704592175  Rel. Test L2 Loss :  0.06218259871006012  Test L2 Loss :  0.08974788844585418  inv_L_scale:  [1.0, 1.0]
Epoch :  163  Time:  0.905  Rel. Train L2 Loss :  0.060888555645942685  Rel. Test L2 Loss :  0.0625233605504036  Test L2 Loss :  0.09040667563676834  inv_L_scale:  [1.0, 1.0]
Epoch :  164  Time:  0.906  Rel. Train L2 Loss :  0.06085835682021247  Rel. Test L2 Loss :  0.06233986079692841  Test L2 Loss :  0.08988778293132782  inv_L_scale:  [1.0, 1.0]
Epoch :  165  Time:  0.907  Rel. Train L2 Loss :  0.06187724481026331  Rel. Test L2 Loss :  0.061909647285938264  Test L2 Loss :  0.08954203814268112  inv_L_scale:  [1.0, 1.0]
Epoch :  166  Time:  0.908  Rel. Train L2 Loss :  0.061148213843504585  Rel. Test L2 Loss :  0.06296960592269897  Test L2 Loss :  0.09104305982589722  inv_L_scale:  [1.0, 1.0]
Epoch :  167  Time:  0.907  Rel. Train L2 Loss :  0.06277370118432575  Rel. Test L2 Loss :  0.06278536826372147  Test L2 Loss :  0.09082118034362793  inv_L_scale:  [1.0, 1.0]
Epoch :  168  Time:  0.917  Rel. Train L2 Loss :  0.0609215997490618  Rel. Test L2 Loss :  0.06321308225393295  Test L2 Loss :  0.0913571572303772  inv_L_scale:  [1.0, 1.0]
Epoch :  169  Time:  0.918  Rel. Train L2 Loss :  0.06040718345178498  Rel. Test L2 Loss :  0.061984525322914125  Test L2 Loss :  0.0895280134677887  inv_L_scale:  [1.0, 1.0]
Epoch :  170  Time:  0.894  Rel. Train L2 Loss :  0.06050385309590234  Rel. Test L2 Loss :  0.06591973483562469  Test L2 Loss :  0.0955459114909172  inv_L_scale:  [1.0, 1.0]
Epoch :  171  Time:  0.895  Rel. Train L2 Loss :  0.060880125082201426  Rel. Test L2 Loss :  0.06214373141527176  Test L2 Loss :  0.08998596131801605  inv_L_scale:  [1.0, 1.0]
Epoch :  172  Time:  0.894  Rel. Train L2 Loss :  0.06019758587082227  Rel. Test L2 Loss :  0.06210177600383759  Test L2 Loss :  0.0898965784907341  inv_L_scale:  [1.0, 1.0]
Epoch :  173  Time:  0.895  Rel. Train L2 Loss :  0.06021485921409395  Rel. Test L2 Loss :  0.06392906755208969  Test L2 Loss :  0.09228553771972656  inv_L_scale:  [1.0, 1.0]
Epoch :  174  Time:  0.897  Rel. Train L2 Loss :  0.0602106699678633  Rel. Test L2 Loss :  0.06267467945814133  Test L2 Loss :  0.09050686359405517  inv_L_scale:  [1.0, 1.0]
Epoch :  175  Time:  0.894  Rel. Train L2 Loss :  0.06128174275159836  Rel. Test L2 Loss :  0.061824418008327484  Test L2 Loss :  0.08956504940986633  inv_L_scale:  [1.0, 1.0]
Epoch :  176  Time:  0.893  Rel. Train L2 Loss :  0.059642706678973305  Rel. Test L2 Loss :  0.062791987657547  Test L2 Loss :  0.09046180427074432  inv_L_scale:  [1.0, 1.0]
Epoch :  177  Time:  0.895  Rel. Train L2 Loss :  0.060111672282218934  Rel. Test L2 Loss :  0.06215400636196136  Test L2 Loss :  0.08979043751955032  inv_L_scale:  [1.0, 1.0]
Epoch :  178  Time:  0.895  Rel. Train L2 Loss :  0.06084282351864709  Rel. Test L2 Loss :  0.06213560402393341  Test L2 Loss :  0.08986784934997559  inv_L_scale:  [1.0, 1.0]
Epoch :  179  Time:  0.893  Rel. Train L2 Loss :  0.05979009969366921  Rel. Test L2 Loss :  0.06369913846254349  Test L2 Loss :  0.09244822144508362  inv_L_scale:  [1.0, 1.0]
Epoch :  180  Time:  0.898  Rel. Train L2 Loss :  0.06023471441533831  Rel. Test L2 Loss :  0.06214030861854553  Test L2 Loss :  0.08974563419818878  inv_L_scale:  [1.0, 1.0]
Epoch :  181  Time:  0.895  Rel. Train L2 Loss :  0.06004039835598734  Rel. Test L2 Loss :  0.0626621513068676  Test L2 Loss :  0.09061288625001908  inv_L_scale:  [1.0, 1.0]
Epoch :  182  Time:  0.895  Rel. Train L2 Loss :  0.0598649091190762  Rel. Test L2 Loss :  0.06191850081086159  Test L2 Loss :  0.08976503193378449  inv_L_scale:  [1.0, 1.0]
Epoch :  183  Time:  0.895  Rel. Train L2 Loss :  0.059738245043489666  Rel. Test L2 Loss :  0.06266376554965973  Test L2 Loss :  0.09074836790561676  inv_L_scale:  [1.0, 1.0]
Epoch :  184  Time:  0.894  Rel. Train L2 Loss :  0.06027826993001832  Rel. Test L2 Loss :  0.0617703178524971  Test L2 Loss :  0.08934754163026809  inv_L_scale:  [1.0, 1.0]
Epoch :  185  Time:  0.889  Rel. Train L2 Loss :  0.059571000635623934  Rel. Test L2 Loss :  0.06360670983791351  Test L2 Loss :  0.09169865190982819  inv_L_scale:  [1.0, 1.0]
Epoch :  186  Time:  0.891  Rel. Train L2 Loss :  0.059471030135949454  Rel. Test L2 Loss :  0.06252976655960082  Test L2 Loss :  0.09009368866682052  inv_L_scale:  [1.0, 1.0]
Epoch :  187  Time:  0.882  Rel. Train L2 Loss :  0.05997796144750383  Rel. Test L2 Loss :  0.06136115714907646  Test L2 Loss :  0.08879991114139557  inv_L_scale:  [1.0, 1.0]
Epoch :  188  Time:  0.882  Rel. Train L2 Loss :  0.06028050124645233  Rel. Test L2 Loss :  0.062154022753238676  Test L2 Loss :  0.08986489176750183  inv_L_scale:  [1.0, 1.0]
Epoch :  189  Time:  0.871  Rel. Train L2 Loss :  0.059565719498528374  Rel. Test L2 Loss :  0.06223334804177284  Test L2 Loss :  0.09033890068531036  inv_L_scale:  [1.0, 1.0]
Epoch :  190  Time:  0.87  Rel. Train L2 Loss :  0.05930266363753213  Rel. Test L2 Loss :  0.06368327111005784  Test L2 Loss :  0.09243037074804306  inv_L_scale:  [1.0, 1.0]
Epoch :  191  Time:  0.871  Rel. Train L2 Loss :  0.05971628967258665  Rel. Test L2 Loss :  0.06165909558534622  Test L2 Loss :  0.08941759765148163  inv_L_scale:  [1.0, 1.0]
Epoch :  192  Time:  0.871  Rel. Train L2 Loss :  0.05924261228905784  Rel. Test L2 Loss :  0.06154348075389862  Test L2 Loss :  0.08942528069019318  inv_L_scale:  [1.0, 1.0]
Epoch :  193  Time:  0.871  Rel. Train L2 Loss :  0.059502886897987786  Rel. Test L2 Loss :  0.06239997059106827  Test L2 Loss :  0.09046062648296356  inv_L_scale:  [1.0, 1.0]
Epoch :  194  Time:  0.871  Rel. Train L2 Loss :  0.059166149463918474  Rel. Test L2 Loss :  0.06205016821622848  Test L2 Loss :  0.08976764529943466  inv_L_scale:  [1.0, 1.0]
Epoch :  195  Time:  0.871  Rel. Train L2 Loss :  0.05961198588212331  Rel. Test L2 Loss :  0.06076234608888626  Test L2 Loss :  0.08792077422142029  inv_L_scale:  [1.0, 1.0]
Epoch :  196  Time:  0.87  Rel. Train L2 Loss :  0.05929895755317476  Rel. Test L2 Loss :  0.06098289459943771  Test L2 Loss :  0.08803148180246353  inv_L_scale:  [1.0, 1.0]
Epoch :  197  Time:  0.87  Rel. Train L2 Loss :  0.05957462728023529  Rel. Test L2 Loss :  0.06292430445551872  Test L2 Loss :  0.09127838790416717  inv_L_scale:  [1.0, 1.0]
Epoch :  198  Time:  0.87  Rel. Train L2 Loss :  0.059613788790173  Rel. Test L2 Loss :  0.06139768898487091  Test L2 Loss :  0.08915691882371903  inv_L_scale:  [1.0, 1.0]
Epoch :  199  Time:  0.87  Rel. Train L2 Loss :  0.059432124495506285  Rel. Test L2 Loss :  0.0637301880121231  Test L2 Loss :  0.09160780310630798  inv_L_scale:  [1.0, 1.0]
Epoch :  200  Time:  0.87  Rel. Train L2 Loss :  0.05869934476084179  Rel. Test L2 Loss :  0.0621917787194252  Test L2 Loss :  0.09006891638040543  inv_L_scale:  [1.0, 1.0]
Epoch :  201  Time:  0.87  Rel. Train L2 Loss :  0.05896860629320145  Rel. Test L2 Loss :  0.060065619200468066  Test L2 Loss :  0.0867444086074829  inv_L_scale:  [1.0, 1.0]
Epoch :  202  Time:  0.874  Rel. Train L2 Loss :  0.05910619058542781  Rel. Test L2 Loss :  0.06149419844150543  Test L2 Loss :  0.0890222418308258  inv_L_scale:  [1.0, 1.0]
Epoch :  203  Time:  0.868  Rel. Train L2 Loss :  0.059051208512650596  Rel. Test L2 Loss :  0.060793310850858685  Test L2 Loss :  0.08829314291477203  inv_L_scale:  [1.0, 1.0]
Epoch :  204  Time:  0.869  Rel. Train L2 Loss :  0.05900812831189897  Rel. Test L2 Loss :  0.06220527917146683  Test L2 Loss :  0.08956651210784912  inv_L_scale:  [1.0, 1.0]
Epoch :  205  Time:  0.865  Rel. Train L2 Loss :  0.05973104644152853  Rel. Test L2 Loss :  0.060927833020687105  Test L2 Loss :  0.0884061735868454  inv_L_scale:  [1.0, 1.0]
Epoch :  206  Time:  0.865  Rel. Train L2 Loss :  0.05883474694357978  Rel. Test L2 Loss :  0.06194177180528641  Test L2 Loss :  0.08936449587345123  inv_L_scale:  [1.0, 1.0]
Epoch :  207  Time:  0.867  Rel. Train L2 Loss :  0.059127825597922005  Rel. Test L2 Loss :  0.061145279407501224  Test L2 Loss :  0.08852030903100967  inv_L_scale:  [1.0, 1.0]
Epoch :  208  Time:  0.867  Rel. Train L2 Loss :  0.058446389536062876  Rel. Test L2 Loss :  0.059928582310676576  Test L2 Loss :  0.08654580980539323  inv_L_scale:  [1.0, 1.0]
Epoch :  209  Time:  0.866  Rel. Train L2 Loss :  0.05839433987935384  Rel. Test L2 Loss :  0.06439787209033966  Test L2 Loss :  0.0927080425620079  inv_L_scale:  [1.0, 1.0]
Epoch :  210  Time:  0.867  Rel. Train L2 Loss :  0.058611129704448914  Rel. Test L2 Loss :  0.061081899404525755  Test L2 Loss :  0.088609000146389  inv_L_scale:  [1.0, 1.0]
Epoch :  211  Time:  0.866  Rel. Train L2 Loss :  0.058906773659918046  Rel. Test L2 Loss :  0.060078892558813095  Test L2 Loss :  0.08738801270723343  inv_L_scale:  [1.0, 1.0]
Epoch :  212  Time:  0.866  Rel. Train L2 Loss :  0.058339956435892314  Rel. Test L2 Loss :  0.0601306714117527  Test L2 Loss :  0.08704006850719452  inv_L_scale:  [1.0, 1.0]
Epoch :  213  Time:  0.867  Rel. Train L2 Loss :  0.05826702660984463  Rel. Test L2 Loss :  0.061166547536849976  Test L2 Loss :  0.08840972423553467  inv_L_scale:  [1.0, 1.0]
Epoch :  214  Time:  0.866  Rel. Train L2 Loss :  0.05840116219388114  Rel. Test L2 Loss :  0.05964570969343185  Test L2 Loss :  0.08646436035633087  inv_L_scale:  [1.0, 1.0]
Epoch :  215  Time:  0.868  Rel. Train L2 Loss :  0.05848397947020001  Rel. Test L2 Loss :  0.06005998209118843  Test L2 Loss :  0.08694821774959564  inv_L_scale:  [1.0, 1.0]
Epoch :  216  Time:  0.865  Rel. Train L2 Loss :  0.05818034983343548  Rel. Test L2 Loss :  0.061001346856355665  Test L2 Loss :  0.08805860340595245  inv_L_scale:  [1.0, 1.0]
Epoch :  217  Time:  0.867  Rel. Train L2 Loss :  0.058806288093328475  Rel. Test L2 Loss :  0.0615671706199646  Test L2 Loss :  0.08898707747459411  inv_L_scale:  [1.0, 1.0]
Epoch :  218  Time:  0.867  Rel. Train L2 Loss :  0.05803267505433824  Rel. Test L2 Loss :  0.06551458865404129  Test L2 Loss :  0.09470284849405289  inv_L_scale:  [1.0, 1.0]
Epoch :  219  Time:  0.868  Rel. Train L2 Loss :  0.05903726372453901  Rel. Test L2 Loss :  0.060431872010231015  Test L2 Loss :  0.08736018866300582  inv_L_scale:  [1.0, 1.0]
Epoch :  220  Time:  0.867  Rel. Train L2 Loss :  0.058351966672473485  Rel. Test L2 Loss :  0.06068807691335678  Test L2 Loss :  0.08800426959991454  inv_L_scale:  [1.0, 1.0]
Epoch :  221  Time:  0.867  Rel. Train L2 Loss :  0.05808586170276006  Rel. Test L2 Loss :  0.059743596017360685  Test L2 Loss :  0.08651564091444015  inv_L_scale:  [1.0, 1.0]
Epoch :  222  Time:  0.867  Rel. Train L2 Loss :  0.05820408970117569  Rel. Test L2 Loss :  0.060842255353927614  Test L2 Loss :  0.08835056364536285  inv_L_scale:  [1.0, 1.0]
Epoch :  223  Time:  0.869  Rel. Train L2 Loss :  0.05897285117043389  Rel. Test L2 Loss :  0.06004845857620239  Test L2 Loss :  0.08726629287004471  inv_L_scale:  [1.0, 1.0]
Epoch :  224  Time:  0.865  Rel. Train L2 Loss :  0.05857674459616343  Rel. Test L2 Loss :  0.06011109605431557  Test L2 Loss :  0.08735093265771866  inv_L_scale:  [1.0, 1.0]
Epoch :  225  Time:  0.864  Rel. Train L2 Loss :  0.05840262621641159  Rel. Test L2 Loss :  0.06210903599858284  Test L2 Loss :  0.09016822099685669  inv_L_scale:  [1.0, 1.0]
Epoch :  226  Time:  0.867  Rel. Train L2 Loss :  0.058054053584734595  Rel. Test L2 Loss :  0.06165294140577316  Test L2 Loss :  0.08922042846679687  inv_L_scale:  [1.0, 1.0]
Epoch :  227  Time:  0.867  Rel. Train L2 Loss :  0.05818010745777024  Rel. Test L2 Loss :  0.05918539702892303  Test L2 Loss :  0.08582639276981353  inv_L_scale:  [1.0, 1.0]
Epoch :  228  Time:  0.87  Rel. Train L2 Loss :  0.05759808139668571  Rel. Test L2 Loss :  0.060571889579296115  Test L2 Loss :  0.0876382365822792  inv_L_scale:  [1.0, 1.0]
Epoch :  229  Time:  0.867  Rel. Train L2 Loss :  0.057560544510682425  Rel. Test L2 Loss :  0.060252549648284914  Test L2 Loss :  0.0873207527399063  inv_L_scale:  [1.0, 1.0]
Epoch :  230  Time:  0.866  Rel. Train L2 Loss :  0.05803222563531664  Rel. Test L2 Loss :  0.06163101345300674  Test L2 Loss :  0.08921640992164612  inv_L_scale:  [1.0, 1.0]
Epoch :  231  Time:  0.867  Rel. Train L2 Loss :  0.0583297707968288  Rel. Test L2 Loss :  0.05936743721365929  Test L2 Loss :  0.08613141536712647  inv_L_scale:  [1.0, 1.0]
Epoch :  232  Time:  0.867  Rel. Train L2 Loss :  0.0576661295692126  Rel. Test L2 Loss :  0.05974447309970856  Test L2 Loss :  0.08630926609039306  inv_L_scale:  [1.0, 1.0]
Epoch :  233  Time:  0.865  Rel. Train L2 Loss :  0.05777969754404492  Rel. Test L2 Loss :  0.05980203494429588  Test L2 Loss :  0.0866473776102066  inv_L_scale:  [1.0, 1.0]
Epoch :  234  Time:  0.865  Rel. Train L2 Loss :  0.057424895680612986  Rel. Test L2 Loss :  0.06318242698907853  Test L2 Loss :  0.09147579550743103  inv_L_scale:  [1.0, 1.0]
Epoch :  235  Time:  0.866  Rel. Train L2 Loss :  0.05804355334904459  Rel. Test L2 Loss :  0.05951218768954277  Test L2 Loss :  0.08596233159303665  inv_L_scale:  [1.0, 1.0]
Epoch :  236  Time:  0.865  Rel. Train L2 Loss :  0.05709625081883536  Rel. Test L2 Loss :  0.058396512269973756  Test L2 Loss :  0.08457679986953735  inv_L_scale:  [1.0, 1.0]
Epoch :  237  Time:  0.865  Rel. Train L2 Loss :  0.05738211118512684  Rel. Test L2 Loss :  0.05954823404550552  Test L2 Loss :  0.08629197150468826  inv_L_scale:  [1.0, 1.0]
Epoch :  238  Time:  0.866  Rel. Train L2 Loss :  0.05714854902691311  Rel. Test L2 Loss :  0.0601256850361824  Test L2 Loss :  0.08691766887903213  inv_L_scale:  [1.0, 1.0]
Epoch :  239  Time:  0.865  Rel. Train L2 Loss :  0.0575225109855334  Rel. Test L2 Loss :  0.05902037262916565  Test L2 Loss :  0.08552651405334473  inv_L_scale:  [1.0, 1.0]
Epoch :  240  Time:  0.866  Rel. Train L2 Loss :  0.058047496775786085  Rel. Test L2 Loss :  0.05935697376728058  Test L2 Loss :  0.08578344702720642  inv_L_scale:  [1.0, 1.0]
Epoch :  241  Time:  0.868  Rel. Train L2 Loss :  0.057136831498808334  Rel. Test L2 Loss :  0.06163103550672531  Test L2 Loss :  0.08895163714885712  inv_L_scale:  [1.0, 1.0]
Epoch :  242  Time:  0.864  Rel. Train L2 Loss :  0.057663455208142596  Rel. Test L2 Loss :  0.05985516428947449  Test L2 Loss :  0.08650253772735596  inv_L_scale:  [1.0, 1.0]
Epoch :  243  Time:  0.866  Rel. Train L2 Loss :  0.057654143902990555  Rel. Test L2 Loss :  0.058905384242534636  Test L2 Loss :  0.08547847747802734  inv_L_scale:  [1.0, 1.0]
Epoch :  244  Time:  0.864  Rel. Train L2 Loss :  0.05703752631942431  Rel. Test L2 Loss :  0.059535067826509476  Test L2 Loss :  0.08646848618984222  inv_L_scale:  [1.0, 1.0]
Epoch :  245  Time:  0.866  Rel. Train L2 Loss :  0.056869137750731574  Rel. Test L2 Loss :  0.06023253262042999  Test L2 Loss :  0.08729614824056625  inv_L_scale:  [1.0, 1.0]
Epoch :  246  Time:  0.866  Rel. Train L2 Loss :  0.05695743176672194  Rel. Test L2 Loss :  0.059367468655109404  Test L2 Loss :  0.08587705373764037  inv_L_scale:  [1.0, 1.0]
Epoch :  247  Time:  0.866  Rel. Train L2 Loss :  0.05697744212216801  Rel. Test L2 Loss :  0.06094367787241936  Test L2 Loss :  0.08779127299785613  inv_L_scale:  [1.0, 1.0]
Epoch :  248  Time:  0.865  Rel. Train L2 Loss :  0.05680620508061515  Rel. Test L2 Loss :  0.05903616040945053  Test L2 Loss :  0.08539491266012192  inv_L_scale:  [1.0, 1.0]
Epoch :  249  Time:  0.865  Rel. Train L2 Loss :  0.057071879903475446  Rel. Test L2 Loss :  0.0581244820356369  Test L2 Loss :  0.08410300403833389  inv_L_scale:  [1.0, 1.0]
Epoch :  250  Time:  0.866  Rel. Train L2 Loss :  0.056550274391969045  Rel. Test L2 Loss :  0.05847956120967865  Test L2 Loss :  0.08458487331867218  inv_L_scale:  [1.0, 1.0]
Epoch :  251  Time:  0.866  Rel. Train L2 Loss :  0.0567477140824  Rel. Test L2 Loss :  0.05808140009641647  Test L2 Loss :  0.08406232625246048  inv_L_scale:  [1.0, 1.0]
Epoch :  252  Time:  0.865  Rel. Train L2 Loss :  0.056796042058202954  Rel. Test L2 Loss :  0.05883404865860939  Test L2 Loss :  0.08521605044603348  inv_L_scale:  [1.0, 1.0]
Epoch :  253  Time:  0.868  Rel. Train L2 Loss :  0.056483580188618765  Rel. Test L2 Loss :  0.060857594907283784  Test L2 Loss :  0.08824071943759919  inv_L_scale:  [1.0, 1.0]
Epoch :  254  Time:  0.868  Rel. Train L2 Loss :  0.05733915107117759  Rel. Test L2 Loss :  0.05967734009027481  Test L2 Loss :  0.08636013895273209  inv_L_scale:  [1.0, 1.0]
Epoch :  255  Time:  0.866  Rel. Train L2 Loss :  0.05726418086224132  Rel. Test L2 Loss :  0.05968805491924286  Test L2 Loss :  0.08616788834333419  inv_L_scale:  [1.0, 1.0]
Epoch :  256  Time:  0.866  Rel. Train L2 Loss :  0.057064010186327827  Rel. Test L2 Loss :  0.059587399363517764  Test L2 Loss :  0.08612840443849563  inv_L_scale:  [1.0, 1.0]
Epoch :  257  Time:  0.866  Rel. Train L2 Loss :  0.05670211330056191  Rel. Test L2 Loss :  0.05990836828947067  Test L2 Loss :  0.08660356163978576  inv_L_scale:  [1.0, 1.0]
Epoch :  258  Time:  0.866  Rel. Train L2 Loss :  0.056548571669393116  Rel. Test L2 Loss :  0.05893232315778732  Test L2 Loss :  0.08532380133867264  inv_L_scale:  [1.0, 1.0]
Epoch :  259  Time:  0.867  Rel. Train L2 Loss :  0.05636289533641603  Rel. Test L2 Loss :  0.05922566682100296  Test L2 Loss :  0.08569106668233871  inv_L_scale:  [1.0, 1.0]
Epoch :  260  Time:  0.868  Rel. Train L2 Loss :  0.05646718892786238  Rel. Test L2 Loss :  0.05940003395080566  Test L2 Loss :  0.08612235695123673  inv_L_scale:  [1.0, 1.0]
Epoch :  261  Time:  0.864  Rel. Train L2 Loss :  0.05640349843435817  Rel. Test L2 Loss :  0.05852414131164551  Test L2 Loss :  0.0847425827383995  inv_L_scale:  [1.0, 1.0]
Epoch :  262  Time:  0.864  Rel. Train L2 Loss :  0.056052542825539904  Rel. Test L2 Loss :  0.058154220432043074  Test L2 Loss :  0.08411792308092117  inv_L_scale:  [1.0, 1.0]
Epoch :  263  Time:  0.865  Rel. Train L2 Loss :  0.05637600850727823  Rel. Test L2 Loss :  0.05877459108829498  Test L2 Loss :  0.085150286257267  inv_L_scale:  [1.0, 1.0]
Epoch :  264  Time:  0.866  Rel. Train L2 Loss :  0.055959455834494694  Rel. Test L2 Loss :  0.05863388657569885  Test L2 Loss :  0.08486350536346436  inv_L_scale:  [1.0, 1.0]
Epoch :  265  Time:  0.866  Rel. Train L2 Loss :  0.056262917551729415  Rel. Test L2 Loss :  0.058705614656209944  Test L2 Loss :  0.08475880563259125  inv_L_scale:  [1.0, 1.0]
Epoch :  266  Time:  0.868  Rel. Train L2 Loss :  0.05584638597236739  Rel. Test L2 Loss :  0.058906303942203524  Test L2 Loss :  0.08521450281143189  inv_L_scale:  [1.0, 1.0]
Epoch :  267  Time:  0.866  Rel. Train L2 Loss :  0.05597985625267029  Rel. Test L2 Loss :  0.059575677961111066  Test L2 Loss :  0.08636008501052857  inv_L_scale:  [1.0, 1.0]
Epoch :  268  Time:  0.866  Rel. Train L2 Loss :  0.05599346243672901  Rel. Test L2 Loss :  0.05854069769382477  Test L2 Loss :  0.08508417516946792  inv_L_scale:  [1.0, 1.0]
Epoch :  269  Time:  0.866  Rel. Train L2 Loss :  0.056043812698788116  Rel. Test L2 Loss :  0.05889515414834023  Test L2 Loss :  0.08547013491392136  inv_L_scale:  [1.0, 1.0]
Epoch :  270  Time:  0.866  Rel. Train L2 Loss :  0.05582682987054189  Rel. Test L2 Loss :  0.05971438989043236  Test L2 Loss :  0.08660797297954559  inv_L_scale:  [1.0, 1.0]
Epoch :  271  Time:  0.866  Rel. Train L2 Loss :  0.056215164992544385  Rel. Test L2 Loss :  0.05879994839429856  Test L2 Loss :  0.08522826761007309  inv_L_scale:  [1.0, 1.0]
Epoch :  272  Time:  0.865  Rel. Train L2 Loss :  0.056450614151027464  Rel. Test L2 Loss :  0.05848648056387901  Test L2 Loss :  0.0848636543750763  inv_L_scale:  [1.0, 1.0]
Epoch :  273  Time:  0.866  Rel. Train L2 Loss :  0.056294387711419  Rel. Test L2 Loss :  0.05730634719133377  Test L2 Loss :  0.08305296659469605  inv_L_scale:  [1.0, 1.0]
Epoch :  274  Time:  0.866  Rel. Train L2 Loss :  0.05640931010246277  Rel. Test L2 Loss :  0.05829451590776444  Test L2 Loss :  0.08432308435440064  inv_L_scale:  [1.0, 1.0]
Epoch :  275  Time:  0.866  Rel. Train L2 Loss :  0.05587093556920687  Rel. Test L2 Loss :  0.057707606703042987  Test L2 Loss :  0.08376630425453185  inv_L_scale:  [1.0, 1.0]
Epoch :  276  Time:  0.866  Rel. Train L2 Loss :  0.055818518184953266  Rel. Test L2 Loss :  0.05785945504903793  Test L2 Loss :  0.08378080010414124  inv_L_scale:  [1.0, 1.0]
Epoch :  277  Time:  0.866  Rel. Train L2 Loss :  0.05548032472531001  Rel. Test L2 Loss :  0.05872543752193451  Test L2 Loss :  0.08519122838973998  inv_L_scale:  [1.0, 1.0]
Epoch :  278  Time:  0.869  Rel. Train L2 Loss :  0.05602765056822035  Rel. Test L2 Loss :  0.05815565377473831  Test L2 Loss :  0.08428079158067703  inv_L_scale:  [1.0, 1.0]
Epoch :  279  Time:  0.865  Rel. Train L2 Loss :  0.055815655125512016  Rel. Test L2 Loss :  0.05802792236208916  Test L2 Loss :  0.08426524341106414  inv_L_scale:  [1.0, 1.0]
Epoch :  280  Time:  0.866  Rel. Train L2 Loss :  0.05577669163544973  Rel. Test L2 Loss :  0.05784179657697677  Test L2 Loss :  0.08364850401878357  inv_L_scale:  [1.0, 1.0]
Epoch :  281  Time:  0.864  Rel. Train L2 Loss :  0.055265811946656966  Rel. Test L2 Loss :  0.05721185714006424  Test L2 Loss :  0.08289115697145462  inv_L_scale:  [1.0, 1.0]
Epoch :  282  Time:  0.864  Rel. Train L2 Loss :  0.05570047914981842  Rel. Test L2 Loss :  0.059686214327812195  Test L2 Loss :  0.08645733833312988  inv_L_scale:  [1.0, 1.0]
Epoch :  283  Time:  0.866  Rel. Train L2 Loss :  0.05586392909288406  Rel. Test L2 Loss :  0.057130944728851316  Test L2 Loss :  0.0826836758852005  inv_L_scale:  [1.0, 1.0]
Epoch :  284  Time:  0.864  Rel. Train L2 Loss :  0.05548317111200757  Rel. Test L2 Loss :  0.0568211704492569  Test L2 Loss :  0.08246253371238708  inv_L_scale:  [1.0, 1.0]
Epoch :  285  Time:  0.866  Rel. Train L2 Loss :  0.05503237782253159  Rel. Test L2 Loss :  0.05763131678104401  Test L2 Loss :  0.08340335488319398  inv_L_scale:  [1.0, 1.0]
Epoch :  286  Time:  0.865  Rel. Train L2 Loss :  0.05551750063896179  Rel. Test L2 Loss :  0.058740095496177674  Test L2 Loss :  0.08512306392192841  inv_L_scale:  [1.0, 1.0]
Epoch :  287  Time:  0.865  Rel. Train L2 Loss :  0.05529246967699793  Rel. Test L2 Loss :  0.058477538228034975  Test L2 Loss :  0.0847724747657776  inv_L_scale:  [1.0, 1.0]
Epoch :  288  Time:  0.866  Rel. Train L2 Loss :  0.05558849783407317  Rel. Test L2 Loss :  0.057196771800518034  Test L2 Loss :  0.08309958934783936  inv_L_scale:  [1.0, 1.0]
Epoch :  289  Time:  0.865  Rel. Train L2 Loss :  0.055310758584075505  Rel. Test L2 Loss :  0.05930408820509911  Test L2 Loss :  0.0860381042957306  inv_L_scale:  [1.0, 1.0]
Epoch :  290  Time:  0.865  Rel. Train L2 Loss :  0.055270988874965246  Rel. Test L2 Loss :  0.05762165486812591  Test L2 Loss :  0.08337929308414459  inv_L_scale:  [1.0, 1.0]
Epoch :  291  Time:  0.866  Rel. Train L2 Loss :  0.055035369098186494  Rel. Test L2 Loss :  0.05900294974446297  Test L2 Loss :  0.08556035935878753  inv_L_scale:  [1.0, 1.0]
Epoch :  292  Time:  0.863  Rel. Train L2 Loss :  0.05491120234131813  Rel. Test L2 Loss :  0.058214882761240004  Test L2 Loss :  0.0842590656876564  inv_L_scale:  [1.0, 1.0]
Epoch :  293  Time:  0.863  Rel. Train L2 Loss :  0.05491090574198299  Rel. Test L2 Loss :  0.0568308824300766  Test L2 Loss :  0.08233973801136017  inv_L_scale:  [1.0, 1.0]
Epoch :  294  Time:  0.863  Rel. Train L2 Loss :  0.05494563000069724  Rel. Test L2 Loss :  0.05762266293168068  Test L2 Loss :  0.08348076760768891  inv_L_scale:  [1.0, 1.0]
Epoch :  295  Time:  0.863  Rel. Train L2 Loss :  0.05482819866802957  Rel. Test L2 Loss :  0.05789042919874191  Test L2 Loss :  0.08391952455043793  inv_L_scale:  [1.0, 1.0]
Epoch :  296  Time:  0.863  Rel. Train L2 Loss :  0.05509927387038867  Rel. Test L2 Loss :  0.058877543359994886  Test L2 Loss :  0.08514626860618592  inv_L_scale:  [1.0, 1.0]
Epoch :  297  Time:  0.863  Rel. Train L2 Loss :  0.05557355822788344  Rel. Test L2 Loss :  0.0572362607717514  Test L2 Loss :  0.08302589058876038  inv_L_scale:  [1.0, 1.0]
Epoch :  298  Time:  0.863  Rel. Train L2 Loss :  0.05456699242194494  Rel. Test L2 Loss :  0.05761130511760712  Test L2 Loss :  0.08353935718536377  inv_L_scale:  [1.0, 1.0]
Epoch :  299  Time:  0.863  Rel. Train L2 Loss :  0.054664718045128714  Rel. Test L2 Loss :  0.05692379280924797  Test L2 Loss :  0.08253792732954025  inv_L_scale:  [1.0, 1.0]
Epoch :  300  Time:  0.863  Rel. Train L2 Loss :  0.054319711476564406  Rel. Test L2 Loss :  0.056823360472917556  Test L2 Loss :  0.08257118612527847  inv_L_scale:  [1.0, 1.0]
Epoch :  301  Time:  0.863  Rel. Train L2 Loss :  0.055012805494997236  Rel. Test L2 Loss :  0.05688079193234444  Test L2 Loss :  0.0824589478969574  inv_L_scale:  [1.0, 1.0]
Epoch :  302  Time:  0.863  Rel. Train L2 Loss :  0.054428367151154414  Rel. Test L2 Loss :  0.056846387833356854  Test L2 Loss :  0.08222091794013978  inv_L_scale:  [1.0, 1.0]
Epoch :  303  Time:  0.863  Rel. Train L2 Loss :  0.054583850155274075  Rel. Test L2 Loss :  0.056475793719291685  Test L2 Loss :  0.08189235657453536  inv_L_scale:  [1.0, 1.0]
Epoch :  304  Time:  0.863  Rel. Train L2 Loss :  0.05429502636194229  Rel. Test L2 Loss :  0.05737860575318336  Test L2 Loss :  0.08355389177799225  inv_L_scale:  [1.0, 1.0]
Epoch :  305  Time:  0.863  Rel. Train L2 Loss :  0.05518738185365995  Rel. Test L2 Loss :  0.05734514698386192  Test L2 Loss :  0.08320020705461502  inv_L_scale:  [1.0, 1.0]
Epoch :  306  Time:  0.862  Rel. Train L2 Loss :  0.054812303880850476  Rel. Test L2 Loss :  0.0575037693977356  Test L2 Loss :  0.08321678757667542  inv_L_scale:  [1.0, 1.0]
Epoch :  307  Time:  0.863  Rel. Train L2 Loss :  0.05441671427753236  Rel. Test L2 Loss :  0.057140712291002274  Test L2 Loss :  0.08295382976531983  inv_L_scale:  [1.0, 1.0]
Epoch :  308  Time:  0.863  Rel. Train L2 Loss :  0.05441453508204884  Rel. Test L2 Loss :  0.05725585639476776  Test L2 Loss :  0.08301730334758758  inv_L_scale:  [1.0, 1.0]
Epoch :  309  Time:  0.863  Rel. Train L2 Loss :  0.05412061823738946  Rel. Test L2 Loss :  0.05699565723538399  Test L2 Loss :  0.08280164480209351  inv_L_scale:  [1.0, 1.0]
Epoch :  310  Time:  0.863  Rel. Train L2 Loss :  0.054007266528076595  Rel. Test L2 Loss :  0.05746193692088127  Test L2 Loss :  0.08320457130670547  inv_L_scale:  [1.0, 1.0]
Epoch :  311  Time:  0.863  Rel. Train L2 Loss :  0.05401258268290096  Rel. Test L2 Loss :  0.05708580702543259  Test L2 Loss :  0.08278876602649689  inv_L_scale:  [1.0, 1.0]
Epoch :  312  Time:  0.863  Rel. Train L2 Loss :  0.05424697952138053  Rel. Test L2 Loss :  0.05594571843743324  Test L2 Loss :  0.08132883101701736  inv_L_scale:  [1.0, 1.0]
Epoch :  313  Time:  0.863  Rel. Train L2 Loss :  0.05397358482082685  Rel. Test L2 Loss :  0.0577082547545433  Test L2 Loss :  0.08366159498691558  inv_L_scale:  [1.0, 1.0]
Epoch :  314  Time:  0.863  Rel. Train L2 Loss :  0.053903348031971186  Rel. Test L2 Loss :  0.056784119457006454  Test L2 Loss :  0.0824049586057663  inv_L_scale:  [1.0, 1.0]
Epoch :  315  Time:  0.863  Rel. Train L2 Loss :  0.0539120066497061  Rel. Test L2 Loss :  0.057006950676441195  Test L2 Loss :  0.08245059996843337  inv_L_scale:  [1.0, 1.0]
Epoch :  316  Time:  0.863  Rel. Train L2 Loss :  0.05374519674314393  Rel. Test L2 Loss :  0.056921425610780715  Test L2 Loss :  0.08247206389904022  inv_L_scale:  [1.0, 1.0]
Epoch :  317  Time:  0.862  Rel. Train L2 Loss :  0.05380646619531843  Rel. Test L2 Loss :  0.05683986991643906  Test L2 Loss :  0.08241396903991699  inv_L_scale:  [1.0, 1.0]
Epoch :  318  Time:  0.863  Rel. Train L2 Loss :  0.05430738661024306  Rel. Test L2 Loss :  0.05739119008183479  Test L2 Loss :  0.0832326078414917  inv_L_scale:  [1.0, 1.0]
Epoch :  319  Time:  0.863  Rel. Train L2 Loss :  0.05386153080397182  Rel. Test L2 Loss :  0.0568000628054142  Test L2 Loss :  0.08227773666381837  inv_L_scale:  [1.0, 1.0]
Epoch :  320  Time:  0.863  Rel. Train L2 Loss :  0.05370380060540305  Rel. Test L2 Loss :  0.056943697184324266  Test L2 Loss :  0.08284114956855775  inv_L_scale:  [1.0, 1.0]
Epoch :  321  Time:  0.863  Rel. Train L2 Loss :  0.05421020650201373  Rel. Test L2 Loss :  0.0575164307653904  Test L2 Loss :  0.08338381588459015  inv_L_scale:  [1.0, 1.0]
Epoch :  322  Time:  0.864  Rel. Train L2 Loss :  0.0536370379726092  Rel. Test L2 Loss :  0.05678458064794541  Test L2 Loss :  0.08239693313837052  inv_L_scale:  [1.0, 1.0]
Epoch :  323  Time:  0.863  Rel. Train L2 Loss :  0.05383990670243899  Rel. Test L2 Loss :  0.05815242499113083  Test L2 Loss :  0.08416044235229492  inv_L_scale:  [1.0, 1.0]
Epoch :  324  Time:  0.863  Rel. Train L2 Loss :  0.05363117179108991  Rel. Test L2 Loss :  0.05678976148366928  Test L2 Loss :  0.08202804327011108  inv_L_scale:  [1.0, 1.0]
Epoch :  325  Time:  0.863  Rel. Train L2 Loss :  0.05359064698219299  Rel. Test L2 Loss :  0.055973969548940655  Test L2 Loss :  0.08109306126832962  inv_L_scale:  [1.0, 1.0]
Epoch :  326  Time:  0.863  Rel. Train L2 Loss :  0.05348111170861456  Rel. Test L2 Loss :  0.05682330399751663  Test L2 Loss :  0.08221281468868255  inv_L_scale:  [1.0, 1.0]
Epoch :  327  Time:  0.863  Rel. Train L2 Loss :  0.05381928256816334  Rel. Test L2 Loss :  0.05648461803793907  Test L2 Loss :  0.08193106055259705  inv_L_scale:  [1.0, 1.0]
Epoch :  328  Time:  0.863  Rel. Train L2 Loss :  0.053454485287268955  Rel. Test L2 Loss :  0.05745402604341507  Test L2 Loss :  0.0831823068857193  inv_L_scale:  [1.0, 1.0]
Epoch :  329  Time:  0.863  Rel. Train L2 Loss :  0.05371837503380246  Rel. Test L2 Loss :  0.056471249610185625  Test L2 Loss :  0.0819580090045929  inv_L_scale:  [1.0, 1.0]
Epoch :  330  Time:  0.863  Rel. Train L2 Loss :  0.05353512701061037  Rel. Test L2 Loss :  0.05732888996601105  Test L2 Loss :  0.08329665005207061  inv_L_scale:  [1.0, 1.0]
Epoch :  331  Time:  0.863  Rel. Train L2 Loss :  0.0536278811428282  Rel. Test L2 Loss :  0.05594265431165695  Test L2 Loss :  0.08121742725372315  inv_L_scale:  [1.0, 1.0]
Epoch :  332  Time:  0.863  Rel. Train L2 Loss :  0.05343700481785668  Rel. Test L2 Loss :  0.056062856018543245  Test L2 Loss :  0.08150502264499665  inv_L_scale:  [1.0, 1.0]
Epoch :  333  Time:  0.863  Rel. Train L2 Loss :  0.05321410553322898  Rel. Test L2 Loss :  0.05617807745933533  Test L2 Loss :  0.08132880389690399  inv_L_scale:  [1.0, 1.0]
Epoch :  334  Time:  0.862  Rel. Train L2 Loss :  0.05312857243749831  Rel. Test L2 Loss :  0.056505110561847684  Test L2 Loss :  0.08208958595991135  inv_L_scale:  [1.0, 1.0]
Epoch :  335  Time:  0.863  Rel. Train L2 Loss :  0.053210205485423406  Rel. Test L2 Loss :  0.05648899853229523  Test L2 Loss :  0.08186561822891235  inv_L_scale:  [1.0, 1.0]
Epoch :  336  Time:  0.863  Rel. Train L2 Loss :  0.05310523849394586  Rel. Test L2 Loss :  0.056462219506502154  Test L2 Loss :  0.08181064754724503  inv_L_scale:  [1.0, 1.0]
Epoch :  337  Time:  0.863  Rel. Train L2 Loss :  0.053260836882723706  Rel. Test L2 Loss :  0.05585240036249161  Test L2 Loss :  0.0811271870136261  inv_L_scale:  [1.0, 1.0]
Epoch :  338  Time:  0.863  Rel. Train L2 Loss :  0.05284583646390173  Rel. Test L2 Loss :  0.055963936746120456  Test L2 Loss :  0.08110805094242096  inv_L_scale:  [1.0, 1.0]
Epoch :  339  Time:  0.865  Rel. Train L2 Loss :  0.05289591880308257  Rel. Test L2 Loss :  0.05599929615855217  Test L2 Loss :  0.08135019570589065  inv_L_scale:  [1.0, 1.0]
Epoch :  340  Time:  0.864  Rel. Train L2 Loss :  0.052956096794870164  Rel. Test L2 Loss :  0.05605457827448845  Test L2 Loss :  0.08115290760993958  inv_L_scale:  [1.0, 1.0]
Epoch :  341  Time:  0.863  Rel. Train L2 Loss :  0.0529172218673759  Rel. Test L2 Loss :  0.056301828771829605  Test L2 Loss :  0.08179647624492645  inv_L_scale:  [1.0, 1.0]
Epoch :  342  Time:  0.863  Rel. Train L2 Loss :  0.05312525673045052  Rel. Test L2 Loss :  0.05516394093632698  Test L2 Loss :  0.0801955807209015  inv_L_scale:  [1.0, 1.0]
Epoch :  343  Time:  0.863  Rel. Train L2 Loss :  0.05287207101782163  Rel. Test L2 Loss :  0.05698247596621513  Test L2 Loss :  0.0826693457365036  inv_L_scale:  [1.0, 1.0]
Epoch :  344  Time:  0.862  Rel. Train L2 Loss :  0.05292052783899837  Rel. Test L2 Loss :  0.05600981414318085  Test L2 Loss :  0.08129963129758835  inv_L_scale:  [1.0, 1.0]
Epoch :  345  Time:  0.862  Rel. Train L2 Loss :  0.05284002939860026  Rel. Test L2 Loss :  0.05623369634151459  Test L2 Loss :  0.08163531512022018  inv_L_scale:  [1.0, 1.0]
Epoch :  346  Time:  0.863  Rel. Train L2 Loss :  0.052744964957237246  Rel. Test L2 Loss :  0.05604154035449028  Test L2 Loss :  0.08132746815681458  inv_L_scale:  [1.0, 1.0]
Epoch :  347  Time:  0.862  Rel. Train L2 Loss :  0.05269404513968362  Rel. Test L2 Loss :  0.05603718355298042  Test L2 Loss :  0.08138287276029586  inv_L_scale:  [1.0, 1.0]
Epoch :  348  Time:  0.862  Rel. Train L2 Loss :  0.05276929320560561  Rel. Test L2 Loss :  0.05508838444948196  Test L2 Loss :  0.08004289209842681  inv_L_scale:  [1.0, 1.0]
Epoch :  349  Time:  0.863  Rel. Train L2 Loss :  0.0526381477382448  Rel. Test L2 Loss :  0.05563169747591019  Test L2 Loss :  0.08066095173358917  inv_L_scale:  [1.0, 1.0]
Epoch :  350  Time:  0.862  Rel. Train L2 Loss :  0.05274707699815432  Rel. Test L2 Loss :  0.05610000386834144  Test L2 Loss :  0.0815068581700325  inv_L_scale:  [1.0, 1.0]
Epoch :  351  Time:  0.863  Rel. Train L2 Loss :  0.05245355354415046  Rel. Test L2 Loss :  0.055896579325199126  Test L2 Loss :  0.08101196944713593  inv_L_scale:  [1.0, 1.0]
Epoch :  352  Time:  0.863  Rel. Train L2 Loss :  0.052659280912743675  Rel. Test L2 Loss :  0.05544516012072563  Test L2 Loss :  0.08045198768377304  inv_L_scale:  [1.0, 1.0]
Epoch :  353  Time:  0.863  Rel. Train L2 Loss :  0.05251219044129054  Rel. Test L2 Loss :  0.055601458549499515  Test L2 Loss :  0.08058975517749786  inv_L_scale:  [1.0, 1.0]
Epoch :  354  Time:  0.863  Rel. Train L2 Loss :  0.05253980325327979  Rel. Test L2 Loss :  0.05571095436811447  Test L2 Loss :  0.08082811921834945  inv_L_scale:  [1.0, 1.0]
Epoch :  355  Time:  0.863  Rel. Train L2 Loss :  0.05256047639581892  Rel. Test L2 Loss :  0.056381944417953495  Test L2 Loss :  0.08179571509361266  inv_L_scale:  [1.0, 1.0]
Epoch :  356  Time:  0.863  Rel. Train L2 Loss :  0.05260260250833299  Rel. Test L2 Loss :  0.05657643973827362  Test L2 Loss :  0.08198149800300598  inv_L_scale:  [1.0, 1.0]
Epoch :  357  Time:  0.863  Rel. Train L2 Loss :  0.05277000303897593  Rel. Test L2 Loss :  0.05562479078769684  Test L2 Loss :  0.0807001233100891  inv_L_scale:  [1.0, 1.0]
Epoch :  358  Time:  0.863  Rel. Train L2 Loss :  0.0526706674695015  Rel. Test L2 Loss :  0.05586478978395462  Test L2 Loss :  0.08108777344226838  inv_L_scale:  [1.0, 1.0]
Epoch :  359  Time:  0.863  Rel. Train L2 Loss :  0.0522297446264161  Rel. Test L2 Loss :  0.05521074533462524  Test L2 Loss :  0.08023165911436081  inv_L_scale:  [1.0, 1.0]
Epoch :  360  Time:  0.863  Rel. Train L2 Loss :  0.05238882407546044  Rel. Test L2 Loss :  0.05508640676736832  Test L2 Loss :  0.0800184765458107  inv_L_scale:  [1.0, 1.0]
Epoch :  361  Time:  0.863  Rel. Train L2 Loss :  0.052155187245872286  Rel. Test L2 Loss :  0.05542466744780541  Test L2 Loss :  0.08037669092416763  inv_L_scale:  [1.0, 1.0]
Epoch :  362  Time:  0.862  Rel. Train L2 Loss :  0.05225517061021593  Rel. Test L2 Loss :  0.05553532272577286  Test L2 Loss :  0.08046833157539368  inv_L_scale:  [1.0, 1.0]
Epoch :  363  Time:  0.862  Rel. Train L2 Loss :  0.052179975774553085  Rel. Test L2 Loss :  0.05534074872732162  Test L2 Loss :  0.0802770820260048  inv_L_scale:  [1.0, 1.0]
Epoch :  364  Time:  0.862  Rel. Train L2 Loss :  0.05197224934895833  Rel. Test L2 Loss :  0.05550528556108475  Test L2 Loss :  0.08053122818470002  inv_L_scale:  [1.0, 1.0]
Epoch :  365  Time:  0.863  Rel. Train L2 Loss :  0.05209039807319641  Rel. Test L2 Loss :  0.055450011640787125  Test L2 Loss :  0.0806252247095108  inv_L_scale:  [1.0, 1.0]
Epoch :  366  Time:  0.863  Rel. Train L2 Loss :  0.0521666556596756  Rel. Test L2 Loss :  0.05513280972838402  Test L2 Loss :  0.08007698655128478  inv_L_scale:  [1.0, 1.0]
Epoch :  367  Time:  0.862  Rel. Train L2 Loss :  0.051867090422246194  Rel. Test L2 Loss :  0.05500777542591095  Test L2 Loss :  0.07976433962583541  inv_L_scale:  [1.0, 1.0]
Epoch :  368  Time:  0.863  Rel. Train L2 Loss :  0.05186843494574229  Rel. Test L2 Loss :  0.055206134468317035  Test L2 Loss :  0.08007146805524826  inv_L_scale:  [1.0, 1.0]
Epoch :  369  Time:  0.862  Rel. Train L2 Loss :  0.052075723989142314  Rel. Test L2 Loss :  0.05519461214542389  Test L2 Loss :  0.0801466879248619  inv_L_scale:  [1.0, 1.0]
Epoch :  370  Time:  0.862  Rel. Train L2 Loss :  0.05187200569444232  Rel. Test L2 Loss :  0.0554690283536911  Test L2 Loss :  0.08053374201059342  inv_L_scale:  [1.0, 1.0]
Epoch :  371  Time:  0.862  Rel. Train L2 Loss :  0.05187309455540445  Rel. Test L2 Loss :  0.05518447503447533  Test L2 Loss :  0.08026416182518005  inv_L_scale:  [1.0, 1.0]
Epoch :  372  Time:  0.861  Rel. Train L2 Loss :  0.05180188356174363  Rel. Test L2 Loss :  0.055281823873519896  Test L2 Loss :  0.08023313611745835  inv_L_scale:  [1.0, 1.0]
Epoch :  373  Time:  0.863  Rel. Train L2 Loss :  0.051757215956846875  Rel. Test L2 Loss :  0.054688261598348616  Test L2 Loss :  0.07944969415664672  inv_L_scale:  [1.0, 1.0]
Epoch :  374  Time:  0.862  Rel. Train L2 Loss :  0.051738937265343135  Rel. Test L2 Loss :  0.054750196635723114  Test L2 Loss :  0.07946572184562684  inv_L_scale:  [1.0, 1.0]
Epoch :  375  Time:  0.862  Rel. Train L2 Loss :  0.05191518091493183  Rel. Test L2 Loss :  0.05506724983453751  Test L2 Loss :  0.07997266232967376  inv_L_scale:  [1.0, 1.0]
Epoch :  376  Time:  0.862  Rel. Train L2 Loss :  0.05176033463742998  Rel. Test L2 Loss :  0.05508210808038712  Test L2 Loss :  0.07994697898626328  inv_L_scale:  [1.0, 1.0]
Epoch :  377  Time:  0.862  Rel. Train L2 Loss :  0.051776521454254786  Rel. Test L2 Loss :  0.055046629011631015  Test L2 Loss :  0.07997278273105621  inv_L_scale:  [1.0, 1.0]
Epoch :  378  Time:  0.862  Rel. Train L2 Loss :  0.05176003840234544  Rel. Test L2 Loss :  0.05518656000494957  Test L2 Loss :  0.08006754219532013  inv_L_scale:  [1.0, 1.0]
Epoch :  379  Time:  0.862  Rel. Train L2 Loss :  0.05178510008586778  Rel. Test L2 Loss :  0.05466559857130051  Test L2 Loss :  0.07938827455043793  inv_L_scale:  [1.0, 1.0]
Epoch :  380  Time:  0.862  Rel. Train L2 Loss :  0.05158856133619944  Rel. Test L2 Loss :  0.05476651966571808  Test L2 Loss :  0.0795358020067215  inv_L_scale:  [1.0, 1.0]
Epoch :  381  Time:  0.862  Rel. Train L2 Loss :  0.05162381450335185  Rel. Test L2 Loss :  0.05526265323162079  Test L2 Loss :  0.08020725071430207  inv_L_scale:  [1.0, 1.0]
Epoch :  382  Time:  0.862  Rel. Train L2 Loss :  0.051473898109462526  Rel. Test L2 Loss :  0.054799803495407105  Test L2 Loss :  0.07949690252542496  inv_L_scale:  [1.0, 1.0]
Epoch :  383  Time:  0.862  Rel. Train L2 Loss :  0.05142830640077591  Rel. Test L2 Loss :  0.05511906653642654  Test L2 Loss :  0.08000206381082535  inv_L_scale:  [1.0, 1.0]
Epoch :  384  Time:  0.862  Rel. Train L2 Loss :  0.05145765652259191  Rel. Test L2 Loss :  0.054895598888397214  Test L2 Loss :  0.07964733392000198  inv_L_scale:  [1.0, 1.0]
Epoch :  385  Time:  0.862  Rel. Train L2 Loss :  0.051577602492438424  Rel. Test L2 Loss :  0.05493733644485474  Test L2 Loss :  0.079748974442482  inv_L_scale:  [1.0, 1.0]
Epoch :  386  Time:  0.862  Rel. Train L2 Loss :  0.051347344468037286  Rel. Test L2 Loss :  0.054735904335975645  Test L2 Loss :  0.07946854472160339  inv_L_scale:  [1.0, 1.0]
Epoch :  387  Time:  0.862  Rel. Train L2 Loss :  0.05132987823751237  Rel. Test L2 Loss :  0.0547168929874897  Test L2 Loss :  0.07950372368097305  inv_L_scale:  [1.0, 1.0]
Epoch :  388  Time:  0.862  Rel. Train L2 Loss :  0.05130167772372564  Rel. Test L2 Loss :  0.054815692901611326  Test L2 Loss :  0.079445661008358  inv_L_scale:  [1.0, 1.0]
Epoch :  389  Time:  0.862  Rel. Train L2 Loss :  0.051167500548892554  Rel. Test L2 Loss :  0.054499349296092986  Test L2 Loss :  0.07918253034353256  inv_L_scale:  [1.0, 1.0]
Epoch :  390  Time:  0.864  Rel. Train L2 Loss :  0.051302253405253094  Rel. Test L2 Loss :  0.05494287595152855  Test L2 Loss :  0.07979202717542648  inv_L_scale:  [1.0, 1.0]
Epoch :  391  Time:  0.863  Rel. Train L2 Loss :  0.051199506223201754  Rel. Test L2 Loss :  0.054759181886911396  Test L2 Loss :  0.07953948229551315  inv_L_scale:  [1.0, 1.0]
Epoch :  392  Time:  0.863  Rel. Train L2 Loss :  0.05118895793954532  Rel. Test L2 Loss :  0.054730710983276365  Test L2 Loss :  0.0794112977385521  inv_L_scale:  [1.0, 1.0]
Epoch :  393  Time:  0.862  Rel. Train L2 Loss :  0.05112863841984007  Rel. Test L2 Loss :  0.054629428684711455  Test L2 Loss :  0.07937339633703232  inv_L_scale:  [1.0, 1.0]
Epoch :  394  Time:  0.863  Rel. Train L2 Loss :  0.051165335492955315  Rel. Test L2 Loss :  0.05484431564807892  Test L2 Loss :  0.07962163984775543  inv_L_scale:  [1.0, 1.0]
Epoch :  395  Time:  0.862  Rel. Train L2 Loss :  0.051162896967596475  Rel. Test L2 Loss :  0.05467747718095779  Test L2 Loss :  0.07945475608110428  inv_L_scale:  [1.0, 1.0]
Epoch :  396  Time:  0.863  Rel. Train L2 Loss :  0.051071171280410554  Rel. Test L2 Loss :  0.054789642691612246  Test L2 Loss :  0.07948592633008957  inv_L_scale:  [1.0, 1.0]
Epoch :  397  Time:  0.864  Rel. Train L2 Loss :  0.051039623667796456  Rel. Test L2 Loss :  0.054663927853107454  Test L2 Loss :  0.07940461009740829  inv_L_scale:  [1.0, 1.0]
Epoch :  398  Time:  0.862  Rel. Train L2 Loss :  0.05091960507962439  Rel. Test L2 Loss :  0.054703446924686434  Test L2 Loss :  0.07944547832012176  inv_L_scale:  [1.0, 1.0]
Epoch :  399  Time:  0.862  Rel. Train L2 Loss :  0.050962451895078024  Rel. Test L2 Loss :  0.054763634353876114  Test L2 Loss :  0.07950593411922455  inv_L_scale:  [1.0, 1.0]
Epoch :  400  Time:  0.861  Rel. Train L2 Loss :  0.05104983556601736  Rel. Test L2 Loss :  0.054765745401382446  Test L2 Loss :  0.07940634965896606  inv_L_scale:  [1.0, 1.0]
Epoch :  401  Time:  0.862  Rel. Train L2 Loss :  0.05092315682106548  Rel. Test L2 Loss :  0.05449323445558548  Test L2 Loss :  0.07909478604793549  inv_L_scale:  [1.0, 1.0]
Epoch :  402  Time:  0.862  Rel. Train L2 Loss :  0.05087874329752392  Rel. Test L2 Loss :  0.05425314515829086  Test L2 Loss :  0.0788210877776146  inv_L_scale:  [1.0, 1.0]
Epoch :  403  Time:  0.862  Rel. Train L2 Loss :  0.05086623668670654  Rel. Test L2 Loss :  0.054370366632938386  Test L2 Loss :  0.07899239063262939  inv_L_scale:  [1.0, 1.0]
Epoch :  404  Time:  0.862  Rel. Train L2 Loss :  0.050908994360102544  Rel. Test L2 Loss :  0.054526651799678805  Test L2 Loss :  0.07913933634757996  inv_L_scale:  [1.0, 1.0]
Epoch :  405  Time:  0.862  Rel. Train L2 Loss :  0.050943477700153984  Rel. Test L2 Loss :  0.054590116739273074  Test L2 Loss :  0.07921705305576325  inv_L_scale:  [1.0, 1.0]
Epoch :  406  Time:  0.862  Rel. Train L2 Loss :  0.05078650340437889  Rel. Test L2 Loss :  0.054490270763635634  Test L2 Loss :  0.07914352953433991  inv_L_scale:  [1.0, 1.0]
Epoch :  407  Time:  0.863  Rel. Train L2 Loss :  0.05070163468519846  Rel. Test L2 Loss :  0.054370142817497254  Test L2 Loss :  0.07891494452953339  inv_L_scale:  [1.0, 1.0]
Epoch :  408  Time:  0.863  Rel. Train L2 Loss :  0.050719421638382806  Rel. Test L2 Loss :  0.05437848731875419  Test L2 Loss :  0.0789417165517807  inv_L_scale:  [1.0, 1.0]
Epoch :  409  Time:  0.863  Rel. Train L2 Loss :  0.05071630458037058  Rel. Test L2 Loss :  0.054349529147148135  Test L2 Loss :  0.07895252734422684  inv_L_scale:  [1.0, 1.0]
Epoch :  410  Time:  0.862  Rel. Train L2 Loss :  0.050606552528010475  Rel. Test L2 Loss :  0.054337492734193804  Test L2 Loss :  0.07885443925857544  inv_L_scale:  [1.0, 1.0]
Epoch :  411  Time:  0.862  Rel. Train L2 Loss :  0.05062428143289354  Rel. Test L2 Loss :  0.05423617005348205  Test L2 Loss :  0.07874478816986084  inv_L_scale:  [1.0, 1.0]
Epoch :  412  Time:  0.862  Rel. Train L2 Loss :  0.050604095309972764  Rel. Test L2 Loss :  0.054323024451732635  Test L2 Loss :  0.0788385346531868  inv_L_scale:  [1.0, 1.0]
Epoch :  413  Time:  0.862  Rel. Train L2 Loss :  0.05053312674164772  Rel. Test L2 Loss :  0.05444172739982605  Test L2 Loss :  0.07909845024347305  inv_L_scale:  [1.0, 1.0]
Epoch :  414  Time:  0.862  Rel. Train L2 Loss :  0.0505974055826664  Rel. Test L2 Loss :  0.05465657562017441  Test L2 Loss :  0.0793282413482666  inv_L_scale:  [1.0, 1.0]
Epoch :  415  Time:  0.863  Rel. Train L2 Loss :  0.05055652524034182  Rel. Test L2 Loss :  0.05426816806197166  Test L2 Loss :  0.07891113042831421  inv_L_scale:  [1.0, 1.0]
Epoch :  416  Time:  0.862  Rel. Train L2 Loss :  0.050506564974784854  Rel. Test L2 Loss :  0.05444896847009659  Test L2 Loss :  0.07903273969888687  inv_L_scale:  [1.0, 1.0]
Epoch :  417  Time:  0.862  Rel. Train L2 Loss :  0.050485875358184176  Rel. Test L2 Loss :  0.05420258492231369  Test L2 Loss :  0.07876369267702103  inv_L_scale:  [1.0, 1.0]
Epoch :  418  Time:  0.862  Rel. Train L2 Loss :  0.05044013596243328  Rel. Test L2 Loss :  0.05453978568315506  Test L2 Loss :  0.07907212644815445  inv_L_scale:  [1.0, 1.0]
Epoch :  419  Time:  0.862  Rel. Train L2 Loss :  0.050418389058775374  Rel. Test L2 Loss :  0.054317214041948315  Test L2 Loss :  0.07889507412910461  inv_L_scale:  [1.0, 1.0]
Epoch :  420  Time:  0.862  Rel. Train L2 Loss :  0.05044785468114747  Rel. Test L2 Loss :  0.05408620983362198  Test L2 Loss :  0.07851306319236756  inv_L_scale:  [1.0, 1.0]
Epoch :  421  Time:  0.862  Rel. Train L2 Loss :  0.05039192289113999  Rel. Test L2 Loss :  0.054047809094190595  Test L2 Loss :  0.07850305616855621  inv_L_scale:  [1.0, 1.0]
Epoch :  422  Time:  0.862  Rel. Train L2 Loss :  0.05032965103785197  Rel. Test L2 Loss :  0.05422115176916122  Test L2 Loss :  0.07867722749710084  inv_L_scale:  [1.0, 1.0]
Epoch :  423  Time:  0.862  Rel. Train L2 Loss :  0.05037823049558533  Rel. Test L2 Loss :  0.05417025178670883  Test L2 Loss :  0.0786361238360405  inv_L_scale:  [1.0, 1.0]
Epoch :  424  Time:  0.862  Rel. Train L2 Loss :  0.050299255218770766  Rel. Test L2 Loss :  0.054270370602607726  Test L2 Loss :  0.07881109058856964  inv_L_scale:  [1.0, 1.0]
Epoch :  425  Time:  0.862  Rel. Train L2 Loss :  0.050316365410884224  Rel. Test L2 Loss :  0.054176318794488906  Test L2 Loss :  0.07863420128822327  inv_L_scale:  [1.0, 1.0]
Epoch :  426  Time:  0.862  Rel. Train L2 Loss :  0.050328769716951584  Rel. Test L2 Loss :  0.05409504279494286  Test L2 Loss :  0.0785684758424759  inv_L_scale:  [1.0, 1.0]
Epoch :  427  Time:  0.862  Rel. Train L2 Loss :  0.050184019671546086  Rel. Test L2 Loss :  0.05411077439785004  Test L2 Loss :  0.07856492638587952  inv_L_scale:  [1.0, 1.0]
Epoch :  428  Time:  0.862  Rel. Train L2 Loss :  0.0502117409143183  Rel. Test L2 Loss :  0.054116527289152144  Test L2 Loss :  0.07857794523239135  inv_L_scale:  [1.0, 1.0]
Epoch :  429  Time:  0.862  Rel. Train L2 Loss :  0.05017463275127941  Rel. Test L2 Loss :  0.05424444228410721  Test L2 Loss :  0.07879079818725586  inv_L_scale:  [1.0, 1.0]
Epoch :  430  Time:  0.862  Rel. Train L2 Loss :  0.05015306951271163  Rel. Test L2 Loss :  0.05419267147779465  Test L2 Loss :  0.07868724584579467  inv_L_scale:  [1.0, 1.0]
Epoch :  431  Time:  0.862  Rel. Train L2 Loss :  0.05014988718761338  Rel. Test L2 Loss :  0.054041264355182646  Test L2 Loss :  0.07842652052640915  inv_L_scale:  [1.0, 1.0]
Epoch :  432  Time:  0.863  Rel. Train L2 Loss :  0.05010305878188875  Rel. Test L2 Loss :  0.05411157056689262  Test L2 Loss :  0.07858326941728593  inv_L_scale:  [1.0, 1.0]
Epoch :  433  Time:  0.862  Rel. Train L2 Loss :  0.05007893790801366  Rel. Test L2 Loss :  0.054137206822633746  Test L2 Loss :  0.0785882306098938  inv_L_scale:  [1.0, 1.0]
Epoch :  434  Time:  0.862  Rel. Train L2 Loss :  0.05006992883152432  Rel. Test L2 Loss :  0.05402116239070892  Test L2 Loss :  0.0784639409184456  inv_L_scale:  [1.0, 1.0]
Epoch :  435  Time:  0.862  Rel. Train L2 Loss :  0.050082136823071374  Rel. Test L2 Loss :  0.05418138891458511  Test L2 Loss :  0.07867752522230148  inv_L_scale:  [1.0, 1.0]
Epoch :  436  Time:  0.862  Rel. Train L2 Loss :  0.050091040001975166  Rel. Test L2 Loss :  0.05397581294178963  Test L2 Loss :  0.07844600588083267  inv_L_scale:  [1.0, 1.0]
Epoch :  437  Time:  0.862  Rel. Train L2 Loss :  0.05001441074742211  Rel. Test L2 Loss :  0.05412038832902908  Test L2 Loss :  0.07865199446678162  inv_L_scale:  [1.0, 1.0]
Epoch :  438  Time:  0.862  Rel. Train L2 Loss :  0.049968606448835794  Rel. Test L2 Loss :  0.054020313769578936  Test L2 Loss :  0.07844489395618438  inv_L_scale:  [1.0, 1.0]
Epoch :  439  Time:  0.862  Rel. Train L2 Loss :  0.04994394550720851  Rel. Test L2 Loss :  0.05409583568572998  Test L2 Loss :  0.07858309477567672  inv_L_scale:  [1.0, 1.0]
Epoch :  440  Time:  0.862  Rel. Train L2 Loss :  0.04995072225729624  Rel. Test L2 Loss :  0.05399475812911987  Test L2 Loss :  0.07840232968330384  inv_L_scale:  [1.0, 1.0]
Epoch :  441  Time:  0.862  Rel. Train L2 Loss :  0.04991446311275164  Rel. Test L2 Loss :  0.0540105602145195  Test L2 Loss :  0.07847000062465667  inv_L_scale:  [1.0, 1.0]
Epoch :  442  Time:  0.862  Rel. Train L2 Loss :  0.04990959846311145  Rel. Test L2 Loss :  0.05412877216935158  Test L2 Loss :  0.0785957932472229  inv_L_scale:  [1.0, 1.0]
Epoch :  443  Time:  0.863  Rel. Train L2 Loss :  0.04987682681944635  Rel. Test L2 Loss :  0.054015088230371475  Test L2 Loss :  0.07847170501947404  inv_L_scale:  [1.0, 1.0]
Epoch :  444  Time:  0.862  Rel. Train L2 Loss :  0.04990642143620385  Rel. Test L2 Loss :  0.05399198621511459  Test L2 Loss :  0.07838910549879075  inv_L_scale:  [1.0, 1.0]
Epoch :  445  Time:  0.862  Rel. Train L2 Loss :  0.049880584246582454  Rel. Test L2 Loss :  0.053940576761960984  Test L2 Loss :  0.07832186341285706  inv_L_scale:  [1.0, 1.0]
Epoch :  446  Time:  0.862  Rel. Train L2 Loss :  0.0498702321615484  Rel. Test L2 Loss :  0.05396638184785843  Test L2 Loss :  0.07835271865129471  inv_L_scale:  [1.0, 1.0]
Epoch :  447  Time:  0.862  Rel. Train L2 Loss :  0.04984828992022408  Rel. Test L2 Loss :  0.05401360079646111  Test L2 Loss :  0.078441521525383  inv_L_scale:  [1.0, 1.0]
Epoch :  448  Time:  0.862  Rel. Train L2 Loss :  0.049820193979475236  Rel. Test L2 Loss :  0.05390222638845444  Test L2 Loss :  0.07825652450323105  inv_L_scale:  [1.0, 1.0]
Epoch :  449  Time:  0.862  Rel. Train L2 Loss :  0.04981429459320175  Rel. Test L2 Loss :  0.05406418338418007  Test L2 Loss :  0.07850178599357605  inv_L_scale:  [1.0, 1.0]
Epoch :  450  Time:  0.862  Rel. Train L2 Loss :  0.049814105199442966  Rel. Test L2 Loss :  0.05395278438925743  Test L2 Loss :  0.07837106704711914  inv_L_scale:  [1.0, 1.0]
Epoch :  451  Time:  0.862  Rel. Train L2 Loss :  0.04978644665744569  Rel. Test L2 Loss :  0.05404755532741547  Test L2 Loss :  0.07849668949842453  inv_L_scale:  [1.0, 1.0]
Epoch :  452  Time:  0.862  Rel. Train L2 Loss :  0.04976795451508628  Rel. Test L2 Loss :  0.05398163825273514  Test L2 Loss :  0.0783727991580963  inv_L_scale:  [1.0, 1.0]
Epoch :  453  Time:  0.862  Rel. Train L2 Loss :  0.04971640338500341  Rel. Test L2 Loss :  0.05391720667481423  Test L2 Loss :  0.07831615567207337  inv_L_scale:  [1.0, 1.0]
Epoch :  454  Time:  0.862  Rel. Train L2 Loss :  0.04974030478133096  Rel. Test L2 Loss :  0.053916049301624296  Test L2 Loss :  0.07833064794540405  inv_L_scale:  [1.0, 1.0]
Epoch :  455  Time:  0.862  Rel. Train L2 Loss :  0.04969239186909464  Rel. Test L2 Loss :  0.05395955190062523  Test L2 Loss :  0.07834724515676499  inv_L_scale:  [1.0, 1.0]
Epoch :  456  Time:  0.862  Rel. Train L2 Loss :  0.04968014703856574  Rel. Test L2 Loss :  0.053930625915527344  Test L2 Loss :  0.07831566542387008  inv_L_scale:  [1.0, 1.0]
Epoch :  457  Time:  0.862  Rel. Train L2 Loss :  0.049690713054604  Rel. Test L2 Loss :  0.05393987506628037  Test L2 Loss :  0.07831451773643494  inv_L_scale:  [1.0, 1.0]
Epoch :  458  Time:  0.862  Rel. Train L2 Loss :  0.04966936747233073  Rel. Test L2 Loss :  0.05394839644432068  Test L2 Loss :  0.07833173602819443  inv_L_scale:  [1.0, 1.0]
Epoch :  459  Time:  0.861  Rel. Train L2 Loss :  0.04964907457431157  Rel. Test L2 Loss :  0.05390147715806961  Test L2 Loss :  0.07826359719038009  inv_L_scale:  [1.0, 1.0]
Epoch :  460  Time:  0.863  Rel. Train L2 Loss :  0.04963221510251363  Rel. Test L2 Loss :  0.05388315320014954  Test L2 Loss :  0.07824704736471176  inv_L_scale:  [1.0, 1.0]
Epoch :  461  Time:  0.862  Rel. Train L2 Loss :  0.04962006795737479  Rel. Test L2 Loss :  0.05386606767773628  Test L2 Loss :  0.07822942912578583  inv_L_scale:  [1.0, 1.0]
Epoch :  462  Time:  0.862  Rel. Train L2 Loss :  0.04960517888267835  Rel. Test L2 Loss :  0.05390975683927536  Test L2 Loss :  0.07829111218452453  inv_L_scale:  [1.0, 1.0]
Epoch :  463  Time:  0.861  Rel. Train L2 Loss :  0.04958482955892881  Rel. Test L2 Loss :  0.05390370592474938  Test L2 Loss :  0.07828698188066482  inv_L_scale:  [1.0, 1.0]
Epoch :  464  Time:  0.862  Rel. Train L2 Loss :  0.04956343359417385  Rel. Test L2 Loss :  0.05388069167733192  Test L2 Loss :  0.0782338598370552  inv_L_scale:  [1.0, 1.0]
Epoch :  465  Time:  0.862  Rel. Train L2 Loss :  0.04956767315665881  Rel. Test L2 Loss :  0.05393928930163384  Test L2 Loss :  0.07832000136375428  inv_L_scale:  [1.0, 1.0]
Epoch :  466  Time:  0.862  Rel. Train L2 Loss :  0.04955375282300843  Rel. Test L2 Loss :  0.05391723990440369  Test L2 Loss :  0.0782918506860733  inv_L_scale:  [1.0, 1.0]
Epoch :  467  Time:  0.862  Rel. Train L2 Loss :  0.04954067309697469  Rel. Test L2 Loss :  0.053881070464849475  Test L2 Loss :  0.07824782848358154  inv_L_scale:  [1.0, 1.0]
Epoch :  468  Time:  0.861  Rel. Train L2 Loss :  0.04952426570985052  Rel. Test L2 Loss :  0.05387029021978378  Test L2 Loss :  0.07823347121477127  inv_L_scale:  [1.0, 1.0]
Epoch :  469  Time:  0.862  Rel. Train L2 Loss :  0.04951962989237573  Rel. Test L2 Loss :  0.05386883527040481  Test L2 Loss :  0.07823413133621215  inv_L_scale:  [1.0, 1.0]
Epoch :  470  Time:  0.862  Rel. Train L2 Loss :  0.0495218715733952  Rel. Test L2 Loss :  0.053881842195987704  Test L2 Loss :  0.07825803160667419  inv_L_scale:  [1.0, 1.0]
Epoch :  471  Time:  0.862  Rel. Train L2 Loss :  0.04950078022148874  Rel. Test L2 Loss :  0.05385737806558609  Test L2 Loss :  0.07820287644863129  inv_L_scale:  [1.0, 1.0]
Epoch :  472  Time:  0.862  Rel. Train L2 Loss :  0.04948672945300738  Rel. Test L2 Loss :  0.053916344046592714  Test L2 Loss :  0.07829547554254532  inv_L_scale:  [1.0, 1.0]
Epoch :  473  Time:  0.862  Rel. Train L2 Loss :  0.04948351653085815  Rel. Test L2 Loss :  0.05389425963163376  Test L2 Loss :  0.07825512647628784  inv_L_scale:  [1.0, 1.0]
Epoch :  474  Time:  0.862  Rel. Train L2 Loss :  0.04948181279831462  Rel. Test L2 Loss :  0.053877415359020235  Test L2 Loss :  0.07824252545833588  inv_L_scale:  [1.0, 1.0]
Epoch :  475  Time:  0.862  Rel. Train L2 Loss :  0.04946827388472027  Rel. Test L2 Loss :  0.05384686693549156  Test L2 Loss :  0.07820098996162414  inv_L_scale:  [1.0, 1.0]
Epoch :  476  Time:  0.861  Rel. Train L2 Loss :  0.04947002703944842  Rel. Test L2 Loss :  0.05387778326869011  Test L2 Loss :  0.07823983788490295  inv_L_scale:  [1.0, 1.0]
Epoch :  477  Time:  0.862  Rel. Train L2 Loss :  0.04946679203046693  Rel. Test L2 Loss :  0.05386256977915764  Test L2 Loss :  0.07821424037218094  inv_L_scale:  [1.0, 1.0]
Epoch :  478  Time:  0.863  Rel. Train L2 Loss :  0.0494502453174856  Rel. Test L2 Loss :  0.05388171285390854  Test L2 Loss :  0.07825686126947402  inv_L_scale:  [1.0, 1.0]
Epoch :  479  Time:  0.862  Rel. Train L2 Loss :  0.049446457127730055  Rel. Test L2 Loss :  0.05387052685022354  Test L2 Loss :  0.07823301017284394  inv_L_scale:  [1.0, 1.0]
Epoch :  480  Time:  0.862  Rel. Train L2 Loss :  0.04943861009346114  Rel. Test L2 Loss :  0.05387777552008629  Test L2 Loss :  0.07823908597230911  inv_L_scale:  [1.0, 1.0]
Epoch :  481  Time:  0.862  Rel. Train L2 Loss :  0.04941910314891074  Rel. Test L2 Loss :  0.05385050684213638  Test L2 Loss :  0.07819592595100402  inv_L_scale:  [1.0, 1.0]
Epoch :  482  Time:  0.862  Rel. Train L2 Loss :  0.04940853224860298  Rel. Test L2 Loss :  0.05386692315340042  Test L2 Loss :  0.07821660250425339  inv_L_scale:  [1.0, 1.0]
Epoch :  483  Time:  0.861  Rel. Train L2 Loss :  0.049407813681496514  Rel. Test L2 Loss :  0.05386823147535324  Test L2 Loss :  0.07823055416345596  inv_L_scale:  [1.0, 1.0]
Epoch :  484  Time:  0.862  Rel. Train L2 Loss :  0.0494047680331601  Rel. Test L2 Loss :  0.0538551327586174  Test L2 Loss :  0.07820961326360702  inv_L_scale:  [1.0, 1.0]
Epoch :  485  Time:  0.862  Rel. Train L2 Loss :  0.04940011238058408  Rel. Test L2 Loss :  0.05388021618127823  Test L2 Loss :  0.07824416249990464  inv_L_scale:  [1.0, 1.0]
Epoch :  486  Time:  0.862  Rel. Train L2 Loss :  0.04940079197287559  Rel. Test L2 Loss :  0.0538690473139286  Test L2 Loss :  0.07824457049369812  inv_L_scale:  [1.0, 1.0]
Epoch :  487  Time:  0.862  Rel. Train L2 Loss :  0.049383724066946244  Rel. Test L2 Loss :  0.05387861117720604  Test L2 Loss :  0.0782409942150116  inv_L_scale:  [1.0, 1.0]
Epoch :  488  Time:  0.862  Rel. Train L2 Loss :  0.04939383892549409  Rel. Test L2 Loss :  0.05386954829096794  Test L2 Loss :  0.0782274729013443  inv_L_scale:  [1.0, 1.0]
Epoch :  489  Time:  0.862  Rel. Train L2 Loss :  0.049377686927715936  Rel. Test L2 Loss :  0.05387682616710663  Test L2 Loss :  0.07823724567890167  inv_L_scale:  [1.0, 1.0]
Epoch :  490  Time:  0.862  Rel. Train L2 Loss :  0.04937920254137781  Rel. Test L2 Loss :  0.053865963220596315  Test L2 Loss :  0.07823061168193818  inv_L_scale:  [1.0, 1.0]
Epoch :  491  Time:  0.862  Rel. Train L2 Loss :  0.049369886302285726  Rel. Test L2 Loss :  0.05387198805809021  Test L2 Loss :  0.07823259860277176  inv_L_scale:  [1.0, 1.0]
Epoch :  492  Time:  0.862  Rel. Train L2 Loss :  0.049371231744686765  Rel. Test L2 Loss :  0.053870221972465514  Test L2 Loss :  0.07823483020067215  inv_L_scale:  [1.0, 1.0]
Epoch :  493  Time:  0.862  Rel. Train L2 Loss :  0.04937131812175115  Rel. Test L2 Loss :  0.053863368779420856  Test L2 Loss :  0.07822658836841584  inv_L_scale:  [1.0, 1.0]
Epoch :  494  Time:  0.862  Rel. Train L2 Loss :  0.04936824560165405  Rel. Test L2 Loss :  0.05386702850461006  Test L2 Loss :  0.07823222398757934  inv_L_scale:  [1.0, 1.0]
Epoch :  495  Time:  0.862  Rel. Train L2 Loss :  0.049371204541789164  Rel. Test L2 Loss :  0.05388606935739517  Test L2 Loss :  0.07825280040502548  inv_L_scale:  [1.0, 1.0]
Epoch :  496  Time:  0.862  Rel. Train L2 Loss :  0.049366679224703044  Rel. Test L2 Loss :  0.05387501358985901  Test L2 Loss :  0.07823310762643815  inv_L_scale:  [1.0, 1.0]
Epoch :  497  Time:  0.861  Rel. Train L2 Loss :  0.049366548624303605  Rel. Test L2 Loss :  0.0538605572283268  Test L2 Loss :  0.07821549117565155  inv_L_scale:  [1.0, 1.0]
Epoch :  498  Time:  0.861  Rel. Train L2 Loss :  0.049365833616918986  Rel. Test L2 Loss :  0.05388329744338989  Test L2 Loss :  0.07824217796325683  inv_L_scale:  [1.0, 1.0]
Epoch :  499  Time:  0.862  Rel. Train L2 Loss :  0.04936551945077049  Rel. Test L2 Loss :  0.05386780738830566  Test L2 Loss :  0.07822660654783249  inv_L_scale:  [1.0, 1.0]
